"use strict";(self.webpackChunklangflow_docs=self.webpackChunklangflow_docs||[]).push([[3456],{9047:(e,n,t)=>{t.d(n,{Z:()=>O});var s=t(7294),i=t(5893);function o(e){const{mdxAdmonitionTitle:n,rest:t}=function(e){const n=s.Children.toArray(e),t=n.find((e=>s.isValidElement(e)&&"mdxAdmonitionTitle"===e.type)),o=n.filter((e=>e!==t)),d=t?.props.children;return{mdxAdmonitionTitle:d,rest:o.length>0?(0,i.jsx)(i.Fragment,{children:o}):null}}(e.children),o=e.title??n;return{...e,...o&&{title:o},children:t}}var d=t(6905),r=t(5999),l=t(5281);const a={admonition:"admonition_xJq3",admonitionHeading:"admonitionHeading_Gvgb",admonitionIcon:"admonitionIcon_Rf37",admonitionContent:"admonitionContent_BuS1"};function c(e){let{type:n,className:t,children:s}=e;return(0,i.jsx)("div",{className:(0,d.Z)(l.k.common.admonition,l.k.common.admonitionType(n),a.admonition,t),children:s})}function h(e){let{icon:n,title:t}=e;return(0,i.jsxs)("div",{className:a.admonitionHeading,children:[(0,i.jsx)("span",{className:a.admonitionIcon,children:n}),t]})}function m(e){let{children:n}=e;return n?(0,i.jsx)("div",{className:a.admonitionContent,children:n}):null}function u(e){const{type:n,icon:t,title:s,children:o,className:d}=e;return(0,i.jsxs)(c,{type:n,className:d,children:[(0,i.jsx)(h,{title:s,icon:t}),(0,i.jsx)(m,{children:o})]})}function x(e){return(0,i.jsx)("svg",{viewBox:"0 0 14 16",...e,children:(0,i.jsx)("path",{fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"})})}const g={icon:(0,i.jsx)(x,{}),title:(0,i.jsx)(r.Z,{id:"theme.admonition.note",description:"The default label used for the Note admonition (:::note)",children:"note"})};function p(e){return(0,i.jsx)(u,{...g,...e,className:(0,d.Z)("alert alert--secondary",e.className),children:e.children})}function f(e){return(0,i.jsx)("svg",{viewBox:"0 0 12 16",...e,children:(0,i.jsx)("path",{fillRule:"evenodd",d:"M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"})})}const j={icon:(0,i.jsx)(f,{}),title:(0,i.jsx)(r.Z,{id:"theme.admonition.tip",description:"The default label used for the Tip admonition (:::tip)",children:"tip"})};function b(e){return(0,i.jsx)(u,{...j,...e,className:(0,d.Z)("alert alert--success",e.className),children:e.children})}function v(e){return(0,i.jsx)("svg",{viewBox:"0 0 14 16",...e,children:(0,i.jsx)("path",{fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"})})}const w={icon:(0,i.jsx)(v,{}),title:(0,i.jsx)(r.Z,{id:"theme.admonition.info",description:"The default label used for the Info admonition (:::info)",children:"info"})};function y(e){return(0,i.jsx)(u,{...w,...e,className:(0,d.Z)("alert alert--info",e.className),children:e.children})}function I(e){return(0,i.jsx)("svg",{viewBox:"0 0 16 16",...e,children:(0,i.jsx)("path",{fillRule:"evenodd",d:"M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"})})}const A={icon:(0,i.jsx)(I,{}),title:(0,i.jsx)(r.Z,{id:"theme.admonition.warning",description:"The default label used for the Warning admonition (:::warning)",children:"warning"})};function k(e){return(0,i.jsx)("svg",{viewBox:"0 0 12 16",...e,children:(0,i.jsx)("path",{fillRule:"evenodd",d:"M5.05.31c.81 2.17.41 3.38-.52 4.31C3.55 5.67 1.98 6.45.9 7.98c-1.45 2.05-1.7 6.53 3.53 7.7-2.2-1.16-2.67-4.52-.3-6.61-.61 2.03.53 3.33 1.94 2.86 1.39-.47 2.3.53 2.27 1.67-.02.78-.31 1.44-1.13 1.81 3.42-.59 4.78-3.42 4.78-5.56 0-2.84-2.53-3.22-1.25-5.61-1.52.13-2.03 1.13-1.89 2.75.09 1.08-1.02 1.8-1.86 1.33-.67-.41-.66-1.19-.06-1.78C8.18 5.31 8.68 2.45 5.05.32L5.03.3l.02.01z"})})}const _={icon:(0,i.jsx)(k,{}),title:(0,i.jsx)(r.Z,{id:"theme.admonition.danger",description:"The default label used for the Danger admonition (:::danger)",children:"danger"})};const T={icon:(0,i.jsx)(I,{}),title:(0,i.jsx)(r.Z,{id:"theme.admonition.caution",description:"The default label used for the Caution admonition (:::caution)",children:"caution"})};const z={...{note:p,tip:b,info:y,warning:function(e){return(0,i.jsx)(u,{...A,...e,className:(0,d.Z)("alert alert--warning",e.className),children:e.children})},danger:function(e){return(0,i.jsx)(u,{..._,...e,className:(0,d.Z)("alert alert--danger",e.className),children:e.children})}},...{secondary:e=>(0,i.jsx)(p,{title:"secondary",...e}),important:e=>(0,i.jsx)(y,{title:"important",...e}),success:e=>(0,i.jsx)(b,{title:"success",...e}),caution:function(e){return(0,i.jsx)(u,{...T,...e,className:(0,d.Z)("alert alert--warning",e.className),children:e.children})}}};var C=t(5108);function O(e){const n=o(e),t=(s=n.type,z[s]||(C.warn(`No admonition component found for admonition type "${s}". Using Info as fallback.`),z.info));var s;return(0,i.jsx)(t,{...n})}},7116:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>r,default:()=>m,frontMatter:()=>d,metadata:()=>l,toc:()=>c});t(7294);var s=t(5893),i=t(1151),o=t(9047);const d={},r="Embeddings",l={id:"components/embeddings",title:"Embeddings",description:"We appreciate your understanding as we polish our documentation \u2013 it may",source:"@site/docs/components/embeddings.mdx",sourceDirName:"components",slug:"/components/embeddings",permalink:"/components/embeddings",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"docs",previous:{title:"Custom Components",permalink:"/components/custom"},next:{title:"LLMs",permalink:"/components/llms"}},a={},c=[{value:"BedrockEmbeddings",id:"bedrockembeddings",level:3},{value:"CohereEmbeddings",id:"cohereembeddings",level:3},{value:"HuggingFaceEmbeddings",id:"huggingfaceembeddings",level:3},{value:"OpenAIEmbeddings",id:"openaiembeddings",level:3},{value:"VertexAIEmbeddings",id:"vertexaiembeddings",level:3},{value:"OllamaEmbeddings",id:"ollamaembeddings",level:3}];function h(e){const n=Object.assign({h1:"h1",p:"p",hr:"hr",h3:"h3",a:"a",strong:"strong",ul:"ul",li:"li",code:"code"},(0,i.ah)(),e.components);return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"embeddings",children:"Embeddings"}),"\n",(0,s.jsx)(o.Z,{type:"caution",icon:"\ud83d\udea7",title:"ZONE UNDER CONSTRUCTION",children:(0,s.jsx)("p",{children:(0,s.jsx)(n.p,{children:"We appreciate your understanding as we polish our documentation \u2013 it may\ncontain some rough edges. Share your feedback or report issues to help us\nimprove! \ud83d\udee0\ufe0f\ud83d\udcdd"})})}),"\n",(0,s.jsx)(n.p,{children:"Embeddings are vector representations of text that capture the semantic meaning of the text. They are created using text embedding models and allow us to think about the text in a vector space, enabling us to perform tasks like semantic search, where we look for pieces of text that are most similar in the vector space."}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"bedrockembeddings",children:"BedrockEmbeddings"}),"\n",(0,s.jsxs)(n.p,{children:["Used to load ",(0,s.jsx)(n.a,{href:"https://aws.amazon.com/bedrock/",children:"Amazon Bedrocks\u2019s"})," embedding models."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Params"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"credentials_profile_name:"})," The name of the profile in the ~/.aws/credentials or ~/.aws/config files, which has either access keys or role information specified. If not specified, the default credential profile or, if on an EC2 instance, credentials from IMDS will be used. See ",(0,s.jsx)(n.a,{href:"https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html",children:"the AWS documentation"})," for more details."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"model_id:"})," Id of the model to call, e.g., amazon.titan-embed-text-v1, this is equivalent to the modelId property in the list-foundation-models api."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"endpoint_url:"})," Needed if you don\u2019t want to default to us-east-1 endpoint."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"region_name:"})," The aws region e.g., us-west-2. Fallsback to AWS_DEFAULT_REGION env variable or region specified in ~/.aws/config in case it is not provided here."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"cohereembeddings",children:"CohereEmbeddings"}),"\n",(0,s.jsxs)(n.p,{children:["Used to load ",(0,s.jsx)(n.a,{href:"https://cohere.com/",children:"Cohere\u2019s"})," embedding models."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Params"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"cohere_api_key:"})," Holds the API key required to authenticate with the Cohere service."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"model:"})," The language model used for embedding text documents and performing queries \u2014defaults to ",(0,s.jsx)(n.code,{children:"embed-english-v2.0"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"truncate:"})," Used to specify whether or not to truncate the input text. Truncation is useful when dealing with long texts that exceed the model's maximum input length. By truncating the text, the user can ensure that it fits within the model's constraints."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"huggingfaceembeddings",children:"HuggingFaceEmbeddings"}),"\n",(0,s.jsxs)(n.p,{children:["Used to load ",(0,s.jsx)(n.a,{href:"https://huggingface.co",children:"HuggingFace\u2019s"})," embedding models."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Params"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"cache_folder:"})," Used to specify the folder where the embeddings will be cached. When embeddings are computed for a text, they can be stored in the cache folder so that they can be reused later without the need to recompute them. This can improve the performance of the application by avoiding redundant computations."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"encode_kwargs:"})," Used to pass additional keyword arguments to the encoding method of the underlying HuggingFace model. These keyword arguments can be used to customize the encoding process, such as specifying the maximum length of the input sequence or enabling truncation or padding."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"model_kwargs:"})," Used to customize the behavior of the model, such as specifying the model architecture, the tokenizer, or any other model-specific configuration options. By using ",(0,s.jsx)(n.code,{children:"model_kwargs"}),", the user can configure the HuggingFace model according to specific needs and preferences."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"model_name:"})," Used to specify the name or identifier of the HuggingFace model that will be used for generating embeddings. It allows users to choose a specific pre-trained model from the Hugging Face model hub \u2014 defaults to ",(0,s.jsx)(n.code,{children:"sentence-transformers/all-mpnet-base-v2"}),"."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"openaiembeddings",children:"OpenAIEmbeddings"}),"\n",(0,s.jsxs)(n.p,{children:["Used to load ",(0,s.jsx)(n.a,{href:"https://openai.com/",children:"OpenAI\u2019s"})," embedding models."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Params"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"chunk_size:"})," Determines the maximum size of each chunk of text that is processed for embedding. If any of the incoming text chunks exceeds ",(0,s.jsx)(n.code,{children:"chunk_size"})," characters, it will be split into multiple chunks of size ",(0,s.jsx)(n.code,{children:"chunk_size"})," or less before being embedded \u2014 defaults to ",(0,s.jsx)(n.code,{children:"1000"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"deployment:"})," Used to specify the deployment name or identifier of the text embedding model. It allows the user to choose a specific deployment of the model to use for embedding. When the deployment is provided, this can be useful when the user has multiple deployments of the same model with different configurations or versions \u2014 defaults to ",(0,s.jsx)(n.code,{children:"text-embedding-ada-002"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"embedding_ctx_length:"})," This parameter determines the maximum context length for the text embedding model. It specifies the number of tokens that the model considers when generating embeddings for a piece of text \u2014 defaults to ",(0,s.jsx)(n.code,{children:"8191"})," (this means that the model will consider up to 8191 tokens when generating embeddings)."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"max_retries:"})," Determines the maximum number of times to retry a request if the model provider returns an error from their API \u2014 defaults to ",(0,s.jsx)(n.code,{children:"6"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"model:"})," Defines which pre-trained text embedding model to use \u2014 defaults to ",(0,s.jsx)(n.code,{children:"text-embedding-ada-002"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"openai_api_base:"})," Refers to the base URL for the Azure OpenAI resource. It is used to configure the API to connect to the Azure OpenAI service. The base URL can be found in the Azure portal under the user Azure OpenAI resource."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"openai_api_key:"})," Is used to authenticate and authorize access to the OpenAI service."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"openai_api_type:"})," Is used to specify the type of OpenAI API being used, either the regular OpenAI API or the Azure OpenAI API. This parameter allows the ",(0,s.jsx)(n.code,{children:"OpenAIEmbeddings"})," class to connect to the appropriate API service."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"openai_api_version:"})," Is used to specify the version of the OpenAI API being used. This parameter allows the ",(0,s.jsx)(n.code,{children:"OpenAIEmbeddings"})," class to connect to the appropriate version of the OpenAI API service."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"openai_organization:"})," Is used to specify the organization associated with the OpenAI API key. If not provided, the default organization associated with the API key will be used."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"openai_proxy:"})," Proxy enables better budgeting and cost management for making OpenAI API calls, including more transparency into pricing."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"request_timeout:"})," Used to specify the maximum amount of time, in milliseconds, to wait for a response from the OpenAI API when generating embeddings for a given text."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"tiktoken_model_name:"})," Used to count the number of tokens in documents to constrain them to be under a certain limit. By default, when set to None, this will be the same as the embedding model name."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"vertexaiembeddings",children:"VertexAIEmbeddings"}),"\n",(0,s.jsxs)(n.p,{children:["Wrapper around ",(0,s.jsx)(n.a,{href:"https://cloud.google.com/vertex-ai",children:"Google Vertex AI"})," ",(0,s.jsx)(n.a,{href:"https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings",children:"Embeddings API"}),"."]}),"\n",(0,s.jsx)(o.Z,{type:"info",children:(0,s.jsxs)(n.p,{children:["Vertex AI is a cloud computing platform offered by Google Cloud Platform (GCP). It provides access, management, and development of applications and services through global data centers. To use Vertex AI PaLM, you need to have the ",(0,s.jsx)(n.a,{href:"https://pypi.org/project/google-cloud-aiplatform/",children:"google-cloud-aiplatform"})," Python package installed and credentials configured for your environment."]})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"credentials:"})," The default custom credentials (google.auth.credentials.Credentials) to use."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"location:"})," The default location to use when making API calls \u2013 defaults to ",(0,s.jsx)(n.code,{children:"us-central1"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"max_output_tokens:"})," Token limit determines the maximum amount of text output from one prompt \u2013 defaults to ",(0,s.jsx)(n.code,{children:"128"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"model_name:"})," The name of the Vertex AI large language model \u2013 defaults to ",(0,s.jsx)(n.code,{children:"text-bison"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"project:"})," The default GCP project to use when making Vertex API calls."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"request_parallelism:"})," The amount of parallelism allowed for requests issued to VertexAI models \u2013 defaults to ",(0,s.jsx)(n.code,{children:"5"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"temperature:"})," Tunes the degree of randomness in text generations. Should be a non-negative value \u2013 defaults to ",(0,s.jsx)(n.code,{children:"0"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"top_k:"})," How the model selects tokens for output, the next token is selected from \u2013 defaults to ",(0,s.jsx)(n.code,{children:"40"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"top_p:"})," Tokens are selected from most probable to least until the sum of their \u2013 defaults to ",(0,s.jsx)(n.code,{children:"0.95"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tuned_model_name:"})," The name of a tuned model. If provided, model_name is ignored."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"verbose:"})," This parameter is used to control the level of detail in the output of the chain. When set to True, it will print out some internal states of the chain while it is being run, which can help debug and understand the chain's behavior. If set to False, it will suppress the verbose output \u2013 defaults to ",(0,s.jsx)(n.code,{children:"False"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"ollamaembeddings",children:"OllamaEmbeddings"}),"\n",(0,s.jsxs)(n.p,{children:["Used to load ",(0,s.jsx)(n.a,{href:"https://ollama.ai/",children:"Ollama\u2019s"})," embedding models. Wrapper around LangChain's ",(0,s.jsx)(n.a,{href:"https://python.langchain.com/docs/integrations/text_embedding/ollama",children:"Ollama API"}),"."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"model"})," The name of the Ollama model to use \u2013 defaults to ",(0,s.jsx)(n.code,{children:"llama2"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"base_url"})," The base URL for the Ollama API \u2013 defaults to ",(0,s.jsx)(n.code,{children:"http://localhost:11434"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"temperature"})," Tunes the degree of randomness in text generations. Should be a non-negative value \u2013 defaults to ",(0,s.jsx)(n.code,{children:"0"}),"."]}),"\n"]})]})}const m=function(e={}){const{wrapper:n}=Object.assign({},(0,i.ah)(),e.components);return n?(0,s.jsx)(n,Object.assign({},e,{children:(0,s.jsx)(h,e)})):h(e)}},1151:(e,n,t)=>{t.d(n,{Zo:()=>r,ah:()=>o});var s=t(7294);const i=s.createContext({});function o(e){const n=s.useContext(i);return s.useMemo((()=>"function"==typeof e?e(n):{...n,...e}),[n,e])}const d={};function r({components:e,children:n,disableParentContext:t}){let r;return r=t?"function"==typeof e?e({}):e||d:o(e),s.createElement(i.Provider,{value:r},n)}}}]);