---
title: Processing
slug: /components-processing
---

import Icon from "@site/src/components/icon";
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import PartialParams from '@site/docs/_partial-hidden-params.mdx';
import PartialCurlyBraces from '@site/docs/_partial-escape-curly-braces.mdx';

Processing components process and transform data within a flow.
For example:

* **Extract and format data**: Extract content from structured data using templates with the [**Parser** component](#parser), or split text into chunks with the [**Split Text** component](#split-text).

* **Transform data structures**: Convert data between different types with the [**Type Convert** component](#type-convert), or perform operations on structured data with the [**Data Operations** component](#data-operations) and [**DataFrame Operations** component](#dataframe-operations).

## Prompt Template

See [**Prompt Template** component](/components-prompts).

## Data Operations

The **Data Operations** component performs operations on [`Data`](/data-types#data) objects, including extracting, filtering, and editing keys and values in the `Data`.
For all options, see [Available data operations](#available-data-operations).
The output is a new `Data` object containing the modified data after running the selected operation.

### Use the Data Operations component in a flow

The following example demonstrates how to use a **Data Operations** component in a flow using data from a webhook payload:

1. Create a flow with a **Webhook** component and a **Data Operations** component, and then connect the **Webhook** component's output to the **Data Operations** component's **Data** input.

    All operations in the **Data Operations** component require at least one `Data` input from another component.
    If the preceding component doesn't produce `Data` output, you can use another component, such as the **Type Convert** component, to reformat the data before passing it to the **Data Operations** component.
    Alternatively, you could consider using a component that is designed to process the original data type, such as the **Parser** or **DataFrame Operations** components.

2. In the **Operations** field, select the operation you want to perform on the incoming `Data`.
For this example, select the **Select Keys** operation.

    :::tip
    You can select only one operation.
    If you need to perform multiple operations on the data, you can chain multiple **Data Operations** components together to execute each operation in sequence.
    For more complex multi-step operations, consider using a component like the **Smart Transform** component.
    :::

3. Under **Select Keys**, add keys for `name`, `username`, and `email`.
Click <Icon name="Plus" aria-hidden="true" /> **Add more** to add a field for each key.

    For this example, assume that the webhook will receive consistent payloads that always contain `name`, `username`, and `email` keys.
    The **Select Keys** operation extracts the value of these keys from each incoming payload.

4. Optional: If you want to view the output in the **Playground**, connect the **Data Operations** component's output to a **Chat Output** component.

    ![A flow with Webhook, Data Operations, and Chat Output components](/img/component-data-operations-select-key.png)

5. To test the flow, send the following request to your flow's webhook endpoint.
For more information about the webhook endpoint, see [Trigger flows with webhooks](/webhook).

    ```bash
    curl -X POST "http://$LANGFLOW_SERVER_URL/api/v1/webhook/$FLOW_ID" \
    -H "Content-Type: application/json" \
    -H "x-api-key: $LANGFLOW_API_KEY" \
    -d '{
      "id": 1,
      "name": "Leanne Graham",
      "username": "Bret",
      "email": "Sincere@april.biz",
      "address": {
        "street": "Main Street",
        "suite": "Apt. 556",
        "city": "Springfield",
        "zipcode": "92998-3874",
        "geo": {
          "lat": "-37.3159",
          "lng": "81.1496"
        }
      },
      "phone": "1-770-736-8031 x56442",
      "website": "hildegard.org",
      "company": {
        "name": "Acme-Corp",
        "catchPhrase": "Multi-layered client-server neural-net",
        "bs": "harness real-time e-markets"
      }
    }'
    ```

6. To view the `Data` resulting from the **Select Keys** operation, do one of the following:

   * If you attached a **Chat Output** component, open the **Playground** to see the result as a chat message.
   * Click <Icon name="TextSearch" aria-hidden="true" /> **Inspect output** on the **Data Operations** component.

### Data Operations parameters

Many parameters are conditional based on the selected **Operation** (`operation`).

| Name | Display Name | Info |
|------|--------------|------|
| data | Data | Input parameter. The `Data` object to operate on. |
| operation | Operation | Input parameter. The operation to perform on the data. See [Available data operations](#available-data-operations) |
| select_keys_input | Select Keys | Input parameter. A list of keys to select from the data. |
| filter_key | Filter Key | Input parameter. The key to filter by. |
| operator | Comparison Operator | Input parameter. The operator to apply for comparing values. |
| filter_values | Filter Values | Input parameter. A list of values to filter by. |
| append_update_data | Append or Update | Input parameter. The data to append or update the existing data with. |
| remove_keys_input | Remove Keys | Input parameter. A list of keys to remove from the data. |
| rename_keys_input | Rename Keys | Input parameter. A list of keys to rename in the data. |
| mapped_json_display | JSON to Map | Input parameter. JSON structure to explore for path selection. Only applies to the **Path Selection** operation. For more information, see [Path Selection operation examples](#path-selection-operation-examples). |
| selected_key | Select Path | Input parameter. The JSON path expression to extract values. Only applies to the **Path Selection** operation. For more information, see [Path Selection operation examples](#path-selection-operation-examples). |
| query | JQ Expression | Input parameter. The [`jq`](https://jqlang.org/manual/) expression for advanced JSON filtering and transformation. Only applies to the **JQ Expression** operation. For more information, see [JQ Expression operation examples](#jq-expression-operation-examples). |

#### Available data operations

Options for the `operations` input parameter are as follows.
All operations act on an incoming `Data` object.

| Name | Required Inputs | Process |
|-----------|----------------|-------------|
| Select Keys | `select_keys_input` | Selects specific keys from the data. |
| Literal Eval | None | Evaluates string values as Python literals. |
| Combine | None | Combines multiple data objects into one. |
| Filter Values | `filter_key`, `filter_values`, `operator` | Filters data based on key-value pair. |
| Append or Update | `append_update_data` | Adds or updates key-value pairs. |
| Remove Keys | `remove_keys_input` | Removes specified keys from the data. |
| Rename Keys | `rename_keys_input` | Renames keys in the data. |
| Path Selection | `mapped_json_display`, `selected_key` | Extracts values from nested JSON structures using path expressions. |
| JQ Expression | `query` | Performs advanced JSON queries using [`jq`](https://jqlang.org/manual/) syntax for filtering, projections, and transformations. |

### Path Selection operation examples

Use the Path Selection operation to extract values from nested JSON structures with dot notation paths.

1. In the **Operations** dropdown, select **Path Selection**.
2. In the **JSON to Map** field, enter your JSON structure.

    This example uses the following JSON structure.
    ```json
    {
      "user": {
        "profile": {
          "name": "John Doe",
          "email": "john@example.com"
        },
        "settings": {
          "theme": "dark"
        }
      }
    }
    ```
    The **Select Path** dropdown auto-populates with available paths.
3. In the **Select Paths** dropdown, select the path.
    You can select paths such as `.user.profile.name` to extract "John Doe", or select `.user.settings.theme` to extract "dark".

### JQ Expression operation example {#jq-expression-operation-examples}

Use the **JQ Expressions** operation to use the [jq](https://jqlang.org/) query language to perform more advanced JSON filtering.
1. In the **Operations** dropdown, select **JQ Expression**.
2. In the **JQ Expression** field, enter a `jq` filter to query against the **Data Operations** component's Data input.

    For this example JSON structure, enter expressions like `.user.profile.name` to extract "John Doe", `.user.profile | {name, email}` to project fields to a new object, or `.user.profile | tostring` to convert the field to a string.
    ```json
    {
      "user": {
        "profile": {
          "name": "John Doe",
          "email": "john@example.com"
        },
        "settings": {
          "theme": "dark"
        }
      }
    }
    ```

## DataFrame Operations

The **DataFrame Operations** component performs operations on [`DataFrame`](/data-types#dataframe) (table) rows and columns, including schema changes, record changes, sorting, and filtering.
For all options, see [DataFrame Operations parameters](#dataframe-operations-parameters).

The output is a new `DataFrame` containing the modified data after running the selected operation.

### Use the DataFrame Operations component in a flow

The following steps explain how to configure a **DataFrame Operations** component in a flow.
You can follow along with an example or use your own flow.
The only requirement is that the preceding component must create `DataFrame` output that you can pass to the **DataFrame Operations** component.

1. Create a new flow or use an existing flow.

    <details>
    <summary>Example: API response extraction flow</summary>

    The following example flow uses five components to extract `Data` from an API response, transform it to a `DataFrame`, and then perform further processing on the tabular data using a **DataFrame Operations** component.
    The sixth component, **Chat Output**, is optional in this example.
    It only serves as a convenient way for you to view the final output in the **Playground**, rather than inspecting the component logs.

    ![A flow that ingests an API response, extracts it to a DataFrame with a Smart Transform component, and the processes it through a DataFrame Operations component](/img/component-dataframe-operations.png)

    If you want to use this example to test the **DataFrame Operations** component, do the following:

    1. Create a flow with the following components:

        * **API Request**
        * **Language Model**
        * **Smart Transform**
        * **Type Convert**

    2. Configure the [**Smart Transform** component](/components-llm-operations#smart-transform) and its dependencies:

        * **API Request**: Configure the [**API Request** component](/components-data#api-request) to get JSON data from an endpoint of your choice, and then connect the **API Response** output to the **Smart Transform** component's **Data** input.
        * **Language Model**: Select your preferred provider and model, and then enter a valid API key.
        Change the output to **Language Model**, and then connect the `LanguageModel` output to the **Smart Transform** component's **Language Model** input.
        * **Smart Transform**: In the **Instructions** field, enter natural language instructions to extract data from the API response.
        Your instructions depend on the response content and desired outcome.
        For example, if the response contains a large `result` field, you might provide instructions like `explode the result field out into a Data object`.

    3. Convert the **Smart Transform** component's `Data` output to `DataFrame`:

        1. Connect the **Filtered Data** output to the **Type Convert** component's **Data** input.
        2. Set the **Type Convert** component's **Output Type** to **DataFrame**.

    Now the flow is ready for you to add the **DataFrame Operations** component.

    </details>

2. Add a **DataFrame Operations** component to the flow, and then connect `DataFrame` output from another component to the **DataFrame** input.

    All operations in the **DataFrame Operations** component require at least one `DataFrame` input from another component.
    If a component doesn't produce `DataFrame` output, you can use another component, such as the **Type Convert** component, to reformat the data before passing it to the **DataFrame Operations** component.
    Alternatively, you could consider using a component that is designed to process the original data type, such as the **Parser** or **Data Operations** components.

    If you are following along with the example flow, connect the **Type Convert** component's **DataFrame Output** port to the **DataFrame** input.

3. In the **Operations** field, select the operation you want to perform on the incoming `DataFrame`.
For example, the **Filter** operation filters the rows based on a specified column and value.

    :::tip
    You can select only one operation.
    If you need to perform multiple operations on the data, you can chain multiple **DataFrame Operations** components together to execute each operation in sequence.
    For more complex multi-step operations, like dramatic schema changes or pivots, consider using an LLM-powered component, like the **Structured Output** or **Smart Transform** component, as a replacement or preparation for the **DataFrame Operations** component.
    :::

    If you're following along with the example flow, select any operation that you want to apply to the data that was extracted by the **Smart Transform** component.
    To view the contents of the incoming `DataFrame`, click <Icon name="Play" aria-hidden="true" /> **Run component** on the **Type Convert** component, and then <Icon name="TextSearch" aria-hidden="true" /> **Inspect output**.
    If the `DataFrame` seems malformed, click <Icon name="TextSearch" aria-hidden="true" /> **Inspect output** on each upstream component to determine where the error occurs, and then modify your flow's configuration as needed.
    For example, if the **Smart Transform** component didn't extract the expected fields, modify your instructions or verify that the given fields are present in the **API Response** output.

4. Configure the operation's parameters.
The specific parameters depend on the selected operation.
For example, if you select the **Filter** operation, you must define a filter condition using the **Column Name**, **Filter Value**, and **Filter Operator** parameters.
For more information, see [DataFrame Operations parameters](#dataframe-operations-parameters)

5. To test the flow, click <Icon name="Play" aria-hidden="true" /> **Run component** on the **DataFrame Operations** component, and then click <Icon name="TextSearch" aria-hidden="true" /> **Inspect output** to view the new `DataFrame` created from the **Filter** operation.

   If you want to view the output in the **Playground**, connect the **DataFrame Operations** component's output to a **Chat Output** component, rerun the **DataFrame Operations** component, and then click **Playground**.

For another example, see [Conditional looping](/components-logic#conditional-looping).

### DataFrame Operations parameters

Most **DataFrame Operations** parameters are conditional because they only apply to specific operations.

The only permanent parameters are **DataFrame** (`df`), which is the `DataFrame` input, and **Operation** (`operation`), which is the operation to perform on the `DataFrame`.
Once you select an operation, the conditional parameters for that operation appear on the **DataFrame Operations** component.

<Tabs>
<TabItem value="addcolumn" label="Add Column" default>

The **Add Column** operation allows you to add a new column to the `DataFrame` with a constant value.

The parameters are **New Column Name** (`new_column_name`) and **New Column Value** (`new_column_value`).

</TabItem>
<TabItem value="dropcolumn" label="Drop Column">

The **Drop Column** operation allows you to remove a column from the `DataFrame`, specified by **Column Name** (`column_name`).

</TabItem>
<TabItem value="filter" label="Filter">

The **Filter** operation allows you to filter the `DataFrame` based on a specified condition.
The output is a `DataFrame` containing only the rows that matched the filter condition.

Provide the following parameters:

* **Column Name** (`column_name`): The name of the column to filter on.
* **Filter Value** (`filter_value`): The value to filter on.
* **Filter Operator** (`filter_operator`): The operator to use for filtering, one of `equals` (default), `not equals`, `contains`, `not contains`, `starts with`, `ends with`, `greater than`, or `less than`.

</TabItem>
<TabItem value="head" label="Head">

The **Head** operation allows you to retrieve the first `n` rows of the `DataFrame`, where `n` is set in **Number of Rows** (`num_rows`).
The default is `5`.

The output is a `DataFrame` containing only the selected rows.

</TabItem>
<TabItem value="renamecolumn" label="Rename Column">

The **Rename Column** operation allows you to rename an existing column in the `DataFrame`.

The parameters are **Column Name** (`column_name`), which is the current name, and **New Column Name** (`new_column_name`).

</TabItem>
<TabItem value="replacevalue" label="Replace Value">

The **Replace Value** operation allows you to replace values in a specific column of the `DataFrame`.
This operation replaces a target value with a new value.
All cells matching the target value are replaced with the new value in the new `DataFrame` output.

Provide the following parameters:

* **Column Name** (`column_name`): The name of the column to modify.
* **Value to Replace** (`replace_value`): The value that you want to replace.
* **Replacement Value** (`replacement_value`): The new value to use.

</TabItem>
<TabItem value="selectcolumns" label="Select Columns">

The **Select Columns** operation allows you to select one or more specific columns from the `DataFrame`.

Provide a list of column names in **Columns to Select** (`columns_to_select`).
In the visual editor, click <Icon name="Plus" aria-hidden="true"/> **Add More** to add multiple fields, and then enter one column name in each field.

The output is a `DataFrame` containing only the specified columns.

</TabItem>
<TabItem value="sort" label="Sort">

The **Sort** operation allows you to sort the `DataFrame` on a specific column in ascending or descending order.

Provide the following parameters:

* **Column Name** (`column_name`): The name of the column to sort on.
* **Sort Ascending** (`ascending`): Whether to sort in ascending or descending order. If enabled (`true`), sorts in ascending order; if disabled (`false`), sorts in descending order. Default: Enabled (`true`)

</TabItem>
<TabItem value="tail" label="Tail">

The **Tail** operation allows you to retrieve the last `n` rows of the `DataFrame`, where `n` is set in **Number of Rows** (`num_rows`).
The default is `5`.

The output is a `DataFrame` containing only the selected rows.

</TabItem>
<TabItem value="dropduplicates" label="Drop Duplicates">

The **Drop Duplicates** operation removes rows from the `DataFrame` by identifying all duplicate values within a single column.

The only parameter is the **Column Name** (`column_name`).

When the flow runs, all rows with duplicate values in the given column are removed.
The output is a `DataFrame` containing all columns from the original `DataFrame`, but only rows with non-duplicate values.

</TabItem>
</Tabs>

## Dynamic Create Data

The **Dynamic Create Data** component creates a [`Data`](/data-types#data) object or [`Message`](/data-types#message) with configurable fields.
Define the table in the **Input Configuration** field, and the component creates corresponding input or output handles in the component.

### Use the Dynamic Create Data component in a flow

The following example demonstrates how to use a **Dynamic Create Data** component to create a structured `Data` or `Message` object from multiple sources.

1. Add the **Dynamic Create Data** component to your flow.

2. To define your data's fields, in the **Input Configuration** field, click <Icon name="Table" aria-hidden="true"/> **Open table**.

3. To add rows to your table, click <Icon name="Plus" aria-hidden="true"/> **Add a new row**.
   Adding a new row creates input and output handles for the **Field Type**.
   For example, if you add a `Text` type field, then`Text` input and output handles are added to the component.
   For each new row, configure the **Field Name** and **Field Type**.

    * **Field Name**: The name of the field used as both the internal key and display label.
    * **Field Type**: The type of input field to create. The type options are:
      * Text: Accepts direct text input or accepts `Text` or `Message` output from other components.
      * Data: Accepts `Data` input from other components.
      * Number: Accepts direct numeric input or accepts `Text` or `Message` outputs from other components.
      * Handle: Accepts `Text`, `Data`, or `Message` output from other components.
      * Boolean: Accepts Boolean values. Cannot accept input from another component.

    For more information, see [Langflow data types](/data-types).
4. Depending on your **Field Type** selections, either connect output from other components to dynamically populate the inputs, or enter values manually in the **Dynamic Create Data** component's fields.

5. Select the desired output type at the component's output port. The component outputs either a [`Data`](/data-types#data) object containing all field values from the component's inputs, or a [`Message`](/data-types#message) containing all field values formatted as a text string.

### Dynamic Create Data parameters

<PartialParams />

| Name | Display Name | Info |
|------|--------------|------|
| `form_fields` | **Input Configuration** | Input parameter. A table that defines the dynamic form fields. |
| `include_metadata` | **Include Metadata** | Input parameter. Whether to include form configuration metadata in the output.|
| `form_data` | **Data** | Output parameter. A `Data` object containing all field values from the dynamic inputs. |
| `message` | **Message** | Output parameter. A formatted `Text` message containing all field values in a human-readable format. |

## Parser {#parser}

The **Parser** component extracts text from structured data (`DataFrame` or `Data`) using a template or direct stringification.
The output is a `Message` containing the parsed text.

This is a versatile component for data extraction and manipulation in your flows.
For examples of **Parser** components in flows, see the following:

* [**Batch Run** component example](/components-llm-operations#batch-run)
* [**Structured Output** component example](/components-llm-operations#structured-output)
* **Financial Report Parser** template
* [Trigger flows with webhooks](/webhook)
* [Create a vector RAG chatbot](/chat-with-rag)

![A flow that uses a Parser component to extract text from a Structured Output component.](/img/component-parser.png)

### Parsing modes

The **Parser** component has two modes: **Parser** and **Stringify**.

<Tabs>
<TabItem value="template" label="Parser (template) mode" default>

In **Parser** mode, you create a template for text output that can include literal strings and variables for extracted keys.

Use curly braces to define variables anywhere in the template.
Variables must match keys in the `DataFrame` or `Data` input, such as column names.
For example, `{name}` extracts the value of a `name` key.
For more information about the content and structure of `DataFrame` and `Data` objects, see [Langflow data types](/data-types).

<PartialCurlyBraces />

When the flow runs, the **Parser** component iterates over the input, producing a `Message` for each parsed item.
For example, parsing a `DataFrame` creates a `Message` for each row, populated with the unique values from that row.

<details>
<summary>Employee summary template</summary>

This example template extracts employee data into a natural language summary about an employee's hire date and current role:

```text
{employee_first_name} {employee_last_name} was hired on {start_date}.
Their current position is {job_title} ({grade}).
```

The resulting `Message` output replaces the variables with the corresponding extracted values.
For example:

```text
Renlo Kai was hired on 11-July-2017.
Their current position is Software Engineer (Principal).
```

</details>

<details>
<summary>Employee profile template</summary>

This example template uses Markdown syntax and extracted employee data to create an employee profile:

```text
# Employee Profile
## Personal Information
- **Name:** {name}
- **ID:** {id}
- **Email:** {email}
```

When the flow runs, the **Parser** component iterates over each row of the `DataFrame`, populating the template's variables with the appropriate extracted values.
The resulting text for each row is output as a [`Message`](/data-types#message).

</details>

The following parameters are available in **Parser** mode.
<PartialParams />

| Name | Display Name | Info |
|------|--------------|------|
| input_data | Data or DataFrame | Input parameter. The `Data` or `DataFrame` input to parse. |
| pattern | Template | Input parameter. The formatting template using plaintext and variables for keys (`{KEY_NAME}`). See the preceding examples for more information. |
| sep | Separator | Input parameter. A string defining the separator for rows or lines. Default: `\n` (new line). |
| clean_data | Clean Data | Whether to remove empty rows and lines in each cell or key of the `DataFrame` or `Data` input. Default: Enabled (`true`) |

</TabItem>
<TabItem value="stringify" label="Stringify mode">

Use **Stringify** mode to convert the entire input directly to text.
This mode doesn't support templates or key selection.

The following parameters are available in **Stringify** mode.
<PartialParams />

| Name | Display Name | Info |
|------|--------------|------|
| input_data | Data or DataFrame | Input parameter. The `Data` or `DataFrame` input to parse. |
| sep | Separator | Input parameter. A string defining the separator for rows or lines. Default: `\n` (new line). |
| clean_data | Clean Data | Whether to remove empty rows and lines in each cell or key of the `DataFrame` or `Data` input. Default: Enabled (`true`) |

</TabItem>
</Tabs>

### Test and troubleshoot parsed text

To test the **Parser** component, click <Icon name="Play" aria-hidden="true"/> **Run component**, and then click <Icon name="TextSearch" aria-hidden="true"/> **Inspect output** to see the `Message` output with the parsed text.
You can also connect a **Chat Output** component if you want to view the output in the **Playground**.

If the `Message` output from the **Parser** component has empty or unexpected values, there might be a mapping error between the input and the parsing mode, the input has empty values, or the input isn't suitable for plaintext extraction.

For example, assume you use the following template to parse a `DataFrame`:

```text
{employee_first_name} {employee_last_name} is a {job_title} ({grade}).
```

The following `Message` could result from parsing a row where `employee_first_name` was empty and `grade` was `null`:

```text
 Smith is a Software Engineer (null).
```

To troubleshoot missing or unexpected values, you can do the following:

* Make sure the variables in your template map to keys in the incoming `Data` or `DataFrame`.
To see the data being passed directly to the **Parser** component, click <Icon name="TextSearch" aria-hidden="true"/> **Inspect output** on the component that is sending data to the **Parser** component.

* Check the source data for missing or incorrect values.
There are several ways you can address these inconsistencies:

    * Rectify the source data directly.
    * Use other components to amend or filter anomalies before passing the data to the **Parser** component.
    There are many components you can use for this depending on your goal, such as the **Data Operations**, **Structured Output**, and **Smart Transform** components.
    * Enable the **Parser** component's **Clean Data** parameter to skip empty rows or lines.

## Split Text

The **Split Text** component splits data into chunks based on parameters like chunk size and separator.
It is often used to chunk data to be tokenized and embedded into vector databases.
For examples, see [Use embedding model components in a flow](/components-embedding-models#use-embedding-model-components-in-a-flow) and [Create a Vector RAG chatbot](/chat-with-rag).

![An embedding generation flow that uses a Split Text component to chunk data.](/img/component-split-text.png)

The component accepts `Message`, `Data`, or `DataFrame`, and then outputs either **Chunks** or **DataFrame**.
The **Chunks** output returns a list of [`Data`](/data-types#data) objects containing individual text chunks.
The **DataFrame** output returns the list of chunks as a structured [`DataFrame`](/data-types#dataframe) with additional `text` and `metadata` columns.

### Split Text parameters

The **Split Text** component's parameters control how the text is split into chunks, specifically the `chunk_size`, `chunk_overlap`, and `separator` parameters.

To test the chunking behavior, add a **Text Input** or **Read File** component with some sample data to chunk, click <Icon name="Play" aria-hidden="true" /> **Run component** on the **Split Text** component, and then click <Icon name="TextSearch" aria-hidden="true" /> **Inspect output** to view the list of chunks and their metadata. The **text** column contains the actual text chunks created from your chunking settings.
If the chunks aren't split as you expect, adjust the parameters, rerun the component, and then inspect the new output.

<PartialParams />

| Name | Display Name | Info |
|------|--------------|------|
| data_inputs | Input | Input parameter. The data to split. Input must be in `Message`, `Data`, or `DataFrame` format. |
| chunk_overlap | Chunk Overlap | Input parameter. The number of characters to overlap between chunks. This helps maintain context across chunks. When a separator is encountered, the overlap is applied at the point of the separator so that the subsequent chunk contains the last _n_ characters of the preceding chunk. Default: `200`. |
| chunk_size | Chunk Size | Input parameter. The target length for each chunk after splitting. The data is first split by separator, and then chunks smaller than the `chunk_size` are merged up to this limit. However, if the initial separator split produces any chunks larger than the `chunk_size`, those chunks are neither further subdivided nor combined with any smaller chunks; these chunks will be output as-is even though they exceed the `chunk_size`. Default: `1000`. See [Tokenization errors due to chunk size](#chunk-size) for important considerations. |
| separator | Separator | Input parameter. A string defining a character to split on, such as `\n` to split on new line characters, `\n\n` to split at paragraph breaks, or `},` to split at the end of JSON objects. You can directly provide the separator string, or pass a separator string from another component as `Message` input. |
| text_key | Text Key | Input parameter. The key to use for the text column that is extracted from the input and then split. Default: `text`. |
| keep_separator | Keep Separator | Input parameter. Select how to handle separators in output chunks. If `False`, separators are omitted from output chunks. Options include `False` (remove separators), `True` (keep separators in chunks without preference for placement), `Start` (place separators at the beginning of chunks), or `End` (place separators at the end of chunks). Default: `False`. |

### Tokenization errors due to chunk size {#chunk-size}

When using **Split Text** with embedding models (especially NVIDIA models like `nvidia/nv-embed-v1`), you may need to use smaller chunk sizes (`500` or less) even though the model supports larger token limits.
The **Split Text** component doesn't always enforce the exact chunk size you set, and individual chunks may exceed your specified limit.
If you encounter tokenization errors, modify your text splitting strategy by reducing the chunk size, changing the overlap length, or using a more common separator.
Then, test your configuration by running the flow and inspecting the component's output.

### Other text splitters

See [LangChain text splitter components](/bundles-langchain#text-splitters).

## Type Convert

The **Type Convert** component converts data from one type to another.
It supports `Data`, `DataFrame`, and `Message` data types.

<Tabs>
<TabItem value="data" label="Data" default>

A `Data` object is a structured object that contains a primary `text` key and other key-value pairs:

```json
"data": {
  "text": "User Profile",
  "name": "Charlie Lastname",
  "age": 28,
  "email": "charlie.lastname@example.com"
},
```

The larger context associated with a component's `data` dictionary also identifies which key is the primary `text_key`, and it can provide an optional default value if the primary key isn't specified.
For example:

```json
{
  "text_key": "text",
  "data": {
    "text": "User Profile",
    "name": "Charlie Lastname",
    "age": 28,
    "email": "charlie.lastname@example.com"
  },
  "default_value": ""
}
```

</TabItem>
<TabItem value="dataframe" label="DataFrame">

A `DataFrame` is an array that represents a tabular data structure with rows and columns.

It consists of a list (array) of dictionary objects, where each dictionary represents a row.
Each key in the dictionaries corresponds to a column name.
For example, the following `DataFrame` contains two rows with columns for `name`, `age`, and `email`:

```json
[
  {
    "name": "Charlie Lastname",
    "age": 28,
    "email": "charlie.lastname@example.com"
  },
  {
    "name": "Bobby Othername",
    "age": 25,
    "email": "bobby.othername@example.com"
  }
]
```

</TabItem>
<TabItem value="message" label="Message">

A `Message` is primarily for passing a `text` string, such as`"Name: Charlie Lastname, Age: 28, Email: charlie.lastname@example.com"`.
However, the entire `Message` object can include metadata about the message, particularly when used as chat input or output.

</TabItem>
</Tabs>

For more information, see [Langflow data types](/data-types).

### Use the Type Convert component in a flow

The **Type Convert** component is typically used to transform data into a format required by a downstream component.
For example, if a component outputs a `Message`, but the following component requires `Data`, then you can use the **Type Convert** component to reformat the `Message` as `Data` before passing it to the downstream component.

The following example uses the **Type Convert** component to convert the `DataFrame` output from a **Web Search** component into `Message` data that is passed as text input for an LLM:

1. Create a flow based on the **Basic prompting** template.

2. Add a **Web Search** component to the flow, and then enter a search query, such as `environmental news`.

3. In the **Prompt Template** component, replace the contents of the **Template** field with the following text:

    ```text
    Answer the user's question using the {context}
    ```

    The curly braces define a [prompt variable](/components-prompts#define-variables-in-prompts) that becomes an input field on the **Prompt Template** component.
    In this example, you will use the **context** field to pass the search results into the template, as explained in the next steps.

3. Add a **Type Convert** component to the flow, and then set the **Output Type** to **Message**.

    Because the **Web Search** component's `DataFrame` output is incompatible with the **context** variable's `Message` input, you must use the **Type Convert** component to change the `DataFrame` to a `Message` in order to pass the search results to the **Prompt Template** component.

4. Connect the additional components to the rest of the flow:

    * Connect the **Web Search** component's output to the **Type Convert** component's input.
    * Connect the **Type Convert** component's output to the **Prompt Template** component's **context** input.

    ![Convert web search output to text input](/img/component-type-convert-and-web-search.png)

5. In the **Language Model** component, add your OpenAI API key.

    If you want to use a different provider or model, edit the **Model Provider**, **Model Name**, and **API Key** fields accordingly.

6. Click **Playground**, and then ask something relevant to your search query, such as `latest news` or `what's the latest research on the environment?`.

    <details>
    <summary>Result</summary>

    The LLM uses the search results context, your chat message, and it's built-in training data to respond to your question.
    For example:

    ```text
    Here are some of the latest news articles related to the environment:
    Ozone Pollution and Global Warming: A recent study highlights that ozone pollution is a significant global environmental concern, threatening human health and crop production while exacerbating global warming. Read more
    ...
    ```

    </details>

### Type Convert parameters

| Name | Display Name | Info |
|------|--------------|------|
| input_data | Input Data | Input parameter. The data to convert. Accepts `Data`, `DataFrame`, or `Message` input. |
| output_type | Output Type | Input parameter. The desired output type, as one of **Data**, **DataFrame** or **Message**. |
| output | Output | Output parameter. The converted data in the specified format. The output port changes depending on the selected **Output Type**. |