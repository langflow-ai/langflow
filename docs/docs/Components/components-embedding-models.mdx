---
title: Embedding Model
slug: /components-embedding-models
---

import Icon from "@site/src/components/icon";

Embedding model components in Langflow generate text embeddings using a specified Large Language Model (LLM).

Langflow includes an **Embedding Model** core component that has built-in support for some LLMs.
Alternatively, you can use any [additional embedding model](#additional-embedding-models) in place of the **Embedding Model** core component.

## Use embedding model components in a flow

Use embedding model components anywhere you need to generate embeddings in a flow.

This example shows how to use an embedding model component in a flow to create a semantic search system.
This flow loads a text file, splits the text into chunks, generates embeddings for each chunk, and then loads the chunks and embeddings into a vector store. The input and output components allow a user to query the vector store through a chat interface.

![A semantic search flow that uses Embedding Model, File, Split Text, Chroma DB, Chat Input, and Chat Output components](/img/component-embedding-models-add-chat.png)

1. Create a flow, add a **File** component, and then select a file containing text data, such as a PDF, that you can use to test the flow.

2. Add the **Embedding Model** core component, and then provide a valid OpenAI API key.
You can enter the API key directly or use a <Icon name="Globe" aria-hidden="true"/> [global variable](/configuration-global-variables).

    :::tip My preferred provider or model isn't listed
    If your preferred embedding model provider or model isn't supported by the **Embedding Model** core component, you can use any [additional embedding models](#additional-embedding-models) in place of the core component.

    Browse <Icon name="Blocks" aria-hidden="true" /> [**Bundles**](/components-bundle-components) or <Icon name="Search" aria-hidden="true" /> **Search** for your preferred provider to find additional embedding models, such as the [**Hugging Face Embeddings Inference** component](/bundles-huggingface#hugging-face-embeddings-inference).
    :::

3. Add a [**Split Text** component](/components-processing#split-text) to your flow.
This component splits text input into smaller chunks to be processed into embeddings.

4. Add a vector store component, such as the **Chroma DB** component, to your flow, and then configure the component to connect to your vector database.
This component stores the generated embeddings so they can be used for similarity search.

5. Connect the components:

    * Connect the **File** component's **Loaded Files** output to the **Split Text** component's **Data or DataFrame** input.
    * Connect the **Split Text** component's **Chunks** output to the vector store component's **Ingest Data** input.
    * Connect the **Embedding Model** component's **Embeddings** output to the vector store component's **Embedding** input.

6. To query the vector store, add [**Chat Input and Output** components](/components-io#chat-io):

    * Connect the **Chat Input** component to the vector store component's **Search Query** input.
    * Connect the vector store component's **Search Results** output to the **Chat Output** component.

7. Click **Playground**, and then enter a search query to retrieve text chunks that are most semantically similar to your query.

## Embedding Model parameters

The following parameters are for the **Embedding Model** core component.
Other embedding model components can have additional or different parameters.

import PartialParams from '@site/docs/_partial-hidden-params.mdx';

<PartialParams />

| Name | Display Name | Type | Description |
|------|--------------|------|-------------|
| provider | Model Provider | List | Input parameter. Select the embedding model provider. |
| model | Model Name | List | Input parameter. Select the embedding model to use.|
| api_key | OpenAI API Key | Secret[String] | Input parameter. The API key required for authenticating with the provider. |
| api_base | API Base URL | String | Input parameter. Base URL for the API. Leave empty for default. |
| dimensions | Dimensions | Integer | Input parameter. The number of dimensions for the output embeddings. |
| chunk_size | Chunk Size | Integer | Input parameter. The size of text chunks to process. Default: `1000`. |
| request_timeout | Request Timeout | Float | Input parameter. Timeout for API requests. |
| max_retries | Max Retries | Integer | Input parameter. Maximum number of retry attempts. Default: `3`. |
| show_progress_bar | Show Progress Bar | Boolean | Input parameter. Whether to display a progress bar during embedding generation. |
| model_kwargs | Model Kwargs | Dictionary | Input parameter. Additional keyword arguments to pass to the model. |
| embeddings | Embeddings | Embeddings | Output parameter. An instance for generating embeddings using the selected provider. |

## Additional embedding models

If your provider or model isn't supported by the **Embedding Model** core component, you can replace this component with any other component that generates embeddings.

To find additional embedding model components, browse <Icon name="Blocks" aria-hidden="true" /> [**Bundles**](/components-bundle-components) or <Icon name="Search" aria-hidden="true" /> **Search** for your preferred provider.

## Pair models with vector stores

import PartialVectorRagBlurb from '@site/docs/_partial-vector-rag-blurb.mdx';

<PartialVectorRagBlurb />

<details>
<summary>Example: Vector search flow</summary>

import PartialVectorRagFlow from '@site/docs/_partial-vector-rag-flow.mdx';

<PartialVectorRagFlow />

</details>