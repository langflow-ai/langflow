---
title: Knowledge Bases
slug: /components-kb
---

import Icon from "@site/src/components/icon";
import PartialParams from '@site/docs/_partial-hidden-params.mdx';
import PartialKbSummary from '@site/docs/_partial-kb-summary.mdx';

<PartialKbSummary />

For more information about vector databases in Langflow, see [Manage vector data](/knowledge).

## Use knowledge bases in flows

To use knowledge bases in flows, you use the **Knowledge Ingestion** component to create and write to knowledge bases, and then you use the **Knowledge Retrieval** component to read from your knowledge bases.
You can use these components in the same flow or different flows, depending on where you want to read or write data.

The following example uses two flows to demonstrate how to create, populate, and search a Langflow knowledge base.
The first flow creates a knowledge base and loads it with customer sales data.
Then, the second flow retrieves data stored in the knowledge base.
To follow along with this example, download [`customer-orders.csv`](/files/customer_orders/customer_orders.csv) to your local machine, or adapt the steps for your own structured data.

1. Add the **Knowledge Ingestion** component to a flow.
2. In the **Knowledge** field, select **New knowledge** to create a new knowledge base, or select one of your existing knowledge bases.

    :::tip
    Treat knowledge bases as you would any vector database.
    Don't write data randomly; instead treat each knowledge base as a unique dataset, keeping data organized and avoiding mixing unrelated data in the same knowledge base.

    Additionally, knowledge bases only support structured data.
    When writing to an existing knowledge base, make sure your new data matches the existing schema.
    :::

3. If you selected **New knowledge**, configure your new knowledge base, and then click **Create**.

    * **Knowledge Name**: The name of your knowledge base.
    * **Choose Embedding**: Select an embedding model to genenerate embeddings for your data.
    This cannot be changed later.

        The vector dimensions are determined by the chosen embedding model.
        For example, the `text-embedding-3-small` model has a default of 1536 dimensions.

        If you want to use a different provider or model, you cannot use knowledge bases.
        Instead, you must use vector store and embedding model components.
        For more information, see [Embedding model components](/components-embedding-models).

    * **API Key**: Enter your API key to authenticate with your chosen embedding model provider.
    For example, `text-embedding-3-small` requires an OpenAI API key.

        This key is stored in Langflow KMS, so you don't need to provide it again when you use the knowledge base in other flows.

4. To load data into the knowledge base, connect `Data` or `DataFrame` output from another component to the **Knowledge Ingestion** component's **Input** port.
These data type are required because Langflow knowledge bases only support structured data.

    For example, to load `customer-orders.csv`, do the following:

    1. Add a [**File** component](/components-data#file) to your flow.
    2. Click **Select files**, and then add `customer-orders.csv`.
    3. Connect the **File** component's **Structured Content** output to the **Knowledge Ingestion** component's **Input** port.

5. Click **Open table** under **Column Configuration** to specify the primary key and columns to embed.
This can help prevent duplicate writes, improve search quality, and ensure that you only generate embeddings for relevant content.

    Any unspecified columns are loaded as metadata rows (not embedded).
    You don't need to add all of the columns, just the primary key and any columns that add context for your semantic searches.
    If entirely unspecified, Langflow uses the default, minimal schema, which is a single `text` column.

    Click <Icon name="Plus" aria-hidden="true"/> **Add a new row** to create a row for each critical column in your incoming `DataFrame`.
    For each column, you can set the following options:

        * **Column Name**: The name of the column, such as `customer_id`.

        * **Vectorize**: Enable this setting to generate embeddings for the content in this column using the knowledge base's selected embedding model.
        Enable this setting for only one column that contains the content that you want to search semantically.

        * **Identifier**: Enable this setting to specify the unique identifier (primary key) column.
        There should only be one identifier.
        This helps prevent duplicate entries.

    For `customer-orders.csv`, add the following columns to the column configuration:

        * `order_id`: Enable **Identifier** for this column to set it as the primary key.
        Make sure **Identifier** is disabled for all other columns.

        * `product_name`: Enable **Vectorize** for this column to generate embeddings for product names.
        This column is selected for this example because it contains common, natural language terms that users would search for.
        Make sure **Vectorize** is disabled for all other columns.

        * Other columns: You don't need to specify any other columns because all unspecified columns are loaded as metadata without embeddings.

6. To load the data into your knowledge base, click <Icon name="Play" aria-hidden="true"/> **Run component** on the **Knowledge Ingestion** component, and then click <Icon name="TextSearch" aria-hidden="True" /> **Inspect output** to see how the `DataFrame` columns were processed.

    <details>
    <summary>Example: Knowledge Ingestion output</summary>
    ```json
    {
      "kb_id": "639450aa-c8d9-4183-b60c-535882499e02",
      "kb_name": "customer-sales",
      "rows": 35,
      "column_metadata": {
        "total_columns": 7,
        "mapped_columns": 5,
        "unmapped_columns": 2,
        "columns": [
          {
            "name": "product_id",
            "vectorize": false,
            "identifier": false
          },
          {
            "name": "customer_email",
            "vectorize": false,
            "identifier": false
          },
          {
            "name": "product_name",
            "vectorize": true,
            "identifier": false
          },
          {
            "name": "product_category",
            "vectorize": false,
            "identifier": false
          },
          {
            "name": "order_id",
            "vectorize": false,
            "identifier": true
          }
        ],
        "summary": {
          "vectorized_columns": [
            "product_name"
          ],
          "identifier_columns": [
            "order_id"
          ]
        }
      },
      "path": "~/.langflow/knowledge_bases/customer-sales",
      "config_columns": 5,
      "timestamp": "2025-08-20T21:18:39.243830+00:00"
    }
    ```
    </details>

7. Search your knowledge base:

    After you create and load data to a knowledge base, you can use the **Knowledge Retrieval** component in any flow to retrieve data from your knowledge base using semantic search:

    1. Add a **Knowledge Retrieval** component to your flow.
    2. In the **Knowledge** field, select the knowledge base you want to search, such as the customer sales data knowledge base created in the previous steps.
    3. To view the search results as chat messages, connect the **Results** output to a **Chat Output** component.
    4. In **Search query**, enter a query that relates to your embedded data.
    For the customer sales data example, enter a product name like `laptop` or `wireless devices`.
    5. Click <Icon name="Play" aria-hidden="true"/> **Run component** on the **Knowledge Retrieval** component, and then open the **Playground** to view the output.

:::tip
The preceding example was simplified for demonstration purposes.
In a real-world scenario, you would integrate these components into complete flows with more components.

For more examples of knowledge bases in flows, see the **Knowledge Ingestion** and **Knowledge Retrieval** [templates](/concepts-flows#create-a-flow) in Langflow.
:::

## Knowledge Ingestion

The **Knowledge Ingestion** component writes to a new or existing knowledge base.

Input must be [`Data`](/data-types#data) or [`DataFrame`](/data-types#dataframe) that is already chunked or processed for storage in a vector database.
If necessary, use other components to prepare the data before passing it to the **Knowledge Ingestion** component.
For an example, see the **Knowledge Ingestion** template in Langflow.

The output is a `Data` object containing metadata about the ingestion, including knowledge base information, number of rows ingested, and the column configuration (names, settings, number of mapped and unmapped columns).

### Knowledge Ingestion parameters

<PartialParams />

| Name | Display Name | Info |
|------|--------------|------|
| knowledge_base | Knowledge | Input parameter. Create or select a knowledge base to store data. |
| input_df | Data or DataFrame | Input parameter. Content to load into the knowledge base, already chunked or processed. |
| column_config | Column Configuration | Input parameter. Specify the primary key column and columns for which to generate embeddings. Default: A single `text` that is embedded and used as the primary identifier. For more information, see the example in [Use knowledge bases in flows](#use-knowledge-bases-in-flows). |
| chunk_size | Chunk Size | Input parameter. Batch size for processing embeddings. Default: `1000`. |
| api_key | Embedding Provider API Key | Input parameter. API key for the knowledge base's embedding provider. The embedding provider and model are chosen when you create a knowledge base. |
| allow_duplicates | Allow Duplicates | Input parameter.  Whether to allow duplicate rows in the knowledge base. Default: Disabled (false). |

## Knowledge Retrieval

The **Knowledge Retrieval** component reads from an existing knowledge base using semantic search.

The output is a [`DataFrame`](/data-types#dataframe) containing the top matching results from the queried knowledge base.

### Knowledge Retrieval parameters

<PartialParams />

| Name | Display Name | Info |
|------|--------------|------|
| knowledge_base | Knowledge | Input parameter. Select the knowledge base to retrieve data from. |
| api_key | Embedding Provider API Key | Input parameter. Optional API key for the embedding provider to override a previously-provided key. The embedding provider and model are chosen when you create a knowledge base. |
| search_query | Search Query | Input parameter. Optional search query to filter knowledge base data using semantic similarity. If omitted, the top results are returned from an arbitrary sort. |
| top_k | Top K Results | Input parameter. Number of search results to return. Default: `5`. |
| include_metadata | Include Metadata | Input parameter. Whether to include all metadata and embeddings in the output. If enabled, each output row includes all metadata, embeddings, and content. If disabled, only the content is returned. Default: Enabled (true). |

## Knowledge base storage locations

Each knowledge base is a [ChromaDB](https://docs.trychroma.com/docs/overview/introduction) vector database.
Each database is stored in a separate directory that contains the following:

- **Vector embeddings**: Embeddings are stored using the Chroma vector database.
- **Metadata files**: Configuration and embedding model information.
- **Source data**: The original data used to create the knowledge base.

Knowledge bases are stored local to your Langflow instance.
The default storage location depends on your operating system and installation method:

- **macOS Desktop**: `/Users/<username>/.langflow/knowledge_bases`
- **Windows Desktop**: `C:\Users\<name>\AppData\Roaming\com.Langflow\knowledge_bases`
- **OSS macOS/Windows/Linux/WSL (`uv pip install`)**: `<path_to_venv>/lib/python3.12/site-packages/langflow/knowledge_bases` (Python version may vary)
- **OSS macOS/Windows/Linux/WSL (`git clone`)**: `<path_to_clone>/src/backend/base/langflow/knowledge_bases`

If you set the `LANGFLOW_CONFIG_DIR` environment variable, the `knowledge_bases` subdirectory is created relative to that path.

To change the default `knowledge_bases` directory path, set the `LANGFLOW_KNOWLEDGE_BASES_DIR` environment variable:

```bash
export LANGFLOW_KNOWLEDGE_BASES_DIR="/path/to/parent/directory"
```

## Manage knowledge bases

On the [**Projects** page](/concepts-flows#projects) page, click **Knowledge** below the list of projects to view and manage your knowledge bases.

For each knowledge base, you can see the following information:

* Name
* Embedding model
* Size on disk
* Number of words, characters, and chunks
* The average length of chunks

Chunking behavior is determined by the embedding model, and the embedding model is set when you create the knowledge base.
If you need to change the embedding model, you must delete and recreate the knowledge base.

To delete a knowledge base, select the checkbox next to the knowledge base, and then click <Icon name="Trash2" aria-hidden="true"/> **Delete**.
If any flows use the deleted knowledge base, you must update them to use a different knowledge base.

## See also

* [Manage vector data](/knowledge)