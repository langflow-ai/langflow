---
title: Instana
slug: /integrations-instana-traceloop
description: Instrument Langflow with the Traceloop SDK and export traces and metrics to Instana using OpenTelemetry.
---

Traceloop SDK is a lightweight instrumentation toolkit designed for LLM (Large Language Model) applications. It enables developers to automatically capture and export traces, metrics, and key observability signals from their LLM-powered workflows.

When combined with Instana, the exported telemetry data from Traceloop provides end-to-end visibility, allowing users to visualize traces, analyze performance bottlenecks, and ensure reliable operation of LLM-driven applications.

This guide demonstrates how to integrate the Instana observability platform with your Langflow application using the Traceloop SDK so you can monitor and analyze LLM performance.

## Prerequisites

- Create a [Traceloop API key](https://app.traceloop.com/settings/api-key)
- Create an [Instana endpoint and Instana key](https://www.ibm.com/docs/en/instana-observability/1.0.302)
- [Install and start Langflow](/get-started-installation)

## Configure environment variables

1. In the root directory of your Langflow application, create a `.env` file.
2. Add your Traceloop and Instana credentials to the `.env` file:

   ```text
   TRACELOOP_API_KEY=**YOUR_TRACELOOP_API_KEY**
   # Example: https://otlp-magenta-saas.instana.rocks:4318
   TRACELOOP_BASE_URL=<instana_endpoint>
   TRACELOOP_HEADERS="x-instana-key=<your_instana_key>"
   # Set to true only for plain HTTP endpoints. For HTTPS, use false.
   OTEL_EXPORTER_OTLP_INSECURE=false
   # If your Traceloop version requires a URL, use: http://host.docker.internal:8000
   TRACELOOP_METRICS_ENDPOINT=host.docker.internal:8000
   TRACELOOP_METRICS_ENABLED=true
   OTEL_METRIC_EXPORT_INTERVAL=10000
   ```

3. Save the `.env` file.
4. Make sure the OpenTelemetry (OTel) Collector is running.
In your Collector’s `config.yaml`, add the following values.
   ```yaml
   # Example values — update to your environment
   llm.application: "LLM_DC"
   instances:
      - otel.agentless.mode: true
      # Example endpoint: https://otlp-magenta-saas.instana.rocks:4318
      otel.backend.url: "<INSTANA_ENDPOINT>"
      otel.backend.using.http: false
      callback.interval: 10
      otel.service.name: "DC1"
      otel.service.port: 8000
      currency: "USD"
   ```

## Start Langflow with environment variables

1. Launch your Langflow application using the environment file:
```bash
uv run langflow run --env-file .env
```

Traceloop automatically begins monitoring and collecting telemetry data from your LLM applications.

To verify that observability is working correctly, do the following:

2. Run a flow in Langflow to generate traffic.
3. To view traces in Instana, open Instana and select **Applications**.
4. In **Services**, search for `Langflow`. 
5. Select Langflow to view and analyze the associated calls.
6. To view metrics in Instana, open Instana and select **Infrastructure**.
7. In **Analyze Infrastructure**, select **Otel LLMonitor**.
8. To view your Metrics dashboard, select `LLM:DC1@your_machine_name.local` 

## See also

For additional configuration options and advanced features, see the [Traceloop](https://www.traceloop.com/docs/introduction) or [Instana](https://www.ibm.com/docs/en/instana-observability/current) documentation.