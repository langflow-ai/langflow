---
title: Integrate Instana using Traceloop SDK with Langflow
slug: /integrations-instana-traceloop
---

# Langflow Observability with Instana using Traceloop SDK Integration Guide

This guide explains how to integrate Instana observability platform using Traceloop SDK with your Langflow applications to monitor and analyze LLM performance.

## About Traceloop

Traceloop SDK is a lightweight instrumentation toolkit designed for LLM (Large Language Model) applications. It enables developers to automatically capture and export traces, metrics, and key observability signals from their LLM-powered workflows.

When combined with Instana, the exported telemetry data from Traceloop provides end-to-end visibility—allowing users to visualize traces, analyze performance bottlenecks, and ensure reliable operation of LLM-driven applications.

## About Instana

Instana is IBM’s observability platform that provides real-time visibility into application performance. In this integration, Instana acts as the backend for viewing and analyzing the traces and metrics exported using the Traceloop SDK. It allows developers to monitor Langflow’s LLM workflows, visualize trace spans, and analyze performance metrics, making it easier to identify bottlenecks and ensure smooth operation.

## Prerequisites

Before setting up observability, ensure you have:
- A `Traceloop API key` (for Traceloop integration): Navigate to the [Traceloop API Key settings](https://app.traceloop.com/settings/api-keys) to generate  your API keys.
- An `Instana endpoint` and `Instana key` (for Instana integration): Checkout [Instana Documentation](https://www.ibm.com/docs/en/instana-observability/1.0.302) for reference.
- A running Langflow application setup

## Integration Setup

### Step 1: Configure Environment Variables
1. Create a `.env` file in the root directory of your Langflow application (if it doesn't exist already)
2. Add your Traceloop and Instana credentials to the `.env` file:
   ```
   TRACELOOP_API_KEY=<your_traceloop_api_key>
   TRACELOOP_BASE_URL=<Instana_endpoint> (Eg: https://otlp-magenta-saas.instana.rocks:4318)
   TRACELOOP_HEADERS="x-instana-key=<your_instana_key>"
   OTEL_EXPORTER_OTLP_INSECURE=true
   TRACELOOP_METRICS_ENDPOINT=host.docker.internal:8000
   TRACELOOP_METRICS_ENABLED=true
   OTEL_METRIC_EXPORT_INTERVAL=10000
   ```
3. Save the `.env` file
4. Make sure OTEL Data Collector is up and running.
   - In otel-dc `config.yaml`, add the following:
     ```
     llm.application: LLM_DC

      instances:
      - otel.agentless.mode: true
         otel.backend.url: <Instana_endpoint> (Eg: https://otlp-magenta-saas.instana.rocks:4318)
         otel.backend.using.http: false
         callback.interval: 10
         otel.service.name: DC1
         otel.service.port: 8000
         currency: USD
     ```

### Step 2: Start Langflow with Environment Variables
Launch your Langflow application using the environment file:
```bash
uv run langflow run --env-file .env
```

Once configured, Traceloop will automatically begin monitoring and collecting telemetry data from your LLM applications.

To verify that observability is working correctly:

1. **Run a flow in Langflow:**
   - In Langflow, select the "Simple Agent" starter project
   - In the **Agent** component's **API Key** field, enter your LLM API key
   - Click **Playground**
   - Ask your Agent several questions to generate test traffic

2. **View Traces in Instana:**
   - Open Instana and select `Applications` from the sidebar.
   - Click on `Services` tab in the Navbar (Top).
   - Search for `Langflow` and click on it to view and analyze the associated calls.

3. **View Metrics in Instana:**
   - Open Instana and select `Infrastructure`.
   - Click on `Analyse Infrastructure`.
   - Search for `Otel LLMonitor`.
   - Select `LLM:DC1@your_machine_name.local` to view your Metrics dashboard.

## Troubleshooting

If you don't see traces appearing:
- Verify that your API keys and endpoints are correct in the `.env` file
- Ensure the `.env` file is in the correct root directory
- Confirm that Langflow is starting with the `--env-file .env` parameter
- Check that you've generated sufficient test traffic through the Playground

If you don’t see metrics appearing:
- Ensure the OpenTelemetry (Otel) Data Collector is running without errors.
- Verify that the Otel DC config.yaml is configured as described above.
- Confirm that the Instana endpoint and the service port (e.g., service.port: 8000) are correctly exposed and accessible.
- Check whether the metrics are being logged in the Otel DC terminal output.

For additional configuration options and advanced features, refer to the respective platform documentation for [Traceloop](https://www.traceloop.com/docs/introduction) or [Instana](https://www.ibm.com/docs/en/instana-observability/current).