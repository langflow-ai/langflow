---
title: Integrate Instana using the Traceloop SDK with Langflow
slug: /integrations-instana-traceloop
description: Instrument Langflow with the Traceloop SDK and export traces and metrics to Instana using OpenTelemetry.
---

This guide shows you how to integrate the Instana observability platform with your Langflow application using the Traceloop SDK so you can monitor and analyze LLM performance.
## About Traceloop

Traceloop SDK is a lightweight instrumentation toolkit designed for LLM (Large Language Model) applications. It enables developers to automatically capture and export traces, metrics, and key observability signals from their LLM-powered workflows.

When combined with Instana, the exported telemetry data from Traceloop provides end-to-end visibility—allowing users to visualize traces, analyze performance bottlenecks, and ensure reliable operation of LLM-driven applications.

## About Instana

Instana is IBM’s observability platform that provides real-time visibility into application performance. In this integration, Instana acts as the backend for viewing and analyzing the traces and metrics exported using the Traceloop SDK. It allows developers to monitor Langflow’s LLM workflows, visualize trace spans, and analyze performance metrics, making it easier to identify bottlenecks and ensure smooth operation.

## Prerequisites

Before setting up observability, ensure you have:
- A `Traceloop API key` (for Traceloop integration): Navigate to the [Traceloop API Key settings](https://app.traceloop.com/settings/api-keys) to generate  your API keys.
- An `Instana endpoint` and `Instana key` (for Instana integration): Checkout [Instana Documentation](https://www.ibm.com/docs/en/instana-observability/1.0.302) for reference.
- A running Langflow application setup

## Integration Setup
### Step 1: Configure Environment Variables
1. Create a `.env` file in the root directory of your Langflow application (if it doesn't exist already).
2. Add your Traceloop and Instana credentials to the `.env` file:

   ```dotenv
   TRACELOOP_API_KEY=<your_traceloop_api_key>
   # Example: https://otlp-magenta-saas.instana.rocks:4318
   TRACELOOP_BASE_URL=<instana_endpoint>
   TRACELOOP_HEADERS="x-instana-key=<your_instana_key>"
   # Set to true only for plain HTTP endpoints. For HTTPS, use false.
   OTEL_EXPORTER_OTLP_INSECURE=false
   # If your Traceloop version requires a URL, use: http://host.docker.internal:8000
   TRACELOOP_METRICS_ENDPOINT=host.docker.internal:8000
   TRACELOOP_METRICS_ENABLED=true
   OTEL_METRIC_EXPORT_INTERVAL=10000
   ```

Warning: Never commit your `.env` file to source control. If your keys are exposed, rotate them immediately.

3. Save the `.env` file.
4. Make sure the OpenTelemetry (OTel) Collector is running.
   - In your Collector’s `config.yaml`, add the following (update to match your Instana endpoint and service names):
   ```yaml
   # Example values — update to your environment
   llm.application: "LLM_DC"
   instances:
      - otel.agentless.mode: true
      # Example endpoint: https://otlp-magenta-saas.instana.rocks:4318
      otel.backend.url: "<INSTANA_ENDPOINT>"
      otel.backend.using.http: false
      callback.interval: 10
      otel.service.name: "DC1"
      otel.service.port: 8000
      currency: "USD"
   ```

### Step 2: Start Langflow with Environment Variables
Launch your Langflow application using the environment file:
```bash
uv run langflow run --env-file .env
```

Once configured, Traceloop will automatically begin monitoring and collecting telemetry data from your LLM applications.

To verify that observability is working correctly:

1. **Run a flow in Langflow:**
   - In Langflow, select the "Simple Agent" starter project
   - In the **Agent** component's **API Key** field, enter your LLM API key
   - Click **Playground**
   - Ask your Agent several questions to generate test traffic

2. **View Traces in Instana:**
   - Open Instana and select `Applications` from the sidebar.
   - Click on `Services` tab in the Navbar (Top).
   - Search for `Langflow` and click on it to view and analyze the associated calls.

3. **View Metrics in Instana:**
   - Open Instana and select `Infrastructure`.
   - Click on `Analyse Infrastructure`.
   - Search for `Otel LLMonitor`.
   - Select `LLM:DC1@your_machine_name.local` to view your Metrics dashboard.

## Troubleshooting

If you don't see traces appearing:
- Verify that your API keys and endpoints are correct in the `.env` file
- Ensure the `.env` file is in the correct root directory
- Confirm that Langflow is starting with the `--env-file .env` parameter
- Check that you've generated sufficient test traffic through the Playground

If you don’t see metrics appearing:
- Ensure the OpenTelemetry (Otel) Data Collector is running without errors.
- Verify that the Otel DC config.yaml is configured as described above.
- Confirm that the Instana endpoint and the service port (e.g., service.port: 8000) are correctly exposed and accessible.
- Check whether the metrics are being logged in the Otel DC terminal output.

For additional configuration options and advanced features, refer to the respective platform documentation for [Traceloop](https://www.traceloop.com/docs/introduction) or [Instana](https://www.ibm.com/docs/en/instana-observability/current).