---
title: Langflow best practices on Kubernetes
slug: /deployment-prod-best-practices
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

This guide provides best practices for deploying Langflow in production environments on Kubernetes.

## Scaling resources

Langflow's resource requirements depend on whether you're deploying the IDE for development or the runtime for production flows.

This section describes strategies for scaling RAM, disk, instances, and users per instance.

### Resource requirements by deployment type

* **IDE**: Deploy for developers using the UI. Requires frontend (512Mi RAM, 0.3 CPU) and backend (1Gi RAM, 0.5 CPU) services.
* **Runtime**: Deploy for production flows. Headless, requiring 2Gi RAM and 1 CPU per instance, focused on API endpoints.

### Example resource configuration

| Component | RAM Request | CPU Request | Replica Count | Notes |
|-----------|-------------|-------------|---------------|-------|
| IDE Backend | 1Gi | 0.5 | 1 | Scale replicas for more developers. |
| IDE Frontend | 512Mi | 0.3 | 1 | Adjust based on UI load. |
| Runtime | 2Gi | 1000m | 3 | Use HPA for dynamic scaling. |
| PostgreSQL | 4Gi | 2 | 1+ | Use replication for high availability. |

### RAM

 RAM usage in Langflow depends on flow complexity, the size of language models, and concurrent request volume. The runtime (for production flows) has a baseline requirement, while the IDE (for developers) requires additional resources for the frontend and backend.

#### Base requirements

* **Runtime**: 2Gi per instance.
* **IDE Backend**: 1Gi per instance.
* **IDE Frontend**: 512Mi per instance.

#### Factors affecting RAM usage:

* **Flow Complexity**: Flows with many nodes or large datasets (e.g., RAG pipelines) increase memory needs.
* **Language Models**: Larger LLMs or embeddings loaded in-memory consume significant RAM.
* **Concurrent Requests**: More simultaneous API calls or UI sessions require additional memory.

#### Scaling recommendations:

* Start with 2Gi for runtime instances and 1.5Gi total (1Gi backend + 512Mi frontend) for IDE instances.
* Monitor memory usage with tools like Prometheus to identify bottlenecks.
* Adjust memory requests and limits in Kubernetes. For example:

    ```yaml
    resources:
      requests:
        memory: "2Gi"
        cpu: "1000m"
      limits:
        memory: "4Gi"
        cpu: "2000m"
    ```

* For intensive use (e.g., multi-core CPU setups), allocate 4Gi or more per instance.

### Disk

Disk storage is used for the SQLite or PostgreSQL database and file storage for large files, such as documents for RAG. The database stores flow configurations, user data, and settings, while files are managed on disk.

#### Usage

* **Database**: Stores flow definitions, user profiles, and logs. Size depends on the number of flows and users.
* **File Storage**: Large files are stored in directories like `/opt/langflow/data/` or `.cache/langflow/`.

#### Scaling recomendations

* Use an external PostgreSQL database for production to improve scalability and reliability.
* Configure shared file storage such as NFS or cloud storage for multi-instance setups to ensure file access across replicas.
* Estimate initial database size based on expected flows and users, such as 10GB for moderate use, and monitor growth.
* Use Persistent Volumes in Kubernetes for database and file storage, with dynamic provisioning for scalability.

### Instances

Scaling instances involves adding more replicas to handle increased load, applicable to both IDE and runtime deployments. Horizontal scaling is preferred for production environments.

#### Base configuration

* **Runtime**: Default replica count of 3.
* **IDE**: Default replica count of 1 for both backend and frontend.

#### Scaling recommendations

* Implement Horizontal Pod Autoscaler (HPA) in Kubernetes to dynamically adjust replicas based on CPU or memory usage. Example HPA configuration:

    ```yaml
    apiVersion: autoscaling/v2
    kind: HorizontalPodAutoscaler
    metadata:
      name: langflow-runtime-hpa
    spec:
      scaleTargetRef:
        apiVersion: apps/v1
        kind: Deployment
        name: langflow-runtime
      minReplicas: 1
      maxReplicas: 10
      metrics:
      - type: Resource
        resource:
          name: cpu
          target:
            type: Utilization
            averageUtilization: 80
    ```

* For bursty workloads, such as 100,000s of tokens per second, ensure sufficient replicas to handle spikes.
* Vertically scale by increasing CPU/memory requests for complex flows, but prioritize horizontal scaling for reliability.

### Users per instance

The number of users or requests per instance depends on whether you're supporting developers with the IDE or API clients with the runtime:

* **IDE (Langflow UI)**:
    * Each developer using the UI generates requests to the backend, requiring resources for session handling.
    * Scale backend replicas based on concurrent developers (e.g., 1 replica per 10-20 developers, adjusted using load testing).

* **Runtime (production flows)**:
    * Users are typically API clients making requests to flow endpoints.
    * Capacity depends on request rate and flow complexity. For example, a single instance with 2vCPUs and 2GB RAM can handle ~30 concurrent connections for simple flows.
    * Perform load testing to determine the number of requests per instance and scale replicas accordingly.

#### Scaling recommendations

* Use load balancers to distribute requests across replicas.
* Monitor API request rates and response times to adjust replica counts.
* For IDE, ensure frontend and backend replicas are balanced to avoid bottlenecks.

## Failure Points

Langflow's reliability in production depends on mitigating key failure points, particularly around the database, file system, and instance availability.

### Database failure

* **Impact**: Disrupts flow retrieval, saving, user authentication, user management, project collection access, configuration updates, and log writing.
* **Mitigation**: Use a replicated PostgreSQL setup with high availability and regular backups. Flows already loaded in memory may continue to function.

### File system issues

* **Impact**: Concurrency issues in file caching, such as `/app/data/.cache`, can cause IO errors in multi-instance setups.
* **Mitigation**: Use a shared, POSIX-compliant file system or cloud storage. Avoid ramdisk solutions due to data loss on container shutdown.

### Instance failures

* **Impact**: A single instance failure can disrupt service if not replicated.
* **Mitigation**: Deploy multiple replicas with Kubernetes to ensure availability. Use health checks to detect and replace failed pods.

### Network and dependency failures

* **Impact**: External APIs or services used in flows may fail, causing flow errors.
* **Mitigation**: Implement retry logic and error handling in flows. Monitor network latency and dependency health.

## Monitoring recommendations

Effective monitoring ensures Langflow operates reliably and performs well under varying loads.

### Database health

* Monitor availability, query performance, and resource usage (CPU, memory, disk).
* Use tools like pgAdmin or cloud-native monitoring for PostgreSQL.

### Application logs

* Collect and analyze logs for errors, warnings, and flow execution issues.
* Centralize logs using tools like ELK Stack or Fluentd.

### Resource usage

* Track CPU, memory, and disk usage of Langflow instances.
* Use Prometheus and Grafana for real-time monitoring in Kubernetes.

### API performance

* Monitor response times, error rates, and request throughput.
* Set alerts for high latency or error spikes.

### Observability tools

* Integrate with LangSmith or LangFuse for detailed flow tracing and metrics.
* Use these tools to debug flow performance and optimize execution.

### Example monitoring setup

* Deploy Prometheus for metrics collection.
* Use Grafana dashboards to visualize resource usage and API performance.
* Configure alerts for critical thresholds (e.g., 90% memory usage, 500ms API latency).

## Security implications

Running Langflow in production requires robust security measures to protect the application, data, and users.

### Container security

* Enable `readOnlyRootFilesystem: true` in runtime containers to prevent unauthorized modifications.
* Only disable if necessary and with compensating controls.

### Secrets management

* Store sensitive data like API keys in Kubernetes secrets or external secret managers.
* Avoid embedding secrets in flow JSON files.

### Authentication and authorization

* Implement strong authentication for the IDE UI and runtime API like OAuth or API tokens.
* Enforce role-based access control to limit user permissions.

### Data privacy

* Ensure compliance with regulations like GDPR if handling personal data.
* Encrypt sensitive data at rest and in transit.

### Encryption

* Use HTTPS for all communications to secure data in transit.
* Configure TLS for PostgreSQL connections.

### Additional security measures

* Conduct regular security audits and apply software updates.
* Restrict network access to Langflow services using firewalls or network policies.
* Monitor for suspicious activity using intrusion detection systems.

## See also

* [Deploy the Langflow production environment on Kubernetes](/deployment-kubernetes-prod)
* [Langflow Helm Charts repository](https://github.com/langflow-ai/langflow-helm-charts)
* [Database guide for enterprise DBAs](/enterprise-database-guide)