---
title: Langflow database guide for enterprise DBAs
slug: /enterprise-database-guide
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

The Langflow database stores data that is essential for more Langflow operations, including startup, flow execution, user interactions, and administrative tasks.
The database supports both frontend (visual editor) and backend (API) operations, making its availability critical to Langflow's stability and functionality.
For details about the database schema, see [Memory management options](/memory).

This guide is designed for enterprise database administrators (DBAs) and operators responsible for deploying and managing Langflow in production environments.
It explains how to configure Langflow to use PostgreSQL, including high availability (HA) and active-active configurations, as well as best practices for monitoring, maintenance, and security.

## Configure Langflow with PostgreSQL

Langflow's default database is SQLite.
However, PostgreSQL is recommended for production deployments due to its scalability, performance, and robustness.

The following steps explain how to configure Langflow to use PostgreSQL for a standalone or containerized deployment.
For more information, see [Configure an external PostgreSQL database](/configuration-custom-database).

1. Set up PostgreSQL:

   Deploy a PostgreSQL instance (version 12 or higher recommended) using a local server, Docker, or a managed cloud service.
   Then, create a database for Langflow and a user with appropriate permissions to manage and write to the database.

2. Obtain the connection string in the format `postgresql://user:password@host:port/dbname`, such as`postgresql://langflow:securepassword@postgres:5432/langflow`.

   For High Availability setups, use a virtual IP or proxy hostname.
   For more information, see [High Availability for PostgreSQL](#high-availability-ha-for-postgresql).

3. Configure Langflow with the `.env` or `docker-compose.yml` files.

    <Tabs groupId="environment">
    <TabItem value=".env" label=".env" default>

    1. Create a `.env` file in the `langflow` directory:

        ```shell
        touch .env
        ```

    2. Add the connection string to the `.env` file:

        ```text
        LANGFLOW_DATABASE_URL="postgresql://langflow:securepassword@postgres:5432/langflow"
        ```

    For more environment variables, see the `.env.example` file in the Langflow repository.

    </TabItem>
    <TabItem value="docker-compose.yml" label="docker-compose.yml">

    Use the sample `docker-compose.yml` from the Langflow Repository.
    You can use the default values or customize them as needed.

    ```yaml
    version: '3'
    services:
      langflow:
        image: langflowai/langflow:latest
        ports:
          - "7860:7860"
        environment:
          - LANGFLOW_DATABASE_URL=postgresql://langflow:langflow@postgres:5432/langflow
      postgres:
        image: postgres:16
        ports:
          - "5432:5432"
        environment:
          - POSTGRES_USER=langflow
          - POSTGRES_PASSWORD=langflow
          - POSTGRES_DB=langflow
        volumes:
          - langflow-postgres:/var/lib/postgresql/data
    volumes:
      - langflow-postgres:
    ```

    </TabItem>
    </Tabs>


4. Start Langflow with your PostgreSQL connection:

    <Tabs groupId="environment">
      <TabItem value=".env" label=".env" default>

      ```shell
      uv run langflow run --env-file .env
      ```

      </TabItem>
      <TabItem value="docker-compose.yml" label="docker-compose.yml">

      Navigate to the directory containing `docker-compose.yml`, and then run `docker-compose up`.

      </TabItem>
    </Tabs>

5. Optional: Run migrations.

    Langflow uses SQLAlchemy and Alembic to manage its database schema.
    When you first connect to PostgreSQL, Langflow automatically runs migrations to create the necessary tables.

    To manually run migrations, run `langflow migration --test` to preview the changes, and then run `langflow migration --no-test` to apply the migrations.

    :::danger
    Migrations are a destructive operation that can delete data.
    Always run `--test` to preview changes before applying them.
    For more information, see [Langflow CLI](/configuration-cli).
    :::

6. To verify the configuration, create any flow using the Langflow visual editor or API, and then query your database to confirm the tables and activity are recorded there. The content of the flow doesn't matter; you only need to confirm that the flow is stored in your PostgreSQL database.
You can query the database in two ways:

    * Query the database container:

        ```
        docker exec -it <postgres-container> psql -U langflow -d langflow
        ```

    * Use SQL:

        ```
        SELECT * FROM pg_stat_activity WHERE datname = 'langflow';
        ```

## Advanced PostgreSQL configurations

Once your basic setup is running with Langflow connected to PostgreSQL, you might want to configure High Availability to prevent downtime if your database server fails, or Active-Active configurations to handle more users and provide automatic failover if one Langflow instance goes down.

Some situations to prepare for in these configurations:

* **Concurrency**: PostgreSQL handles concurrent connections well, but monitor for contention or deadlocks during high load.
* **Session Management**: For the IDE, ensure session persistence or stateless authentication such as JWT to avoid issues with load balancing.
* **File Storage**: Large files are stored on disk, for example at `/opt/langflow/data/`, and require shared storage such as NFS or cloud storage for multi-instance setups.

### High Availability (HA) for PostgreSQL

For production deployments, you can enhance your PostgreSQL setup with high availability to ensure continuous operation, especially when multiple Langflow instances rely on the same database.

To configure HA for PostgreSQL, follow these steps:

1. Set up streaming replication.
Configure one primary database for writes and one or more replicas for reads and failover.
Choose between synchronous or asynchronous replication based on your latency and consistency requirements.

2. Implement automatic failover using one of these options:
    * Use [Patroni](https://patroni.readthedocs.io/en/latest/) with etcd or [Consul](https://developer.hashicorp.com/consul).
    * Use [Pgpool-II](https://www.pgpool.net/docs/46/en/html/index.html) for connection pooling and failover.
    * Use managed services like AWS RDS or Google Cloud SQL which provide built-in HA with automatic failover.

    For example, to configure HA using Patroni:

    1. Deploy a PostgreSQL cluster with Patroni, etcd, and [HAProxy](https://www.haproxy.org/).
    2. Configure Langflow's `LANGFLOW_DATABASE_URL` to point to HAProxy's virtual IP.
    3. Monitor failover events and ensure replicas are in sync.

3. Update your PostgreSQL connection string to point to the HA setup.
     * Use a virtual IP or DNS name that resolves to the current primary database, such as `postgresql://langflow:securepassword@db-proxy:5432/langflow?sslmode=require`.
     * For managed services, use the provided endpoint, such as `langflow.cluster-xyz.us-east-1.rds.amazonaws.com`.
     * Langflow, through [SQLAlchemy](https://docs.sqlalchemy.org/en/20/), supports reconnection attempts and ensures recovery after failover.

4. Optional: configure load balancing.
For read-heavy workloads, distribute read queries across replicas using a connection pooler like [PgBouncer](https://www.pgbouncer.org/) or with a load balancer.
Configure Langflow to use a single connection string pointing to the primary PostgreSQL database or to a proxy.

### Active-Active High Availability for Langflow

Building on your HA PostgreSQL setup, you can deploy multiple Langflow instances in an active-active configuration to ensure scalability and resilience.

To configure Active-Active HA for Langflow, follow these steps:

1. Deploy multiple Langflow instances using Kubernetes or Docker Swarm.
The example configuration deploys 3 `langflow-runtime` replicas for production flows.

2. Include a load balancer to distribute requests across the 3 instances.
The example configuration includes the Kubernetes load balancer service to distribute traffic to healthy pods.

3. Ensure all instances connect to the same HA PostgreSQL database.
The example configuration uses the same connection string from your HA PostgreSQL setup.

    ```yaml
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: langflow-runtime
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: langflow-runtime
      template:
        metadata:
          labels:
            app: langflow-runtime
        spec:
          containers:
          - name: langflow
            image: langflowai/langflow:latest
            ports:
            - containerPort: 7860
            env:
            - name: LANGFLOW_DATABASE_URL
              value: "postgresql://langflow:securepassword@db-proxy:5432/langflow?sslmode=require"
    ---
    apiVersion: v1
    kind: Service
    metadata:
      name: langflow-runtime
    spec:
      selector:
        app: langflow-runtime
      ports:
      - port: 80
        targetPort: 7860
      type: LoadBalancer
    ```

## Impact of database failure

If the PostgreSQL database becomes unavailable, the following Langflow functions will fail:

* **Flow Retrieval**: Cannot load new or existing flows from the database.
* **Flow Saving**: Unable to save new flows or updates to existing flows.
* **User Authentication**: Login and user management functions fail.
* **Project Collection Access**: Cannot access or share community/custom project collections.
* **Configuration Retrieval**: Unable to load application settings.
* **Configuration Updates**: Changes to settings cannot be saved.
* **Execution Log Access**: Cannot retrieve historical flow execution logs.
* **Log Writing**: New execution or system activity logs cannot be recorded.
* **Multi-User Collaboration**: Sharing flows or projects across users fails.
* **API Flow Loading**: API requests to load new flows (non-cached) fail.

Flows already loaded in memory may continue to function with cached configurations.
However, any operation requiring database access fails until the database is restored.

Langflow, through SQLAlchemy, attempts to reconnect to the database after a failure and reduces disruption once the database is back online.

To further mitigate these issues and minimize the chance of database failure, use HA configurations and record backups regularly.

## Monitoring and maintenance

Database administrators must monitor and maintain the PostgreSQL database to ensure optimal performance and reliability.

### Monitoring

* **Performance Metrics**:
  * CPU, memory, and disk I/O usage.
  * Use `pg_stat_statements` to monitor query performance and slow queries.
  * Use `pg_stat_activity` to monitor connection counts and contention.
* **Replication Health**:
  * Check replica lag and synchronization status.
  * Monitor failover events and alerts.
* **Tools**:
  * Use pgAdmin, Prometheus with PostgreSQL exporter, or cloud-native monitoring for managed services.
  * Centralize Langflow application logs with ELK Stack or Fluentd for correlation with database issues.

### Maintenance

* **Backups**:
  * Schedule daily logical backups using `pg_dump` or continuous archiving with a write-ahead log (WAL).
  * Test restore procedures quarterly to ensure data recovery.
* **Schema Management**:
  * Langflow manages its schema using migrations, executed with `langflow migration`.
  * Avoid manual schema changes to prevent conflicts with Langflow's migration system.
* **Optimization**:
  * Analyze query patterns, such as frequent reads on flow tables, and create indexes as needed.
  * Tune PostgreSQL parameters, such as `work_mem` and `shared_buffers`, based on workload.

## Security considerations

Securing the database and Langflow's connection to it is critical for enterprise deployments.

* **Secure Credentials**:
  * Store database credentials in a secrets management system like HashiCorp Vault or Kubernetes secrets.
  * Restrict access to the `.env` file or environment variables containing the connection string.
* **SSL Encryption**:
  * Enable SSL for database connections by appending `?sslmode=require` or `?sslmode=verify-full` to the connection string.
  * Ensure PostgreSQL is configured with valid SSL certificates.
* **Access Control**:
  * Grant the Langflow database user minimal permissions, such as CREATE, SELECT, INSERT, UPDATE, DELETE on Langflow tables.
  * Use network security groups or VPCs to restrict database access to Langflow instances.
* **Auditing**:
  * Enable PostgreSQL logging, such as `log_connections` and `log_statements`, to track access and changes.
  * Regularly review logs for suspicious activity.
* **Updates**:
  * Apply security patches to PostgreSQL and Langflow promptly.
  * Monitor for vulnerabilities using tools like Dependabot for Langflow dependencies.

## See also

* [Configure an external PostgreSQL database](/configuration-custom-database)
* [Langflow architecture on Kubernetes](/deployment-architecture)
* [Deploy the Langflow production environment on Kubernetes](/deployment-kubernetes-prod)