{
    "data": {
      "nodes": [
        {
          "id": "TextInput-qsulq",
          "type": "genericNode",
          "position": {
            "x": 334.84637409564385,
            "y": -1851.2882723236562
          },
          "data": {
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "list_add_label": "Add More",
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "Acute laryngitis",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Text to be passed as input.",
                  "title_case": false,
                  "copy_field": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                }
              },
              "description": "Get text inputs from the Playground.",
              "icon": "type",
              "base_classes": [
                "Message"
              ],
              "display_name": "Text Input",
              "documentation": "",
              "minimized": false,
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "Message",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "allows_loop": false,
                  "tool_mode": true
                }
              ],
              "field_order": [
                "input_value"
              ],
              "beta": false,
              "legacy": false,
              "edited": false,
              "metadata": {},
              "tool_mode": false,
              "category": "inputs",
              "key": "TextInput",
              "score": 0.0020353564437605998
            },
            "showNode": true,
            "type": "TextInput",
            "id": "TextInput-qsulq"
          },
          "selected": false,
          "measured": {
            "width": 320,
            "height": 234
          },
          "dragging": false
        },
        {
          "id": "TextInput-tl957",
          "type": "genericNode",
          "position": {
            "x": 327.7117627629448,
            "y": -1460.0581491671132
          },
          "data": {
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "list_add_label": "Add More",
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "Debridement of eczematous skin, each additional 10% of body surface",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Text to be passed as input.",
                  "title_case": false,
                  "copy_field": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                }
              },
              "description": "Get text inputs from the Playground.",
              "icon": "type",
              "base_classes": [
                "Message"
              ],
              "display_name": "Text Input",
              "documentation": "",
              "minimized": false,
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "Message",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "allows_loop": false,
                  "tool_mode": true
                }
              ],
              "field_order": [
                "input_value"
              ],
              "beta": false,
              "legacy": false,
              "edited": false,
              "metadata": {},
              "tool_mode": false,
              "category": "inputs",
              "key": "TextInput",
              "score": 0.0020353564437605998
            },
            "showNode": true,
            "type": "TextInput",
            "id": "TextInput-tl957"
          },
          "selected": false,
          "measured": {
            "width": 320,
            "height": 234
          },
          "dragging": false
        },
        {
          "id": "Prompt-jMTFG",
          "type": "genericNode",
          "position": {
            "x": 990.7919010540265,
            "y": -1883.4707675939487
          },
          "data": {
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "list": false,
                  "list_add_label": "Add More",
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "{procedure_description} is considered medically necessary for {diagnosis_description} under which scenarios/indications?",
                  "display_name": "Template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "prompt",
                  "_input_type": "PromptInput"
                },
                "tool_placeholder": {
                  "tool_mode": true,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "list_add_label": "Add More",
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tool_placeholder",
                  "value": "",
                  "display_name": "Tool Placeholder",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "A placeholder input for tool mode.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "procedure_description": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "name": "procedure_description",
                  "display_name": "procedure_description",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "diagnosis_description": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "name": "diagnosis_description",
                  "display_name": "diagnosis_description",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "priority": null,
              "documentation": "",
              "minimized": false,
              "custom_fields": {
                "template": [
                  "procedure_description",
                  "diagnosis_description"
                ]
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": null,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "required_inputs": null,
                  "allows_loop": false,
                  "options": null,
                  "tool_mode": true
                }
              ],
              "field_order": [
                "template",
                "tool_placeholder"
              ],
              "beta": false,
              "legacy": false,
              "error": null,
              "edited": false,
              "metadata": {},
              "tool_mode": false
            },
            "showNode": true,
            "type": "Prompt",
            "id": "Prompt-jMTFG"
          },
          "selected": false,
          "measured": {
            "width": 320,
            "height": 433
          },
          "dragging": false
        },
        {
          "id": "KnowledgeHubSearch-1BsTI",
          "type": "genericNode",
          "position": {
            "x": 1562.1483176375789,
            "y": -2035.7557467826953
          },
          "data": {
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from __future__ import annotations\n\nfrom typing import Any\n\nfrom langflow.custom import Component\nfrom langflow.io import MultilineInput, MultiselectInput, Output\nfrom langflow.schema import Data\nfrom langflow.services.manager import service_manager\nfrom loguru import logger\n\n\nclass KnowledgeHub(Component):\n    display_name = \"Knowledge Hub Search\"\n    description = (\n        \"This component is used to search for information in the knowledge hub.\"\n    )\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"Autonomize\"\n    name = \"KnowledgeHubSearch\"\n\n    def __init__(self, **kwargs):\n        self._hub_data: list[dict[str, str]] = []\n        super().__init__(**kwargs)\n\n    async def update_build_config(\n        self, build_config: dict, field_value: Any, field_name: str | None = None\n    ):\n        \"\"\"Update the build configuration based on field changes.\"\"\"\n        logger.info(f\"update_build_config called with field_name: {field_name}\")\n\n        if field_name == \"selected_hubs\":\n            try:\n                # Load the hub options when the field is refreshed\n                service = service_manager.get(\"knowledge_service\")\n                if not service.ready:\n                    logger.error(\"KnowledgeHub service is not ready\")\n                    return build_config\n                self._hub_data = await service.get_knowledge_hubs()\n\n                # Debug the raw response\n                logger.info(f\"Raw hub data: {self._hub_data}\")\n\n                options = [hub[\"name\"] for hub in self._hub_data]\n                logger.info(f\"Extracted hub options: {options}\")\n\n                # Debug the build_config before update\n                logger.info(\n                    f\"Build config before update: {build_config.get('selected_hubs', {})}\"\n                )\n\n                build_config[\"selected_hubs\"][\"options\"] = options\n\n                # Debug the build_config after update\n                logger.info(\n                    f\"Build config after update: {build_config.get('selected_hubs', {})}\"\n                )\n\n                return build_config\n            except Exception as e:\n                logger.exception(f\"Error in update_build_config: {e!s}\")\n                raise\n        return build_config\n\n    inputs = [\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n            tool_mode=True,\n        ),\n        MultiselectInput(\n            name=\"selected_hubs\",\n            display_name=\"Data Sources\",\n            value=[],\n            refresh_button=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Query Results\",\n            name=\"query_results\",\n            method=\"build_output\",\n        ),\n    ]\n\n    async def build_output(self) -> Data:\n        \"\"\"Generate the output based on selected knowledge hubs.\"\"\"\n        try:\n            if not self.selected_hubs:\n                logger.warning(\"No knowledge hubs selected.\")\n                return Data(value={\"query_results\": []})\n\n            # Make sure we have hub data\n            if not self._hub_data:\n                service = service_manager.get(\"knowledge_service\")\n                if not service.ready:\n                    logger.error(\"KnowledgeHub service is not ready\")\n                    return Data(value={\"query_results\": []})\n                self._hub_data = await service.get_knowledge_hubs()\n\n            # Map the selected names to their IDs\n            selected_hub_ids = [\n                hub[\"id\"] for hub in self._hub_data if hub[\"name\"] in self.selected_hubs\n            ]\n\n            service = service_manager.get(\"knowledge_service\")\n            if not service.ready:\n                logger.error(\"KnowledgeHub service is not ready\")\n                return Data(value={\"query_results\": []})\n            query_results = await service.query_vector_store(\n                knowledge_hub_ids=selected_hub_ids, query=self.search_query\n            )\n            logger.debug(f\"query_results: {query_results}\")\n            # Concatenate content from query results\n            contents = [\n                result.get(\"metadata\", {}).get(\"content\", \"\")\n                for result in query_results\n            ]\n            plain_text = \"\\n\\n=== NEW CHUNK ===\\n\\n\".join(contents)\n\n            data = Data(\n                text=plain_text,\n                data={\n                    \"result\": query_results,\n                },\n            )\n            self.status = data\n            return data\n\n        except Exception as e:\n            logger.error(f\"Error in build_output: {e!s}\")\n            return Data(value={\"query_results\": []})\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "search_query": {
                  "tool_mode": true,
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "list_add_label": "Add More",
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "search_query",
                  "value": "",
                  "display_name": "Search Query",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "copy_field": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "selected_hubs": {
                  "tool_mode": false,
                  "trace_as_metadata": true,
                  "options": [
                    "Blue Shield CA - Medical Policy",
                    "Blue Cross CA - Medical Drug Clinical Criteria",
                    "Carelon Guidelines - 2023",
                    "Blue Cross Blue Shield - MA - Interqual - Medical Policy",
                    "Conduent Guidelines",
                    "CMS - 2024",
                    "Evicore Guidelines - 2023",
                    "Aetna Guidelines",
                    "Essence Healthcare - Internal Guidelines - 2025",
                    "E2E-Testing",
                    "EOC",
                    "CMS-DME",
                    "EOC-Doc",
                    "test-data",
                    "test@123",
                    "Evicore-2025",
                    "TestKnowledgeHub",
                    "Molina EOC Guidelines (deprecated)",
                    "CMS Benefits Accumulator Guidelines",
                    "Molina EOC Guidelines"
                  ],
                  "combobox": false,
                  "toggle": false,
                  "list": true,
                  "list_add_label": "Add More",
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "selected_hubs",
                  "value": [
                    "Carelon Guidelines - 2023"
                  ],
                  "display_name": "Data Sources",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "refresh_button": true,
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultiselectInput"
                }
              },
              "description": "This component is used to search for information in the knowledge hub.",
              "icon": "Autonomize",
              "base_classes": [
                "Data"
              ],
              "display_name": "Knowledge Hub Search",
              "documentation": "http://docs.langflow.org/components/custom",
              "minimized": false,
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "query_results",
                  "hidden": null,
                  "display_name": "Query Results",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "required_inputs": null,
                  "allows_loop": false,
                  "options": null,
                  "tool_mode": true
                }
              ],
              "field_order": [
                "search_query",
                "selected_hubs"
              ],
              "beta": false,
              "legacy": false,
              "edited": false,
              "metadata": {},
              "tool_mode": false,
              "category": "vectorstores",
              "key": "KnowledgeHubSearch",
              "score": 0.01857804455091699
            },
            "showNode": true,
            "type": "KnowledgeHubSearch",
            "id": "KnowledgeHubSearch-1BsTI"
          },
          "selected": false,
          "measured": {
            "width": 320,
            "height": 340
          },
          "dragging": false
        },
        {
          "id": "ParserComponent-d7mAH",
          "type": "genericNode",
          "position": {
            "x": 2148.9440773183887,
            "y": -1778.175270455275
          },
          "data": {
            "node": {
              "template": {
                "_type": "Component",
                "input_data": {
                  "trace_as_metadata": true,
                  "list": false,
                  "list_add_label": "Add More",
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "input_data",
                  "value": "",
                  "display_name": "Data or DataFrame",
                  "advanced": false,
                  "input_types": [
                    "DataFrame",
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "Accepts either a DataFrame or a Data object.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import json\nfrom typing import Any\n\nfrom langflow.custom import Component\nfrom langflow.io import (\n    BoolInput,\n    HandleInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n    TabInput,\n)\nfrom langflow.schema import Data, DataFrame\nfrom langflow.schema.message import Message\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = (\n        \"Format a DataFrame or Data object into text using a template. \"\n        \"Enable 'Stringify' to convert input into a readable string instead.\"\n    )\n    icon = \"braces\"\n\n    inputs = [\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                return json.dumps(data.data)\n            if isinstance(data, DataFrame):\n                if hasattr(self, \"clean_data\") and self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n                return data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([self._safe_convert(item) for item in self.input_data])\n        else:\n            result = self._safe_convert(self.input_data)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "mode": {
                  "tool_mode": false,
                  "trace_as_metadata": true,
                  "options": [
                    "Parser",
                    "Stringify"
                  ],
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "mode",
                  "value": "Parser",
                  "display_name": "Mode",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Convert into raw string instead of using a template.",
                  "real_time_refresh": true,
                  "title_case": false,
                  "type": "tab",
                  "_input_type": "TabInput"
                },
                "pattern": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "list_add_label": "Add More",
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "pattern",
                  "value": "Text: {text}",
                  "display_name": "Template",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": true,
                  "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                  "title_case": false,
                  "copy_field": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "sep": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "list_add_label": "Add More",
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sep",
                  "value": "\n",
                  "display_name": "Separator",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "String used to separate rows/items.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Format a DataFrame or Data object into text using a template. Enable 'Stringify' to convert input into a readable string instead.",
              "icon": "braces",
              "base_classes": [
                "Message"
              ],
              "display_name": "Parser",
              "documentation": "",
              "minimized": false,
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "parsed_text",
                  "display_name": "Parsed Text",
                  "method": "parse_combined_text",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "allows_loop": false,
                  "tool_mode": true
                }
              ],
              "field_order": [
                "mode",
                "pattern",
                "input_data",
                "sep"
              ],
              "beta": false,
              "legacy": false,
              "edited": false,
              "metadata": {},
              "tool_mode": false,
              "category": "processing",
              "key": "ParserComponent",
              "score": 0.001
            },
            "showNode": true,
            "type": "ParserComponent",
            "id": "ParserComponent-d7mAH"
          },
          "selected": false,
          "measured": {
            "width": 320,
            "height": 371
          }
        },
        {
          "id": "Prompt-dzqah",
          "type": "genericNode",
          "position": {
            "x": 2770.795168097013,
            "y": -1884.8654085790586
          },
          "data": {
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "list": false,
                  "list_add_label": "Add More",
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "Question:\n{question}\nContext:\n{context}\nClinical Guideline Criteria are as follows:",
                  "display_name": "Template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "prompt",
                  "_input_type": "PromptInput"
                },
                "tool_placeholder": {
                  "tool_mode": true,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "list_add_label": "Add More",
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tool_placeholder",
                  "value": "",
                  "display_name": "Tool Placeholder",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "A placeholder input for tool mode.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "question": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "name": "question",
                  "display_name": "question",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "context": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "name": "context",
                  "display_name": "context",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "priority": null,
              "documentation": "",
              "minimized": false,
              "custom_fields": {
                "template": [
                  "question",
                  "context"
                ]
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": null,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "required_inputs": null,
                  "allows_loop": false,
                  "options": null,
                  "tool_mode": true
                }
              ],
              "field_order": [
                "template",
                "tool_placeholder"
              ],
              "beta": false,
              "legacy": false,
              "error": null,
              "edited": false,
              "metadata": {},
              "tool_mode": false
            },
            "showNode": true,
            "type": "Prompt",
            "id": "Prompt-dzqah"
          },
          "selected": false,
          "measured": {
            "width": 320,
            "height": 433
          },
          "dragging": false
        },
        {
          "id": "AzureOpenAIModel-60mCZ",
          "type": "genericNode",
          "position": {
            "x": 3431.8322562740423,
            "y": -1831.7248089073114
          },
          "data": {
            "node": {
              "template": {
                "_type": "Component",
                "api_key": {
                  "load_from_db": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "api_key",
                  "value": null,
                  "display_name": "API Key",
                  "advanced": false,
                  "input_types": [],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "api_version": {
                  "tool_mode": false,
                  "trace_as_metadata": true,
                  "options": [
                    "2025-02-01-preview",
                    "2025-01-01-preview",
                    "2024-12-01-preview",
                    "2024-10-01-preview",
                    "2024-09-01-preview",
                    "2024-08-01-preview",
                    "2024-07-01-preview",
                    "2024-06-01",
                    "2024-03-01-preview",
                    "2024-02-15-preview",
                    "2023-12-01-preview",
                    "2023-05-15"
                  ],
                  "options_metadata": [],
                  "combobox": false,
                  "dialog_inputs": {},
                  "toggle": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "api_version",
                  "value": "2024-06-01",
                  "display_name": "API Version",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "azure_deployment": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "list_add_label": "Add More",
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "azure_deployment",
                  "value": "GPT316k",
                  "display_name": "Deployment Name",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "azure_endpoint": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "list_add_label": "Add More",
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "azure_endpoint",
                  "value": "https://cog-54p2emd7pu2vu.openai.azure.com/",
                  "display_name": "Azure Endpoint",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain_openai import AzureChatOpenAI\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import MessageTextInput\nfrom langflow.io import DropdownInput, IntInput, SecretStrInput, SliderInput\n\n\nclass AzureChatOpenAIComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI\"\n    description: str = \"Generate text using Azure OpenAI LLMs.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/llms/azure_openai\"\n    beta = False\n    icon = \"Azure\"\n    name = \"AzureOpenAIModel\"\n\n    AZURE_OPENAI_API_VERSIONS = [\n        \"2024-06-01\",\n        \"2024-07-01-preview\",\n        \"2024-08-01-preview\",\n        \"2024-09-01-preview\",\n        \"2024-10-01-preview\",\n        \"2023-05-15\",\n        \"2023-12-01-preview\",\n        \"2024-02-15-preview\",\n        \"2024-03-01-preview\",\n        \"2024-12-01-preview\",\n        \"2025-01-01-preview\",\n        \"2025-02-01-preview\",\n    ]\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        MessageTextInput(\n            name=\"azure_endpoint\",\n            display_name=\"Azure Endpoint\",\n            info=\"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`\",\n            required=True,\n        ),\n        MessageTextInput(name=\"azure_deployment\", display_name=\"Deployment Name\", required=True),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\", required=True),\n        DropdownInput(\n            name=\"api_version\",\n            display_name=\"API Version\",\n            options=sorted(AZURE_OPENAI_API_VERSIONS, reverse=True),\n            value=next(\n                (\n                    version\n                    for version in sorted(AZURE_OPENAI_API_VERSIONS, reverse=True)\n                    if not version.endswith(\"-preview\")\n                ),\n                AZURE_OPENAI_API_VERSIONS[0],\n            ),\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.7,\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\n            info=\"Controls randomness. Lower values are more deterministic, higher values are more creative.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        azure_endpoint = self.azure_endpoint\n        azure_deployment = self.azure_deployment\n        api_version = self.api_version\n        api_key = self.api_key\n        temperature = self.temperature\n        max_tokens = self.max_tokens\n        stream = self.stream\n\n        try:\n            output = AzureChatOpenAI(\n                azure_endpoint=azure_endpoint,\n                azure_deployment=azure_deployment,\n                api_version=api_version,\n                api_key=api_key,\n                temperature=temperature,\n                max_tokens=max_tokens or None,\n                streaming=stream,\n            )\n        except Exception as e:\n            msg = f\"Could not connect to AzureOpenAI API: {e}\"\n            raise ValueError(msg) from e\n\n        return output\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "tool_mode": false,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "list_add_label": "Add More",
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "max_tokens": {
                  "tool_mode": false,
                  "trace_as_metadata": true,
                  "list": false,
                  "list_add_label": "Add More",
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_tokens",
                  "value": "",
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "stream": {
                  "tool_mode": false,
                  "trace_as_metadata": true,
                  "list": false,
                  "list_add_label": "Add More",
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "stream",
                  "value": false,
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "system_message": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "list_add_label": "Add More",
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "system_message",
                  "value": "You are an AI assistant known for your accuracy and helpfulness. Carefully review the following clinical guidelines that are used to approve procedures for various medical conditions. Follow these specific instructions: 1. You must generate exactly **eight (8)** guidelines — no more, no less. 2. If there are **more than eight** guidelines in the context, **combine** and merge them logically so that the final output always contains **eight guidelines**. 3. If there are **fewer than eight** guidelines, **split** or expand them appropriately, ensuring that each original guideline is still represented, and the final count remains **eight guidelines**. 4. Each guideline MUST be **standalone** and **independent** and in a single line. 5. **Every guideline** provided in the context must be considered to answer the question. **Do not skip** or omit any. Ensure your final output always contains exactly **eight comprehensive guidelines**.",
                  "display_name": "System Message",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "copy_field": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "temperature": {
                  "tool_mode": false,
                  "min_label": "",
                  "max_label": "",
                  "min_label_icon": "",
                  "max_label_icon": "",
                  "slider_buttons": false,
                  "slider_buttons_options": [],
                  "slider_input": false,
                  "range_spec": {
                    "step_type": "float",
                    "min": 0,
                    "max": 2,
                    "step": 0.01
                  },
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "temperature",
                  "value": 0.7,
                  "display_name": "Temperature",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Controls randomness. Lower values are more deterministic, higher values are more creative.",
                  "title_case": false,
                  "type": "slider",
                  "_input_type": "SliderInput"
                }
              },
              "description": "Generate text using Azure OpenAI LLMs.",
              "icon": "Azure",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "Azure OpenAI",
              "documentation": "https://python.langchain.com/docs/integrations/llms/azure_openai",
              "minimized": false,
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Message",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "required_inputs": [],
                  "allows_loop": false,
                  "tool_mode": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "required_inputs": [
                    "api_key",
                    "azure_deployment",
                    "azure_endpoint"
                  ],
                  "allows_loop": false,
                  "tool_mode": true
                }
              ],
              "field_order": [
                "input_value",
                "system_message",
                "stream",
                "azure_endpoint",
                "azure_deployment",
                "api_key",
                "api_version",
                "temperature",
                "max_tokens"
              ],
              "beta": false,
              "legacy": false,
              "edited": false,
              "metadata": {},
              "tool_mode": false,
              "category": "models",
              "key": "AzureOpenAIModel",
              "score": 0.003924824467069744
            },
            "showNode": true,
            "type": "AzureOpenAIModel",
            "id": "AzureOpenAIModel-60mCZ"
          },
          "selected": false,
          "measured": {
            "width": 320,
            "height": 714
          },
          "dragging": false
        },
        {
          "id": "TextOutput-z3Y5W",
          "type": "genericNode",
          "position": {
            "x": 4078.648056986818,
            "y": -1918.5829307173126
          },
          "data": {
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "list_add_label": "Add More",
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Text to be passed as output.",
                  "title_case": false,
                  "copy_field": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                }
              },
              "description": "Display a text output in the Playground.",
              "icon": "type",
              "base_classes": [
                "Message"
              ],
              "display_name": "Text Output",
              "documentation": "",
              "minimized": false,
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "Message",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "allows_loop": false,
                  "tool_mode": true
                }
              ],
              "field_order": [
                "input_value"
              ],
              "beta": false,
              "legacy": false,
              "edited": false,
              "metadata": {},
              "tool_mode": false,
              "category": "outputs",
              "key": "TextOutput",
              "score": 0.003169567463043492
            },
            "showNode": true,
            "type": "TextOutput",
            "id": "TextOutput-z3Y5W"
          },
          "selected": false,
          "measured": {
            "width": 320,
            "height": 234
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "TextInput-qsulq",
          "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-qsulqœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-jMTFG",
          "targetHandle": "{œfieldNameœ:œdiagnosis_descriptionœ,œidœ:œPrompt-jMTFGœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "diagnosis_description",
              "id": "Prompt-jMTFG",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "TextInput",
              "id": "TextInput-qsulq",
              "name": "text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "xy-edge__TextInput-qsulq{œdataTypeœ:œTextInputœ,œidœ:œTextInput-qsulqœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-jMTFG{œfieldNameœ:œdiagnosis_descriptionœ,œidœ:œPrompt-jMTFGœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
        },
        {
          "source": "TextInput-tl957",
          "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-tl957œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-jMTFG",
          "targetHandle": "{œfieldNameœ:œprocedure_descriptionœ,œidœ:œPrompt-jMTFGœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "procedure_description",
              "id": "Prompt-jMTFG",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "TextInput",
              "id": "TextInput-tl957",
              "name": "text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "xy-edge__TextInput-tl957{œdataTypeœ:œTextInputœ,œidœ:œTextInput-tl957œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-jMTFG{œfieldNameœ:œprocedure_descriptionœ,œidœ:œPrompt-jMTFGœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
        },
        {
          "source": "Prompt-jMTFG",
          "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-jMTFGœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "target": "KnowledgeHubSearch-1BsTI",
          "targetHandle": "{œfieldNameœ:œsearch_queryœ,œidœ:œKnowledgeHubSearch-1BsTIœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "search_query",
              "id": "KnowledgeHubSearch-1BsTI",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-jMTFG",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "xy-edge__Prompt-jMTFG{œdataTypeœ:œPromptœ,œidœ:œPrompt-jMTFGœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-KnowledgeHubSearch-1BsTI{œfieldNameœ:œsearch_queryœ,œidœ:œKnowledgeHubSearch-1BsTIœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
        },
        {
          "source": "KnowledgeHubSearch-1BsTI",
          "sourceHandle": "{œdataTypeœ:œKnowledgeHubSearchœ,œidœ:œKnowledgeHubSearch-1BsTIœ,œnameœ:œquery_resultsœ,œoutput_typesœ:[œDataœ]}",
          "target": "ParserComponent-d7mAH",
          "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-d7mAHœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_data",
              "id": "ParserComponent-d7mAH",
              "inputTypes": [
                "DataFrame",
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "KnowledgeHubSearch",
              "id": "KnowledgeHubSearch-1BsTI",
              "name": "query_results",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "xy-edge__KnowledgeHubSearch-1BsTI{œdataTypeœ:œKnowledgeHubSearchœ,œidœ:œKnowledgeHubSearch-1BsTIœ,œnameœ:œquery_resultsœ,œoutput_typesœ:[œDataœ]}-ParserComponent-d7mAH{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-d7mAHœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
        },
        {
          "source": "ParserComponent-d7mAH",
          "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-d7mAHœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-dzqah",
          "targetHandle": "{œfieldNameœ:œcontextœ,œidœ:œPrompt-dzqahœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "context",
              "id": "Prompt-dzqah",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ParserComponent",
              "id": "ParserComponent-d7mAH",
              "name": "parsed_text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "xy-edge__ParserComponent-d7mAH{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-d7mAHœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt-dzqah{œfieldNameœ:œcontextœ,œidœ:œPrompt-dzqahœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
        },
        {
          "source": "Prompt-jMTFG",
          "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-jMTFGœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-dzqah",
          "targetHandle": "{œfieldNameœ:œquestionœ,œidœ:œPrompt-dzqahœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "question",
              "id": "Prompt-dzqah",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-jMTFG",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "xy-edge__Prompt-jMTFG{œdataTypeœ:œPromptœ,œidœ:œPrompt-jMTFGœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-Prompt-dzqah{œfieldNameœ:œquestionœ,œidœ:œPrompt-dzqahœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
        },
        {
          "source": "Prompt-dzqah",
          "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-dzqahœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "target": "AzureOpenAIModel-60mCZ",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œAzureOpenAIModel-60mCZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "AzureOpenAIModel-60mCZ",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-dzqah",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "xy-edge__Prompt-dzqah{œdataTypeœ:œPromptœ,œidœ:œPrompt-dzqahœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-AzureOpenAIModel-60mCZ{œfieldNameœ:œinput_valueœ,œidœ:œAzureOpenAIModel-60mCZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
        },
        {
          "source": "AzureOpenAIModel-60mCZ",
          "sourceHandle": "{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-60mCZœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
          "target": "TextOutput-z3Y5W",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-z3Y5Wœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "TextOutput-z3Y5W",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "AzureOpenAIModel",
              "id": "AzureOpenAIModel-60mCZ",
              "name": "text_output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "xy-edge__AzureOpenAIModel-60mCZ{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-60mCZœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-TextOutput-z3Y5W{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-z3Y5Wœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
        }
      ],
      "viewport": {
        "x": -1438.4002876835002,
        "y": 1262.7752992198566,
        "zoom": 0.5411123222628582
      }
    },
    "description": "The Clinical Summarization Agent extracts and condenses essential information from lengthy clinical documents, such as progress notes or discharge summaries, to provide concise, easy-to-understand overviews for quick clinical review.",
    "name": "Clinical Summarization Agent",
    "last_tested_version": "1.4.3",
    "endpoint_name": null,
    "is_component": false,
    "tags": [
    "classification"
  ]

  }
