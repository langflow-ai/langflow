{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIEmbeddings",
            "id": "OpenAIEmbeddings-fcwMC",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          },
          "targetHandle": {
            "fieldName": "embedding_model",
            "id": "AstraDBGraph-jr8pY",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-OpenAIEmbeddings-jyvkr{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-jyvkrœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-AstraDBGraph-jr8pY{œfieldNameœ:œembedding_modelœ,œidœ:œAstraDBGraph-jr8pYœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "OpenAIEmbeddings-fcwMC",
        "sourceHandle": "{œdataTypeœ: œOpenAIEmbeddingsœ, œidœ: œOpenAIEmbeddings-fcwMCœ, œnameœ: œembeddingsœ, œoutput_typesœ: [œEmbeddingsœ]}",
        "target": "AstraDBGraph-jr8pY",
        "targetHandle": "{œfieldNameœ: œembedding_modelœ, œidœ: œAstraDBGraph-jr8pYœ, œinputTypesœ: [œEmbeddingsœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-DA114",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "search_query",
            "id": "AstraDBGraph-jr8pY",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ChatInput-ZCSfi{œdataTypeœ:œChatInputœ,œidœ:œChatInput-ZCSfiœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-AstraDBGraph-jr8pY{œfieldNameœ:œsearch_queryœ,œidœ:œAstraDBGraph-jr8pYœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ChatInput-DA114",
        "sourceHandle": "{œdataTypeœ: œChatInputœ, œidœ: œChatInput-DA114œ, œnameœ: œmessageœ, œoutput_typesœ: [œMessageœ]}",
        "target": "AstraDBGraph-jr8pY",
        "targetHandle": "{œfieldNameœ: œsearch_queryœ, œidœ: œAstraDBGraph-jr8pYœ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "AstraDBGraph",
            "id": "AstraDBGraph-jr8pY",
            "name": "search_results",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-alciW",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-AstraDBGraph-jr8pY{œdataTypeœ:œAstraDBGraphœ,œidœ:œAstraDBGraph-jr8pYœ,œnameœ:œsearch_resultsœ,œoutput_typesœ:[œDataœ]}-ParseData-T6FGT{œfieldNameœ:œdataœ,œidœ:œParseData-T6FGTœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "AstraDBGraph-jr8pY",
        "sourceHandle": "{œdataTypeœ: œAstraDBGraphœ, œidœ: œAstraDBGraph-jr8pYœ, œnameœ: œsearch_resultsœ, œoutput_typesœ: [œDataœ]}",
        "target": "ParseData-alciW",
        "targetHandle": "{œfieldNameœ: œdataœ, œidœ: œParseData-alciWœ, œinputTypesœ: [œDataœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-alciW",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "context",
            "id": "Prompt-2M2d5",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParseData-alciW{œdataTypeœ:œParseDataœ,œidœ:œParseData-alciWœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-rmO8w{œfieldNameœ:œcontextœ,œidœ:œPrompt-rmO8wœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-alciW",
        "sourceHandle": "{œdataTypeœ: œParseDataœ, œidœ: œParseData-alciWœ, œnameœ: œtextœ, œoutput_typesœ: [œMessageœ]}",
        "target": "Prompt-rmO8w",
        "targetHandle": "{œfieldNameœ: œcontextœ, œidœ: œPrompt-2M2d5œ, œinputTypesœ: [œMessageœ, œTextœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-DA114",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "question",
            "id": "Prompt-2M2d5",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ChatInput-DA114{œdataTypeœ:œChatInputœ,œidœ:œChatInput-DA114œ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Prompt-rmO8w{œfieldNameœ:œquestionœ,œidœ:œPrompt-rmO8wœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ChatInput-DA114",
        "sourceHandle": "{œdataTypeœ: œChatInputœ, œidœ: œChatInput-DA114œ, œnameœ: œmessageœ, œoutput_typesœ: [œMessageœ]}",
        "target": "Prompt-rmO8w",
        "targetHandle": "{œfieldNameœ: œquestionœ, œidœ: œPrompt-2M2d5œ, œinputTypesœ: [œMessageœ, œTextœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-rmO8w",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-a26gL",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt-rmO8w{œdataTypeœ:œPromptœ,œidœ:œPrompt-rmO8wœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-LnWKb{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-LnWKbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-rmO8w",
        "sourceHandle": "{œdataTypeœ: œPromptœ, œidœ: œPrompt-rmO8wœ, œnameœ: œpromptœ, œoutput_typesœ: [œMessageœ]}",
        "target": "OpenAIModel-LnWKb",
        "targetHandle": "{œfieldNameœ: œinput_valueœ, œidœ: œOpenAIModel-a26gLœ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-LnWKb",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-KIkbc",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-OpenAIModel-LnWKb{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-LnWKbœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-KIkbc{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-KIkbcœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "OpenAIModel-LnWKb",
        "sourceHandle": "{œdataTypeœ: œOpenAIModelœ, œidœ: œOpenAIModel-LnWKbœ, œnameœ: œtext_outputœ, œoutput_typesœ: [œMessageœ]}",
        "target": "ChatOutput-KIkbc",
        "targetHandle": "{œfieldNameœ: œinput_valueœ, œidœ: œChatOutput-KIkbcœ, œinputTypesœ: [œDataœ, œDataFrameœ, œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "URL",
            "id": "URL-qOh1r",
            "name": "data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data_input",
            "id": "LanguageRecursiveTextSplitter-jefpx",
            "inputTypes": [
              "Document",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-URL-qOh1r{œdataTypeœ:œURLœ,œidœ:œURL-qOh1rœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-LanguageRecursiveTextSplitter-KDtC3{œfieldNameœ:œdata_inputœ,œidœ:œLanguageRecursiveTextSplitter-KDtC3œ,œinputTypesœ:[œDocumentœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "URL-qOh1r",
        "sourceHandle": "{œdataTypeœ: œURLœ, œidœ: œURL-qOh1rœ, œnameœ: œdataœ, œoutput_typesœ: [œDataœ]}",
        "target": "LanguageRecursiveTextSplitter-KDtC3",
        "targetHandle": "{œfieldNameœ: œdata_inputœ, œidœ: œLanguageRecursiveTextSplitter-jefpxœ, œinputTypesœ: [œDocumentœ, œDataœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LanguageRecursiveTextSplitter",
            "id": "LanguageRecursiveTextSplitter-KDtC3",
            "name": "data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data_input",
            "id": "HtmlLinkExtractor-exHgk",
            "inputTypes": [
              "Document",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-LanguageRecursiveTextSplitter-KDtC3{œdataTypeœ:œLanguageRecursiveTextSplitterœ,œidœ:œLanguageRecursiveTextSplitter-KDtC3œ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-HtmlLinkExtractor-LWuvQ{œfieldNameœ:œdata_inputœ,œidœ:œHtmlLinkExtractor-LWuvQœ,œinputTypesœ:[œDocumentœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "LanguageRecursiveTextSplitter-KDtC3",
        "sourceHandle": "{œdataTypeœ: œLanguageRecursiveTextSplitterœ, œidœ: œLanguageRecursiveTextSplitter-KDtC3œ, œnameœ: œdataœ, œoutput_typesœ: [œDataœ]}",
        "target": "HtmlLinkExtractor-LWuvQ",
        "targetHandle": "{œfieldNameœ: œdata_inputœ, œidœ: œHtmlLinkExtractor-exHgkœ, œinputTypesœ: [œDocumentœ, œDataœ], œtypeœ: œotherœ}"
      },
      {
        "data": {
          "sourceHandle": {
            "dataType": "HtmlLinkExtractor",
            "id": "HtmlLinkExtractor-exHgk",
            "name": "data",
            "output_types": []
          },
          "targetHandle": {
            "fieldName": "ingest_data",
            "id": "AstraDBGraph-FX0tA",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ChatInput-DA114{œdataTypeœ:œChatInputœ,œidœ:œChatInput-DA114œ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-AstraDBGraph-xJiDN{œfieldNameœ:œsearch_queryœ,œidœ:œAstraDBGraph-xJiDNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "ChatInput-DA114",
        "sourceHandle": "{œdataTypeœ: œHtmlLinkExtractorœ, œidœ: œHtmlLinkExtractor-exHgkœ, œnameœ: œdataœ, œoutput_typesœ: []}",
        "target": "AstraDBGraph-xJiDN",
        "targetHandle": "{œfieldNameœ: œingest_dataœ, œidœ: œAstraDBGraph-FX0tAœ, œinputTypesœ: [œDataœ], œtypeœ: œotherœ}"
      },
      {
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIEmbeddings",
            "id": "OpenAIEmbeddings-fcwMC",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          },
          "targetHandle": {
            "fieldName": "embedding_model",
            "id": "AstraDBGraph-FX0tA",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__OpenAIEmbeddings-fcwMC{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-fcwMCœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-AstraDBGraph-xJiDN{œfieldNameœ:œembedding_modelœ,œidœ:œAstraDBGraph-xJiDNœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "source": "OpenAIEmbeddings-fcwMC",
        "sourceHandle": "{œdataTypeœ: œOpenAIEmbeddingsœ, œidœ: œOpenAIEmbeddings-fcwMCœ, œnameœ: œembeddingsœ, œoutput_typesœ: [œEmbeddingsœ]}",
        "target": "AstraDBGraph-xJiDN",
        "targetHandle": "{œfieldNameœ: œembedding_modelœ, œidœ: œAstraDBGraph-FX0tAœ, œinputTypesœ: [œEmbeddingsœ], œtypeœ: œotherœ}"
      },
      {
        "data": {
          "sourceHandle": {
            "dataType": "AstraDBGraph",
            "id": "AstraDBGraph-xJiDN",
            "name": "search_results",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-alciW",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__AstraDBGraph-xJiDN{œdataTypeœ:œAstraDBGraphœ,œidœ:œAstraDBGraph-xJiDNœ,œnameœ:œsearch_resultsœ,œoutput_typesœ:[œDataœ]}-ParseData-alciW{œfieldNameœ:œdataœ,œidœ:œParseData-alciWœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "source": "AstraDBGraph-xJiDN",
        "sourceHandle": "{œdataTypeœ: œAstraDBGraphœ, œidœ: œAstraDBGraph-xJiDNœ, œnameœ: œsearch_resultsœ, œoutput_typesœ: [œDataœ]}",
        "target": "ParseData-alciW",
        "targetHandle": "{œfieldNameœ: œdataœ, œidœ: œParseData-alciWœ, œinputTypesœ: [œDataœ], œtypeœ: œotherœ}"
      },
      {
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIEmbeddings",
            "id": "OpenAIEmbeddings-XKhhV",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          },
          "targetHandle": {
            "fieldName": "embedding_model",
            "id": "AstraDBGraph-uza6S",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__OpenAIEmbeddings-XKhhV{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-XKhhVœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-AstraDBGraph-uza6S{œfieldNameœ:œembedding_modelœ,œidœ:œAstraDBGraph-uza6Sœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "source": "OpenAIEmbeddings-XKhhV",
        "sourceHandle": "{œdataTypeœ: œOpenAIEmbeddingsœ, œidœ: œOpenAIEmbeddings-XKhhVœ, œnameœ: œembeddingsœ, œoutput_typesœ: [œEmbeddingsœ]}",
        "target": "AstraDBGraph-uza6S",
        "targetHandle": "{œfieldNameœ: œembedding_modelœ, œidœ: œAstraDBGraph-uza6Sœ, œinputTypesœ: [œEmbeddingsœ], œtypeœ: œotherœ}"
      },
      {
        "data": {
          "sourceHandle": {
            "dataType": "HtmlLinkExtractor",
            "id": "HtmlLinkExtractor-LWuvQ",
            "name": "data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "ingest_data",
            "id": "AstraDBGraph-uza6S",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__HtmlLinkExtractor-LWuvQ{œdataTypeœ:œHtmlLinkExtractorœ,œidœ:œHtmlLinkExtractor-LWuvQœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-AstraDBGraph-uza6S{œfieldNameœ:œingest_dataœ,œidœ:œAstraDBGraph-uza6Sœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "source": "HtmlLinkExtractor-LWuvQ",
        "sourceHandle": "{œdataTypeœ: œHtmlLinkExtractorœ, œidœ: œHtmlLinkExtractor-LWuvQœ, œnameœ: œdataœ, œoutput_typesœ: [œDataœ]}",
        "target": "AstraDBGraph-uza6S",
        "targetHandle": "{œfieldNameœ: œingest_dataœ, œidœ: œAstraDBGraph-uza6Sœ, œinputTypesœ: [œDataœ], œtypeœ: œotherœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "ChatInput-DA114",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        background_color = self.background_color\n        text_color = self.text_color\n        icon = self.chat_icon\n\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\n                \"background_color\": background_color,\n                \"text_color\": text_color,\n                \"icon\": icon,\n            },\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "_input_type": "FileInput",
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "How does Haskell handle function composition and what are some practical examples of its use?"
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "ChatInput"
        },
        "dragging": false,
        "height": 233,
        "id": "ChatInput-DA114",
        "measured": {
          "height": 233,
          "width": 360
        },
        "position": {
          "x": -1800.3752844686821,
          "y": 7028.578266524353
        },
        "positionAbsolute": {
          "x": -1516.4270244619845,
          "y": 6211.967942125529
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "OpenAIEmbeddings-fcwMC",
          "node": {
            "base_classes": [
              "Embeddings"
            ],
            "beta": false,
            "category": "embeddings",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate embeddings using OpenAI models.",
            "display_name": "OpenAI Embeddings",
            "documentation": "",
            "edited": false,
            "field_order": [
              "default_headers",
              "default_query",
              "chunk_size",
              "client",
              "deployment",
              "embedding_ctx_length",
              "max_retries",
              "model",
              "model_kwargs",
              "openai_api_key",
              "openai_api_base",
              "openai_api_type",
              "openai_api_version",
              "openai_organization",
              "openai_proxy",
              "request_timeout",
              "show_progress_bar",
              "skip_empty",
              "tiktoken_model_name",
              "tiktoken_enable",
              "dimensions"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "key": "OpenAIEmbeddings",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Embeddings",
                "method": "build_embeddings",
                "name": "embeddings",
                "required_inputs": [
                  "openai_api_key"
                ],
                "selected": "Embeddings",
                "tool_mode": true,
                "types": [
                  "Embeddings"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.000052003277518821525,
            "template": {
              "_type": "Component",
              "chunk_size": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Chunk Size",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "chunk_size",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1000
              },
              "client": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Client",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "client",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_openai import OpenAIEmbeddings\n\nfrom langflow.base.embeddings.model import LCEmbeddingsModel\nfrom langflow.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass OpenAIEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIEmbeddings\"\n\n    inputs = [\n        DictInput(\n            name=\"default_headers\",\n            display_name=\"Default Headers\",\n            advanced=True,\n            info=\"Default headers to use for the API request.\",\n        ),\n        DictInput(\n            name=\"default_query\",\n            display_name=\"Default Query\",\n            advanced=True,\n            info=\"Default query parameters to use for the API request.\",\n        ),\n        IntInput(name=\"chunk_size\", display_name=\"Chunk Size\", advanced=True, value=1000),\n        MessageTextInput(name=\"client\", display_name=\"Client\", advanced=True),\n        MessageTextInput(name=\"deployment\", display_name=\"Deployment\", advanced=True),\n        IntInput(name=\"embedding_ctx_length\", display_name=\"Embedding Context Length\", advanced=True, value=1536),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=\"text-embedding-3-small\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\", required=True),\n        MessageTextInput(name=\"openai_api_base\", display_name=\"OpenAI API Base\", advanced=True),\n        MessageTextInput(name=\"openai_api_type\", display_name=\"OpenAI API Type\", advanced=True),\n        MessageTextInput(name=\"openai_api_version\", display_name=\"OpenAI API Version\", advanced=True),\n        MessageTextInput(\n            name=\"openai_organization\",\n            display_name=\"OpenAI Organization\",\n            advanced=True,\n        ),\n        MessageTextInput(name=\"openai_proxy\", display_name=\"OpenAI Proxy\", advanced=True),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n        BoolInput(name=\"show_progress_bar\", display_name=\"Show Progress Bar\", advanced=True),\n        BoolInput(name=\"skip_empty\", display_name=\"Skip Empty\", advanced=True),\n        MessageTextInput(\n            name=\"tiktoken_model_name\",\n            display_name=\"TikToken Model Name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tiktoken_enable\",\n            display_name=\"TikToken Enable\",\n            advanced=True,\n            value=True,\n            info=\"If False, you must have transformers installed.\",\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. \"\n            \"Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return OpenAIEmbeddings(\n            client=self.client or None,\n            model=self.model,\n            dimensions=self.dimensions or None,\n            deployment=self.deployment or None,\n            api_version=self.openai_api_version or None,\n            base_url=self.openai_api_base or None,\n            openai_api_type=self.openai_api_type or None,\n            openai_proxy=self.openai_proxy or None,\n            embedding_ctx_length=self.embedding_ctx_length,\n            api_key=self.openai_api_key or None,\n            organization=self.openai_organization or None,\n            allowed_special=\"all\",\n            disallowed_special=\"all\",\n            chunk_size=self.chunk_size,\n            max_retries=self.max_retries,\n            timeout=self.request_timeout or None,\n            tiktoken_enabled=self.tiktoken_enable,\n            tiktoken_model_name=self.tiktoken_model_name or None,\n            show_progress_bar=self.show_progress_bar,\n            model_kwargs=self.model_kwargs,\n            skip_empty=self.skip_empty,\n            default_headers=self.default_headers or None,\n            default_query=self.default_query or None,\n        )\n"
              },
              "default_headers": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Default Headers",
                "dynamic": false,
                "info": "Default headers to use for the API request.",
                "list": false,
                "name": "default_headers",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "default_query": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Default Query",
                "dynamic": false,
                "info": "Default query parameters to use for the API request.",
                "list": false,
                "name": "default_query",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "deployment": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Deployment",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "deployment",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "dimensions": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Dimensions",
                "dynamic": false,
                "info": "The number of dimensions the resulting output embeddings should have. Only supported by certain models.",
                "list": false,
                "name": "dimensions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "embedding_ctx_length": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Embedding Context Length",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "embedding_ctx_length",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1536
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 3
              },
              "model": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Model",
                "dynamic": false,
                "info": "",
                "name": "model",
                "options": [
                  "text-embedding-3-small",
                  "text-embedding-3-large",
                  "text-embedding-ada-002"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "text-embedding-3-large"
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "openai_api_base": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "load_from_db": true,
                "name": "openai_api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "openai_api_type": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI API Type",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "openai_api_type",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_api_version": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI API Version",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "openai_api_version",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_organization": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI Organization",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "openai_organization",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_proxy": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI Proxy",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "openai_proxy",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "request_timeout": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Request Timeout",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "request_timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": ""
              },
              "show_progress_bar": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Show Progress Bar",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "show_progress_bar",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "skip_empty": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Skip Empty",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "skip_empty",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "tiktoken_enable": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "TikToken Enable",
                "dynamic": false,
                "info": "If False, you must have transformers installed.",
                "list": false,
                "name": "tiktoken_enable",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "tiktoken_model_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "TikToken Model Name",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "tiktoken_model_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "OpenAIEmbeddings"
        },
        "dragging": false,
        "height": 320,
        "id": "OpenAIEmbeddings-fcwMC",
        "measured": {
          "height": 320,
          "width": 360
        },
        "position": {
          "x": -1794.2005649575194,
          "y": 7363.047766731913
        },
        "positionAbsolute": {
          "x": -1530.978455316274,
          "y": 6600.325433283265
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Implementation of Graph Vector Store using Astra DB",
          "display_name": "Astra DB Graph",
          "id": "AstraDBGraph-jr8pY",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Implementation of Graph Vector Store using Astra DB",
            "display_name": "Astra DB Graph",
            "documentation": "",
            "edited": false,
            "field_order": [
              "token",
              "api_endpoint",
              "collection_name",
              "metadata_incoming_links_key",
              "search_query",
              "ingest_data",
              "keyspace",
              "embedding_model",
              "metric",
              "batch_size",
              "bulk_insert_batch_concurrency",
              "bulk_insert_overwrite_concurrency",
              "bulk_delete_concurrency",
              "setup_mode",
              "pre_delete_collection",
              "metadata_indexing_include",
              "metadata_indexing_exclude",
              "collection_indexing_policy",
              "number_of_results",
              "search_type",
              "search_score_threshold",
              "search_filter"
            ],
            "frozen": false,
            "icon": "AstraDB",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Search Results",
                "method": "search_documents",
                "name": "search_results",
                "required_inputs": [
                  "api_endpoint",
                  "collection_name",
                  "token"
                ],
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "method": "as_dataframe",
                "name": "dataframe",
                "required_inputs": [],
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_endpoint": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "API Endpoint",
                "dynamic": false,
                "info": "API endpoint URL for the Astra DB service.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": false,
                "name": "api_endpoint",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "ASTRA_DB_API_ENDPOINT"
              },
              "batch_size": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Batch Size",
                "dynamic": false,
                "info": "Optional number of data to process in a single batch.",
                "list": false,
                "name": "batch_size",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "bulk_delete_concurrency": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Bulk Delete Concurrency",
                "dynamic": false,
                "info": "Optional concurrency level for bulk delete operations.",
                "list": false,
                "name": "bulk_delete_concurrency",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "bulk_insert_batch_concurrency": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Bulk Insert Batch Concurrency",
                "dynamic": false,
                "info": "Optional concurrency level for bulk insert operations.",
                "list": false,
                "name": "bulk_insert_batch_concurrency",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "bulk_insert_overwrite_concurrency": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Bulk Insert Overwrite Concurrency",
                "dynamic": false,
                "info": "Optional concurrency level for bulk insert operations that overwrite existing data.",
                "list": false,
                "name": "bulk_insert_overwrite_concurrency",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import os\n\nimport orjson\nfrom astrapy.admin import parse_api_endpoint\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom langflow.helpers import docs_to_data\nfrom langflow.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    HandleInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom langflow.schema import Data\n\n\nclass AstraDBGraphVectorStoreComponent(LCVectorStoreComponent):\n    display_name: str = \"Astra DB Graph\"\n    description: str = \"Implementation of Graph Vector Store using Astra DB\"\n    name = \"AstraDBGraph\"\n    icon: str = \"AstraDB\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n            required=True,\n            advanced=os.getenv(\"ASTRA_ENHANCED\", \"false\").lower() == \"true\",\n        ),\n        SecretStrInput(\n            name=\"api_endpoint\",\n            display_name=\"Database\" if os.getenv(\"ASTRA_ENHANCED\", \"false\").lower() == \"true\" else \"API Endpoint\",\n            info=\"API endpoint URL for the Astra DB service.\",\n            value=\"ASTRA_DB_API_ENDPOINT\",\n            required=True,\n        ),\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            info=\"The name of the collection within Astra DB where the vectors will be stored.\",\n            required=True,\n        ),\n        StrInput(\n            name=\"metadata_incoming_links_key\",\n            display_name=\"Metadata incoming links key\",\n            info=\"Metadata key used for incoming links.\",\n            advanced=True,\n        ),\n        *LCVectorStoreComponent.inputs,\n        StrInput(\n            name=\"keyspace\",\n            display_name=\"Keyspace\",\n            info=\"Optional keyspace within Astra DB to use for the collection.\",\n            advanced=True,\n        ),\n        HandleInput(\n            name=\"embedding_model\",\n            display_name=\"Embedding Model\",\n            input_types=[\"Embeddings\"],\n            info=\"Allows an embedding model configuration.\",\n        ),\n        DropdownInput(\n            name=\"metric\",\n            display_name=\"Metric\",\n            info=\"Optional distance metric for vector comparisons in the vector store.\",\n            options=[\"cosine\", \"dot_product\", \"euclidean\"],\n            value=\"cosine\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"batch_size\",\n            display_name=\"Batch Size\",\n            info=\"Optional number of data to process in a single batch.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_batch_concurrency\",\n            display_name=\"Bulk Insert Batch Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_overwrite_concurrency\",\n            display_name=\"Bulk Insert Overwrite Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations that overwrite existing data.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_delete_concurrency\",\n            display_name=\"Bulk Delete Concurrency\",\n            info=\"Optional concurrency level for bulk delete operations.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"setup_mode\",\n            display_name=\"Setup Mode\",\n            info=\"Configuration mode for setting up the vector store, with options like 'Sync', or 'Off'.\",\n            options=[\"Sync\", \"Off\"],\n            advanced=True,\n            value=\"Sync\",\n        ),\n        BoolInput(\n            name=\"pre_delete_collection\",\n            display_name=\"Pre Delete Collection\",\n            info=\"Boolean flag to determine whether to delete the collection before creating a new one.\",\n            advanced=True,\n            value=False,\n        ),\n        StrInput(\n            name=\"metadata_indexing_include\",\n            display_name=\"Metadata Indexing Include\",\n            info=\"Optional list of metadata fields to include in the indexing.\",\n            advanced=True,\n            list=True,\n        ),\n        StrInput(\n            name=\"metadata_indexing_exclude\",\n            display_name=\"Metadata Indexing Exclude\",\n            info=\"Optional list of metadata fields to exclude from the indexing.\",\n            advanced=True,\n            list=True,\n        ),\n        StrInput(\n            name=\"collection_indexing_policy\",\n            display_name=\"Collection Indexing Policy\",\n            info='Optional JSON string for the \"indexing\" field of the collection. '\n            \"See https://docs.datastax.com/en/astra-db-serverless/api-reference/collections.html#the-indexing-option\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            info=\"Search type to use\",\n            options=[\n                \"Similarity\",\n                \"Similarity with score threshold\",\n                \"MMR (Max Marginal Relevance)\",\n                \"Graph Traversal\",\n                \"MMR (Max Marginal Relevance) Graph Traversal\",\n            ],\n            value=\"MMR (Max Marginal Relevance) Graph Traversal\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results. \"\n            \"(when using 'Similarity with score threshold')\",\n            value=0,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"search_filter\",\n            display_name=\"Search Metadata Filter\",\n            info=\"Optional dictionary of filters to apply to the search query.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self):\n        try:\n            from langchain_astradb import AstraDBGraphVectorStore\n            from langchain_astradb.utils.astradb import SetupMode\n        except ImportError as e:\n            msg = (\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n            raise ImportError(msg) from e\n\n        try:\n            if not self.setup_mode:\n                self.setup_mode = self._inputs[\"setup_mode\"].options[0]\n\n            setup_mode_value = SetupMode[self.setup_mode.upper()]\n        except KeyError as e:\n            msg = f\"Invalid setup mode: {self.setup_mode}\"\n            raise ValueError(msg) from e\n\n        try:\n            self.log(f\"Initializing Graph Vector Store {self.collection_name}\")\n\n            vector_store = AstraDBGraphVectorStore(\n                embedding=self.embedding_model,\n                collection_name=self.collection_name,\n                metadata_incoming_links_key=self.metadata_incoming_links_key or \"incoming_links\",\n                token=self.token,\n                api_endpoint=self.api_endpoint,\n                namespace=self.keyspace or None,\n                environment=parse_api_endpoint(self.api_endpoint).environment if self.api_endpoint else None,\n                metric=self.metric or None,\n                batch_size=self.batch_size or None,\n                bulk_insert_batch_concurrency=self.bulk_insert_batch_concurrency or None,\n                bulk_insert_overwrite_concurrency=self.bulk_insert_overwrite_concurrency or None,\n                bulk_delete_concurrency=self.bulk_delete_concurrency or None,\n                setup_mode=setup_mode_value,\n                pre_delete_collection=self.pre_delete_collection,\n                metadata_indexing_include=[s for s in self.metadata_indexing_include if s] or None,\n                metadata_indexing_exclude=[s for s in self.metadata_indexing_exclude if s] or None,\n                collection_indexing_policy=orjson.loads(self.collection_indexing_policy.encode(\"utf-8\"))\n                if self.collection_indexing_policy\n                else None,\n            )\n        except Exception as e:\n            msg = f\"Error initializing AstraDBGraphVectorStore: {e}\"\n            raise ValueError(msg) from e\n\n        self.log(f\"Vector Store initialized: {vector_store.astra_env.collection_name}\")\n        self._add_documents_to_vector_store(vector_store)\n\n        return vector_store\n\n    def _add_documents_to_vector_store(self, vector_store) -> None:\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                msg = \"Vector Store Inputs must be Data objects.\"\n                raise TypeError(msg)\n\n        if documents:\n            self.log(f\"Adding {len(documents)} documents to the Vector Store.\")\n            try:\n                vector_store.add_documents(documents)\n            except Exception as e:\n                msg = f\"Error adding documents to AstraDBGraphVectorStore: {e}\"\n                raise ValueError(msg) from e\n        else:\n            self.log(\"No documents to add to the Vector Store.\")\n\n    def _map_search_type(self) -> str:\n        match self.search_type:\n            case \"Similarity\":\n                return \"similarity\"\n            case \"Similarity with score threshold\":\n                return \"similarity_score_threshold\"\n            case \"MMR (Max Marginal Relevance)\":\n                return \"mmr\"\n            case \"Graph Traversal\":\n                return \"traversal\"\n            case \"MMR (Max Marginal Relevance) Graph Traversal\":\n                return \"mmr_traversal\"\n            case _:\n                return \"similarity\"\n\n    def _build_search_args(self):\n        args = {\n            \"k\": self.number_of_results,\n            \"score_threshold\": self.search_score_threshold,\n        }\n\n        if self.search_filter:\n            clean_filter = {k: v for k, v in self.search_filter.items() if k and v}\n            if len(clean_filter) > 0:\n                args[\"filter\"] = clean_filter\n        return args\n\n    def search_documents(self, vector_store=None) -> list[Data]:\n        if not vector_store:\n            vector_store = self.build_vector_store()\n\n        self.log(\"Searching for documents in AstraDBGraphVectorStore.\")\n        self.log(f\"Search query: {self.search_query}\")\n        self.log(f\"Search type: {self.search_type}\")\n        self.log(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            try:\n                search_type = self._map_search_type()\n                search_args = self._build_search_args()\n\n                docs = vector_store.search(query=self.search_query, search_type=search_type, **search_args)\n\n                # Drop links from the metadata. At this point the links don't add any value for building the\n                # context and haven't been restored to json which causes the conversion to fail.\n                self.log(\"Removing links from metadata.\")\n                for doc in docs:\n                    if \"links\" in doc.metadata:\n                        doc.metadata.pop(\"links\")\n\n            except Exception as e:\n                msg = f\"Error performing search in AstraDBGraphVectorStore: {e}\"\n                raise ValueError(msg) from e\n\n            self.log(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n\n            self.log(f\"Converted documents to data: {len(data)}\")\n\n            self.status = data\n            return data\n        self.log(\"No search input provided. Skipping search.\")\n        return []\n\n    def get_retriever_kwargs(self):\n        search_args = self._build_search_args()\n        return {\n            \"search_type\": self._map_search_type(),\n            \"search_kwargs\": search_args,\n        }\n"
              },
              "collection_indexing_policy": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Collection Indexing Policy",
                "dynamic": false,
                "info": "Optional JSON string for the \"indexing\" field of the collection. See https://docs.datastax.com/en/astra-db-serverless/api-reference/collections.html#the-indexing-option",
                "list": false,
                "load_from_db": false,
                "name": "collection_indexing_policy",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "collection_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Collection Name",
                "dynamic": false,
                "info": "The name of the collection within Astra DB where the vectors will be stored.",
                "list": false,
                "load_from_db": false,
                "name": "collection_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "haskell_chunked"
              },
              "embedding_model": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Embedding Model",
                "dynamic": false,
                "info": "Allows an embedding model configuration.",
                "input_types": [
                  "Embeddings"
                ],
                "list": false,
                "name": "embedding_model",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "ingest_data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Ingest Data",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "name": "ingest_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "keyspace": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Keyspace",
                "dynamic": false,
                "info": "Optional keyspace within Astra DB to use for the collection.",
                "list": false,
                "load_from_db": false,
                "name": "keyspace",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "metadata_incoming_links_key": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Metadata incoming links key",
                "dynamic": false,
                "info": "Metadata key used for incoming links.",
                "list": false,
                "load_from_db": false,
                "name": "metadata_incoming_links_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "metadata_indexing_exclude": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Metadata Indexing Exclude",
                "dynamic": false,
                "info": "Optional list of metadata fields to exclude from the indexing.",
                "list": true,
                "load_from_db": false,
                "name": "metadata_indexing_exclude",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": [
                  ""
                ]
              },
              "metadata_indexing_include": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Metadata Indexing Include",
                "dynamic": false,
                "info": "Optional list of metadata fields to include in the indexing.",
                "list": true,
                "load_from_db": false,
                "name": "metadata_indexing_include",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "metric": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Metric",
                "dynamic": false,
                "info": "Optional distance metric for vector comparisons in the vector store.",
                "name": "metric",
                "options": [
                  "cosine",
                  "dot_product",
                  "euclidean"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "cosine"
              },
              "number_of_results": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Results",
                "dynamic": false,
                "info": "Number of results to return.",
                "list": false,
                "load_from_db": false,
                "name": "number_of_results",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "pre_delete_collection": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Pre Delete Collection",
                "dynamic": false,
                "info": "Boolean flag to determine whether to delete the collection before creating a new one.",
                "list": false,
                "name": "pre_delete_collection",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "search_filter": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Search Metadata Filter",
                "dynamic": false,
                "info": "Optional dictionary of filters to apply to the search query.",
                "list": true,
                "name": "search_filter",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "search_query": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "search_query",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "search_score_threshold": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Search Score Threshold",
                "dynamic": false,
                "info": "Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')",
                "list": false,
                "load_from_db": false,
                "name": "search_score_threshold",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": -2
              },
              "search_type": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Search Type",
                "dynamic": false,
                "info": "Search type to use",
                "name": "search_type",
                "options": [
                  "Similarity",
                  "Similarity with score threshold",
                  "MMR (Max Marginal Relevance)",
                  "Graph Traversal",
                  "MMR (Max Marginal Relevance) Graph Traversal"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "MMR (Max Marginal Relevance) Graph Traversal"
              },
              "setup_mode": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Setup Mode",
                "dynamic": false,
                "info": "Configuration mode for setting up the vector store, with options like 'Sync', or 'Off'.",
                "name": "setup_mode",
                "options": [
                  "Sync",
                  "Off"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Sync"
              },
              "should_cache_vector_store": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Cache Vector Store",
                "dynamic": false,
                "info": "If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_cache_vector_store",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "token": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Astra DB Application Token",
                "dynamic": false,
                "info": "Authentication token for accessing Astra DB.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": false,
                "name": "token",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "ASTRA_DB_APPLICATION_TOKEN"
              }
            },
            "tool_mode": false
          },
          "type": "AstraDBGraph"
        },
        "dragging": false,
        "id": "AstraDBGraph-jr8pY",
        "measured": {
          "height": 631,
          "width": 320
        },
        "position": {
          "x": -1277.8700822899038,
          "y": 7080.542929356194
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "description": "Convert Data into plain text following a specified template.",
          "display_name": "Parse Data",
          "id": "ParseData-alciW",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data into plain text following a specified template.",
            "display_name": "Parse Data",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "parse_data",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "name": "data_list",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{data}"
              }
            },
            "tool_mode": false
          },
          "type": "ParseData"
        },
        "dragging": false,
        "id": "ParseData-alciW",
        "measured": {
          "height": 383,
          "width": 360
        },
        "position": {
          "x": -711.6072978271402,
          "y": 7008.616446963303
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt-rmO8w",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "context",
                "question"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "icon": "prompts",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "name": "prompt",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "context": {
                "advanced": false,
                "display_name": "context",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message",
                  "Text"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "context",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "question": {
                "advanced": false,
                "display_name": "question",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message",
                  "Text"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "question",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "{context}\n\n---\n\nGiven the context above, answer the question as best as possible. If there isn't information on the context about the question, respond by saying so in a funny way\n\nQuestion: {question}\n\nAnswer: "
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "Prompt"
        },
        "dragging": false,
        "id": "Prompt-rmO8w",
        "measured": {
          "height": 448,
          "width": 360
        },
        "position": {
          "x": -241.95389238895368,
          "y": 7132.715577428476
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OpenAIModel-LnWKb",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "text_response",
                "name": "text_output",
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "method": "build_model",
                "name": "model_output",
                "required_inputs": [
                  "api_key"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "OPENAI_API_KEY"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[1],\n            combobox=True,\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\", display_name=\"Temperature\", value=0.1, range_spec=RangeSpec(min=0, max=1, step=0.01)\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = self.json_mode\n        seed = self.seed\n        max_retries = self.max_retries\n        timeout = self.timeout\n\n        api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n            max_retries=max_retries,\n            request_timeout=timeout,\n        )\n        if json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.5-preview",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4-turbo"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "type": "slider",
                "value": 0.1
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              }
            },
            "tool_mode": false
          },
          "type": "OpenAIModel"
        },
        "dragging": false,
        "id": "OpenAIModel-LnWKb",
        "measured": {
          "height": 734,
          "width": 360
        },
        "position": {
          "x": 317.8221390146513,
          "y": 7078.366528905622
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-KIkbc",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n\n                # Replace pipe characters to avoid markdown table issues\n                processed_data = data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n\n                processed_data = processed_data.map(\n                    lambda x: str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x\n                )\n\n                return processed_data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-KIkbc",
        "measured": {
          "height": 257,
          "width": 360
        },
        "position": {
          "x": 804.9181649370599,
          "y": 7243.316205548675
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "URL-qOh1r",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "category": "data",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Fetch content from one or more URLs.",
            "display_name": "URL",
            "documentation": "",
            "edited": false,
            "field_order": [
              "urls",
              "format"
            ],
            "frozen": false,
            "icon": "layout-template",
            "key": "URL",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data",
                "method": "fetch_content",
                "name": "data",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "fetch_content_text",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "method": "as_dataframe",
                "name": "dataframe",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 2.220446049250313e-16,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\n\nfrom langchain_community.document_loaders import AsyncHtmlLoader, WebBaseLoader\n\nfrom langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\n\n\nclass URLComponent(Component):\n    display_name = \"URL\"\n    description = \"Load and retrive data from specified URLs.\"\n    icon = \"layout-template\"\n    name = \"URL\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"urls\",\n            display_name=\"URLs\",\n            is_list=True,\n            tool_mode=True,\n            placeholder=\"Enter a URL...\",\n            list_add_label=\"Add URL\",\n        ),\n        DropdownInput(\n            name=\"format\",\n            display_name=\"Output Format\",\n            info=\"Output Format. Use 'Text' to extract the text from the HTML or 'Raw HTML' for the raw HTML content.\",\n            options=[\"Text\", \"Raw HTML\"],\n            value=\"Text\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"fetch_content\"),\n        Output(display_name=\"Message\", name=\"text\", method=\"fetch_content_text\"),\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"as_dataframe\"),\n    ]\n\n    def ensure_url(self, string: str) -> str:\n        \"\"\"Ensures the given string is a URL by adding 'http://' if it doesn't start with 'http://' or 'https://'.\n\n        Raises an error if the string is not a valid URL.\n\n        Parameters:\n            string (str): The string to be checked and possibly modified.\n\n        Returns:\n            str: The modified string that is ensured to be a URL.\n\n        Raises:\n            ValueError: If the string is not a valid URL.\n        \"\"\"\n        if not string.startswith((\"http://\", \"https://\")):\n            string = \"http://\" + string\n\n        # Basic URL validation regex\n        url_regex = re.compile(\n            r\"^(https?:\\/\\/)?\"  # optional protocol\n            r\"(www\\.)?\"  # optional www\n            r\"([a-zA-Z0-9.-]+)\"  # domain\n            r\"(\\.[a-zA-Z]{2,})?\"  # top-level domain\n            r\"(:\\d+)?\"  # optional port\n            r\"(\\/[^\\s]*)?$\",  # optional path\n            re.IGNORECASE,\n        )\n\n        if not url_regex.match(string):\n            msg = f\"Invalid URL: {string}\"\n            raise ValueError(msg)\n\n        return string\n\n    def fetch_content(self) -> list[Data]:\n        urls = [self.ensure_url(url.strip()) for url in self.urls if url.strip()]\n        if self.format == \"Raw HTML\":\n            loader = AsyncHtmlLoader(web_path=urls, encoding=\"utf-8\")\n        else:\n            loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\n        docs = loader.load()\n        data = [Data(text=doc.page_content, **doc.metadata) for doc in docs]\n        self.status = data\n        return data\n\n    def fetch_content_text(self) -> Message:\n        data = self.fetch_content()\n\n        result_string = data_to_text(\"{text}\", data)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def as_dataframe(self) -> DataFrame:\n        return DataFrame(self.fetch_content())\n"
              },
              "format": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Output Format",
                "dynamic": false,
                "info": "Output Format. Use 'Text' to extract the text from the HTML or 'Raw HTML' for the raw HTML content.",
                "name": "format",
                "options": [
                  "Text",
                  "Raw HTML"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Raw HTML"
              },
              "urls": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "URLs",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": true,
                "load_from_db": false,
                "name": "urls",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": [
                  "https://learnyouahaskell.com/introduction",
                  "https://learnyouahaskell.com/starting-out",
                  "https://learnyouahaskell.com/types-and-typeclasses",
                  "https://learnyouahaskell.com/syntax-in-functions",
                  "https://learnyouahaskell.com/recursion",
                  "https://learnyouahaskell.com/higher-order-functions",
                  "https://learnyouahaskell.com/modules",
                  "https://learnyouahaskell.com/making-our-own-types-and-typeclasses",
                  "https://learnyouahaskell.com/input-and-output",
                  "https://learnyouahaskell.com/functionally-solving-problems",
                  "https://learnyouahaskell.com/functors-applicative-functors-and-monoids",
                  "https://learnyouahaskell.com/a-fistful-of-monads",
                  "https://learnyouahaskell.com/for-a-few-monads-more",
                  "https://learnyouahaskell.com/zippers"
                ]
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "URL"
        },
        "dragging": false,
        "id": "URL-qOh1r",
        "measured": {
          "height": 1194,
          "width": 360
        },
        "position": {
          "x": -1742.8952423980936,
          "y": 5868.349789218463
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "LanguageRecursiveTextSplitter-KDtC3",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "category": "vectorstores",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Implementation of Graph Vector Store using Astra DB",
            "display_name": "Astra DB Graph",
            "documentation": "",
            "edited": false,
            "field_order": [
              "token",
              "api_endpoint",
              "collection_name",
              "metadata_incoming_links_key",
              "search_query",
              "ingest_data",
              "keyspace",
              "embedding_model",
              "metric",
              "batch_size",
              "bulk_insert_batch_concurrency",
              "bulk_insert_overwrite_concurrency",
              "bulk_delete_concurrency",
              "setup_mode",
              "pre_delete_collection",
              "metadata_indexing_include",
              "metadata_indexing_exclude",
              "collection_indexing_policy",
              "number_of_results",
              "search_type",
              "search_score_threshold",
              "search_filter"
            ],
            "frozen": false,
            "icon": "AstraDB",
            "key": "AstraDBGraph",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Search Results",
                "method": "search_documents",
                "name": "search_results",
                "required_inputs": [
                  "api_endpoint",
                  "collection_name",
                  "token"
                ],
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "method": "as_dataframe",
                "name": "dataframe",
                "required_inputs": [],
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.13582020910317566,
            "template": {
              "_type": "Component",
              "api_endpoint": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "API Endpoint",
                "dynamic": false,
                "info": "API endpoint URL for the Astra DB service.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": false,
                "name": "api_endpoint",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "ASTRA_DB_API_ENDPOINT"
              },
              "batch_size": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Batch Size",
                "dynamic": false,
                "info": "Optional number of data to process in a single batch.",
                "list": false,
                "name": "batch_size",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "bulk_delete_concurrency": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Bulk Delete Concurrency",
                "dynamic": false,
                "info": "Optional concurrency level for bulk delete operations.",
                "list": false,
                "name": "bulk_delete_concurrency",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "bulk_insert_batch_concurrency": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Bulk Insert Batch Concurrency",
                "dynamic": false,
                "info": "Optional concurrency level for bulk insert operations.",
                "list": false,
                "name": "bulk_insert_batch_concurrency",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "bulk_insert_overwrite_concurrency": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Bulk Insert Overwrite Concurrency",
                "dynamic": false,
                "info": "Optional concurrency level for bulk insert operations that overwrite existing data.",
                "list": false,
                "name": "bulk_insert_overwrite_concurrency",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import os\n\nimport orjson\nfrom astrapy.admin import parse_api_endpoint\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom langflow.helpers import docs_to_data\nfrom langflow.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    HandleInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom langflow.schema import Data\n\n\nclass AstraDBGraphVectorStoreComponent(LCVectorStoreComponent):\n    display_name: str = \"Astra DB Graph\"\n    description: str = \"Implementation of Graph Vector Store using Astra DB\"\n    name = \"AstraDBGraph\"\n    icon: str = \"AstraDB\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n            required=True,\n            advanced=os.getenv(\"ASTRA_ENHANCED\", \"false\").lower() == \"true\",\n        ),\n        SecretStrInput(\n            name=\"api_endpoint\",\n            display_name=\"Database\" if os.getenv(\"ASTRA_ENHANCED\", \"false\").lower() == \"true\" else \"API Endpoint\",\n            info=\"API endpoint URL for the Astra DB service.\",\n            value=\"ASTRA_DB_API_ENDPOINT\",\n            required=True,\n        ),\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            info=\"The name of the collection within Astra DB where the vectors will be stored.\",\n            required=True,\n        ),\n        StrInput(\n            name=\"metadata_incoming_links_key\",\n            display_name=\"Metadata incoming links key\",\n            info=\"Metadata key used for incoming links.\",\n            advanced=True,\n        ),\n        *LCVectorStoreComponent.inputs,\n        StrInput(\n            name=\"keyspace\",\n            display_name=\"Keyspace\",\n            info=\"Optional keyspace within Astra DB to use for the collection.\",\n            advanced=True,\n        ),\n        HandleInput(\n            name=\"embedding_model\",\n            display_name=\"Embedding Model\",\n            input_types=[\"Embeddings\"],\n            info=\"Allows an embedding model configuration.\",\n        ),\n        DropdownInput(\n            name=\"metric\",\n            display_name=\"Metric\",\n            info=\"Optional distance metric for vector comparisons in the vector store.\",\n            options=[\"cosine\", \"dot_product\", \"euclidean\"],\n            value=\"cosine\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"batch_size\",\n            display_name=\"Batch Size\",\n            info=\"Optional number of data to process in a single batch.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_batch_concurrency\",\n            display_name=\"Bulk Insert Batch Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_overwrite_concurrency\",\n            display_name=\"Bulk Insert Overwrite Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations that overwrite existing data.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_delete_concurrency\",\n            display_name=\"Bulk Delete Concurrency\",\n            info=\"Optional concurrency level for bulk delete operations.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"setup_mode\",\n            display_name=\"Setup Mode\",\n            info=\"Configuration mode for setting up the vector store, with options like 'Sync', or 'Off'.\",\n            options=[\"Sync\", \"Off\"],\n            advanced=True,\n            value=\"Sync\",\n        ),\n        BoolInput(\n            name=\"pre_delete_collection\",\n            display_name=\"Pre Delete Collection\",\n            info=\"Boolean flag to determine whether to delete the collection before creating a new one.\",\n            advanced=True,\n            value=False,\n        ),\n        StrInput(\n            name=\"metadata_indexing_include\",\n            display_name=\"Metadata Indexing Include\",\n            info=\"Optional list of metadata fields to include in the indexing.\",\n            advanced=True,\n            list=True,\n        ),\n        StrInput(\n            name=\"metadata_indexing_exclude\",\n            display_name=\"Metadata Indexing Exclude\",\n            info=\"Optional list of metadata fields to exclude from the indexing.\",\n            advanced=True,\n            list=True,\n        ),\n        StrInput(\n            name=\"collection_indexing_policy\",\n            display_name=\"Collection Indexing Policy\",\n            info='Optional JSON string for the \"indexing\" field of the collection. '\n            \"See https://docs.datastax.com/en/astra-db-serverless/api-reference/collections.html#the-indexing-option\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            info=\"Search type to use\",\n            options=[\n                \"Similarity\",\n                \"Similarity with score threshold\",\n                \"MMR (Max Marginal Relevance)\",\n                \"Graph Traversal\",\n                \"MMR (Max Marginal Relevance) Graph Traversal\",\n            ],\n            value=\"MMR (Max Marginal Relevance) Graph Traversal\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results. \"\n            \"(when using 'Similarity with score threshold')\",\n            value=0,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"search_filter\",\n            display_name=\"Search Metadata Filter\",\n            info=\"Optional dictionary of filters to apply to the search query.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self):\n        try:\n            from langchain_astradb import AstraDBGraphVectorStore\n            from langchain_astradb.utils.astradb import SetupMode\n        except ImportError as e:\n            msg = (\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n            raise ImportError(msg) from e\n\n        try:\n            if not self.setup_mode:\n                self.setup_mode = self._inputs[\"setup_mode\"].options[0]\n\n            setup_mode_value = SetupMode[self.setup_mode.upper()]\n        except KeyError as e:\n            msg = f\"Invalid setup mode: {self.setup_mode}\"\n            raise ValueError(msg) from e\n\n        try:\n            self.log(f\"Initializing Graph Vector Store {self.collection_name}\")\n\n            vector_store = AstraDBGraphVectorStore(\n                embedding=self.embedding_model,\n                collection_name=self.collection_name,\n                metadata_incoming_links_key=self.metadata_incoming_links_key or \"incoming_links\",\n                token=self.token,\n                api_endpoint=self.api_endpoint,\n                namespace=self.keyspace or None,\n                environment=parse_api_endpoint(self.api_endpoint).environment if self.api_endpoint else None,\n                metric=self.metric or None,\n                batch_size=self.batch_size or None,\n                bulk_insert_batch_concurrency=self.bulk_insert_batch_concurrency or None,\n                bulk_insert_overwrite_concurrency=self.bulk_insert_overwrite_concurrency or None,\n                bulk_delete_concurrency=self.bulk_delete_concurrency or None,\n                setup_mode=setup_mode_value,\n                pre_delete_collection=self.pre_delete_collection,\n                metadata_indexing_include=[s for s in self.metadata_indexing_include if s] or None,\n                metadata_indexing_exclude=[s for s in self.metadata_indexing_exclude if s] or None,\n                collection_indexing_policy=orjson.loads(self.collection_indexing_policy.encode(\"utf-8\"))\n                if self.collection_indexing_policy\n                else None,\n            )\n        except Exception as e:\n            msg = f\"Error initializing AstraDBGraphVectorStore: {e}\"\n            raise ValueError(msg) from e\n\n        self.log(f\"Vector Store initialized: {vector_store.astra_env.collection_name}\")\n        self._add_documents_to_vector_store(vector_store)\n\n        return vector_store\n\n    def _add_documents_to_vector_store(self, vector_store) -> None:\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                msg = \"Vector Store Inputs must be Data objects.\"\n                raise TypeError(msg)\n\n        if documents:\n            self.log(f\"Adding {len(documents)} documents to the Vector Store.\")\n            try:\n                vector_store.add_documents(documents)\n            except Exception as e:\n                msg = f\"Error adding documents to AstraDBGraphVectorStore: {e}\"\n                raise ValueError(msg) from e\n        else:\n            self.log(\"No documents to add to the Vector Store.\")\n\n    def _map_search_type(self) -> str:\n        match self.search_type:\n            case \"Similarity\":\n                return \"similarity\"\n            case \"Similarity with score threshold\":\n                return \"similarity_score_threshold\"\n            case \"MMR (Max Marginal Relevance)\":\n                return \"mmr\"\n            case \"Graph Traversal\":\n                return \"traversal\"\n            case \"MMR (Max Marginal Relevance) Graph Traversal\":\n                return \"mmr_traversal\"\n            case _:\n                return \"similarity\"\n\n    def _build_search_args(self):\n        args = {\n            \"k\": self.number_of_results,\n            \"score_threshold\": self.search_score_threshold,\n        }\n\n        if self.search_filter:\n            clean_filter = {k: v for k, v in self.search_filter.items() if k and v}\n            if len(clean_filter) > 0:\n                args[\"filter\"] = clean_filter\n        return args\n\n    def search_documents(self, vector_store=None) -> list[Data]:\n        if not vector_store:\n            vector_store = self.build_vector_store()\n\n        self.log(\"Searching for documents in AstraDBGraphVectorStore.\")\n        self.log(f\"Search query: {self.search_query}\")\n        self.log(f\"Search type: {self.search_type}\")\n        self.log(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            try:\n                search_type = self._map_search_type()\n                search_args = self._build_search_args()\n\n                docs = vector_store.search(query=self.search_query, search_type=search_type, **search_args)\n\n                # Drop links from the metadata. At this point the links don't add any value for building the\n                # context and haven't been restored to json which causes the conversion to fail.\n                self.log(\"Removing links from metadata.\")\n                for doc in docs:\n                    if \"links\" in doc.metadata:\n                        doc.metadata.pop(\"links\")\n\n            except Exception as e:\n                msg = f\"Error performing search in AstraDBGraphVectorStore: {e}\"\n                raise ValueError(msg) from e\n\n            self.log(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n\n            self.log(f\"Converted documents to data: {len(data)}\")\n\n            self.status = data\n            return data\n        self.log(\"No search input provided. Skipping search.\")\n        return []\n\n    def get_retriever_kwargs(self):\n        search_args = self._build_search_args()\n        return {\n            \"search_type\": self._map_search_type(),\n            \"search_kwargs\": search_args,\n        }\n"
              },
              "collection_indexing_policy": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Collection Indexing Policy",
                "dynamic": false,
                "info": "Optional JSON string for the \"indexing\" field of the collection. See https://docs.datastax.com/en/astra-db-serverless/api-reference/collections.html#the-indexing-option",
                "list": false,
                "load_from_db": false,
                "name": "collection_indexing_policy",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "collection_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Collection Name",
                "dynamic": false,
                "info": "The name of the collection within Astra DB where the vectors will be stored.",
                "list": false,
                "load_from_db": false,
                "name": "collection_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "haskell_chunked"
              },
              "embedding_model": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Embedding Model",
                "dynamic": false,
                "info": "Allows an embedding model configuration.",
                "input_types": [
                  "Embeddings"
                ],
                "list": false,
                "name": "embedding_model",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "ingest_data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Ingest Data",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "name": "ingest_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "keyspace": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Keyspace",
                "dynamic": false,
                "info": "Optional keyspace within Astra DB to use for the collection.",
                "list": false,
                "load_from_db": false,
                "name": "keyspace",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "metadata_incoming_links_key": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Metadata incoming links key",
                "dynamic": false,
                "info": "Metadata key used for incoming links.",
                "list": false,
                "load_from_db": false,
                "name": "metadata_incoming_links_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "metadata_indexing_exclude": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Metadata Indexing Exclude",
                "dynamic": false,
                "info": "Optional list of metadata fields to exclude from the indexing.",
                "list": true,
                "load_from_db": false,
                "name": "metadata_indexing_exclude",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "metadata_indexing_include": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Metadata Indexing Include",
                "dynamic": false,
                "info": "Optional list of metadata fields to include in the indexing.",
                "list": true,
                "load_from_db": false,
                "name": "metadata_indexing_include",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "metric": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Metric",
                "dynamic": false,
                "info": "Optional distance metric for vector comparisons in the vector store.",
                "name": "metric",
                "options": [
                  "cosine",
                  "dot_product",
                  "euclidean"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "cosine"
              },
              "number_of_results": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Results",
                "dynamic": false,
                "info": "Number of results to return.",
                "list": false,
                "name": "number_of_results",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 4
              },
              "pre_delete_collection": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Pre Delete Collection",
                "dynamic": false,
                "info": "Boolean flag to determine whether to delete the collection before creating a new one.",
                "list": false,
                "name": "pre_delete_collection",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "search_filter": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Search Metadata Filter",
                "dynamic": false,
                "info": "Optional dictionary of filters to apply to the search query.",
                "list": true,
                "name": "search_filter",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "search_query": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "search_query",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "search_score_threshold": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Search Score Threshold",
                "dynamic": false,
                "info": "Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')",
                "list": false,
                "name": "search_score_threshold",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": 0
              },
              "search_type": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Search Type",
                "dynamic": false,
                "info": "Search type to use",
                "name": "search_type",
                "options": [
                  "Similarity",
                  "Similarity with score threshold",
                  "MMR (Max Marginal Relevance)",
                  "Graph Traversal",
                  "MMR (Max Marginal Relevance) Graph Traversal"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "MMR (Max Marginal Relevance) Graph Traversal"
              },
              "setup_mode": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Setup Mode",
                "dynamic": false,
                "info": "Configuration mode for setting up the vector store, with options like 'Sync', or 'Off'.",
                "name": "setup_mode",
                "options": [
                  "Sync",
                  "Off"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Sync"
              },
              "should_cache_vector_store": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Cache Vector Store",
                "dynamic": false,
                "info": "If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_cache_vector_store",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "token": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Astra DB Application Token",
                "dynamic": false,
                "info": "Authentication token for accessing Astra DB.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": false,
                "name": "token",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "ASTRA_DB_APPLICATION_TOKEN"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "AstraDBGraph"
        },
        "dragging": false,
        "id": "AstraDBGraph-FX0tA",
        "measured": {
          "height": 631,
          "width": 320
        },
        "position": {
          "x": 16.3856689286402,
          "y": 5909.200823867262
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "LanguageRecursiveTextSplitter-jefpx",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "category": "langchain_utilities",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Split text into chunks of a specified length based on language.",
            "display_name": "Language Recursive Text Splitter",
            "documentation": "https://docs.langflow.org/components/text-splitters#languagerecursivetextsplitter",
            "edited": false,
            "field_order": [
              "chunk_size",
              "chunk_overlap",
              "data_input",
              "code_language"
            ],
            "frozen": false,
            "icon": "LangChain",
            "key": "LanguageRecursiveTextSplitter",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data",
                "method": "transform_data",
                "name": "data",
                "required_inputs": [],
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.12416523075924112,
            "template": {
              "_type": "Component",
              "chunk_overlap": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Chunk Overlap",
                "dynamic": false,
                "info": "The amount of overlap between chunks.",
                "list": false,
                "name": "chunk_overlap",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 200
              },
              "chunk_size": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Chunk Size",
                "dynamic": false,
                "info": "The maximum length of each chunk.",
                "list": false,
                "name": "chunk_size",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1000
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_text_splitters import Language, RecursiveCharacterTextSplitter, TextSplitter\n\nfrom langflow.base.textsplitters.model import LCTextSplitterComponent\nfrom langflow.inputs import DataInput, DropdownInput, IntInput\n\n\nclass LanguageRecursiveTextSplitterComponent(LCTextSplitterComponent):\n    display_name: str = \"Language Recursive Text Splitter\"\n    description: str = \"Split text into chunks of a specified length based on language.\"\n    documentation: str = \"https://docs.langflow.org/components/text-splitters#languagerecursivetextsplitter\"\n    name = \"LanguageRecursiveTextSplitter\"\n    icon = \"LangChain\"\n\n    inputs = [\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum length of each chunk.\",\n            value=1000,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"The amount of overlap between chunks.\",\n            value=200,\n        ),\n        DataInput(\n            name=\"data_input\",\n            display_name=\"Input\",\n            info=\"The texts to split.\",\n            input_types=[\"Document\", \"Data\"],\n            required=True,\n        ),\n        DropdownInput(\n            name=\"code_language\", display_name=\"Code Language\", options=[x.value for x in Language], value=\"python\"\n        ),\n    ]\n\n    def get_data_input(self) -> Any:\n        return self.data_input\n\n    def build_text_splitter(self) -> TextSplitter:\n        return RecursiveCharacterTextSplitter.from_language(\n            language=Language(self.code_language),\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n        )\n"
              },
              "code_language": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Code Language",
                "dynamic": false,
                "info": "",
                "name": "code_language",
                "options": [
                  "cpp",
                  "go",
                  "java",
                  "kotlin",
                  "js",
                  "ts",
                  "php",
                  "proto",
                  "python",
                  "rst",
                  "ruby",
                  "rust",
                  "scala",
                  "swift",
                  "markdown",
                  "latex",
                  "html",
                  "sol",
                  "csharp",
                  "cobol",
                  "c",
                  "lua",
                  "perl",
                  "haskell",
                  "elixir",
                  "powershell"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "html"
              },
              "data_input": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The texts to split.",
                "input_types": [
                  "Document",
                  "Data"
                ],
                "list": false,
                "name": "data_input",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "LanguageRecursiveTextSplitter"
        },
        "dragging": false,
        "id": "LanguageRecursiveTextSplitter-KDtC3",
        "measured": {
          "height": 513,
          "width": 360
        },
        "position": {
          "x": -1312.6794416503267,
          "y": 5995.335519138236
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "HtmlLinkExtractor-LWuvQ",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "category": "langchain_utilities",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extract hyperlinks from HTML content.",
            "display_name": "HTML Link Extractor",
            "documentation": "https://python.langchain.com/v0.2/api_reference/community/graph_vectorstores/langchain_community.graph_vectorstores.extractors.html_link_extractor.HtmlLinkExtractor.html",
            "edited": false,
            "field_order": [
              "kind",
              "drop_fragments",
              "data_input"
            ],
            "frozen": false,
            "icon": "LangChain",
            "key": "HtmlLinkExtractor",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data",
                "method": "transform_data",
                "name": "data",
                "required_inputs": [],
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.01857804455091699,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_community.graph_vectorstores.extractors import HtmlLinkExtractor, LinkExtractorTransformer\nfrom langchain_core.documents import BaseDocumentTransformer\n\nfrom langflow.base.document_transformers.model import LCDocumentTransformerComponent\nfrom langflow.inputs import BoolInput, DataInput, StrInput\n\n\nclass HtmlLinkExtractorComponent(LCDocumentTransformerComponent):\n    display_name = \"HTML Link Extractor\"\n    description = \"Extract hyperlinks from HTML content.\"\n    documentation = \"https://python.langchain.com/v0.2/api_reference/community/graph_vectorstores/langchain_community.graph_vectorstores.extractors.html_link_extractor.HtmlLinkExtractor.html\"\n    name = \"HtmlLinkExtractor\"\n    icon = \"LangChain\"\n\n    inputs = [\n        StrInput(name=\"kind\", display_name=\"Kind of edge\", value=\"hyperlink\", required=False),\n        BoolInput(name=\"drop_fragments\", display_name=\"Drop URL fragments\", value=True, required=False),\n        DataInput(\n            name=\"data_input\",\n            display_name=\"Input\",\n            info=\"The texts from which to extract links.\",\n            input_types=[\"Document\", \"Data\"],\n            required=True,\n        ),\n    ]\n\n    def get_data_input(self) -> Any:\n        return self.data_input\n\n    def build_document_transformer(self) -> BaseDocumentTransformer:\n        return LinkExtractorTransformer(\n            [HtmlLinkExtractor(kind=self.kind, drop_fragments=self.drop_fragments).as_document_extractor()]\n        )\n"
              },
              "data_input": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The texts from which to extract links.",
                "input_types": [
                  "Document",
                  "Data"
                ],
                "list": false,
                "name": "data_input",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "drop_fragments": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Drop URL fragments",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "drop_fragments",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "kind": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Kind of edge",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "kind",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "hyperlink"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "HtmlLinkExtractor"
        },
        "dragging": false,
        "id": "HtmlLinkExtractor-LWuvQ",
        "measured": {
          "height": 354,
          "width": 360
        },
        "position": {
          "x": -819.2825457919793,
          "y": 6116.365935466731
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OpenAIEmbeddings-XKhhV",
          "node": {
            "base_classes": [
              "Embeddings"
            ],
            "beta": false,
            "category": "embeddings",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate embeddings using OpenAI models.",
            "display_name": "OpenAI Embeddings",
            "documentation": "",
            "edited": false,
            "field_order": [
              "default_headers",
              "default_query",
              "chunk_size",
              "client",
              "deployment",
              "embedding_ctx_length",
              "max_retries",
              "model",
              "model_kwargs",
              "openai_api_key",
              "openai_api_base",
              "openai_api_type",
              "openai_api_version",
              "openai_organization",
              "openai_proxy",
              "request_timeout",
              "show_progress_bar",
              "skip_empty",
              "tiktoken_model_name",
              "tiktoken_enable",
              "dimensions"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "key": "OpenAIEmbeddings",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Embeddings",
                "method": "build_embeddings",
                "name": "embeddings",
                "required_inputs": [
                  "openai_api_key"
                ],
                "selected": "Embeddings",
                "tool_mode": true,
                "types": [
                  "Embeddings"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.000052003277518821525,
            "template": {
              "_type": "Component",
              "chunk_size": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Chunk Size",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "chunk_size",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1000
              },
              "client": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Client",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "client",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_openai import OpenAIEmbeddings\n\nfrom langflow.base.embeddings.model import LCEmbeddingsModel\nfrom langflow.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass OpenAIEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIEmbeddings\"\n\n    inputs = [\n        DictInput(\n            name=\"default_headers\",\n            display_name=\"Default Headers\",\n            advanced=True,\n            info=\"Default headers to use for the API request.\",\n        ),\n        DictInput(\n            name=\"default_query\",\n            display_name=\"Default Query\",\n            advanced=True,\n            info=\"Default query parameters to use for the API request.\",\n        ),\n        IntInput(name=\"chunk_size\", display_name=\"Chunk Size\", advanced=True, value=1000),\n        MessageTextInput(name=\"client\", display_name=\"Client\", advanced=True),\n        MessageTextInput(name=\"deployment\", display_name=\"Deployment\", advanced=True),\n        IntInput(name=\"embedding_ctx_length\", display_name=\"Embedding Context Length\", advanced=True, value=1536),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=\"text-embedding-3-small\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\", required=True),\n        MessageTextInput(name=\"openai_api_base\", display_name=\"OpenAI API Base\", advanced=True),\n        MessageTextInput(name=\"openai_api_type\", display_name=\"OpenAI API Type\", advanced=True),\n        MessageTextInput(name=\"openai_api_version\", display_name=\"OpenAI API Version\", advanced=True),\n        MessageTextInput(\n            name=\"openai_organization\",\n            display_name=\"OpenAI Organization\",\n            advanced=True,\n        ),\n        MessageTextInput(name=\"openai_proxy\", display_name=\"OpenAI Proxy\", advanced=True),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n        BoolInput(name=\"show_progress_bar\", display_name=\"Show Progress Bar\", advanced=True),\n        BoolInput(name=\"skip_empty\", display_name=\"Skip Empty\", advanced=True),\n        MessageTextInput(\n            name=\"tiktoken_model_name\",\n            display_name=\"TikToken Model Name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tiktoken_enable\",\n            display_name=\"TikToken Enable\",\n            advanced=True,\n            value=True,\n            info=\"If False, you must have transformers installed.\",\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. \"\n            \"Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return OpenAIEmbeddings(\n            client=self.client or None,\n            model=self.model,\n            dimensions=self.dimensions or None,\n            deployment=self.deployment or None,\n            api_version=self.openai_api_version or None,\n            base_url=self.openai_api_base or None,\n            openai_api_type=self.openai_api_type or None,\n            openai_proxy=self.openai_proxy or None,\n            embedding_ctx_length=self.embedding_ctx_length,\n            api_key=self.openai_api_key or None,\n            organization=self.openai_organization or None,\n            allowed_special=\"all\",\n            disallowed_special=\"all\",\n            chunk_size=self.chunk_size,\n            max_retries=self.max_retries,\n            timeout=self.request_timeout or None,\n            tiktoken_enabled=self.tiktoken_enable,\n            tiktoken_model_name=self.tiktoken_model_name or None,\n            show_progress_bar=self.show_progress_bar,\n            model_kwargs=self.model_kwargs,\n            skip_empty=self.skip_empty,\n            default_headers=self.default_headers or None,\n            default_query=self.default_query or None,\n        )\n"
              },
              "default_headers": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Default Headers",
                "dynamic": false,
                "info": "Default headers to use for the API request.",
                "list": false,
                "name": "default_headers",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "default_query": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Default Query",
                "dynamic": false,
                "info": "Default query parameters to use for the API request.",
                "list": false,
                "name": "default_query",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "deployment": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Deployment",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "deployment",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "dimensions": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Dimensions",
                "dynamic": false,
                "info": "The number of dimensions the resulting output embeddings should have. Only supported by certain models.",
                "list": false,
                "name": "dimensions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "embedding_ctx_length": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Embedding Context Length",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "embedding_ctx_length",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1536
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 3
              },
              "model": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Model",
                "dynamic": false,
                "info": "",
                "name": "model",
                "options": [
                  "text-embedding-3-small",
                  "text-embedding-3-large",
                  "text-embedding-ada-002"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "text-embedding-3-large"
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "openai_api_base": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "load_from_db": true,
                "name": "openai_api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "openai_api_type": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI API Type",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "openai_api_type",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_api_version": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI API Version",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "openai_api_version",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_organization": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI Organization",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "openai_organization",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_proxy": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI Proxy",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "openai_proxy",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "request_timeout": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Request Timeout",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "request_timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": ""
              },
              "show_progress_bar": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Show Progress Bar",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "show_progress_bar",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "skip_empty": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Skip Empty",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "skip_empty",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "tiktoken_enable": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "TikToken Enable",
                "dynamic": false,
                "info": "If False, you must have transformers installed.",
                "list": false,
                "name": "tiktoken_enable",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "tiktoken_model_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "TikToken Model Name",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "tiktoken_model_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "OpenAIEmbeddings"
        },
        "dragging": false,
        "id": "OpenAIEmbeddings-XKhhV",
        "measured": {
          "height": 349,
          "width": 360
        },
        "position": {
          "x": -826.5880014143661,
          "y": 6515.86676043142
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "note-Nosro",
          "node": {
            "description": "## 📖 README\n\nLoad your data into a vector database with the 📚 **Load Data** flow, and then use your data as chat context with the 🐕 **Retriever** flow.\n\n**🚨 Add your OpenAI API key as a global variable to easily add it to all of the OpenAI components in this flow.** \n\n**Quick start**\n1. Run the 📚 **Load Data** flow.\n2. Run the 🐕 **Retriever** flow.\n\n**Next steps** \n\n- Experiment by changing the prompt and the loaded data to see how the bot's responses change. ",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note"
        },
        "dragging": false,
        "height": 695,
        "id": "note-Nosro",
        "measured": {
          "height": 695,
          "width": 328
        },
        "position": {
          "x": -2651.9749287591367,
          "y": 6278.741596879104
        },
        "resizing": false,
        "selected": false,
        "type": "noteNode",
        "width": 324
      },
      {
        "data": {
          "id": "note-Cps5A",
          "node": {
            "description": "## 📚 1. Load Data Flow\n\nRun this first! Load data multiple urls, and embed it into the vector database in a graph based format.\n\nClick ▶️ **Run component** on the **Astra DB Graph** component to load your data.\n\n* If you're using OSS Langflow, add your Astra DB Application Token to the Astra DB component.\n\n#### Next steps:\n Experiment by changing the prompt and the contextual data to see how the retrieval flow's responses change.",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note"
        },
        "dragging": false,
        "height": 499,
        "id": "note-Cps5A",
        "measured": {
          "height": 499,
          "width": 329
        },
        "position": {
          "x": -2156.877891666127,
          "y": 5887.194729165318
        },
        "resizing": false,
        "selected": false,
        "type": "noteNode",
        "width": 325
      },
      {
        "data": {
          "id": "note-VWvJC",
          "node": {
            "description": "## 🐕 2. Retriever Flow\n\nThis flow answers your questions with contextual data retrieved from your vector database. using graph RAG.\n\nOpen the **Playground** and ask, \n\n```\nhow to create a function in Haskell ?\n```\n",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note"
        },
        "dragging": false,
        "id": "note-VWvJC",
        "measured": {
          "height": 324,
          "width": 328
        },
        "position": {
          "x": -2255.4854518934735,
          "y": 7190.4854518934735
        },
        "selected": false,
        "type": "noteNode"
      },
      {
        "data": {
          "id": "AstraDBGraph-xJiDN",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "category": "vectorstores",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Implementation of Graph Vector Store using Astra DB",
            "display_name": "Astra DB Graph",
            "documentation": "",
            "edited": false,
            "field_order": [
              "token",
              "api_endpoint",
              "collection_name",
              "metadata_incoming_links_key",
              "ingest_data",
              "search_query",
              "should_cache_vector_store",
              "keyspace",
              "embedding_model",
              "metric",
              "batch_size",
              "bulk_insert_batch_concurrency",
              "bulk_insert_overwrite_concurrency",
              "bulk_delete_concurrency",
              "setup_mode",
              "pre_delete_collection",
              "metadata_indexing_include",
              "metadata_indexing_exclude",
              "collection_indexing_policy",
              "number_of_results",
              "search_type",
              "search_score_threshold",
              "search_filter"
            ],
            "frozen": false,
            "icon": "AstraDB",
            "key": "AstraDBGraph",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Search Results",
                "method": "search_documents",
                "name": "search_results",
                "required_inputs": [
                  "api_endpoint",
                  "collection_name",
                  "token"
                ],
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "method": "as_dataframe",
                "name": "dataframe",
                "required_inputs": [],
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.01857804455091699,
            "template": {
              "_type": "Component",
              "api_endpoint": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "API Endpoint",
                "dynamic": false,
                "info": "API endpoint URL for the Astra DB service.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": true,
                "name": "api_endpoint",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "batch_size": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Batch Size",
                "dynamic": false,
                "info": "Optional number of data to process in a single batch.",
                "list": false,
                "list_add_label": "Add More",
                "name": "batch_size",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "bulk_delete_concurrency": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Bulk Delete Concurrency",
                "dynamic": false,
                "info": "Optional concurrency level for bulk delete operations.",
                "list": false,
                "list_add_label": "Add More",
                "name": "bulk_delete_concurrency",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "bulk_insert_batch_concurrency": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Bulk Insert Batch Concurrency",
                "dynamic": false,
                "info": "Optional concurrency level for bulk insert operations.",
                "list": false,
                "list_add_label": "Add More",
                "name": "bulk_insert_batch_concurrency",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "bulk_insert_overwrite_concurrency": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Bulk Insert Overwrite Concurrency",
                "dynamic": false,
                "info": "Optional concurrency level for bulk insert operations that overwrite existing data.",
                "list": false,
                "list_add_label": "Add More",
                "name": "bulk_insert_overwrite_concurrency",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import os\n\nimport orjson\nfrom astrapy.admin import parse_api_endpoint\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom langflow.helpers import docs_to_data\nfrom langflow.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    HandleInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom langflow.schema import Data\n\n\nclass AstraDBGraphVectorStoreComponent(LCVectorStoreComponent):\n    display_name: str = \"Astra DB Graph\"\n    description: str = \"Implementation of Graph Vector Store using Astra DB\"\n    name = \"AstraDBGraph\"\n    icon: str = \"AstraDB\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n            required=True,\n            advanced=os.getenv(\"ASTRA_ENHANCED\", \"false\").lower() == \"true\",\n        ),\n        SecretStrInput(\n            name=\"api_endpoint\",\n            display_name=\"Database\" if os.getenv(\"ASTRA_ENHANCED\", \"false\").lower() == \"true\" else \"API Endpoint\",\n            info=\"API endpoint URL for the Astra DB service.\",\n            value=\"ASTRA_DB_API_ENDPOINT\",\n            required=True,\n        ),\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            info=\"The name of the collection within Astra DB where the vectors will be stored.\",\n            required=True,\n        ),\n        StrInput(\n            name=\"metadata_incoming_links_key\",\n            display_name=\"Metadata incoming links key\",\n            info=\"Metadata key used for incoming links.\",\n            advanced=True,\n        ),\n        *LCVectorStoreComponent.inputs,\n        StrInput(\n            name=\"keyspace\",\n            display_name=\"Keyspace\",\n            info=\"Optional keyspace within Astra DB to use for the collection.\",\n            advanced=True,\n        ),\n        HandleInput(\n            name=\"embedding_model\",\n            display_name=\"Embedding Model\",\n            input_types=[\"Embeddings\"],\n            info=\"Allows an embedding model configuration.\",\n        ),\n        DropdownInput(\n            name=\"metric\",\n            display_name=\"Metric\",\n            info=\"Optional distance metric for vector comparisons in the vector store.\",\n            options=[\"cosine\", \"dot_product\", \"euclidean\"],\n            value=\"cosine\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"batch_size\",\n            display_name=\"Batch Size\",\n            info=\"Optional number of data to process in a single batch.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_batch_concurrency\",\n            display_name=\"Bulk Insert Batch Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_overwrite_concurrency\",\n            display_name=\"Bulk Insert Overwrite Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations that overwrite existing data.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_delete_concurrency\",\n            display_name=\"Bulk Delete Concurrency\",\n            info=\"Optional concurrency level for bulk delete operations.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"setup_mode\",\n            display_name=\"Setup Mode\",\n            info=\"Configuration mode for setting up the vector store, with options like 'Sync', or 'Off'.\",\n            options=[\"Sync\", \"Off\"],\n            advanced=True,\n            value=\"Sync\",\n        ),\n        BoolInput(\n            name=\"pre_delete_collection\",\n            display_name=\"Pre Delete Collection\",\n            info=\"Boolean flag to determine whether to delete the collection before creating a new one.\",\n            advanced=True,\n            value=False,\n        ),\n        StrInput(\n            name=\"metadata_indexing_include\",\n            display_name=\"Metadata Indexing Include\",\n            info=\"Optional list of metadata fields to include in the indexing.\",\n            advanced=True,\n            list=True,\n        ),\n        StrInput(\n            name=\"metadata_indexing_exclude\",\n            display_name=\"Metadata Indexing Exclude\",\n            info=\"Optional list of metadata fields to exclude from the indexing.\",\n            advanced=True,\n            list=True,\n        ),\n        StrInput(\n            name=\"collection_indexing_policy\",\n            display_name=\"Collection Indexing Policy\",\n            info='Optional JSON string for the \"indexing\" field of the collection. '\n            \"See https://docs.datastax.com/en/astra-db-serverless/api-reference/collections.html#the-indexing-option\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            info=\"Search type to use\",\n            options=[\n                \"Similarity\",\n                \"Similarity with score threshold\",\n                \"MMR (Max Marginal Relevance)\",\n                \"Graph Traversal\",\n                \"MMR (Max Marginal Relevance) Graph Traversal\",\n            ],\n            value=\"MMR (Max Marginal Relevance) Graph Traversal\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results. \"\n            \"(when using 'Similarity with score threshold')\",\n            value=0,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"search_filter\",\n            display_name=\"Search Metadata Filter\",\n            info=\"Optional dictionary of filters to apply to the search query.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self):\n        try:\n            from langchain_astradb import AstraDBGraphVectorStore\n            from langchain_astradb.utils.astradb import SetupMode\n        except ImportError as e:\n            msg = (\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n            raise ImportError(msg) from e\n\n        try:\n            if not self.setup_mode:\n                self.setup_mode = self._inputs[\"setup_mode\"].options[0]\n\n            setup_mode_value = SetupMode[self.setup_mode.upper()]\n        except KeyError as e:\n            msg = f\"Invalid setup mode: {self.setup_mode}\"\n            raise ValueError(msg) from e\n\n        try:\n            self.log(f\"Initializing Graph Vector Store {self.collection_name}\")\n\n            vector_store = AstraDBGraphVectorStore(\n                embedding=self.embedding_model,\n                collection_name=self.collection_name,\n                metadata_incoming_links_key=self.metadata_incoming_links_key or \"incoming_links\",\n                token=self.token,\n                api_endpoint=self.api_endpoint,\n                namespace=self.keyspace or None,\n                environment=parse_api_endpoint(self.api_endpoint).environment if self.api_endpoint else None,\n                metric=self.metric or None,\n                batch_size=self.batch_size or None,\n                bulk_insert_batch_concurrency=self.bulk_insert_batch_concurrency or None,\n                bulk_insert_overwrite_concurrency=self.bulk_insert_overwrite_concurrency or None,\n                bulk_delete_concurrency=self.bulk_delete_concurrency or None,\n                setup_mode=setup_mode_value,\n                pre_delete_collection=self.pre_delete_collection,\n                metadata_indexing_include=[s for s in self.metadata_indexing_include if s] or None,\n                metadata_indexing_exclude=[s for s in self.metadata_indexing_exclude if s] or None,\n                collection_indexing_policy=orjson.loads(self.collection_indexing_policy.encode(\"utf-8\"))\n                if self.collection_indexing_policy\n                else None,\n            )\n        except Exception as e:\n            msg = f\"Error initializing AstraDBGraphVectorStore: {e}\"\n            raise ValueError(msg) from e\n\n        self.log(f\"Vector Store initialized: {vector_store.astra_env.collection_name}\")\n        self._add_documents_to_vector_store(vector_store)\n\n        return vector_store\n\n    def _add_documents_to_vector_store(self, vector_store) -> None:\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                msg = \"Vector Store Inputs must be Data objects.\"\n                raise TypeError(msg)\n\n        if documents:\n            self.log(f\"Adding {len(documents)} documents to the Vector Store.\")\n            try:\n                vector_store.add_documents(documents)\n            except Exception as e:\n                msg = f\"Error adding documents to AstraDBGraphVectorStore: {e}\"\n                raise ValueError(msg) from e\n        else:\n            self.log(\"No documents to add to the Vector Store.\")\n\n    def _map_search_type(self) -> str:\n        match self.search_type:\n            case \"Similarity\":\n                return \"similarity\"\n            case \"Similarity with score threshold\":\n                return \"similarity_score_threshold\"\n            case \"MMR (Max Marginal Relevance)\":\n                return \"mmr\"\n            case \"Graph Traversal\":\n                return \"traversal\"\n            case \"MMR (Max Marginal Relevance) Graph Traversal\":\n                return \"mmr_traversal\"\n            case _:\n                return \"similarity\"\n\n    def _build_search_args(self):\n        args = {\n            \"k\": self.number_of_results,\n            \"score_threshold\": self.search_score_threshold,\n        }\n\n        if self.search_filter:\n            clean_filter = {k: v for k, v in self.search_filter.items() if k and v}\n            if len(clean_filter) > 0:\n                args[\"filter\"] = clean_filter\n        return args\n\n    def search_documents(self, vector_store=None) -> list[Data]:\n        if not vector_store:\n            vector_store = self.build_vector_store()\n\n        self.log(\"Searching for documents in AstraDBGraphVectorStore.\")\n        self.log(f\"Search query: {self.search_query}\")\n        self.log(f\"Search type: {self.search_type}\")\n        self.log(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            try:\n                search_type = self._map_search_type()\n                search_args = self._build_search_args()\n\n                docs = vector_store.search(query=self.search_query, search_type=search_type, **search_args)\n\n                # Drop links from the metadata. At this point the links don't add any value for building the\n                # context and haven't been restored to json which causes the conversion to fail.\n                self.log(\"Removing links from metadata.\")\n                for doc in docs:\n                    if \"links\" in doc.metadata:\n                        doc.metadata.pop(\"links\")\n\n            except Exception as e:\n                msg = f\"Error performing search in AstraDBGraphVectorStore: {e}\"\n                raise ValueError(msg) from e\n\n            self.log(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n\n            self.log(f\"Converted documents to data: {len(data)}\")\n\n            self.status = data\n            return data\n        self.log(\"No search input provided. Skipping search.\")\n        return []\n\n    def get_retriever_kwargs(self):\n        search_args = self._build_search_args()\n        return {\n            \"search_type\": self._map_search_type(),\n            \"search_kwargs\": search_args,\n        }\n"
              },
              "collection_indexing_policy": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Collection Indexing Policy",
                "dynamic": false,
                "info": "Optional JSON string for the \"indexing\" field of the collection. See https://docs.datastax.com/en/astra-db-serverless/api-reference/collections.html#the-indexing-option",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "collection_indexing_policy",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "collection_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Collection Name",
                "dynamic": false,
                "info": "The name of the collection within Astra DB where the vectors will be stored.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "collection_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "embedding_model": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Embedding Model",
                "dynamic": false,
                "info": "Allows an embedding model configuration.",
                "input_types": [
                  "Embeddings"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "embedding_model",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "ingest_data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Ingest Data",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "ingest_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "keyspace": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Keyspace",
                "dynamic": false,
                "info": "Optional keyspace within Astra DB to use for the collection.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "keyspace",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "metadata_incoming_links_key": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Metadata incoming links key",
                "dynamic": false,
                "info": "Metadata key used for incoming links.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "metadata_incoming_links_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "metadata_indexing_exclude": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Metadata Indexing Exclude",
                "dynamic": false,
                "info": "Optional list of metadata fields to exclude from the indexing.",
                "list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "metadata_indexing_exclude",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "metadata_indexing_include": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Metadata Indexing Include",
                "dynamic": false,
                "info": "Optional list of metadata fields to include in the indexing.",
                "list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "metadata_indexing_include",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "metric": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Metric",
                "dynamic": false,
                "info": "Optional distance metric for vector comparisons in the vector store.",
                "name": "metric",
                "options": [
                  "cosine",
                  "dot_product",
                  "euclidean"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "cosine"
              },
              "number_of_results": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Results",
                "dynamic": false,
                "info": "Number of results to return.",
                "list": false,
                "list_add_label": "Add More",
                "name": "number_of_results",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 4
              },
              "pre_delete_collection": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Pre Delete Collection",
                "dynamic": false,
                "info": "Boolean flag to determine whether to delete the collection before creating a new one.",
                "list": false,
                "list_add_label": "Add More",
                "name": "pre_delete_collection",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "search_filter": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Search Metadata Filter",
                "dynamic": false,
                "info": "Optional dictionary of filters to apply to the search query.",
                "list": true,
                "list_add_label": "Add More",
                "name": "search_filter",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "search_query": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "search_query",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "search_score_threshold": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Search Score Threshold",
                "dynamic": false,
                "info": "Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')",
                "list": false,
                "list_add_label": "Add More",
                "name": "search_score_threshold",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": 0
              },
              "search_type": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Search Type",
                "dynamic": false,
                "info": "Search type to use",
                "name": "search_type",
                "options": [
                  "Similarity",
                  "Similarity with score threshold",
                  "MMR (Max Marginal Relevance)",
                  "Graph Traversal",
                  "MMR (Max Marginal Relevance) Graph Traversal"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "MMR (Max Marginal Relevance) Graph Traversal"
              },
              "setup_mode": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Setup Mode",
                "dynamic": false,
                "info": "Configuration mode for setting up the vector store, with options like 'Sync', or 'Off'.",
                "name": "setup_mode",
                "options": [
                  "Sync",
                  "Off"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Sync"
              },
              "should_cache_vector_store": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Cache Vector Store",
                "dynamic": false,
                "info": "If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_cache_vector_store",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "token": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Astra DB Application Token",
                "dynamic": false,
                "info": "Authentication token for accessing Astra DB.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": true,
                "name": "token",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "AstraDBGraph"
        },
        "dragging": false,
        "id": "AstraDBGraph-xJiDN",
        "measured": {
          "height": 709,
          "width": 360
        },
        "position": {
          "x": -1289.3629248195448,
          "y": 7017.257953990425
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "AstraDBGraph-uza6S",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "category": "vectorstores",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Implementation of Graph Vector Store using Astra DB",
            "display_name": "Astra DB Graph",
            "documentation": "",
            "edited": false,
            "field_order": [
              "token",
              "api_endpoint",
              "collection_name",
              "metadata_incoming_links_key",
              "ingest_data",
              "search_query",
              "should_cache_vector_store",
              "keyspace",
              "embedding_model",
              "metric",
              "batch_size",
              "bulk_insert_batch_concurrency",
              "bulk_insert_overwrite_concurrency",
              "bulk_delete_concurrency",
              "setup_mode",
              "pre_delete_collection",
              "metadata_indexing_include",
              "metadata_indexing_exclude",
              "collection_indexing_policy",
              "number_of_results",
              "search_type",
              "search_score_threshold",
              "search_filter"
            ],
            "frozen": false,
            "icon": "AstraDB",
            "key": "AstraDBGraph",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Search Results",
                "method": "search_documents",
                "name": "search_results",
                "required_inputs": [
                  "api_endpoint",
                  "collection_name",
                  "token"
                ],
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "DataFrame",
                "method": "as_dataframe",
                "name": "dataframe",
                "required_inputs": [],
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.01857804455091699,
            "template": {
              "_type": "Component",
              "api_endpoint": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "API Endpoint",
                "dynamic": false,
                "info": "API endpoint URL for the Astra DB service.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": true,
                "name": "api_endpoint",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "batch_size": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Batch Size",
                "dynamic": false,
                "info": "Optional number of data to process in a single batch.",
                "list": false,
                "list_add_label": "Add More",
                "name": "batch_size",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "bulk_delete_concurrency": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Bulk Delete Concurrency",
                "dynamic": false,
                "info": "Optional concurrency level for bulk delete operations.",
                "list": false,
                "list_add_label": "Add More",
                "name": "bulk_delete_concurrency",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "bulk_insert_batch_concurrency": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Bulk Insert Batch Concurrency",
                "dynamic": false,
                "info": "Optional concurrency level for bulk insert operations.",
                "list": false,
                "list_add_label": "Add More",
                "name": "bulk_insert_batch_concurrency",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "bulk_insert_overwrite_concurrency": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Bulk Insert Overwrite Concurrency",
                "dynamic": false,
                "info": "Optional concurrency level for bulk insert operations that overwrite existing data.",
                "list": false,
                "list_add_label": "Add More",
                "name": "bulk_insert_overwrite_concurrency",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import os\n\nimport orjson\nfrom astrapy.admin import parse_api_endpoint\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom langflow.helpers import docs_to_data\nfrom langflow.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    HandleInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom langflow.schema import Data\n\n\nclass AstraDBGraphVectorStoreComponent(LCVectorStoreComponent):\n    display_name: str = \"Astra DB Graph\"\n    description: str = \"Implementation of Graph Vector Store using Astra DB\"\n    name = \"AstraDBGraph\"\n    icon: str = \"AstraDB\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n            required=True,\n            advanced=os.getenv(\"ASTRA_ENHANCED\", \"false\").lower() == \"true\",\n        ),\n        SecretStrInput(\n            name=\"api_endpoint\",\n            display_name=\"Database\" if os.getenv(\"ASTRA_ENHANCED\", \"false\").lower() == \"true\" else \"API Endpoint\",\n            info=\"API endpoint URL for the Astra DB service.\",\n            value=\"ASTRA_DB_API_ENDPOINT\",\n            required=True,\n        ),\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            info=\"The name of the collection within Astra DB where the vectors will be stored.\",\n            required=True,\n        ),\n        StrInput(\n            name=\"metadata_incoming_links_key\",\n            display_name=\"Metadata incoming links key\",\n            info=\"Metadata key used for incoming links.\",\n            advanced=True,\n        ),\n        *LCVectorStoreComponent.inputs,\n        StrInput(\n            name=\"keyspace\",\n            display_name=\"Keyspace\",\n            info=\"Optional keyspace within Astra DB to use for the collection.\",\n            advanced=True,\n        ),\n        HandleInput(\n            name=\"embedding_model\",\n            display_name=\"Embedding Model\",\n            input_types=[\"Embeddings\"],\n            info=\"Allows an embedding model configuration.\",\n        ),\n        DropdownInput(\n            name=\"metric\",\n            display_name=\"Metric\",\n            info=\"Optional distance metric for vector comparisons in the vector store.\",\n            options=[\"cosine\", \"dot_product\", \"euclidean\"],\n            value=\"cosine\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"batch_size\",\n            display_name=\"Batch Size\",\n            info=\"Optional number of data to process in a single batch.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_batch_concurrency\",\n            display_name=\"Bulk Insert Batch Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_overwrite_concurrency\",\n            display_name=\"Bulk Insert Overwrite Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations that overwrite existing data.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_delete_concurrency\",\n            display_name=\"Bulk Delete Concurrency\",\n            info=\"Optional concurrency level for bulk delete operations.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"setup_mode\",\n            display_name=\"Setup Mode\",\n            info=\"Configuration mode for setting up the vector store, with options like 'Sync', or 'Off'.\",\n            options=[\"Sync\", \"Off\"],\n            advanced=True,\n            value=\"Sync\",\n        ),\n        BoolInput(\n            name=\"pre_delete_collection\",\n            display_name=\"Pre Delete Collection\",\n            info=\"Boolean flag to determine whether to delete the collection before creating a new one.\",\n            advanced=True,\n            value=False,\n        ),\n        StrInput(\n            name=\"metadata_indexing_include\",\n            display_name=\"Metadata Indexing Include\",\n            info=\"Optional list of metadata fields to include in the indexing.\",\n            advanced=True,\n            list=True,\n        ),\n        StrInput(\n            name=\"metadata_indexing_exclude\",\n            display_name=\"Metadata Indexing Exclude\",\n            info=\"Optional list of metadata fields to exclude from the indexing.\",\n            advanced=True,\n            list=True,\n        ),\n        StrInput(\n            name=\"collection_indexing_policy\",\n            display_name=\"Collection Indexing Policy\",\n            info='Optional JSON string for the \"indexing\" field of the collection. '\n            \"See https://docs.datastax.com/en/astra-db-serverless/api-reference/collections.html#the-indexing-option\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            info=\"Search type to use\",\n            options=[\n                \"Similarity\",\n                \"Similarity with score threshold\",\n                \"MMR (Max Marginal Relevance)\",\n                \"Graph Traversal\",\n                \"MMR (Max Marginal Relevance) Graph Traversal\",\n            ],\n            value=\"MMR (Max Marginal Relevance) Graph Traversal\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results. \"\n            \"(when using 'Similarity with score threshold')\",\n            value=0,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"search_filter\",\n            display_name=\"Search Metadata Filter\",\n            info=\"Optional dictionary of filters to apply to the search query.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self):\n        try:\n            from langchain_astradb import AstraDBGraphVectorStore\n            from langchain_astradb.utils.astradb import SetupMode\n        except ImportError as e:\n            msg = (\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n            raise ImportError(msg) from e\n\n        try:\n            if not self.setup_mode:\n                self.setup_mode = self._inputs[\"setup_mode\"].options[0]\n\n            setup_mode_value = SetupMode[self.setup_mode.upper()]\n        except KeyError as e:\n            msg = f\"Invalid setup mode: {self.setup_mode}\"\n            raise ValueError(msg) from e\n\n        try:\n            self.log(f\"Initializing Graph Vector Store {self.collection_name}\")\n\n            vector_store = AstraDBGraphVectorStore(\n                embedding=self.embedding_model,\n                collection_name=self.collection_name,\n                metadata_incoming_links_key=self.metadata_incoming_links_key or \"incoming_links\",\n                token=self.token,\n                api_endpoint=self.api_endpoint,\n                namespace=self.keyspace or None,\n                environment=parse_api_endpoint(self.api_endpoint).environment if self.api_endpoint else None,\n                metric=self.metric or None,\n                batch_size=self.batch_size or None,\n                bulk_insert_batch_concurrency=self.bulk_insert_batch_concurrency or None,\n                bulk_insert_overwrite_concurrency=self.bulk_insert_overwrite_concurrency or None,\n                bulk_delete_concurrency=self.bulk_delete_concurrency or None,\n                setup_mode=setup_mode_value,\n                pre_delete_collection=self.pre_delete_collection,\n                metadata_indexing_include=[s for s in self.metadata_indexing_include if s] or None,\n                metadata_indexing_exclude=[s for s in self.metadata_indexing_exclude if s] or None,\n                collection_indexing_policy=orjson.loads(self.collection_indexing_policy.encode(\"utf-8\"))\n                if self.collection_indexing_policy\n                else None,\n            )\n        except Exception as e:\n            msg = f\"Error initializing AstraDBGraphVectorStore: {e}\"\n            raise ValueError(msg) from e\n\n        self.log(f\"Vector Store initialized: {vector_store.astra_env.collection_name}\")\n        self._add_documents_to_vector_store(vector_store)\n\n        return vector_store\n\n    def _add_documents_to_vector_store(self, vector_store) -> None:\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                msg = \"Vector Store Inputs must be Data objects.\"\n                raise TypeError(msg)\n\n        if documents:\n            self.log(f\"Adding {len(documents)} documents to the Vector Store.\")\n            try:\n                vector_store.add_documents(documents)\n            except Exception as e:\n                msg = f\"Error adding documents to AstraDBGraphVectorStore: {e}\"\n                raise ValueError(msg) from e\n        else:\n            self.log(\"No documents to add to the Vector Store.\")\n\n    def _map_search_type(self) -> str:\n        match self.search_type:\n            case \"Similarity\":\n                return \"similarity\"\n            case \"Similarity with score threshold\":\n                return \"similarity_score_threshold\"\n            case \"MMR (Max Marginal Relevance)\":\n                return \"mmr\"\n            case \"Graph Traversal\":\n                return \"traversal\"\n            case \"MMR (Max Marginal Relevance) Graph Traversal\":\n                return \"mmr_traversal\"\n            case _:\n                return \"similarity\"\n\n    def _build_search_args(self):\n        args = {\n            \"k\": self.number_of_results,\n            \"score_threshold\": self.search_score_threshold,\n        }\n\n        if self.search_filter:\n            clean_filter = {k: v for k, v in self.search_filter.items() if k and v}\n            if len(clean_filter) > 0:\n                args[\"filter\"] = clean_filter\n        return args\n\n    def search_documents(self, vector_store=None) -> list[Data]:\n        if not vector_store:\n            vector_store = self.build_vector_store()\n\n        self.log(\"Searching for documents in AstraDBGraphVectorStore.\")\n        self.log(f\"Search query: {self.search_query}\")\n        self.log(f\"Search type: {self.search_type}\")\n        self.log(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            try:\n                search_type = self._map_search_type()\n                search_args = self._build_search_args()\n\n                docs = vector_store.search(query=self.search_query, search_type=search_type, **search_args)\n\n                # Drop links from the metadata. At this point the links don't add any value for building the\n                # context and haven't been restored to json which causes the conversion to fail.\n                self.log(\"Removing links from metadata.\")\n                for doc in docs:\n                    if \"links\" in doc.metadata:\n                        doc.metadata.pop(\"links\")\n\n            except Exception as e:\n                msg = f\"Error performing search in AstraDBGraphVectorStore: {e}\"\n                raise ValueError(msg) from e\n\n            self.log(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n\n            self.log(f\"Converted documents to data: {len(data)}\")\n\n            self.status = data\n            return data\n        self.log(\"No search input provided. Skipping search.\")\n        return []\n\n    def get_retriever_kwargs(self):\n        search_args = self._build_search_args()\n        return {\n            \"search_type\": self._map_search_type(),\n            \"search_kwargs\": search_args,\n        }\n"
              },
              "collection_indexing_policy": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Collection Indexing Policy",
                "dynamic": false,
                "info": "Optional JSON string for the \"indexing\" field of the collection. See https://docs.datastax.com/en/astra-db-serverless/api-reference/collections.html#the-indexing-option",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "collection_indexing_policy",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "collection_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Collection Name",
                "dynamic": false,
                "info": "The name of the collection within Astra DB where the vectors will be stored.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "collection_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "embedding_model": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Embedding Model",
                "dynamic": false,
                "info": "Allows an embedding model configuration.",
                "input_types": [
                  "Embeddings"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "embedding_model",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "ingest_data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Ingest Data",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "ingest_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "keyspace": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Keyspace",
                "dynamic": false,
                "info": "Optional keyspace within Astra DB to use for the collection.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "keyspace",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "metadata_incoming_links_key": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Metadata incoming links key",
                "dynamic": false,
                "info": "Metadata key used for incoming links.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "metadata_incoming_links_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "metadata_indexing_exclude": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Metadata Indexing Exclude",
                "dynamic": false,
                "info": "Optional list of metadata fields to exclude from the indexing.",
                "list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "metadata_indexing_exclude",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "metadata_indexing_include": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Metadata Indexing Include",
                "dynamic": false,
                "info": "Optional list of metadata fields to include in the indexing.",
                "list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "metadata_indexing_include",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "metric": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Metric",
                "dynamic": false,
                "info": "Optional distance metric for vector comparisons in the vector store.",
                "name": "metric",
                "options": [
                  "cosine",
                  "dot_product",
                  "euclidean"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "cosine"
              },
              "number_of_results": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Results",
                "dynamic": false,
                "info": "Number of results to return.",
                "list": false,
                "list_add_label": "Add More",
                "name": "number_of_results",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 4
              },
              "pre_delete_collection": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Pre Delete Collection",
                "dynamic": false,
                "info": "Boolean flag to determine whether to delete the collection before creating a new one.",
                "list": false,
                "list_add_label": "Add More",
                "name": "pre_delete_collection",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "search_filter": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Search Metadata Filter",
                "dynamic": false,
                "info": "Optional dictionary of filters to apply to the search query.",
                "list": true,
                "list_add_label": "Add More",
                "name": "search_filter",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "search_query": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "search_query",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "search_score_threshold": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Search Score Threshold",
                "dynamic": false,
                "info": "Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')",
                "list": false,
                "list_add_label": "Add More",
                "name": "search_score_threshold",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": 0
              },
              "search_type": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Search Type",
                "dynamic": false,
                "info": "Search type to use",
                "name": "search_type",
                "options": [
                  "Similarity",
                  "Similarity with score threshold",
                  "MMR (Max Marginal Relevance)",
                  "Graph Traversal",
                  "MMR (Max Marginal Relevance) Graph Traversal"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "MMR (Max Marginal Relevance) Graph Traversal"
              },
              "setup_mode": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Setup Mode",
                "dynamic": false,
                "info": "Configuration mode for setting up the vector store, with options like 'Sync', or 'Off'.",
                "name": "setup_mode",
                "options": [
                  "Sync",
                  "Off"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Sync"
              },
              "should_cache_vector_store": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Cache Vector Store",
                "dynamic": false,
                "info": "If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_cache_vector_store",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "token": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Astra DB Application Token",
                "dynamic": false,
                "info": "Authentication token for accessing Astra DB.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": true,
                "name": "token",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "AstraDBGraph"
        },
        "dragging": false,
        "id": "AstraDBGraph-uza6S",
        "measured": {
          "height": 709,
          "width": 360
        },
        "position": {
          "x": -351.01793894175796,
          "y": 6101.568873207264
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": 1127.2300847911954,
      "y": -2570.5545905062804,
      "zoom": 0.4514602881701939
    }
  },
  "description": "Extracts links from web pages and processes the content using Graph RAG Chain with Maximal Marginal Relevance (MMR) traversal.",
  "endpoint_name": null,
  "icon": "chartNetwork",
  "id": "73ceae85-141a-42e3-9f41-a0749434ca0e",
  "is_component": false,
  "last_tested_version": "1.1.1",
  "name": "Graph RAG",
  "tags": [
    "rag",
    "q-a"
  ]
}