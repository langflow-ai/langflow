{
  "id": "85392e54-20f3-4ab5-a179-cb4bef16f639",
  "data": {
    "nodes": [
      {
        "id": "Prompt-amqBu",
        "type": "genericNode",
        "position": {
          "x": 2191.5837146441663,
          "y": 1047.9307944451873
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_core.prompts import PromptTemplate\n\nfrom langflow.field_typing import Prompt, TemplateField, Text\nfrom langflow.interface.custom.custom_component import CustomComponent\n\n\nclass PromptComponent(CustomComponent):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n\n    def build_config(self):\n        return {\n            \"template\": TemplateField(display_name=\"Template\"),\n            \"code\": TemplateField(advanced=True),\n        }\n\n    def build(\n        self,\n        template: Prompt,\n        **kwargs,\n    ) -> Text:\n        from langflow.base.prompts.utils import dict_values_to_string\n\n        prompt_template = PromptTemplate.from_template(Text(template))\n        kwargs = dict_values_to_string(kwargs)\n        kwargs = {k: \"\\n\".join(v) if isinstance(v, list) else v for k, v in kwargs.items()}\n        try:\n            formated_prompt = prompt_template.format(**kwargs)\n        except Exception as exc:\n            raise ValueError(f\"Error formatting prompt: {exc}\") from exc\n        self.status = f'Prompt:\\n\"{formated_prompt}\"'\n        return formated_prompt\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "type": "prompt",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "You are a helpful assistant. Given a long document, your task is to create a concise summary that captures the main points and key details. The summary should be clear, accurate, and succinct. Please provide the summary in the format below:\n####\n{document}\n####\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "template",
                "display_name": "Template",
                "advanced": false,
                "input_types": ["Text"],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "_type": "CustomComponent",
              "document": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "document",
                "display_name": "document",
                "advanced": false,
                "input_types": [
                  "Document",
                  "BaseOutputParser",
                  "Record",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": ["object", "str", "Text"],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": ["document"]
            },
            "output_types": ["Text"],
            "full_path": null,
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false,
            "error": null
          },
          "id": "Prompt-amqBu",
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt"
        },
        "selected": false,
        "width": 384,
        "height": 385,
        "positionAbsolute": {
          "x": 2191.5837146441663,
          "y": 1047.9307944451873
        },
        "dragging": false
      },
      {
        "id": "Prompt-gTNiz",
        "type": "genericNode",
        "position": {
          "x": 3731.0813766902447,
          "y": 799.631909121391
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_core.prompts import PromptTemplate\n\nfrom langflow.field_typing import Prompt, TemplateField, Text\nfrom langflow.interface.custom.custom_component import CustomComponent\n\n\nclass PromptComponent(CustomComponent):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n\n    def build_config(self):\n        return {\n            \"template\": TemplateField(display_name=\"Template\"),\n            \"code\": TemplateField(advanced=True),\n        }\n\n    def build(\n        self,\n        template: Prompt,\n        **kwargs,\n    ) -> Text:\n        from langflow.base.prompts.utils import dict_values_to_string\n\n        prompt_template = PromptTemplate.from_template(Text(template))\n        kwargs = dict_values_to_string(kwargs)\n        kwargs = {k: \"\\n\".join(v) if isinstance(v, list) else v for k, v in kwargs.items()}\n        try:\n            formated_prompt = prompt_template.format(**kwargs)\n        except Exception as exc:\n            raise ValueError(f\"Error formatting prompt: {exc}\") from exc\n        self.status = f'Prompt:\\n\"{formated_prompt}\"'\n        return formated_prompt\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "type": "prompt",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "Given a summary of an article, please create two multiple-choice questions that cover the key points and details mentioned. Ensure the questions are clear and provide three options (A, B, C), with one correct answer.\n####\n{summary}\n####",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "template",
                "display_name": "Template",
                "advanced": false,
                "input_types": ["Text"],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "_type": "CustomComponent",
              "summary": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "summary",
                "display_name": "summary",
                "advanced": false,
                "input_types": [
                  "Document",
                  "BaseOutputParser",
                  "Record",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": ["object", "str", "Text"],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": ["summary"]
            },
            "output_types": ["Text"],
            "full_path": null,
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false,
            "error": null
          },
          "id": "Prompt-gTNiz",
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt"
        },
        "selected": false,
        "width": 384,
        "height": 385,
        "dragging": false
      },
      {
        "id": "ChatOutput-EJkG3",
        "type": "genericNode",
        "position": {
          "x": 3722.1747844849388,
          "y": 1283.413553222214
        },
        "data": {
          "type": "ChatOutput",
          "node": {
            "template": {
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional, Union\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.field_typing import Text\nfrom langflow.schema import Record\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n\n    def build(\n        self,\n        sender: Optional[str] = \"Machine\",\n        sender_name: Optional[str] = \"AI\",\n        input_value: Optional[str] = None,\n        session_id: Optional[str] = None,\n        return_record: Optional[bool] = False,\n        record_template: Optional[str] = \"{text}\",\n    ) -> Union[Text, Record]:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            return_record=return_record,\n            record_template=record_template or \"\",\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "input_value",
                "display_name": "Message",
                "advanced": false,
                "input_types": ["Text"],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "record_template": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "{text}",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "record_template",
                "display_name": "Record Template",
                "advanced": true,
                "dynamic": false,
                "info": "In case of Message being a Record, this template will be used to convert it to text.",
                "load_from_db": false,
                "title_case": false,
                "input_types": ["Text"]
              },
              "return_record": {
                "type": "bool",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "return_record",
                "display_name": "Return Record",
                "advanced": true,
                "dynamic": false,
                "info": "Return the message as a record containing the sender, sender_name, and session_id.",
                "load_from_db": false,
                "title_case": false
              },
              "sender": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "value": "Machine",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": ["Machine", "User"],
                "name": "sender",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": ["Text"]
              },
              "sender_name": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "Summarizer",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "sender_name",
                "display_name": "Sender Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": ["Text"]
              },
              "session_id": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "session_id",
                "display_name": "Session ID",
                "advanced": true,
                "dynamic": false,
                "info": "If provided, the message will be stored in the memory.",
                "load_from_db": false,
                "title_case": false,
                "input_types": ["Text"]
              },
              "_type": "CustomComponent"
            },
            "description": "Display a chat message in the Playground.",
            "icon": "ChatOutput",
            "base_classes": ["object", "Record", "Text", "str"],
            "display_name": "Chat Output",
            "documentation": "",
            "custom_fields": {
              "sender": null,
              "sender_name": null,
              "input_value": null,
              "session_id": null,
              "return_record": null,
              "record_template": null
            },
            "output_types": ["Text", "Record"],
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false
          },
          "id": "ChatOutput-EJkG3"
        },
        "selected": false,
        "width": 384,
        "height": 385,
        "dragging": false
      },
      {
        "id": "ChatOutput-DNmvg",
        "type": "genericNode",
        "position": {
          "x": 5077.71285886074,
          "y": 1232.9152769735522
        },
        "data": {
          "type": "ChatOutput",
          "node": {
            "template": {
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional, Union\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.field_typing import Text\nfrom langflow.schema import Record\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n\n    def build(\n        self,\n        sender: Optional[str] = \"Machine\",\n        sender_name: Optional[str] = \"AI\",\n        input_value: Optional[str] = None,\n        session_id: Optional[str] = None,\n        return_record: Optional[bool] = False,\n        record_template: Optional[str] = \"{text}\",\n    ) -> Union[Text, Record]:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            return_record=return_record,\n            record_template=record_template or \"\",\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "input_value",
                "display_name": "Message",
                "advanced": false,
                "input_types": ["Text"],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "record_template": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "{text}",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "record_template",
                "display_name": "Record Template",
                "advanced": true,
                "dynamic": false,
                "info": "In case of Message being a Record, this template will be used to convert it to text.",
                "load_from_db": false,
                "title_case": false,
                "input_types": ["Text"]
              },
              "return_record": {
                "type": "bool",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "return_record",
                "display_name": "Return Record",
                "advanced": true,
                "dynamic": false,
                "info": "Return the message as a record containing the sender, sender_name, and session_id.",
                "load_from_db": false,
                "title_case": false
              },
              "sender": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "value": "Machine",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": ["Machine", "User"],
                "name": "sender",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": ["Text"]
              },
              "sender_name": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "Question Generator",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "sender_name",
                "display_name": "Sender Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": ["Text"]
              },
              "session_id": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "session_id",
                "display_name": "Session ID",
                "advanced": true,
                "dynamic": false,
                "info": "If provided, the message will be stored in the memory.",
                "load_from_db": false,
                "title_case": false,
                "input_types": ["Text"]
              },
              "_type": "CustomComponent"
            },
            "description": "Display a chat message in the Playground.",
            "icon": "ChatOutput",
            "base_classes": ["object", "Record", "Text", "str"],
            "display_name": "Chat Output",
            "documentation": "",
            "custom_fields": {
              "sender": null,
              "sender_name": null,
              "input_value": null,
              "session_id": null,
              "return_record": null,
              "record_template": null
            },
            "output_types": ["Text", "Record"],
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false
          },
          "id": "ChatOutput-DNmvg"
        },
        "selected": false,
        "width": 384,
        "height": 385
      },
      {
        "id": "TextInput-sptaH",
        "type": "genericNode",
        "position": {
          "x": 1700.5624822024752,
          "y": 1039.603088937466
        },
        "data": {
          "type": "TextInput",
          "node": {
            "template": {
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional\n\nfrom langflow.base.io.text import TextComponent\nfrom langflow.field_typing import Text\n\n\nclass TextInput(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Value\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as input.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Optional[Text] = \"\",\n        record_template: Optional[str] = \"\",\n    ) -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "Revolutionary Nano-Battery Technology Unveiled  In a groundbreaking announcement yesterday, researchers from the fictional Tech Innovations Institute revealed the development of a new nano-battery technology that promises to revolutionize energy storage. The new battery, dubbed the \"EnerGCell\", uses advanced nanomaterials to achieve unprecedented efficiency and storage capacities.  According to lead researcher Dr. Ada Byron, the EnerGCell can store up to ten times more energy than the best lithium-ion batteries available today, while charging in just a fraction of the time. \"We're talking about charging your electric vehicle in just five minutes for a range of over 1,000 miles,\" Dr. Byron stated during the press conference.  The technology behind the EnerGCell involves a complex arrangement of nanostructured electrodes that allow for rapid ion transfer and extremely high energy density. This breakthrough was achieved after a decade of research into nanomaterials and their applications in energy storage.  The implications of this technology are vast, promising to accelerate the adoption of renewable energy by making it more practical and affordable to store wind and solar power. It could also lead to significant advancements in electric vehicles, mobile devices, and any other technology that relies on batteries.  Despite the excitement, some experts are calling for patience, noting that the EnerGCell is still in its early stages of development and may take several years before it's commercially available. However, the potential impact of such a technology on the environment and the global economy is undeniable.  Tech Innovations Institute plans to continue refining the EnerGCell and begin pilot projects with select partners in the coming year. If successful, this nano-battery technology could indeed be the breakthrough needed to usher in a new era of clean energy and technology.",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "input_value",
                "display_name": "Value",
                "advanced": false,
                "input_types": ["Record", "Text"],
                "dynamic": false,
                "info": "Text or Record to be passed as input.",
                "load_from_db": false,
                "title_case": false
              },
              "record_template": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "record_template",
                "display_name": "Record Template",
                "advanced": true,
                "dynamic": false,
                "info": "Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.",
                "load_from_db": false,
                "title_case": false,
                "input_types": ["Text"]
              },
              "_type": "CustomComponent"
            },
            "description": "Get text inputs from the Playground.",
            "icon": "type",
            "base_classes": ["str", "Text", "object"],
            "display_name": "Text Input",
            "documentation": "",
            "custom_fields": {
              "input_value": null,
              "record_template": null
            },
            "output_types": ["Text"],
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false
          },
          "id": "TextInput-sptaH"
        },
        "selected": false,
        "width": 384,
        "height": 290,
        "positionAbsolute": {
          "x": 1700.5624822024752,
          "y": 1039.603088937466
        },
        "dragging": false
      },
      {
        "id": "TextOutput-2MS4a",
        "type": "genericNode",
        "position": {
          "x": 2917.216113690115,
          "y": 513.0058511435552
        },
        "data": {
          "type": "TextOutput",
          "node": {
            "template": {
              "input_value": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "input_value",
                "display_name": "Value",
                "advanced": false,
                "input_types": ["Record", "Text"],
                "dynamic": false,
                "info": "Text or Record to be passed as output.",
                "load_from_db": false,
                "title_case": false
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional\n\nfrom langflow.base.io.text import TextComponent\nfrom langflow.field_typing import Text\n\n\nclass TextOutput(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Value\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as output.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(self, input_value: Optional[Text] = \"\", record_template: str = \"\") -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "record_template": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "record_template",
                "display_name": "Record Template",
                "advanced": true,
                "dynamic": false,
                "info": "Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.",
                "load_from_db": false,
                "title_case": false,
                "input_types": ["Text"]
              },
              "_type": "CustomComponent"
            },
            "description": "Display a text output in the Playground.",
            "icon": "type",
            "base_classes": ["str", "Text", "object"],
            "display_name": "First Prompt",
            "documentation": "",
            "custom_fields": {
              "input_value": null,
              "record_template": null
            },
            "output_types": ["Text"],
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false
          },
          "id": "TextOutput-2MS4a"
        },
        "selected": false,
        "width": 384,
        "height": 290,
        "positionAbsolute": {
          "x": 2917.216113690115,
          "y": 513.0058511435552
        },
        "dragging": false
      },
      {
        "id": "OpenAIModel-uYXZJ",
        "type": "genericNode",
        "position": {
          "x": 2925.784767523062,
          "y": 933.6465680967775
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "input_value": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "input_value",
                "display_name": "Input",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": ["Text"]
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import MODEL_NAMES\nfrom langflow.field_typing import NestedDict, Text\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n\n    field_order = [\n        \"max_tokens\",\n        \"model_kwargs\",\n        \"model_name\",\n        \"openai_api_base\",\n        \"openai_api_key\",\n        \"temperature\",\n        \"input_value\",\n        \"system_message\",\n        \"stream\",\n    ]\n\n    def build_config(self):\n        return {\n            \"input_value\": {\"display_name\": \"Input\"},\n            \"max_tokens\": {\n                \"display_name\": \"Max Tokens\",\n                \"advanced\": True,\n            },\n            \"model_kwargs\": {\n                \"display_name\": \"Model Kwargs\",\n                \"advanced\": True,\n            },\n            \"model_name\": {\n                \"display_name\": \"Model Name\",\n                \"advanced\": False,\n                \"options\": MODEL_NAMES,\n                \"value\": \"gpt-4-turbo-preview\",\n            },\n            \"openai_api_base\": {\n                \"display_name\": \"OpenAI API Base\",\n                \"advanced\": True,\n                \"info\": (\n                    \"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\\n\\n\"\n                    \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\"\n                ),\n            },\n            \"openai_api_key\": {\n                \"display_name\": \"OpenAI API Key\",\n                \"info\": \"The OpenAI API Key to use for the OpenAI model.\",\n                \"advanced\": False,\n                \"password\": True,\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"advanced\": False,\n                \"value\": 0.1,\n            },\n            \"stream\": {\n                \"display_name\": \"Stream\",\n                \"info\": STREAM_INFO_TEXT,\n                \"advanced\": True,\n            },\n            \"system_message\": {\n                \"display_name\": \"System Message\",\n                \"info\": \"System message to pass to the model.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Text,\n        openai_api_key: str,\n        temperature: float,\n        model_name: str,\n        max_tokens: Optional[int] = 256,\n        model_kwargs: NestedDict = {},\n        openai_api_base: Optional[str] = None,\n        stream: bool = False,\n        system_message: Optional[str] = None,\n    ) -> Text:\n        if not openai_api_base:\n            openai_api_base = \"https://api.openai.com/v1\"\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n\n        output = ChatOpenAI(\n            max_tokens=max_tokens,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature,\n        )\n\n        return self.get_chat_result(output, stream, input_value, system_message)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "max_tokens": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 256,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "max_tokens",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model_kwargs": {
                "type": "NestedDict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": {},
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "model_kwargs",
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model_name": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "value": "gpt-4-turbo-preview",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "name": "model_name",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": ["Text"]
              },
              "openai_api_base": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "openai_api_base",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\n\nYou can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "load_from_db": false,
                "title_case": false,
                "input_types": ["Text"]
              },
              "openai_api_key": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": true,
                "name": "openai_api_key",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "load_from_db": false,
                "title_case": false,
                "input_types": ["Text"],
                "value": ""
              },
              "stream": {
                "type": "bool",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "stream",
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "load_from_db": false,
                "title_case": false
              },
              "system_message": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "system_message",
                "display_name": "System Message",
                "advanced": true,
                "dynamic": false,
                "info": "System message to pass to the model.",
                "load_from_db": false,
                "title_case": false,
                "input_types": ["Text"]
              },
              "temperature": {
                "type": "float",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 0.1,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "temperature",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "rangeSpec": {
                  "step_type": "float",
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "load_from_db": false,
                "title_case": false
              },
              "_type": "CustomComponent"
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": ["str", "Text", "object"],
            "display_name": "OpenAI",
            "documentation": "",
            "custom_fields": {
              "input_value": null,
              "openai_api_key": null,
              "temperature": null,
              "model_name": null,
              "max_tokens": null,
              "model_kwargs": null,
              "openai_api_base": null,
              "stream": null,
              "system_message": null
            },
            "output_types": ["Text"],
            "field_formatters": {},
            "frozen": false,
            "field_order": [
              "max_tokens",
              "model_kwargs",
              "model_name",
              "openai_api_base",
              "openai_api_key",
              "temperature",
              "input_value",
              "system_message",
              "stream"
            ],
            "beta": false
          },
          "id": "OpenAIModel-uYXZJ"
        },
        "selected": false,
        "width": 384,
        "height": 565,
        "positionAbsolute": {
          "x": 2925.784767523062,
          "y": 933.6465680967775
        },
        "dragging": false
      },
      {
        "id": "TextOutput-MUDOR",
        "type": "genericNode",
        "position": {
          "x": 4446.064323520379,
          "y": 633.833297518702
        },
        "data": {
          "type": "TextOutput",
          "node": {
            "template": {
              "input_value": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "input_value",
                "display_name": "Value",
                "advanced": false,
                "input_types": ["Record", "Text"],
                "dynamic": false,
                "info": "Text or Record to be passed as output.",
                "load_from_db": false,
                "title_case": false
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional\n\nfrom langflow.base.io.text import TextComponent\nfrom langflow.field_typing import Text\n\n\nclass TextOutput(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Value\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as output.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(self, input_value: Optional[Text] = \"\", record_template: str = \"\") -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "record_template": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "record_template",
                "display_name": "Record Template",
                "advanced": true,
                "dynamic": false,
                "info": "Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.",
                "load_from_db": false,
                "title_case": false,
                "input_types": ["Text"]
              },
              "_type": "CustomComponent"
            },
            "description": "Display a text output in the Playground.",
            "icon": "type",
            "base_classes": ["str", "Text", "object"],
            "display_name": "Second Prompt",
            "documentation": "",
            "custom_fields": {
              "input_value": null,
              "record_template": null
            },
            "output_types": ["Text"],
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false
          },
          "id": "TextOutput-MUDOR"
        },
        "selected": false,
        "width": 384,
        "height": 290,
        "dragging": false,
        "positionAbsolute": {
          "x": 4446.064323520379,
          "y": 633.833297518702
        }
      },
      {
        "id": "OpenAIModel-XawYB",
        "type": "genericNode",
        "position": {
          "x": 4500.152018344182,
          "y": 1027.7382026227656
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "input_value": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "input_value",
                "display_name": "Input",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": ["Text"]
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import MODEL_NAMES\nfrom langflow.field_typing import NestedDict, Text\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n\n    field_order = [\n        \"max_tokens\",\n        \"model_kwargs\",\n        \"model_name\",\n        \"openai_api_base\",\n        \"openai_api_key\",\n        \"temperature\",\n        \"input_value\",\n        \"system_message\",\n        \"stream\",\n    ]\n\n    def build_config(self):\n        return {\n            \"input_value\": {\"display_name\": \"Input\"},\n            \"max_tokens\": {\n                \"display_name\": \"Max Tokens\",\n                \"advanced\": True,\n            },\n            \"model_kwargs\": {\n                \"display_name\": \"Model Kwargs\",\n                \"advanced\": True,\n            },\n            \"model_name\": {\n                \"display_name\": \"Model Name\",\n                \"advanced\": False,\n                \"options\": MODEL_NAMES,\n                \"value\": \"gpt-4-turbo-preview\",\n            },\n            \"openai_api_base\": {\n                \"display_name\": \"OpenAI API Base\",\n                \"advanced\": True,\n                \"info\": (\n                    \"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\\n\\n\"\n                    \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\"\n                ),\n            },\n            \"openai_api_key\": {\n                \"display_name\": \"OpenAI API Key\",\n                \"info\": \"The OpenAI API Key to use for the OpenAI model.\",\n                \"advanced\": False,\n                \"password\": True,\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"advanced\": False,\n                \"value\": 0.1,\n            },\n            \"stream\": {\n                \"display_name\": \"Stream\",\n                \"info\": STREAM_INFO_TEXT,\n                \"advanced\": True,\n            },\n            \"system_message\": {\n                \"display_name\": \"System Message\",\n                \"info\": \"System message to pass to the model.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Text,\n        openai_api_key: str,\n        temperature: float,\n        model_name: str,\n        max_tokens: Optional[int] = 256,\n        model_kwargs: NestedDict = {},\n        openai_api_base: Optional[str] = None,\n        stream: bool = False,\n        system_message: Optional[str] = None,\n    ) -> Text:\n        if not openai_api_base:\n            openai_api_base = \"https://api.openai.com/v1\"\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n\n        output = ChatOpenAI(\n            max_tokens=max_tokens,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature,\n        )\n\n        return self.get_chat_result(output, stream, input_value, system_message)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "max_tokens": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 256,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "max_tokens",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model_kwargs": {
                "type": "NestedDict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": {},
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "model_kwargs",
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model_name": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "value": "gpt-4-turbo-preview",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "name": "model_name",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": ["Text"]
              },
              "openai_api_base": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "openai_api_base",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\n\nYou can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "load_from_db": false,
                "title_case": false,
                "input_types": ["Text"]
              },
              "openai_api_key": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": true,
                "name": "openai_api_key",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "load_from_db": false,
                "title_case": false,
                "input_types": ["Text"],
                "value": ""
              },
              "stream": {
                "type": "bool",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "stream",
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "load_from_db": false,
                "title_case": false
              },
              "system_message": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "system_message",
                "display_name": "System Message",
                "advanced": true,
                "dynamic": false,
                "info": "System message to pass to the model.",
                "load_from_db": false,
                "title_case": false,
                "input_types": ["Text"]
              },
              "temperature": {
                "type": "float",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 0.1,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "temperature",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "rangeSpec": {
                  "step_type": "float",
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "load_from_db": false,
                "title_case": false
              },
              "_type": "CustomComponent"
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": ["str", "Text", "object"],
            "display_name": "OpenAI",
            "documentation": "",
            "custom_fields": {
              "input_value": null,
              "openai_api_key": null,
              "temperature": null,
              "model_name": null,
              "max_tokens": null,
              "model_kwargs": null,
              "openai_api_base": null,
              "stream": null,
              "system_message": null
            },
            "output_types": ["Text"],
            "field_formatters": {},
            "frozen": false,
            "field_order": [
              "max_tokens",
              "model_kwargs",
              "model_name",
              "openai_api_base",
              "openai_api_key",
              "temperature",
              "input_value",
              "system_message",
              "stream"
            ],
            "beta": false
          },
          "id": "OpenAIModel-XawYB"
        },
        "selected": false,
        "width": 384,
        "height": 565,
        "positionAbsolute": {
          "x": 4500.152018344182,
          "y": 1027.7382026227656
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "TextInput-sptaH",
        "sourceHandle": "{baseClasses:[str,Text,object],dataType:TextInput,id:TextInput-sptaH}",
        "target": "Prompt-amqBu",
        "targetHandle": "{fieldName:document,id:Prompt-amqBu,inputTypes:[Document,BaseOutputParser,Record,Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "document",
            "id": "Prompt-amqBu",
            "inputTypes": ["Document", "BaseOutputParser", "Record", "Text"],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": ["str", "Text", "object"],
            "dataType": "TextInput",
            "id": "TextInput-sptaH"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900 stroke-connection",
        "id": "reactflow__edge-TextInput-sptaH{baseClasses:[str,Text,object],dataType:TextInput,id:TextInput-sptaH}-Prompt-amqBu{fieldName:document,id:Prompt-amqBu,inputTypes:[Document,BaseOutputParser,Record,Text],type:str}"
      },
      {
        "source": "Prompt-amqBu",
        "sourceHandle": "{baseClasses:[object,str,Text],dataType:Prompt,id:Prompt-amqBu}",
        "target": "TextOutput-2MS4a",
        "targetHandle": "{fieldName:input_value,id:TextOutput-2MS4a,inputTypes:[Record,Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "TextOutput-2MS4a",
            "inputTypes": ["Record", "Text"],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": ["object", "str", "Text"],
            "dataType": "Prompt",
            "id": "Prompt-amqBu"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900 stroke-connection",
        "id": "reactflow__edge-Prompt-amqBu{baseClasses:[object,str,Text],dataType:Prompt,id:Prompt-amqBu}-TextOutput-2MS4a{fieldName:input_value,id:TextOutput-2MS4a,inputTypes:[Record,Text],type:str}"
      },
      {
        "source": "Prompt-amqBu",
        "sourceHandle": "{baseClasses:[object,str,Text],dataType:Prompt,id:Prompt-amqBu}",
        "target": "OpenAIModel-uYXZJ",
        "targetHandle": "{fieldName:input_value,id:OpenAIModel-uYXZJ,inputTypes:[Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-uYXZJ",
            "inputTypes": ["Text"],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": ["object", "str", "Text"],
            "dataType": "Prompt",
            "id": "Prompt-amqBu"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900 stroke-connection",
        "id": "reactflow__edge-Prompt-amqBu{baseClasses:[object,str,Text],dataType:Prompt,id:Prompt-amqBu}-OpenAIModel-uYXZJ{fieldName:input_value,id:OpenAIModel-uYXZJ,inputTypes:[Text],type:str}"
      },
      {
        "source": "OpenAIModel-uYXZJ",
        "sourceHandle": "{baseClasses:[str,Text,object],dataType:OpenAIModel,id:OpenAIModel-uYXZJ}",
        "target": "Prompt-gTNiz",
        "targetHandle": "{fieldName:summary,id:Prompt-gTNiz,inputTypes:[Document,BaseOutputParser,Record,Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "summary",
            "id": "Prompt-gTNiz",
            "inputTypes": ["Document", "BaseOutputParser", "Record", "Text"],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": ["str", "Text", "object"],
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-uYXZJ"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900 stroke-connection",
        "id": "reactflow__edge-OpenAIModel-uYXZJ{baseClasses:[str,Text,object],dataType:OpenAIModel,id:OpenAIModel-uYXZJ}-Prompt-gTNiz{fieldName:summary,id:Prompt-gTNiz,inputTypes:[Document,BaseOutputParser,Record,Text],type:str}"
      },
      {
        "source": "OpenAIModel-uYXZJ",
        "sourceHandle": "{baseClasses:[str,Text,object],dataType:OpenAIModel,id:OpenAIModel-uYXZJ}",
        "target": "ChatOutput-EJkG3",
        "targetHandle": "{fieldName:input_value,id:ChatOutput-EJkG3,inputTypes:[Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-EJkG3",
            "inputTypes": ["Text"],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": ["str", "Text", "object"],
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-uYXZJ"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900 stroke-connection",
        "id": "reactflow__edge-OpenAIModel-uYXZJ{baseClasses:[str,Text,object],dataType:OpenAIModel,id:OpenAIModel-uYXZJ}-ChatOutput-EJkG3{fieldName:input_value,id:ChatOutput-EJkG3,inputTypes:[Text],type:str}"
      },
      {
        "source": "Prompt-gTNiz",
        "sourceHandle": "{baseClasses:[object,str,Text],dataType:Prompt,id:Prompt-gTNiz}",
        "target": "TextOutput-MUDOR",
        "targetHandle": "{fieldName:input_value,id:TextOutput-MUDOR,inputTypes:[Record,Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "TextOutput-MUDOR",
            "inputTypes": ["Record", "Text"],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": ["object", "str", "Text"],
            "dataType": "Prompt",
            "id": "Prompt-gTNiz"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900 stroke-connection",
        "id": "reactflow__edge-Prompt-gTNiz{baseClasses:[object,str,Text],dataType:Prompt,id:Prompt-gTNiz}-TextOutput-MUDOR{fieldName:input_value,id:TextOutput-MUDOR,inputTypes:[Record,Text],type:str}"
      },
      {
        "source": "Prompt-gTNiz",
        "sourceHandle": "{baseClasses:[object,str,Text],dataType:Prompt,id:Prompt-gTNiz}",
        "target": "OpenAIModel-XawYB",
        "targetHandle": "{fieldName:input_value,id:OpenAIModel-XawYB,inputTypes:[Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-XawYB",
            "inputTypes": ["Text"],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": ["object", "str", "Text"],
            "dataType": "Prompt",
            "id": "Prompt-gTNiz"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900 stroke-connection",
        "id": "reactflow__edge-Prompt-gTNiz{baseClasses:[object,str,Text],dataType:Prompt,id:Prompt-gTNiz}-OpenAIModel-XawYB{fieldName:input_value,id:OpenAIModel-XawYB,inputTypes:[Text],type:str}"
      },
      {
        "source": "OpenAIModel-XawYB",
        "sourceHandle": "{baseClasses:[str,Text,object],dataType:OpenAIModel,id:OpenAIModel-XawYB}",
        "target": "ChatOutput-DNmvg",
        "targetHandle": "{fieldName:input_value,id:ChatOutput-DNmvg,inputTypes:[Text],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-DNmvg",
            "inputTypes": ["Text"],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": ["str", "Text", "object"],
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-XawYB"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900 stroke-connection",
        "id": "reactflow__edge-OpenAIModel-XawYB{baseClasses:[str,Text,object],dataType:OpenAIModel,id:OpenAIModel-XawYB}-ChatOutput-DNmvg{fieldName:input_value,id:ChatOutput-DNmvg,inputTypes:[Text],type:str}"
      }
    ],
    "viewport": {
      "x": -383.7251879618552,
      "y": 69.19813933800037,
      "zoom": 0.3105753483695743
    }
  },
  "description": "The Prompt Chaining flow chains prompts with LLMs, refining outputs through iterative stages.",
  "name": "Prompt Chaining",
  "last_tested_version": "1.0.0a0",
  "is_component": false
}
