{
  "data": {
    "edges": [
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-DMJcY",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "LanguageModelComponent-v0TUF",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt-DMJcY{œdataTypeœ:œPromptœ,œidœ:œPrompt-DMJcYœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-LanguageModelComponent-v0TUF{œfieldNameœ:œinput_valueœ,œidœ:œLanguageModelComponent-v0TUFœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "Prompt-DMJcY",
        "sourceHandle": "{œdataTypeœ: œPromptœ, œidœ: œPrompt-DMJcYœ, œnameœ: œpromptœ, œoutput_typesœ: [œMessageœ]}",
        "target": "LanguageModelComponent-v0TUF",
        "targetHandle": "{œfieldNameœ: œinput_valueœ, œidœ: œLanguageModelComponent-v0TUFœ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-uW39E",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "LanguageModelComponent-v0TUF",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt-uW39E{œdataTypeœ:œPromptœ,œidœ:œPrompt-uW39Eœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-LanguageModelComponent-v0TUF{œfieldNameœ:œsystem_messageœ,œidœ:œLanguageModelComponent-v0TUFœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "Prompt-uW39E",
        "sourceHandle": "{œdataTypeœ: œPromptœ, œidœ: œPrompt-uW39Eœ, œnameœ: œpromptœ, œoutput_typesœ: [œMessageœ]}",
        "target": "LanguageModelComponent-v0TUF",
        "targetHandle": "{œfieldNameœ: œsystem_messageœ, œidœ: œLanguageModelComponent-v0TUFœ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LanguageModelComponent",
            "id": "LanguageModelComponent-v0TUF",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-yEaTG",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__LanguageModelComponent-v0TUF{œdataTypeœ:œLanguageModelComponentœ,œidœ:œLanguageModelComponent-v0TUFœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-yEaTG{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-yEaTGœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œstrœ}",
        "source": "LanguageModelComponent-v0TUF",
        "sourceHandle": "{œdataTypeœ: œLanguageModelComponentœ, œidœ: œLanguageModelComponent-v0TUFœ, œnameœ: œtext_outputœ, œoutput_typesœ: [œMessageœ]}",
        "target": "ChatOutput-yEaTG",
        "targetHandle": "{œfieldNameœ: œinput_valueœ, œidœ: œChatOutput-yEaTGœ, œinputTypesœ: [œDataœ, œDataFrameœ, œMessageœ], œtypeœ: œstrœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt",
          "id": "Prompt-DMJcY",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "product",
                "pain_points",
                "goals",
                "current_solutions",
                "target_audience",
                "expertise_level"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "field_order": [
              "template"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.4.2",
            "metadata": {
              "code_hash": "3bf0b511e227",
              "module": "langflow.components.prompts.prompt.PromptComponent"
            },
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "method": "build_prompt",
                "name": "prompt",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "current_solutions": {
                "advanced": false,
                "display_name": "current_solutions",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message",
                  "Text"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "current_solutions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "- Basic website blockers\n- Manual \"Do Not Disturb\" modes\n- Traditional time management apps\n- Paper planners and to-do lists\n- Pomodoro timer apps\n- Calendar blocking\n"
              },
              "expertise_level": {
                "advanced": false,
                "display_name": "expertise_level",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message",
                  "Text"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "expertise_level",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "Intermediate to Advanced - Users are familiar with basic productivity tools and concepts but seek more sophisticated solutions. They understand terms like \"deep work\" and \"time blocking\" and are comfortable adopting new technology that promises meaningful improvements to their workflow."
              },
              "goals": {
                "advanced": false,
                "display_name": "goals",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message",
                  "Text"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "goals",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "- Achieve longer periods of uninterrupted focus\n- Improve work efficiency and output quality\n- Develop sustainable productivity habits\n- Better manage time and energy levels\n- Reduce stress from digital overwhelm\n- Create more balanced workdays"
              },
              "pain_points": {
                "advanced": false,
                "display_name": "pain_points",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message",
                  "Text"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "pain_points",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "- Constant interruptions from notifications and social media\n- Difficulty maintaining sustained focus during deep work\n- Inconsistent productivity levels throughout the day\n- Struggle to build effective work routines\n- Time wasted switching between tasks\n- Burnout from poor work-life balance\n"
              },
              "product": {
                "advanced": false,
                "display_name": "product",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message",
                  "Text"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "product",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "FocusFlow - An AI-powered productivity app that automatically detects and blocks digital distractions while learning from user behavior to create personalized focus schedules. Features include smart notification management, work pattern analysis, and adaptive focus modes."
              },
              "target_audience": {
                "advanced": false,
                "display_name": "target_audience",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message",
                  "Text"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "target_audience",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "Knowledge workers aged 25-45, primarily working in tech, creative, or professional services. They are tech-savvy professionals who work remotely or in hybrid settings, earning $75,000+ annually. They value work-life balance and are willing to invest in tools that boost their productivity. Many are active on LinkedIn and tech-focused platforms, regularly consuming content about personal development and productivity."
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "Product:\n{product}\n \nPain Points:\n{pain_points}\n \nGoals:\n{goals}\n \nCurrent Solutions:\n{current_solutions}\n \nSpecific Target Audience:\n{target_audience}\n\nExpertise Level:\n{expertise_level}\n"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "selected_output": "prompt",
          "type": "Prompt"
        },
        "dragging": false,
        "height": 779,
        "id": "Prompt-DMJcY",
        "measured": {
          "height": 779,
          "width": 320
        },
        "position": {
          "x": 815.644070953848,
          "y": 116.56584278832369
        },
        "positionAbsolute": {
          "x": 816.9328565352126,
          "y": 189.70442453076902
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "note-pZHnX",
          "node": {
            "description": "## SEO Keyword Generator\n\nThis template creates strategic keywords based on your product and audience profile.\n\n### Prerequisites\n\n* [OpenAI API Key](https://platform.openai.com/)\n\n### Quickstart\n\n1. In the **Language Model** component, add your OpenAI API Key.\n\n2. In the **Prompt** component, complete the following fields. Optionally, just run the flow with the included example values.\n\n* Product Information\n*  Pain Points\n* Goals\n* Target Audience\n* Expertise Level\n* Review Output \n\n3. Open the **Playground**, and then click **Run Flow**. The LLM generates keywords based on your inputs.",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note"
        },
        "dragging": false,
        "height": 716,
        "id": "note-pZHnX",
        "measured": {
          "height": 716,
          "width": 568
        },
        "position": {
          "x": 147.91696397014965,
          "y": 259.0768584326721
        },
        "positionAbsolute": {
          "x": 221.74248905040588,
          "y": 363.5469410934121
        },
        "resizing": false,
        "selected": false,
        "style": {
          "height": 607,
          "width": 324
        },
        "type": "noteNode",
        "width": 568
      },
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt",
          "id": "Prompt-uW39E",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": []
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "field_order": [
              "template"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.4.2",
            "metadata": {
              "code_hash": "3bf0b511e227",
              "module": "langflow.components.prompts.prompt.PromptComponent"
            },
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "method": "build_prompt",
                "name": "prompt",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "You are a digital marketing strategist specialized in generating highly relevant, optimized keywords for a product’s specific target audience. Your task is to create a list of keywords that are not only attractive and impactful but also resonate with the needs and desires of the customers, capturing the core motivations driving them to seek a solution.\n\nBelow are details about the product, including its target audience, the pain points faced by this audience, and the current solutions they consider or use. Use this information to generate precise keywords that connect directly with the unique value of the product and with the customers' goals. Consider factors like the customer’s level of expertise and major market trends to create a powerful and well-grounded keyword list.\n\n### Product Information:\n- **Product:** – A brief description of the product, including what sets it apart in the market.\n- **Customer Pain Points:** – Specific pain points that the audience faces and that the product aims to address.\n- **Customer Goals:** – The primary goals and aspirations of the target audience that the product helps to achieve.\n- **Current Solutions Used:** – How the audience currently tries to address these pain points, including competitor solutions or alternatives.\n- **Specific Target Audience:** – A detailed description of the target audience, including demographics, interests, lifestyle, and behavioral profile.\n- **Customer Expertise Level:**– The level of familiarity or experience the audience has with similar or related solutions.\n\n### Guidelines for Keyword Generation:\n1. **Focus on Pain Points and Solutions**: Generate keywords that accurately reflect the customers’ pain points, clearly conveying how the product offers an effective and unique solution.\n2. **Emphasize Goals and Benefits**: Highlight keywords aligned with customer goals, emphasizing the positive impact and achievable results of the product.\n3. **Consider Competition and Differentiators**: Think about existing solutions and how the product stands out. Create keywords that emphasize differentiators and help the product stand out in a competitive landscape.\n4. **Tailor to Target Audience**: Use terms and phrases that resonate directly with the target audience’s profile, utilizing language and themes most appealing to this segment.\n5. **Customize to Expertise Level**: Adjust the complexity of the keywords according to the audience’s experience level, ensuring they are appealing and accessible.\n6. **Incorporate Market Trends**: Where possible, include keywords that reflect the latest trends in the sector, increasing the content’s relevance and timeliness.\n\n### Example Keyword Suggestions:\n- **For customer pain points:**  – Use keywords that reinforce customer pain points, making it clear how the product can be a solution.\n- **For goals and aspirations:**  – Keywords that symbolize the outcomes and goals desired by customers, such as ‘stress relief,’ ‘productivity boost.’\n- **For product differentiators:** – Keywords that contrast the product with current solutions, highlighting its unique advantages.\n\nFor each keyword generated, provide a brief explanation of how it connects with the product details and the target audience, ensuring the final list is powerful, strategic, and well-founded for maximum market impact."
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "selected_output": "prompt",
          "type": "Prompt"
        },
        "dragging": false,
        "height": 260,
        "id": "Prompt-uW39E",
        "measured": {
          "height": 260,
          "width": 320
        },
        "position": {
          "x": 813.5727530934735,
          "y": 991.0702563306074
        },
        "positionAbsolute": {
          "x": 813.5727530934735,
          "y": 991.0702563306074
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Display a chat message in the Playground.",
          "display_name": "Chat Output",
          "id": "ChatOutput-yEaTG",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.4.2",
            "metadata": {
              "code_hash": "4848ad3e35d5",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "orjson",
                    "version": "3.10.15"
                  },
                  {
                    "name": "fastapi",
                    "version": "0.119.1"
                  },
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 3
              },
              "module": "lfx.components.input_output.chat_output.ChatOutput"
            },
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean data before converting to string.",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom lfx.base.io.chat import ChatComponent\nfrom lfx.helpers.data import safe_convert\nfrom lfx.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.message import Message\nfrom lfx.schema.properties import Source\nfrom lfx.template.field.base import Output\nfrom lfx.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"context_id\",\n            display_name=\"Context ID\",\n            info=\"The context ID of the chat. Adds an extra layer to the local memory.\",\n            value=\"\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            advanced=True,\n            info=\"Whether to clean data before converting to string.\",\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, _, display_name, source_id = self.get_properties_from_source_component()\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.context_id = self.context_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            clean_data: bool = getattr(self, \"clean_data\", False)\n            return \"\\n\".join([safe_convert(item, clean_data=clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "context_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Context ID",
                "dynamic": false,
                "info": "The context ID of the chat. Adds an extra layer to the local memory.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "context_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "type": "ChatOutput"
        },
        "dragging": false,
        "height": 234,
        "id": "ChatOutput-yEaTG",
        "measured": {
          "height": 234,
          "width": 320
        },
        "position": {
          "x": 1598.2529634286327,
          "y": 623.4799714496987
        },
        "positionAbsolute": {
          "x": 1598.2529634286327,
          "y": 623.4799714496987
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "note-8FcOF",
          "node": {
            "description": "### 💡 Add your OpenAI API key here",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "transparent"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "id": "note-8FcOF",
        "measured": {
          "height": 324,
          "width": 324
        },
        "position": {
          "x": 1208.3032428372405,
          "y": 369.8385257208433
        },
        "selected": false,
        "type": "noteNode"
      },
      {
        "data": {
          "id": "LanguageModelComponent-v0TUF",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Runs a language model given a specified provider.",
            "display_name": "Language Model",
            "documentation": "https://docs.langflow.org/components-models",
            "edited": false,
            "field_order": [
              "model",
              "api_key",
              "input_value",
              "system_message",
              "stream",
              "temperature"
            ],
            "frozen": false,
            "icon": "brain-circuit",
            "legacy": false,
            "metadata": {
              "code_hash": "ce0b00e37a88",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "langchain_anthropic",
                    "version": "0.3.14"
                  },
                  {
                    "name": "langchain_ibm",
                    "version": "0.3.19"
                  },
                  {
                    "name": "langchain_ollama",
                    "version": "0.2.1"
                  },
                  {
                    "name": "langchain_openai",
                    "version": "0.3.23"
                  },
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 5
              },
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ],
              "module": "lfx.components.models.language_model.LanguageModelComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "method": "text_response",
                "name": "text_output",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "method": "build_model",
                "name": "model_output",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": true,
                "display_name": "API Key",
                "dynamic": false,
                "info": "Model Provider API key",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_anthropic import ChatAnthropic\nfrom langchain_ibm import ChatWatsonx\nfrom langchain_ollama import ChatOllama\nfrom langchain_openai import ChatOpenAI\n\nfrom lfx.base.models.anthropic_constants import ANTHROPIC_MODELS\nfrom lfx.base.models.google_generative_ai_constants import GOOGLE_GENERATIVE_AI_MODELS\nfrom lfx.base.models.google_generative_ai_model import ChatGoogleGenerativeAIFixed\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.base.models.openai_constants import OPENAI_CHAT_MODEL_NAMES, OPENAI_REASONING_MODEL_NAMES\nfrom lfx.base.models.unified_models import get_api_key_for_provider\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.inputs.inputs import BoolInput\nfrom lfx.io import MessageInput, ModelInput, MultilineInput, SecretStrInput, SliderInput\n\n# Mapping of class names to actual class objects\nMODEL_CLASSES = {\n    \"ChatOpenAI\": ChatOpenAI,\n    \"ChatAnthropic\": ChatAnthropic,\n    \"ChatGoogleGenerativeAIFixed\": ChatGoogleGenerativeAIFixed,\n    \"ChatOllama\": ChatOllama,\n    \"ChatWatsonx\": ChatWatsonx,\n}\n\n\ndef _get_language_model_options() -> list[dict[str, Any]]:\n    \"\"\"Return a list of available language model providers with their configuration.\"\"\"\n    # OpenAI models\n    openai_options = [\n        {\n            \"name\": model_name,\n            \"icon\": \"OpenAI\",\n            \"category\": \"OpenAI\",\n            \"provider\": \"OpenAI\",\n            \"metadata\": {\n                \"context_length\": 128000,\n                \"model_class\": \"ChatOpenAI\",\n                \"model_name_param\": \"model\",\n                \"api_key_param\": \"api_key\",\n                \"reasoning_models\": OPENAI_REASONING_MODEL_NAMES,\n            },\n        }\n        for model_name in OPENAI_CHAT_MODEL_NAMES\n    ]\n\n    # Anthropic models\n    anthropic_options = [\n        {\n            \"name\": model_name,\n            \"icon\": \"Anthropic\",\n            \"category\": \"Anthropic\",\n            \"provider\": \"Anthropic\",\n            \"metadata\": {\n                \"context_length\": 200000,\n                \"model_class\": \"ChatAnthropic\",\n                \"model_name_param\": \"model\",\n                \"api_key_param\": \"api_key\",\n            },\n        }\n        for model_name in ANTHROPIC_MODELS\n    ]\n\n    # Google models\n    google_options = [\n        {\n            \"name\": model_name,\n            \"icon\": \"GoogleGenerativeAI\",\n            \"category\": \"Google\",\n            \"provider\": \"Google\",\n            \"metadata\": {\n                \"context_length\": 32768,\n                \"model_class\": \"ChatGoogleGenerativeAIFixed\",\n                \"model_name_param\": \"model\",\n                \"api_key_param\": \"google_api_key\",\n            },\n        }\n        for model_name in GOOGLE_GENERATIVE_AI_MODELS\n    ]\n\n    # Ollama models (local)\n    ollama_options = [\n        {\n            \"name\": \"ChatOllama\",\n            \"icon\": \"Ollama\",\n            \"category\": \"Ollama\",\n            \"provider\": \"Ollama\",\n            \"metadata\": {\n                \"context_length\": 8192,  # Varies by model\n                \"model_class\": \"ChatOllama\",\n                \"model_name_param\": \"model\",\n                \"base_url_param\": \"base_url\",\n            },\n        }\n    ]\n\n    # WatsonX models\n    watsonx_options = [\n        {\n            \"name\": \"ChatWatsonx\",\n            \"icon\": \"WatsonxAI\",\n            \"category\": \"IBM WatsonX\",\n            \"provider\": \"IBM WatsonX\",\n            \"metadata\": {\n                \"context_length\": 8192,  # Varies by model\n                \"model_class\": \"ChatWatsonx\",\n                \"model_name_param\": \"model_id\",\n                \"api_key_param\": \"apikey\",\n                \"url_param\": \"url\",\n                \"project_id_param\": \"project_id\",\n            },\n        }\n    ]\n\n    # Combine all options and return\n    return openai_options + anthropic_options + google_options + ollama_options + watsonx_options\n\n\n# Compute model options once at module level\n_MODEL_OPTIONS = _get_language_model_options()\n_PROVIDERS = [provider[\"provider\"] for provider in _MODEL_OPTIONS]\n\n\nclass LanguageModelComponent(LCModelComponent):\n    display_name = \"Language Model\"\n    description = \"Runs a language model given a specified provider.\"\n    documentation: str = \"https://docs.langflow.org/components-models\"\n    icon = \"brain-circuit\"\n    category = \"models\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        ModelInput(\n            name=\"model\",\n            display_name=\"Language Model\",\n            options=_MODEL_OPTIONS,\n            providers=_PROVIDERS,\n            info=\"Select your model provider\",\n            real_time_refresh=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"API Key\",\n            info=\"Model Provider API key\",\n            real_time_refresh=True,\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"The input text to send to the model\",\n        ),\n        MultilineInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"A system message that helps set the behavior of the assistant\",\n            advanced=False,\n        ),\n        BoolInput(\n            name=\"stream\",\n            display_name=\"Stream\",\n            info=\"Whether to stream the response\",\n            value=False,\n            advanced=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            info=\"Controls randomness in responses\",\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:\n        # Safely extract model configuration\n        if not self.model or not isinstance(self.model, list) or len(self.model) == 0:\n            msg = \"A model selection is required\"\n            raise ValueError(msg)\n\n        model = self.model[0]\n        temperature = self.temperature\n        stream = self.stream\n\n        # Extract model configuration from metadata\n        model_name = model.get(\"name\")\n        provider = model.get(\"provider\")\n        metadata = model.get(\"metadata\", {})\n\n        # Get model class and parameter names from metadata\n        api_key_param = metadata.get(\"api_key_param\", \"api_key\")\n\n        # Get API key from user input or global variables\n        api_key = get_api_key_for_provider(self.user_id, provider, self.api_key)\n\n        # Validate API key (Ollama doesn't require one)\n        if not api_key and provider != \"Ollama\":\n            msg = (\n                f\"{provider} API key is required when using {provider} provider. \"\n                f\"Please provide it in the component or configure it globally as \"\n                f\"{provider.upper().replace(' ', '_')}_API_KEY.\"\n            )\n            raise ValueError(msg)\n\n        # Get model class from metadata\n        model_class = MODEL_CLASSES.get(metadata.get(\"model_class\"))\n        if model_class is None:\n            msg = f\"No model class defined for {model_name}\"\n            raise ValueError(msg)\n        model_name_param = metadata.get(\"model_name_param\", \"model\")\n\n        # Check if this is a reasoning model that doesn't support temperature\n        reasoning_models = metadata.get(\"reasoning_models\", [])\n        if model_name in reasoning_models:\n            temperature = None\n\n        # Build kwargs dynamically\n        kwargs = {\n            model_name_param: model_name,\n            \"streaming\": stream,\n            api_key_param: api_key,\n        }\n\n        if temperature is not None:\n            kwargs[\"temperature\"] = temperature\n\n        return model_class(**kwargs)\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input text to send to the model",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "model": {
                "_input_type": "ModelInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "Select your model provider",
                "list": false,
                "list_add_label": "Add More",
                "model_type": "language",
                "name": "model",
                "options": [
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5",
                        "gpt-5-mini",
                        "gpt-5-nano",
                        "gpt-5-chat-latest",
                        "o1",
                        "o3-mini",
                        "o3",
                        "o3-pro",
                        "o4-mini",
                        "o4-mini-high"
                      ]
                    },
                    "name": "gpt-4o-mini",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5",
                        "gpt-5-mini",
                        "gpt-5-nano",
                        "gpt-5-chat-latest",
                        "o1",
                        "o3-mini",
                        "o3",
                        "o3-pro",
                        "o4-mini",
                        "o4-mini-high"
                      ]
                    },
                    "name": "gpt-4o",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5",
                        "gpt-5-mini",
                        "gpt-5-nano",
                        "gpt-5-chat-latest",
                        "o1",
                        "o3-mini",
                        "o3",
                        "o3-pro",
                        "o4-mini",
                        "o4-mini-high"
                      ]
                    },
                    "name": "gpt-4.1",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5",
                        "gpt-5-mini",
                        "gpt-5-nano",
                        "gpt-5-chat-latest",
                        "o1",
                        "o3-mini",
                        "o3",
                        "o3-pro",
                        "o4-mini",
                        "o4-mini-high"
                      ]
                    },
                    "name": "gpt-4.1-mini",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5",
                        "gpt-5-mini",
                        "gpt-5-nano",
                        "gpt-5-chat-latest",
                        "o1",
                        "o3-mini",
                        "o3",
                        "o3-pro",
                        "o4-mini",
                        "o4-mini-high"
                      ]
                    },
                    "name": "gpt-4.1-nano",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5",
                        "gpt-5-mini",
                        "gpt-5-nano",
                        "gpt-5-chat-latest",
                        "o1",
                        "o3-mini",
                        "o3",
                        "o3-pro",
                        "o4-mini",
                        "o4-mini-high"
                      ]
                    },
                    "name": "gpt-4-turbo",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5",
                        "gpt-5-mini",
                        "gpt-5-nano",
                        "gpt-5-chat-latest",
                        "o1",
                        "o3-mini",
                        "o3",
                        "o3-pro",
                        "o4-mini",
                        "o4-mini-high"
                      ]
                    },
                    "name": "gpt-4-turbo-preview",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5",
                        "gpt-5-mini",
                        "gpt-5-nano",
                        "gpt-5-chat-latest",
                        "o1",
                        "o3-mini",
                        "o3",
                        "o3-pro",
                        "o4-mini",
                        "o4-mini-high"
                      ]
                    },
                    "name": "gpt-4",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5",
                        "gpt-5-mini",
                        "gpt-5-nano",
                        "gpt-5-chat-latest",
                        "o1",
                        "o3-mini",
                        "o3",
                        "o3-pro",
                        "o4-mini",
                        "o4-mini-high"
                      ]
                    },
                    "name": "gpt-3.5-turbo",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 200000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-sonnet-4-5-20250929",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 200000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-opus-4-1-20250805",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 200000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-opus-4-20250514",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 200000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-sonnet-4-20250514",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 200000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-3-7-sonnet-latest",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 200000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-3-5-sonnet-latest",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 200000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-3-5-haiku-latest",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 200000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-3-opus-latest",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Google",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 32768,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-1.5-pro",
                    "provider": "Google"
                  },
                  {
                    "category": "Google",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 32768,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-1.5-flash",
                    "provider": "Google"
                  },
                  {
                    "category": "Google",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 32768,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-1.5-flash-8b",
                    "provider": "Google"
                  },
                  {
                    "category": "Google",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 32768,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-2.5-pro",
                    "provider": "Google"
                  },
                  {
                    "category": "Google",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 32768,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-2.5-flash",
                    "provider": "Google"
                  },
                  {
                    "category": "Google",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 32768,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-2.5-flash-lite",
                    "provider": "Google"
                  },
                  {
                    "category": "Google",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 32768,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-2.0-flash-lite",
                    "provider": "Google"
                  },
                  {
                    "category": "Google",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 32768,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-2.0-flash",
                    "provider": "Google"
                  },
                  {
                    "category": "Google",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 32768,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-exp-1206",
                    "provider": "Google"
                  },
                  {
                    "category": "Google",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 32768,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemini-2.0-flash-thinking-exp-01-21",
                    "provider": "Google"
                  },
                  {
                    "category": "Google",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 32768,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "learnlm-1.5-pro-experimental",
                    "provider": "Google"
                  },
                  {
                    "category": "Google",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 32768,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemma-2-2b",
                    "provider": "Google"
                  },
                  {
                    "category": "Google",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 32768,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemma-2-9b",
                    "provider": "Google"
                  },
                  {
                    "category": "Google",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "api_key_param": "google_api_key",
                      "context_length": 32768,
                      "model_class": "ChatGoogleGenerativeAIFixed",
                      "model_name_param": "model"
                    },
                    "name": "gemma-2-27b",
                    "provider": "Google"
                  },
                  {
                    "category": "Ollama",
                    "icon": "Ollama",
                    "metadata": {
                      "base_url_param": "base_url",
                      "context_length": 8192,
                      "model_class": "ChatOllama",
                      "model_name_param": "model"
                    },
                    "name": "ChatOllama",
                    "provider": "Ollama"
                  },
                  {
                    "category": "IBM WatsonX",
                    "icon": "WatsonxAI",
                    "metadata": {
                      "api_key_param": "apikey",
                      "context_length": 8192,
                      "model_class": "ChatWatsonx",
                      "model_name_param": "model_id",
                      "project_id_param": "project_id",
                      "url_param": "url"
                    },
                    "name": "ChatWatsonx",
                    "provider": "IBM WatsonX"
                  }
                ],
                "placeholder": "",
                "providers": [
                  "OpenAI",
                  "OpenAI",
                  "OpenAI",
                  "OpenAI",
                  "OpenAI",
                  "OpenAI",
                  "OpenAI",
                  "OpenAI",
                  "OpenAI",
                  "Anthropic",
                  "Anthropic",
                  "Anthropic",
                  "Anthropic",
                  "Anthropic",
                  "Anthropic",
                  "Anthropic",
                  "Anthropic",
                  "Google",
                  "Google",
                  "Google",
                  "Google",
                  "Google",
                  "Google",
                  "Google",
                  "Google",
                  "Google",
                  "Google",
                  "Google",
                  "Google",
                  "Google",
                  "Google",
                  "Ollama",
                  "IBM WatsonX"
                ],
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "model",
                "value": ""
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Whether to stream the response",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "A system message that helps set the behavior of the assistant",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness in responses",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              }
            },
            "tool_mode": false
          },
          "selected_output": "text_output",
          "showNode": true,
          "type": "LanguageModelComponent"
        },
        "dragging": false,
        "id": "LanguageModelComponent-v0TUF",
        "measured": {
          "height": 369,
          "width": 320
        },
        "position": {
          "x": 1207.0370518175405,
          "y": 422.53292270683676
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": 48.68939950323727,
      "y": -23.36004753561133,
      "zoom": 0.5908002515580706
    }
  },
  "description": "Generates targeted SEO keywords based on product information, pain points, and customer profiles for strategic marketing.",
  "endpoint_name": null,
  "id": "4195859a-b59d-4f51-9c87-5f92c4629ef2",
  "is_component": false,
  "last_tested_version": "1.6.4",
  "name": "SEO Keyword Generator",
  "tags": [
    "chatbots",
    "assistants"
  ]
}