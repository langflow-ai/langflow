{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-eLatG",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "context",
            "id": "Prompt-MP8Gr",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParseData-eLatG{œdataTypeœ:œParseDataœ,œidœ:œParseData-eLatGœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-MP8Gr{œfieldNameœ:œcontextœ,œidœ:œPrompt-MP8Grœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "source": "ParseData-eLatG",
        "sourceHandle": "{œdataTypeœ: œParseDataœ, œidœ: œParseData-eLatGœ, œnameœ: œtextœ, œoutput_typesœ: [œMessageœ]}",
        "target": "Prompt-MP8Gr",
        "targetHandle": "{œfieldNameœ: œcontextœ, œidœ: œPrompt-MP8Grœ, œinputTypesœ: [œMessageœ, œTextœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-L1dXB",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "question",
            "id": "Prompt-MP8Gr",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ChatInput-L1dXB{œdataTypeœ:œChatInputœ,œidœ:œChatInput-L1dXBœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Prompt-MP8Gr{œfieldNameœ:œquestionœ,œidœ:œPrompt-MP8Grœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "source": "ChatInput-L1dXB",
        "sourceHandle": "{œdataTypeœ: œChatInputœ, œidœ: œChatInput-L1dXBœ, œnameœ: œmessageœ, œoutput_typesœ: [œMessageœ]}",
        "target": "Prompt-MP8Gr",
        "targetHandle": "{œfieldNameœ: œquestionœ, œidœ: œPrompt-MP8Grœ, œinputTypesœ: [œMessageœ, œTextœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-L1dXB",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "search_query",
            "id": "AzureSearchVectorStoreComponent-N4BR1",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ChatInput-L1dXB{œdataTypeœ:œChatInputœ,œidœ:œChatInput-L1dXBœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-AzureSearchVectorStoreComponent-N4BR1{œfieldNameœ:œsearch_queryœ,œidœ:œAzureSearchVectorStoreComponent-N4BR1œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "ChatInput-L1dXB",
        "sourceHandle": "{œdataTypeœ: œChatInputœ, œidœ: œChatInput-L1dXBœ, œnameœ: œmessageœ, œoutput_typesœ: [œMessageœ]}",
        "target": "AzureSearchVectorStoreComponent-N4BR1",
        "targetHandle": "{œfieldNameœ: œsearch_queryœ, œidœ: œAzureSearchVectorStoreComponent-N4BR1œ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "SplitText",
            "id": "SplitText-mcBRT",
            "name": "chunks",
            "output_types": []
          },
          "targetHandle": {
            "fieldName": "ingest_data",
            "id": "AzureSearchVectorStoreComponent-RGl0S",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-SplitText-mcBRT{œdataTypeœ:œSplitTextœ,œidœ:œSplitText-mcBRTœ,œnameœ:œchunksœ,œoutput_typesœ:[œDataœ]}-AzureSearchVectorStoreComponent-RGl0S{œfieldNameœ:œingest_dataœ,œidœ:œAzureSearchVectorStoreComponent-RGl0Sœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "source": "SplitText-mcBRT",
        "sourceHandle": "{œdataTypeœ: œSplitTextœ, œidœ: œSplitText-mcBRTœ, œnameœ: œchunksœ, œoutput_typesœ: []}",
        "target": "AzureSearchVectorStoreComponent-RGl0S",
        "targetHandle": "{œfieldNameœ: œingest_dataœ, œidœ: œAzureSearchVectorStoreComponent-RGl0Sœ, œinputTypesœ: [œDataœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "AzureOpenAIEmbeddings",
            "id": "AzureOpenAIEmbeddings-D6JrE",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          },
          "targetHandle": {
            "fieldName": "embedding",
            "id": "AzureSearchVectorStoreComponent-RGl0S",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-AzureOpenAIEmbeddings-D6JrE{œdataTypeœ:œAzureOpenAIEmbeddingsœ,œidœ:œAzureOpenAIEmbeddings-D6JrEœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-AzureSearchVectorStoreComponent-RGl0S{œfieldNameœ:œembeddingœ,œidœ:œAzureSearchVectorStoreComponent-RGl0Sœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "source": "AzureOpenAIEmbeddings-D6JrE",
        "sourceHandle": "{œdataTypeœ: œAzureOpenAIEmbeddingsœ, œidœ: œAzureOpenAIEmbeddings-D6JrEœ, œnameœ: œembeddingsœ, œoutput_typesœ: [œEmbeddingsœ]}",
        "target": "AzureSearchVectorStoreComponent-RGl0S",
        "targetHandle": "{œfieldNameœ: œembeddingœ, œidœ: œAzureSearchVectorStoreComponent-RGl0Sœ, œinputTypesœ: [œEmbeddingsœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "AzureOpenAIEmbeddings",
            "id": "AzureOpenAIEmbeddings-s8MJB",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          },
          "targetHandle": {
            "fieldName": "embedding",
            "id": "AzureSearchVectorStoreComponent-N4BR1",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-AzureOpenAIEmbeddings-s8MJB{œdataTypeœ:œAzureOpenAIEmbeddingsœ,œidœ:œAzureOpenAIEmbeddings-s8MJBœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-AzureSearchVectorStoreComponent-N4BR1{œfieldNameœ:œembeddingœ,œidœ:œAzureSearchVectorStoreComponent-N4BR1œ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "source": "AzureOpenAIEmbeddings-s8MJB",
        "sourceHandle": "{œdataTypeœ: œAzureOpenAIEmbeddingsœ, œidœ: œAzureOpenAIEmbeddings-s8MJBœ, œnameœ: œembeddingsœ, œoutput_typesœ: [œEmbeddingsœ]}",
        "target": "AzureSearchVectorStoreComponent-N4BR1",
        "targetHandle": "{œfieldNameœ: œembeddingœ, œidœ: œAzureSearchVectorStoreComponent-N4BR1œ, œinputTypesœ: [œEmbeddingsœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-MP8Gr",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "AzureOpenAIModel-0OM2g",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt-MP8Gr{œdataTypeœ:œPromptœ,œidœ:œPrompt-MP8Grœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-AzureOpenAIModel-0OM2g{œfieldNameœ:œinput_valueœ,œidœ:œAzureOpenAIModel-0OM2gœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "Prompt-MP8Gr",
        "sourceHandle": "{œdataTypeœ: œPromptœ, œidœ: œPrompt-MP8Grœ, œnameœ: œpromptœ, œoutput_typesœ: [œMessageœ]}",
        "target": "AzureOpenAIModel-0OM2g",
        "targetHandle": "{œfieldNameœ: œinput_valueœ, œidœ: œAzureOpenAIModel-0OM2gœ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "AzureOpenAIModel",
            "id": "AzureOpenAIModel-0OM2g",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-3APoI",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-AzureOpenAIModel-0OM2g{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-0OM2gœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-3APoI{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-3APoIœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "AzureOpenAIModel-0OM2g",
        "sourceHandle": "{œdataTypeœ: œAzureOpenAIModelœ, œidœ: œAzureOpenAIModel-0OM2gœ, œnameœ: œtext_outputœ, œoutput_typesœ: [œMessageœ]}",
        "target": "ChatOutput-3APoI",
        "targetHandle": "{œfieldNameœ: œinput_valueœ, œidœ: œChatOutput-3APoIœ, œinputTypesœ: [œDataœ, œDataFrameœ, œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "AzureSearchVectorStoreComponent",
            "id": "AzureSearchVectorStoreComponent-N4BR1",
            "name": "search_results",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-eLatG",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-AzureSearchVectorStoreComponent-N4BR1{œdataTypeœ:œAzureSearchVectorStoreComponentœ,œidœ:œAzureSearchVectorStoreComponent-N4BR1œ,œnameœ:œsearch_resultsœ,œoutput_typesœ:[œDataœ]}-ParseData-eLatG{œfieldNameœ:œdataœ,œidœ:œParseData-eLatGœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "source": "AzureSearchVectorStoreComponent-N4BR1",
        "sourceHandle": "{œdataTypeœ: œAzureSearchVectorStoreComponentœ, œidœ: œAzureSearchVectorStoreComponent-N4BR1œ, œnameœ: œsearch_resultsœ, œoutput_typesœ: [œDataœ]}",
        "target": "ParseData-eLatG",
        "targetHandle": "{œfieldNameœ: œdataœ, œidœ: œParseData-eLatGœ, œinputTypesœ: [œDataœ], œtypeœ: œotherœ}"
      },
      {
        "data": {
          "sourceHandle": {
            "dataType": "FileReader",
            "id": "FileReader-3TisE",
            "name": "data",
            "output_types": []
          },
          "targetHandle": {
            "fieldName": "data_inputs",
            "id": "SplitText-mcBRT",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__FileReader-3TisE{œdataTypeœ:œFileReaderœ,œidœ:œFileReader-3TisEœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-SplitText-mcBRT{œfieldNameœ:œdata_inputsœ,œidœ:œSplitText-mcBRTœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "source": "FileReader-3TisE",
        "sourceHandle": "{œdataTypeœ: œFileReaderœ, œidœ: œFileReader-3TisEœ, œnameœ: œdataœ, œoutput_typesœ: []}",
        "target": "SplitText-mcBRT",
        "targetHandle": "{œfieldNameœ: œdata_inputsœ, œidœ: œSplitText-mcBRTœ, œinputTypesœ: [œDataœ, œDataFrameœ, œMessageœ], œtypeœ: œotherœ}"
      },
      {
        "data": {
          "sourceHandle": {
            "dataType": "BlobStorage",
            "id": "BlobStorage-n6pLf",
            "name": "file_path",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "file_path",
            "id": "FileReader-3TisE",
            "inputTypes": [
              "Data",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__BlobStorage-n6pLf{œdataTypeœ:œBlobStorageœ,œidœ:œBlobStorage-n6pLfœ,œnameœ:œfile_pathœ,œoutput_typesœ:[œDataœ]}-FileReader-3TisE{œfieldNameœ:œfile_pathœ,œidœ:œFileReader-3TisEœ,œinputTypesœ:[œDataœ,œMessageœ],œtypeœ:œotherœ}",
        "source": "BlobStorage-n6pLf",
        "sourceHandle": "{œdataTypeœ: œBlobStorageœ, œidœ: œBlobStorage-n6pLfœ, œnameœ: œfile_pathœ, œoutput_typesœ: [œDataœ]}",
        "target": "FileReader-3TisE",
        "targetHandle": "{œfieldNameœ: œfile_pathœ, œidœ: œFileReader-3TisEœ, œinputTypesœ: [œDataœ, œMessageœ], œtypeœ: œotherœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "description": "Get chat inputs from the Playground.",
          "display_name": "Chat Input",
          "id": "ChatInput-L1dXB",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {
              "code_hash": "46a90558cb44",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 1
              },
              "module": "lfx.components.input_output.chat.ChatInput"
            },
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chat Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from lfx.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom lfx.base.io.chat import ChatComponent\nfrom lfx.inputs.inputs import BoolInput\nfrom lfx.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom lfx.schema.message import Message\nfrom lfx.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-input\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n            temp_file=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Chat Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "csv",
                  "json",
                  "pdf",
                  "txt",
                  "md",
                  "mdx",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "advanced": false,
                "display_name": "Input Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "What is the document is about?"
              },
              "sender": {
                "advanced": true,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            }
          },
          "type": "ChatInput"
        },
        "dragging": false,
        "height": 234,
        "id": "ChatInput-L1dXB",
        "measured": {
          "height": 234,
          "width": 320
        },
        "position": {
          "x": 644.4813529866299,
          "y": 448.0418256008611
        },
        "positionAbsolute": {
          "x": 743.9745420290319,
          "y": 463.6977510207854
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Convert Data into plain text following a specified template.",
          "display_name": "Parse Data",
          "id": "ParseData-eLatG",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "display_name": "Parse Data",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "legacy": true,
            "lf_version": "1.1.1",
            "metadata": {
              "code_hash": "3fac44a9bb37",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 1
              },
              "legacy_name": "Parse Data",
              "module": "lfx.components.processing.parse_data.ParseDataComponent"
            },
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "group_outputs": false,
                "method": "parse_data",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "group_outputs": false,
                "method": "parse_data_as_list",
                "name": "data_list",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from lfx.custom.custom_component.component import Component\nfrom lfx.helpers.data import data_to_text, data_to_text_list\nfrom lfx.io import DataInput, MultilineInput, Output, StrInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    replacement = [\"processing.DataOperations\", \"processing.TypeConverterComponent\"]\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              }
            }
          },
          "type": "ParseData"
        },
        "dragging": false,
        "height": 350,
        "id": "ParseData-eLatG",
        "measured": {
          "height": 350,
          "width": 320
        },
        "position": {
          "x": 1615.442686416003,
          "y": 590.0570885832859
        },
        "positionAbsolute": {
          "x": 1606.0595305373527,
          "y": 751.4473696960695
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt",
          "id": "Prompt-MP8Gr",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "context",
                "question"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "Autonomize",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "name": "prompt",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"Autonomize\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(\n        self, new_frontend_node: dict, current_frontend_node: dict\n    ):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(\n            new_frontend_node, current_frontend_node\n        )\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(\n            new_template=frontend_node,\n            previous_template=current_frontend_node[\"template\"],\n        )\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "context": {
                "advanced": false,
                "display_name": "context",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message",
                  "Text"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "context",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "description": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Description",
                "dynamic": false,
                "info": "Description of the prompt",
                "list": false,
                "load_from_db": false,
                "name": "description",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "prompt_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "New Prompt Name",
                "dynamic": false,
                "info": "Name for saving the new prompt",
                "list": false,
                "load_from_db": false,
                "name": "prompt_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "question": {
                "advanced": false,
                "display_name": "question",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message",
                  "Text"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "question",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "save_prompt": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Save Prompt",
                "dynamic": false,
                "info": "Save this prompt to the library",
                "list": false,
                "name": "save_prompt",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "saved_prompt": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Choose your Template",
                "dynamic": false,
                "info": "Choose your Template",
                "name": "saved_prompt",
                "options": [],
                "placeholder": "",
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "template": {
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "{context}\n\n---\n\nGiven the context above, answer the question as best as possible.\n\nQuestion: {question}\n\nAnswer: "
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "Prompt"
        },
        "dragging": false,
        "height": 433,
        "id": "Prompt-MP8Gr",
        "measured": {
          "height": 433,
          "width": 320
        },
        "position": {
          "x": 1977.9097981422992,
          "y": 640.5656416923846
        },
        "positionAbsolute": {
          "x": 1977.9097981422992,
          "y": 640.5656416923846
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Split text into chunks based on specified criteria.",
          "display_name": "Split Text",
          "id": "SplitText-mcBRT",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Split text into chunks based on specified criteria.",
            "display_name": "Split Text",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data_inputs",
              "chunk_overlap",
              "chunk_size",
              "separator"
            ],
            "frozen": false,
            "icon": "scissors-line-dashed",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {
              "code_hash": "f2867efda61f",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "langchain_text_splitters",
                    "version": "0.3.11"
                  },
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 2
              },
              "module": "lfx.components.processing.split_text.SplitTextComponent"
            },
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chunks",
                "group_outputs": false,
                "method": "split_text",
                "name": "dataframe",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "chunk_overlap": {
                "advanced": false,
                "display_name": "Chunk Overlap",
                "dynamic": false,
                "info": "Number of characters to overlap between chunks.",
                "list": false,
                "name": "chunk_overlap",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 200
              },
              "chunk_size": {
                "advanced": false,
                "display_name": "Chunk Size",
                "dynamic": false,
                "info": "The maximum length of each chunk. Text is first split by separator, then chunks are merged up to this size. Individual splits larger than this won't be further divided.",
                "list": false,
                "name": "chunk_size",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1000
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_text_splitters import CharacterTextSplitter\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import DropdownInput, HandleInput, IntInput, MessageTextInput, Output\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.message import Message\nfrom lfx.utils.util import unescape_string\n\n\nclass SplitTextComponent(Component):\n    display_name: str = \"Split Text\"\n    description: str = \"Split text into chunks based on specified criteria.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#split-text\"\n    icon = \"scissors-line-dashed\"\n    name = \"SplitText\"\n\n    inputs = [\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Input\",\n            info=\"The data with texts to split in chunks.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"Number of characters to overlap between chunks.\",\n            value=200,\n        ),\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=(\n                \"The maximum length of each chunk. Text is first split by separator, \"\n                \"then chunks are merged up to this size. \"\n                \"Individual splits larger than this won't be further divided.\"\n            ),\n            value=1000,\n        ),\n        MessageTextInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            info=(\n                \"The character to split on. Use \\\\n for newline. \"\n                \"Examples: \\\\n\\\\n for paragraphs, \\\\n for lines, . for sentences\"\n            ),\n            value=\"\\n\",\n        ),\n        MessageTextInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"The key to use for the text column.\",\n            value=\"text\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"keep_separator\",\n            display_name=\"Keep Separator\",\n            info=\"Whether to keep the separator in the output chunks and where to place it.\",\n            options=[\"False\", \"True\", \"Start\", \"End\"],\n            value=\"False\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chunks\", name=\"dataframe\", method=\"split_text\"),\n    ]\n\n    def _docs_to_data(self, docs) -> list[Data]:\n        return [Data(text=doc.page_content, data=doc.metadata) for doc in docs]\n\n    def _fix_separator(self, separator: str) -> str:\n        \"\"\"Fix common separator issues and convert to proper format.\"\"\"\n        if separator == \"/n\":\n            return \"\\n\"\n        if separator == \"/t\":\n            return \"\\t\"\n        return separator\n\n    def split_text_base(self):\n        separator = self._fix_separator(self.separator)\n        separator = unescape_string(separator)\n\n        if isinstance(self.data_inputs, DataFrame):\n            if not len(self.data_inputs):\n                msg = \"DataFrame is empty\"\n                raise TypeError(msg)\n\n            self.data_inputs.text_key = self.text_key\n            try:\n                documents = self.data_inputs.to_lc_documents()\n            except Exception as e:\n                msg = f\"Error converting DataFrame to documents: {e}\"\n                raise TypeError(msg) from e\n        elif isinstance(self.data_inputs, Message):\n            self.data_inputs = [self.data_inputs.to_data()]\n            return self.split_text_base()\n        else:\n            if not self.data_inputs:\n                msg = \"No data inputs provided\"\n                raise TypeError(msg)\n\n            documents = []\n            if isinstance(self.data_inputs, Data):\n                self.data_inputs.text_key = self.text_key\n                documents = [self.data_inputs.to_lc_document()]\n            else:\n                try:\n                    documents = [input_.to_lc_document() for input_ in self.data_inputs if isinstance(input_, Data)]\n                    if not documents:\n                        msg = f\"No valid Data inputs found in {type(self.data_inputs)}\"\n                        raise TypeError(msg)\n                except AttributeError as e:\n                    msg = f\"Invalid input type in collection: {e}\"\n                    raise TypeError(msg) from e\n        try:\n            # Convert string 'False'/'True' to boolean\n            keep_sep = self.keep_separator\n            if isinstance(keep_sep, str):\n                if keep_sep.lower() == \"false\":\n                    keep_sep = False\n                elif keep_sep.lower() == \"true\":\n                    keep_sep = True\n                # 'start' and 'end' are kept as strings\n\n            splitter = CharacterTextSplitter(\n                chunk_overlap=self.chunk_overlap,\n                chunk_size=self.chunk_size,\n                separator=separator,\n                keep_separator=keep_sep,\n            )\n            return splitter.split_documents(documents)\n        except Exception as e:\n            msg = f\"Error splitting text: {e}\"\n            raise TypeError(msg) from e\n\n    def split_text(self) -> DataFrame:\n        return DataFrame(self._docs_to_data(self.split_text_base()))\n"
              },
              "data_inputs": {
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The data with texts to split in chunks.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "name": "data_inputs",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "keep_separator": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Keep Separator",
                "dynamic": false,
                "external_options": {},
                "info": "Whether to keep the separator in the output chunks and where to place it.",
                "name": "keep_separator",
                "options": [
                  "False",
                  "True",
                  "Start",
                  "End"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "False"
              },
              "separator": {
                "advanced": false,
                "display_name": "Separator",
                "dynamic": false,
                "info": "The character to split on. Use \\n for newline. Examples: \\n\\n for paragraphs, \\n for lines, . for sentences",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "separator",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "text_key": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Key",
                "dynamic": false,
                "info": "The key to use for the text column.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "text"
              }
            }
          },
          "type": "SplitText"
        },
        "dragging": false,
        "height": 475,
        "id": "SplitText-mcBRT",
        "measured": {
          "height": 475,
          "width": 320
        },
        "position": {
          "x": 1321.4995709295729,
          "y": 1421.5452472223965
        },
        "positionAbsolute": {
          "x": 1683.4543896546102,
          "y": 1350.7871623588553
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Display a chat message in the Playground.",
          "display_name": "Chat Output",
          "id": "ChatOutput-3APoI",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {
              "code_hash": "ccda4dbe4ae1",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "orjson",
                    "version": "3.10.15"
                  },
                  {
                    "name": "fastapi",
                    "version": "0.117.1"
                  },
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 3
              },
              "module": "lfx.components.input_output.chat_output.ChatOutput"
            },
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean data before converting to string.",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom lfx.base.io.chat import ChatComponent\nfrom lfx.helpers.data import safe_convert\nfrom lfx.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.message import Message\nfrom lfx.schema.properties import Source\nfrom lfx.template.field.base import Output\nfrom lfx.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            advanced=True,\n            info=\"Whether to clean data before converting to string.\",\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            clean_data: bool = getattr(self, \"clean_data\", False)\n            return \"\\n\".join([safe_convert(item, clean_data=clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "type": "ChatOutput"
        },
        "dragging": false,
        "height": 234,
        "id": "ChatOutput-3APoI",
        "measured": {
          "height": 234,
          "width": 320
        },
        "position": {
          "x": 2868.4669328752643,
          "y": 774.8529753163065
        },
        "positionAbsolute": {
          "x": 2734.385670401691,
          "y": 810.6079786425926
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "AzureSearchVectorStoreComponent-N4BR1",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Azure AI Search Vector Store with search capabilities",
            "display_name": "Azure AI Search",
            "documentation": "",
            "edited": false,
            "field_order": [
              "azure_search_endpoint",
              "azure_search_key",
              "index_name",
              "auth_type",
              "search_type",
              "semantic_configuration_name",
              "vector_search_dimensions",
              "search_query",
              "ingest_data",
              "embedding",
              "number_of_results"
            ],
            "frozen": false,
            "icon": "Azure",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Search Results",
                "method": "search_documents",
                "name": "search_results",
                "required_inputs": [
                  "index_name"
                ],
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "auth_type": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Authentication Type",
                "dynamic": false,
                "info": "Choose between API Key or Managed Identity authentication",
                "name": "auth_type",
                "options": [
                  "api_key",
                  "managed_identity"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "api_key"
              },
              "azure_search_endpoint": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Azure Search Endpoint",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "azure_search_endpoint",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "azure_search_key": {
                "_input_type": "SecretStrInput",
                "advanced": true,
                "display_name": "Azure Search Key",
                "dynamic": false,
                "info": "If not provided, will use Managed Identity",
                "input_types": [
                  "Message"
                ],
                "load_from_db": false,
                "name": "azure_search_key",
                "password": true,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from azure.identity import DefaultAzureCredential\nfrom langchain_community.vectorstores.azuresearch import AzureSearch\nfrom langchain_core.embeddings import Embeddings\n\nfrom langflow.base.vectorstores.model import (\n    LCVectorStoreComponent,\n    check_cached_vector_store,\n)\nfrom langflow.helpers.data import docs_to_data\nfrom langflow.io import (\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom langflow.schema import Data\nfrom langflow.custom.genesis.services.azure_search import AzureSearchSetting\n\nazure_search_setting = AzureSearchSetting()\n\n\nclass AzureSearchVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Azure AI Search\"\n    description = \"Azure AI Search Vector Store with search capabilities\"\n    icon = \"Azure\"\n\n    inputs = [\n        StrInput(\n            name=\"azure_search_endpoint\",\n            display_name=\"Azure Search Endpoint\",\n            required=False,\n            advanced=True,\n        ),\n        SecretStrInput(\n            name=\"azure_search_key\",\n            display_name=\"Azure Search Key\",\n            required=False,\n            advanced=True,\n            info=\"If not provided, will use Managed Identity\",\n        ),\n        StrInput(name=\"index_name\", display_name=\"Index Name\", required=True),\n        DropdownInput(\n            name=\"auth_type\",\n            display_name=\"Authentication Type\",\n            options=[\"api_key\", \"managed_identity\"],\n            value=\"api_key\",\n            info=\"Choose between API Key or Managed Identity authentication\",\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            options=[\"similarity\", \"hybrid\", \"semantic_hybrid\"],\n            value=\"hybrid\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"semantic_configuration_name\",\n            display_name=\"Semantic Configuration Name\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"vector_search_dimensions\",\n            display_name=\"Vector Search Dimensions\",\n            info=\"Dimensions of the vector search space. If not provided, will be inferred from embedding function\",\n            advanced=True,\n        ),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(\n            name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> AzureSearch:\n        if not isinstance(self.embedding, Embeddings):\n            msg = \"Invalid embedding object\"\n            raise TypeError(msg)\n\n        # Base configuration\n        config_args = {\n            \"azure_search_endpoint\": self.azure_search_endpoint\n            or azure_search_setting.ENDPOINT,\n            \"index_name\": self.index_name,\n        }\n\n        # Handle authentication\n        if self.auth_type == \"managed_identity\":\n            # Use Managed Identity\n            try:\n                credential = DefaultAzureCredential()\n                config_args[\"azure_ad_access_token\"] = credential.get_token(\n                    \"https://search.azure.com/.default\"\n                ).token\n            except Exception as e:\n                raise ValueError(\n                    f\"Failed to get token from Managed Identity: {e!s}\"\n                ) from e\n        else:\n            # Use API Key if provided\n            azure_openai_key = self.azure_search_key or azure_search_setting.API_KEY\n            if not azure_openai_key:\n                raise ValueError(\n                    \"API Key authentication selected but no key provided. \"\n                    \"Either provide an API key or switch to Managed Identity authentication.\"\n                )\n            config_args[\"azure_search_key\"] = azure_openai_key\n\n        # Add optional parameters\n        if (\n            hasattr(self, \"semantic_configuration_name\")\n            and self.semantic_configuration_name\n        ):\n            config_args[\"semantic_configuration_name\"] = (\n                self.semantic_configuration_name\n            )\n        if hasattr(self, \"vector_search_dimensions\") and self.vector_search_dimensions:\n            config_args[\"vector_search_dimensions\"] = self.vector_search_dimensions\n\n        # Process documents if any\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents:\n            return AzureSearch.from_texts(\n                texts=[doc.page_content for doc in documents],\n                embedding=self.embedding,\n                metadatas=(\n                    [doc.metadata for doc in documents]\n                    if documents and hasattr(documents[0], \"metadata\")\n                    else None\n                ),\n                **config_args,\n            )\n        return AzureSearch(embedding_function=self.embedding, **config_args)\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        if (\n            self.search_query\n            and isinstance(self.search_query, str)\n            and self.search_query.strip()\n        ):\n            if self.search_type == \"similarity\":\n                docs = vector_store.similarity_search(\n                    query=self.search_query,\n                    k=self.number_of_results,\n                )\n            elif self.search_type == \"hybrid\":\n                docs = vector_store.hybrid_search(\n                    query=self.search_query,\n                    k=self.number_of_results,\n                )\n            elif self.search_type == \"semantic_hybrid\":\n                docs = vector_store.semantic_hybrid_search(\n                    query=self.search_query,\n                    k=self.number_of_results,\n                )\n            else:\n                raise ValueError(f\"Invalid search_type: {self.search_type}\")\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n\n    def get_retriever_kwargs(self):\n        \"\"\"Get retriever-specific kwargs.\"\"\"\n        return {\n            \"search_type\": self.search_type,\n            \"k\": self.number_of_results,\n        }\n"
              },
              "embedding": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Embedding",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Embeddings"
                ],
                "list": false,
                "name": "embedding",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "index_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Index Name",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "index_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "langtest"
              },
              "ingest_data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Ingest Data",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "name": "ingest_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "number_of_results": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Results",
                "dynamic": false,
                "info": "Number of results to return",
                "list": false,
                "name": "number_of_results",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 4
              },
              "search_query": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "search_query",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "search_type": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Search Type",
                "dynamic": false,
                "info": "",
                "name": "search_type",
                "options": [
                  "similarity",
                  "hybrid",
                  "semantic_hybrid"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "hybrid"
              },
              "semantic_configuration_name": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Semantic Configuration Name",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "semantic_configuration_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "vector_search_dimensions": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Vector Search Dimensions",
                "dynamic": false,
                "info": "Dimensions of the vector search space. If not provided, will be inferred from embedding function",
                "list": false,
                "name": "vector_search_dimensions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "AzureSearchVectorStoreComponent"
        },
        "dragging": false,
        "id": "AzureSearchVectorStoreComponent-N4BR1",
        "measured": {
          "height": 524,
          "width": 320
        },
        "position": {
          "x": 1240.9736814411574,
          "y": 454.1868556465568
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "AzureSearchVectorStoreComponent-RGl0S",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Azure AI Search Vector Store with search capabilities",
            "display_name": "Azure AI Search",
            "documentation": "",
            "edited": false,
            "field_order": [
              "azure_search_endpoint",
              "azure_search_key",
              "index_name",
              "auth_type",
              "search_type",
              "semantic_configuration_name",
              "vector_search_dimensions",
              "search_query",
              "ingest_data",
              "embedding",
              "number_of_results"
            ],
            "frozen": false,
            "icon": "Azure",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Search Results",
                "method": "search_documents",
                "name": "search_results",
                "required_inputs": [
                  "index_name"
                ],
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "auth_type": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Authentication Type",
                "dynamic": false,
                "info": "Choose between API Key or Managed Identity authentication",
                "name": "auth_type",
                "options": [
                  "api_key",
                  "managed_identity"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "api_key"
              },
              "azure_search_endpoint": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Azure Search Endpoint",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "azure_search_endpoint",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "azure_search_key": {
                "_input_type": "SecretStrInput",
                "advanced": true,
                "display_name": "Azure Search Key",
                "dynamic": false,
                "info": "If not provided, will use Managed Identity",
                "input_types": [
                  "Message"
                ],
                "load_from_db": false,
                "name": "azure_search_key",
                "password": true,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from azure.identity import DefaultAzureCredential\nfrom langchain_community.vectorstores.azuresearch import AzureSearch\nfrom langchain_core.embeddings import Embeddings\n\nfrom langflow.base.vectorstores.model import (\n    LCVectorStoreComponent,\n    check_cached_vector_store,\n)\nfrom langflow.helpers.data import docs_to_data\nfrom langflow.io import (\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom langflow.schema import Data\nfrom langflow.custom.genesis.services.azure_search import AzureSearchSetting\n\nazure_search_setting = AzureSearchSetting()\n\n\nclass AzureSearchVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Azure AI Search\"\n    description = \"Azure AI Search Vector Store with search capabilities\"\n    icon = \"Azure\"\n\n    inputs = [\n        StrInput(\n            name=\"azure_search_endpoint\",\n            display_name=\"Azure Search Endpoint\",\n            required=False,\n            advanced=True,\n        ),\n        SecretStrInput(\n            name=\"azure_search_key\",\n            display_name=\"Azure Search Key\",\n            required=False,\n            advanced=True,\n            info=\"If not provided, will use Managed Identity\",\n        ),\n        StrInput(name=\"index_name\", display_name=\"Index Name\", required=True),\n        DropdownInput(\n            name=\"auth_type\",\n            display_name=\"Authentication Type\",\n            options=[\"api_key\", \"managed_identity\"],\n            value=\"api_key\",\n            info=\"Choose between API Key or Managed Identity authentication\",\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            options=[\"similarity\", \"hybrid\", \"semantic_hybrid\"],\n            value=\"hybrid\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"semantic_configuration_name\",\n            display_name=\"Semantic Configuration Name\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"vector_search_dimensions\",\n            display_name=\"Vector Search Dimensions\",\n            info=\"Dimensions of the vector search space. If not provided, will be inferred from embedding function\",\n            advanced=True,\n        ),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(\n            name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> AzureSearch:\n        if not isinstance(self.embedding, Embeddings):\n            msg = \"Invalid embedding object\"\n            raise TypeError(msg)\n\n        # Base configuration\n        config_args = {\n            \"azure_search_endpoint\": self.azure_search_endpoint\n            or azure_search_setting.ENDPOINT,\n            \"index_name\": self.index_name,\n        }\n\n        # Handle authentication\n        if self.auth_type == \"managed_identity\":\n            # Use Managed Identity\n            try:\n                credential = DefaultAzureCredential()\n                config_args[\"azure_ad_access_token\"] = credential.get_token(\n                    \"https://search.azure.com/.default\"\n                ).token\n            except Exception as e:\n                raise ValueError(\n                    f\"Failed to get token from Managed Identity: {e!s}\"\n                ) from e\n        else:\n            # Use API Key if provided\n            azure_openai_key = self.azure_search_key or azure_search_setting.API_KEY\n            if not azure_openai_key:\n                raise ValueError(\n                    \"API Key authentication selected but no key provided. \"\n                    \"Either provide an API key or switch to Managed Identity authentication.\"\n                )\n            config_args[\"azure_search_key\"] = azure_openai_key\n\n        # Add optional parameters\n        if (\n            hasattr(self, \"semantic_configuration_name\")\n            and self.semantic_configuration_name\n        ):\n            config_args[\"semantic_configuration_name\"] = (\n                self.semantic_configuration_name\n            )\n        if hasattr(self, \"vector_search_dimensions\") and self.vector_search_dimensions:\n            config_args[\"vector_search_dimensions\"] = self.vector_search_dimensions\n\n        # Process documents if any\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents:\n            return AzureSearch.from_texts(\n                texts=[doc.page_content for doc in documents],\n                embedding=self.embedding,\n                metadatas=(\n                    [doc.metadata for doc in documents]\n                    if documents and hasattr(documents[0], \"metadata\")\n                    else None\n                ),\n                **config_args,\n            )\n        return AzureSearch(embedding_function=self.embedding, **config_args)\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        if (\n            self.search_query\n            and isinstance(self.search_query, str)\n            and self.search_query.strip()\n        ):\n            if self.search_type == \"similarity\":\n                docs = vector_store.similarity_search(\n                    query=self.search_query,\n                    k=self.number_of_results,\n                )\n            elif self.search_type == \"hybrid\":\n                docs = vector_store.hybrid_search(\n                    query=self.search_query,\n                    k=self.number_of_results,\n                )\n            elif self.search_type == \"semantic_hybrid\":\n                docs = vector_store.semantic_hybrid_search(\n                    query=self.search_query,\n                    k=self.number_of_results,\n                )\n            else:\n                raise ValueError(f\"Invalid search_type: {self.search_type}\")\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n\n    def get_retriever_kwargs(self):\n        \"\"\"Get retriever-specific kwargs.\"\"\"\n        return {\n            \"search_type\": self.search_type,\n            \"k\": self.number_of_results,\n        }\n"
              },
              "embedding": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Embedding",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Embeddings"
                ],
                "list": false,
                "name": "embedding",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "index_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Index Name",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "index_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "langtest"
              },
              "ingest_data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Ingest Data",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "name": "ingest_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "number_of_results": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Results",
                "dynamic": false,
                "info": "Number of results to return",
                "list": false,
                "name": "number_of_results",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 4
              },
              "search_query": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "search_query",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "search_type": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Search Type",
                "dynamic": false,
                "info": "",
                "name": "search_type",
                "options": [
                  "similarity",
                  "hybrid",
                  "semantic_hybrid"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "hybrid"
              },
              "semantic_configuration_name": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Semantic Configuration Name",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "semantic_configuration_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "vector_search_dimensions": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Vector Search Dimensions",
                "dynamic": false,
                "info": "Dimensions of the vector search space. If not provided, will be inferred from embedding function",
                "list": false,
                "name": "vector_search_dimensions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "AzureSearchVectorStoreComponent"
        },
        "dragging": false,
        "id": "AzureSearchVectorStoreComponent-RGl0S",
        "measured": {
          "height": 524,
          "width": 320
        },
        "position": {
          "x": 1998.209143755444,
          "y": 1577.6692371154274
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "AzureOpenAIEmbeddings-D6JrE",
          "node": {
            "base_classes": [
              "Embeddings"
            ],
            "beta": false,
            "category": "embeddings",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate embeddings using Azure OpenAI models.",
            "display_name": "Azure OpenAI Embeddings",
            "documentation": "https://python.langchain.com/docs/integrations/text_embedding/azureopenai",
            "edited": false,
            "field_order": [
              "model",
              "azure_endpoint",
              "azure_deployment",
              "api_version",
              "api_key",
              "dimensions"
            ],
            "frozen": false,
            "icon": "Azure",
            "key": "AzureOpenAIEmbeddings",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {
              "code_hash": "6b54f3243a6a",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "langchain_openai",
                    "version": "0.3.23"
                  },
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 2
              },
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ],
              "module": "lfx.components.azure.azure_openai_embeddings.AzureOpenAIEmbeddingsComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Embeddings",
                "group_outputs": false,
                "method": "build_embeddings",
                "name": "embeddings",
                "selected": "Embeddings",
                "tool_mode": true,
                "types": [
                  "Embeddings"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.01857804455091699,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Azure OpenAI API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "api_version": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "API Version",
                "dynamic": false,
                "info": "",
                "name": "api_version",
                "options": [
                  "2022-12-01",
                  "2023-03-15-preview",
                  "2023-05-15",
                  "2023-06-01-preview",
                  "2023-07-01-preview",
                  "2023-08-01-preview"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "2023-08-01-preview"
              },
              "azure_deployment": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Deployment Name",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "azure_deployment",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "azure_endpoint": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Azure Endpoint",
                "dynamic": false,
                "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "azure_endpoint",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_openai import AzureOpenAIEmbeddings\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom lfx.field_typing import Embeddings\nfrom lfx.io import DropdownInput, IntInput, MessageTextInput, Output, SecretStrInput\n\n\nclass AzureOpenAIEmbeddingsComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI Embeddings\"\n    description: str = \"Generate embeddings using Azure OpenAI models.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/text_embedding/azureopenai\"\n    icon = \"Azure\"\n    name = \"AzureOpenAIEmbeddings\"\n\n    API_VERSION_OPTIONS = [\n        \"2022-12-01\",\n        \"2023-03-15-preview\",\n        \"2023-05-15\",\n        \"2023-06-01-preview\",\n        \"2023-07-01-preview\",\n        \"2023-08-01-preview\",\n    ]\n\n    inputs = [\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=OPENAI_EMBEDDING_MODEL_NAMES[0],\n        ),\n        MessageTextInput(\n            name=\"azure_endpoint\",\n            display_name=\"Azure Endpoint\",\n            required=True,\n            info=\"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`\",\n        ),\n        MessageTextInput(\n            name=\"azure_deployment\",\n            display_name=\"Deployment Name\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"api_version\",\n            display_name=\"API Version\",\n            options=API_VERSION_OPTIONS,\n            value=API_VERSION_OPTIONS[-1],\n            advanced=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Azure OpenAI API Key\",\n            required=True,\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. \"\n            \"Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        try:\n            embeddings = AzureOpenAIEmbeddings(\n                model=self.model,\n                azure_endpoint=self.azure_endpoint,\n                azure_deployment=self.azure_deployment,\n                api_version=self.api_version,\n                api_key=self.api_key,\n                dimensions=self.dimensions or None,\n            )\n        except Exception as e:\n            msg = f\"Could not connect to AzureOpenAIEmbeddings API: {e}\"\n            raise ValueError(msg) from e\n\n        return embeddings\n"
              },
              "dimensions": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Dimensions",
                "dynamic": false,
                "info": "The number of dimensions the resulting output embeddings should have. Only supported by certain models.",
                "list": false,
                "name": "dimensions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Model",
                "dynamic": false,
                "info": "",
                "name": "model",
                "options": [
                  "text-embedding-3-small",
                  "text-embedding-3-large",
                  "text-embedding-ada-002"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "text-embedding-ada-002"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "AzureOpenAIEmbeddings"
        },
        "dragging": false,
        "id": "AzureOpenAIEmbeddings-D6JrE",
        "measured": {
          "height": 254,
          "width": 320
        },
        "position": {
          "x": 1346.8513238599735,
          "y": 2048.651106406188
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "AzureOpenAIEmbeddings-s8MJB",
          "node": {
            "base_classes": [
              "Embeddings"
            ],
            "beta": false,
            "category": "embeddings",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate embeddings using Azure OpenAI models.",
            "display_name": "Azure OpenAI Embeddings",
            "documentation": "https://python.langchain.com/docs/integrations/text_embedding/azureopenai",
            "edited": false,
            "field_order": [
              "model",
              "azure_endpoint",
              "azure_deployment",
              "api_version",
              "api_key",
              "dimensions"
            ],
            "frozen": false,
            "icon": "Azure",
            "key": "AzureOpenAIEmbeddings",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {
              "code_hash": "6b54f3243a6a",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "langchain_openai",
                    "version": "0.3.23"
                  },
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 2
              },
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ],
              "module": "lfx.components.azure.azure_openai_embeddings.AzureOpenAIEmbeddingsComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Embeddings",
                "group_outputs": false,
                "method": "build_embeddings",
                "name": "embeddings",
                "selected": "Embeddings",
                "tool_mode": true,
                "types": [
                  "Embeddings"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.01857804455091699,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Azure OpenAI API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "api_version": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "API Version",
                "dynamic": false,
                "info": "",
                "name": "api_version",
                "options": [
                  "2022-12-01",
                  "2023-03-15-preview",
                  "2023-05-15",
                  "2023-06-01-preview",
                  "2023-07-01-preview",
                  "2023-08-01-preview"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "2023-08-01-preview"
              },
              "azure_deployment": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Deployment Name",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "azure_deployment",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "azure_endpoint": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Azure Endpoint",
                "dynamic": false,
                "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "azure_endpoint",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_openai import AzureOpenAIEmbeddings\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom lfx.field_typing import Embeddings\nfrom lfx.io import DropdownInput, IntInput, MessageTextInput, Output, SecretStrInput\n\n\nclass AzureOpenAIEmbeddingsComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI Embeddings\"\n    description: str = \"Generate embeddings using Azure OpenAI models.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/text_embedding/azureopenai\"\n    icon = \"Azure\"\n    name = \"AzureOpenAIEmbeddings\"\n\n    API_VERSION_OPTIONS = [\n        \"2022-12-01\",\n        \"2023-03-15-preview\",\n        \"2023-05-15\",\n        \"2023-06-01-preview\",\n        \"2023-07-01-preview\",\n        \"2023-08-01-preview\",\n    ]\n\n    inputs = [\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=OPENAI_EMBEDDING_MODEL_NAMES[0],\n        ),\n        MessageTextInput(\n            name=\"azure_endpoint\",\n            display_name=\"Azure Endpoint\",\n            required=True,\n            info=\"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`\",\n        ),\n        MessageTextInput(\n            name=\"azure_deployment\",\n            display_name=\"Deployment Name\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"api_version\",\n            display_name=\"API Version\",\n            options=API_VERSION_OPTIONS,\n            value=API_VERSION_OPTIONS[-1],\n            advanced=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Azure OpenAI API Key\",\n            required=True,\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. \"\n            \"Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        try:\n            embeddings = AzureOpenAIEmbeddings(\n                model=self.model,\n                azure_endpoint=self.azure_endpoint,\n                azure_deployment=self.azure_deployment,\n                api_version=self.api_version,\n                api_key=self.api_key,\n                dimensions=self.dimensions or None,\n            )\n        except Exception as e:\n            msg = f\"Could not connect to AzureOpenAIEmbeddings API: {e}\"\n            raise ValueError(msg) from e\n\n        return embeddings\n"
              },
              "dimensions": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Dimensions",
                "dynamic": false,
                "info": "The number of dimensions the resulting output embeddings should have. Only supported by certain models.",
                "list": false,
                "name": "dimensions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Model",
                "dynamic": false,
                "info": "",
                "name": "model",
                "options": [
                  "text-embedding-3-small",
                  "text-embedding-3-large",
                  "text-embedding-ada-002"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "text-embedding-ada-002"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "AzureOpenAIEmbeddings"
        },
        "dragging": false,
        "id": "AzureOpenAIEmbeddings-s8MJB",
        "measured": {
          "height": 254,
          "width": 320
        },
        "position": {
          "x": 765.5906523735014,
          "y": 808.7173952219861
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "AzureOpenAIModel-0OM2g",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "models",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate text using Azure OpenAI LLMs.",
            "display_name": "Azure OpenAI",
            "documentation": "https://python.langchain.com/docs/integrations/llms/azure_openai",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "azure_endpoint",
              "azure_deployment",
              "api_key",
              "api_version",
              "temperature",
              "max_tokens"
            ],
            "frozen": false,
            "icon": "Azure",
            "key": "AzureOpenAIModel",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {
              "code_hash": "cc8d003556d8",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "langchain_openai",
                    "version": "0.3.23"
                  },
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 2
              },
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ],
              "module": "lfx.components.azure.azure_openai.AzureChatOpenAIComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "method": "text_response",
                "name": "text_output",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "method": "build_model",
                "name": "model_output",
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.003924824467069744,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": true,
                "display_name": "Azure Chat OpenAI API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "api_version": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "API Version",
                "dynamic": false,
                "info": "",
                "name": "api_version",
                "options": [
                  "2025-02-01-preview",
                  "2025-01-01-preview",
                  "2024-12-01-preview",
                  "2024-10-01-preview",
                  "2024-09-01-preview",
                  "2024-08-01-preview",
                  "2024-07-01-preview",
                  "2024-06-01",
                  "2024-03-01-preview",
                  "2024-02-15-preview",
                  "2023-12-01-preview",
                  "2023-05-15"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "2024-06-01"
              },
              "azure_deployment": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Deployment Name",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "azure_deployment",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "azure_endpoint": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Azure Endpoint",
                "dynamic": false,
                "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "azure_endpoint",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_openai import AzureChatOpenAI\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.inputs.inputs import MessageTextInput\nfrom lfx.io import DropdownInput, IntInput, SecretStrInput, SliderInput\n\n\nclass AzureChatOpenAIComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI\"\n    description: str = \"Generate text using Azure OpenAI LLMs.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/llms/azure_openai\"\n    beta = False\n    icon = \"Azure\"\n    name = \"AzureOpenAIModel\"\n\n    AZURE_OPENAI_API_VERSIONS = [\n        \"2024-06-01\",\n        \"2024-07-01-preview\",\n        \"2024-08-01-preview\",\n        \"2024-09-01-preview\",\n        \"2024-10-01-preview\",\n        \"2023-05-15\",\n        \"2023-12-01-preview\",\n        \"2024-02-15-preview\",\n        \"2024-03-01-preview\",\n        \"2024-12-01-preview\",\n        \"2025-01-01-preview\",\n        \"2025-02-01-preview\",\n    ]\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        MessageTextInput(\n            name=\"azure_endpoint\",\n            display_name=\"Azure Endpoint\",\n            info=\"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`\",\n            required=True,\n        ),\n        MessageTextInput(name=\"azure_deployment\", display_name=\"Deployment Name\", required=True),\n        SecretStrInput(name=\"api_key\", display_name=\"Azure Chat OpenAI API Key\", required=True),\n        DropdownInput(\n            name=\"api_version\",\n            display_name=\"API Version\",\n            options=sorted(AZURE_OPENAI_API_VERSIONS, reverse=True),\n            value=next(\n                (\n                    version\n                    for version in sorted(AZURE_OPENAI_API_VERSIONS, reverse=True)\n                    if not version.endswith(\"-preview\")\n                ),\n                AZURE_OPENAI_API_VERSIONS[0],\n            ),\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.7,\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\n            info=\"Controls randomness. Lower values are more deterministic, higher values are more creative.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        azure_endpoint = self.azure_endpoint\n        azure_deployment = self.azure_deployment\n        api_version = self.api_version\n        api_key = self.api_key\n        temperature = self.temperature\n        max_tokens = self.max_tokens\n        stream = self.stream\n\n        try:\n            output = AzureChatOpenAI(\n                azure_endpoint=azure_endpoint,\n                azure_deployment=azure_deployment,\n                api_version=api_version,\n                api_key=api_key,\n                temperature=temperature,\n                max_tokens=max_tokens or None,\n                streaming=stream,\n            )\n        except Exception as e:\n            msg = f\"Could not connect to AzureOpenAI API: {e}\"\n            raise ValueError(msg) from e\n\n        return output\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "name": "max_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "FloatInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness. Lower values are more deterministic, higher values are more creative.",
                "list": false,
                "name": "temperature",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": 0.7
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "AzureOpenAIModel"
        },
        "dragging": false,
        "id": "AzureOpenAIModel-0OM2g",
        "measured": {
          "height": 674,
          "width": 320
        },
        "position": {
          "x": 2414.144625479402,
          "y": 587.0069908880855
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "FileReader-3TisE",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Load and process files from signed URLs in the data input.",
            "display_name": "File",
            "documentation": "",
            "edited": false,
            "field_order": [
              "file_path",
              "silent_errors",
              "delete_server_file_after_processing",
              "ignore_unsupported_extensions",
              "ignore_unspecified_files",
              "use_multithreading",
              "concurrency_multithreading",
              "keep_downloaded_files"
            ],
            "frozen": false,
            "icon": "file-text",
            "legacy": false,
            "metadata": {
              "code_hash": "0ae813b50258",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "aiohttp",
                    "version": "3.12.15"
                  },
                  {
                    "name": "lfx",
                    "version": null
                  },
                  {
                    "name": "src",
                    "version": null
                  }
                ],
                "total_dependencies": 3
              },
              "module": "custom_components.file_reader"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Processed Data",
                "group_outputs": false,
                "method": "process_files",
                "name": "processed_data",
                "selected": "list",
                "tool_mode": true,
                "types": [
                  "list"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import asyncio\nimport logging\nimport os\nimport tempfile\n\nimport aiohttp\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import BoolInput, DataInput, IntInput, Output\n\nfrom src.backend.base.langflow.custom.genesis.components.data.utils import TEXT_FILE_TYPES, parse_text_file_to_data\n\nlogger = logging.getLogger(__name__)\n\n\nclass FileReaderComponent(Component):\n    \"\"\"Handles loading and processing of files from signed URLs or local paths.\"\"\"\n\n    display_name = \"File Reader\"\n    category: str = \"data\"\n    description = \"Load and process files from signed URLs in the data input.\"\n    icon = \"file-text\"\n    name = \"FileReader\"\n\n    VALID_EXTENSIONS = TEXT_FILE_TYPES\n\n    inputs = [\n        DataInput(\n            name=\"input_data\",\n            display_name=\"Data\",\n            info=\"List of dicts, each with a file URL (e.g., {'file_path': 'https://...'}).\",\n            is_list=True,\n            required=True,\n        ),\n        BoolInput(\n            name=\"silent_errors\",\n            display_name=\"Silent Errors\",\n            value=True,\n            info=\"If true, errors will not raise exceptions.\",\n        ),\n        BoolInput(\n            name=\"keep_downloaded_files\",\n            display_name=\"Keep Downloaded Files\",\n            value=False,\n            info=\"If true, downloaded files will not be deleted after processing.\",\n        ),\n        BoolInput(\n            name=\"ignore_unsupported_extensions\",\n            display_name=\"Ignore Unsupported Extensions\",\n            value=True,\n            info=\"If true, files with unsupported extensions will be ignored.\",\n        ),\n        IntInput(\n            name=\"concurrency\",\n            display_name=\"Processing Concurrency\",\n            value=1,\n            info=\"Number of files to process concurrently.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Processed Data\", name=\"processed_data\", method=\"process_files\"\n        ),\n    ]\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.temp_dir = tempfile.mkdtemp()\n        self._downloaded_files = {}\n\n    async def _download_file_from_signed_url(self, url: str) -> str | None:\n        try:\n            filename = os.path.basename(url.split(\"?\")[0]) or \"downloaded.txt\"\n            local_path = os.path.join(self.temp_dir, filename)\n            async with aiohttp.ClientSession() as session:\n                async with session.get(url) as response:\n                    response.raise_for_status()\n                    with open(local_path, \"wb\") as f:\n                        while True:\n                            chunk = await response.content.read(8192)\n                            if not chunk:\n                                break\n                            f.write(chunk)\n            self._downloaded_files[url] = local_path\n            logger.info(f\"Successfully downloaded file to {local_path}\")\n            return local_path\n        except Exception as e:\n            logger.error(f\"Error downloading file from signed URL: {e!s}\")\n            if not getattr(self, \"silent_errors\", True):\n                raise\n            return None\n\n    async def process_files(self) -> list:\n        data_input = getattr(self, \"input_data\", None)\n        silent_errors = getattr(self, \"silent_errors\", True)\n        getattr(self, \"keep_downloaded_files\", False)\n        getattr(self, \"concurrency\", 1)\n        ignore_unsupported_extensions = getattr(\n            self, \"ignore_unsupported_extensions\", True\n        )\n\n        if not data_input:\n            raise ValueError(\"No data input provided.\")\n\n        processed_data = []\n        for item in data_input:\n            url = item.get(\"file_path\") or item.get(\"url\") or item.get(\"path\")\n            if not url:\n                if not silent_errors:\n                    raise ValueError(\"No file URL found in data item.\")\n                continue\n            # Download the file\n            loop = asyncio.get_event_loop()\n            local_path = loop.run_until_complete(\n                self._download_file_from_signed_url(url)\n            )\n            if not local_path:\n                continue\n            # Process the file\n            result = parse_text_file_to_data(local_path, silent_errors=silent_errors)\n            processed_data.append(result)\n\n        # Optionally filter unsupported extensions\n        if ignore_unsupported_extensions:\n            processed_data = [\n                d\n                for d in processed_data\n                if any(d.endswith(ext) for ext in self.VALID_EXTENSIONS)\n            ]\n\n        return processed_data\n\n    def __del__(self):\n        if (\n            self.temp_dir\n            and os.path.exists(self.temp_dir)\n            and not getattr(self, \"keep_downloaded_files\", False)\n        ):\n            try:\n                for file_path in self._downloaded_files.values():\n                    if os.path.exists(file_path):\n                        os.remove(file_path)\n                os.rmdir(self.temp_dir)\n            except Exception as e:\n                logger.error(f\"Error cleaning up temporary files: {e!s}\")\n"
              },
              "concurrency": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Processing Concurrency",
                "dynamic": false,
                "info": "Number of files to process concurrently.",
                "list": false,
                "list_add_label": "Add More",
                "name": "concurrency",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "ignore_unsupported_extensions": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Ignore Unsupported Extensions",
                "dynamic": false,
                "info": "If true, files with unsupported extensions will be ignored.",
                "list": false,
                "name": "ignore_unsupported_extensions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "input_data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "List of dicts, each with a file URL (e.g., {'file_path': 'https://...'}).",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "keep_downloaded_files": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Keep Downloaded Files",
                "dynamic": false,
                "info": "If true, downloaded files will not be deleted after processing.",
                "list": false,
                "name": "keep_downloaded_files",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "silent_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Silent Errors",
                "dynamic": false,
                "info": "If true, errors will not raise exceptions.",
                "list": false,
                "name": "silent_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "FileReader"
        },
        "dragging": false,
        "id": "FileReader-3TisE",
        "measured": {
          "height": 282,
          "width": 320
        },
        "position": {
          "x": 883.721443113202,
          "y": 1415.5414778470786
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "BlobStorage-n6pLf",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Load files from Azure Blob Storage",
            "display_name": "Blob Storage",
            "documentation": "http://docs.langflow.org/components/storage",
            "edited": false,
            "field_order": [
              "storage_account",
              "container_name",
              "file_name",
              "return_all_files"
            ],
            "frozen": false,
            "icon": "Autonomize",
            "legacy": false,
            "metadata": {
              "code_hash": "c0b124e117a5",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "lfx",
                    "version": null
                  },
                  {
                    "name": "loguru",
                    "version": "0.7.3"
                  }
                ],
                "total_dependencies": 2
              },
              "module": "lfx.components.input_output.blob_storage.BlobStorageComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "File Path",
                "group_outputs": false,
                "method": "get_file_paths",
                "name": "file_path",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "\"\"\"Blob Storage Component for loading files from Azure Blob Storage.\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import Any\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import BoolInput, DropdownInput, Output, StrInput\nfrom lfx.schema.data import Data\nfrom lfx.services.manager import get_service_manager\nfrom loguru import logger\n\n\nclass BlobStorageComponent(Component):\n    display_name = \"Blob Storage\"\n    category: str = \"input_output\"\n    description = \"Load files from Azure Blob Storage\"\n    documentation = \"http://docs.langflow.org/components/storage\"\n    icon = \"Autonomize\"\n    name = \"BlobStorage\"\n\n    # Match the property name expected by FileComponent\n    FILE_PATH_FIELD = \"file_path\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self._container_list: list[str] = []\n        self._file_list: list[str] = []\n\n    inputs = [\n        StrInput(\n            name=\"storage_account\",\n            display_name=\"Storage Account\",\n            required=False,\n            info=\"Storage Account name\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"container_name\",\n            display_name=\"Container\",\n            info=\"Select a container from the storage account\",\n            required=True,\n            refresh_button=True,\n        ),\n        DropdownInput(\n            name=\"file_name\",\n            display_name=\"File\",\n            info=\"Select a file from the container\",\n            required=True,\n            refresh_button=True,\n        ),\n        BoolInput(\n            name=\"return_all_files\",\n            display_name=\"Return All Files\",\n            info=\"If true and no specific file is selected, returns all files in the container\",\n            value=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            name=\"file_path\",  # Match the property name expected by FileComponent\n            display_name=\"File Path\",\n            method=\"get_file_paths\",\n        ),\n    ]\n\n    async def update_build_config(\n        self, build_config: dict, field_value: Any, field_name: str | None = None\n    ):\n        \"\"\"Update the build configuration based on field changes.\"\"\"\n        logger.info(f\"update_build_config called with field_name: {field_name}\")\n\n        storage_account = getattr(self, \"storage_account\", None)\n        container_name = getattr(self, \"container_name\", None)\n\n        if field_name == \"container_name\":\n            try:\n                # Load the container options when the field is refreshed\n                service = get_service_manager().get(\"flexstore_service\")\n                self._container_list = await service.get_containers(storage_account)\n\n                build_config[\"container_name\"][\"options\"] = self._container_list\n                return build_config\n\n            except Exception as e:\n                logger.exception(f\"Error updating container list: {e!s}\")\n                raise\n\n        elif field_name == \"file_name\" and container_name:\n            try:\n                # Load the file options when the field is refreshed\n                service = get_service_manager().get(\"flexstore_service\")\n                self._file_list = await service.get_files(\n                    storage_account, container_name\n                )\n\n                build_config[\"file_name\"][\"options\"] = self._file_list\n                return build_config\n\n            except Exception as e:\n                logger.exception(f\"Error updating file list: {e!s}\")\n                raise\n\n        return build_config\n\n    async def get_file_paths(self) -> list[Data]:\n        \"\"\"Get file paths for the FileComponent to process.\"\"\"\n        try:\n            if not self.container_name:\n                logger.warning(\"Container name is required.\")\n                return []\n\n            service = get_service_manager().get(\"flexstore_service\")\n            file_paths = []\n\n            # If a specific file is selected\n            if self.file_name:\n                signed_url = await service.get_signed_url(\n                    self.storage_account, self.container_name, self.file_name\n                )\n                if signed_url:\n                    file_paths = [Data(data={self.FILE_PATH_FIELD: signed_url})]\n            # If no specific file is selected and return_all_files is True\n            elif self.return_all_files:\n                files = await service.get_files(\n                    self.storage_account, self.container_name\n                )\n                for file in files:\n                    signed_url = await service.get_signed_url(\n                        self.storage_account, self.container_name, file\n                    )\n                    if signed_url:\n                        file_paths.append(Data(data={self.FILE_PATH_FIELD: signed_url}))\n\n            if file_paths:\n                self.status = file_paths\n                logger.info(f\"Generated {len(file_paths)} file paths\")\n                for path in file_paths:\n                    logger.debug(f\"File path: {path.data.get(self.FILE_PATH_FIELD)}\")\n            else:\n                logger.warning(\"No file paths generated\")\n\n            return file_paths\n\n        except Exception as e:\n            logger.error(f\"Error in get_file_paths: {e!s}\")\n            return []\n"
              },
              "container_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Container",
                "dynamic": false,
                "info": "Select a container from the storage account",
                "name": "container_name",
                "options": [],
                "placeholder": "",
                "refresh_button": true,
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "genesis-container"
              },
              "file_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "File",
                "dynamic": false,
                "info": "Select a file from the container",
                "name": "file_name",
                "options": [],
                "placeholder": "",
                "refresh_button": true,
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "return_all_files": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Return All Files",
                "dynamic": false,
                "info": "If true and no specific file is selected, returns all files in the container",
                "list": false,
                "name": "return_all_files",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "storage_account": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Storage Account",
                "dynamic": false,
                "info": "Storage Account name",
                "list": false,
                "load_from_db": false,
                "name": "storage_account",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "BlobStorage"
        },
        "dragging": false,
        "id": "BlobStorage-n6pLf",
        "measured": {
          "height": 367,
          "width": 320
        },
        "position": {
          "x": 465.3911650078687,
          "y": 1363.044132844184
        },
        "selected": true,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": -280.5072827560847,
      "y": -803.8780461448314,
      "zoom": 0.7111554088964501
    }
  },
  "description": "Load your data for chat context with Retrieval Augmented Generation.",
  "endpoint_name": null,
  "id": "6f83b375-1dce-49dd-a6ab-f452d12e9e76",
  "is_component": false,
  "last_tested_version": "1.1.1",
  "name": "Document Retrieval Agent"
}