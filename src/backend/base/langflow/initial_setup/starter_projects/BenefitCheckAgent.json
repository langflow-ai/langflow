{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "EncoderProTool",
            "id": "EncoderProTool-Z95W8",
            "name": "api_build_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-BJ0z7",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-EncoderProTool-Z95W8{œdataTypeœ:œEncoderProToolœ,œidœ:œEncoderProTool-Z95W8œ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-Agent-BJ0z7{œfieldNameœ:œtoolsœ,œidœ:œAgent-BJ0z7œ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "EncoderProTool-Z95W8",
        "sourceHandle": "{œdataTypeœ: œEncoderProToolœ, œidœ: œEncoderProTool-Z95W8œ, œnameœ: œapi_build_toolœ, œoutput_typesœ: [œToolœ]}",
        "target": "Agent-BJ0z7",
        "targetHandle": "{œfieldNameœ: œtoolsœ, œidœ: œAgent-BJ0z7œ, œinputTypesœ: [œToolœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "PALookupTool",
            "id": "PALookupTool-NaTa8",
            "name": "api_build_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-BJ0z7",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-PALookupTool-NaTa8{œdataTypeœ:œPALookupToolœ,œidœ:œPALookupTool-NaTa8œ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-Agent-BJ0z7{œfieldNameœ:œtoolsœ,œidœ:œAgent-BJ0z7œ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "PALookupTool-NaTa8",
        "sourceHandle": "{œdataTypeœ: œPALookupToolœ, œidœ: œPALookupTool-NaTa8œ, œnameœ: œapi_build_toolœ, œoutput_typesœ: [œToolœ]}",
        "target": "Agent-BJ0z7",
        "targetHandle": "{œfieldNameœ: œtoolsœ, œidœ: œAgent-BJ0z7œ, œinputTypesœ: [œToolœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-BJ0z7",
            "name": "response",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-Jfah7",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Agent-BJ0z7{œdataTypeœ:œAgentœ,œidœ:œAgent-BJ0z7œ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-Jfah7{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-Jfah7œ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Agent-BJ0z7",
        "sourceHandle": "{œdataTypeœ: œAgentœ, œidœ: œAgent-BJ0z7œ, œnameœ: œresponseœ, œoutput_typesœ: [œMessageœ]}",
        "target": "ChatOutput-Jfah7",
        "targetHandle": "{œfieldNameœ: œinput_valueœ, œidœ: œChatOutput-Jfah7œ, œinputTypesœ: [œDataœ, œDataFrameœ, œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "KnowledgeHubSearch",
            "id": "KnowledgeHubSearch-ICnyv",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-TjsA4",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-KnowledgeHubSearch-ICnyv{œdataTypeœ:œKnowledgeHubSearchœ,œidœ:œKnowledgeHubSearch-ICnyvœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}-Agent-TjsA4{œfieldNameœ:œtoolsœ,œidœ:œAgent-TjsA4œ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "KnowledgeHubSearch-ICnyv",
        "sourceHandle": "{œdataTypeœ: œKnowledgeHubSearchœ, œidœ: œKnowledgeHubSearch-ICnyvœ, œnameœ: œcomponent_as_toolœ, œoutput_typesœ: [œToolœ]}",
        "target": "Agent-TjsA4",
        "targetHandle": "{œfieldNameœ: œtoolsœ, œidœ: œAgent-TjsA4œ, œinputTypesœ: [œToolœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-TjsA4",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-BJ0z7",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-Agent-TjsA4{œdataTypeœ:œAgentœ,œidœ:œAgent-TjsA4œ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}-Agent-BJ0z7{œfieldNameœ:œtoolsœ,œidœ:œAgent-BJ0z7œ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "Agent-TjsA4",
        "sourceHandle": "{œdataTypeœ: œAgentœ, œidœ: œAgent-TjsA4œ, œnameœ: œcomponent_as_toolœ, œoutput_typesœ: [œToolœ]}",
        "target": "Agent-BJ0z7",
        "targetHandle": "{œfieldNameœ: œtoolsœ, œidœ: œAgent-BJ0z7œ, œinputTypesœ: [œToolœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-tXVY4",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_prompt",
            "id": "Agent-gq2Yh",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt-tXVY4{œdataTypeœ:œPromptœ,œidœ:œPrompt-tXVY4œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-Agent-gq2Yh{œfieldNameœ:œsystem_promptœ,œidœ:œAgent-gq2Yhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-tXVY4",
        "sourceHandle": "{œdataTypeœ: œPromptœ, œidœ: œPrompt-tXVY4œ, œnameœ: œpromptœ, œoutput_typesœ: [œMessageœ]}",
        "target": "Agent-gq2Yh",
        "targetHandle": "{œfieldNameœ: œsystem_promptœ, œidœ: œAgent-gq2Yhœ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "KnowledgeHubSearch",
            "id": "KnowledgeHubSearch-oOLSB",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-gq2Yh",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-KnowledgeHubSearch-oOLSB{œdataTypeœ:œKnowledgeHubSearchœ,œidœ:œKnowledgeHubSearch-oOLSBœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}-Agent-gq2Yh{œfieldNameœ:œtoolsœ,œidœ:œAgent-gq2Yhœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "KnowledgeHubSearch-oOLSB",
        "sourceHandle": "{œdataTypeœ: œKnowledgeHubSearchœ, œidœ: œKnowledgeHubSearch-oOLSBœ, œnameœ: œcomponent_as_toolœ, œoutput_typesœ: [œToolœ]}",
        "target": "Agent-gq2Yh",
        "targetHandle": "{œfieldNameœ: œtoolsœ, œidœ: œAgent-gq2Yhœ, œinputTypesœ: [œToolœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-gq2Yh",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-BJ0z7",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-Agent-gq2Yh{œdataTypeœ:œAgentœ,œidœ:œAgent-gq2Yhœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}-Agent-BJ0z7{œfieldNameœ:œtoolsœ,œidœ:œAgent-BJ0z7œ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "Agent-gq2Yh",
        "sourceHandle": "{œdataTypeœ: œAgentœ, œidœ: œAgent-gq2Yhœ, œnameœ: œcomponent_as_toolœ, œoutput_typesœ: [œToolœ]}",
        "target": "Agent-BJ0z7",
        "targetHandle": "{œfieldNameœ: œtoolsœ, œidœ: œAgent-BJ0z7œ, œinputTypesœ: [œToolœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "QNextAuthHistoryTool",
            "id": "QNextAuthHistoryTool-s2kGz",
            "name": "api_build_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-gq2Yh",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-QNextAuthHistoryTool-s2kGz{œdataTypeœ:œQNextAuthHistoryToolœ,œidœ:œQNextAuthHistoryTool-s2kGzœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-Agent-gq2Yh{œfieldNameœ:œtoolsœ,œidœ:œAgent-gq2Yhœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "source": "QNextAuthHistoryTool-s2kGz",
        "sourceHandle": "{œdataTypeœ: œQNextAuthHistoryToolœ, œidœ: œQNextAuthHistoryTool-s2kGzœ, œnameœ: œapi_build_toolœ, œoutput_typesœ: [œToolœ]}",
        "target": "Agent-gq2Yh",
        "targetHandle": "{œfieldNameœ: œtoolsœ, œidœ: œAgent-gq2Yhœ, œinputTypesœ: [œToolœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "PromptTemplate",
            "id": "PromptTemplate-JrAir",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_prompt",
            "id": "Agent-TjsA4",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-PromptTemplate-JrAir{œdataTypeœ:œPromptTemplateœ,œidœ:œPromptTemplate-JrAirœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-Agent-TjsA4{œfieldNameœ:œsystem_promptœ,œidœ:œAgent-TjsA4œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "PromptTemplate-JrAir",
        "sourceHandle": "{œdataTypeœ: œPromptTemplateœ, œidœ: œPromptTemplate-JrAirœ, œnameœ: œpromptœ, œoutput_typesœ: [œMessageœ]}",
        "target": "Agent-TjsA4",
        "targetHandle": "{œfieldNameœ: œsystem_promptœ, œidœ: œAgent-TjsA4œ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "PromptTemplate",
            "id": "PromptTemplate-pLVYM",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_prompt",
            "id": "Agent-BJ0z7",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-PromptTemplate-pLVYM{œdataTypeœ:œPromptTemplateœ,œidœ:œPromptTemplate-pLVYMœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-Agent-BJ0z7{œfieldNameœ:œsystem_promptœ,œidœ:œAgent-BJ0z7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "PromptTemplate-pLVYM",
        "sourceHandle": "{œdataTypeœ: œPromptTemplateœ, œidœ: œPromptTemplate-pLVYMœ, œnameœ: œpromptœ, œoutput_typesœ: [œMessageœ]}",
        "target": "Agent-BJ0z7",
        "targetHandle": "{œfieldNameœ: œsystem_promptœ, œidœ: œAgent-BJ0z7œ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-oPALw",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "Agent-BJ0z7",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ChatInput-oPALw{œdataTypeœ:œChatInputœ,œidœ:œChatInput-oPALwœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Agent-BJ0z7{œfieldNameœ:œinput_valueœ,œidœ:œAgent-BJ0z7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "ChatInput-oPALw",
        "sourceHandle": "{œdataTypeœ: œChatInputœ, œidœ: œChatInput-oPALwœ, œnameœ: œmessageœ, œoutput_typesœ: [œMessageœ]}",
        "target": "Agent-BJ0z7",
        "targetHandle": "{œfieldNameœ: œinput_valueœ, œidœ: œAgent-BJ0z7œ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "Agent-BJ0z7",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "display_name": "Benefit Check Agent",
            "documentation": "",
            "edited": false,
            "field_order": [
              "agent_llm",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "system_prompt",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "return_intermediate_steps",
              "agent_description",
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template",
              "add_current_date_tool"
            ],
            "frozen": false,
            "icon": "bot",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {
              "code_hash": "d61b1f3d692a",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "langchain_core",
                    "version": "0.3.76"
                  },
                  {
                    "name": "pydantic",
                    "version": "2.10.6"
                  },
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 3
              },
              "module": "lfx.components.agents.agent.AgentComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Response",
                "group_outputs": false,
                "method": "message_response",
                "name": "response",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "add_current_date_tool": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Current Date",
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "input_types": [],
                "list": false,
                "name": "add_current_date_tool",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "agent_llm": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Model Provider",
                "dynamic": false,
                "info": "The provider of the language model that the agent will use to generate responses.",
                "input_types": [],
                "load_from_db": false,
                "name": "agent_llm",
                "options": [
                  "Anthropic",
                  "Google Generative AI",
                  "OpenAI"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Azure OpenAI"
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nimport re\n\nfrom langchain_core.tools import StructuredTool, Tool\nfrom pydantic import ValidationError\n\nfrom lfx.base.agents.agent import LCToolsAgentComponent\nfrom lfx.base.agents.events import ExceptionWithMessageError\nfrom lfx.base.models.model_input_constants import (\n    ALL_PROVIDER_FIELDS,\n    MODEL_DYNAMIC_UPDATE_FIELDS,\n    MODEL_PROVIDERS_DICT,\n    MODELS_METADATA,\n)\nfrom lfx.base.models.model_utils import get_model_name\nfrom lfx.components.helpers.current_date import CurrentDateComponent\nfrom lfx.components.helpers.memory import MemoryComponent\nfrom lfx.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom lfx.custom.custom_component.component import get_component_toolkit\nfrom lfx.custom.utils import update_component_build_config\nfrom lfx.helpers.base_model import build_model_from_schema\nfrom lfx.inputs.inputs import BoolInput\nfrom lfx.io import DropdownInput, IntInput, MultilineInput, Output, TableInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.dotdict import dotdict\nfrom lfx.schema.message import Message\nfrom lfx.schema.table import EditMode\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nMODEL_PROVIDERS_LIST = [\"Anthropic\", \"Google Generative AI\", \"OpenAI\"]\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    documentation: str = \"https://docs.langflow.org/agents\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    # Filter out json_mode from OpenAI inputs since we handle structured output differently\n    if \"OpenAI\" in MODEL_PROVIDERS_DICT:\n        openai_inputs_filtered = [\n            input_field\n            for input_field in MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"]\n            if not (hasattr(input_field, \"name\") and input_field.name == \"json_mode\")\n        ]\n    else:\n        openai_inputs_filtered = []\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*MODEL_PROVIDERS_LIST],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            refresh_button=False,\n            input_types=[],\n            options_metadata=[MODELS_METADATA[key] for key in MODEL_PROVIDERS_LIST if key in MODELS_METADATA]\n            + [{\"icon\": \"brain\"}],\n            external_options={\n                \"fields\": {\n                    \"data\": {\n                        \"node\": {\n                            \"name\": \"connect_other_models\",\n                            \"display_name\": \"Connect other models\",\n                            \"icon\": \"CornerDownLeft\",\n                        }\n                    }\n                },\n            },\n        ),\n        *openai_inputs_filtered,\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Chat History Messages\",\n            value=100,\n            info=\"Number of chat history messages to retrieve.\",\n            advanced=True,\n            show=True,\n        ),\n        MultilineInput(\n            name=\"format_instructions\",\n            display_name=\"Output Format Instructions\",\n            info=\"Generic Template for structured output formatting. Valid only with Structured response.\",\n            value=(\n                \"You are an AI that extracts structured JSON objects from unstructured text. \"\n                \"Use a predefined schema with expected types (str, int, float, bool, dict). \"\n                \"Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. \"\n                \"Fill missing or ambiguous values with defaults: null for missing values. \"\n                \"Remove exact duplicates but keep variations that have different field values. \"\n                \"Always return valid JSON in the expected format, never throw errors. \"\n                \"If multiple objects can be extracted, return them all in the structured format.\"\n            ),\n            advanced=True,\n        ),\n        TableInput(\n            name=\"output_schema\",\n            display_name=\"Output Schema\",\n            info=(\n                \"Schema Validation: Define the structure and data types for structured output. \"\n                \"No validation if no output schema.\"\n            ),\n            advanced=True,\n            required=False,\n            value=[],\n            table_schema=[\n                {\n                    \"name\": \"name\",\n                    \"display_name\": \"Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Specify the name of the output field.\",\n                    \"default\": \"field\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"description\",\n                    \"display_name\": \"Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Describe the purpose of the output field.\",\n                    \"default\": \"description of field\",\n                    \"edit_mode\": EditMode.POPOVER,\n                },\n                {\n                    \"name\": \"type\",\n                    \"display_name\": \"Type\",\n                    \"type\": \"str\",\n                    \"edit_mode\": EditMode.INLINE,\n                    \"description\": (\"Indicate the data type of the output field (e.g., str, int, float, bool, dict).\"),\n                    \"options\": [\"str\", \"int\", \"float\", \"bool\", \"dict\"],\n                    \"default\": \"str\",\n                },\n                {\n                    \"name\": \"multiple\",\n                    \"display_name\": \"As List\",\n                    \"type\": \"boolean\",\n                    \"description\": \"Set to True if this output field should be a list of the specified type.\",\n                    \"default\": \"False\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n            ],\n        ),\n        *LCToolsAgentComponent.get_base_inputs(),\n        # removed memory inputs from agent component\n        # *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [\n        Output(name=\"response\", display_name=\"Response\", method=\"message_response\"),\n    ]\n\n    async def get_agent_requirements(self):\n        \"\"\"Get the agent requirements for the agent.\"\"\"\n        llm_model, display_name = await self.get_llm()\n        if llm_model is None:\n            msg = \"No language model selected. Please choose a model to proceed.\"\n            raise ValueError(msg)\n        self.model_name = get_model_name(llm_model, display_name=display_name)\n\n        # Get memory data\n        self.chat_history = await self.get_memory_data()\n        if isinstance(self.chat_history, Message):\n            self.chat_history = [self.chat_history]\n\n        # Add current date tool if enabled\n        if self.add_current_date_tool:\n            if not isinstance(self.tools, list):  # type: ignore[has-type]\n                self.tools = []\n            current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n            if not isinstance(current_date_tool, StructuredTool):\n                msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                raise TypeError(msg)\n            self.tools.append(current_date_tool)\n        return llm_model, self.chat_history, self.tools\n\n    async def message_response(self) -> Message:\n        try:\n            llm_model, self.chat_history, self.tools = await self.get_agent_requirements()\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            result = await self.run_agent(agent)\n\n            # Store result for potential JSON output\n            self._agent_result = result\n\n        except (ValueError, TypeError, KeyError) as e:\n            await logger.aerror(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            await logger.aerror(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        # Avoid catching blind Exception; let truly unexpected exceptions propagate\n        except Exception as e:\n            await logger.aerror(f\"Unexpected error: {e!s}\")\n            raise\n        else:\n            return result\n\n    def _preprocess_schema(self, schema):\n        \"\"\"Preprocess schema to ensure correct data types for build_model_from_schema.\"\"\"\n        processed_schema = []\n        for field in schema:\n            processed_field = {\n                \"name\": str(field.get(\"name\", \"field\")),\n                \"type\": str(field.get(\"type\", \"str\")),\n                \"description\": str(field.get(\"description\", \"\")),\n                \"multiple\": field.get(\"multiple\", False),\n            }\n            # Ensure multiple is handled correctly\n            if isinstance(processed_field[\"multiple\"], str):\n                processed_field[\"multiple\"] = processed_field[\"multiple\"].lower() in [\n                    \"true\",\n                    \"1\",\n                    \"t\",\n                    \"y\",\n                    \"yes\",\n                ]\n            processed_schema.append(processed_field)\n        return processed_schema\n\n    async def build_structured_output_base(self, content: str):\n        \"\"\"Build structured output with optional BaseModel validation.\"\"\"\n        json_pattern = r\"\\{.*\\}\"\n        schema_error_msg = \"Try setting an output schema\"\n\n        # Try to parse content as JSON first\n        json_data = None\n        try:\n            json_data = json.loads(content)\n        except json.JSONDecodeError:\n            json_match = re.search(json_pattern, content, re.DOTALL)\n            if json_match:\n                try:\n                    json_data = json.loads(json_match.group())\n                except json.JSONDecodeError:\n                    return {\"content\": content, \"error\": schema_error_msg}\n            else:\n                return {\"content\": content, \"error\": schema_error_msg}\n\n        # If no output schema provided, return parsed JSON without validation\n        if not hasattr(self, \"output_schema\") or not self.output_schema or len(self.output_schema) == 0:\n            return json_data\n\n        # Use BaseModel validation with schema\n        try:\n            processed_schema = self._preprocess_schema(self.output_schema)\n            output_model = build_model_from_schema(processed_schema)\n\n            # Validate against the schema\n            if isinstance(json_data, list):\n                # Multiple objects\n                validated_objects = []\n                for item in json_data:\n                    try:\n                        validated_obj = output_model.model_validate(item)\n                        validated_objects.append(validated_obj.model_dump())\n                    except ValidationError as e:\n                        await logger.aerror(f\"Validation error for item: {e}\")\n                        # Include invalid items with error info\n                        validated_objects.append({\"data\": item, \"validation_error\": str(e)})\n                return validated_objects\n\n            # Single object\n            try:\n                validated_obj = output_model.model_validate(json_data)\n                return [validated_obj.model_dump()]  # Return as list for consistency\n            except ValidationError as e:\n                await logger.aerror(f\"Validation error: {e}\")\n                return [{\"data\": json_data, \"validation_error\": str(e)}]\n\n        except (TypeError, ValueError) as e:\n            await logger.aerror(f\"Error building structured output: {e}\")\n            # Fallback to parsed JSON without validation\n            return json_data\n\n    async def json_response(self) -> Data:\n        \"\"\"Convert agent response to structured JSON Data output with schema validation.\"\"\"\n        # Always use structured chat agent for JSON response mode for better JSON formatting\n        try:\n            system_components = []\n\n            # 1. Agent Instructions (system_prompt)\n            agent_instructions = getattr(self, \"system_prompt\", \"\") or \"\"\n            if agent_instructions:\n                system_components.append(f\"{agent_instructions}\")\n\n            # 2. Format Instructions\n            format_instructions = getattr(self, \"format_instructions\", \"\") or \"\"\n            if format_instructions:\n                system_components.append(f\"Format instructions: {format_instructions}\")\n\n            # 3. Schema Information from BaseModel\n            if hasattr(self, \"output_schema\") and self.output_schema and len(self.output_schema) > 0:\n                try:\n                    processed_schema = self._preprocess_schema(self.output_schema)\n                    output_model = build_model_from_schema(processed_schema)\n                    schema_dict = output_model.model_json_schema()\n                    schema_info = (\n                        \"You are given some text that may include format instructions, \"\n                        \"explanations, or other content alongside a JSON schema.\\n\\n\"\n                        \"Your task:\\n\"\n                        \"- Extract only the JSON schema.\\n\"\n                        \"- Return it as valid JSON.\\n\"\n                        \"- Do not include format instructions, explanations, or extra text.\\n\\n\"\n                        \"Input:\\n\"\n                        f\"{json.dumps(schema_dict, indent=2)}\\n\\n\"\n                        \"Output (only JSON schema):\"\n                    )\n                    system_components.append(schema_info)\n                except (ValidationError, ValueError, TypeError, KeyError) as e:\n                    await logger.aerror(f\"Could not build schema for prompt: {e}\", exc_info=True)\n\n            # Combine all components\n            combined_instructions = \"\\n\\n\".join(system_components) if system_components else \"\"\n            llm_model, self.chat_history, self.tools = await self.get_agent_requirements()\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=combined_instructions,\n            )\n\n            # Create and run structured chat agent\n            try:\n                structured_agent = self.create_agent_runnable()\n            except (NotImplementedError, ValueError, TypeError) as e:\n                await logger.aerror(f\"Error with structured chat agent: {e}\")\n                raise\n            try:\n                result = await self.run_agent(structured_agent)\n            except (\n                ExceptionWithMessageError,\n                ValueError,\n                TypeError,\n                RuntimeError,\n            ) as e:\n                await logger.aerror(f\"Error with structured agent result: {e}\")\n                raise\n            # Extract content from structured agent result\n            if hasattr(result, \"content\"):\n                content = result.content\n            elif hasattr(result, \"text\"):\n                content = result.text\n            else:\n                content = str(result)\n\n        except (\n            ExceptionWithMessageError,\n            ValueError,\n            TypeError,\n            NotImplementedError,\n            AttributeError,\n        ) as e:\n            await logger.aerror(f\"Error with structured chat agent: {e}\")\n            # Fallback to regular agent\n            content_str = \"No content returned from agent\"\n            return Data(data={\"content\": content_str, \"error\": str(e)})\n\n        # Process with structured output validation\n        try:\n            structured_output = await self.build_structured_output_base(content)\n\n            # Handle different output formats\n            if isinstance(structured_output, list) and structured_output:\n                if len(structured_output) == 1:\n                    return Data(data=structured_output[0])\n                return Data(data={\"results\": structured_output})\n            if isinstance(structured_output, dict):\n                return Data(data=structured_output)\n            return Data(data={\"content\": content})\n\n        except (ValueError, TypeError) as e:\n            await logger.aerror(f\"Error in structured output processing: {e}\")\n            return Data(data={\"content\": content, \"error\": str(e)})\n\n    async def get_memory_data(self):\n        # TODO: This is a temporary fix to avoid message duplication. We should develop a function for this.\n        messages = (\n            await MemoryComponent(**self.get_base_args())\n            .set(\n                session_id=self.graph.session_id,\n                order=\"Ascending\",\n                n_messages=self.n_messages,\n            )\n            .retrieve_messages()\n        )\n        return [\n            message for message in messages if getattr(message, \"id\", None) != getattr(self.input_value, \"id\", None)\n        ]\n\n    async def get_llm(self):\n        if not isinstance(self.agent_llm, str):\n            return self.agent_llm, None\n\n        try:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if not provider_info:\n                msg = f\"Invalid model provider: {self.agent_llm}\"\n                raise ValueError(msg)\n\n            component_class = provider_info.get(\"component_class\")\n            display_name = component_class.display_name\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\", \"\")\n\n            return self._build_llm_model(component_class, inputs, prefix), display_name\n\n        except (AttributeError, ValueError, TypeError, RuntimeError) as e:\n            await logger.aerror(f\"Error building {self.agent_llm} language model: {e!s}\")\n            msg = f\"Failed to initialize language model: {e!s}\"\n            raise ValueError(msg) from e\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {}\n        for input_ in inputs:\n            if hasattr(self, f\"{prefix}{input_.name}\"):\n                model_kwargs[input_.name] = getattr(self, f\"{prefix}{input_.name}\")\n        return component.set(**model_kwargs).build_model()\n\n    def set_component_params(self, component):\n        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n        if provider_info:\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\")\n            # Filter out json_mode and only use attributes that exist on this component\n            model_kwargs = {}\n            for input_ in inputs:\n                if hasattr(self, f\"{prefix}{input_.name}\"):\n                    model_kwargs[input_.name] = getattr(self, f\"{prefix}{input_.name}\")\n\n            return component.set(**model_kwargs)\n        return component\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self, build_config: dotdict, field_value: str, field_name: str | None = None\n    ) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name in (\"agent_llm\",):\n            build_config[\"agent_llm\"][\"value\"] = field_value\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n                build_config[\"agent_llm\"][\"display_name\"] = \"Model Provider\"\n            elif field_value == \"connect_other_models\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    info=\"The provider of the language model that the agent will use to generate responses.\",\n                    options=[*MODEL_PROVIDERS_LIST],\n                    real_time_refresh=True,\n                    refresh_button=False,\n                    input_types=[\"LanguageModel\"],\n                    placeholder=\"Awaiting model input.\",\n                    options_metadata=[MODELS_METADATA[key] for key in MODEL_PROVIDERS_LIST if key in MODELS_METADATA],\n                    external_options={\n                        \"fields\": {\n                            \"data\": {\n                                \"node\": {\n                                    \"name\": \"connect_other_models\",\n                                    \"display_name\": \"Connect other models\",\n                                    \"icon\": \"CornerDownLeft\",\n                                },\n                            }\n                        },\n                    },\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if (\n            isinstance(self.agent_llm, str)\n            and self.agent_llm in MODEL_PROVIDERS_DICT\n            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS\n        ):\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                component_class = self.set_component_params(component_class)\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n\n    async def _get_tools(self) -> list[Tool]:\n        component_toolkit = get_component_toolkit()\n        tools_names = self._build_tools_names()\n        agent_description = self.get_tool_description()\n        # TODO: Agent Description Depreciated Feature to be removed\n        description = f\"{agent_description}{tools_names}\"\n        tools = component_toolkit(component=self).get_tools(\n            tool_name=\"Call_Agent\",\n            tool_description=description,\n            callbacks=self.get_langchain_callbacks(),\n        )\n        if hasattr(self, \"tools_metadata\"):\n            tools = component_toolkit(component=self, metadata=self.tools_metadata).update_tools_metadata(tools=tools)\n        return tools\n"
              },
              "format_instructions": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Output Format Instructions",
                "dynamic": false,
                "info": "Generic Template for structured output formatting. Valid only with Structured response.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "format_instructions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are an AI that extracts structured JSON objects from unstructured text. Use a predefined schema with expected types (str, int, float, bool, dict). Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. Fill missing or ambiguous values with defaults: null for missing values. Remove exact duplicates but keep variations that have different field values. Always return valid JSON in the expected format, never throw errors. If multiple objects can be extracted, return them all in the structured format."
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "input_types": [],
                "list": false,
                "name": "handle_parsing_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "input_types": [],
                "list": false,
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 15
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "external_options": {},
                "info": "To see the model names, first choose a provider. Then, enter your API key and click the refresh button next to the model name.",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-5",
                  "gpt-5-mini",
                  "gpt-5-nano",
                  "gpt-5-chat-latest",
                  "o1",
                  "o3-mini",
                  "o3",
                  "o3-pro",
                  "o4-mini",
                  "o4-mini-high"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": false,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4o-mini"
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Chat History Messages",
                "dynamic": false,
                "info": "Number of chat history messages to retrieve.",
                "input_types": [],
                "list": false,
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "output_schema": {
                "_input_type": "TableInput",
                "advanced": true,
                "display_name": "Output Schema",
                "dynamic": false,
                "info": "Schema Validation: Define the structure and data types for structured output. No validation if no output schema.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "output_schema",
                "placeholder": "",
                "required": false,
                "show": true,
                "table_icon": "Table",
                "table_schema": [
                  {
                    "default": "field",
                    "description": "Specify the name of the output field.",
                    "display_name": "Name",
                    "edit_mode": "inline",
                    "name": "name",
                    "type": "str"
                  },
                  {
                    "default": "description of field",
                    "description": "Describe the purpose of the output field.",
                    "display_name": "Description",
                    "edit_mode": "popover",
                    "name": "description",
                    "type": "str"
                  },
                  {
                    "default": "str",
                    "description": "Indicate the data type of the output field (e.g., str, int, float, bool, dict).",
                    "display_name": "Type",
                    "edit_mode": "inline",
                    "name": "type",
                    "options": [
                      "str",
                      "int",
                      "float",
                      "bool",
                      "dict"
                    ],
                    "type": "str"
                  },
                  {
                    "default": "False",
                    "description": "Set to True if this output field should be a list of the specified type.",
                    "display_name": "As List",
                    "edit_mode": "inline",
                    "name": "multiple",
                    "type": "boolean"
                  }
                ],
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": []
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Agent Instructions",
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are a helpful assistant that can use tools to answer questions and perform tasks."
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.7
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Agent"
        },
        "dragging": false,
        "id": "Agent-BJ0z7",
        "measured": {
          "height": 817,
          "width": 320
        },
        "position": {
          "x": 2122.7573908645354,
          "y": -701.25606921868
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "description": "Get information and coverage status for service codes.",
          "display_name": "Encoder Pro",
          "id": "EncoderProTool-Z95W8",
          "node": {
            "base_classes": [
              "Data",
              "Tool"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get information and coverage status for service codes.",
            "display_name": "Encoder Pro",
            "documentation": "",
            "edited": false,
            "field_order": [
              "default_service_code",
              "default_check_coverage"
            ],
            "frozen": false,
            "icon": "Autonomize",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {
              "code_hash": "9caa784c54f9",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "langchain_core",
                    "version": "0.3.76"
                  },
                  {
                    "name": "langflow",
                    "version": null
                  },
                  {
                    "name": "lfx",
                    "version": null
                  },
                  {
                    "name": "pydantic",
                    "version": "2.10.6"
                  }
                ],
                "total_dependencies": 4
              },
              "module": "lfx.components.data.encoder_pro_tool.EncoderProTool"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Data",
                "hidden": true,
                "method": "run_model",
                "name": "api_run_model",
                "required_inputs": [],
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Tool",
                "method": "build_tool",
                "name": "api_build_tool",
                "required_inputs": [],
                "selected": "Tool",
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "\"\"\"Tool component for checking service code information and coverage using Encoder Pro.\"\"\"\n\nfrom typing import Any, Dict\n\nfrom langchain_core.tools import StructuredTool, ToolException\nfrom langflow.base.langchain_utilities.model import LCToolComponent\nfrom langflow.field_typing import Tool\nfrom langflow.inputs import MessageTextInput\nfrom langflow.logging import logger\nfrom lfx.schema.data import Data\nfrom pydantic import BaseModel, Field\n\nfrom langflow.custom.genesis.services.deps import get_encoder_pro_service\n\n\nclass EncoderProTool(LCToolComponent):\n    \"\"\"Tool component for checking service code information and coverage using Encoder Pro.\"\"\"\n\n    display_name: str = \"Encoder Pro\"\n    description: str = \"Get information and coverage status for service codes.\"\n    icon: str = \"Autonomize\"\n    name: str = \"EncoderProTool\"\n\n    class CodeInfoSchema(BaseModel):\n        \"\"\"Schema for the Encoder Pro code information tool.\"\"\"\n\n        service_code: str = Field(\n            ...,\n            description=\"Service code to check (CPT or HCPCS)\",\n            examples=[\"95810\", \"J7352\"],\n        )\n        check_coverage: bool = Field(\n            True,\n            description=\"Whether to check Medicare coverage status\",\n        )\n\n    inputs = [\n        MessageTextInput(\n            name=\"default_service_code\",\n            display_name=\"Default Service Code\",\n            info=\"Default service code to check.\",\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"default_check_coverage\",\n            display_name=\"Check Coverage\",\n            info=\"Whether to check Medicare coverage status by default (true/false).\",\n            tool_mode=True,\n        ),\n    ]\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the Encoder Pro Tool component.\"\"\"\n        super().__init__(**kwargs)\n\n    async def get_code_info(\n        self, service_code: str, check_coverage: bool = True\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Get detailed information about a service code including description and coverage status.\n\n        Args:\n            service_code: The CPT or HCPCS code to check\n            check_coverage: Whether to check Medicare coverage status\n\n        Returns:\n            Dictionary containing code information and coverage status\n        \"\"\"\n        logger.info(\n            f\"Getting information for service code: {service_code}, check coverage: {check_coverage}\"\n        )\n\n        try:\n            # Normalize input\n            clean_code = service_code.strip()\n\n            # Validate the code format (basic validation)\n            if not clean_code:\n                raise ValueError(\"Service code cannot be empty\")\n\n            # Determine code type\n            code_type = self._determine_code_type(clean_code)\n\n            # Get combined result\n            result = {\n                \"code\": clean_code,\n                \"code_type\": code_type.upper(),\n            }\n\n            # Get description\n            try:\n                description_data = (\n                    await get_encoder_pro_service().get_layman_description(\n                        code_type, clean_code\n                    )\n                )\n                result[\"description\"] = description_data.get(\n                    \"descriptionLay\", \"Description not available\"\n                )\n                result[\"technical_description\"] = description_data.get(\n                    \"description\", \"\"\n                )\n            except Exception as e:\n                logger.error(f\"Error getting description for code {clean_code}: {e}\")\n                result[\"description\"] = \"Error retrieving description\"\n                result[\"description_error\"] = str(e)\n\n            # Check coverage if requested\n            if check_coverage:\n                try:\n                    is_covered, coverage_data = (\n                        await get_encoder_pro_service().check_code_coverage(clean_code)\n                    )\n                    result[\"is_covered\"] = is_covered\n                    result[\"coverage_details\"] = coverage_data\n\n                    # Extract color codes for easier access\n                    if \"colorCodes\" in coverage_data:\n                        result[\"color_codes\"] = coverage_data[\"colorCodes\"]\n\n                except Exception as e:\n                    logger.error(f\"Error checking coverage for code {clean_code}: {e}\")\n                    result[\"is_covered\"] = None\n                    result[\"coverage_error\"] = str(e)\n\n            return result\n\n        except Exception as e:\n            logger.error(f\"Error getting code information: {e}\")\n            raise ToolException(f\"Error getting code information: {str(e)}\")\n\n    def _determine_code_type(self, code: str) -> str:\n        \"\"\"\n        Determine the code type (CPT or HCPCS) based on the code format.\n\n        Args:\n            code: The code to evaluate\n\n        Returns:\n            Code type ('cpt' or 'hcpcs')\n        \"\"\"\n        # Simple heuristic - could be improved for production\n        if code.isdigit() and len(code) == 5:\n            return \"cpt\"\n        else:\n            return \"hcpcs\"\n\n    def build_tool(self) -> Tool:\n        \"\"\"Build the Encoder Pro tool for use by an agent.\"\"\"\n\n        # Create synchronous wrapper for async function\n        def sync_wrapper(async_func):\n            def wrapper(*args, **kwargs):\n                try:\n                    # Create a new event loop for each call\n                    loop = asyncio.new_event_loop()\n                    asyncio.set_event_loop(loop)\n\n                    try:\n                        return loop.run_until_complete(async_func(*args, **kwargs))\n                    finally:\n                        loop.close()\n                except Exception as e:\n                    logger.error(f\"Error in {async_func.__name__}: {str(e)}\")\n                    # Return structured error response\n                    return {\n                        \"error\": str(e),\n                        \"code\": kwargs.get(\"service_code\", \"unknown\"),\n                        \"code_type\": \"Unknown\",\n                        \"description\": \"Error retrieving code information\",\n                        \"is_covered\": None,\n                        \"system_error\": True,\n                    }\n\n            return wrapper\n\n        return StructuredTool.from_function(\n            name=\"get_service_code_info\",\n            description=(\n                \"Get detailed information about a medical service code (CPT or HCPCS), \"\n                \"including its description and Medicare coverage status. \"\n                \"Use this to understand what a specific code means and whether it's covered.\"\n            ),\n            func=sync_wrapper(self.get_code_info),\n            args_schema=self.CodeInfoSchema,\n        )\n\n    def run_model(self) -> list[Data]:\n        \"\"\"Run the tool directly with the component's inputs, for API/direct use.\"\"\"\n        # Get values from UI inputs or use defaults\n        service_code = (\n            self.default_service_code\n            if hasattr(self, \"default_service_code\") and self.default_service_code\n            else \"\"\n        )\n\n        # Parse check_coverage from string to boolean\n        check_coverage_str = (\n            self.default_check_coverage\n            if hasattr(self, \"default_check_coverage\") and self.default_check_coverage\n            else \"\"\n        )\n        check_coverage = True  # Default value\n        if check_coverage_str.lower() in (\"false\", \"no\", \"0\", \"f\", \"n\"):\n            check_coverage = False\n\n        if not service_code:\n            return [\n                Data(\n                    data={\"error\": \"No service code provided\"},\n                    text=\"Error: No service code provided\",\n                )\n            ]\n\n        # Get the tool to use its structured functionality\n        self.build_tool()\n\n        try:\n            import asyncio\n\n            # Create a dedicated event loop\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n\n            try:\n                # Run the async function\n                result = loop.run_until_complete(\n                    self.get_code_info(\n                        service_code=service_code, check_coverage=check_coverage\n                    )\n                )\n            finally:\n                loop.close()\n\n            # Format the result as text\n            text_result = f\"Service Code Information: {service_code} ({result.get('code_type', 'Unknown')})\\n\\n\"\n            text_result += f\"Description: {result.get('description', 'Unknown')}\\n\"\n\n            if check_coverage:\n                coverage_status = (\n                    \"Covered\" if result.get(\"is_covered\") else \"Not Covered\"\n                )\n                if result.get(\"is_covered\") is None:\n                    coverage_status = \"Coverage status unknown\"\n\n                text_result += f\"Medicare Coverage: {coverage_status}\\n\"\n\n                # Add color codes if available\n                if \"color_codes\" in result:\n                    color_codes = result[\"color_codes\"]\n                    if isinstance(color_codes, list) and color_codes:\n                        text_result += \"\\nColor Codes:\\n\"\n                        for color_code in color_codes:\n                            color = color_code.get(\"colorCode\", \"Unknown\")\n                            desc = color_code.get(\"shortDescription\", \"\")\n                            text_result += f\"- {color}: {desc}\\n\"\n\n            return [Data(data=result, text=text_result)]\n\n        except Exception as e:\n            error_message = f\"Error getting code information: {str(e)}\"\n            return [Data(data={\"error\": error_message}, text=error_message)]\n"
              },
              "default_check_coverage": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Check Coverage",
                "dynamic": false,
                "info": "Whether to check Medicare coverage status by default (true/false).",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "default_check_coverage",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "default_service_code": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Default Service Code",
                "dynamic": false,
                "info": "Default service code to check.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "default_service_code",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "EncoderProTool"
        },
        "dragging": false,
        "id": "EncoderProTool-Z95W8",
        "measured": {
          "height": 339,
          "width": 320
        },
        "position": {
          "x": 697.8580958993084,
          "y": -1001.0560620538688
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "QNextAuthHistoryTool-s2kGz",
          "node": {
            "base_classes": [
              "Data",
              "Tool"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Retrieve claim and authorization history for a member from QNext.",
            "display_name": "QNXT Claim & Auth History",
            "documentation": "",
            "edited": false,
            "field_order": [
              "default_member_id",
              "default_start_date",
              "default_end_date",
              "default_limit"
            ],
            "frozen": false,
            "icon": "Autonomize",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {
              "code_hash": "73857e195df2",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "langchain_core",
                    "version": "0.3.76"
                  },
                  {
                    "name": "langflow",
                    "version": null
                  },
                  {
                    "name": "lfx",
                    "version": null
                  },
                  {
                    "name": "pydantic",
                    "version": "2.10.6"
                  }
                ],
                "total_dependencies": 4
              },
              "module": "lfx.components.data.qnext_auth_history_tool.QNextAuthHistoryTool"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Data",
                "method": "run_model",
                "name": "api_run_model",
                "required_inputs": [],
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Tool",
                "method": "build_tool",
                "name": "api_build_tool",
                "required_inputs": [],
                "selected": "Tool",
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "\"\"\"Tool component for retrieving claim and authorization history.\"\"\"\n\nimport asyncio\nimport traceback\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional\n\nfrom langchain_core.tools import StructuredTool\nfrom langflow.base.langchain_utilities.model import LCToolComponent\nfrom lfx.io import MessageTextInput\nfrom langflow.field_typing import Tool\nfrom langflow.logging import logger\nfrom lfx.schema.data import Data\nfrom pydantic import BaseModel, Field\n\nfrom langflow.custom.genesis.services.deps import get_claim_auth_history_service\n\n\nclass ClaimHistorySchema(BaseModel):\n    \"\"\"Schema for the claim history tool.\"\"\"\n\n    member_id: str = Field(\n        ...,\n        description=\"Member ID to retrieve claim history for\",\n    )\n    start_date: Optional[str] = Field(\n        None,\n        description=\"Start date for claim history (ISO format, e.g., '2023-01-01'). If not provided, defaults to 12 months ago.\",\n    )\n    end_date: Optional[str] = Field(\n        None,\n        description=\"End date for claim history (ISO format, e.g., '2023-12-31'). If not provided, defaults to current date.\",\n    )\n    limit: Optional[int] = Field(\n        10,\n        description=\"Maximum number of claims to retrieve\",\n    )\n\n\nclass AuthHistorySchema(BaseModel):\n    \"\"\"Schema for the authorization history tool.\"\"\"\n\n    member_id: str = Field(\n        ...,\n        description=\"Member ID to retrieve authorization history for\",\n    )\n    start_date: Optional[str] = Field(\n        None,\n        description=\"Start date for authorization history (ISO format, e.g., '2023-01-01'). If not provided, defaults to 12 months ago.\",\n    )\n    end_date: Optional[str] = Field(\n        None,\n        description=\"End date for authorization history (ISO format, e.g., '2023-12-31'). If not provided, defaults to current date.\",\n    )\n    limit: Optional[int] = Field(\n        10,\n        description=\"Maximum number of authorizations to retrieve\",\n    )\n\n\nclass QNextAuthHistoryTool(LCToolComponent):\n    \"\"\"Tool component for retrieving claim and authorization history.\"\"\"\n\n    display_name: str = \"QNXT\"\n    description: str = (\n        \"Retrieve claim and authorization history for a member from QNext.\"\n    )\n    icon: str = \"Autonomize\"\n    name: str = \"QNextAuthHistoryTool\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"default_member_id\",\n            display_name=\"Default Member ID\",\n            info=\"Default member ID to retrieve history for (optional).\",\n            required=False,\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"default_start_date\",\n            display_name=\"Default Start Date\",\n            info=\"Default start date in ISO format (e.g., '2023-01-01').\",\n            required=False,\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"default_end_date\",\n            display_name=\"Default End Date\",\n            info=\"Default end date in ISO format (e.g., '2023-12-31').\",\n            required=False,\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"default_limit\",\n            display_name=\"Default Limit\",\n            info=\"Default maximum number of records to retrieve.\",\n            required=False,\n            field_type=\"int\",\n            tool_mode=True,\n        ),\n    ]\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the Claim & Auth History Tool component.\"\"\"\n        super().__init__(**kwargs)\n\n    @property\n    def history_service(self):\n        \"\"\"Get the Claim & Auth History service.\"\"\"\n        return get_claim_auth_history_service()\n\n    async def get_claim_history(\n        self,\n        member_id: str,\n        start_date: Optional[str] = None,\n        end_date: Optional[str] = None,\n        limit: Optional[int] = 10,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Retrieve claim history for a member.\n        \"\"\"\n        logger.info(f\"Getting claim history for member ID: {member_id}\")\n\n        try:\n            # Validate member ID\n            if not member_id:\n                raise ValueError(\"Member ID is required\")\n\n            # Validate limit\n            if limit is not None and (not isinstance(limit, int) or limit < 1):\n                limit = 10\n\n            # Call the service\n            result = await self.history_service.get_claim_history(\n                member_id=member_id,\n                start_date=start_date,\n                end_date=end_date,\n                limit=limit,\n            )\n\n            # Process the result for better usability\n            summary = self._create_claim_summary(result)\n            result[\"summary\"] = summary\n\n            return result\n\n        except Exception as e:\n            logger.error(f\"Error getting claim history: {e}\")\n            # Return structured error response instead of raising\n            return {\n                \"error\": str(e),\n                \"member_id\": member_id,\n                \"claims\": [],\n                \"total_count\": 0,\n                \"summary\": {\n                    \"total_claims\": 0,\n                    \"status_counts\": {},\n                    \"service_codes\": {},\n                },\n            }\n\n    async def get_auth_history(\n        self,\n        member_id: str,\n        start_date: Optional[str] = None,\n        end_date: Optional[str] = None,\n        limit: Optional[int] = 10,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Retrieve authorization history for a member.\n        \"\"\"\n        logger.info(f\"Getting authorization history for member ID: {member_id}\")\n\n        try:\n            # Validate member ID\n            if not member_id:\n                raise ValueError(\"Member ID is required\")\n\n            # Validate limit\n            if limit is not None and (not isinstance(limit, int) or limit < 1):\n                limit = 10\n\n            # Call the service\n            result = await self.history_service.get_auth_history(\n                member_id=member_id,\n                start_date=start_date,\n                end_date=end_date,\n                limit=limit,\n            )\n\n            # Process the result for better usability\n            summary = self._create_auth_summary(result)\n            result[\"summary\"] = summary\n\n            return result\n\n        except Exception as e:\n            logger.error(f\"Error getting authorization history: {e}\")\n            # Return structured error response instead of raising\n            return {\n                \"error\": str(e),\n                \"member_id\": member_id,\n                \"authorizations\": [],\n                \"total_count\": 0,\n                \"summary\": {\n                    \"total_authorizations\": 0,\n                    \"status_counts\": {},\n                    \"service_codes\": {},\n                },\n            }\n\n    def _create_claim_summary(self, claim_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Create a summary of claim data for easier consumption.\n        \"\"\"\n        claims = claim_data.get(\"claims\", [])\n\n        # Count claims by status - ensure status is a string to avoid unhashable issues\n        status_counts = {}\n        for claim in claims:\n            status = str(claim.get(\"status\", \"Unknown\"))\n            status_counts[status] = status_counts.get(status, 0) + 1\n\n        # Count unique service codes - ensure code is a string\n        service_codes = {}\n        for claim in claims:\n            for service in claim.get(\"services\", []):\n                code = str(service.get(\"service_code\", \"Unknown\"))\n                service_codes[code] = service_codes.get(code, 0) + 1\n\n        # Calculate total amounts\n        total_billed = sum(claim.get(\"total_billed\", 0) for claim in claims)\n        total_paid = sum(claim.get(\"total_paid\", 0) for claim in claims)\n\n        # Return the summary\n        return {\n            \"total_claims\": len(claims),\n            \"status_counts\": status_counts,\n            \"service_codes\": service_codes,\n            \"total_billed\": round(total_billed, 2) if total_billed else 0,\n            \"total_paid\": round(total_paid, 2) if total_paid else 0,\n            \"payment_ratio\": (\n                round(total_paid / total_billed, 2) if total_billed > 0 else 0\n            ),\n        }\n\n    def _create_auth_summary(self, auth_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Create a summary of authorization data for easier consumption.\n        \"\"\"\n        auths = auth_data.get(\"authorizations\", [])\n\n        # Count authorizations by status - ensure status is a string\n        status_counts = {}\n        for auth in auths:\n            status = str(auth.get(\"status\", \"Unknown\"))\n            status_counts[status] = status_counts.get(status, 0) + 1\n\n        # Count unique service codes - ensure code is a string\n        service_codes = {}\n        for auth in auths:\n            for service in auth.get(\"services\", []):\n                code = str(service.get(\"service_code\", \"Unknown\"))\n                service_codes[code] = service_codes.get(code, 0) + 1\n\n        # Count active vs. expired auths\n        now = datetime.now().strftime(\"%Y-%m-%d\")\n        active_count = 0\n        for auth in auths:\n            auth_period = auth.get(\"auth_period\", {})\n            end_date = auth_period.get(\"end_date\", \"\")\n            if end_date >= now:\n                active_count += 1\n\n        # Return the summary\n        return {\n            \"total_authorizations\": len(auths),\n            \"active_authorizations\": active_count,\n            \"expired_authorizations\": len(auths) - active_count,\n            \"status_counts\": status_counts,\n            \"service_codes\": service_codes,\n        }\n\n    def build_tool(self) -> List[Tool]:\n        \"\"\"Build the claim and auth history tools for use by an agent.\"\"\"\n\n        # Create synchronous wrapper for async functions\n        def sync_wrapper(async_func):\n            def wrapper(*args, **kwargs):\n                try:\n                    # Create a new event loop for each call\n                    loop = asyncio.new_event_loop()\n                    asyncio.set_event_loop(loop)\n\n                    try:\n                        return loop.run_until_complete(async_func(*args, **kwargs))\n                    finally:\n                        loop.close()\n                except Exception as e:\n                    logger.error(f\"Error in {async_func.__name__}: {str(e)}\")\n                    # Return a structured result with error information\n                    error_response = {\n                        \"error\": str(e),\n                        \"system_error\": True,\n                        \"member_id\": (\n                            args[0] if args else kwargs.get(\"member_id\", \"unknown\")\n                        ),\n                    }\n\n                    # Add specific fields based on which function failed\n                    if async_func.__name__ == \"get_claim_history\":\n                        error_response.update(\n                            {\n                                \"claims\": [],\n                                \"total_count\": 0,\n                                \"summary\": {\n                                    \"total_claims\": 0,\n                                    \"service_codes\": {},\n                                    \"status_counts\": {},\n                                },\n                            }\n                        )\n                    elif async_func.__name__ == \"get_auth_history\":\n                        error_response.update(\n                            {\n                                \"authorizations\": [],\n                                \"total_count\": 0,\n                                \"summary\": {\n                                    \"total_authorizations\": 0,\n                                    \"service_codes\": {},\n                                    \"status_counts\": {},\n                                },\n                            }\n                        )\n\n                    return error_response\n\n            return wrapper\n\n        # Claim history tool with sync wrapper\n        claim_tool = StructuredTool.from_function(\n            name=\"get_claim_history\",\n            description=(\n                \"Retrieve claim history for a member to analyze past services and payments. \"\n                \"This includes details like dates of service, providers, diagnoses, service codes, and payment statuses.\"\n            ),\n            func=sync_wrapper(self.get_claim_history),\n            args_schema=ClaimHistorySchema,\n        )\n\n        # Auth history tool with sync wrapper\n        auth_tool = StructuredTool.from_function(\n            name=\"get_authorization_history\",\n            description=(\n                \"Retrieve authorization history for a member to analyze past and current authorizations. \"\n                \"This includes details like authorization dates, requesting providers, diagnoses, service codes, and statuses.\"\n            ),\n            func=sync_wrapper(self.get_auth_history),\n            args_schema=AuthHistorySchema,\n        )\n\n        return [claim_tool, auth_tool]\n\n    def run_model(self) -> list[Data]:\n        \"\"\"Run the tool directly with the component's inputs, for API/direct use.\"\"\"\n        # Get values from UI inputs or use defaults\n        member_id = (\n            self.default_member_id\n            if hasattr(self, \"default_member_id\") and self.default_member_id\n            else None\n        )\n        start_date = (\n            self.default_start_date\n            if hasattr(self, \"default_start_date\") and self.default_start_date\n            else None\n        )\n        end_date = (\n            self.default_end_date\n            if hasattr(self, \"default_end_date\") and self.default_end_date\n            else None\n        )\n        limit = (\n            self.default_limit\n            if hasattr(self, \"default_limit\") and self.default_limit\n            else 10\n        )\n\n        if not member_id:\n            return [\n                Data(\n                    data={\"error\": \"No member ID provided\"},\n                    text=\"Error: No member ID provided\",\n                )\n            ]\n\n        try:\n            # Create a dedicated event loop for this operation\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n\n            try:\n                # Run both functions in the same event loop\n                claim_future = self.get_claim_history(\n                    member_id=member_id,\n                    start_date=start_date,\n                    end_date=end_date,\n                    limit=limit,\n                )\n\n                auth_future = self.get_auth_history(\n                    member_id=member_id,\n                    start_date=start_date,\n                    end_date=end_date,\n                    limit=limit,\n                )\n\n                # Run both concurrently\n                claim_result, auth_result = loop.run_until_complete(\n                    asyncio.gather(claim_future, auth_future)\n                )\n            finally:\n                loop.close()\n\n            # Safely handle results\n            if not isinstance(claim_result, dict):\n                claim_result = {\n                    \"error\": \"Invalid claim result format\",\n                    \"claims\": [],\n                    \"summary\": {\"total_claims\": 0},\n                }\n\n            if not isinstance(auth_result, dict):\n                auth_result = {\n                    \"error\": \"Invalid auth result format\",\n                    \"authorizations\": [],\n                    \"summary\": {\"total_authorizations\": 0},\n                }\n\n            # Combine results\n            combined_result = {\n                \"member_id\": member_id,\n                \"date_range\": {\"start_date\": start_date, \"end_date\": end_date},\n                \"claims\": claim_result,\n                \"authorizations\": auth_result,\n            }\n\n            # Format the result as a list of Data objects\n            text = f\"Retrieved claim and auth history for member {member_id}.\"\n            if \"summary\" in claim_result:\n                text += (\n                    f\" Found {claim_result['summary'].get('total_claims', 0)} claims\"\n                )\n            if \"summary\" in auth_result:\n                text += f\" and {auth_result['summary'].get('total_authorizations', 0)} authorizations.\"\n\n            return [Data(data=combined_result, text=text)]\n\n        except Exception as e:\n            logger.error(f\"Error retrieving claim and authorization history: {str(e)}\")\n            logger.error(traceback.format_exc())\n            return [\n                Data(\n                    data={\"error\": str(e), \"member_id\": member_id},\n                    text=f\"Error retrieving claim and authorization history: {str(e)}\",\n                )\n            ]\n"
              },
              "default_end_date": {
                "advanced": false,
                "display_name": "Default End Date",
                "dynamic": false,
                "fileTypes": [],
                "file_path": "",
                "info": "Default end date in ISO format (e.g., '2023-12-31').",
                "list": false,
                "load_from_db": false,
                "multiline": false,
                "name": "default_end_date",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str"
              },
              "default_limit": {
                "advanced": false,
                "display_name": "Default Limit",
                "dynamic": false,
                "fileTypes": [],
                "file_path": "",
                "info": "Default maximum number of records to retrieve.",
                "list": false,
                "load_from_db": false,
                "multiline": false,
                "name": "default_limit",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "int"
              },
              "default_member_id": {
                "advanced": false,
                "display_name": "Default Member ID",
                "dynamic": false,
                "fileTypes": [],
                "file_path": "",
                "info": "Default member ID to retrieve history for (optional).",
                "list": false,
                "load_from_db": false,
                "multiline": false,
                "name": "default_member_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "default_start_date": {
                "advanced": false,
                "display_name": "Default Start Date",
                "dynamic": false,
                "fileTypes": [],
                "file_path": "",
                "info": "Default start date in ISO format (e.g., '2023-01-01').",
                "list": false,
                "load_from_db": false,
                "multiline": false,
                "name": "default_start_date",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "QNextAuthHistoryTool"
        },
        "dragging": false,
        "id": "QNextAuthHistoryTool-s2kGz",
        "measured": {
          "height": 559,
          "width": 320
        },
        "position": {
          "x": 986.9291360389806,
          "y": 967.7204955558304
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "PALookupTool-NaTa8",
          "node": {
            "base_classes": [
              "Data",
              "Tool"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Check if Prior Authorization is required for specific service codes.",
            "display_name": "PA Lookup",
            "documentation": "",
            "edited": false,
            "field_order": [
              "default_service_codes",
              "default_lob",
              "default_state"
            ],
            "frozen": false,
            "icon": "Autonomize",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {
              "code_hash": "c98d37159aa3",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "langchain_core",
                    "version": "0.3.76"
                  },
                  {
                    "name": "langflow",
                    "version": null
                  },
                  {
                    "name": "lfx",
                    "version": null
                  },
                  {
                    "name": "pydantic",
                    "version": "2.10.6"
                  }
                ],
                "total_dependencies": 4
              },
              "module": "lfx.components.data.pa_lookup_tool.PALookupTool"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Data",
                "method": "run_model",
                "name": "api_run_model",
                "required_inputs": [],
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Tool",
                "method": "build_tool",
                "name": "api_build_tool",
                "required_inputs": [],
                "selected": "Tool",
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "\"\"\"Tool component for checking Prior Authorization requirements for service codes.\"\"\"\n\nfrom typing import Any, Dict, List\n\nfrom langchain_core.tools import StructuredTool, ToolException\nfrom langflow.base.langchain_utilities.model import LCToolComponent\nfrom langflow.field_typing import Tool\nfrom langflow.inputs import MessageTextInput\nfrom langflow.logging import logger\nfrom lfx.schema.data import Data\nfrom pydantic import BaseModel, Field\n\nfrom langflow.custom.genesis.services.deps import get_pa_lookup_service\n\n\nclass PALookupTool(LCToolComponent):\n    \"\"\"Tool component for checking Prior Authorization requirements for service codes.\"\"\"\n\n    display_name: str = \"PA Lookup\"\n    description: str = (\n        \"Check if Prior Authorization is required for specific service codes.\"\n    )\n    icon: str = \"Autonomize\"\n    name: str = \"PALookupTool\"\n\n    class PALookupSchema(BaseModel):\n        \"\"\"Schema for the PA Lookup tool.\"\"\"\n\n        service_codes: List[str] = Field(\n            ...,\n            description=\"List of service codes to check for Prior Authorization requirements\",\n            examples=[[\"95810\"], [\"58571\", \"38900\"]],\n        )\n        lob: str = Field(\n            ...,\n            description=\"Line of Business: Medicare, Medicaid, or Marketplace\",\n            examples=[\"Medicare\", \"Medicaid\", \"Marketplace\"],\n        )\n        state: str = Field(\n            ...,\n            description=\"Two-letter state code (e.g., MI for Michigan, WA for Washington)\",\n            examples=[\"MI\", \"WA\", \"CA\"],\n        )\n\n    inputs = [\n        MessageTextInput(\n            name=\"default_service_codes\",\n            display_name=\"Default Service Codes\",\n            info=\"Default service codes to check for PA requirements (comma-separated).\",\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"default_lob\",\n            display_name=\"Default Line of Business\",\n            info=\"Default Line of Business (Medicare, Medicaid, Marketplace).\",\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"default_state\",\n            display_name=\"Default State\",\n            info=\"Default two-letter state code.\",\n            tool_mode=True,\n        ),\n    ]\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the PA Lookup Tool component.\"\"\"\n        super().__init__(**kwargs)\n\n    @property\n    def pa_lookup_service(self):\n        \"\"\"Get the PA Lookup service.\"\"\"\n        return get_pa_lookup_service()\n\n    async def check_pa_requirements(\n        self, service_codes: List[str], lob: str, state: str\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Check if prior authorization is required for the specified service codes.\n\n        Args:\n            service_codes: List of service codes to check\n            lob: Line of Business (Medicare, Medicaid, Marketplace)\n            state: Two-letter state code\n\n        Returns:\n            Dictionary containing PA status for each code and other details\n        \"\"\"\n        logger.info(\n            f\"Checking PA requirements for codes: {service_codes}, LOB: {lob}, State: {state}\"\n        )\n\n        try:\n            # Normalize inputs\n            clean_codes = [code.strip() for code in service_codes]\n            clean_lob = lob.strip().title()  # Ensure proper capitalization\n            clean_state = state.strip().upper()\n\n            # Validate LOB\n            if clean_lob not in [\"Medicare\", \"Medicaid\", \"Marketplace\"]:\n                raise ValueError(\n                    f\"Invalid Line of Business: {lob}. Must be Medicare, Medicaid, or Marketplace.\"\n                )\n\n            # Validate state (simplified validation - in production, use a comprehensive list)\n            if len(clean_state) != 2 or not clean_state.isalpha():\n                raise ValueError(\n                    f\"Invalid state code: {state}. Must be a two-letter state code (e.g., MI, WA).\"\n                )\n\n            # Call the service\n            result = await self.pa_lookup_service.check_pa_status(\n                codes=clean_codes, lob=clean_lob, state=clean_state\n            )\n\n            # Process the result for better readability for the agent\n            simplified_result = self._simplify_pa_result(result)\n\n            return simplified_result\n\n        except Exception as e:\n            logger.error(f\"Error checking PA requirements: {e}\")\n            raise ToolException(f\"Error checking PA requirements: {str(e)}\")\n\n    def _simplify_pa_result(self, result: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Simplify the PA lookup result for easier consumption by the agent.\n\n        Args:\n            result: Raw PA lookup result\n\n        Returns:\n            Simplified result\n        \"\"\"\n        simplified = {\"status\": result.get(\"message\", \"Unknown\"), \"codes\": {}}\n\n        # Extract PA status for each code\n        pa_data_group = result.get(\"paStatusDataGrp\", {})\n        pa_required_data = pa_data_group.get(\"paRequiredData\", [])\n\n        for code_data in pa_required_data:\n            code = code_data.get(\"Code\", \"Unknown\")\n            pa_status = code_data.get(\"paStatus\", \"Unknown\")\n            description = code_data.get(\"codeDesc\", \"\")\n\n            # Simplify the PA status for easier interpretation\n            is_required = \"Required\" in pa_status\n            has_exclusions = \"Exclusions\" in pa_status\n\n            simplified[\"codes\"][code] = {\n                \"description\": description,\n                \"pa_required\": is_required,\n                \"has_exclusions\": has_exclusions,\n                \"full_status\": pa_status,\n            }\n\n        return simplified\n\n    def build_tool(self) -> Tool:\n        \"\"\"Build the PA Lookup tool for use by an agent.\"\"\"\n\n        # Create synchronous wrapper for async function\n        def sync_wrapper(async_func):\n            def wrapper(*args, **kwargs):\n                try:\n                    import asyncio\n\n                    # Create a new event loop for each call\n                    loop = asyncio.new_event_loop()\n                    asyncio.set_event_loop(loop)\n\n                    try:\n                        return loop.run_until_complete(async_func(*args, **kwargs))\n                    finally:\n                        loop.close()\n                except Exception as e:\n                    logger.error(f\"Error in {async_func.__name__}: {str(e)}\")\n                    # Return structured error response\n                    return {\n                        \"error\": str(e),\n                        \"status\": \"Error\",\n                        \"codes\": {},\n                        \"service_codes\": kwargs.get(\"service_codes\", []),\n                        \"lob\": kwargs.get(\"lob\", \"\"),\n                        \"state\": kwargs.get(\"state\", \"\"),\n                        \"system_error\": True,\n                    }\n\n            return wrapper\n\n        return StructuredTool.from_function(\n            name=\"check_prior_authorization\",\n            description=\"Check if Prior Authorization (PA) is required for specific service codes based on Line of Business (Medicare, Medicaid, Marketplace) and state.\",\n            func=sync_wrapper(self.check_pa_requirements),\n            args_schema=self.PALookupSchema,\n        )\n\n    def run_model(self) -> list[Data]:\n        \"\"\"Run the tool directly with the component's inputs, for API/direct use.\"\"\"\n        # Get values from UI inputs or use defaults\n        service_codes_str = (\n            self.default_service_codes\n            if hasattr(self, \"default_service_codes\") and self.default_service_codes\n            else \"\"\n        )\n        service_codes = (\n            [code.strip() for code in service_codes_str.split(\",\")]\n            if service_codes_str\n            else []\n        )\n\n        lob = (\n            self.default_lob\n            if hasattr(self, \"default_lob\") and self.default_lob\n            else \"Medicare\"\n        )\n        state = (\n            self.default_state\n            if hasattr(self, \"default_state\") and self.default_state\n            else \"MI\"\n        )\n\n        if not service_codes:\n            return [\n                Data(\n                    data={\"error\": \"No service codes provided\"},\n                    text=\"Error: No service codes provided\",\n                )\n            ]\n\n        # Get the tool to use its structured functionality\n        self.build_tool()\n\n        try:\n            import asyncio\n\n            # Create a dedicated event loop\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n\n            try:\n                result = loop.run_until_complete(\n                    self.check_pa_requirements(\n                        service_codes=service_codes, lob=lob, state=state\n                    )\n                )\n            finally:\n                loop.close()\n\n            # Format the result as text\n            text_result = (\n                f\"PA Status Results for {len(service_codes)} service codes\\n\\n\"\n            )\n\n            for code, code_info in result.get(\"codes\", {}).items():\n                pa_required = (\n                    \"Required\" if code_info.get(\"pa_required\") else \"Not Required\"\n                )\n                text_result += f\"Code: {code} - {code_info.get('description', '')}\\n\"\n                text_result += f\"PA Status: {pa_required}\\n\"\n                if code_info.get(\"has_exclusions\"):\n                    text_result += \"Note: This code has some exclusions or conditions\\n\"\n                text_result += f\"Full Status: {code_info.get('full_status', '')}\\n\\n\"\n\n            return [Data(data=result, text=text_result)]\n\n        except Exception as e:\n            error_message = f\"Error checking PA requirements: {str(e)}\"\n            return [Data(data={\"error\": error_message}, text=error_message)]\n"
              },
              "default_lob": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Default Line of Business",
                "dynamic": false,
                "info": "Default Line of Business (Medicare, Medicaid, Marketplace).",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "default_lob",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "default_service_codes": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Default Service Codes",
                "dynamic": false,
                "info": "Default service codes to check for PA requirements (comma-separated).",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "default_service_codes",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "default_state": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Default State",
                "dynamic": false,
                "info": "Default two-letter state code.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "default_state",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "PALookupTool"
        },
        "dragging": false,
        "id": "PALookupTool-NaTa8",
        "measured": {
          "height": 473,
          "width": 320
        },
        "position": {
          "x": 750.1017109744134,
          "y": -615.0291635975764
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "KnowledgeHubSearch-ICnyv",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "category": "vectorstores",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "This component is used to search for information in the knowledge hub.",
            "display_name": "Knowledge Hub Search",
            "documentation": "http://docs.langflow.org/components/custom",
            "edited": false,
            "field_order": [
              "search_query",
              "selected_hubs"
            ],
            "frozen": false,
            "icon": "Autonomize",
            "key": "KnowledgeHubSearch",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {
              "code_hash": "ccfec8690c10",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "lfx",
                    "version": null
                  },
                  {
                    "name": "loguru",
                    "version": "0.7.3"
                  }
                ],
                "total_dependencies": 2
              },
              "module": "lfx.components.knowledge_bases.knowledge_hub.KnowledgeHub"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "hidden": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.01857804455091699,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from __future__ import annotations\n\nfrom typing import Any\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import MultilineInput, MultiselectInput, Output\nfrom lfx.schema.data import Data\nfrom lfx.services.manager import get_service_manager\nfrom loguru import logger\n\n\nclass KnowledgeHub(Component):\n    display_name = \"Knowledge Hub Search\"\n    description = (\n        \"This component is used to search for information in the knowledge hub.\"\n    )\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"Autonomize\"\n    name = \"KnowledgeHubSearch\"\n\n    def __init__(self, **kwargs):\n        self._hub_data: list[dict[str, str]] = []\n        self._selected_hub_names: list[str] = []  # Track selected hub names\n        super().__init__(**kwargs)\n\n    async def update_build_config(\n        self, build_config: dict, field_value: Any, field_name: str | None = None\n    ):\n        \"\"\"Update the build configuration based on field changes.\"\"\"\n        logger.info(f\"update_build_config called with field_name: {field_name}\")\n\n        if field_name == \"selected_hubs\":\n            try:\n                # Load the hub options when the field is refreshed\n                service = get_service_manager().get(\"knowledge_service\")\n                if not service.ready:\n                    logger.error(\"KnowledgeHub service is not ready\")\n                    return build_config\n                self._hub_data = await service.get_knowledge_hubs()\n\n                # Debug the raw response\n                logger.info(f\"Raw hub data: {self._hub_data}\")\n\n                options = [hub[\"name\"] for hub in self._hub_data]\n                logger.info(f\"Extracted hub options: {options}\")\n\n                # Debug the build_config before update\n                logger.info(\n                    f\"Build config before update: {build_config.get('selected_hubs', {})}\"\n                )\n\n                build_config[\"selected_hubs\"][\"options\"] = options\n\n                # Store selected hub names for validation during build\n                if field_value and isinstance(field_value, list):\n                    self._selected_hub_names = field_value\n                    logger.info(\n                        f\"Stored selected hub names: {self._selected_hub_names}\"\n                    )\n\n                # Debug the build_config after update\n                logger.info(\n                    f\"Build config after update: {build_config.get('selected_hubs', {})}\"\n                )\n\n                return build_config\n            except Exception as e:\n                logger.exception(f\"Error in update_build_config: {e!s}\")\n                raise\n        return build_config\n\n    inputs = [\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n            tool_mode=True,\n        ),\n        MultiselectInput(\n            name=\"selected_hubs\",\n            display_name=\"Data Sources\",\n            value=[],\n            refresh_button=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Query Results\",\n            name=\"query_results\",\n            method=\"build_output\",\n        ),\n    ]\n\n    async def _validate_and_refresh_data_sources(self) -> tuple[bool, list[str]]:\n        \"\"\"Validate that the selected data sources are still available, if not fetch and update them\"\"\"\n        if not self._selected_hub_names:\n            logger.info(\"No data sources selected, validation skipped\")\n            return True, []\n\n        try:\n            # Fetch fresh hub data\n            service = get_service_manager().get(\"knowledge_service\")\n            if not service.ready:\n                logger.error(\"KnowledgeHub service is not ready for validation\")\n                return (\n                    True,\n                    self._selected_hub_names,\n                )  # Return original selection if service not ready\n\n            fresh_hub_data = await service.get_knowledge_hubs()\n            available_names = [hub[\"name\"] for hub in fresh_hub_data]\n\n            logger.info(f\"Available data sources: {available_names}\")\n            logger.info(f\"Selected data sources: {self._selected_hub_names}\")\n\n            # Check which selected hubs are still available\n            still_available = []\n            missing_hubs = []\n            refreshed_hubs = []\n\n            for selected_name in self._selected_hub_names:\n                if selected_name in available_names:\n                    still_available.append(selected_name)\n                    logger.info(f\"Data source '{selected_name}' is still available\")\n                else:\n                    missing_hubs.append(selected_name)\n                    logger.warning(\n                        f\"Data source '{selected_name}' is no longer available\"\n                    )\n\n            # Try to find missing hubs in fresh data (in case of name changes or refresh issues)\n            for missing_name in missing_hubs:\n                # Look for exact match first\n                found_hub = next(\n                    (hub for hub in fresh_hub_data if hub[\"name\"] == missing_name), None\n                )\n\n                if found_hub:\n                    still_available.append(found_hub[\"name\"])\n                    refreshed_hubs.append(found_hub[\"name\"])\n                    logger.info(\n                        f\"Refreshed data source '{missing_name}' found and re-added\"\n                    )\n                else:\n                    # Try partial match (in case of minor name changes)\n                    partial_matches = [\n                        hub[\"name\"]\n                        for hub in fresh_hub_data\n                        if missing_name.lower() in hub[\"name\"].lower()\n                        or hub[\"name\"].lower() in missing_name.lower()\n                    ]\n\n                    if partial_matches:\n                        logger.info(\n                            f\"Possible matches for missing '{missing_name}': {partial_matches}\"\n                        )\n                        # For now, don't auto-select partial matches, just log them\n                    else:\n                        logger.error(\n                            f\"Data source '{missing_name}' not found even after refresh\"\n                        )\n\n            # Update the hub data cache\n            self._hub_data = fresh_hub_data\n\n            # Update selected hub names to only include available ones\n            self._selected_hub_names = still_available\n\n            if refreshed_hubs:\n                logger.info(f\"Successfully refreshed data sources: {refreshed_hubs}\")\n\n            if missing_hubs and not refreshed_hubs:\n                logger.warning(\n                    f\"Some data sources are no longer available: {[h for h in missing_hubs if h not in refreshed_hubs]}\"\n                )\n                return False, still_available\n\n            return True, still_available\n\n        except Exception as e:\n            logger.error(f\"Error validating/refreshing data sources: {e}\")\n            logger.exception(\"Full error details:\")\n            # If we can't validate, return original selection to avoid breaking the flow\n            return True, self._selected_hub_names\n\n    async def build_output(self) -> Data:\n        \"\"\"Generate the output based on selected knowledge hubs.\"\"\"\n        try:\n            # Validate and refresh data sources if needed\n            if self._selected_hub_names:\n                is_valid, validated_hubs = (\n                    await self._validate_and_refresh_data_sources()\n                )\n\n                if not is_valid and not validated_hubs:\n                    error_message = f\"Error: Selected data sources are no longer available. Please select different data sources.\"\n                    logger.error(error_message)\n                    return Data(\n                        text=error_message,\n                        data={\"error\": error_message, \"query_results\": []},\n                    )\n\n                # Use validated hubs instead of self.selected_hubs\n                effective_selected_hubs = validated_hubs\n            else:\n                effective_selected_hubs = (\n                    self.selected_hubs if hasattr(self, \"selected_hubs\") else []\n                )\n\n            if not effective_selected_hubs:\n                logger.warning(\"No knowledge hubs selected or available.\")\n                return Data(value={\"query_results\": []})\n\n            # Make sure we have hub data\n            if not self._hub_data:\n                service = get_service_manager().get(\"knowledge_service\")\n                if not service.ready:\n                    logger.error(\"KnowledgeHub service is not ready\")\n                    return Data(value={\"query_results\": []})\n                self._hub_data = await service.get_knowledge_hubs()\n\n            # Map the selected names to their IDs\n            selected_hub_ids = [\n                hub[\"id\"]\n                for hub in self._hub_data\n                if hub[\"name\"] in effective_selected_hubs\n            ]\n\n            logger.info(f\"Using data sources: {effective_selected_hubs}\")\n            logger.info(f\"Mapped to hub IDs: {selected_hub_ids}\")\n\n            service = get_service_manager().get(\"knowledge_service\")\n            if not service.ready:\n                logger.error(\"KnowledgeHub service is not ready\")\n                return Data(value={\"query_results\": []})\n\n            query_results = await service.query_vector_store(\n                knowledge_hub_ids=selected_hub_ids, query=self.search_query\n            )\n            logger.debug(f\"query_results: {query_results}\")\n\n            # Concatenate content from query results\n            contents = [\n                result.get(\"metadata\", {}).get(\"content\", \"\")\n                for result in query_results\n            ]\n            plain_text = \"\\n\\n=== NEW CHUNK ===\\n\\n\".join(contents)\n\n            data = Data(\n                text=plain_text,\n                data={\n                    \"result\": query_results,\n                    \"used_data_sources\": effective_selected_hubs,  # Include which sources were actually used\n                },\n            )\n            self.status = data\n            return data\n\n        except Exception as e:\n            logger.error(f\"Error in build_output: {e!s}\")\n            return Data(value={\"query_results\": []})\n"
              },
              "search_query": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "search_query",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "what are the services that are covered for you ?"
              },
              "selected_hubs": {
                "_input_type": "MultiselectInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Data Sources",
                "dynamic": false,
                "info": "",
                "list": true,
                "name": "selected_hubs",
                "options": [],
                "placeholder": "",
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": [
                  "Sample EOC Guidelines"
                ]
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tools",
                "value": [
                  {
                    "args": {
                      "search_query": {
                        "default": "",
                        "description": "",
                        "title": "Search Query",
                        "type": "string"
                      }
                    },
                    "description": "KnowledgeHubSearch. build_output - This component is used to search for information in the knowledge hub.",
                    "display_description": "KnowledgeHubSearch. build_output - This component is used to search for information in the knowledge hub.",
                    "display_name": "build_output",
                    "name": "build_output",
                    "readonly": false,
                    "status": true,
                    "tags": [
                      "build_output"
                    ]
                  }
                ]
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "KnowledgeHubSearch"
        },
        "dragging": false,
        "id": "KnowledgeHubSearch-ICnyv",
        "measured": {
          "height": 385,
          "width": 320
        },
        "position": {
          "x": 815.219806137723,
          "y": -1514.1069040623706
        },
        "selected": true,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt-tXVY4",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": []
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "name": "prompt",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "# Accumulator Check Agent Prompt\n\nYou are a Healthcare Utilization Management Specialist responsible for validating that requested services don't exceed allowed frequency or quantity limits. You'll analyze authorization requests against historical claims, determine past usage, and verify compliance with benefit limits.\n\n## INPUT:\nYou will receive a Healthcare Authorization Processing Report from the initial assessment. This report contains service codes, descriptions, member information, and claim/authorization history.\n\n## PROCESS:\n\n### 1. Parse the Authorization Report:\nExtract key data elements:\n- Member information (ID, plan, state, line of business)\n- Service code details (codes, descriptions, types, units requested)\n- Claims history (past usage of the same services)\n- Authorization history (previously approved authorizations)\n\n### 2. For Each Service Code:\n- Use knowledgehub tool to find relevant usage limits using this query format:\n  ```\n  What is the allowed usage limit for [SERVICE DESCRIPTION] (CPT/HCPCS code [CODE]) for [UNITS] units? \n  Return policy-based frequency caps or visit limits.\n  ```\n- Specify the following parameters:\n  * collection_name: \"benefits_limits_collection\"\n  * Should include any relevant filters based on member's plan\n\n### 3. Calculate Past Utilization:\n- Identify past claims that used the same service code\n- Count total units used within relevant timeframes (calendar year, rolling periods)\n- Consider authorization history to understand utilization patterns\n\n### 4. Validate Against Limits:\nFor each service code, determine if:\n- A specific usage limit exists (frequency caps, visit limits, annual maximums)\n- The requested units + previously used units would exceed this limit\n- Any timeframe restrictions apply (calendar year, rolling 12 months, lifetime)\n- Special conditions or exceptions apply based on diagnosis\n\n### 5. When No Explicit Limits Found:\n- Fall back to analyzing EOC benefit language for implied limits\n- Look for terms like \"once per year,\" \"limited to X visits,\" etc.\n\n## OUTPUT:\n\nProvide a comprehensive utilization validation report with these sections:\n\n**ACCUMULATOR VALIDATION SUMMARY:**\n- Overview of all services and validation results\n\n**SERVICE UTILIZATION DETAILS:**\nFor each service code:\n- **Service Code:** [CODE]\n- **Service Description:** [DESCRIPTION]\n- **Units Requested:** [UNITS]\n- **Previous Utilization:** [TOTAL PAST UNITS]\n- **Validation Status:** VALIDATED or NOT VALIDATED\n- **Justification:** Explain the decision based on limits and past usage\n- **Applicable Limits:** Quote the most relevant usage limit language\n\n**FINAL RECOMMENDATION:**\n- Overall recommendation based on the validation results\n- Any additional steps required\n\n## GUIDELINES:\n\n1. Consider both upper limits (maximum allowed in period) and lower limits (minimum time between services)\n2. Pay special attention to timelines - calendar year vs. rolling periods\n3. When usage limits are ambiguous, quote the exact language and explain your interpretation\n4. Note that some services have combined limits (e.g., shared visit limits across therapy types)\n5. For DME items, check if they have lifetime limits or replacement schedules\n6. Identify any diagnosis-dependent limitations (some services are limited unless specific conditions are present)\n\nYour goal is to ensure requested services comply with all frequency and quantity limits specified in the member's benefit plan, preventing overutilization while ensuring appropriate access to needed services."
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt"
        },
        "dragging": false,
        "id": "Prompt-tXVY4",
        "measured": {
          "height": 257,
          "width": 320
        },
        "position": {
          "x": 1024.0095542783142,
          "y": 58.709552432460015
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "KnowledgeHubSearch-oOLSB",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "category": "vectorstores",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "This component is used to search for information in the knowledge hub.",
            "display_name": "Knowledge Hub Search",
            "documentation": "http://docs.langflow.org/components/custom",
            "edited": false,
            "field_order": [
              "search_query",
              "selected_hubs"
            ],
            "frozen": false,
            "icon": "Autonomize",
            "key": "KnowledgeHubSearch",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {
              "code_hash": "ccfec8690c10",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "lfx",
                    "version": null
                  },
                  {
                    "name": "loguru",
                    "version": "0.7.3"
                  }
                ],
                "total_dependencies": 2
              },
              "module": "lfx.components.knowledge_bases.knowledge_hub.KnowledgeHub"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "hidden": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.01857804455091699,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from __future__ import annotations\n\nfrom typing import Any\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import MultilineInput, MultiselectInput, Output\nfrom lfx.schema.data import Data\nfrom lfx.services.manager import get_service_manager\nfrom loguru import logger\n\n\nclass KnowledgeHub(Component):\n    display_name = \"Knowledge Hub Search\"\n    description = (\n        \"This component is used to search for information in the knowledge hub.\"\n    )\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"Autonomize\"\n    name = \"KnowledgeHubSearch\"\n\n    def __init__(self, **kwargs):\n        self._hub_data: list[dict[str, str]] = []\n        self._selected_hub_names: list[str] = []  # Track selected hub names\n        super().__init__(**kwargs)\n\n    async def update_build_config(\n        self, build_config: dict, field_value: Any, field_name: str | None = None\n    ):\n        \"\"\"Update the build configuration based on field changes.\"\"\"\n        logger.info(f\"update_build_config called with field_name: {field_name}\")\n\n        if field_name == \"selected_hubs\":\n            try:\n                # Load the hub options when the field is refreshed\n                service = get_service_manager().get(\"knowledge_service\")\n                if not service.ready:\n                    logger.error(\"KnowledgeHub service is not ready\")\n                    return build_config\n                self._hub_data = await service.get_knowledge_hubs()\n\n                # Debug the raw response\n                logger.info(f\"Raw hub data: {self._hub_data}\")\n\n                options = [hub[\"name\"] for hub in self._hub_data]\n                logger.info(f\"Extracted hub options: {options}\")\n\n                # Debug the build_config before update\n                logger.info(\n                    f\"Build config before update: {build_config.get('selected_hubs', {})}\"\n                )\n\n                build_config[\"selected_hubs\"][\"options\"] = options\n\n                # Store selected hub names for validation during build\n                if field_value and isinstance(field_value, list):\n                    self._selected_hub_names = field_value\n                    logger.info(\n                        f\"Stored selected hub names: {self._selected_hub_names}\"\n                    )\n\n                # Debug the build_config after update\n                logger.info(\n                    f\"Build config after update: {build_config.get('selected_hubs', {})}\"\n                )\n\n                return build_config\n            except Exception as e:\n                logger.exception(f\"Error in update_build_config: {e!s}\")\n                raise\n        return build_config\n\n    inputs = [\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n            tool_mode=True,\n        ),\n        MultiselectInput(\n            name=\"selected_hubs\",\n            display_name=\"Data Sources\",\n            value=[],\n            refresh_button=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Query Results\",\n            name=\"query_results\",\n            method=\"build_output\",\n        ),\n    ]\n\n    async def _validate_and_refresh_data_sources(self) -> tuple[bool, list[str]]:\n        \"\"\"Validate that the selected data sources are still available, if not fetch and update them\"\"\"\n        if not self._selected_hub_names:\n            logger.info(\"No data sources selected, validation skipped\")\n            return True, []\n\n        try:\n            # Fetch fresh hub data\n            service = get_service_manager().get(\"knowledge_service\")\n            if not service.ready:\n                logger.error(\"KnowledgeHub service is not ready for validation\")\n                return (\n                    True,\n                    self._selected_hub_names,\n                )  # Return original selection if service not ready\n\n            fresh_hub_data = await service.get_knowledge_hubs()\n            available_names = [hub[\"name\"] for hub in fresh_hub_data]\n\n            logger.info(f\"Available data sources: {available_names}\")\n            logger.info(f\"Selected data sources: {self._selected_hub_names}\")\n\n            # Check which selected hubs are still available\n            still_available = []\n            missing_hubs = []\n            refreshed_hubs = []\n\n            for selected_name in self._selected_hub_names:\n                if selected_name in available_names:\n                    still_available.append(selected_name)\n                    logger.info(f\"Data source '{selected_name}' is still available\")\n                else:\n                    missing_hubs.append(selected_name)\n                    logger.warning(\n                        f\"Data source '{selected_name}' is no longer available\"\n                    )\n\n            # Try to find missing hubs in fresh data (in case of name changes or refresh issues)\n            for missing_name in missing_hubs:\n                # Look for exact match first\n                found_hub = next(\n                    (hub for hub in fresh_hub_data if hub[\"name\"] == missing_name), None\n                )\n\n                if found_hub:\n                    still_available.append(found_hub[\"name\"])\n                    refreshed_hubs.append(found_hub[\"name\"])\n                    logger.info(\n                        f\"Refreshed data source '{missing_name}' found and re-added\"\n                    )\n                else:\n                    # Try partial match (in case of minor name changes)\n                    partial_matches = [\n                        hub[\"name\"]\n                        for hub in fresh_hub_data\n                        if missing_name.lower() in hub[\"name\"].lower()\n                        or hub[\"name\"].lower() in missing_name.lower()\n                    ]\n\n                    if partial_matches:\n                        logger.info(\n                            f\"Possible matches for missing '{missing_name}': {partial_matches}\"\n                        )\n                        # For now, don't auto-select partial matches, just log them\n                    else:\n                        logger.error(\n                            f\"Data source '{missing_name}' not found even after refresh\"\n                        )\n\n            # Update the hub data cache\n            self._hub_data = fresh_hub_data\n\n            # Update selected hub names to only include available ones\n            self._selected_hub_names = still_available\n\n            if refreshed_hubs:\n                logger.info(f\"Successfully refreshed data sources: {refreshed_hubs}\")\n\n            if missing_hubs and not refreshed_hubs:\n                logger.warning(\n                    f\"Some data sources are no longer available: {[h for h in missing_hubs if h not in refreshed_hubs]}\"\n                )\n                return False, still_available\n\n            return True, still_available\n\n        except Exception as e:\n            logger.error(f\"Error validating/refreshing data sources: {e}\")\n            logger.exception(\"Full error details:\")\n            # If we can't validate, return original selection to avoid breaking the flow\n            return True, self._selected_hub_names\n\n    async def build_output(self) -> Data:\n        \"\"\"Generate the output based on selected knowledge hubs.\"\"\"\n        try:\n            # Validate and refresh data sources if needed\n            if self._selected_hub_names:\n                is_valid, validated_hubs = (\n                    await self._validate_and_refresh_data_sources()\n                )\n\n                if not is_valid and not validated_hubs:\n                    error_message = f\"Error: Selected data sources are no longer available. Please select different data sources.\"\n                    logger.error(error_message)\n                    return Data(\n                        text=error_message,\n                        data={\"error\": error_message, \"query_results\": []},\n                    )\n\n                # Use validated hubs instead of self.selected_hubs\n                effective_selected_hubs = validated_hubs\n            else:\n                effective_selected_hubs = (\n                    self.selected_hubs if hasattr(self, \"selected_hubs\") else []\n                )\n\n            if not effective_selected_hubs:\n                logger.warning(\"No knowledge hubs selected or available.\")\n                return Data(value={\"query_results\": []})\n\n            # Make sure we have hub data\n            if not self._hub_data:\n                service = get_service_manager().get(\"knowledge_service\")\n                if not service.ready:\n                    logger.error(\"KnowledgeHub service is not ready\")\n                    return Data(value={\"query_results\": []})\n                self._hub_data = await service.get_knowledge_hubs()\n\n            # Map the selected names to their IDs\n            selected_hub_ids = [\n                hub[\"id\"]\n                for hub in self._hub_data\n                if hub[\"name\"] in effective_selected_hubs\n            ]\n\n            logger.info(f\"Using data sources: {effective_selected_hubs}\")\n            logger.info(f\"Mapped to hub IDs: {selected_hub_ids}\")\n\n            service = get_service_manager().get(\"knowledge_service\")\n            if not service.ready:\n                logger.error(\"KnowledgeHub service is not ready\")\n                return Data(value={\"query_results\": []})\n\n            query_results = await service.query_vector_store(\n                knowledge_hub_ids=selected_hub_ids, query=self.search_query\n            )\n            logger.debug(f\"query_results: {query_results}\")\n\n            # Concatenate content from query results\n            contents = [\n                result.get(\"metadata\", {}).get(\"content\", \"\")\n                for result in query_results\n            ]\n            plain_text = \"\\n\\n=== NEW CHUNK ===\\n\\n\".join(contents)\n\n            data = Data(\n                text=plain_text,\n                data={\n                    \"result\": query_results,\n                    \"used_data_sources\": effective_selected_hubs,  # Include which sources were actually used\n                },\n            )\n            self.status = data\n            return data\n\n        except Exception as e:\n            logger.error(f\"Error in build_output: {e!s}\")\n            return Data(value={\"query_results\": []})\n"
              },
              "search_query": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "search_query",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "what are the services that are covered for you ?"
              },
              "selected_hubs": {
                "_input_type": "MultiselectInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Data Sources",
                "dynamic": false,
                "info": "",
                "list": true,
                "name": "selected_hubs",
                "options": [],
                "placeholder": "",
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": [
                  "CMS Benefits Accumulator Guidelines"
                ]
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tools",
                "value": [
                  {
                    "args": {
                      "search_query": {
                        "default": "",
                        "description": "",
                        "title": "Search Query",
                        "type": "string"
                      }
                    },
                    "description": "KnowledgeHubSearch. build_output - This component is used to search for information in the knowledge hub.",
                    "display_description": "KnowledgeHubSearch. build_output - This component is used to search for information in the knowledge hub.",
                    "display_name": "build_output",
                    "name": "build_output",
                    "readonly": false,
                    "status": true,
                    "tags": [
                      "build_output"
                    ]
                  }
                ]
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "KnowledgeHubSearch"
        },
        "dragging": false,
        "id": "KnowledgeHubSearch-oOLSB",
        "measured": {
          "height": 385,
          "width": 320
        },
        "position": {
          "x": 858.0019088439532,
          "y": 415.6556869246377
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-Jfah7",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {
              "code_hash": "ccda4dbe4ae1",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "orjson",
                    "version": "3.10.15"
                  },
                  {
                    "name": "fastapi",
                    "version": "0.117.1"
                  },
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 3
              },
              "module": "lfx.components.input_output.chat_output.ChatOutput"
            },
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean data before converting to string.",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom lfx.base.io.chat import ChatComponent\nfrom lfx.helpers.data import safe_convert\nfrom lfx.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.message import Message\nfrom lfx.schema.properties import Source\nfrom lfx.template.field.base import Output\nfrom lfx.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            advanced=True,\n            info=\"Whether to clean data before converting to string.\",\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            clean_data: bool = getattr(self, \"clean_data\", False)\n            return \"\\n\".join([safe_convert(item, clean_data=clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-Jfah7",
        "measured": {
          "height": 65,
          "width": 192
        },
        "position": {
          "x": 2909.6327349706667,
          "y": -410.8223292222654
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Agent-TjsA4",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "display_name": "EOC Check Agent",
            "documentation": "",
            "edited": false,
            "field_order": [
              "agent_llm",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "system_prompt",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "return_intermediate_steps",
              "agent_description",
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template",
              "add_current_date_tool"
            ],
            "frozen": false,
            "icon": "bot",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {
              "code_hash": "d61b1f3d692a",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "langchain_core",
                    "version": "0.3.76"
                  },
                  {
                    "name": "pydantic",
                    "version": "2.10.6"
                  },
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 3
              },
              "module": "lfx.components.agents.agent.AgentComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "hidden": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "add_current_date_tool": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Current Date",
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "input_types": [],
                "list": false,
                "name": "add_current_date_tool",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "agent_llm": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Model Provider",
                "dynamic": false,
                "info": "The provider of the language model that the agent will use to generate responses.",
                "input_types": [],
                "name": "agent_llm",
                "options": [
                  "Anthropic",
                  "Google Generative AI",
                  "OpenAI"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Azure OpenAI"
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nimport re\n\nfrom langchain_core.tools import StructuredTool, Tool\nfrom pydantic import ValidationError\n\nfrom lfx.base.agents.agent import LCToolsAgentComponent\nfrom lfx.base.agents.events import ExceptionWithMessageError\nfrom lfx.base.models.model_input_constants import (\n    ALL_PROVIDER_FIELDS,\n    MODEL_DYNAMIC_UPDATE_FIELDS,\n    MODEL_PROVIDERS_DICT,\n    MODELS_METADATA,\n)\nfrom lfx.base.models.model_utils import get_model_name\nfrom lfx.components.helpers.current_date import CurrentDateComponent\nfrom lfx.components.helpers.memory import MemoryComponent\nfrom lfx.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom lfx.custom.custom_component.component import get_component_toolkit\nfrom lfx.custom.utils import update_component_build_config\nfrom lfx.helpers.base_model import build_model_from_schema\nfrom lfx.inputs.inputs import BoolInput\nfrom lfx.io import DropdownInput, IntInput, MultilineInput, Output, TableInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.dotdict import dotdict\nfrom lfx.schema.message import Message\nfrom lfx.schema.table import EditMode\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nMODEL_PROVIDERS_LIST = [\"Anthropic\", \"Google Generative AI\", \"OpenAI\"]\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    documentation: str = \"https://docs.langflow.org/agents\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    # Filter out json_mode from OpenAI inputs since we handle structured output differently\n    if \"OpenAI\" in MODEL_PROVIDERS_DICT:\n        openai_inputs_filtered = [\n            input_field\n            for input_field in MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"]\n            if not (hasattr(input_field, \"name\") and input_field.name == \"json_mode\")\n        ]\n    else:\n        openai_inputs_filtered = []\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*MODEL_PROVIDERS_LIST],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            refresh_button=False,\n            input_types=[],\n            options_metadata=[MODELS_METADATA[key] for key in MODEL_PROVIDERS_LIST if key in MODELS_METADATA]\n            + [{\"icon\": \"brain\"}],\n            external_options={\n                \"fields\": {\n                    \"data\": {\n                        \"node\": {\n                            \"name\": \"connect_other_models\",\n                            \"display_name\": \"Connect other models\",\n                            \"icon\": \"CornerDownLeft\",\n                        }\n                    }\n                },\n            },\n        ),\n        *openai_inputs_filtered,\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Chat History Messages\",\n            value=100,\n            info=\"Number of chat history messages to retrieve.\",\n            advanced=True,\n            show=True,\n        ),\n        MultilineInput(\n            name=\"format_instructions\",\n            display_name=\"Output Format Instructions\",\n            info=\"Generic Template for structured output formatting. Valid only with Structured response.\",\n            value=(\n                \"You are an AI that extracts structured JSON objects from unstructured text. \"\n                \"Use a predefined schema with expected types (str, int, float, bool, dict). \"\n                \"Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. \"\n                \"Fill missing or ambiguous values with defaults: null for missing values. \"\n                \"Remove exact duplicates but keep variations that have different field values. \"\n                \"Always return valid JSON in the expected format, never throw errors. \"\n                \"If multiple objects can be extracted, return them all in the structured format.\"\n            ),\n            advanced=True,\n        ),\n        TableInput(\n            name=\"output_schema\",\n            display_name=\"Output Schema\",\n            info=(\n                \"Schema Validation: Define the structure and data types for structured output. \"\n                \"No validation if no output schema.\"\n            ),\n            advanced=True,\n            required=False,\n            value=[],\n            table_schema=[\n                {\n                    \"name\": \"name\",\n                    \"display_name\": \"Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Specify the name of the output field.\",\n                    \"default\": \"field\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"description\",\n                    \"display_name\": \"Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Describe the purpose of the output field.\",\n                    \"default\": \"description of field\",\n                    \"edit_mode\": EditMode.POPOVER,\n                },\n                {\n                    \"name\": \"type\",\n                    \"display_name\": \"Type\",\n                    \"type\": \"str\",\n                    \"edit_mode\": EditMode.INLINE,\n                    \"description\": (\"Indicate the data type of the output field (e.g., str, int, float, bool, dict).\"),\n                    \"options\": [\"str\", \"int\", \"float\", \"bool\", \"dict\"],\n                    \"default\": \"str\",\n                },\n                {\n                    \"name\": \"multiple\",\n                    \"display_name\": \"As List\",\n                    \"type\": \"boolean\",\n                    \"description\": \"Set to True if this output field should be a list of the specified type.\",\n                    \"default\": \"False\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n            ],\n        ),\n        *LCToolsAgentComponent.get_base_inputs(),\n        # removed memory inputs from agent component\n        # *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [\n        Output(name=\"response\", display_name=\"Response\", method=\"message_response\"),\n    ]\n\n    async def get_agent_requirements(self):\n        \"\"\"Get the agent requirements for the agent.\"\"\"\n        llm_model, display_name = await self.get_llm()\n        if llm_model is None:\n            msg = \"No language model selected. Please choose a model to proceed.\"\n            raise ValueError(msg)\n        self.model_name = get_model_name(llm_model, display_name=display_name)\n\n        # Get memory data\n        self.chat_history = await self.get_memory_data()\n        if isinstance(self.chat_history, Message):\n            self.chat_history = [self.chat_history]\n\n        # Add current date tool if enabled\n        if self.add_current_date_tool:\n            if not isinstance(self.tools, list):  # type: ignore[has-type]\n                self.tools = []\n            current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n            if not isinstance(current_date_tool, StructuredTool):\n                msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                raise TypeError(msg)\n            self.tools.append(current_date_tool)\n        return llm_model, self.chat_history, self.tools\n\n    async def message_response(self) -> Message:\n        try:\n            llm_model, self.chat_history, self.tools = await self.get_agent_requirements()\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            result = await self.run_agent(agent)\n\n            # Store result for potential JSON output\n            self._agent_result = result\n\n        except (ValueError, TypeError, KeyError) as e:\n            await logger.aerror(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            await logger.aerror(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        # Avoid catching blind Exception; let truly unexpected exceptions propagate\n        except Exception as e:\n            await logger.aerror(f\"Unexpected error: {e!s}\")\n            raise\n        else:\n            return result\n\n    def _preprocess_schema(self, schema):\n        \"\"\"Preprocess schema to ensure correct data types for build_model_from_schema.\"\"\"\n        processed_schema = []\n        for field in schema:\n            processed_field = {\n                \"name\": str(field.get(\"name\", \"field\")),\n                \"type\": str(field.get(\"type\", \"str\")),\n                \"description\": str(field.get(\"description\", \"\")),\n                \"multiple\": field.get(\"multiple\", False),\n            }\n            # Ensure multiple is handled correctly\n            if isinstance(processed_field[\"multiple\"], str):\n                processed_field[\"multiple\"] = processed_field[\"multiple\"].lower() in [\n                    \"true\",\n                    \"1\",\n                    \"t\",\n                    \"y\",\n                    \"yes\",\n                ]\n            processed_schema.append(processed_field)\n        return processed_schema\n\n    async def build_structured_output_base(self, content: str):\n        \"\"\"Build structured output with optional BaseModel validation.\"\"\"\n        json_pattern = r\"\\{.*\\}\"\n        schema_error_msg = \"Try setting an output schema\"\n\n        # Try to parse content as JSON first\n        json_data = None\n        try:\n            json_data = json.loads(content)\n        except json.JSONDecodeError:\n            json_match = re.search(json_pattern, content, re.DOTALL)\n            if json_match:\n                try:\n                    json_data = json.loads(json_match.group())\n                except json.JSONDecodeError:\n                    return {\"content\": content, \"error\": schema_error_msg}\n            else:\n                return {\"content\": content, \"error\": schema_error_msg}\n\n        # If no output schema provided, return parsed JSON without validation\n        if not hasattr(self, \"output_schema\") or not self.output_schema or len(self.output_schema) == 0:\n            return json_data\n\n        # Use BaseModel validation with schema\n        try:\n            processed_schema = self._preprocess_schema(self.output_schema)\n            output_model = build_model_from_schema(processed_schema)\n\n            # Validate against the schema\n            if isinstance(json_data, list):\n                # Multiple objects\n                validated_objects = []\n                for item in json_data:\n                    try:\n                        validated_obj = output_model.model_validate(item)\n                        validated_objects.append(validated_obj.model_dump())\n                    except ValidationError as e:\n                        await logger.aerror(f\"Validation error for item: {e}\")\n                        # Include invalid items with error info\n                        validated_objects.append({\"data\": item, \"validation_error\": str(e)})\n                return validated_objects\n\n            # Single object\n            try:\n                validated_obj = output_model.model_validate(json_data)\n                return [validated_obj.model_dump()]  # Return as list for consistency\n            except ValidationError as e:\n                await logger.aerror(f\"Validation error: {e}\")\n                return [{\"data\": json_data, \"validation_error\": str(e)}]\n\n        except (TypeError, ValueError) as e:\n            await logger.aerror(f\"Error building structured output: {e}\")\n            # Fallback to parsed JSON without validation\n            return json_data\n\n    async def json_response(self) -> Data:\n        \"\"\"Convert agent response to structured JSON Data output with schema validation.\"\"\"\n        # Always use structured chat agent for JSON response mode for better JSON formatting\n        try:\n            system_components = []\n\n            # 1. Agent Instructions (system_prompt)\n            agent_instructions = getattr(self, \"system_prompt\", \"\") or \"\"\n            if agent_instructions:\n                system_components.append(f\"{agent_instructions}\")\n\n            # 2. Format Instructions\n            format_instructions = getattr(self, \"format_instructions\", \"\") or \"\"\n            if format_instructions:\n                system_components.append(f\"Format instructions: {format_instructions}\")\n\n            # 3. Schema Information from BaseModel\n            if hasattr(self, \"output_schema\") and self.output_schema and len(self.output_schema) > 0:\n                try:\n                    processed_schema = self._preprocess_schema(self.output_schema)\n                    output_model = build_model_from_schema(processed_schema)\n                    schema_dict = output_model.model_json_schema()\n                    schema_info = (\n                        \"You are given some text that may include format instructions, \"\n                        \"explanations, or other content alongside a JSON schema.\\n\\n\"\n                        \"Your task:\\n\"\n                        \"- Extract only the JSON schema.\\n\"\n                        \"- Return it as valid JSON.\\n\"\n                        \"- Do not include format instructions, explanations, or extra text.\\n\\n\"\n                        \"Input:\\n\"\n                        f\"{json.dumps(schema_dict, indent=2)}\\n\\n\"\n                        \"Output (only JSON schema):\"\n                    )\n                    system_components.append(schema_info)\n                except (ValidationError, ValueError, TypeError, KeyError) as e:\n                    await logger.aerror(f\"Could not build schema for prompt: {e}\", exc_info=True)\n\n            # Combine all components\n            combined_instructions = \"\\n\\n\".join(system_components) if system_components else \"\"\n            llm_model, self.chat_history, self.tools = await self.get_agent_requirements()\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=combined_instructions,\n            )\n\n            # Create and run structured chat agent\n            try:\n                structured_agent = self.create_agent_runnable()\n            except (NotImplementedError, ValueError, TypeError) as e:\n                await logger.aerror(f\"Error with structured chat agent: {e}\")\n                raise\n            try:\n                result = await self.run_agent(structured_agent)\n            except (\n                ExceptionWithMessageError,\n                ValueError,\n                TypeError,\n                RuntimeError,\n            ) as e:\n                await logger.aerror(f\"Error with structured agent result: {e}\")\n                raise\n            # Extract content from structured agent result\n            if hasattr(result, \"content\"):\n                content = result.content\n            elif hasattr(result, \"text\"):\n                content = result.text\n            else:\n                content = str(result)\n\n        except (\n            ExceptionWithMessageError,\n            ValueError,\n            TypeError,\n            NotImplementedError,\n            AttributeError,\n        ) as e:\n            await logger.aerror(f\"Error with structured chat agent: {e}\")\n            # Fallback to regular agent\n            content_str = \"No content returned from agent\"\n            return Data(data={\"content\": content_str, \"error\": str(e)})\n\n        # Process with structured output validation\n        try:\n            structured_output = await self.build_structured_output_base(content)\n\n            # Handle different output formats\n            if isinstance(structured_output, list) and structured_output:\n                if len(structured_output) == 1:\n                    return Data(data=structured_output[0])\n                return Data(data={\"results\": structured_output})\n            if isinstance(structured_output, dict):\n                return Data(data=structured_output)\n            return Data(data={\"content\": content})\n\n        except (ValueError, TypeError) as e:\n            await logger.aerror(f\"Error in structured output processing: {e}\")\n            return Data(data={\"content\": content, \"error\": str(e)})\n\n    async def get_memory_data(self):\n        # TODO: This is a temporary fix to avoid message duplication. We should develop a function for this.\n        messages = (\n            await MemoryComponent(**self.get_base_args())\n            .set(\n                session_id=self.graph.session_id,\n                order=\"Ascending\",\n                n_messages=self.n_messages,\n            )\n            .retrieve_messages()\n        )\n        return [\n            message for message in messages if getattr(message, \"id\", None) != getattr(self.input_value, \"id\", None)\n        ]\n\n    async def get_llm(self):\n        if not isinstance(self.agent_llm, str):\n            return self.agent_llm, None\n\n        try:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if not provider_info:\n                msg = f\"Invalid model provider: {self.agent_llm}\"\n                raise ValueError(msg)\n\n            component_class = provider_info.get(\"component_class\")\n            display_name = component_class.display_name\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\", \"\")\n\n            return self._build_llm_model(component_class, inputs, prefix), display_name\n\n        except (AttributeError, ValueError, TypeError, RuntimeError) as e:\n            await logger.aerror(f\"Error building {self.agent_llm} language model: {e!s}\")\n            msg = f\"Failed to initialize language model: {e!s}\"\n            raise ValueError(msg) from e\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {}\n        for input_ in inputs:\n            if hasattr(self, f\"{prefix}{input_.name}\"):\n                model_kwargs[input_.name] = getattr(self, f\"{prefix}{input_.name}\")\n        return component.set(**model_kwargs).build_model()\n\n    def set_component_params(self, component):\n        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n        if provider_info:\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\")\n            # Filter out json_mode and only use attributes that exist on this component\n            model_kwargs = {}\n            for input_ in inputs:\n                if hasattr(self, f\"{prefix}{input_.name}\"):\n                    model_kwargs[input_.name] = getattr(self, f\"{prefix}{input_.name}\")\n\n            return component.set(**model_kwargs)\n        return component\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self, build_config: dotdict, field_value: str, field_name: str | None = None\n    ) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name in (\"agent_llm\",):\n            build_config[\"agent_llm\"][\"value\"] = field_value\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n                build_config[\"agent_llm\"][\"display_name\"] = \"Model Provider\"\n            elif field_value == \"connect_other_models\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    info=\"The provider of the language model that the agent will use to generate responses.\",\n                    options=[*MODEL_PROVIDERS_LIST],\n                    real_time_refresh=True,\n                    refresh_button=False,\n                    input_types=[\"LanguageModel\"],\n                    placeholder=\"Awaiting model input.\",\n                    options_metadata=[MODELS_METADATA[key] for key in MODEL_PROVIDERS_LIST if key in MODELS_METADATA],\n                    external_options={\n                        \"fields\": {\n                            \"data\": {\n                                \"node\": {\n                                    \"name\": \"connect_other_models\",\n                                    \"display_name\": \"Connect other models\",\n                                    \"icon\": \"CornerDownLeft\",\n                                },\n                            }\n                        },\n                    },\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if (\n            isinstance(self.agent_llm, str)\n            and self.agent_llm in MODEL_PROVIDERS_DICT\n            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS\n        ):\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                component_class = self.set_component_params(component_class)\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n\n    async def _get_tools(self) -> list[Tool]:\n        component_toolkit = get_component_toolkit()\n        tools_names = self._build_tools_names()\n        agent_description = self.get_tool_description()\n        # TODO: Agent Description Depreciated Feature to be removed\n        description = f\"{agent_description}{tools_names}\"\n        tools = component_toolkit(component=self).get_tools(\n            tool_name=\"Call_Agent\",\n            tool_description=description,\n            callbacks=self.get_langchain_callbacks(),\n        )\n        if hasattr(self, \"tools_metadata\"):\n            tools = component_toolkit(component=self, metadata=self.tools_metadata).update_tools_metadata(tools=tools)\n        return tools\n"
              },
              "format_instructions": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Output Format Instructions",
                "dynamic": false,
                "info": "Generic Template for structured output formatting. Valid only with Structured response.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "format_instructions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are an AI that extracts structured JSON objects from unstructured text. Use a predefined schema with expected types (str, int, float, bool, dict). Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. Fill missing or ambiguous values with defaults: null for missing values. Remove exact duplicates but keep variations that have different field values. Always return valid JSON in the expected format, never throw errors. If multiple objects can be extracted, return them all in the structured format."
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "input_types": [],
                "list": false,
                "name": "handle_parsing_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "input_types": [],
                "list": false,
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 15
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "external_options": {},
                "info": "To see the model names, first choose a provider. Then, enter your API key and click the refresh button next to the model name.",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-5",
                  "gpt-5-mini",
                  "gpt-5-nano",
                  "gpt-5-chat-latest",
                  "o1",
                  "o3-mini",
                  "o3",
                  "o3-pro",
                  "o4-mini",
                  "o4-mini-high"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": false,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4o-mini"
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Chat History Messages",
                "dynamic": false,
                "info": "Number of chat history messages to retrieve.",
                "input_types": [],
                "list": false,
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "output_schema": {
                "_input_type": "TableInput",
                "advanced": true,
                "display_name": "Output Schema",
                "dynamic": false,
                "info": "Schema Validation: Define the structure and data types for structured output. No validation if no output schema.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "output_schema",
                "placeholder": "",
                "required": false,
                "show": true,
                "table_icon": "Table",
                "table_schema": [
                  {
                    "default": "field",
                    "description": "Specify the name of the output field.",
                    "display_name": "Name",
                    "edit_mode": "inline",
                    "name": "name",
                    "type": "str"
                  },
                  {
                    "default": "description of field",
                    "description": "Describe the purpose of the output field.",
                    "display_name": "Description",
                    "edit_mode": "popover",
                    "name": "description",
                    "type": "str"
                  },
                  {
                    "default": "str",
                    "description": "Indicate the data type of the output field (e.g., str, int, float, bool, dict).",
                    "display_name": "Type",
                    "edit_mode": "inline",
                    "name": "type",
                    "options": [
                      "str",
                      "int",
                      "float",
                      "bool",
                      "dict"
                    ],
                    "type": "str"
                  },
                  {
                    "default": "False",
                    "description": "Set to True if this output field should be a list of the specified type.",
                    "display_name": "As List",
                    "edit_mode": "inline",
                    "name": "multiple",
                    "type": "boolean"
                  }
                ],
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": []
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Agent Instructions",
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are a helpful assistant that can use tools to answer questions and perform tasks."
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.7
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tools",
                "value": [
                  {
                    "args": {
                      "input_value": {
                        "default": "",
                        "description": "The input provided by the user for the agent to process.",
                        "title": "Input Value",
                        "type": "string"
                      },
                      "order": {
                        "default": "Ascending",
                        "description": "Order of the messages.",
                        "enum": [
                          "Ascending",
                          "Descending"
                        ],
                        "title": "Order",
                        "type": "string"
                      }
                    },
                    "description": "A helpful assistant with access to the following tools:",
                    "display_description": "Agent. message_response - Define the agent's instructions, then enter a task to complete using tools.",
                    "display_name": "message_response",
                    "name": "Agent",
                    "readonly": false,
                    "status": true,
                    "tags": [
                      "Agent"
                    ]
                  }
                ]
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "Agent"
        },
        "dragging": false,
        "id": "Agent-TjsA4",
        "measured": {
          "height": 866,
          "width": 320
        },
        "position": {
          "x": 1726.7564029836815,
          "y": -1234.313227967561
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Agent-gq2Yh",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "display_name": "Accumulator Check Agent",
            "documentation": "",
            "edited": false,
            "field_order": [
              "agent_llm",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "system_prompt",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "return_intermediate_steps",
              "agent_description",
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template",
              "add_current_date_tool"
            ],
            "frozen": false,
            "icon": "bot",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {
              "code_hash": "d61b1f3d692a",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "langchain_core",
                    "version": "0.3.76"
                  },
                  {
                    "name": "pydantic",
                    "version": "2.10.6"
                  },
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 3
              },
              "module": "lfx.components.agents.agent.AgentComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "hidden": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "add_current_date_tool": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Current Date",
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "input_types": [],
                "list": false,
                "name": "add_current_date_tool",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "agent_llm": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Model Provider",
                "dynamic": false,
                "info": "The provider of the language model that the agent will use to generate responses.",
                "input_types": [],
                "name": "agent_llm",
                "options": [
                  "Anthropic",
                  "Google Generative AI",
                  "OpenAI"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Azure OpenAI"
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nimport re\n\nfrom langchain_core.tools import StructuredTool, Tool\nfrom pydantic import ValidationError\n\nfrom lfx.base.agents.agent import LCToolsAgentComponent\nfrom lfx.base.agents.events import ExceptionWithMessageError\nfrom lfx.base.models.model_input_constants import (\n    ALL_PROVIDER_FIELDS,\n    MODEL_DYNAMIC_UPDATE_FIELDS,\n    MODEL_PROVIDERS_DICT,\n    MODELS_METADATA,\n)\nfrom lfx.base.models.model_utils import get_model_name\nfrom lfx.components.helpers.current_date import CurrentDateComponent\nfrom lfx.components.helpers.memory import MemoryComponent\nfrom lfx.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom lfx.custom.custom_component.component import get_component_toolkit\nfrom lfx.custom.utils import update_component_build_config\nfrom lfx.helpers.base_model import build_model_from_schema\nfrom lfx.inputs.inputs import BoolInput\nfrom lfx.io import DropdownInput, IntInput, MultilineInput, Output, TableInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.dotdict import dotdict\nfrom lfx.schema.message import Message\nfrom lfx.schema.table import EditMode\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nMODEL_PROVIDERS_LIST = [\"Anthropic\", \"Google Generative AI\", \"OpenAI\"]\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    documentation: str = \"https://docs.langflow.org/agents\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    # Filter out json_mode from OpenAI inputs since we handle structured output differently\n    if \"OpenAI\" in MODEL_PROVIDERS_DICT:\n        openai_inputs_filtered = [\n            input_field\n            for input_field in MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"]\n            if not (hasattr(input_field, \"name\") and input_field.name == \"json_mode\")\n        ]\n    else:\n        openai_inputs_filtered = []\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*MODEL_PROVIDERS_LIST],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            refresh_button=False,\n            input_types=[],\n            options_metadata=[MODELS_METADATA[key] for key in MODEL_PROVIDERS_LIST if key in MODELS_METADATA]\n            + [{\"icon\": \"brain\"}],\n            external_options={\n                \"fields\": {\n                    \"data\": {\n                        \"node\": {\n                            \"name\": \"connect_other_models\",\n                            \"display_name\": \"Connect other models\",\n                            \"icon\": \"CornerDownLeft\",\n                        }\n                    }\n                },\n            },\n        ),\n        *openai_inputs_filtered,\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Chat History Messages\",\n            value=100,\n            info=\"Number of chat history messages to retrieve.\",\n            advanced=True,\n            show=True,\n        ),\n        MultilineInput(\n            name=\"format_instructions\",\n            display_name=\"Output Format Instructions\",\n            info=\"Generic Template for structured output formatting. Valid only with Structured response.\",\n            value=(\n                \"You are an AI that extracts structured JSON objects from unstructured text. \"\n                \"Use a predefined schema with expected types (str, int, float, bool, dict). \"\n                \"Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. \"\n                \"Fill missing or ambiguous values with defaults: null for missing values. \"\n                \"Remove exact duplicates but keep variations that have different field values. \"\n                \"Always return valid JSON in the expected format, never throw errors. \"\n                \"If multiple objects can be extracted, return them all in the structured format.\"\n            ),\n            advanced=True,\n        ),\n        TableInput(\n            name=\"output_schema\",\n            display_name=\"Output Schema\",\n            info=(\n                \"Schema Validation: Define the structure and data types for structured output. \"\n                \"No validation if no output schema.\"\n            ),\n            advanced=True,\n            required=False,\n            value=[],\n            table_schema=[\n                {\n                    \"name\": \"name\",\n                    \"display_name\": \"Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Specify the name of the output field.\",\n                    \"default\": \"field\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"description\",\n                    \"display_name\": \"Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Describe the purpose of the output field.\",\n                    \"default\": \"description of field\",\n                    \"edit_mode\": EditMode.POPOVER,\n                },\n                {\n                    \"name\": \"type\",\n                    \"display_name\": \"Type\",\n                    \"type\": \"str\",\n                    \"edit_mode\": EditMode.INLINE,\n                    \"description\": (\"Indicate the data type of the output field (e.g., str, int, float, bool, dict).\"),\n                    \"options\": [\"str\", \"int\", \"float\", \"bool\", \"dict\"],\n                    \"default\": \"str\",\n                },\n                {\n                    \"name\": \"multiple\",\n                    \"display_name\": \"As List\",\n                    \"type\": \"boolean\",\n                    \"description\": \"Set to True if this output field should be a list of the specified type.\",\n                    \"default\": \"False\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n            ],\n        ),\n        *LCToolsAgentComponent.get_base_inputs(),\n        # removed memory inputs from agent component\n        # *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [\n        Output(name=\"response\", display_name=\"Response\", method=\"message_response\"),\n    ]\n\n    async def get_agent_requirements(self):\n        \"\"\"Get the agent requirements for the agent.\"\"\"\n        llm_model, display_name = await self.get_llm()\n        if llm_model is None:\n            msg = \"No language model selected. Please choose a model to proceed.\"\n            raise ValueError(msg)\n        self.model_name = get_model_name(llm_model, display_name=display_name)\n\n        # Get memory data\n        self.chat_history = await self.get_memory_data()\n        if isinstance(self.chat_history, Message):\n            self.chat_history = [self.chat_history]\n\n        # Add current date tool if enabled\n        if self.add_current_date_tool:\n            if not isinstance(self.tools, list):  # type: ignore[has-type]\n                self.tools = []\n            current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n            if not isinstance(current_date_tool, StructuredTool):\n                msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                raise TypeError(msg)\n            self.tools.append(current_date_tool)\n        return llm_model, self.chat_history, self.tools\n\n    async def message_response(self) -> Message:\n        try:\n            llm_model, self.chat_history, self.tools = await self.get_agent_requirements()\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            result = await self.run_agent(agent)\n\n            # Store result for potential JSON output\n            self._agent_result = result\n\n        except (ValueError, TypeError, KeyError) as e:\n            await logger.aerror(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            await logger.aerror(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        # Avoid catching blind Exception; let truly unexpected exceptions propagate\n        except Exception as e:\n            await logger.aerror(f\"Unexpected error: {e!s}\")\n            raise\n        else:\n            return result\n\n    def _preprocess_schema(self, schema):\n        \"\"\"Preprocess schema to ensure correct data types for build_model_from_schema.\"\"\"\n        processed_schema = []\n        for field in schema:\n            processed_field = {\n                \"name\": str(field.get(\"name\", \"field\")),\n                \"type\": str(field.get(\"type\", \"str\")),\n                \"description\": str(field.get(\"description\", \"\")),\n                \"multiple\": field.get(\"multiple\", False),\n            }\n            # Ensure multiple is handled correctly\n            if isinstance(processed_field[\"multiple\"], str):\n                processed_field[\"multiple\"] = processed_field[\"multiple\"].lower() in [\n                    \"true\",\n                    \"1\",\n                    \"t\",\n                    \"y\",\n                    \"yes\",\n                ]\n            processed_schema.append(processed_field)\n        return processed_schema\n\n    async def build_structured_output_base(self, content: str):\n        \"\"\"Build structured output with optional BaseModel validation.\"\"\"\n        json_pattern = r\"\\{.*\\}\"\n        schema_error_msg = \"Try setting an output schema\"\n\n        # Try to parse content as JSON first\n        json_data = None\n        try:\n            json_data = json.loads(content)\n        except json.JSONDecodeError:\n            json_match = re.search(json_pattern, content, re.DOTALL)\n            if json_match:\n                try:\n                    json_data = json.loads(json_match.group())\n                except json.JSONDecodeError:\n                    return {\"content\": content, \"error\": schema_error_msg}\n            else:\n                return {\"content\": content, \"error\": schema_error_msg}\n\n        # If no output schema provided, return parsed JSON without validation\n        if not hasattr(self, \"output_schema\") or not self.output_schema or len(self.output_schema) == 0:\n            return json_data\n\n        # Use BaseModel validation with schema\n        try:\n            processed_schema = self._preprocess_schema(self.output_schema)\n            output_model = build_model_from_schema(processed_schema)\n\n            # Validate against the schema\n            if isinstance(json_data, list):\n                # Multiple objects\n                validated_objects = []\n                for item in json_data:\n                    try:\n                        validated_obj = output_model.model_validate(item)\n                        validated_objects.append(validated_obj.model_dump())\n                    except ValidationError as e:\n                        await logger.aerror(f\"Validation error for item: {e}\")\n                        # Include invalid items with error info\n                        validated_objects.append({\"data\": item, \"validation_error\": str(e)})\n                return validated_objects\n\n            # Single object\n            try:\n                validated_obj = output_model.model_validate(json_data)\n                return [validated_obj.model_dump()]  # Return as list for consistency\n            except ValidationError as e:\n                await logger.aerror(f\"Validation error: {e}\")\n                return [{\"data\": json_data, \"validation_error\": str(e)}]\n\n        except (TypeError, ValueError) as e:\n            await logger.aerror(f\"Error building structured output: {e}\")\n            # Fallback to parsed JSON without validation\n            return json_data\n\n    async def json_response(self) -> Data:\n        \"\"\"Convert agent response to structured JSON Data output with schema validation.\"\"\"\n        # Always use structured chat agent for JSON response mode for better JSON formatting\n        try:\n            system_components = []\n\n            # 1. Agent Instructions (system_prompt)\n            agent_instructions = getattr(self, \"system_prompt\", \"\") or \"\"\n            if agent_instructions:\n                system_components.append(f\"{agent_instructions}\")\n\n            # 2. Format Instructions\n            format_instructions = getattr(self, \"format_instructions\", \"\") or \"\"\n            if format_instructions:\n                system_components.append(f\"Format instructions: {format_instructions}\")\n\n            # 3. Schema Information from BaseModel\n            if hasattr(self, \"output_schema\") and self.output_schema and len(self.output_schema) > 0:\n                try:\n                    processed_schema = self._preprocess_schema(self.output_schema)\n                    output_model = build_model_from_schema(processed_schema)\n                    schema_dict = output_model.model_json_schema()\n                    schema_info = (\n                        \"You are given some text that may include format instructions, \"\n                        \"explanations, or other content alongside a JSON schema.\\n\\n\"\n                        \"Your task:\\n\"\n                        \"- Extract only the JSON schema.\\n\"\n                        \"- Return it as valid JSON.\\n\"\n                        \"- Do not include format instructions, explanations, or extra text.\\n\\n\"\n                        \"Input:\\n\"\n                        f\"{json.dumps(schema_dict, indent=2)}\\n\\n\"\n                        \"Output (only JSON schema):\"\n                    )\n                    system_components.append(schema_info)\n                except (ValidationError, ValueError, TypeError, KeyError) as e:\n                    await logger.aerror(f\"Could not build schema for prompt: {e}\", exc_info=True)\n\n            # Combine all components\n            combined_instructions = \"\\n\\n\".join(system_components) if system_components else \"\"\n            llm_model, self.chat_history, self.tools = await self.get_agent_requirements()\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=combined_instructions,\n            )\n\n            # Create and run structured chat agent\n            try:\n                structured_agent = self.create_agent_runnable()\n            except (NotImplementedError, ValueError, TypeError) as e:\n                await logger.aerror(f\"Error with structured chat agent: {e}\")\n                raise\n            try:\n                result = await self.run_agent(structured_agent)\n            except (\n                ExceptionWithMessageError,\n                ValueError,\n                TypeError,\n                RuntimeError,\n            ) as e:\n                await logger.aerror(f\"Error with structured agent result: {e}\")\n                raise\n            # Extract content from structured agent result\n            if hasattr(result, \"content\"):\n                content = result.content\n            elif hasattr(result, \"text\"):\n                content = result.text\n            else:\n                content = str(result)\n\n        except (\n            ExceptionWithMessageError,\n            ValueError,\n            TypeError,\n            NotImplementedError,\n            AttributeError,\n        ) as e:\n            await logger.aerror(f\"Error with structured chat agent: {e}\")\n            # Fallback to regular agent\n            content_str = \"No content returned from agent\"\n            return Data(data={\"content\": content_str, \"error\": str(e)})\n\n        # Process with structured output validation\n        try:\n            structured_output = await self.build_structured_output_base(content)\n\n            # Handle different output formats\n            if isinstance(structured_output, list) and structured_output:\n                if len(structured_output) == 1:\n                    return Data(data=structured_output[0])\n                return Data(data={\"results\": structured_output})\n            if isinstance(structured_output, dict):\n                return Data(data=structured_output)\n            return Data(data={\"content\": content})\n\n        except (ValueError, TypeError) as e:\n            await logger.aerror(f\"Error in structured output processing: {e}\")\n            return Data(data={\"content\": content, \"error\": str(e)})\n\n    async def get_memory_data(self):\n        # TODO: This is a temporary fix to avoid message duplication. We should develop a function for this.\n        messages = (\n            await MemoryComponent(**self.get_base_args())\n            .set(\n                session_id=self.graph.session_id,\n                order=\"Ascending\",\n                n_messages=self.n_messages,\n            )\n            .retrieve_messages()\n        )\n        return [\n            message for message in messages if getattr(message, \"id\", None) != getattr(self.input_value, \"id\", None)\n        ]\n\n    async def get_llm(self):\n        if not isinstance(self.agent_llm, str):\n            return self.agent_llm, None\n\n        try:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if not provider_info:\n                msg = f\"Invalid model provider: {self.agent_llm}\"\n                raise ValueError(msg)\n\n            component_class = provider_info.get(\"component_class\")\n            display_name = component_class.display_name\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\", \"\")\n\n            return self._build_llm_model(component_class, inputs, prefix), display_name\n\n        except (AttributeError, ValueError, TypeError, RuntimeError) as e:\n            await logger.aerror(f\"Error building {self.agent_llm} language model: {e!s}\")\n            msg = f\"Failed to initialize language model: {e!s}\"\n            raise ValueError(msg) from e\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {}\n        for input_ in inputs:\n            if hasattr(self, f\"{prefix}{input_.name}\"):\n                model_kwargs[input_.name] = getattr(self, f\"{prefix}{input_.name}\")\n        return component.set(**model_kwargs).build_model()\n\n    def set_component_params(self, component):\n        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n        if provider_info:\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\")\n            # Filter out json_mode and only use attributes that exist on this component\n            model_kwargs = {}\n            for input_ in inputs:\n                if hasattr(self, f\"{prefix}{input_.name}\"):\n                    model_kwargs[input_.name] = getattr(self, f\"{prefix}{input_.name}\")\n\n            return component.set(**model_kwargs)\n        return component\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self, build_config: dotdict, field_value: str, field_name: str | None = None\n    ) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name in (\"agent_llm\",):\n            build_config[\"agent_llm\"][\"value\"] = field_value\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n                build_config[\"agent_llm\"][\"display_name\"] = \"Model Provider\"\n            elif field_value == \"connect_other_models\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    info=\"The provider of the language model that the agent will use to generate responses.\",\n                    options=[*MODEL_PROVIDERS_LIST],\n                    real_time_refresh=True,\n                    refresh_button=False,\n                    input_types=[\"LanguageModel\"],\n                    placeholder=\"Awaiting model input.\",\n                    options_metadata=[MODELS_METADATA[key] for key in MODEL_PROVIDERS_LIST if key in MODELS_METADATA],\n                    external_options={\n                        \"fields\": {\n                            \"data\": {\n                                \"node\": {\n                                    \"name\": \"connect_other_models\",\n                                    \"display_name\": \"Connect other models\",\n                                    \"icon\": \"CornerDownLeft\",\n                                },\n                            }\n                        },\n                    },\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if (\n            isinstance(self.agent_llm, str)\n            and self.agent_llm in MODEL_PROVIDERS_DICT\n            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS\n        ):\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                component_class = self.set_component_params(component_class)\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n\n    async def _get_tools(self) -> list[Tool]:\n        component_toolkit = get_component_toolkit()\n        tools_names = self._build_tools_names()\n        agent_description = self.get_tool_description()\n        # TODO: Agent Description Depreciated Feature to be removed\n        description = f\"{agent_description}{tools_names}\"\n        tools = component_toolkit(component=self).get_tools(\n            tool_name=\"Call_Agent\",\n            tool_description=description,\n            callbacks=self.get_langchain_callbacks(),\n        )\n        if hasattr(self, \"tools_metadata\"):\n            tools = component_toolkit(component=self, metadata=self.tools_metadata).update_tools_metadata(tools=tools)\n        return tools\n"
              },
              "format_instructions": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Output Format Instructions",
                "dynamic": false,
                "info": "Generic Template for structured output formatting. Valid only with Structured response.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "format_instructions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are an AI that extracts structured JSON objects from unstructured text. Use a predefined schema with expected types (str, int, float, bool, dict). Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. Fill missing or ambiguous values with defaults: null for missing values. Remove exact duplicates but keep variations that have different field values. Always return valid JSON in the expected format, never throw errors. If multiple objects can be extracted, return them all in the structured format."
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "input_types": [],
                "list": false,
                "name": "handle_parsing_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "input_types": [],
                "list": false,
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 15
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "external_options": {},
                "info": "To see the model names, first choose a provider. Then, enter your API key and click the refresh button next to the model name.",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-5",
                  "gpt-5-mini",
                  "gpt-5-nano",
                  "gpt-5-chat-latest",
                  "o1",
                  "o3-mini",
                  "o3",
                  "o3-pro",
                  "o4-mini",
                  "o4-mini-high"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": false,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4o-mini"
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Chat History Messages",
                "dynamic": false,
                "info": "Number of chat history messages to retrieve.",
                "input_types": [],
                "list": false,
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "output_schema": {
                "_input_type": "TableInput",
                "advanced": true,
                "display_name": "Output Schema",
                "dynamic": false,
                "info": "Schema Validation: Define the structure and data types for structured output. No validation if no output schema.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "output_schema",
                "placeholder": "",
                "required": false,
                "show": true,
                "table_icon": "Table",
                "table_schema": [
                  {
                    "default": "field",
                    "description": "Specify the name of the output field.",
                    "display_name": "Name",
                    "edit_mode": "inline",
                    "name": "name",
                    "type": "str"
                  },
                  {
                    "default": "description of field",
                    "description": "Describe the purpose of the output field.",
                    "display_name": "Description",
                    "edit_mode": "popover",
                    "name": "description",
                    "type": "str"
                  },
                  {
                    "default": "str",
                    "description": "Indicate the data type of the output field (e.g., str, int, float, bool, dict).",
                    "display_name": "Type",
                    "edit_mode": "inline",
                    "name": "type",
                    "options": [
                      "str",
                      "int",
                      "float",
                      "bool",
                      "dict"
                    ],
                    "type": "str"
                  },
                  {
                    "default": "False",
                    "description": "Set to True if this output field should be a list of the specified type.",
                    "display_name": "As List",
                    "edit_mode": "inline",
                    "name": "multiple",
                    "type": "boolean"
                  }
                ],
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": []
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Agent Instructions",
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are a helpful assistant that can use tools to answer questions and perform tasks."
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 2,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.7
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tools",
                "value": [
                  {
                    "args": {
                      "input_value": {
                        "default": "",
                        "description": "The input provided by the user for the agent to process.",
                        "title": "Input Value",
                        "type": "string"
                      },
                      "order": {
                        "default": "Ascending",
                        "description": "Order of the messages.",
                        "enum": [
                          "Ascending",
                          "Descending"
                        ],
                        "title": "Order",
                        "type": "string"
                      }
                    },
                    "description": "A helpful assistant with access to the following tools:",
                    "display_description": "Agent. message_response - Define the agent's instructions, then enter a task to complete using tools.",
                    "display_name": "message_response",
                    "name": "Agent",
                    "readonly": false,
                    "status": true,
                    "tags": [
                      "Agent"
                    ]
                  }
                ]
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "Agent"
        },
        "dragging": false,
        "id": "Agent-gq2Yh",
        "measured": {
          "height": 866,
          "width": 320
        },
        "position": {
          "x": 1667.2259750812361,
          "y": 5.609687389722936
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "PromptTemplate-JrAir",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Select or edit prompt templates.",
            "display_name": "Prompt Template",
            "documentation": "",
            "edited": false,
            "field_order": [
              "saved_prompt",
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "icon": "Autonomize",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {
              "code_hash": "ced1bc0d56bb",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "langflow",
                    "version": null
                  },
                  {
                    "name": "lfx",
                    "version": null
                  },
                  {
                    "name": "loguru",
                    "version": "0.7.3"
                  }
                ],
                "total_dependencies": 3
              },
              "module": "lfx.components.prompts.prompt_template.PromptTemplateComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "group_outputs": false,
                "method": "build_prompt",
                "name": "prompt",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\nfrom textwrap import dedent\n\n# from lfx.custom.custom_component.component import Component\nfrom langflow.components.processing.prompt import PromptComponent\nfrom lfx.io import DropdownInput, Output\nfrom langflow.schema.message import Message\nfrom loguru import logger\n\nfrom langflow.custom.genesis.services.deps import get_prompt_service\n\n\nclass PromptTemplateComponent(PromptComponent):\n    display_name = \"Prompt Template\"\n    category: str = \"processing\"\n    description = \"Select or edit prompt templates.\"\n    icon = \"Autonomize\"\n    name = \"PromptTemplate\"\n\n    inputs = [\n        DropdownInput(\n            name=\"saved_prompt\",\n            display_name=\"Choose from Templates\",\n            info=\"Select a Template\",\n            refresh_button=True,\n            real_time_refresh=True,\n        ),\n        *PromptComponent.inputs,\n    ]\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    def __init__(self, **data):\n        super().__init__(**data)\n        self.prompt_service = get_prompt_service()\n        self._selected_prompt_name = None  # Track the selected prompt name\n        self._attributes[\"template\"] = dedent(\n            \"\"\"\n            Given the following context, answer the question.\n            Context: {context}\n\n            Question: {question}\n            Answer:\"\"\"\n        )\n\n    @staticmethod\n    def _extract_template_content(selected_prompt: dict) -> str:\n        \"\"\"Extract template content from the actual API response structure\"\"\"\n        logger.info(\n            f\"Processing selected_prompt: {selected_prompt.get('name', 'Unknown')}\"\n        )\n\n        # Based on the actual structure, template is in:\n        # latest_versions[0]['template'][0]['content']['text']\n\n        try:\n            # Check if latest_versions exists\n            if \"latest_versions\" in selected_prompt:\n                latest_versions = selected_prompt[\"latest_versions\"]\n                logger.info(f\"Found latest_versions with {len(latest_versions)} items\")\n\n                if latest_versions and len(latest_versions) > 0:\n                    first_version = latest_versions[0]\n                    logger.info(f\"First version keys: {list(first_version.keys())}\")\n\n                    # Check if template exists in the first version\n                    if \"template\" in first_version:\n                        template_list = first_version[\"template\"]\n                        logger.info(\n                            f\"Found template list with {len(template_list)} items\"\n                        )\n\n                        if template_list and len(template_list) > 0:\n                            first_template = template_list[0]\n                            logger.info(\n                                f\"First template item keys: {list(first_template.keys())}\"\n                            )\n\n                            # Check for content structure\n                            if \"content\" in first_template:\n                                content = first_template[\"content\"]\n                                logger.info(f\"Found content: {content}\")\n\n                                if isinstance(content, dict) and \"text\" in content:\n                                    result = content[\"text\"]\n                                    if result and result.strip():\n                                        logger.info(\n                                            f\"Successfully extracted template text: {result[:100]}...\"\n                                        )\n                                        return result\n                                    else:\n                                        logger.warning(\"Template text is empty\")\n                                else:\n                                    logger.warning(\n                                        f\"Content structure unexpected: {content}\"\n                                    )\n                            else:\n                                logger.warning(\"No 'content' field in template item\")\n                        else:\n                            logger.warning(\"Template list is empty\")\n                    else:\n                        logger.warning(\"No 'template' field in first version\")\n                else:\n                    logger.warning(\"latest_versions is empty\")\n            else:\n                logger.warning(\"No 'latest_versions' field found\")\n\n                # Fallback: try direct template field (for backward compatibility)\n                if \"template\" in selected_prompt:\n                    template = selected_prompt[\"template\"]\n                    logger.info(f\"Trying fallback direct template: {template}\")\n\n                    if isinstance(template, str) and template.strip():\n                        return template\n                    elif isinstance(template, list) and template:\n                        first_item = template[0]\n                        if isinstance(first_item, dict) and \"content\" in first_item:\n                            content = first_item[\"content\"]\n                            if isinstance(content, dict) and \"text\" in content:\n                                return content[\"text\"]\n\n        except Exception as e:\n            logger.error(f\"Error extracting template content: {e}\")\n            logger.exception(\"Full error details:\")\n\n        logger.error(\"Failed to extract template content from any expected location\")\n        return \"\"\n\n    @staticmethod\n    def _extract_variables(template: str) -> list[str]:\n        \"\"\"Extract variables from template - supports both {var} and {{ var }} formats\"\"\"\n        # Your templates use {{ var }} format based on the seed data\n        vars_double = re.findall(r\"\\{\\{\\s*(\\w+)\\s*\\}\\}\", template)\n        vars_single = re.findall(r\"\\{(\\w+)\\}\", template)\n\n        # Combine and deduplicate\n        variables = list(set(vars_double + vars_single))\n        logger.info(f\"Extracted variables from template: {variables}\")\n        logger.info(\n            f\"Template used for extraction: {template[:200]}...\"\n        )  # First 200 chars\n\n        return variables\n\n    async def _validate_and_refresh_template(self) -> bool:\n        \"\"\"Validate that the selected template is still available, if not fetch and re-add it\"\"\"\n        if not self._selected_prompt_name:\n            logger.info(\"No template selected, validation skipped\")\n            return True\n\n        try:\n            criteria = {\"max_results\": 100}\n            prompts = await self.prompt_service.get_prompts(criteria)\n            prompt_list = prompts.get(\"prompts\", [])\n\n            # Check if the selected template still exists\n            available_names = [\n                p.get(\"name\") for p in prompt_list if isinstance(p, dict)\n            ]\n\n            if self._selected_prompt_name in available_names:\n                logger.info(\n                    f\"Template '{self._selected_prompt_name}' is still available\"\n                )\n                return True\n            else:\n                logger.warning(\n                    f\"Template '{self._selected_prompt_name}' is no longer available, attempting to refresh...\"\n                )\n\n                # Try to find the template again and refresh it\n                selected_prompt = next(\n                    (\n                        p\n                        for p in prompt_list\n                        if p.get(\"name\") == self._selected_prompt_name\n                    ),\n                    None,\n                )\n\n                if selected_prompt:\n                    logger.info(\n                        f\"Found template '{self._selected_prompt_name}' in fresh fetch, refreshing content...\"\n                    )\n\n                    # Re-extract and update the template content\n                    template_content = self._extract_template_content(selected_prompt)\n\n                    if template_content:\n                        self._attributes[\"template\"] = template_content\n                        if hasattr(self, \"template\"):\n                            self.template = template_content\n                        logger.info(\n                            f\"Successfully refreshed template content: {template_content[:100]}...\"\n                        )\n                        return True\n                    else:\n                        logger.error(\n                            f\"Failed to extract content from refreshed template '{self._selected_prompt_name}'\"\n                        )\n                        return False\n                else:\n                    logger.error(\n                        f\"Template '{self._selected_prompt_name}' not found even after refresh\"\n                    )\n                    logger.info(f\"Available templates: {available_names}\")\n                    return False\n\n        except Exception as e:\n            logger.error(f\"Error validating/refreshing selected template: {e}\")\n            logger.exception(\"Full error details:\")\n            # If we can't validate, assume it's still valid to avoid breaking the flow\n            return True\n\n    async def build_prompt(self) -> Message:\n        # Validate and refresh the selected template if needed\n        if self._selected_prompt_name:\n            is_valid = await self._validate_and_refresh_template()\n            if not is_valid:\n                error_message = f\"Error: Selected template '{self._selected_prompt_name}' is no longer available and could not be refreshed. Please select a different template.\"\n                logger.error(error_message)\n                return Message(text=error_message)\n\n        template = self._attributes.get(\"template\", \"\")\n        variables = self._extract_variables(template)\n\n        for var in variables:\n            # Try different case variations\n            value = (\n                self._attributes.get(var)\n                or self._attributes.get(var.lower())\n                or self._attributes.get(var.title())\n                or \"\"\n            )\n\n            # Replace both {{ var }} and {var} formats\n            template = re.sub(\n                rf\"\\{{\\{{\\s*{re.escape(var)}\\s*\\}}\\}}\", str(value), template\n            )\n            template = re.sub(rf\"\\{{{re.escape(var)}\\}}\", str(value), template)\n\n        return Message(text=template)\n\n    async def update_build_config(\n        self, build_config, field_value, field_name=None\n    ) -> dict:\n        if field_name == \"saved_prompt\":\n            try:\n                criteria = {\"max_results\": 100}\n                prompts = await self.prompt_service.get_prompts(criteria)\n                prompt_list = prompts.get(\"prompts\", [])\n\n                logger.info(f\"Retrieved {len(prompt_list)} prompts from service\")\n\n                # Extract template names for dropdown\n                template_names = [\n                    p.get(\"name\", \"Unnamed Template\")\n                    for p in prompt_list\n                    if isinstance(p, dict)\n                ]\n                build_config[\"saved_prompt\"][\"options\"] = template_names\n                logger.info(f\"Available template names: {template_names}\")\n\n                if field_value:\n                    logger.info(f\"Processing selected prompt: {field_value}\")\n\n                    # Store the selected prompt name for validation during build\n                    self._selected_prompt_name = field_value\n\n                    # Find the selected prompt\n                    selected_prompt = next(\n                        (p for p in prompt_list if p.get(\"name\") == field_value), None\n                    )\n\n                    if selected_prompt:\n                        logger.info(f\"Found prompt with name: {field_value}\")\n\n                        # Extract template content using the correct SDK format\n                        template_content = self._extract_template_content(\n                            selected_prompt\n                        )\n\n                        if not template_content:\n                            logger.error(\"Failed to extract template content\")\n                            return build_config\n\n                        logger.info(\n                            f\"Successfully extracted template: {template_content[:100]}...\"\n                        )\n\n                        # Update the template in the component\n                        self._attributes[\"template\"] = template_content\n                        if hasattr(self, \"template\"):\n                            self.template = template_content\n                        build_config[\"template\"][\"value\"] = template_content\n\n                        # Extract variables from the template\n                        parameters = self._extract_variables(template_content)\n\n                        if not parameters:\n                            logger.info(\n                                \"No variables found in template - no dynamic fields needed\"\n                            )\n                            return build_config\n\n                        logger.info(f\"Found {len(parameters)} parameters: {parameters}\")\n\n                        # Remove existing dynamic fields\n                        fields_to_remove = [\n                            key\n                            for key in list(build_config.keys())\n                            if isinstance(build_config.get(key, {}), dict)\n                            and build_config[key].get(\"is_custom_field\", False)\n                        ]\n\n                        for key in fields_to_remove:\n                            build_config.pop(key, None)\n                            logger.info(f\"Removed existing dynamic field: {key}\")\n\n                        # Create new dynamic fields for each parameter\n                        for param in parameters:\n                            param_name = param.strip()\n                            if not param_name:\n                                continue\n\n                            display_name = param_name.replace(\"_\", \" \").title()\n\n                            build_config[param_name] = {\n                                \"is_custom_field\": True,\n                                \"name\": param_name,\n                                \"display_name\": display_name,\n                                \"value\": \"\",\n                                \"info\": f\"Enter value for {display_name}\",\n                                \"required\": True,\n                                \"show\": True,\n                                \"multiline\": True,\n                                \"dynamic\": True,\n                                \"placeholder\": f\"Enter {display_name.lower()}...\",\n                                \"advanced\": False,\n                                \"field_type\": \"str\",\n                                \"fileTypes\": [],\n                                \"file_path\": \"\",\n                                \"input_types\": [\"Message\", \"Text\"],\n                                \"list\": False,\n                                \"load_from_db\": False,\n                                \"title_case\": False,\n                                \"type\": \"str\",\n                            }\n\n                            logger.info(\n                                f\"Created dynamic field: {param_name} -> {display_name}\"\n                            )\n\n                        logger.info(\n                            f\"Successfully created {len(parameters)} dynamic fields\"\n                        )\n\n                    else:\n                        logger.warning(\n                            f\"Prompt '{field_value}' not found in available prompts\"\n                        )\n                        logger.info(\n                            f\"Available prompts: {[p.get('name') for p in prompt_list]}\"\n                        )\n\n                else:\n                    # Clear the selected prompt name if no value is selected\n                    self._selected_prompt_name = None\n\n            except Exception as e:\n                logger.error(f\"Error in update_build_config: {e}\")\n                logger.exception(\"Full error details:\")\n                build_config[\"saved_prompt\"][\"options\"] = []\n\n        return build_config\n"
              },
              "saved_prompt": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Choose from Templates",
                "dynamic": false,
                "info": "Select a Template",
                "name": "saved_prompt",
                "options": [],
                "placeholder": "",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "EOC Validation Agent"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "You are a Healthcare Benefits Validation Specialist responsible for determining service coverage based on Evidence of Coverage (EOC) documents. You'll analyze authorization processing reports and validate whether requested services are covered under the member's plan by searching EOC documents.\n\n## INPUT:\nYou will receive a Healthcare Authorization Processing Report from the first-level assessment. This report contains service codes, descriptions, member information, and preliminary coverage determinations.\n\n## PROCESS:\n\n### 1. Parse the Authorization Report:\nExtract key data elements:\n- Member information (ID, plan, state, line of business)\n- Service code details (codes, descriptions, types)\n- Initial coverage determinations\n- Any diagnostic information\n\n### 2. Vector Search Process:\nFor EACH service code in the report:\n- Construct a search query in this format:\n  ```\n  Service code: [CODE]\n  Service name: [NAME]\n  Service type: [TYPE]\n  Find related covered benefits for this service.\n  ```\n- Execute the knowledgehub tool using this query\n- Specify the following parameters:\n  * collection_name: \"eoc_medical_benefits\"\n  * document_filter: use member's state and LOB\n\n### 3. Coverage Validation Analysis:\nFor each service and its search results:\n- Carefully examine each benefit description returned\n- Determine if the service is explicitly or implicitly covered\n- Consider diagnosis requirements, limitations, and conditions\n- Evaluate authorization requirements\n- Pay special attention to DME codes and home health services which often have specific coverage conditions\n\n### 4. When Validating Coverage:\n- A service is VALIDATED when:\n  * The benefit clearly covers the requested service\n  * All conditions and requirements are met\n- A service is NOT VALIDATED when:\n  * No matching benefit is found\n  * The benefit explicitly excludes the service\n  * Required conditions are not met\n  * Required diagnosis information is missing\n\n## OUTPUT:\nProvide a comprehensive validation report with these sections:\n\n**VALIDATION SUMMARY:**\n- Brief overview of all services and validation results\n\n**SERVICE VALIDATION DETAILS:**\nFor each service code:\n- **Service Code:** [CODE]\n- **Service Description:** [DESCRIPTION]\n- **Validation Status:** VALIDATED or NOT VALIDATED\n- **Justification:** Detailed explanation referencing specific benefit language\n- **Relevant EOC Sections:** Quote the most relevant parts of the benefits found\n\n**COVERAGE BENEFITS:**\n- List of all benefits found relevant to the services\n- Include page numbers and document references\n\n**FINAL RECOMMENDATION:**\n- Overall recommendation based on the validation results\n- Any additional steps required (e.g., medical necessity documentation)\n\n## GUIDELINES:\n1. Be thorough in your search - try multiple query variations if initial results are insufficient\n2. Always ground your validation in the actual benefit language, not assumptions\n3. When benefit language is ambiguous, note this in your explanation\n4. If vector search returns insufficient results, note this as a limitation\n5. Always include direct quotes from benefits to support your validation decisions\n6. Remember that coverage often depends on medical necessity, which may require additional assessment\n\nYour goal is to produce accurate coverage validations that clearly explain whether each service is covered under the member's specific plan, based on the actual language in their Evidence of Coverage documents."
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "PromptTemplate"
        },
        "dragging": false,
        "id": "PromptTemplate-JrAir",
        "measured": {
          "height": 327,
          "width": 320
        },
        "position": {
          "x": 1312.3247213160364,
          "y": -1674.4482926466233
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "PromptTemplate-pLVYM",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Select or edit prompt templates.",
            "display_name": "Prompt Template",
            "documentation": "",
            "edited": false,
            "field_order": [
              "saved_prompt",
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "icon": "Autonomize",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {
              "code_hash": "ced1bc0d56bb",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "langflow",
                    "version": null
                  },
                  {
                    "name": "lfx",
                    "version": null
                  },
                  {
                    "name": "loguru",
                    "version": "0.7.3"
                  }
                ],
                "total_dependencies": 3
              },
              "module": "lfx.components.prompts.prompt_template.PromptTemplateComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "group_outputs": false,
                "method": "build_prompt",
                "name": "prompt",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\nfrom textwrap import dedent\n\n# from lfx.custom.custom_component.component import Component\nfrom langflow.components.processing.prompt import PromptComponent\nfrom lfx.io import DropdownInput, Output\nfrom langflow.schema.message import Message\nfrom loguru import logger\n\nfrom langflow.custom.genesis.services.deps import get_prompt_service\n\n\nclass PromptTemplateComponent(PromptComponent):\n    display_name = \"Prompt Template\"\n    category: str = \"processing\"\n    description = \"Select or edit prompt templates.\"\n    icon = \"Autonomize\"\n    name = \"PromptTemplate\"\n\n    inputs = [\n        DropdownInput(\n            name=\"saved_prompt\",\n            display_name=\"Choose from Templates\",\n            info=\"Select a Template\",\n            refresh_button=True,\n            real_time_refresh=True,\n        ),\n        *PromptComponent.inputs,\n    ]\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    def __init__(self, **data):\n        super().__init__(**data)\n        self.prompt_service = get_prompt_service()\n        self._selected_prompt_name = None  # Track the selected prompt name\n        self._attributes[\"template\"] = dedent(\n            \"\"\"\n            Given the following context, answer the question.\n            Context: {context}\n\n            Question: {question}\n            Answer:\"\"\"\n        )\n\n    @staticmethod\n    def _extract_template_content(selected_prompt: dict) -> str:\n        \"\"\"Extract template content from the actual API response structure\"\"\"\n        logger.info(\n            f\"Processing selected_prompt: {selected_prompt.get('name', 'Unknown')}\"\n        )\n\n        # Based on the actual structure, template is in:\n        # latest_versions[0]['template'][0]['content']['text']\n\n        try:\n            # Check if latest_versions exists\n            if \"latest_versions\" in selected_prompt:\n                latest_versions = selected_prompt[\"latest_versions\"]\n                logger.info(f\"Found latest_versions with {len(latest_versions)} items\")\n\n                if latest_versions and len(latest_versions) > 0:\n                    first_version = latest_versions[0]\n                    logger.info(f\"First version keys: {list(first_version.keys())}\")\n\n                    # Check if template exists in the first version\n                    if \"template\" in first_version:\n                        template_list = first_version[\"template\"]\n                        logger.info(\n                            f\"Found template list with {len(template_list)} items\"\n                        )\n\n                        if template_list and len(template_list) > 0:\n                            first_template = template_list[0]\n                            logger.info(\n                                f\"First template item keys: {list(first_template.keys())}\"\n                            )\n\n                            # Check for content structure\n                            if \"content\" in first_template:\n                                content = first_template[\"content\"]\n                                logger.info(f\"Found content: {content}\")\n\n                                if isinstance(content, dict) and \"text\" in content:\n                                    result = content[\"text\"]\n                                    if result and result.strip():\n                                        logger.info(\n                                            f\"Successfully extracted template text: {result[:100]}...\"\n                                        )\n                                        return result\n                                    else:\n                                        logger.warning(\"Template text is empty\")\n                                else:\n                                    logger.warning(\n                                        f\"Content structure unexpected: {content}\"\n                                    )\n                            else:\n                                logger.warning(\"No 'content' field in template item\")\n                        else:\n                            logger.warning(\"Template list is empty\")\n                    else:\n                        logger.warning(\"No 'template' field in first version\")\n                else:\n                    logger.warning(\"latest_versions is empty\")\n            else:\n                logger.warning(\"No 'latest_versions' field found\")\n\n                # Fallback: try direct template field (for backward compatibility)\n                if \"template\" in selected_prompt:\n                    template = selected_prompt[\"template\"]\n                    logger.info(f\"Trying fallback direct template: {template}\")\n\n                    if isinstance(template, str) and template.strip():\n                        return template\n                    elif isinstance(template, list) and template:\n                        first_item = template[0]\n                        if isinstance(first_item, dict) and \"content\" in first_item:\n                            content = first_item[\"content\"]\n                            if isinstance(content, dict) and \"text\" in content:\n                                return content[\"text\"]\n\n        except Exception as e:\n            logger.error(f\"Error extracting template content: {e}\")\n            logger.exception(\"Full error details:\")\n\n        logger.error(\"Failed to extract template content from any expected location\")\n        return \"\"\n\n    @staticmethod\n    def _extract_variables(template: str) -> list[str]:\n        \"\"\"Extract variables from template - supports both {var} and {{ var }} formats\"\"\"\n        # Your templates use {{ var }} format based on the seed data\n        vars_double = re.findall(r\"\\{\\{\\s*(\\w+)\\s*\\}\\}\", template)\n        vars_single = re.findall(r\"\\{(\\w+)\\}\", template)\n\n        # Combine and deduplicate\n        variables = list(set(vars_double + vars_single))\n        logger.info(f\"Extracted variables from template: {variables}\")\n        logger.info(\n            f\"Template used for extraction: {template[:200]}...\"\n        )  # First 200 chars\n\n        return variables\n\n    async def _validate_and_refresh_template(self) -> bool:\n        \"\"\"Validate that the selected template is still available, if not fetch and re-add it\"\"\"\n        if not self._selected_prompt_name:\n            logger.info(\"No template selected, validation skipped\")\n            return True\n\n        try:\n            criteria = {\"max_results\": 100}\n            prompts = await self.prompt_service.get_prompts(criteria)\n            prompt_list = prompts.get(\"prompts\", [])\n\n            # Check if the selected template still exists\n            available_names = [\n                p.get(\"name\") for p in prompt_list if isinstance(p, dict)\n            ]\n\n            if self._selected_prompt_name in available_names:\n                logger.info(\n                    f\"Template '{self._selected_prompt_name}' is still available\"\n                )\n                return True\n            else:\n                logger.warning(\n                    f\"Template '{self._selected_prompt_name}' is no longer available, attempting to refresh...\"\n                )\n\n                # Try to find the template again and refresh it\n                selected_prompt = next(\n                    (\n                        p\n                        for p in prompt_list\n                        if p.get(\"name\") == self._selected_prompt_name\n                    ),\n                    None,\n                )\n\n                if selected_prompt:\n                    logger.info(\n                        f\"Found template '{self._selected_prompt_name}' in fresh fetch, refreshing content...\"\n                    )\n\n                    # Re-extract and update the template content\n                    template_content = self._extract_template_content(selected_prompt)\n\n                    if template_content:\n                        self._attributes[\"template\"] = template_content\n                        if hasattr(self, \"template\"):\n                            self.template = template_content\n                        logger.info(\n                            f\"Successfully refreshed template content: {template_content[:100]}...\"\n                        )\n                        return True\n                    else:\n                        logger.error(\n                            f\"Failed to extract content from refreshed template '{self._selected_prompt_name}'\"\n                        )\n                        return False\n                else:\n                    logger.error(\n                        f\"Template '{self._selected_prompt_name}' not found even after refresh\"\n                    )\n                    logger.info(f\"Available templates: {available_names}\")\n                    return False\n\n        except Exception as e:\n            logger.error(f\"Error validating/refreshing selected template: {e}\")\n            logger.exception(\"Full error details:\")\n            # If we can't validate, assume it's still valid to avoid breaking the flow\n            return True\n\n    async def build_prompt(self) -> Message:\n        # Validate and refresh the selected template if needed\n        if self._selected_prompt_name:\n            is_valid = await self._validate_and_refresh_template()\n            if not is_valid:\n                error_message = f\"Error: Selected template '{self._selected_prompt_name}' is no longer available and could not be refreshed. Please select a different template.\"\n                logger.error(error_message)\n                return Message(text=error_message)\n\n        template = self._attributes.get(\"template\", \"\")\n        variables = self._extract_variables(template)\n\n        for var in variables:\n            # Try different case variations\n            value = (\n                self._attributes.get(var)\n                or self._attributes.get(var.lower())\n                or self._attributes.get(var.title())\n                or \"\"\n            )\n\n            # Replace both {{ var }} and {var} formats\n            template = re.sub(\n                rf\"\\{{\\{{\\s*{re.escape(var)}\\s*\\}}\\}}\", str(value), template\n            )\n            template = re.sub(rf\"\\{{{re.escape(var)}\\}}\", str(value), template)\n\n        return Message(text=template)\n\n    async def update_build_config(\n        self, build_config, field_value, field_name=None\n    ) -> dict:\n        if field_name == \"saved_prompt\":\n            try:\n                criteria = {\"max_results\": 100}\n                prompts = await self.prompt_service.get_prompts(criteria)\n                prompt_list = prompts.get(\"prompts\", [])\n\n                logger.info(f\"Retrieved {len(prompt_list)} prompts from service\")\n\n                # Extract template names for dropdown\n                template_names = [\n                    p.get(\"name\", \"Unnamed Template\")\n                    for p in prompt_list\n                    if isinstance(p, dict)\n                ]\n                build_config[\"saved_prompt\"][\"options\"] = template_names\n                logger.info(f\"Available template names: {template_names}\")\n\n                if field_value:\n                    logger.info(f\"Processing selected prompt: {field_value}\")\n\n                    # Store the selected prompt name for validation during build\n                    self._selected_prompt_name = field_value\n\n                    # Find the selected prompt\n                    selected_prompt = next(\n                        (p for p in prompt_list if p.get(\"name\") == field_value), None\n                    )\n\n                    if selected_prompt:\n                        logger.info(f\"Found prompt with name: {field_value}\")\n\n                        # Extract template content using the correct SDK format\n                        template_content = self._extract_template_content(\n                            selected_prompt\n                        )\n\n                        if not template_content:\n                            logger.error(\"Failed to extract template content\")\n                            return build_config\n\n                        logger.info(\n                            f\"Successfully extracted template: {template_content[:100]}...\"\n                        )\n\n                        # Update the template in the component\n                        self._attributes[\"template\"] = template_content\n                        if hasattr(self, \"template\"):\n                            self.template = template_content\n                        build_config[\"template\"][\"value\"] = template_content\n\n                        # Extract variables from the template\n                        parameters = self._extract_variables(template_content)\n\n                        if not parameters:\n                            logger.info(\n                                \"No variables found in template - no dynamic fields needed\"\n                            )\n                            return build_config\n\n                        logger.info(f\"Found {len(parameters)} parameters: {parameters}\")\n\n                        # Remove existing dynamic fields\n                        fields_to_remove = [\n                            key\n                            for key in list(build_config.keys())\n                            if isinstance(build_config.get(key, {}), dict)\n                            and build_config[key].get(\"is_custom_field\", False)\n                        ]\n\n                        for key in fields_to_remove:\n                            build_config.pop(key, None)\n                            logger.info(f\"Removed existing dynamic field: {key}\")\n\n                        # Create new dynamic fields for each parameter\n                        for param in parameters:\n                            param_name = param.strip()\n                            if not param_name:\n                                continue\n\n                            display_name = param_name.replace(\"_\", \" \").title()\n\n                            build_config[param_name] = {\n                                \"is_custom_field\": True,\n                                \"name\": param_name,\n                                \"display_name\": display_name,\n                                \"value\": \"\",\n                                \"info\": f\"Enter value for {display_name}\",\n                                \"required\": True,\n                                \"show\": True,\n                                \"multiline\": True,\n                                \"dynamic\": True,\n                                \"placeholder\": f\"Enter {display_name.lower()}...\",\n                                \"advanced\": False,\n                                \"field_type\": \"str\",\n                                \"fileTypes\": [],\n                                \"file_path\": \"\",\n                                \"input_types\": [\"Message\", \"Text\"],\n                                \"list\": False,\n                                \"load_from_db\": False,\n                                \"title_case\": False,\n                                \"type\": \"str\",\n                            }\n\n                            logger.info(\n                                f\"Created dynamic field: {param_name} -> {display_name}\"\n                            )\n\n                        logger.info(\n                            f\"Successfully created {len(parameters)} dynamic fields\"\n                        )\n\n                    else:\n                        logger.warning(\n                            f\"Prompt '{field_value}' not found in available prompts\"\n                        )\n                        logger.info(\n                            f\"Available prompts: {[p.get('name') for p in prompt_list]}\"\n                        )\n\n                else:\n                    # Clear the selected prompt name if no value is selected\n                    self._selected_prompt_name = None\n\n            except Exception as e:\n                logger.error(f\"Error in update_build_config: {e}\")\n                logger.exception(\"Full error details:\")\n                build_config[\"saved_prompt\"][\"options\"] = []\n\n        return build_config\n"
              },
              "saved_prompt": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Choose from Templates",
                "dynamic": false,
                "info": "Select a Template",
                "name": "saved_prompt",
                "options": [],
                "placeholder": "",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Benefits Check Agent"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "You are a Healthcare Authorization Processing Assistant specialized in evaluating service code eligibility, coverage, and authorization requirements. Your goal is to analyze authorization requests and provide a complete evaluation report following LOB-specific validation workflows.\n\n## INSTRUCTIONS:\nWhen given a healthcare authorization request, you will:\n\n### 1. PARSE INPUT:\nExtract key information from the JSON input including member information, service codes, state, LOB (line of business), and diagnoses.\n- When state is empty, use \"WA\" (Washington) derived from the health plan code (e.g., \"WA-MHI\")\n- When LOB is empty, use \"Medicaid\" for Molina Healthcare plans\n- Extract service codes from the services array\n\n### 2. DETERMINE WORKFLOW:\nBased on the LOB, follow these specific validation workflows:\n\n**For Medicare:**\n- For EACH service code separately, use the encoder pro get_service_code_info tool\n- Use check_prior_authorization\n- Use eoc_check_tool to check coverage in EOC documents\n- Use accumulator_tool with complete member information: service code, member ID, LOB, state, and case details\n\n**For Medicaid:**\n- For EACH service code separately, use the encoder pro get_service_code_info tool\n- Use check_prior_authorization\n- (Skip EOC validation and accumulator checks for Medicaid)\n\n**For Marketplace:**\n- For EACH service code separately, use the encoder pro get_service_code_info tool\n- Use check_prior_authorization\n- Use eoc_check_tool to check coverage in EOC documents\n- (Skip accumulator checks for Marketplace)\n\n### 3. ACCUMULATOR TOOL USAGE:\nWhen calling the accumulator_tool for Medicare cases, pass a comprehensive input that includes:\n- Service code (if specified)\n- Member ID (if specified)\n- Line of business (if specified)\n- State (if specified)\n- Case ID (if specified)\n- Units requested (if specified)\n- Start/end dates (if specified)\n- Associated diagnoses (if specified)\n\n**Format the accumulator_tool input as:**\n```\nService Code: [CODE]\nMember ID: [MEMBER_ID]\nCase ID: [CASE_ID]\nLine of Business: [LOB]\nState: [STATE]\nUnits Requested: [UNITS]\nStart Date: [START_DATE]\nEnd Date: [END_DATE]\nDiagnoses: [DIAGNOSIS_CODES_AND_DESCRIPTIONS]\n```\n\n### 4. CREATE A CONSOLIDATED REPORT with the following sections:\n- **AUTHORIZATION SUMMARY:** General overview of the request\n- **MEMBER DETAILS:** Information about the member\n- **SERVICE CODE ANALYSIS:** Detailed information for each service code\n- **COVERAGE DETERMINATION:** Whether services are covered\n- **DIAGNOSES:** List any diagnoses associated with the current authorization request\n- **PA REQUIREMENTS:** Whether prior authorization is required\n- **EOC VALIDATION:** Include results from EOC validation (Medicare and Marketplace only)\n- **ACCUMULATOR CHECK:** Include results from accumulator check (Medicare only)\n- **RECOMMENDATION:** Suggested decision based on all findings\n\n## ERROR HANDLING:\n- If a tool returns an error, clearly indicate this in the appropriate section with \"Not available due to system error\" and CONTINUE with other sections\n- For DME codes like E1161 (wheelchairs), if errors occur, note that these typically:\n  * Require prior authorization for Medicaid\n  * Are covered when medically necessary with proper documentation\n- AFTER all tools have been called, generate the FINAL report using whatever information is available\n- Do NOT wait for \"pending\" information - all tool results (successful or error) are considered COMPLETE and FINAL\n\nIMPORTANT: When ANY tool returns an error or fails to complete, immediately treat that as a complete response containing \"System Error\". DO NOT retry tools that fail. Complete all tool calls sequentially regardless of errors and then generate the final report.\n\n## OUTPUT FORMAT:\n- Use bullet points for clarity\n- Bold important section headers\n- Include all sections even if information is limited\n- No need to repeat the full report twice\n- Mark incomplete information clearly as \"Not available\" rather than \"Pending\"\n- For sections that don't apply to the current LOB, include the section but note \"Not applicable for [LOB] line of business\"\n\nREMEMBER: Your primary responsibility is to provide a COMPLETE analysis that will help determine whether the authorization request should be approved, denied, or requires further review, EVEN WHEN TOOL RESPONSES CONTAIN ERRORS."
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "PromptTemplate"
        },
        "dragging": false,
        "id": "PromptTemplate-pLVYM",
        "measured": {
          "height": 322,
          "width": 320
        },
        "position": {
          "x": 1237.6224995426203,
          "y": -944.2569858050422
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatInput-oPALw",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "metadata": {
              "code_hash": "46a90558cb44",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 1
              },
              "module": "lfx.components.input_output.chat.ChatInput"
            },
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chat Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from lfx.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom lfx.base.io.chat import ChatComponent\nfrom lfx.inputs.inputs import BoolInput\nfrom lfx.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom lfx.schema.message import Message\nfrom lfx.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-input\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n            temp_file=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Chat Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "_input_type": "FileInput",
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "csv",
                  "json",
                  "pdf",
                  "txt",
                  "md",
                  "mdx",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Input Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatInput"
        },
        "dragging": false,
        "id": "ChatInput-oPALw",
        "measured": {
          "height": 65,
          "width": 192
        },
        "position": {
          "x": 664.6211554924087,
          "y": -36.541312418164296
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": -385.94116677073157,
      "y": 1020.9867682754516,
      "zoom": 0.589443120134206
    }
  },
  "description": "Benefit Check Agent V2",
  "endpoint_name": null,
  "is_component": false,
  "last_tested_version": "1.4.3",
  "name": "Benefit Check Agent",
  "tags": [
    "prior-auth"
  ]
}