{
  "data": {
    "nodes": [
      {
        "data": {
          "id": "Agent-BJ0z7",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "display_name": "Eligibility Verification Agent",
            "documentation": "",
            "edited": false,
            "field_order": [
              "agent_llm",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "system_prompt",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "return_intermediate_steps",
              "agent_description",
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template",
              "add_current_date_tool"
            ],
            "frozen": false,
            "icon": "bot",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "response",
                "hidden": null,
                "display_name": "Response",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "options": null,
                "tool_mode": true
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "add_current_date_tool": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Current Date",
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "input_types": [],
                "list": false,
                "name": "add_current_date_tool",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "agent_llm": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Model Provider",
                "dynamic": false,
                "info": "The provider of the language model that the agent will use to generate responses.",
                "input_types": [],
                "load_from_db": false,
                "name": "agent_llm",
                "options": [
                  "Amazon Bedrock",
                  "Anthropic",
                  "Azure OpenAI",
                  "Google Generative AI",
                  "Groq",
                  "NVIDIA",
                  "OpenAI",
                  "SambaNova",
                  "Custom"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Azure OpenAI"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_core.tools import StructuredTool\n\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.base.agents.events import ExceptionWithMessageError\nfrom langflow.base.models.model_input_constants import (\n    ALL_PROVIDER_FIELDS,\n    MODEL_DYNAMIC_UPDATE_FIELDS,\n    MODEL_PROVIDERS_DICT,\n    MODELS_METADATA,\n)\nfrom langflow.base.models.model_utils import get_model_name\nfrom langflow.components.helpers import CurrentDateComponent\nfrom langflow.components.helpers.memory import MemoryComponent\nfrom langflow.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom langflow.custom.utils import update_component_build_config\nfrom langflow.io import BoolInput, DropdownInput, MultilineInput, Output\nfrom langflow.logging import logger\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            input_types=[],\n            options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())] + [{\"icon\": \"brain\"}],\n        ),\n        *MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"],\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        *LCToolsAgentComponent._base_inputs,\n        *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [Output(name=\"response\", display_name=\"Response\", method=\"message_response\")]\n\n    async def message_response(self) -> Message:\n        try:\n            # Get LLM model and validate\n            llm_model, display_name = self.get_llm()\n            if llm_model is None:\n                msg = \"No language model selected. Please choose a model to proceed.\"\n                raise ValueError(msg)\n            self.model_name = get_model_name(llm_model, display_name=display_name)\n\n            # Get memory data\n            self.chat_history = await self.get_memory_data()\n\n            # Add current date tool if enabled\n            if self.add_current_date_tool:\n                if not isinstance(self.tools, list):  # type: ignore[has-type]\n                    self.tools = []\n                current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n                if not isinstance(current_date_tool, StructuredTool):\n                    msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                    raise TypeError(msg)\n                self.tools.append(current_date_tool)\n\n            # Validate tools\n            if not self.tools:\n                msg = \"Tools are required to run the agent. Please add at least one tool.\"\n                raise ValueError(msg)\n\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools,\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            return await self.run_agent(agent)\n\n        except (ValueError, TypeError, KeyError) as e:\n            logger.error(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            logger.error(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Unexpected error: {e!s}\")\n            raise\n\n    async def get_memory_data(self):\n        memory_kwargs = {\n            component_input.name: getattr(self, f\"{component_input.name}\") for component_input in self.memory_inputs\n        }\n        # filter out empty values\n        memory_kwargs = {k: v for k, v in memory_kwargs.items() if v is not None}\n\n        return await MemoryComponent(**self.get_base_args()).set(**memory_kwargs).retrieve_messages()\n\n    def get_llm(self):\n        if not isinstance(self.agent_llm, str):\n            return self.agent_llm, None\n\n        try:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if not provider_info:\n                msg = f\"Invalid model provider: {self.agent_llm}\"\n                raise ValueError(msg)\n\n            component_class = provider_info.get(\"component_class\")\n            display_name = component_class.display_name\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\", \"\")\n\n            return self._build_llm_model(component_class, inputs, prefix), display_name\n\n        except Exception as e:\n            logger.error(f\"Error building {self.agent_llm} language model: {e!s}\")\n            msg = f\"Failed to initialize language model: {e!s}\"\n            raise ValueError(msg) from e\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n        return component.set(**model_kwargs).build_model()\n\n    def set_component_params(self, component):\n        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n        if provider_info:\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\")\n            model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n\n            return component.set(**model_kwargs)\n        return component\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self, build_config: dotdict, field_value: str, field_name: str | None = None\n    ) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name in (\"agent_llm\",):\n            build_config[\"agent_llm\"][\"value\"] = field_value\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n            elif field_value == \"Custom\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n                    value=\"Custom\",\n                    real_time_refresh=True,\n                    input_types=[\"LanguageModel\"],\n                    options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())]\n                    + [{\"icon\": \"brain\"}],\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if (\n            isinstance(self.agent_llm, str)\n            and self.agent_llm in MODEL_PROVIDERS_DICT\n            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS\n        ):\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                component_class = self.set_component_params(component_class)\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": []
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "input_types": [],
                "list": false,
                "name": "handle_parsing_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "input_types": [],
                "list": false,
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 15
              },
              "memory": {
                "_input_type": "HandleInput",
                "advanced": true,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "Memory"
                ],
                "list": false,
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "input_types": [],
                "list": false,
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "order": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Order",
                "dynamic": false,
                "info": "Order of the messages.",
                "input_types": [],
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Filter by sender type.",
                "input_types": [],
                "name": "sender",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine and User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Filter by sender name.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Agent Instructions",
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are a helpful assistant that can use tools to answer questions and perform tasks."
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{sender_name}: {text}"
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "azure_endpoint": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": true,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "azure_endpoint",
                "value": "AZURE_OPENAI_ENDPOINT",
                "display_name": "Azure Endpoint",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "azure_deployment": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": true,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "azure_deployment",
                "value": "AZURE_OPENAI_DEPLOYMENT",
                "display_name": "Deployment Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "API Key",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "api_version": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "2025-02-01-preview",
                  "2025-01-01-preview",
                  "2024-12-01-preview",
                  "2024-10-01-preview",
                  "2024-09-01-preview",
                  "2024-08-01-preview",
                  "2024-07-01-preview",
                  "2024-06-01",
                  "2024-03-01-preview",
                  "2024-02-15-preview",
                  "2023-12-01-preview",
                  "2023-05-15"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "toggle": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_version",
                "value": "2024-06-01",
                "display_name": "API Version",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "input_types": []
              },
              "temperature": {
                "tool_mode": false,
                "min_label": "",
                "max_label": "",
                "min_label_icon": "",
                "max_label_icon": "",
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 2,
                  "step": 0.01
                },
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.7,
                "display_name": "Temperature",
                "advanced": true,
                "dynamic": false,
                "info": "Controls randomness. Lower values are more deterministic, higher values are more creative.",
                "title_case": false,
                "type": "slider",
                "_input_type": "SliderInput",
                "input_types": []
              },
              "max_tokens": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput",
                "input_types": []
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Agent"
        },
        "dragging": false,
        "id": "Agent-BJ0z7",
        "measured": {
          "height": 817,
          "width": 320
        },
        "position": {
          "x": 2122.7573908645354,
          "y": -701.25606921868
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "description": "Get information and coverage status for service codes.",
          "display_name": "Encoder Pro",
          "id": "EncoderProTool-Z95W8",
          "node": {
            "base_classes": [
              "Data",
              "Tool"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get information and coverage status for service codes.",
            "display_name": "Encoder Pro",
            "documentation": "",
            "edited": false,
            "field_order": [
              "default_service_code",
              "default_check_coverage"
            ],
            "frozen": false,
            "icon": "Autonomize",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Data",
                "hidden": true,
                "method": "run_model",
                "name": "api_run_model",
                "required_inputs": [],
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Tool",
                "method": "build_tool",
                "name": "api_build_tool",
                "required_inputs": [],
                "selected": "Tool",
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "\"\"\"Tool component for checking service code information and coverage using Encoder Pro.\"\"\"\n\nfrom pydantic import BaseModel, Field\nfrom typing import Dict, List, Any, Optional\nfrom langchain_core.tools import StructuredTool, ToolException\n\nfrom langflow.base.langchain_utilities.model import LCToolComponent\nfrom langflow.field_typing import Tool\nfrom langflow.inputs import MessageTextInput\nfrom langflow.schema import Data\nfrom langflow.logging import logger\nfrom app.services.deps import get_encoder_pro_service\n\n\nclass EncoderProTool(LCToolComponent):\n    \"\"\"Tool component for checking service code information and coverage using Encoder Pro.\"\"\"\n\n    display_name: str = \"Encoder Pro\"\n    description: str = \"Get information and coverage status for service codes.\"\n    icon: str = \"Autonomize\"\n    name: str = \"EncoderProTool\"\n\n    class CodeInfoSchema(BaseModel):\n        \"\"\"Schema for the Encoder Pro code information tool.\"\"\"\n\n        service_code: str = Field(\n            ...,\n            description=\"Service code to check (CPT or HCPCS)\",\n            examples=[\"95810\", \"J7352\"],\n        )\n        check_coverage: bool = Field(\n            True,\n            description=\"Whether to check Medicare coverage status\",\n        )\n\n    inputs = [\n        MessageTextInput(\n            name=\"default_service_code\",\n            display_name=\"Default Service Code\",\n            info=\"Default service code to check.\",\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"default_check_coverage\",\n            display_name=\"Check Coverage\",\n            info=\"Whether to check Medicare coverage status by default (true/false).\",\n            tool_mode=True,\n        ),\n    ]\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the Encoder Pro Tool component.\"\"\"\n        super().__init__(**kwargs)\n\n    async def get_code_info(\n        self, service_code: str, check_coverage: bool = True\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Get detailed information about a service code including description and coverage status.\n\n        Args:\n            service_code: The CPT or HCPCS code to check\n            check_coverage: Whether to check Medicare coverage status\n\n        Returns:\n            Dictionary containing code information and coverage status\n        \"\"\"\n        logger.info(\n            f\"Getting information for service code: {service_code}, check coverage: {check_coverage}\"\n        )\n\n        try:\n            # Normalize input\n            clean_code = service_code.strip()\n\n            # Validate the code format (basic validation)\n            if not clean_code:\n                raise ValueError(\"Service code cannot be empty\")\n\n            # Determine code type\n            code_type = self._determine_code_type(clean_code)\n\n            # Get combined result\n            result = {\n                \"code\": clean_code,\n                \"code_type\": code_type.upper(),\n            }\n\n            # Get description\n            try:\n                description_data = (\n                    await get_encoder_pro_service().get_layman_description(\n                        code_type, clean_code\n                    )\n                )\n                result[\"description\"] = description_data.get(\n                    \"descriptionLay\", \"Description not available\"\n                )\n                result[\"technical_description\"] = description_data.get(\n                    \"description\", \"\"\n                )\n            except Exception as e:\n                logger.error(f\"Error getting description for code {clean_code}: {e}\")\n                result[\"description\"] = \"Error retrieving description\"\n                result[\"description_error\"] = str(e)\n\n            # Check coverage if requested\n            if check_coverage:\n                try:\n                    is_covered, coverage_data = (\n                        await get_encoder_pro_service().check_code_coverage(clean_code)\n                    )\n                    result[\"is_covered\"] = is_covered\n                    result[\"coverage_details\"] = coverage_data\n\n                    # Extract color codes for easier access\n                    if \"colorCodes\" in coverage_data:\n                        result[\"color_codes\"] = coverage_data[\"colorCodes\"]\n\n                except Exception as e:\n                    logger.error(f\"Error checking coverage for code {clean_code}: {e}\")\n                    result[\"is_covered\"] = None\n                    result[\"coverage_error\"] = str(e)\n\n            return result\n\n        except Exception as e:\n            logger.error(f\"Error getting code information: {e}\")\n            raise ToolException(f\"Error getting code information: {str(e)}\")\n\n    def _determine_code_type(self, code: str) -> str:\n        \"\"\"\n        Determine the code type (CPT or HCPCS) based on the code format.\n\n        Args:\n            code: The code to evaluate\n\n        Returns:\n            Code type ('cpt' or 'hcpcs')\n        \"\"\"\n        # Simple heuristic - could be improved for production\n        if code.isdigit() and len(code) == 5:\n            return \"cpt\"\n        else:\n            return \"hcpcs\"\n\n    def build_tool(self) -> Tool:\n        \"\"\"Build the Encoder Pro tool for use by an agent.\"\"\"\n\n        # Create synchronous wrapper for async function\n        def sync_wrapper(async_func):\n            def wrapper(*args, **kwargs):\n                try:\n                    # Create a new event loop for each call\n                    loop = asyncio.new_event_loop()\n                    asyncio.set_event_loop(loop)\n\n                    try:\n                        return loop.run_until_complete(async_func(*args, **kwargs))\n                    finally:\n                        loop.close()\n                except Exception as e:\n                    logger.error(f\"Error in {async_func.__name__}: {str(e)}\")\n                    # Return structured error response\n                    return {\n                        \"error\": str(e),\n                        \"code\": kwargs.get(\"service_code\", \"unknown\"),\n                        \"code_type\": \"Unknown\",\n                        \"description\": \"Error retrieving code information\",\n                        \"is_covered\": None,\n                        \"system_error\": True,\n                    }\n\n            return wrapper\n\n        return StructuredTool.from_function(\n            name=\"get_service_code_info\",\n            description=(\n                \"Get detailed information about a medical service code (CPT or HCPCS), \"\n                \"including its description and Medicare coverage status. \"\n                \"Use this to understand what a specific code means and whether it's covered.\"\n            ),\n            func=sync_wrapper(self.get_code_info),\n            args_schema=self.CodeInfoSchema,\n        )\n\n    def run_model(self) -> list[Data]:\n        \"\"\"Run the tool directly with the component's inputs, for API/direct use.\"\"\"\n        # Get values from UI inputs or use defaults\n        service_code = (\n            self.default_service_code\n            if hasattr(self, \"default_service_code\") and self.default_service_code\n            else \"\"\n        )\n\n        # Parse check_coverage from string to boolean\n        check_coverage_str = (\n            self.default_check_coverage\n            if hasattr(self, \"default_check_coverage\") and self.default_check_coverage\n            else \"\"\n        )\n        check_coverage = True  # Default value\n        if check_coverage_str.lower() in (\"false\", \"no\", \"0\", \"f\", \"n\"):\n            check_coverage = False\n\n        if not service_code:\n            return [\n                Data(\n                    data={\"error\": \"No service code provided\"},\n                    text=\"Error: No service code provided\",\n                )\n            ]\n\n        # Get the tool to use its structured functionality\n        tool = self.build_tool()\n\n        try:\n            import asyncio\n\n            # Create a dedicated event loop\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n\n            try:\n                # Run the async function\n                result = loop.run_until_complete(\n                    self.get_code_info(\n                        service_code=service_code, check_coverage=check_coverage\n                    )\n                )\n            finally:\n                loop.close()\n\n            # Format the result as text\n            text_result = f\"Service Code Information: {service_code} ({result.get('code_type', 'Unknown')})\\n\\n\"\n            text_result += f\"Description: {result.get('description', 'Unknown')}\\n\"\n\n            if check_coverage:\n                coverage_status = (\n                    \"Covered\" if result.get(\"is_covered\") else \"Not Covered\"\n                )\n                if result.get(\"is_covered\") is None:\n                    coverage_status = \"Coverage status unknown\"\n\n                text_result += f\"Medicare Coverage: {coverage_status}\\n\"\n\n                # Add color codes if available\n                if \"color_codes\" in result:\n                    color_codes = result[\"color_codes\"]\n                    if isinstance(color_codes, list) and color_codes:\n                        text_result += \"\\nColor Codes:\\n\"\n                        for color_code in color_codes:\n                            color = color_code.get(\"colorCode\", \"Unknown\")\n                            desc = color_code.get(\"shortDescription\", \"\")\n                            text_result += f\"- {color}: {desc}\\n\"\n\n            return [Data(data=result, text=text_result)]\n\n        except Exception as e:\n            error_message = f\"Error getting code information: {str(e)}\"\n            return [Data(data={\"error\": error_message}, text=error_message)]\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "default_check_coverage": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Check Coverage",
                "dynamic": false,
                "info": "Whether to check Medicare coverage status by default (true/false).",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "default_check_coverage",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "default_service_code": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Default Service Code",
                "dynamic": false,
                "info": "Default service code to check.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "default_service_code",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "EncoderProTool"
        },
        "dragging": false,
        "id": "EncoderProTool-Z95W8",
        "measured": {
          "height": 339,
          "width": 320
        },
        "position": {
          "x": 697.8580958993084,
          "y": -1001.0560620538688
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "QNextAuthHistoryTool-s2kGz",
          "node": {
            "base_classes": [
              "Data",
              "Tool"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Retrieve claim and authorization history for a member from QNext.",
            "display_name": "QNXT Claim & Auth History",
            "documentation": "",
            "edited": false,
            "field_order": [
              "default_member_id",
              "default_start_date",
              "default_end_date",
              "default_limit"
            ],
            "frozen": false,
            "icon": "Autonomize",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Data",
                "method": "run_model",
                "name": "api_run_model",
                "required_inputs": [],
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Tool",
                "method": "build_tool",
                "name": "api_build_tool",
                "required_inputs": [],
                "selected": "Tool",
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "\"\"\"Tool component for retrieving claim and authorization history.\"\"\"\n\nfrom pydantic import BaseModel, Field\nfrom typing import Dict, List, Any, Optional\nfrom langchain_core.tools import StructuredTool, ToolException\nfrom datetime import datetime\nimport asyncio\nimport traceback\n\nfrom langflow.base.langchain_utilities.model import LCToolComponent\nfrom langflow.field_typing import Tool\nfrom langflow.custom.custom_component.component import Input\nfrom langflow.schema import Data\nfrom langflow.logging import logger\nfrom app.services.deps import get_claim_auth_history_service\n\n\nclass ClaimHistorySchema(BaseModel):\n    \"\"\"Schema for the claim history tool.\"\"\"\n\n    member_id: str = Field(\n        ...,\n        description=\"Member ID to retrieve claim history for\",\n    )\n    start_date: Optional[str] = Field(\n        None,\n        description=\"Start date for claim history (ISO format, e.g., '2023-01-01'). If not provided, defaults to 12 months ago.\",\n    )\n    end_date: Optional[str] = Field(\n        None,\n        description=\"End date for claim history (ISO format, e.g., '2023-12-31'). If not provided, defaults to current date.\",\n    )\n    limit: Optional[int] = Field(\n        10,\n        description=\"Maximum number of claims to retrieve\",\n    )\n\n\nclass AuthHistorySchema(BaseModel):\n    \"\"\"Schema for the authorization history tool.\"\"\"\n\n    member_id: str = Field(\n        ...,\n        description=\"Member ID to retrieve authorization history for\",\n    )\n    start_date: Optional[str] = Field(\n        None,\n        description=\"Start date for authorization history (ISO format, e.g., '2023-01-01'). If not provided, defaults to 12 months ago.\",\n    )\n    end_date: Optional[str] = Field(\n        None,\n        description=\"End date for authorization history (ISO format, e.g., '2023-12-31'). If not provided, defaults to current date.\",\n    )\n    limit: Optional[int] = Field(\n        10,\n        description=\"Maximum number of authorizations to retrieve\",\n    )\n\n\nclass QNextAuthHistoryTool(LCToolComponent):\n    \"\"\"Tool component for retrieving claim and authorization history.\"\"\"\n\n    display_name: str = \"QNext Claim & Auth History\"\n    description: str = (\n        \"Retrieve claim and authorization history for a member from QNext.\"\n    )\n    icon: str = \"Autonomize\"\n    name: str = \"QNextAuthHistoryTool\"\n\n    inputs = [\n        Input(\n            name=\"default_member_id\",\n            display_name=\"Default Member ID\",\n            info=\"Default member ID to retrieve history for (optional).\",\n            required=False,\n            tool_mode=True,\n        ),\n        Input(\n            name=\"default_start_date\",\n            display_name=\"Default Start Date\",\n            info=\"Default start date in ISO format (e.g., '2023-01-01').\",\n            required=False,\n            tool_mode=True,\n        ),\n        Input(\n            name=\"default_end_date\",\n            display_name=\"Default End Date\",\n            info=\"Default end date in ISO format (e.g., '2023-12-31').\",\n            required=False,\n            tool_mode=True,\n        ),\n        Input(\n            name=\"default_limit\",\n            display_name=\"Default Limit\",\n            info=\"Default maximum number of records to retrieve.\",\n            required=False,\n            field_type=\"int\",\n            tool_mode=True,\n        ),\n    ]\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the Claim & Auth History Tool component.\"\"\"\n        super().__init__(**kwargs)\n\n    @property\n    def history_service(self):\n        \"\"\"Get the Claim & Auth History service.\"\"\"\n        return get_claim_auth_history_service()\n\n    async def get_claim_history(\n        self,\n        member_id: str,\n        start_date: Optional[str] = None,\n        end_date: Optional[str] = None,\n        limit: Optional[int] = 10,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Retrieve claim history for a member.\n        \"\"\"\n        logger.info(f\"Getting claim history for member ID: {member_id}\")\n\n        try:\n            # Validate member ID\n            if not member_id:\n                raise ValueError(\"Member ID is required\")\n\n            # Validate limit\n            if limit is not None and (not isinstance(limit, int) or limit < 1):\n                limit = 10\n\n            # Call the service\n            result = await self.history_service.get_claim_history(\n                member_id=member_id,\n                start_date=start_date,\n                end_date=end_date,\n                limit=limit,\n            )\n\n            # Process the result for better usability\n            summary = self._create_claim_summary(result)\n            result[\"summary\"] = summary\n\n            return result\n\n        except Exception as e:\n            logger.error(f\"Error getting claim history: {e}\")\n            # Return structured error response instead of raising\n            return {\n                \"error\": str(e),\n                \"member_id\": member_id,\n                \"claims\": [],\n                \"total_count\": 0,\n                \"summary\": {\n                    \"total_claims\": 0,\n                    \"status_counts\": {},\n                    \"service_codes\": {},\n                },\n            }\n\n    async def get_auth_history(\n        self,\n        member_id: str,\n        start_date: Optional[str] = None,\n        end_date: Optional[str] = None,\n        limit: Optional[int] = 10,\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Retrieve authorization history for a member.\n        \"\"\"\n        logger.info(f\"Getting authorization history for member ID: {member_id}\")\n\n        try:\n            # Validate member ID\n            if not member_id:\n                raise ValueError(\"Member ID is required\")\n\n            # Validate limit\n            if limit is not None and (not isinstance(limit, int) or limit < 1):\n                limit = 10\n\n            # Call the service\n            result = await self.history_service.get_auth_history(\n                member_id=member_id,\n                start_date=start_date,\n                end_date=end_date,\n                limit=limit,\n            )\n\n            # Process the result for better usability\n            summary = self._create_auth_summary(result)\n            result[\"summary\"] = summary\n\n            return result\n\n        except Exception as e:\n            logger.error(f\"Error getting authorization history: {e}\")\n            # Return structured error response instead of raising\n            return {\n                \"error\": str(e),\n                \"member_id\": member_id,\n                \"authorizations\": [],\n                \"total_count\": 0,\n                \"summary\": {\n                    \"total_authorizations\": 0,\n                    \"status_counts\": {},\n                    \"service_codes\": {},\n                },\n            }\n\n    def _create_claim_summary(self, claim_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Create a summary of claim data for easier consumption.\n        \"\"\"\n        claims = claim_data.get(\"claims\", [])\n\n        # Count claims by status - ensure status is a string to avoid unhashable issues\n        status_counts = {}\n        for claim in claims:\n            status = str(claim.get(\"status\", \"Unknown\"))\n            status_counts[status] = status_counts.get(status, 0) + 1\n\n        # Count unique service codes - ensure code is a string\n        service_codes = {}\n        for claim in claims:\n            for service in claim.get(\"services\", []):\n                code = str(service.get(\"service_code\", \"Unknown\"))\n                service_codes[code] = service_codes.get(code, 0) + 1\n\n        # Calculate total amounts\n        total_billed = sum(claim.get(\"total_billed\", 0) for claim in claims)\n        total_paid = sum(claim.get(\"total_paid\", 0) for claim in claims)\n\n        # Return the summary\n        return {\n            \"total_claims\": len(claims),\n            \"status_counts\": status_counts,\n            \"service_codes\": service_codes,\n            \"total_billed\": round(total_billed, 2) if total_billed else 0,\n            \"total_paid\": round(total_paid, 2) if total_paid else 0,\n            \"payment_ratio\": (\n                round(total_paid / total_billed, 2) if total_billed > 0 else 0\n            ),\n        }\n\n    def _create_auth_summary(self, auth_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Create a summary of authorization data for easier consumption.\n        \"\"\"\n        auths = auth_data.get(\"authorizations\", [])\n\n        # Count authorizations by status - ensure status is a string\n        status_counts = {}\n        for auth in auths:\n            status = str(auth.get(\"status\", \"Unknown\"))\n            status_counts[status] = status_counts.get(status, 0) + 1\n\n        # Count unique service codes - ensure code is a string\n        service_codes = {}\n        for auth in auths:\n            for service in auth.get(\"services\", []):\n                code = str(service.get(\"service_code\", \"Unknown\"))\n                service_codes[code] = service_codes.get(code, 0) + 1\n\n        # Count active vs. expired auths\n        now = datetime.now().strftime(\"%Y-%m-%d\")\n        active_count = 0\n        for auth in auths:\n            auth_period = auth.get(\"auth_period\", {})\n            end_date = auth_period.get(\"end_date\", \"\")\n            if end_date >= now:\n                active_count += 1\n\n        # Return the summary\n        return {\n            \"total_authorizations\": len(auths),\n            \"active_authorizations\": active_count,\n            \"expired_authorizations\": len(auths) - active_count,\n            \"status_counts\": status_counts,\n            \"service_codes\": service_codes,\n        }\n\n    def build_tool(self) -> List[Tool]:\n        \"\"\"Build the claim and auth history tools for use by an agent.\"\"\"\n\n        # Create synchronous wrapper for async functions\n        def sync_wrapper(async_func):\n            def wrapper(*args, **kwargs):\n                try:\n                    # Create a new event loop for each call\n                    loop = asyncio.new_event_loop()\n                    asyncio.set_event_loop(loop)\n\n                    try:\n                        return loop.run_until_complete(async_func(*args, **kwargs))\n                    finally:\n                        loop.close()\n                except Exception as e:\n                    logger.error(f\"Error in {async_func.__name__}: {str(e)}\")\n                    # Return a structured result with error information\n                    error_response = {\n                        \"error\": str(e),\n                        \"system_error\": True,\n                        \"member_id\": (\n                            args[0] if args else kwargs.get(\"member_id\", \"unknown\")\n                        ),\n                    }\n\n                    # Add specific fields based on which function failed\n                    if async_func.__name__ == \"get_claim_history\":\n                        error_response.update(\n                            {\n                                \"claims\": [],\n                                \"total_count\": 0,\n                                \"summary\": {\n                                    \"total_claims\": 0,\n                                    \"service_codes\": {},\n                                    \"status_counts\": {},\n                                },\n                            }\n                        )\n                    elif async_func.__name__ == \"get_auth_history\":\n                        error_response.update(\n                            {\n                                \"authorizations\": [],\n                                \"total_count\": 0,\n                                \"summary\": {\n                                    \"total_authorizations\": 0,\n                                    \"service_codes\": {},\n                                    \"status_counts\": {},\n                                },\n                            }\n                        )\n\n                    return error_response\n\n            return wrapper\n\n        # Claim history tool with sync wrapper\n        claim_tool = StructuredTool.from_function(\n            name=\"get_claim_history\",\n            description=(\n                \"Retrieve claim history for a member to analyze past services and payments. \"\n                \"This includes details like dates of service, providers, diagnoses, service codes, and payment statuses.\"\n            ),\n            func=sync_wrapper(self.get_claim_history),\n            args_schema=ClaimHistorySchema,\n        )\n\n        # Auth history tool with sync wrapper\n        auth_tool = StructuredTool.from_function(\n            name=\"get_authorization_history\",\n            description=(\n                \"Retrieve authorization history for a member to analyze past and current authorizations. \"\n                \"This includes details like authorization dates, requesting providers, diagnoses, service codes, and statuses.\"\n            ),\n            func=sync_wrapper(self.get_auth_history),\n            args_schema=AuthHistorySchema,\n        )\n\n        return [claim_tool, auth_tool]\n\n    def run_model(self) -> list[Data]:\n        \"\"\"Run the tool directly with the component's inputs, for API/direct use.\"\"\"\n        # Get values from UI inputs or use defaults\n        member_id = (\n            self.default_member_id\n            if hasattr(self, \"default_member_id\") and self.default_member_id\n            else None\n        )\n        start_date = (\n            self.default_start_date\n            if hasattr(self, \"default_start_date\") and self.default_start_date\n            else None\n        )\n        end_date = (\n            self.default_end_date\n            if hasattr(self, \"default_end_date\") and self.default_end_date\n            else None\n        )\n        limit = (\n            self.default_limit\n            if hasattr(self, \"default_limit\") and self.default_limit\n            else 10\n        )\n\n        if not member_id:\n            return [\n                Data(\n                    data={\"error\": \"No member ID provided\"},\n                    text=\"Error: No member ID provided\",\n                )\n            ]\n\n        try:\n            # Create a dedicated event loop for this operation\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n\n            try:\n                # Run both functions in the same event loop\n                claim_future = self.get_claim_history(\n                    member_id=member_id,\n                    start_date=start_date,\n                    end_date=end_date,\n                    limit=limit,\n                )\n\n                auth_future = self.get_auth_history(\n                    member_id=member_id,\n                    start_date=start_date,\n                    end_date=end_date,\n                    limit=limit,\n                )\n\n                # Run both concurrently\n                claim_result, auth_result = loop.run_until_complete(\n                    asyncio.gather(claim_future, auth_future)\n                )\n            finally:\n                loop.close()\n\n            # Safely handle results\n            if not isinstance(claim_result, dict):\n                claim_result = {\n                    \"error\": \"Invalid claim result format\",\n                    \"claims\": [],\n                    \"summary\": {\"total_claims\": 0},\n                }\n\n            if not isinstance(auth_result, dict):\n                auth_result = {\n                    \"error\": \"Invalid auth result format\",\n                    \"authorizations\": [],\n                    \"summary\": {\"total_authorizations\": 0},\n                }\n\n            # Combine results\n            combined_result = {\n                \"member_id\": member_id,\n                \"date_range\": {\"start_date\": start_date, \"end_date\": end_date},\n                \"claims\": claim_result,\n                \"authorizations\": auth_result,\n            }\n\n            # Format the result as a list of Data objects\n            text = f\"Retrieved claim and auth history for member {member_id}.\"\n            if \"summary\" in claim_result:\n                text += (\n                    f\" Found {claim_result['summary'].get('total_claims', 0)} claims\"\n                )\n            if \"summary\" in auth_result:\n                text += f\" and {auth_result['summary'].get('total_authorizations', 0)} authorizations.\"\n\n            return [Data(data=combined_result, text=text)]\n\n        except Exception as e:\n            logger.error(f\"Error retrieving claim and authorization history: {str(e)}\")\n            logger.error(traceback.format_exc())\n            return [\n                Data(\n                    data={\"error\": str(e), \"member_id\": member_id},\n                    text=f\"Error retrieving claim and authorization history: {str(e)}\",\n                )\n            ]\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "default_end_date": {
                "advanced": false,
                "display_name": "Default End Date",
                "dynamic": false,
                "fileTypes": [],
                "file_path": "",
                "info": "Default end date in ISO format (e.g., '2023-12-31').",
                "list": false,
                "load_from_db": false,
                "multiline": false,
                "name": "default_end_date",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str"
              },
              "default_limit": {
                "advanced": false,
                "display_name": "Default Limit",
                "dynamic": false,
                "fileTypes": [],
                "file_path": "",
                "info": "Default maximum number of records to retrieve.",
                "list": false,
                "load_from_db": false,
                "multiline": false,
                "name": "default_limit",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "int"
              },
              "default_member_id": {
                "advanced": false,
                "display_name": "Default Member ID",
                "dynamic": false,
                "fileTypes": [],
                "file_path": "",
                "info": "Default member ID to retrieve history for (optional).",
                "list": false,
                "load_from_db": false,
                "multiline": false,
                "name": "default_member_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "default_start_date": {
                "advanced": false,
                "display_name": "Default Start Date",
                "dynamic": false,
                "fileTypes": [],
                "file_path": "",
                "info": "Default start date in ISO format (e.g., '2023-01-01').",
                "list": false,
                "load_from_db": false,
                "multiline": false,
                "name": "default_start_date",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "QNextAuthHistoryTool"
        },
        "dragging": false,
        "id": "QNextAuthHistoryTool-s2kGz",
        "measured": {
          "height": 559,
          "width": 320
        },
        "position": {
          "x": 986.9291360389806,
          "y": 967.7204955558304
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "PALookupTool-NaTa8",
          "node": {
            "base_classes": [
              "Data",
              "Tool"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Check if Prior Authorization is required for specific service codes.",
            "display_name": "PA Lookup",
            "documentation": "",
            "edited": false,
            "field_order": [
              "default_service_codes",
              "default_lob",
              "default_state"
            ],
            "frozen": false,
            "icon": "Autonomize",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Data",
                "method": "run_model",
                "name": "api_run_model",
                "required_inputs": [],
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Tool",
                "method": "build_tool",
                "name": "api_build_tool",
                "required_inputs": [],
                "selected": "Tool",
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "\"\"\"Tool component for checking Prior Authorization requirements for service codes.\"\"\"\n\nfrom pydantic import BaseModel, Field\nfrom typing import Dict, List, Any, Optional\nfrom langchain_core.tools import StructuredTool, ToolException\n\nfrom langflow.base.langchain_utilities.model import LCToolComponent\nfrom langflow.field_typing import Tool\nfrom langflow.inputs import MessageTextInput\nfrom langflow.schema import Data\nfrom langflow.logging import logger\nfrom app.services.deps import get_pa_lookup_service\n\n\nclass PALookupTool(LCToolComponent):\n    \"\"\"Tool component for checking Prior Authorization requirements for service codes.\"\"\"\n\n    display_name: str = \"PA Lookup\"\n    description: str = (\n        \"Check if Prior Authorization is required for specific service codes.\"\n    )\n    icon: str = \"Autonomize\"\n    name: str = \"PALookupTool\"\n\n    class PALookupSchema(BaseModel):\n        \"\"\"Schema for the PA Lookup tool.\"\"\"\n\n        service_codes: List[str] = Field(\n            ...,\n            description=\"List of service codes to check for Prior Authorization requirements\",\n            examples=[[\"95810\"], [\"58571\", \"38900\"]],\n        )\n        lob: str = Field(\n            ...,\n            description=\"Line of Business: Medicare, Medicaid, or Marketplace\",\n            examples=[\"Medicare\", \"Medicaid\", \"Marketplace\"],\n        )\n        state: str = Field(\n            ...,\n            description=\"Two-letter state code (e.g., MI for Michigan, WA for Washington)\",\n            examples=[\"MI\", \"WA\", \"CA\"],\n        )\n\n    inputs = [\n        MessageTextInput(\n            name=\"default_service_codes\",\n            display_name=\"Default Service Codes\",\n            info=\"Default service codes to check for PA requirements (comma-separated).\",\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"default_lob\",\n            display_name=\"Default Line of Business\",\n            info=\"Default Line of Business (Medicare, Medicaid, Marketplace).\",\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"default_state\",\n            display_name=\"Default State\",\n            info=\"Default two-letter state code.\",\n            tool_mode=True,\n        ),\n    ]\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the PA Lookup Tool component.\"\"\"\n        super().__init__(**kwargs)\n\n    @property\n    def pa_lookup_service(self):\n        \"\"\"Get the PA Lookup service.\"\"\"\n        return get_pa_lookup_service()\n\n    async def check_pa_requirements(\n        self, service_codes: List[str], lob: str, state: str\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Check if prior authorization is required for the specified service codes.\n\n        Args:\n            service_codes: List of service codes to check\n            lob: Line of Business (Medicare, Medicaid, Marketplace)\n            state: Two-letter state code\n\n        Returns:\n            Dictionary containing PA status for each code and other details\n        \"\"\"\n        logger.info(\n            f\"Checking PA requirements for codes: {service_codes}, LOB: {lob}, State: {state}\"\n        )\n\n        try:\n            # Normalize inputs\n            clean_codes = [code.strip() for code in service_codes]\n            clean_lob = lob.strip().title()  # Ensure proper capitalization\n            clean_state = state.strip().upper()\n\n            # Validate LOB\n            if clean_lob not in [\"Medicare\", \"Medicaid\", \"Marketplace\"]:\n                raise ValueError(\n                    f\"Invalid Line of Business: {lob}. Must be Medicare, Medicaid, or Marketplace.\"\n                )\n\n            # Validate state (simplified validation - in production, use a comprehensive list)\n            if len(clean_state) != 2 or not clean_state.isalpha():\n                raise ValueError(\n                    f\"Invalid state code: {state}. Must be a two-letter state code (e.g., MI, WA).\"\n                )\n\n            # Call the service\n            result = await self.pa_lookup_service.check_pa_status(\n                codes=clean_codes, lob=clean_lob, state=clean_state\n            )\n\n            # Process the result for better readability for the agent\n            simplified_result = self._simplify_pa_result(result)\n\n            return simplified_result\n\n        except Exception as e:\n            logger.error(f\"Error checking PA requirements: {e}\")\n            raise ToolException(f\"Error checking PA requirements: {str(e)}\")\n\n    def _simplify_pa_result(self, result: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Simplify the PA lookup result for easier consumption by the agent.\n\n        Args:\n            result: Raw PA lookup result\n\n        Returns:\n            Simplified result\n        \"\"\"\n        simplified = {\"status\": result.get(\"message\", \"Unknown\"), \"codes\": {}}\n\n        # Extract PA status for each code\n        pa_data_group = result.get(\"paStatusDataGrp\", {})\n        pa_required_data = pa_data_group.get(\"paRequiredData\", [])\n\n        for code_data in pa_required_data:\n            code = code_data.get(\"Code\", \"Unknown\")\n            pa_status = code_data.get(\"paStatus\", \"Unknown\")\n            description = code_data.get(\"codeDesc\", \"\")\n\n            # Simplify the PA status for easier interpretation\n            is_required = \"Required\" in pa_status\n            has_exclusions = \"Exclusions\" in pa_status\n\n            simplified[\"codes\"][code] = {\n                \"description\": description,\n                \"pa_required\": is_required,\n                \"has_exclusions\": has_exclusions,\n                \"full_status\": pa_status,\n            }\n\n        return simplified\n\n    def build_tool(self) -> Tool:\n        \"\"\"Build the PA Lookup tool for use by an agent.\"\"\"\n\n        # Create synchronous wrapper for async function\n        def sync_wrapper(async_func):\n            def wrapper(*args, **kwargs):\n                try:\n                    import asyncio\n                    # Create a new event loop for each call\n                    loop = asyncio.new_event_loop()\n                    asyncio.set_event_loop(loop)\n\n                    try:\n                        return loop.run_until_complete(async_func(*args, **kwargs))\n                    finally:\n                        loop.close()\n                except Exception as e:\n                    logger.error(f\"Error in {async_func.__name__}: {str(e)}\")\n                    # Return structured error response\n                    return {\n                        \"error\": str(e),\n                        \"status\": \"Error\",\n                        \"codes\": {},\n                        \"service_codes\": kwargs.get(\"service_codes\", []),\n                        \"lob\": kwargs.get(\"lob\", \"\"),\n                        \"state\": kwargs.get(\"state\", \"\"),\n                        \"system_error\": True,\n                    }\n\n            return wrapper\n\n        return StructuredTool.from_function(\n            name=\"check_prior_authorization\",\n            description=\"Check if Prior Authorization (PA) is required for specific service codes based on Line of Business (Medicare, Medicaid, Marketplace) and state.\",\n            func=sync_wrapper(self.check_pa_requirements),\n            args_schema=self.PALookupSchema,\n        )\n\n    def run_model(self) -> list[Data]:\n        \"\"\"Run the tool directly with the component's inputs, for API/direct use.\"\"\"\n        # Get values from UI inputs or use defaults\n        service_codes_str = (\n            self.default_service_codes\n            if hasattr(self, \"default_service_codes\") and self.default_service_codes\n            else \"\"\n        )\n        service_codes = (\n            [code.strip() for code in service_codes_str.split(\",\")]\n            if service_codes_str\n            else []\n        )\n\n        lob = (\n            self.default_lob\n            if hasattr(self, \"default_lob\") and self.default_lob\n            else \"Medicare\"\n        )\n        state = (\n            self.default_state\n            if hasattr(self, \"default_state\") and self.default_state\n            else \"MI\"\n        )\n\n        if not service_codes:\n            return [\n                Data(\n                    data={\"error\": \"No service codes provided\"},\n                    text=\"Error: No service codes provided\",\n                )\n            ]\n\n        # Get the tool to use its structured functionality\n        tool = self.build_tool()\n\n        try:\n            import asyncio\n\n            # Create a dedicated event loop\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n\n            try:\n                result = loop.run_until_complete(\n                    self.check_pa_requirements(\n                        service_codes=service_codes, lob=lob, state=state\n                    )\n                )\n            finally:\n                loop.close()\n\n            # Format the result as text\n            text_result = (\n                f\"PA Status Results for {len(service_codes)} service codes\\n\\n\"\n            )\n\n            for code, code_info in result.get(\"codes\", {}).items():\n                pa_required = (\n                    \"Required\" if code_info.get(\"pa_required\") else \"Not Required\"\n                )\n                text_result += f\"Code: {code} - {code_info.get('description', '')}\\n\"\n                text_result += f\"PA Status: {pa_required}\\n\"\n                if code_info.get(\"has_exclusions\"):\n                    text_result += \"Note: This code has some exclusions or conditions\\n\"\n                text_result += f\"Full Status: {code_info.get('full_status', '')}\\n\\n\"\n\n            return [Data(data=result, text=text_result)]\n\n        except Exception as e:\n            error_message = f\"Error checking PA requirements: {str(e)}\"\n            return [Data(data={\"error\": error_message}, text=error_message)]\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "default_lob": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Default Line of Business",
                "dynamic": false,
                "info": "Default Line of Business (Medicare, Medicaid, Marketplace).",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "default_lob",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "default_service_codes": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Default Service Codes",
                "dynamic": false,
                "info": "Default service codes to check for PA requirements (comma-separated).",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "default_service_codes",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "default_state": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Default State",
                "dynamic": false,
                "info": "Default two-letter state code.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "default_state",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "PALookupTool"
        },
        "dragging": false,
        "id": "PALookupTool-NaTa8",
        "measured": {
          "height": 473,
          "width": 320
        },
        "position": {
          "x": 750.1017109744134,
          "y": -615.0291635975764
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "KnowledgeHubSearch-ICnyv",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "category": "vectorstores",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "This component is used to search for information in the knowledge hub.",
            "display_name": "Knowledge Hub Search",
            "documentation": "http://docs.langflow.org/components/custom",
            "edited": false,
            "field_order": [
              "search_query",
              "selected_hubs"
            ],
            "frozen": false,
            "icon": "Autonomize",
            "key": "KnowledgeHubSearch",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "component_as_tool",
                "hidden": null,
                "display_name": "Toolset",
                "method": "to_toolkit",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "options": null,
                "tool_mode": true
              }
            ],
            "pinned": false,
            "score": 0.01857804455091699,
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from __future__ import annotations\n\nfrom typing import Any\n\nfrom langflow.custom import Component\nfrom langflow.io import MultilineInput, MultiselectInput, Output\nfrom langflow.schema import Data\nfrom langflow.services.manager import service_manager\nfrom loguru import logger\n\n\nclass KnowledgeHub(Component):\n    display_name = \"Knowledge Hub Search\"\n    description = (\n        \"This component is used to search for information in the knowledge hub.\"\n    )\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"Autonomize\"\n    name = \"KnowledgeHubSearch\"\n\n    def __init__(self, **kwargs):\n        self._hub_data: list[dict[str, str]] = []\n        super().__init__(**kwargs)\n\n    async def update_build_config(\n        self, build_config: dict, field_value: Any, field_name: str | None = None\n    ):\n        \"\"\"Update the build configuration based on field changes.\"\"\"\n        logger.info(f\"update_build_config called with field_name: {field_name}\")\n\n        if field_name == \"selected_hubs\":\n            try:\n                # Load the hub options when the field is refreshed\n                service = service_manager.get(\"knowledge_service\")\n                if not service.ready:\n                    logger.error(\"KnowledgeHub service is not ready\")\n                    return build_config\n                self._hub_data = await service.get_knowledge_hubs()\n\n                # Debug the raw response\n                logger.info(f\"Raw hub data: {self._hub_data}\")\n\n                options = [hub[\"name\"] for hub in self._hub_data]\n                logger.info(f\"Extracted hub options: {options}\")\n\n                # Debug the build_config before update\n                logger.info(\n                    f\"Build config before update: {build_config.get('selected_hubs', {})}\"\n                )\n\n                build_config[\"selected_hubs\"][\"options\"] = options\n\n                # Debug the build_config after update\n                logger.info(\n                    f\"Build config after update: {build_config.get('selected_hubs', {})}\"\n                )\n\n                return build_config\n            except Exception as e:\n                logger.exception(f\"Error in update_build_config: {e!s}\")\n                raise\n        return build_config\n\n    inputs = [\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n            tool_mode=True,\n        ),\n        MultiselectInput(\n            name=\"selected_hubs\",\n            display_name=\"Data Sources\",\n            value=[],\n            refresh_button=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Query Results\",\n            name=\"query_results\",\n            method=\"build_output\",\n        ),\n    ]\n\n    async def build_output(self) -> Data:\n        \"\"\"Generate the output based on selected knowledge hubs.\"\"\"\n        try:\n            if not self.selected_hubs:\n                logger.warning(\"No knowledge hubs selected.\")\n                return Data(value={\"query_results\": []})\n\n            # Make sure we have hub data\n            if not self._hub_data:\n                service = service_manager.get(\"knowledge_service\")\n                if not service.ready:\n                    logger.error(\"KnowledgeHub service is not ready\")\n                    return Data(value={\"query_results\": []})\n                self._hub_data = await service.get_knowledge_hubs()\n\n            # Map the selected names to their IDs\n            selected_hub_ids = [\n                hub[\"id\"] for hub in self._hub_data if hub[\"name\"] in self.selected_hubs\n            ]\n\n            service = service_manager.get(\"knowledge_service\")\n            if not service.ready:\n                logger.error(\"KnowledgeHub service is not ready\")\n                return Data(value={\"query_results\": []})\n            query_results = await service.query_vector_store(\n                knowledge_hub_ids=selected_hub_ids, query=self.search_query\n            )\n            logger.debug(f\"query_results: {query_results}\")\n            # Concatenate content from query results\n            contents = [\n                result.get(\"metadata\", {}).get(\"content\", \"\")\n                for result in query_results\n            ]\n            plain_text = \"\\n\\n=== NEW CHUNK ===\\n\\n\".join(contents)\n\n            data = Data(\n                text=plain_text,\n                data={\n                    \"result\": query_results,\n                },\n            )\n            self.status = data\n            return data\n\n        except Exception as e:\n            logger.error(f\"Error in build_output: {e!s}\")\n            return Data(value={\"query_results\": []})\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "search_query": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "search_query",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "what are the services that are covered for you ?"
              },
              "selected_hubs": {
                "_input_type": "MultiselectInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Data Sources",
                "dynamic": false,
                "info": "",
                "list": true,
                "name": "selected_hubs",
                "options": [
                  "Test",
                  "<string>",
                  "<string>",
                  "<string>",
                  "CMS - 2024",
                  "test1234",
                  "test2234",
                  "Sample EOC Guidelines",
                  "CMS Benefits Accumulator Guidelines"
                ],
                "placeholder": "",
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": [
                  "Sample EOC Guidelines"
                ]
              },
              "tools_metadata": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "is_list": true,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools_metadata",
                "value": [
                  {
                    "name": "build_output",
                    "description": "KnowledgeHubSearch. build_output - This component is used to search for information in the knowledge hub.",
                    "tags": [
                      "build_output"
                    ],
                    "status": true,
                    "display_name": "build_output",
                    "display_description": "KnowledgeHubSearch. build_output - This component is used to search for information in the knowledge hub.",
                    "readonly": false,
                    "args": {
                      "search_query": {
                        "default": "",
                        "description": "",
                        "title": "Search Query",
                        "type": "string"
                      }
                    }
                  }
                ],
                "display_name": "Actions",
                "advanced": false,
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "tools",
                "_input_type": "ToolsInput"
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "KnowledgeHubSearch"
        },
        "dragging": false,
        "id": "KnowledgeHubSearch-ICnyv",
        "measured": {
          "height": 385,
          "width": 320
        },
        "position": {
          "x": 815.219806137723,
          "y": -1514.1069040623706
        },
        "selected": true,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt-tXVY4",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": []
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "# Accumulator Check Agent Prompt\n\nYou are a Healthcare Utilization Management Specialist responsible for validating that requested services don't exceed allowed frequency or quantity limits. You'll analyze authorization requests against historical claims, determine past usage, and verify compliance with benefit limits.\n\n## INPUT:\nYou will receive a Healthcare Authorization Processing Report from the initial assessment. This report contains service codes, descriptions, member information, and claim/authorization history.\n\n## PROCESS:\n\n### 1. Parse the Authorization Report:\nExtract key data elements:\n- Member information (ID, plan, state, line of business)\n- Service code details (codes, descriptions, types, units requested)\n- Claims history (past usage of the same services)\n- Authorization history (previously approved authorizations)\n\n### 2. For Each Service Code:\n- Use knowledgehub tool to find relevant usage limits using this query format:\n  ```\n  What is the allowed usage limit for [SERVICE DESCRIPTION] (CPT/HCPCS code [CODE]) for [UNITS] units? \n  Return policy-based frequency caps or visit limits.\n  ```\n- Specify the following parameters:\n  * collection_name: \"benefits_limits_collection\"\n  * Should include any relevant filters based on member's plan\n\n### 3. Calculate Past Utilization:\n- Identify past claims that used the same service code\n- Count total units used within relevant timeframes (calendar year, rolling periods)\n- Consider authorization history to understand utilization patterns\n\n### 4. Validate Against Limits:\nFor each service code, determine if:\n- A specific usage limit exists (frequency caps, visit limits, annual maximums)\n- The requested units + previously used units would exceed this limit\n- Any timeframe restrictions apply (calendar year, rolling 12 months, lifetime)\n- Special conditions or exceptions apply based on diagnosis\n\n### 5. When No Explicit Limits Found:\n- Fall back to analyzing EOC benefit language for implied limits\n- Look for terms like \"once per year,\" \"limited to X visits,\" etc.\n\n## OUTPUT:\n\nProvide a comprehensive utilization validation report with these sections:\n\n**ACCUMULATOR VALIDATION SUMMARY:**\n- Overview of all services and validation results\n\n**SERVICE UTILIZATION DETAILS:**\nFor each service code:\n- **Service Code:** [CODE]\n- **Service Description:** [DESCRIPTION]\n- **Units Requested:** [UNITS]\n- **Previous Utilization:** [TOTAL PAST UNITS]\n- **Validation Status:** VALIDATED or NOT VALIDATED\n- **Justification:** Explain the decision based on limits and past usage\n- **Applicable Limits:** Quote the most relevant usage limit language\n\n**FINAL RECOMMENDATION:**\n- Overall recommendation based on the validation results\n- Any additional steps required\n\n## GUIDELINES:\n\n1. Consider both upper limits (maximum allowed in period) and lower limits (minimum time between services)\n2. Pay special attention to timelines - calendar year vs. rolling periods\n3. When usage limits are ambiguous, quote the exact language and explain your interpretation\n4. Note that some services have combined limits (e.g., shared visit limits across therapy types)\n5. For DME items, check if they have lifetime limits or replacement schedules\n6. Identify any diagnosis-dependent limitations (some services are limited unless specific conditions are present)\n\nYour goal is to ensure requested services comply with all frequency and quantity limits specified in the member's benefit plan, preventing overutilization while ensuring appropriate access to needed services."
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt"
        },
        "dragging": false,
        "id": "Prompt-tXVY4",
        "measured": {
          "height": 257,
          "width": 320
        },
        "position": {
          "x": 1024.0095542783142,
          "y": 58.709552432460015
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "KnowledgeHubSearch-oOLSB",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "category": "vectorstores",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "This component is used to search for information in the knowledge hub.",
            "display_name": "Knowledge Hub Search",
            "documentation": "http://docs.langflow.org/components/custom",
            "edited": false,
            "field_order": [
              "search_query",
              "selected_hubs"
            ],
            "frozen": false,
            "icon": "Autonomize",
            "key": "KnowledgeHubSearch",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "component_as_tool",
                "hidden": null,
                "display_name": "Toolset",
                "method": "to_toolkit",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "options": null,
                "tool_mode": true
              }
            ],
            "pinned": false,
            "score": 0.01857804455091699,
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from __future__ import annotations\n\nfrom typing import Any\n\nfrom langflow.custom import Component\nfrom langflow.io import MultilineInput, MultiselectInput, Output\nfrom langflow.schema import Data\nfrom langflow.services.manager import service_manager\nfrom loguru import logger\n\n\nclass KnowledgeHub(Component):\n    display_name = \"Knowledge Hub Search\"\n    description = (\n        \"This component is used to search for information in the knowledge hub.\"\n    )\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"Autonomize\"\n    name = \"KnowledgeHubSearch\"\n\n    def __init__(self, **kwargs):\n        self._hub_data: list[dict[str, str]] = []\n        super().__init__(**kwargs)\n\n    async def update_build_config(\n        self, build_config: dict, field_value: Any, field_name: str | None = None\n    ):\n        \"\"\"Update the build configuration based on field changes.\"\"\"\n        logger.info(f\"update_build_config called with field_name: {field_name}\")\n\n        if field_name == \"selected_hubs\":\n            try:\n                # Load the hub options when the field is refreshed\n                service = service_manager.get(\"knowledge_service\")\n                if not service.ready:\n                    logger.error(\"KnowledgeHub service is not ready\")\n                    return build_config\n                self._hub_data = await service.get_knowledge_hubs()\n\n                # Debug the raw response\n                logger.info(f\"Raw hub data: {self._hub_data}\")\n\n                options = [hub[\"name\"] for hub in self._hub_data]\n                logger.info(f\"Extracted hub options: {options}\")\n\n                # Debug the build_config before update\n                logger.info(\n                    f\"Build config before update: {build_config.get('selected_hubs', {})}\"\n                )\n\n                build_config[\"selected_hubs\"][\"options\"] = options\n\n                # Debug the build_config after update\n                logger.info(\n                    f\"Build config after update: {build_config.get('selected_hubs', {})}\"\n                )\n\n                return build_config\n            except Exception as e:\n                logger.exception(f\"Error in update_build_config: {e!s}\")\n                raise\n        return build_config\n\n    inputs = [\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n            tool_mode=True,\n        ),\n        MultiselectInput(\n            name=\"selected_hubs\",\n            display_name=\"Data Sources\",\n            value=[],\n            refresh_button=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Query Results\",\n            name=\"query_results\",\n            method=\"build_output\",\n        ),\n    ]\n\n    async def build_output(self) -> Data:\n        \"\"\"Generate the output based on selected knowledge hubs.\"\"\"\n        try:\n            if not self.selected_hubs:\n                logger.warning(\"No knowledge hubs selected.\")\n                return Data(value={\"query_results\": []})\n\n            # Make sure we have hub data\n            if not self._hub_data:\n                service = service_manager.get(\"knowledge_service\")\n                if not service.ready:\n                    logger.error(\"KnowledgeHub service is not ready\")\n                    return Data(value={\"query_results\": []})\n                self._hub_data = await service.get_knowledge_hubs()\n\n            # Map the selected names to their IDs\n            selected_hub_ids = [\n                hub[\"id\"] for hub in self._hub_data if hub[\"name\"] in self.selected_hubs\n            ]\n\n            service = service_manager.get(\"knowledge_service\")\n            if not service.ready:\n                logger.error(\"KnowledgeHub service is not ready\")\n                return Data(value={\"query_results\": []})\n            query_results = await service.query_vector_store(\n                knowledge_hub_ids=selected_hub_ids, query=self.search_query\n            )\n            logger.debug(f\"query_results: {query_results}\")\n            # Concatenate content from query results\n            contents = [\n                result.get(\"metadata\", {}).get(\"content\", \"\")\n                for result in query_results\n            ]\n            plain_text = \"\\n\\n=== NEW CHUNK ===\\n\\n\".join(contents)\n\n            data = Data(\n                text=plain_text,\n                data={\n                    \"result\": query_results,\n                },\n            )\n            self.status = data\n            return data\n\n        except Exception as e:\n            logger.error(f\"Error in build_output: {e!s}\")\n            return Data(value={\"query_results\": []})\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "search_query": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "search_query",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "what are the services that are covered for you ?"
              },
              "selected_hubs": {
                "_input_type": "MultiselectInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Data Sources",
                "dynamic": false,
                "info": "",
                "list": true,
                "name": "selected_hubs",
                "options": [
                  "Test",
                  "<string>",
                  "<string>",
                  "<string>",
                  "CMS - 2024",
                  "test1234",
                  "test2234",
                  "Sample EOC Guidelines",
                  "CMS Benefits Accumulator Guidelines"
                ],
                "placeholder": "",
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": [
                  "CMS Benefits Accumulator Guidelines"
                ]
              },
              "tools_metadata": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "is_list": true,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools_metadata",
                "value": [
                  {
                    "name": "build_output",
                    "description": "KnowledgeHubSearch. build_output - This component is used to search for information in the knowledge hub.",
                    "tags": [
                      "build_output"
                    ],
                    "status": true,
                    "display_name": "build_output",
                    "display_description": "KnowledgeHubSearch. build_output - This component is used to search for information in the knowledge hub.",
                    "readonly": false,
                    "args": {
                      "search_query": {
                        "default": "",
                        "description": "",
                        "title": "Search Query",
                        "type": "string"
                      }
                    }
                  }
                ],
                "display_name": "Actions",
                "advanced": false,
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "tools",
                "_input_type": "ToolsInput"
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "KnowledgeHubSearch"
        },
        "dragging": false,
        "id": "KnowledgeHubSearch-oOLSB",
        "measured": {
          "height": 385,
          "width": 320
        },
        "position": {
          "x": 858.0019088439532,
          "y": 415.6556869246377
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-Jfah7",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n\n                # Replace pipe characters to avoid markdown table issues\n                processed_data = data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n\n                processed_data = processed_data.map(\n                    lambda x: str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x\n                )\n\n                return processed_data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "clean_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "clean_data",
                "value": true,
                "display_name": "Basic Clean Data",
                "advanced": true,
                "dynamic": false,
                "info": "Whether to clean the data",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-Jfah7",
        "measured": {
          "height": 65,
          "width": 192
        },
        "position": {
          "x": 2909.6327349706667,
          "y": -410.8223292222654
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Agent-TjsA4",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "display_name": "EOC Check Agent",
            "documentation": "",
            "edited": false,
            "field_order": [
              "agent_llm",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "system_prompt",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "return_intermediate_steps",
              "agent_description",
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template",
              "add_current_date_tool"
            ],
            "frozen": false,
            "icon": "bot",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "component_as_tool",
                "hidden": null,
                "display_name": "Toolset",
                "method": "to_toolkit",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "options": null,
                "tool_mode": true
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "add_current_date_tool": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Current Date",
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "input_types": [],
                "list": false,
                "name": "add_current_date_tool",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "agent_llm": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Model Provider",
                "dynamic": false,
                "info": "The provider of the language model that the agent will use to generate responses.",
                "input_types": [],
                "name": "agent_llm",
                "options": [
                  "Amazon Bedrock",
                  "Anthropic",
                  "Azure OpenAI",
                  "Google Generative AI",
                  "Groq",
                  "NVIDIA",
                  "OpenAI",
                  "SambaNova",
                  "Custom"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Azure OpenAI"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_core.tools import StructuredTool\n\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.base.agents.events import ExceptionWithMessageError\nfrom langflow.base.models.model_input_constants import (\n    ALL_PROVIDER_FIELDS,\n    MODEL_DYNAMIC_UPDATE_FIELDS,\n    MODEL_PROVIDERS_DICT,\n    MODELS_METADATA,\n)\nfrom langflow.base.models.model_utils import get_model_name\nfrom langflow.components.helpers import CurrentDateComponent\nfrom langflow.components.helpers.memory import MemoryComponent\nfrom langflow.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom langflow.custom.utils import update_component_build_config\nfrom langflow.io import BoolInput, DropdownInput, MultilineInput, Output\nfrom langflow.logging import logger\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            input_types=[],\n            options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())] + [{\"icon\": \"brain\"}],\n        ),\n        *MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"],\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        *LCToolsAgentComponent._base_inputs,\n        *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [Output(name=\"response\", display_name=\"Response\", method=\"message_response\")]\n\n    async def message_response(self) -> Message:\n        try:\n            # Get LLM model and validate\n            llm_model, display_name = self.get_llm()\n            if llm_model is None:\n                msg = \"No language model selected. Please choose a model to proceed.\"\n                raise ValueError(msg)\n            self.model_name = get_model_name(llm_model, display_name=display_name)\n\n            # Get memory data\n            self.chat_history = await self.get_memory_data()\n\n            # Add current date tool if enabled\n            if self.add_current_date_tool:\n                if not isinstance(self.tools, list):  # type: ignore[has-type]\n                    self.tools = []\n                current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n                if not isinstance(current_date_tool, StructuredTool):\n                    msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                    raise TypeError(msg)\n                self.tools.append(current_date_tool)\n\n            # Validate tools\n            if not self.tools:\n                msg = \"Tools are required to run the agent. Please add at least one tool.\"\n                raise ValueError(msg)\n\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools,\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            return await self.run_agent(agent)\n\n        except (ValueError, TypeError, KeyError) as e:\n            logger.error(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            logger.error(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Unexpected error: {e!s}\")\n            raise\n\n    async def get_memory_data(self):\n        memory_kwargs = {\n            component_input.name: getattr(self, f\"{component_input.name}\") for component_input in self.memory_inputs\n        }\n        # filter out empty values\n        memory_kwargs = {k: v for k, v in memory_kwargs.items() if v is not None}\n\n        return await MemoryComponent(**self.get_base_args()).set(**memory_kwargs).retrieve_messages()\n\n    def get_llm(self):\n        if not isinstance(self.agent_llm, str):\n            return self.agent_llm, None\n\n        try:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if not provider_info:\n                msg = f\"Invalid model provider: {self.agent_llm}\"\n                raise ValueError(msg)\n\n            component_class = provider_info.get(\"component_class\")\n            display_name = component_class.display_name\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\", \"\")\n\n            return self._build_llm_model(component_class, inputs, prefix), display_name\n\n        except Exception as e:\n            logger.error(f\"Error building {self.agent_llm} language model: {e!s}\")\n            msg = f\"Failed to initialize language model: {e!s}\"\n            raise ValueError(msg) from e\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n        return component.set(**model_kwargs).build_model()\n\n    def set_component_params(self, component):\n        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n        if provider_info:\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\")\n            model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n\n            return component.set(**model_kwargs)\n        return component\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self, build_config: dotdict, field_value: str, field_name: str | None = None\n    ) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name in (\"agent_llm\",):\n            build_config[\"agent_llm\"][\"value\"] = field_value\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n            elif field_value == \"Custom\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n                    value=\"Custom\",\n                    real_time_refresh=True,\n                    input_types=[\"LanguageModel\"],\n                    options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())]\n                    + [{\"icon\": \"brain\"}],\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if (\n            isinstance(self.agent_llm, str)\n            and self.agent_llm in MODEL_PROVIDERS_DICT\n            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS\n        ):\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                component_class = self.set_component_params(component_class)\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": []
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "input_types": [],
                "list": false,
                "name": "handle_parsing_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "input_types": [],
                "list": false,
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 15
              },
              "memory": {
                "_input_type": "HandleInput",
                "advanced": true,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "Memory"
                ],
                "list": false,
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "input_types": [],
                "list": false,
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "order": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Order",
                "dynamic": false,
                "info": "Order of the messages.",
                "input_types": [],
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Filter by sender type.",
                "input_types": [],
                "name": "sender",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine and User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Filter by sender name.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Agent Instructions",
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are a helpful assistant that can use tools to answer questions and perform tasks."
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{sender_name}: {text}"
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "tools_metadata": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "is_list": true,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools_metadata",
                "value": [
                  {
                    "name": "Agent",
                    "description": "A helpful assistant with access to the following tools:",
                    "tags": [
                      "Agent"
                    ],
                    "status": true,
                    "display_name": "message_response",
                    "display_description": "Agent. message_response - Define the agent's instructions, then enter a task to complete using tools.",
                    "readonly": false,
                    "args": {
                      "input_value": {
                        "default": "",
                        "description": "The input provided by the user for the agent to process.",
                        "title": "Input Value",
                        "type": "string"
                      },
                      "order": {
                        "default": "Ascending",
                        "description": "Order of the messages.",
                        "enum": [
                          "Ascending",
                          "Descending"
                        ],
                        "title": "Order",
                        "type": "string"
                      }
                    }
                  }
                ],
                "display_name": "Actions",
                "advanced": false,
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "tools",
                "_input_type": "ToolsInput"
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "azure_endpoint": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": true,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "azure_endpoint",
                "value": "AZURE_OPENAI_ENDPOINT",
                "display_name": "Azure Endpoint",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "azure_deployment": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": true,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "azure_deployment",
                "value": "AZURE_OPENAI_DEPLOYMENT",
                "display_name": "Deployment Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "API Key",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "api_version": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "2025-02-01-preview",
                  "2025-01-01-preview",
                  "2024-12-01-preview",
                  "2024-10-01-preview",
                  "2024-09-01-preview",
                  "2024-08-01-preview",
                  "2024-07-01-preview",
                  "2024-06-01",
                  "2024-03-01-preview",
                  "2024-02-15-preview",
                  "2023-12-01-preview",
                  "2023-05-15"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "toggle": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_version",
                "value": "2024-06-01",
                "display_name": "API Version",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "input_types": []
              },
              "temperature": {
                "tool_mode": false,
                "min_label": "",
                "max_label": "",
                "min_label_icon": "",
                "max_label_icon": "",
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 2,
                  "step": 0.01
                },
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.7,
                "display_name": "Temperature",
                "advanced": true,
                "dynamic": false,
                "info": "Controls randomness. Lower values are more deterministic, higher values are more creative.",
                "title_case": false,
                "type": "slider",
                "_input_type": "SliderInput",
                "input_types": []
              },
              "max_tokens": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput",
                "input_types": []
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "Agent"
        },
        "dragging": false,
        "id": "Agent-TjsA4",
        "measured": {
          "height": 866,
          "width": 320
        },
        "position": {
          "x": 1726.7564029836815,
          "y": -1234.313227967561
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Agent-gq2Yh",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "display_name": "Accumulator Check Agent",
            "documentation": "",
            "edited": false,
            "field_order": [
              "agent_llm",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "system_prompt",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "return_intermediate_steps",
              "agent_description",
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template",
              "add_current_date_tool"
            ],
            "frozen": false,
            "icon": "bot",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "component_as_tool",
                "hidden": null,
                "display_name": "Toolset",
                "method": "to_toolkit",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "options": null,
                "tool_mode": true
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "add_current_date_tool": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Current Date",
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "input_types": [],
                "list": false,
                "name": "add_current_date_tool",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "agent_llm": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Model Provider",
                "dynamic": false,
                "info": "The provider of the language model that the agent will use to generate responses.",
                "input_types": [],
                "name": "agent_llm",
                "options": [
                  "Amazon Bedrock",
                  "Anthropic",
                  "Azure OpenAI",
                  "Google Generative AI",
                  "Groq",
                  "NVIDIA",
                  "OpenAI",
                  "SambaNova",
                  "Custom"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Azure OpenAI"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_core.tools import StructuredTool\n\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.base.agents.events import ExceptionWithMessageError\nfrom langflow.base.models.model_input_constants import (\n    ALL_PROVIDER_FIELDS,\n    MODEL_DYNAMIC_UPDATE_FIELDS,\n    MODEL_PROVIDERS_DICT,\n    MODELS_METADATA,\n)\nfrom langflow.base.models.model_utils import get_model_name\nfrom langflow.components.helpers import CurrentDateComponent\nfrom langflow.components.helpers.memory import MemoryComponent\nfrom langflow.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom langflow.custom.utils import update_component_build_config\nfrom langflow.io import BoolInput, DropdownInput, MultilineInput, Output\nfrom langflow.logging import logger\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            input_types=[],\n            options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())] + [{\"icon\": \"brain\"}],\n        ),\n        *MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"],\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        *LCToolsAgentComponent._base_inputs,\n        *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [Output(name=\"response\", display_name=\"Response\", method=\"message_response\")]\n\n    async def message_response(self) -> Message:\n        try:\n            # Get LLM model and validate\n            llm_model, display_name = self.get_llm()\n            if llm_model is None:\n                msg = \"No language model selected. Please choose a model to proceed.\"\n                raise ValueError(msg)\n            self.model_name = get_model_name(llm_model, display_name=display_name)\n\n            # Get memory data\n            self.chat_history = await self.get_memory_data()\n\n            # Add current date tool if enabled\n            if self.add_current_date_tool:\n                if not isinstance(self.tools, list):  # type: ignore[has-type]\n                    self.tools = []\n                current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n                if not isinstance(current_date_tool, StructuredTool):\n                    msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                    raise TypeError(msg)\n                self.tools.append(current_date_tool)\n\n            # Validate tools\n            if not self.tools:\n                msg = \"Tools are required to run the agent. Please add at least one tool.\"\n                raise ValueError(msg)\n\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools,\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            return await self.run_agent(agent)\n\n        except (ValueError, TypeError, KeyError) as e:\n            logger.error(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            logger.error(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Unexpected error: {e!s}\")\n            raise\n\n    async def get_memory_data(self):\n        memory_kwargs = {\n            component_input.name: getattr(self, f\"{component_input.name}\") for component_input in self.memory_inputs\n        }\n        # filter out empty values\n        memory_kwargs = {k: v for k, v in memory_kwargs.items() if v is not None}\n\n        return await MemoryComponent(**self.get_base_args()).set(**memory_kwargs).retrieve_messages()\n\n    def get_llm(self):\n        if not isinstance(self.agent_llm, str):\n            return self.agent_llm, None\n\n        try:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if not provider_info:\n                msg = f\"Invalid model provider: {self.agent_llm}\"\n                raise ValueError(msg)\n\n            component_class = provider_info.get(\"component_class\")\n            display_name = component_class.display_name\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\", \"\")\n\n            return self._build_llm_model(component_class, inputs, prefix), display_name\n\n        except Exception as e:\n            logger.error(f\"Error building {self.agent_llm} language model: {e!s}\")\n            msg = f\"Failed to initialize language model: {e!s}\"\n            raise ValueError(msg) from e\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n        return component.set(**model_kwargs).build_model()\n\n    def set_component_params(self, component):\n        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n        if provider_info:\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\")\n            model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n\n            return component.set(**model_kwargs)\n        return component\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self, build_config: dotdict, field_value: str, field_name: str | None = None\n    ) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name in (\"agent_llm\",):\n            build_config[\"agent_llm\"][\"value\"] = field_value\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n            elif field_value == \"Custom\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n                    value=\"Custom\",\n                    real_time_refresh=True,\n                    input_types=[\"LanguageModel\"],\n                    options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())]\n                    + [{\"icon\": \"brain\"}],\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if (\n            isinstance(self.agent_llm, str)\n            and self.agent_llm in MODEL_PROVIDERS_DICT\n            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS\n        ):\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                component_class = self.set_component_params(component_class)\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": []
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "input_types": [],
                "list": false,
                "name": "handle_parsing_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "input_types": [],
                "list": false,
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 15
              },
              "memory": {
                "_input_type": "HandleInput",
                "advanced": true,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "Memory"
                ],
                "list": false,
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "input_types": [],
                "list": false,
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "order": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Order",
                "dynamic": false,
                "info": "Order of the messages.",
                "input_types": [],
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Filter by sender type.",
                "input_types": [],
                "name": "sender",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine and User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Filter by sender name.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Agent Instructions",
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are a helpful assistant that can use tools to answer questions and perform tasks."
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{sender_name}: {text}"
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "tools_metadata": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "is_list": true,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools_metadata",
                "value": [
                  {
                    "name": "Agent",
                    "description": "A helpful assistant with access to the following tools:",
                    "tags": [
                      "Agent"
                    ],
                    "status": true,
                    "display_name": "message_response",
                    "display_description": "Agent. message_response - Define the agent's instructions, then enter a task to complete using tools.",
                    "readonly": false,
                    "args": {
                      "input_value": {
                        "default": "",
                        "description": "The input provided by the user for the agent to process.",
                        "title": "Input Value",
                        "type": "string"
                      },
                      "order": {
                        "default": "Ascending",
                        "description": "Order of the messages.",
                        "enum": [
                          "Ascending",
                          "Descending"
                        ],
                        "title": "Order",
                        "type": "string"
                      }
                    }
                  }
                ],
                "display_name": "Actions",
                "advanced": false,
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "tools",
                "_input_type": "ToolsInput"
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "azure_endpoint": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": true,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "azure_endpoint",
                "value": "AZURE_OPENAI_ENDPOINT",
                "display_name": "Azure Endpoint",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "azure_deployment": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": true,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "azure_deployment",
                "value": "AZURE_OPENAI_DEPLOYMENT",
                "display_name": "Deployment Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "API Key",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "api_version": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "2025-02-01-preview",
                  "2025-01-01-preview",
                  "2024-12-01-preview",
                  "2024-10-01-preview",
                  "2024-09-01-preview",
                  "2024-08-01-preview",
                  "2024-07-01-preview",
                  "2024-06-01",
                  "2024-03-01-preview",
                  "2024-02-15-preview",
                  "2023-12-01-preview",
                  "2023-05-15"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "toggle": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_version",
                "value": "2024-06-01",
                "display_name": "API Version",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "input_types": []
              },
              "temperature": {
                "tool_mode": false,
                "min_label": "",
                "max_label": "",
                "min_label_icon": "",
                "max_label_icon": "",
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 2,
                  "step": 0.01
                },
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.7,
                "display_name": "Temperature",
                "advanced": true,
                "dynamic": false,
                "info": "Controls randomness. Lower values are more deterministic, higher values are more creative.",
                "title_case": false,
                "type": "slider",
                "_input_type": "SliderInput",
                "input_types": []
              },
              "max_tokens": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput",
                "input_types": []
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "Agent"
        },
        "dragging": false,
        "id": "Agent-gq2Yh",
        "measured": {
          "height": 866,
          "width": 320
        },
        "position": {
          "x": 1667.2259750812361,
          "y": 5.609687389722936
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "PromptTemplate-JrAir",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Select or edit prompt templates.",
            "display_name": "Prompt Template",
            "documentation": "",
            "edited": false,
            "field_order": [
              "saved_prompt",
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "icon": "Autonomize",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import re\nfrom textwrap import dedent\nfrom typing import Any\nfrom loguru import logger\nfrom app.services.deps import get_prompt_service\nfrom langflow.custom import Component\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\nclass PromptTemplateComponent(Component):\n    display_name = \"Prompt Template\"\n    description = \"Select or edit prompt templates.\"\n    icon = \"Autonomize\"\n    name = \"PromptTemplate\"\n\n    inputs = [\n        DropdownInput(\n            name=\"saved_prompt\",\n            display_name=\"Choose from Templates\",\n            info=\"Select a Template\",\n            refresh_button=True,\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. Use {key} or {{ key }} for keys in the data.\",\n            value=\"{text}\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    def __init__(self, **data):\n        super().__init__(**data)\n        self.prompt_service = get_prompt_service()\n        self._attributes[\"template\"] = dedent(\n            \"\"\"\n            Given the following context, answer the question.\n            Context: {context}\n\n            Question: {question}\n            Answer:\"\"\"\n        )\n\n    @staticmethod\n    def _extract_template_content(selected_prompt: dict) -> str:\n        # Handles both SDK and plain string formats\n        template = selected_prompt.get(\"template\", \"\")\n        if isinstance(template, str):\n            return template\n        if isinstance(template, list) and template and isinstance(template[0], dict):\n            # SDK format: [{\"role\": ..., \"content\": {\"type\": ..., \"text\": ...}}]\n            content = template[0].get(\"content\", {})\n            if isinstance(content, dict):\n                return content.get(\"text\", \"\")\n        return \"\"\n\n    @staticmethod\n    def _extract_variables(template: str) -> list[str]:\n        # Support both {var} and {{ var }}\n        vars1 = re.findall(r\"\\{\\{\\s*(\\w+)\\s*\\}\\}\", template)\n        vars2 = re.findall(r\"\\{(\\w+)\\}\", template)\n        return list(set(vars1 + vars2))\n\n    async def build_prompt(self) -> Message:\n        template = self._attributes.get(\"template\", \"\")\n        variables = self._extract_variables(template)\n        for var in variables:\n            value = (\n                self._attributes.get(var)\n                or self._attributes.get(var.lower())\n                or self._attributes.get(var.title())\n                or \"\"\n            )\n            # Replace both {var} and {{ var }}\n            template = re.sub(rf\"\\{{\\{{\\s*{var}\\s*\\}}\\}}\", value, template)\n            template = re.sub(rf\"\\{{{var}\\}}\", value, template)\n        return Message(text=template)\n\n    async def update_build_config(\n        self, build_config, field_value, field_name=None\n    ) -> dict:\n        if field_name == \"saved_prompt\":\n            try:\n                criteria = {\"max_results\": 100}\n                prompts = await self.prompt_service.get_prompts(criteria)\n                prompt_list = prompts.get(\"prompts\", [])\n                template_names = [\n                    p.get(\"name\", \"Unnamed Template\")\n                    for p in prompt_list\n                    if isinstance(p, dict)\n                ]\n                build_config[\"saved_prompt\"][\"options\"] = template_names\n\n                if field_value:\n                    selected_prompt = next(\n                        (p for p in prompt_list if p.get(\"name\") == field_value), None\n                    )\n                    if selected_prompt:\n                        template_content = self._extract_template_content(selected_prompt)\n                        self._attributes[\"template\"] = template_content\n                        if hasattr(self, \"template\"):\n                            self.template = template_content\n                        build_config[\"template\"][\"value\"] = template_content\n                        # Extract parameters from template and create dynamic inputs\n                        parameters = self._extract_variables(template_content)\n                        # Remove existing dynamic input fields\n                        fields_to_remove = []\n                        for key in build_config:\n                            if (\n                                isinstance(build_config[key], dict)\n                                and build_config[key].get(\"is_custom_field\") == True\n                                and build_config[key].get(\"dynamic\", False)\n                            ):\n                                fields_to_remove.append(key)\n                        for key in fields_to_remove:\n                            build_config.pop(key)\n                        # Add new input fields for parameters\n                        for param in parameters:\n                            param_name = param.strip()\n                            display_name = param_name.replace(\"_\", \" \").title()\n                            build_config[param_name] = {\n                                \"is_custom_field\": True,\n                                \"name\": param_name,\n                                \"display_name\": display_name,\n                                \"value\": \"\",\n                                \"info\": f\"Enter {display_name}\",\n                                \"required\": True,\n                                \"show\": True,\n                                \"multiline\": True,\n                                \"dynamic\": True,\n                                \"placeholder\": f\"Enter {display_name.lower()}\",\n                                \"advanced\": False,\n                                \"field_type\": \"str\",\n                                \"fileTypes\": [],\n                                \"file_path\": \"\",\n                                \"input_types\": [\"Message\", \"Text\"],\n                                \"list\": False,\n                                \"load_from_db\": False,\n                                \"title_case\": False,\n                                \"type\": \"str\",\n                            }\n                        logger.info(f\"Added dynamic fields: {parameters}\")\n            except Exception as e:\n                logger.error(f\"Error fetching prompts: {e}\")\n                build_config[\"saved_prompt\"][\"options\"] = []\n        return build_config\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "saved_prompt": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Choose from Templates",
                "dynamic": false,
                "info": "Select a Template",
                "name": "saved_prompt",
                "options": [],
                "placeholder": "",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "EOC Validation Agent"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. Use {key} or {{ key }} for keys in the data.",
                "list": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "You are a Healthcare Benefits Validation Specialist responsible for determining service coverage based on Evidence of Coverage (EOC) documents. You'll analyze authorization processing reports and validate whether requested services are covered under the member's plan by searching EOC documents.\n\n## INPUT:\nYou will receive a Healthcare Authorization Processing Report from the first-level assessment. This report contains service codes, descriptions, member information, and preliminary coverage determinations.\n\n## PROCESS:\n\n### 1. Parse the Authorization Report:\nExtract key data elements:\n- Member information (ID, plan, state, line of business)\n- Service code details (codes, descriptions, types)\n- Initial coverage determinations\n- Any diagnostic information\n\n### 2. Vector Search Process:\nFor EACH service code in the report:\n- Construct a search query in this format:\n  ```\n  Service code: [CODE]\n  Service name: [NAME]\n  Service type: [TYPE]\n  Find related covered benefits for this service.\n  ```\n- Execute the knowledgehub tool using this query\n- Specify the following parameters:\n  * collection_name: \"eoc_medical_benefits\"\n  * document_filter: use member's state and LOB\n\n### 3. Coverage Validation Analysis:\nFor each service and its search results:\n- Carefully examine each benefit description returned\n- Determine if the service is explicitly or implicitly covered\n- Consider diagnosis requirements, limitations, and conditions\n- Evaluate authorization requirements\n- Pay special attention to DME codes and home health services which often have specific coverage conditions\n\n### 4. When Validating Coverage:\n- A service is VALIDATED when:\n  * The benefit clearly covers the requested service\n  * All conditions and requirements are met\n- A service is NOT VALIDATED when:\n  * No matching benefit is found\n  * The benefit explicitly excludes the service\n  * Required conditions are not met\n  * Required diagnosis information is missing\n\n## OUTPUT:\nProvide a comprehensive validation report with these sections:\n\n**VALIDATION SUMMARY:**\n- Brief overview of all services and validation results\n\n**SERVICE VALIDATION DETAILS:**\nFor each service code:\n- **Service Code:** [CODE]\n- **Service Description:** [DESCRIPTION]\n- **Validation Status:** VALIDATED or NOT VALIDATED\n- **Justification:** Detailed explanation referencing specific benefit language\n- **Relevant EOC Sections:** Quote the most relevant parts of the benefits found\n\n**COVERAGE BENEFITS:**\n- List of all benefits found relevant to the services\n- Include page numbers and document references\n\n**FINAL RECOMMENDATION:**\n- Overall recommendation based on the validation results\n- Any additional steps required (e.g., medical necessity documentation)\n\n## GUIDELINES:\n1. Be thorough in your search - try multiple query variations if initial results are insufficient\n2. Always ground your validation in the actual benefit language, not assumptions\n3. When benefit language is ambiguous, note this in your explanation\n4. If vector search returns insufficient results, note this as a limitation\n5. Always include direct quotes from benefits to support your validation decisions\n6. Remember that coverage often depends on medical necessity, which may require additional assessment\n\nYour goal is to produce accurate coverage validations that clearly explain whether each service is covered under the member's specific plan, based on the actual language in their Evidence of Coverage documents."
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "PromptTemplate"
        },
        "dragging": false,
        "id": "PromptTemplate-JrAir",
        "measured": {
          "height": 327,
          "width": 320
        },
        "position": {
          "x": 1312.3247213160364,
          "y": -1674.4482926466233
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "PromptTemplate-pLVYM",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Select or edit prompt templates.",
            "display_name": "Prompt Template",
            "documentation": "",
            "edited": false,
            "field_order": [
              "saved_prompt",
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "icon": "Autonomize",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "options": null,
                "tool_mode": true
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import re\nfrom textwrap import dedent\nfrom typing import Any\nfrom loguru import logger\nfrom app.services.deps import get_prompt_service\nfrom langflow.custom import Component\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\nclass PromptTemplateComponent(Component):\n    display_name = \"Prompt Template\"\n    description = \"Select or edit prompt templates.\"\n    icon = \"Autonomize\"\n    name = \"PromptTemplate\"\n\n    inputs = [\n        DropdownInput(\n            name=\"saved_prompt\",\n            display_name=\"Choose from Templates\",\n            info=\"Select a Template\",\n            refresh_button=True,\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. Use {key} or {{ key }} for keys in the data.\",\n            value=\"{text}\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    def __init__(self, **data):\n        super().__init__(**data)\n        self.prompt_service = get_prompt_service()\n        self._attributes[\"template\"] = dedent(\n            \"\"\"\n            Given the following context, answer the question.\n            Context: {context}\n\n            Question: {question}\n            Answer:\"\"\"\n        )\n\n    @staticmethod\n    def _extract_template_content(selected_prompt: dict) -> str:\n        # Handles both SDK and plain string formats\n        template = selected_prompt.get(\"template\", \"\")\n        if isinstance(template, str):\n            return template\n        if isinstance(template, list) and template and isinstance(template[0], dict):\n            # SDK format: [{\"role\": ..., \"content\": {\"type\": ..., \"text\": ...}}]\n            content = template[0].get(\"content\", {})\n            if isinstance(content, dict):\n                return content.get(\"text\", \"\")\n        return \"\"\n\n    @staticmethod\n    def _extract_variables(template: str) -> list[str]:\n        # Support both {var} and {{ var }}\n        vars1 = re.findall(r\"\\{\\{\\s*(\\w+)\\s*\\}\\}\", template)\n        vars2 = re.findall(r\"\\{(\\w+)\\}\", template)\n        return list(set(vars1 + vars2))\n\n    async def build_prompt(self) -> Message:\n        template = self._attributes.get(\"template\", \"\")\n        variables = self._extract_variables(template)\n        for var in variables:\n            value = (\n                self._attributes.get(var)\n                or self._attributes.get(var.lower())\n                or self._attributes.get(var.title())\n                or \"\"\n            )\n            # Replace both {var} and {{ var }}\n            template = re.sub(rf\"\\{{\\{{\\s*{var}\\s*\\}}\\}}\", value, template)\n            template = re.sub(rf\"\\{{{var}\\}}\", value, template)\n        return Message(text=template)\n\n    async def update_build_config(\n        self, build_config, field_value, field_name=None\n    ) -> dict:\n        if field_name == \"saved_prompt\":\n            try:\n                criteria = {\"max_results\": 100}\n                prompts = await self.prompt_service.get_prompts(criteria)\n                prompt_list = prompts.get(\"prompts\", [])\n                template_names = [\n                    p.get(\"name\", \"Unnamed Template\")\n                    for p in prompt_list\n                    if isinstance(p, dict)\n                ]\n                build_config[\"saved_prompt\"][\"options\"] = template_names\n\n                if field_value:\n                    selected_prompt = next(\n                        (p for p in prompt_list if p.get(\"name\") == field_value), None\n                    )\n                    if selected_prompt:\n                        template_content = self._extract_template_content(selected_prompt)\n                        self._attributes[\"template\"] = template_content\n                        if hasattr(self, \"template\"):\n                            self.template = template_content\n                        build_config[\"template\"][\"value\"] = template_content\n                        # Extract parameters from template and create dynamic inputs\n                        parameters = self._extract_variables(template_content)\n                        # Remove existing dynamic input fields\n                        fields_to_remove = []\n                        for key in build_config:\n                            if (\n                                isinstance(build_config[key], dict)\n                                and build_config[key].get(\"is_custom_field\") == True\n                                and build_config[key].get(\"dynamic\", False)\n                            ):\n                                fields_to_remove.append(key)\n                        for key in fields_to_remove:\n                            build_config.pop(key)\n                        # Add new input fields for parameters\n                        for param in parameters:\n                            param_name = param.strip()\n                            display_name = param_name.replace(\"_\", \" \").title()\n                            build_config[param_name] = {\n                                \"is_custom_field\": True,\n                                \"name\": param_name,\n                                \"display_name\": display_name,\n                                \"value\": \"\",\n                                \"info\": f\"Enter {display_name}\",\n                                \"required\": True,\n                                \"show\": True,\n                                \"multiline\": True,\n                                \"dynamic\": True,\n                                \"placeholder\": f\"Enter {display_name.lower()}\",\n                                \"advanced\": False,\n                                \"field_type\": \"str\",\n                                \"fileTypes\": [],\n                                \"file_path\": \"\",\n                                \"input_types\": [\"Message\", \"Text\"],\n                                \"list\": False,\n                                \"load_from_db\": False,\n                                \"title_case\": False,\n                                \"type\": \"str\",\n                            }\n                        logger.info(f\"Added dynamic fields: {parameters}\")\n            except Exception as e:\n                logger.error(f\"Error fetching prompts: {e}\")\n                build_config[\"saved_prompt\"][\"options\"] = []\n        return build_config\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "saved_prompt": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Choose from Templates",
                "dynamic": false,
                "info": "Select a Template",
                "name": "saved_prompt",
                "options": [
                  "Pharmacy_Detailed_Summary_Prompt",
                  "technical-documentation",
                  "question-answer",
                  "key-points-extractor",
                  "ie-criteria-system-prompt",
                  "task-focused",
                  "educational-support",
                  "translation",
                  "factual-answering",
                  "Pharmacy_PA_QA_Contextualization_Prompt",
                  "task-instructions",
                  "comprehensive-analyzer",
                  "classification",
                  "default-assistant",
                  "clinical-summary",
                  "summarize",
                  "context-qa",
                  "simplification",
                  "compare-and-contrast",
                  "qna",
                  "concise-summarizer"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Benefits Check Agent"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. Use {key} or {{ key }} for keys in the data.",
                "list": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "You are a Healthcare Authorization Processing Assistant specialized in evaluating service code eligibility, coverage, and authorization requirements. Your goal is to analyze authorization requests and provide a complete evaluation report following LOB-specific validation workflows.\n\n## INSTRUCTIONS:\nWhen given a healthcare authorization request, you will:\n\n### 1. PARSE INPUT:\nExtract key information from the JSON input including member information, service codes, state, LOB (line of business), and diagnoses.\n- When state is empty, use \"WA\" (Washington) derived from the health plan code (e.g., \"WA-MHI\")\n- When LOB is empty, use \"Medicaid\" for Molina Healthcare plans\n- Extract service codes from the services array\n\n### 2. DETERMINE WORKFLOW:\nBased on the LOB, follow these specific validation workflows:\n\n**For Medicare:**\n- For EACH service code separately, use the encoder pro get_service_code_info tool\n- Use check_prior_authorization\n- Use eoc_check_tool to check coverage in EOC documents\n- Use accumulator_tool with complete member information: service code, member ID, LOB, state, and case details\n\n**For Medicaid:**\n- For EACH service code separately, use the encoder pro get_service_code_info tool\n- Use check_prior_authorization\n- (Skip EOC validation and accumulator checks for Medicaid)\n\n**For Marketplace:**\n- For EACH service code separately, use the encoder pro get_service_code_info tool\n- Use check_prior_authorization\n- Use eoc_check_tool to check coverage in EOC documents\n- (Skip accumulator checks for Marketplace)\n\n### 3. ACCUMULATOR TOOL USAGE:\nWhen calling the accumulator_tool for Medicare cases, pass a comprehensive input that includes:\n- Service code (if specified)\n- Member ID (if specified)\n- Line of business (if specified)\n- State (if specified)\n- Case ID (if specified)\n- Units requested (if specified)\n- Start/end dates (if specified)\n- Associated diagnoses (if specified)\n\n**Format the accumulator_tool input as:**\n```\nService Code: [CODE]\nMember ID: [MEMBER_ID]\nCase ID: [CASE_ID]\nLine of Business: [LOB]\nState: [STATE]\nUnits Requested: [UNITS]\nStart Date: [START_DATE]\nEnd Date: [END_DATE]\nDiagnoses: [DIAGNOSIS_CODES_AND_DESCRIPTIONS]\n```\n\n### 4. CREATE A CONSOLIDATED REPORT with the following sections:\n- **AUTHORIZATION SUMMARY:** General overview of the request\n- **MEMBER DETAILS:** Information about the member\n- **SERVICE CODE ANALYSIS:** Detailed information for each service code\n- **COVERAGE DETERMINATION:** Whether services are covered\n- **DIAGNOSES:** List any diagnoses associated with the current authorization request\n- **PA REQUIREMENTS:** Whether prior authorization is required\n- **EOC VALIDATION:** Include results from EOC validation (Medicare and Marketplace only)\n- **ACCUMULATOR CHECK:** Include results from accumulator check (Medicare only)\n- **RECOMMENDATION:** Suggested decision based on all findings\n\n## ERROR HANDLING:\n- If a tool returns an error, clearly indicate this in the appropriate section with \"Not available due to system error\" and CONTINUE with other sections\n- For DME codes like E1161 (wheelchairs), if errors occur, note that these typically:\n  * Require prior authorization for Medicaid\n  * Are covered when medically necessary with proper documentation\n- AFTER all tools have been called, generate the FINAL report using whatever information is available\n- Do NOT wait for \"pending\" information - all tool results (successful or error) are considered COMPLETE and FINAL\n\nIMPORTANT: When ANY tool returns an error or fails to complete, immediately treat that as a complete response containing \"System Error\". DO NOT retry tools that fail. Complete all tool calls sequentially regardless of errors and then generate the final report.\n\n## OUTPUT FORMAT:\n- Use bullet points for clarity\n- Bold important section headers\n- Include all sections even if information is limited\n- No need to repeat the full report twice\n- Mark incomplete information clearly as \"Not available\" rather than \"Pending\"\n- For sections that don't apply to the current LOB, include the section but note \"Not applicable for [LOB] line of business\"\n\nREMEMBER: Your primary responsibility is to provide a COMPLETE analysis that will help determine whether the authorization request should be approved, denied, or requires further review, EVEN WHEN TOOL RESPONSES CONTAIN ERRORS."
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "PromptTemplate"
        },
        "dragging": false,
        "id": "PromptTemplate-pLVYM",
        "measured": {
          "height": 322,
          "width": 320
        },
        "position": {
          "x": 1237.6224995426203,
          "y": -944.2569858050422
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatInput-oPALw",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n            temp_file=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        background_color = self.background_color\n        text_color = self.text_color\n        icon = self.chat_icon\n\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\n                \"background_color\": background_color,\n                \"text_color\": text_color,\n                \"icon\": icon,\n            },\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "files": {
                "_input_type": "FileInput",
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatInput"
        },
        "dragging": false,
        "id": "ChatInput-oPALw",
        "measured": {
          "height": 65,
          "width": 192
        },
        "position": {
          "x": 664.6211554924087,
          "y": -36.541312418164296
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "EncoderProTool",
            "id": "EncoderProTool-Z95W8",
            "name": "api_build_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-BJ0z7",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-EncoderProTool-Z95W8{dataType:EncoderProTool,id:EncoderProTool-Z95W8,name:api_build_tool,output_types:[Tool]}-Agent-BJ0z7{fieldName:tools,id:Agent-BJ0z7,inputTypes:[Tool],type:other}",
        "selected": false,
        "source": "EncoderProTool-Z95W8",
        "sourceHandle": "{dataType:EncoderProTool,id:EncoderProTool-Z95W8,name:api_build_tool,output_types:[Tool]}",
        "target": "Agent-BJ0z7",
        "targetHandle": "{fieldName:tools,id:Agent-BJ0z7,inputTypes:[Tool],type:other}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "PALookupTool",
            "id": "PALookupTool-NaTa8",
            "name": "api_build_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-BJ0z7",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-PALookupTool-NaTa8{dataType:PALookupTool,id:PALookupTool-NaTa8,name:api_build_tool,output_types:[Tool]}-Agent-BJ0z7{fieldName:tools,id:Agent-BJ0z7,inputTypes:[Tool],type:other}",
        "selected": false,
        "source": "PALookupTool-NaTa8",
        "sourceHandle": "{dataType:PALookupTool,id:PALookupTool-NaTa8,name:api_build_tool,output_types:[Tool]}",
        "target": "Agent-BJ0z7",
        "targetHandle": "{fieldName:tools,id:Agent-BJ0z7,inputTypes:[Tool],type:other}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-BJ0z7",
            "name": "response",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-Jfah7",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Agent-BJ0z7{dataType:Agent,id:Agent-BJ0z7,name:response,output_types:[Message]}-ChatOutput-Jfah7{fieldName:input_value,id:ChatOutput-Jfah7,inputTypes:[Data,DataFrame,Message],type:str}",
        "selected": false,
        "source": "Agent-BJ0z7",
        "sourceHandle": "{dataType:Agent,id:Agent-BJ0z7,name:response,output_types:[Message]}",
        "target": "ChatOutput-Jfah7",
        "targetHandle": "{fieldName:input_value,id:ChatOutput-Jfah7,inputTypes:[Data,DataFrame,Message],type:str}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "KnowledgeHubSearch",
            "id": "KnowledgeHubSearch-ICnyv",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-TjsA4",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-KnowledgeHubSearch-ICnyv{dataType:KnowledgeHubSearch,id:KnowledgeHubSearch-ICnyv,name:component_as_tool,output_types:[Tool]}-Agent-TjsA4{fieldName:tools,id:Agent-TjsA4,inputTypes:[Tool],type:other}",
        "selected": false,
        "source": "KnowledgeHubSearch-ICnyv",
        "sourceHandle": "{dataType:KnowledgeHubSearch,id:KnowledgeHubSearch-ICnyv,name:component_as_tool,output_types:[Tool]}",
        "target": "Agent-TjsA4",
        "targetHandle": "{fieldName:tools,id:Agent-TjsA4,inputTypes:[Tool],type:other}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-TjsA4",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-BJ0z7",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-Agent-TjsA4{dataType:Agent,id:Agent-TjsA4,name:component_as_tool,output_types:[Tool]}-Agent-BJ0z7{fieldName:tools,id:Agent-BJ0z7,inputTypes:[Tool],type:other}",
        "selected": false,
        "source": "Agent-TjsA4",
        "sourceHandle": "{dataType:Agent,id:Agent-TjsA4,name:component_as_tool,output_types:[Tool]}",
        "target": "Agent-BJ0z7",
        "targetHandle": "{fieldName:tools,id:Agent-BJ0z7,inputTypes:[Tool],type:other}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-tXVY4",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_prompt",
            "id": "Agent-gq2Yh",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt-tXVY4{dataType:Prompt,id:Prompt-tXVY4,name:prompt,output_types:[Message]}-Agent-gq2Yh{fieldName:system_prompt,id:Agent-gq2Yh,inputTypes:[Message],type:str}",
        "selected": false,
        "source": "Prompt-tXVY4",
        "sourceHandle": "{dataType:Prompt,id:Prompt-tXVY4,name:prompt,output_types:[Message]}",
        "target": "Agent-gq2Yh",
        "targetHandle": "{fieldName:system_prompt,id:Agent-gq2Yh,inputTypes:[Message],type:str}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "KnowledgeHubSearch",
            "id": "KnowledgeHubSearch-oOLSB",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-gq2Yh",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-KnowledgeHubSearch-oOLSB{dataType:KnowledgeHubSearch,id:KnowledgeHubSearch-oOLSB,name:component_as_tool,output_types:[Tool]}-Agent-gq2Yh{fieldName:tools,id:Agent-gq2Yh,inputTypes:[Tool],type:other}",
        "selected": false,
        "source": "KnowledgeHubSearch-oOLSB",
        "sourceHandle": "{dataType:KnowledgeHubSearch,id:KnowledgeHubSearch-oOLSB,name:component_as_tool,output_types:[Tool]}",
        "target": "Agent-gq2Yh",
        "targetHandle": "{fieldName:tools,id:Agent-gq2Yh,inputTypes:[Tool],type:other}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-gq2Yh",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-BJ0z7",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-Agent-gq2Yh{dataType:Agent,id:Agent-gq2Yh,name:component_as_tool,output_types:[Tool]}-Agent-BJ0z7{fieldName:tools,id:Agent-BJ0z7,inputTypes:[Tool],type:other}",
        "selected": false,
        "source": "Agent-gq2Yh",
        "sourceHandle": "{dataType:Agent,id:Agent-gq2Yh,name:component_as_tool,output_types:[Tool]}",
        "target": "Agent-BJ0z7",
        "targetHandle": "{fieldName:tools,id:Agent-BJ0z7,inputTypes:[Tool],type:other}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "QNextAuthHistoryTool",
            "id": "QNextAuthHistoryTool-s2kGz",
            "name": "api_build_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-gq2Yh",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-QNextAuthHistoryTool-s2kGz{dataType:QNextAuthHistoryTool,id:QNextAuthHistoryTool-s2kGz,name:api_build_tool,output_types:[Tool]}-Agent-gq2Yh{fieldName:tools,id:Agent-gq2Yh,inputTypes:[Tool],type:other}",
        "source": "QNextAuthHistoryTool-s2kGz",
        "sourceHandle": "{dataType:QNextAuthHistoryTool,id:QNextAuthHistoryTool-s2kGz,name:api_build_tool,output_types:[Tool]}",
        "target": "Agent-gq2Yh",
        "targetHandle": "{fieldName:tools,id:Agent-gq2Yh,inputTypes:[Tool],type:other}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "PromptTemplate",
            "id": "PromptTemplate-JrAir",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_prompt",
            "id": "Agent-TjsA4",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-PromptTemplate-JrAir{dataType:PromptTemplate,id:PromptTemplate-JrAir,name:prompt,output_types:[Message]}-Agent-TjsA4{fieldName:system_prompt,id:Agent-TjsA4,inputTypes:[Message],type:str}",
        "source": "PromptTemplate-JrAir",
        "sourceHandle": "{dataType:PromptTemplate,id:PromptTemplate-JrAir,name:prompt,output_types:[Message]}",
        "target": "Agent-TjsA4",
        "targetHandle": "{fieldName:system_prompt,id:Agent-TjsA4,inputTypes:[Message],type:str}",
        "selected": false
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "PromptTemplate",
            "id": "PromptTemplate-pLVYM",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_prompt",
            "id": "Agent-BJ0z7",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-PromptTemplate-pLVYM{dataType:PromptTemplate,id:PromptTemplate-pLVYM,name:prompt,output_types:[Message]}-Agent-BJ0z7{fieldName:system_prompt,id:Agent-BJ0z7,inputTypes:[Message],type:str}",
        "source": "PromptTemplate-pLVYM",
        "sourceHandle": "{dataType:PromptTemplate,id:PromptTemplate-pLVYM,name:prompt,output_types:[Message]}",
        "target": "Agent-BJ0z7",
        "targetHandle": "{fieldName:system_prompt,id:Agent-BJ0z7,inputTypes:[Message],type:str}"
      },
      {
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-oPALw",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "Agent-BJ0z7",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ChatInput-oPALw{dataType:ChatInput,id:ChatInput-oPALw,name:message,output_types:[Message]}-Agent-BJ0z7{fieldName:input_value,id:Agent-BJ0z7,inputTypes:[Message],type:str}",
        "source": "ChatInput-oPALw",
        "sourceHandle": "{dataType:ChatInput,id:ChatInput-oPALw,name:message,output_types:[Message]}",
        "target": "Agent-BJ0z7",
        "targetHandle": "{fieldName:input_value,id:Agent-BJ0z7,inputTypes:[Message],type:str}",
        "className": ""
      }
    ],
    "viewport": {
      "x": -385.94116677073157,
      "y": 1020.9867682754516,
      "zoom": 0.589443120134206
    }
  },
  "description": "Eligibility Verification Agent V2",
  "name": "Eligibility Verification Agent",
  "last_tested_version": "1.4.3",
  "endpoint_name": null,
  "is_component": false,
  "tags": [
    "prior-auth"
  ]
}
