{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "File",
            "id": "File-L0owu",
            "name": "data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-xyxuW",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__File-L0owu{œdataTypeœ:œFileœ,œidœ:œFile-L0owuœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-ParseData-xyxuW{œfieldNameœ:œdataœ,œidœ:œParseData-xyxuWœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "source": "File-L0owu",
        "sourceHandle": "{œdataTypeœ: œFileœ, œidœ: œFile-L0owuœ, œnameœ: œdataœ, œoutput_typesœ: [œDataœ]}",
        "target": "ParseData-xyxuW",
        "targetHandle": "{œfieldNameœ: œdataœ, œidœ: œParseData-xyxuWœ, œinputTypesœ: [œDataœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-xyxuW",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "text",
            "id": "PromptTemplate-XdH8i",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParseData-xyxuW{œdataTypeœ:œParseDataœ,œidœ:œParseData-xyxuWœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-PromptTemplate-XdH8i{œfieldNameœ:œtextœ,œidœ:œPromptTemplate-XdH8iœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "source": "ParseData-xyxuW",
        "sourceHandle": "{œdataTypeœ: œParseDataœ, œidœ: œParseData-xyxuWœ, œnameœ: œtextœ, œoutput_typesœ: [œMessageœ]}",
        "target": "PromptTemplate-XdH8i",
        "targetHandle": "{œfieldNameœ: œtextœ, œidœ: œPromptTemplate-XdH8iœ, œinputTypesœ: [œMessageœ, œTextœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "PromptTemplate",
            "id": "PromptTemplate-XdH8i",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "AzureOpenAIModel-o9cbt",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__PromptTemplate-XdH8i{œdataTypeœ:œPromptTemplateœ,œidœ:œPromptTemplate-XdH8iœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-AzureOpenAIModel-o9cbt{œfieldNameœ:œinput_valueœ,œidœ:œAzureOpenAIModel-o9cbtœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "PromptTemplate-XdH8i",
        "sourceHandle": "{œdataTypeœ: œPromptTemplateœ, œidœ: œPromptTemplate-XdH8iœ, œnameœ: œpromptœ, œoutput_typesœ: [œMessageœ]}",
        "target": "AzureOpenAIModel-o9cbt",
        "targetHandle": "{œfieldNameœ: œinput_valueœ, œidœ: œAzureOpenAIModel-o9cbtœ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "AzureOpenAIModel",
            "id": "AzureOpenAIModel-o9cbt",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "TextInput-pbgqK",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__AzureOpenAIModel-o9cbt{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-o9cbtœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-TextInput-pbgqK{œfieldNameœ:œinput_valueœ,œidœ:œTextInput-pbgqKœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "AzureOpenAIModel-o9cbt",
        "sourceHandle": "{œdataTypeœ: œAzureOpenAIModelœ, œidœ: œAzureOpenAIModel-o9cbtœ, œnameœ: œtext_outputœ, œoutput_typesœ: [œMessageœ]}",
        "target": "TextInput-pbgqK",
        "targetHandle": "{œfieldNameœ: œinput_valueœ, œidœ: œTextInput-pbgqKœ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "File-L0owu",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Load a file to be used in your project.",
            "display_name": "File",
            "documentation": "",
            "edited": false,
            "field_order": [
              "path",
              "file_path",
              "silent_errors",
              "delete_server_file_after_processing",
              "ignore_unsupported_extensions",
              "ignore_unspecified_files",
              "use_multithreading",
              "concurrency_multithreading"
            ],
            "frozen": false,
            "icon": "file-text",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Data",
                "method": "load_files",
                "name": "data",
                "required_inputs": [],
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.data import BaseFileComponent\nfrom langflow.base.data.utils import (\n    TEXT_FILE_TYPES,\n    parallel_load_data,\n    parse_text_file_to_data,\n)\nfrom langflow.io import BoolInput, IntInput\nfrom langflow.schema import Data\n\n\nclass FileComponent(BaseFileComponent):\n    \"\"\"Handles loading and processing of individual or zipped text files.\n\n    This component supports processing multiple valid files within a zip archive,\n    resolving paths, validating file types, and optionally using multithreading for processing.\n    \"\"\"\n\n    display_name = \"File\"\n    description = \"Load a file to be used in your project.\"\n    icon = \"file-text\"\n    name = \"File\"\n\n    VALID_EXTENSIONS = TEXT_FILE_TYPES\n\n    inputs = [\n        *BaseFileComponent._base_inputs,\n        BoolInput(\n            name=\"use_multithreading\",\n            display_name=\"[Deprecated] Use Multithreading\",\n            advanced=True,\n            value=True,\n            info=\"Set 'Processing Concurrency' greater than 1 to enable multithreading.\",\n        ),\n        IntInput(\n            name=\"concurrency_multithreading\",\n            display_name=\"Processing Concurrency\",\n            advanced=False,\n            info=\"When multiple files are being processed, the number of files to process concurrently.\",\n            value=1,\n        ),\n    ]\n\n    outputs = [\n        *BaseFileComponent._base_outputs,\n    ]\n\n    def process_files(\n        self, file_list: list[BaseFileComponent.BaseFile]\n    ) -> list[BaseFileComponent.BaseFile]:\n        \"\"\"Processes files either sequentially or in parallel, depending on concurrency settings.\n\n        Args:\n            file_list (list[BaseFileComponent.BaseFile]): List of files to process.\n\n        Returns:\n            list[BaseFileComponent.BaseFile]: Updated list of files with merged data.\n        \"\"\"\n\n        def process_file(file_path: str, *, silent_errors: bool = False) -> Data | None:\n            \"\"\"Processes a single file and returns its Data object.\"\"\"\n            try:\n                return parse_text_file_to_data(file_path, silent_errors=silent_errors)\n            except FileNotFoundError as e:\n                msg = f\"File not found: {file_path}. Error: {e}\"\n                self.log(msg)\n                if not silent_errors:\n                    raise\n                return None\n            except Exception as e:\n                msg = f\"Unexpected error processing {file_path}: {e}\"\n                self.log(msg)\n                if not silent_errors:\n                    raise\n                return None\n\n        if not file_list:\n            msg = \"No files to process.\"\n            raise ValueError(msg)\n\n        concurrency = (\n            1\n            if not self.use_multithreading\n            else max(1, self.concurrency_multithreading)\n        )\n        file_count = len(file_list)\n\n        parallel_processing_threshold = 2\n        if (\n            concurrency < parallel_processing_threshold\n            or file_count < parallel_processing_threshold\n        ):\n            if file_count > 1:\n                self.log(f\"Processing {file_count} files sequentially.\")\n            processed_data = [\n                process_file(str(file.path), silent_errors=self.silent_errors)\n                for file in file_list\n            ]\n        else:\n            self.log(\n                f\"Starting parallel processing of {file_count} files with concurrency: {concurrency}.\"\n            )\n            file_paths = [str(file.path) for file in file_list]\n            processed_data = parallel_load_data(\n                file_paths,\n                silent_errors=self.silent_errors,\n                load_function=process_file,\n                max_concurrency=concurrency,\n            )\n\n        # Use rollup_basefile_data to merge processed data with BaseFile objects\n        return self.rollup_data(file_list, processed_data)\n"
              },
              "concurrency_multithreading": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Processing Concurrency",
                "dynamic": false,
                "info": "When multiple files are being processed, the number of files to process concurrently.",
                "list": false,
                "name": "concurrency_multithreading",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 4
              },
              "delete_server_file_after_processing": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Delete Server File After Processing",
                "dynamic": false,
                "info": "If true, the Server File Path will be deleted after processing.",
                "list": false,
                "name": "delete_server_file_after_processing",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "file_path": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "URL",
                "dynamic": false,
                "info": "Upload file via URL or local server path. Supports: \n1. Direct HTTP/HTTPS URLs for remote files\n2. Local server file paths\n3. Data objects with file path property\n4. Message objects containing file paths\n\nSupports the same file types as the Path input. Takes precedence over Path input when both are provided.",
                "input_types": [
                  "Data",
                  "Message"
                ],
                "list": true,
                "name": "file_path",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "ignore_unspecified_files": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Ignore Unspecified Files",
                "dynamic": false,
                "info": "If true, Data with no 'file_path' property will be ignored.",
                "list": false,
                "name": "ignore_unspecified_files",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "ignore_unsupported_extensions": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Ignore Unsupported Extensions",
                "dynamic": false,
                "info": "If true, files with unsupported extensions will not be processed.",
                "list": false,
                "name": "ignore_unsupported_extensions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "path": {
                "_input_type": "FileInput",
                "advanced": false,
                "display_name": "Path",
                "dynamic": false,
                "fileTypes": [
                  "pdf",
                  "zip",
                  "tar",
                  "tgz",
                  "bz2",
                  "gz"
                ],
                "file_path": "e141a31b-a4ae-43de-ab23-1b9ee643705c/2025-01-17_14-31-24_0108_Subject199.pdf",
                "info": "Supported file extensions: pdf; optionally bundled in file extensions: zip, tar, tgz, bz2, gz",
                "list": false,
                "name": "path",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "silent_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Silent Errors",
                "dynamic": false,
                "info": "If true, errors will not raise an exception.",
                "list": false,
                "name": "silent_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "use_multithreading": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "[Deprecated] Use Multithreading",
                "dynamic": false,
                "info": "Set 'Processing Concurrency' greater than 1 to enable multithreading.",
                "list": false,
                "name": "use_multithreading",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "File"
        },
        "dragging": false,
        "id": "File-L0owu",
        "measured": {
          "height": 367,
          "width": 320
        },
        "position": {
          "x": 158,
          "y": 140
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseData-xyxuW",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data into plain text following a specified template.",
            "display_name": "Parse Data",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "ParseData",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Text",
                "method": "parse_data",
                "name": "text",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "name": "data_list",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Text\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "name": "data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseData"
        },
        "dragging": false,
        "id": "ParseData-xyxuW",
        "measured": {
          "height": 350,
          "width": 320
        },
        "position": {
          "x": 568,
          "y": 66
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "PromptTemplate-XdH8i",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "prompts",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Create, save, or select prompt templates with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "",
            "edited": false,
            "field_order": [
              "saved_prompt",
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "icon": "Autonomize",
            "key": "PromptTemplate",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "name": "prompt",
                "required_inputs": [],
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 7.568328950209746e-6,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import traceback\nfrom textwrap import dedent\nfrom typing import Any\n\nfrom loguru import logger\n\nfrom genesis_studio.components.prompts import PromptComponent\nfrom langflow.io import DropdownInput\nfrom langflow.schema.message import Message\nfrom genesis_studio.services.deps import get_prompt_service\n\n\nclass PromptTemplateComponent(PromptComponent):\n    \"\"\"A component that extends PromptComponent to add template library functionality.\"\"\"\n\n    display_name: str = \"Prompt Template\"\n    description: str = (\n        \"Create, save, or select prompt templates with dynamic variables.\"\n    )\n    icon = \"Autonomize\"\n    name = \"PromptTemplate\"\n\n    inputs = [\n        DropdownInput(\n            name=\"saved_prompt\",\n            display_name=\"Choose from Templates\",\n            info=\"Select a Template\",\n            value=\"Question Answer\",\n            refresh_button=True,\n            real_time_refresh=True,\n        ),\n        *PromptComponent.inputs,\n    ]\n\n    def __init__(self, **data):\n        super().__init__(**data)\n        self._attributes[\"template\"] = dedent(\n            \"\"\"\n            Given the following context, answer the question.\n            Context: {context}\n\n            Question: {question}\n            Answer:\"\"\"\n        )\n\n    async def build_prompt(self) -> Message:\n        try:\n            return await super().build_prompt()\n        except Exception as e:\n            logger.error(f\"Error in build_prompt: {e!s}\")\n            raise\n\n    async def update_build_config(\n        self, build_config: dict, field_value: Any, field_name: str | None = None\n    ):\n        if field_name == \"saved_prompt\":\n            try:\n                prompt_client = get_prompt_service()\n                try:\n                    # Get only system prompts\n                    prompts = await prompt_client.get_prompts(prompt_type=\"USER\")\n                    logger.debug(f\"prompts: {prompts}\")\n\n                    # Create options array with template names\n                    template_names = [\n                        prompt.get(\"name\", \"Unnamed Template\")\n                        for prompt in prompts\n                        if isinstance(prompt, dict)\n                    ]\n\n                    # Update build_config with template names\n                    if \"saved_prompt\" not in build_config:\n                        build_config[\"saved_prompt\"] = {}\n                    build_config[\"saved_prompt\"][\"options\"] = template_names\n\n                    if field_value:\n                        # Find the selected template using the name\n                        selected_prompt = next(\n                            (p for p in prompts if p.get(\"name\") == field_value), None\n                        )\n\n                        if selected_prompt:\n                            template_content = selected_prompt.get(\"template\", \"\")\n\n                            # Update the template in all possible locations\n                            self._attributes[\"template\"] = template_content\n                            if hasattr(self, \"template\"):\n                                self.template = template_content\n\n                            # Update the template in build_config\n                            if \"template\" not in build_config:\n                                build_config[\"template\"] = {}\n\n                            build_config[\"template\"][\"value\"] = template_content\n\n                            # Also set it in custom_fields if it exists\n                            if \"custom_fields\" in build_config:\n                                build_config[\"custom_fields\"][\n                                    \"template\"\n                                ] = template_content\n\n                            # Extract parameters from template and create dynamic inputs\n                            import re\n\n                            parameters = re.findall(r\"\\{([^}]+)\\}\", template_content)\n                            logger.info(f\"Extracted parameters: {parameters}\")\n\n                            # Remove existing dynamic input fields\n                            fields_to_remove = []\n                            for key in build_config:\n                                if (\n                                    isinstance(build_config[key], dict)\n                                    and build_config[key].get(\"is_custom_field\") == True\n                                    and build_config[key].get(\"dynamic\", False)\n                                ):\n                                    fields_to_remove.append(key)\n\n                            for key in fields_to_remove:\n                                build_config.pop(key)\n\n                            # Add new input fields for parameters\n                            for param in parameters:\n                                param_name = param.strip()\n                                display_name = param_name.replace(\"_\", \" \").title()\n\n                                build_config[param_name] = {\n                                    \"is_custom_field\": True,\n                                    \"name\": param_name,\n                                    \"display_name\": display_name,\n                                    \"value\": \"\",\n                                    \"info\": f\"Enter {display_name}\",\n                                    \"required\": True,\n                                    \"show\": True,\n                                    \"multiline\": True,\n                                    \"dynamic\": True,\n                                    \"placeholder\": f\"Enter {display_name.lower()}\",\n                                    \"advanced\": False,\n                                    \"field_type\": \"str\",\n                                    \"fileTypes\": [],\n                                    \"file_path\": \"\",\n                                    \"input_types\": [\"Message\", \"Text\"],\n                                    \"list\": False,\n                                    \"load_from_db\": False,\n                                    \"title_case\": False,\n                                    \"type\": \"str\",\n                                }\n\n                            logger.info(\n                                f\"Added dynamic fields: {[p for p in parameters]}\"\n                            )\n\n                except Exception as e:\n                    logger.error(f\"Error in template update: {e!s}\")\n                    logger.error(f\"Traceback: {traceback.format_exc()}\")\n                    build_config[\"saved_prompt\"][\"options\"] = []\n\n            except Exception as e:\n                logger.error(f\"Error in update_build_config: {e!s}\")\n                logger.error(f\"Traceback: {traceback.format_exc()}\")\n                build_config[\"saved_prompt\"][\"options\"] = []\n\n        return build_config\n"
              },
              "saved_prompt": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Choose from Templates",
                "dynamic": false,
                "info": "Select a Template",
                "name": "saved_prompt",
                "options": [],
                "placeholder": "",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Question Answer"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": ""
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "PromptTemplate"
        },
        "dragging": false,
        "id": "PromptTemplate-XdH8i",
        "measured": {
          "height": 433,
          "width": 320
        },
        "position": {
          "x": 942,
          "y": 97
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "AzureOpenAIModel-o9cbt",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "models",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate text using Azure OpenAI LLMs.",
            "display_name": "Azure OpenAI",
            "documentation": "https://python.langchain.com/docs/integrations/llms/azure_openai",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "azure_endpoint",
              "azure_deployment",
              "api_key",
              "api_version",
              "temperature",
              "max_tokens"
            ],
            "frozen": false,
            "icon": "Azure",
            "key": "AzureOpenAIModel",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Text",
                "method": "text_response",
                "name": "text_output",
                "required_inputs": [],
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Language Model",
                "method": "build_model",
                "name": "model_output",
                "required_inputs": [],
                "selected": "LanguageModel",
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.003924824467069744,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": true,
                "display_name": "API Key",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "api_version": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "API Version",
                "dynamic": false,
                "info": "",
                "name": "api_version",
                "options": [
                  "2024-10-01-preview",
                  "2024-09-01-preview",
                  "2024-08-01-preview",
                  "2024-07-01-preview",
                  "2024-06-01",
                  "2024-03-01-preview",
                  "2024-02-15-preview",
                  "2023-12-01-preview",
                  "2023-05-15"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "2024-06-01"
              },
              "azure_deployment": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Deployment Name",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "azure_deployment",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "azure_endpoint": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Azure Endpoint",
                "dynamic": false,
                "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "azure_endpoint",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs import MessageTextInput\nfrom langflow.io import DropdownInput, FloatInput, IntInput, SecretStrInput\nfrom genesis_studio.services.azure_openai import AzureOpenAISetting\nfrom genesis_studio.services.deps import get_azure_open_ai_service\n\nazure_openai_setting = AzureOpenAISetting()\n\n\nclass AzureChatOpenAIComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI\"\n    description: str = \"Generate text using Azure OpenAI LLMs.\"\n    documentation: str = (\n        \"https://python.langchain.com/docs/integrations/llms/azure_openai\"\n    )\n    beta = False\n    icon = \"Azure\"\n    name = \"AzureOpenAIModel\"\n\n    AZURE_OPENAI_API_VERSIONS = [\n        \"2024-06-01\",\n        \"2024-07-01-preview\",\n        \"2024-08-01-preview\",\n        \"2024-09-01-preview\",\n        \"2024-10-01-preview\",\n        \"2023-05-15\",\n        \"2023-12-01-preview\",\n        \"2024-02-15-preview\",\n        \"2024-03-01-preview\",\n    ]\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        MessageTextInput(\n            name=\"azure_endpoint\",\n            display_name=\"Azure Endpoint\",\n            info=\"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`\",\n            required=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"azure_deployment\",\n            display_name=\"Deployment Name\",\n            required=False,\n            advanced=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\", display_name=\"API Key\", advanced=True, required=False\n        ),\n        DropdownInput(\n            name=\"api_version\",\n            display_name=\"API Version\",\n            options=sorted(AZURE_OPENAI_API_VERSIONS, reverse=True),\n            value=next(\n                (\n                    version\n                    for version in sorted(AZURE_OPENAI_API_VERSIONS, reverse=True)\n                    if not version.endswith(\"-preview\")\n                ),\n                AZURE_OPENAI_API_VERSIONS[0],\n            ),\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.7),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:\n        try:\n            service = get_azure_open_ai_service()\n            return service.AzureOpenAI(\n                azure_endpoint=self.azure_endpoint,\n                azure_deployment=self.azure_deployment,\n                api_key=self.api_key,\n                api_version=self.api_version,\n                temperature=self.temperature,\n                max_tokens=self.max_tokens,\n                stream=self.stream,\n            )\n        except Exception as e:\n            error_msg = str(e)\n            raise ValueError(f\"Error connecting to Azure OpenAI: {error_msg}\") from e\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "name": "max_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model. You can modify the template or write your own.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "system_prompt_template": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "System Prompt Template",
                "dynamic": false,
                "info": "Select a system prompt template",
                "name": "system_prompt_template",
                "options": [],
                "placeholder": "",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "FloatInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "temperature",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": 0.7
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "AzureOpenAIModel"
        },
        "dragging": false,
        "id": "AzureOpenAIModel-o9cbt",
        "measured": {
          "height": 847,
          "width": 320
        },
        "position": {
          "x": 1372.8144040082068,
          "y": 133.45567879753798
        },
        "selected": true,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-pbgqK",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get text inputs from the Playground.",
            "display_name": "Text Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Text",
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-pbgqK",
        "measured": {
          "height": 234,
          "width": 320
        },
        "position": {
          "x": 1839.2451607604673,
          "y": 362.94078132004586
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": 118.49979164880244,
      "y": 127.66777946228228,
      "zoom": 0.4783040790459355
    }
  },
  "description": "Simple Summarisation",
  "endpoint_name": null,
  "id": "e141a31b-a4ae-43de-ab23-1b9ee643705c",
  "is_component": false,
  "last_tested_version": "1.1.1",
  "name": "Summarisation",
  "tags": [
    "summarization"
  ]
}
