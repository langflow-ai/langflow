{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-u3h2k",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "search_query",
            "id": "ClinicalLLM-Q2Siz",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParseData-u3h2k{œdataTypeœ:œParseDataœ,œidœ:œParseData-u3h2kœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-ClinicalLLM-Q2Siz{œfieldNameœ:œsearch_queryœ,œidœ:œClinicalLLM-Q2Sizœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-u3h2k",
        "sourceHandle": "{œdataTypeœ: œParseDataœ, œidœ: œParseData-u3h2kœ, œnameœ: œtextœ, œoutput_typesœ: [œMessageœ]}",
        "target": "ClinicalLLM-Q2Siz",
        "targetHandle": "{œfieldNameœ: œsearch_queryœ, œidœ: œClinicalLLM-Q2Sizœ, œinputTypesœ: [œMessageœ], œtypeœ: œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ClinicalLLM",
            "id": "ClinicalLLM-Q2Siz",
            "name": "prediction",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-gZwky",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-ClinicalLLM-Q2Siz{œdataTypeœ:œClinicalLLMœ,œidœ:œClinicalLLM-Q2Sizœ,œnameœ:œpredictionœ,œoutput_typesœ:[œDataœ]}-ParseData-gZwky{œfieldNameœ:œdataœ,œidœ:œParseData-gZwkyœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ClinicalLLM-Q2Siz",
        "sourceHandle": "{œdataTypeœ: œClinicalLLMœ, œidœ: œClinicalLLM-Q2Sizœ, œnameœ: œpredictionœ, œoutput_typesœ: [œDataœ]}",
        "target": "ParseData-gZwky",
        "targetHandle": "{œfieldNameœ: œdataœ, œidœ: œParseData-gZwkyœ, œinputTypesœ: [œDataœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "File Path",
            "id": "File Path-8jQBJ",
            "name": "file_path",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "file_path",
            "id": "azure_ocr-KoHV8",
            "inputTypes": [
              "Data",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-File Path-8jQBJ{œdataTypeœ:œFile Pathœ,œidœ:œFile Path-8jQBJœ,œnameœ:œfile_pathœ,œoutput_typesœ:[œDataœ]}-azure_ocr-KoHV8{œfieldNameœ:œfile_pathœ,œidœ:œazure_ocr-KoHV8œ,œinputTypesœ:[œDataœ,œMessageœ],œtypeœ:œotherœ}",
        "source": "File Path-8jQBJ",
        "sourceHandle": "{œdataTypeœ: œFile Pathœ, œidœ: œFile Path-8jQBJœ, œnameœ: œfile_pathœ, œoutput_typesœ: [œDataœ]}",
        "target": "azure_ocr-KoHV8",
        "targetHandle": "{œfieldNameœ: œfile_pathœ, œidœ: œazure_ocr-KoHV8œ, œinputTypesœ: [œDataœ, œMessageœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "azure_ocr",
            "id": "azure_ocr-KoHV8",
            "name": "structured_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-u3h2k",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-azure_ocr-KoHV8{œdataTypeœ:œazure_ocrœ,œidœ:œazure_ocr-KoHV8œ,œnameœ:œstructured_dataœ,œoutput_typesœ:[œDataœ]}-ParseData-u3h2k{œfieldNameœ:œdataœ,œidœ:œParseData-u3h2kœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "source": "azure_ocr-KoHV8",
        "sourceHandle": "{œdataTypeœ: œazure_ocrœ, œidœ: œazure_ocr-KoHV8œ, œnameœ: œstructured_dataœ, œoutput_typesœ: [œDataœ]}",
        "target": "ParseData-u3h2k",
        "targetHandle": "{œfieldNameœ: œdataœ, œidœ: œParseData-u3h2kœ, œinputTypesœ: [œDataœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-gZwky",
            "name": "data_list",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "RelationExtraction-TvyqO",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ParseData-gZwky{œdataTypeœ:œParseDataœ,œidœ:œParseData-gZwkyœ,œnameœ:œdata_listœ,œoutput_typesœ:[œDataœ]}-RelationExtraction-TvyqO{œfieldNameœ:œdataœ,œidœ:œRelationExtraction-TvyqOœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "source": "ParseData-gZwky",
        "sourceHandle": "{œdataTypeœ: œParseDataœ, œidœ: œParseData-gZwkyœ, œnameœ: œdata_listœ, œoutput_typesœ: [œDataœ]}",
        "target": "RelationExtraction-TvyqO",
        "targetHandle": "{œfieldNameœ: œdataœ, œidœ: œRelationExtraction-TvyqOœ, œinputTypesœ: [œDataœ], œtypeœ: œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "RelationExtraction",
            "id": "RelationExtraction-TvyqO",
            "name": "data_list",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "JSONOutput-Ru3z5",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__RelationExtraction-TvyqO{œdataTypeœ:œRelationExtractionœ,œidœ:œRelationExtraction-TvyqOœ,œnameœ:œdata_listœ,œoutput_typesœ:[œDataœ]}-JSONOutput-Ru3z5{œfieldNameœ:œdataœ,œidœ:œJSONOutput-Ru3z5œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "source": "RelationExtraction-TvyqO",
        "sourceHandle": "{œdataTypeœ: œRelationExtractionœ, œidœ: œRelationExtraction-TvyqOœ, œnameœ: œdata_listœ, œoutput_typesœ: [œDataœ]}",
        "target": "JSONOutput-Ru3z5",
        "targetHandle": "{œfieldNameœ: œdataœ, œidœ: œJSONOutput-Ru3z5œ, œinputTypesœ: [œDataœ], œtypeœ: œotherœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "ParseData-u3h2k",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data into plain text following a specified template.",
            "display_name": "Parse Data",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Text",
                "method": "parse_data",
                "name": "text",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "name": "data_list",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Text\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "name": "data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseData"
        },
        "id": "ParseData-u3h2k",
        "measured": {
          "height": 350,
          "width": 320
        },
        "position": {
          "x": 955.7887892952915,
          "y": -156.21377260789296
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ClinicalLLM-Q2Siz",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extract clinical entities from text using Clinical LLM.",
            "display_name": "Clinical LLM",
            "documentation": "https://docs.example.com/clinical-llm",
            "edited": false,
            "field_order": [
              "search_query"
            ],
            "frozen": false,
            "icon": "Autonomize",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Clinical Entities",
                "method": "build_output",
                "name": "prediction",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from pydantic import BaseModel\n\nfrom langflow.base.modelhub import ATModelComponent\nfrom langflow.inputs.input_mixin import FieldTypes\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema import Data\nfrom genesis_studio.services.modelhub.model_endpoint import ModelEndpoint\n\n\nclass Trait(BaseModel):\n    Name: str\n    Score: float\n\n\nclass Attribute(BaseModel):\n    Id: int\n    BeginOffset: int\n    EndOffset: int\n    Text: str\n    Score: float\n    Category: str\n    Type: str\n    Traits: list[Trait]\n\n\nclass Entity(BaseModel):\n    Category: str\n    Type: str\n    Text: str\n    BeginOffset: int\n    EndOffset: int\n    Score: float\n    Traits: list[Trait]\n    Id: int\n    Attributes: list[Attribute] | None = None\n\n\nclass ClinicalPrediction(BaseModel):\n    prediction: list[Entity]\n\n\nclass ClinicalLLMComponent(ATModelComponent):\n    \"\"\"Component for the Clinical LLM model\"\"\"\n\n    display_name: str = \"Clinical LLM\"\n    description: str = \"Extract clinical entities from text using Clinical LLM.\"\n    documentation: str = \"https://docs.example.com/clinical-llm\"\n    icon: str = \"Autonomize\"\n    name: str = \"ClinicalLLM\"\n    _model_name = ModelEndpoint.CLINICAL_LLM\n\n    inputs = [\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search query\",\n            field_type=FieldTypes.TEXT,\n            multiline=True,\n        )\n    ]\n\n    outputs = [\n        Output(\n            name=\"prediction\", display_name=\"Clinical Entities\", method=\"build_output\"\n        ),\n    ]\n\n    async def extract_entities(self, text) -> ClinicalPrediction:\n        \"\"\"Extract clinical entities from the input text\"\"\"\n        try:\n            response = await self.predict(text=text)\n            return ClinicalPrediction(**response)\n        except Exception as e:\n            msg = f\"Error extracting clinical entities: {e!s}\"\n            raise ValueError(msg) from e\n\n    async def build_output(self) -> Data:\n        \"\"\"Generate the output based on selected knowledgehub hubs.\"\"\"\n        query_results = await self.extract_entities(self.search_query)\n        data = Data(value={\"data\": query_results})\n        self.status = data\n        return data\n"
              },
              "search_query": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Search query",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "search_query",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ClinicalLLM"
        },
        "id": "ClinicalLLM-Q2Siz",
        "measured": {
          "height": 254,
          "width": 320
        },
        "position": {
          "x": 1385.0103621193246,
          "y": -195
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParseData-gZwky",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data into plain text following a specified template.",
            "display_name": "Parse Data",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Text",
                "method": "parse_data",
                "name": "text",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "name": "data_list",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Text\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "name": "data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{value}"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParseData"
        },
        "id": "ParseData-gZwky",
        "measured": {
          "height": 350,
          "width": 320
        },
        "position": {
          "x": 1755.14363405295,
          "y": -59.499416685424876
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "JSONOutput-Ru3z5",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display input data as JSON in the Playground.",
            "display_name": "JSON Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "pretty_print"
            ],
            "frozen": false,
            "icon": "Braces",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "JSON",
                "method": "json_response",
                "name": "json",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\n\nfrom langflow.base.io.text import TextComponent\nfrom langflow.inputs import DataInput\nfrom langflow.io import BoolInput, Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass JSONOutputComponent(TextComponent):\n    display_name = \"JSON Output\"\n    description = \"Display input data as JSON in the Playground.\"\n    icon = \"Braces\"\n    name = \"JSONOutput\"\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to JSON.\",\n            is_list=True,\n        ),\n        BoolInput(\n            name=\"pretty_print\",\n            display_name=\"Pretty Print\",\n            info=\"Format JSON with proper indentation\",\n            value=True,\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"JSON\", name=\"json\", method=\"json_response\"),\n    ]\n\n    def _process_data(self, data: Data | list[Data]) -> dict | list:\n        \"\"\"Convert Data object(s) to dictionary/list format.\"\"\"\n        if isinstance(data, list):\n            return [item.dict() for item in data]\n        return data.dict()\n\n    def json_response(self) -> Message:\n        try:\n            # Process the Data input\n            processed_data = self._process_data(self.data)\n\n            # Convert to JSON string with optional pretty printing\n            if self.pretty_print:\n                formatted_json = json.dumps(\n                    processed_data, indent=2, ensure_ascii=False\n                )\n            else:\n                formatted_json = json.dumps(processed_data, ensure_ascii=False)\n\n            message = Message(text=formatted_json)\n            self.status = formatted_json\n            return message\n\n        except Exception as e:\n            error_message = f\"Error processing data to JSON: {e!s}\"\n            message = Message(text=error_message)\n            self.status = error_message\n            return message\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to JSON.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "name": "data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "pretty_print": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Pretty Print",
                "dynamic": false,
                "info": "Format JSON with proper indentation",
                "list": false,
                "name": "pretty_print",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "JSONOutput"
        },
        "dragging": false,
        "id": "JSONOutput-Ru3z5",
        "measured": {
          "height": 196,
          "width": 320
        },
        "position": {
          "x": 2531.1428432781945,
          "y": 344.0833210216154
        },
        "selected": true,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "File Path-8jQBJ",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Load files from server URLs",
            "display_name": "File Path",
            "documentation": "http://docs.langflow.org/components/server_file",
            "edited": false,
            "field_order": [
              "file_urls",
              "validate_urls",
              "return_all_urls"
            ],
            "frozen": false,
            "icon": "File",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [
              "Data"
            ],
            "outputs": [
              {
                "cache": true,
                "display_name": "File Path",
                "method": "get_file_paths",
                "name": "file_path",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from __future__ import annotations\n\nfrom loguru import logger\n\nfrom langflow.custom import Component\nfrom langflow.io import (\n    BoolInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema import Data\n\n\nclass FilePathComponent(Component):\n    display_name = \"File Path\"\n    description = \"Load files from server URLs\"\n    documentation = \"http://docs.langflow.org/components/server_file\"\n    icon = \"File\"\n    name = \"File Path\"\n\n    # Match the property name expected by FileComponent\n    FILE_PATH_FIELD = \"file_path\"\n\n    inputs = [\n        MultilineInput(\n            name=\"file_urls\",\n            display_name=\"File URLs\",\n            required=True,\n            info=\"Enter one or more URLs (one per line) pointing to files on your server\",\n            placeholder=\"https://example.com/file1.pdf\\nhttps://example.com/file2.pdf\",\n        ),\n        BoolInput(\n            name=\"validate_urls\",\n            display_name=\"Validate URLs\",\n            info=\"If true, validates that URLs are accessible before returning them\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"return_all_urls\",\n            display_name=\"Return All URLs\",\n            info=\"If true, returns all URLs even if some are invalid\",\n            value=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            name=\"file_path\",  # Match the property name expected by FileComponent\n            display_name=\"File Path\",\n            method=\"get_file_paths\",\n        ),\n    ]\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self._validated_urls: list[str] = []\n\n    async def validate_url(self, url: str) -> bool:\n        \"\"\"Validate that a URL is accessible.\"\"\"\n        try:\n            import aiohttp\n\n            async with aiohttp.ClientSession() as session:\n                async with session.head(url.strip()) as response:\n                    return response.status < 400\n        except Exception as e:\n            logger.error(f\"Error validating URL {url}: {e!s}\")\n            return False\n\n    async def get_file_paths(self) -> list[Data]:\n        \"\"\"Get file paths for the FileComponent to process.\"\"\"\n        try:\n            if not self.file_urls:\n                logger.warning(\"No URLs provided.\")\n                return []\n\n            # Split URLs by newlines and filter out empty lines\n            urls = [url.strip() for url in self.file_urls.split(\"\\n\") if url.strip()]\n            file_paths = []\n\n            if self.validate_urls:\n                # Validate all URLs concurrently\n                import asyncio\n\n                validation_tasks = [self.validate_url(url) for url in urls]\n                validation_results = await asyncio.gather(*validation_tasks)\n\n                # Pair URLs with their validation results\n                valid_urls = [\n                    url\n                    for url, is_valid in zip(urls, validation_results, strict=False)\n                    if is_valid or self.return_all_urls\n                ]\n\n                if not valid_urls:\n                    logger.warning(\"No valid URLs found.\")\n                    return []\n\n                self._validated_urls = valid_urls\n\n                # Create Data objects for each valid URL\n                for url in valid_urls:\n                    file_paths.append(Data(data={self.FILE_PATH_FIELD: url}))\n            else:\n                # If no validation required, create Data objects for all URLs\n                file_paths = [Data(data={self.FILE_PATH_FIELD: url}) for url in urls]\n\n            if file_paths:\n                self.status = file_paths\n                logger.info(f\"Generated {len(file_paths)} file paths\")\n                for path in file_paths:\n                    logger.debug(f\"File path: {path.data.get(self.FILE_PATH_FIELD)}\")\n            else:\n                logger.warning(\"No file paths generated\")\n\n            return file_paths\n\n        except Exception as e:\n            logger.error(f\"Error in get_file_paths: {e!s}\")\n            return []\n\n    def build(self) -> list[Data]:\n        \"\"\"Build method to support both async and sync operation.\"\"\"\n        import asyncio\n\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n        try:\n            return loop.run_until_complete(self.get_file_paths())\n        finally:\n            loop.close()\n"
              },
              "file_urls": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "display_name": "File URLs",
                "dynamic": false,
                "info": "Enter one or more URLs (one per line) pointing to files on your server",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "file_urls",
                "placeholder": "https://example.com/file1.pdf\nhttps://example.com/file2.pdf",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "https://autonomizestorageaccount.blob.core.windows.net/genesis-platform-dev/PriorAuth000_2.pdf?sv=2025-01-05&st=2025-01-23T14%3A11%3A13Z&se=2025-01-24T14%3A11%3A13Z&skoid=77f6025b-720c-4af4-a874-9c1e1054680b&sktid=2a9d6d51-7674-4d37-8d71-1ee2fe30ccf4&skt=2025-01-23T14%3A11%3A13Z&ske=2025-01-24T14%3A11%3A13Z&sks=b&skv=2025-01-05&sr=b&sp=r&sig=n4Cqed%2BA%2F%2FgO4P8vaDEki87P0YbrebDe%2F5zDPjKmPcE%3D"
              },
              "return_all_urls": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Return All URLs",
                "dynamic": false,
                "info": "If true, returns all URLs even if some are invalid",
                "list": false,
                "name": "return_all_urls",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "validate_urls": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Validate URLs",
                "dynamic": false,
                "info": "If true, validates that URLs are accessible before returning them",
                "list": false,
                "name": "validate_urls",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "File Path"
        },
        "dragging": false,
        "id": "File Path-8jQBJ",
        "measured": {
          "height": 327,
          "width": 320
        },
        "position": {
          "x": 244.28455112136976,
          "y": 423.84335174163766
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "azure_ocr-KoHV8",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Process documents using Azure Form Recognizer OCR capabilities",
            "display_name": "OCR",
            "documentation": "",
            "edited": false,
            "field_order": [
              "file_path",
              "silent_errors",
              "delete_server_file_after_processing",
              "ignore_unsupported_extensions",
              "ignore_unspecified_files",
              "model_type",
              "extract_tables",
              "include_confidence",
              "use_multithreading",
              "concurrency_multithreading"
            ],
            "frozen": false,
            "icon": "Azure",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Structured Data",
                "method": "load_files",
                "name": "structured_data",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import asyncio\nimport concurrent.futures\nimport mimetypes\nimport os\nimport tempfile\nfrom pathlib import Path\nfrom urllib.parse import unquote, urlparse\n\nimport aiohttp\nimport requests\nfrom loguru import logger\n\nfrom langflow.base.data import BaseFileComponent\nfrom langflow.io import BoolInput, DropdownInput, IntInput, Output\nfrom langflow.schema import Data\nfrom genesis_studio.services.deps import (\n    get_azure_ocr_service,\n)  # You'll need to create this\n\n\nclass AzureOCRComponent(BaseFileComponent):\n    \"\"\"Component for OCR processing using Azure Form Recognizer.\"\"\"\n\n    display_name = \"Form Recognizer\"\n    description = \"Process documents using Azure Form Recognizer OCR capabilities\"\n    icon = \"Azure\"\n    name = \"azure_ocr\"\n\n    VALID_EXTENSIONS = [\"pdf\", \"jpg\", \"jpeg\", \"png\", \"bmp\", \"tiff\", \"tif\"]\n\n    inputs = [\n        # Include only the HandleInput and BoolInputs from base_inputs\n        next(\n            input\n            for input in BaseFileComponent._base_inputs\n            if input.name == \"file_path\"\n        ),\n        next(\n            input\n            for input in BaseFileComponent._base_inputs\n            if input.name == \"silent_errors\"\n        ),\n        next(\n            input\n            for input in BaseFileComponent._base_inputs\n            if input.name == \"delete_server_file_after_processing\"\n        ),\n        next(\n            input\n            for input in BaseFileComponent._base_inputs\n            if input.name == \"ignore_unsupported_extensions\"\n        ),\n        next(\n            input\n            for input in BaseFileComponent._base_inputs\n            if input.name == \"ignore_unspecified_files\"\n        ),\n        DropdownInput(\n            name=\"model_type\",\n            display_name=\"Model Type\",\n            options=[\"prebuilt-document\", \"prebuilt-read\", \"prebuilt-layout\"],\n            value=\"prebuilt-document\",\n            info=\"Choose the Form Recognizer model to use\",\n        ),\n        BoolInput(\n            name=\"extract_tables\",\n            display_name=\"Extract Tables\",\n            value=True,\n            info=\"Extract and format tables from the document\",\n        ),\n        BoolInput(\n            name=\"include_confidence\",\n            display_name=\"Include Confidence Scores\",\n            value=False,\n            advanced=True,\n            info=\"Include confidence scores in the extracted text\",\n        ),\n        BoolInput(\n            name=\"use_multithreading\",\n            display_name=\"Use Concurrent Processing\",\n            value=True,\n            info=\"Enable concurrent processing of multiple files\",\n        ),\n        IntInput(\n            name=\"concurrency_multithreading\",\n            display_name=\"Processing Concurrency\",\n            advanced=True,\n            info=\"Number of files to process concurrently\",\n            value=2,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Structured Data\", name=\"structured_data\", method=\"load_files\"\n        ),\n    ]\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.temp_dir = tempfile.mkdtemp()\n        self._downloaded_files = {}\n\n    def get_text_content(self) -> str:\n        \"\"\"Return the concatenated text content from all processed pages.\"\"\"\n        return self._text_content\n\n    def _extract_filename_from_url(self, url: str) -> str:\n        \"\"\"Extract filename from URL or generate a default one.\"\"\"\n        try:\n            parsed_url = urlparse(url)\n            path = unquote(parsed_url.path)\n            filename = os.path.basename(path)\n\n            if filename and \".\" in filename:\n                return filename\n\n            response = requests.head(url, allow_redirects=True)\n            if \"content-disposition\" in response.headers:\n                content_disp = response.headers[\"content-disposition\"]\n                if \"filename=\" in content_disp:\n                    return content_disp.split(\"filename=\")[1].strip(\"\\\"'\")\n\n            if \"content-type\" in response.headers:\n                ext = mimetypes.guess_extension(response.headers[\"content-type\"])\n                if ext:\n                    return f\"downloaded{ext}\"\n\n            return \"downloaded.pdf\"\n        except Exception as e:\n            logger.error(f\"Error extracting filename from URL: {e!s}\")\n            return \"downloaded.pdf\"\n\n    async def _download_file_from_url(self, url: str) -> str | None:\n        \"\"\"Download a file from a URL.\"\"\"\n        try:\n            filename = self._extract_filename_from_url(url)\n            local_path = os.path.join(self.temp_dir, filename)\n\n            async with aiohttp.ClientSession() as session:\n                async with session.get(url) as response:\n                    response.raise_for_status()\n                    with open(local_path, \"wb\") as f:\n                        while True:\n                            chunk = await response.content.read(8192)\n                            if not chunk:\n                                break\n                            f.write(chunk)\n\n            self._downloaded_files[url] = local_path\n            logger.info(f\"Successfully downloaded file to {local_path}\")\n            return local_path\n\n        except Exception as e:\n            logger.error(f\"Error downloading file from URL: {e!s}\")\n            if not self.silent_errors:\n                raise\n            return None\n\n    def _validate_and_resolve_paths(self) -> list[BaseFileComponent.BaseFile]:\n        \"\"\"Handle URLs and local paths.\"\"\"\n        resolved_files = []\n        file_path = self._file_path_as_list()\n\n        for obj in file_path:\n            server_file_path = obj.data.get(self.SERVER_FILE_PATH_FIELDNAME)\n\n            if not server_file_path:\n                if not self.ignore_unspecified_files:\n                    msg = f\"Data object missing '{self.SERVER_FILE_PATH_FIELDNAME}' property.\"\n                    if not self.silent_errors:\n                        raise ValueError(msg)\n                continue\n\n            try:\n                # Check if it's a URL\n                if isinstance(server_file_path, str) and server_file_path.startswith(\n                    (\"http://\", \"https://\")\n                ):\n                    # Create event loop for async download\n                    loop = asyncio.new_event_loop()\n                    asyncio.set_event_loop(loop)\n                    try:\n                        local_path = loop.run_until_complete(\n                            self._download_file_from_url(server_file_path)\n                        )\n                    finally:\n                        loop.close()\n\n                    if not local_path:\n                        continue\n\n                    # Create a new Data object with both the original URL and local path\n                    new_data = Data(\n                        data={\n                            self.SERVER_FILE_PATH_FIELDNAME: local_path,\n                            \"original_url\": server_file_path,\n                        }\n                    )\n\n                    resolved_files.append(\n                        BaseFileComponent.BaseFile(\n                            new_data,\n                            Path(local_path),\n                            delete_after_processing=self.delete_server_file_after_processing,\n                        )\n                    )\n                else:\n                    # Handle local files\n                    resolved_path = Path(self.resolve_path(str(server_file_path)))\n                    if not resolved_path.exists():\n                        msg = f\"File not found: {server_file_path}\"\n                        if not self.silent_errors:\n                            raise ValueError(msg)\n                        continue\n\n                    resolved_files.append(\n                        BaseFileComponent.BaseFile(\n                            obj,\n                            resolved_path,\n                            delete_after_processing=self.delete_server_file_after_processing,\n                        )\n                    )\n\n            except Exception as e:\n                logger.error(f\"Error processing path {server_file_path}: {e!s}\")\n                if not self.silent_errors:\n                    raise\n                continue\n\n        return resolved_files\n\n    async def process_file(\n        self, file_path: str, *, silent_errors: bool = False\n    ) -> tuple[Data, str]:\n        \"\"\"Process a single file using the OCR service.\"\"\"\n        try:\n            service = get_azure_ocr_service()\n\n            with open(file_path, \"rb\") as file:\n                file_content = file.read()\n\n            extracted_content, plain_text = await service.process_document(\n                file_content=file_content,\n                model_type=self.model_type,\n                include_confidence=self.include_confidence,\n                extract_tables=self.extract_tables,\n            )\n\n            structured_data = Data(\n                text=plain_text,\n                data={\n                    self.SERVER_FILE_PATH_FIELDNAME: str(file_path),\n                    \"result\": extracted_content,\n                },\n            )\n\n            return structured_data, plain_text\n\n        except Exception as e:\n            logger.error(f\"Error processing file {file_path}: {e!s}\")\n            if not silent_errors:\n                raise\n            return None, \"\"\n\n    def process_files(\n        self, file_list: list[BaseFileComponent.BaseFile]\n    ) -> list[BaseFileComponent.BaseFile]:\n        \"\"\"Process multiple files with concurrent processing.\"\"\"\n        if not file_list:\n            msg = \"No files to process.\"\n            raise ValueError(msg)\n\n        concurrency = (\n            1\n            if not self.use_multithreading\n            else max(1, self.concurrency_multithreading)\n        )\n        file_count = len(file_list)\n\n        logger.info(f\"Processing {file_count} files with concurrency: {concurrency}\")\n\n        all_plain_text = []\n        processed_data = []\n\n        if concurrency > 1 and file_count > 1:\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n            try:\n                with concurrent.futures.ThreadPoolExecutor(\n                    max_workers=concurrency\n                ) as executor:\n                    future_to_file = {\n                        executor.submit(\n                            lambda path: loop.run_until_complete(\n                                self.process_file(\n                                    str(path), silent_errors=self.silent_errors\n                                )\n                            ),\n                            file.path,\n                        ): file\n                        for file in file_list\n                    }\n                    for future in concurrent.futures.as_completed(future_to_file):\n                        try:\n                            structured_data, plain_text = future.result()\n                            processed_data.append(structured_data)\n                            all_plain_text.append(plain_text)\n                        except Exception as e:\n                            logger.error(f\"Error in concurrent processing: {e!s}\")\n                            if not self.silent_errors:\n                                raise\n                            processed_data.append(None)\n                            all_plain_text.append(\"\")\n            finally:\n                loop.close()\n        else:\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n            try:\n                for file in file_list:\n                    try:\n                        structured_data, plain_text = loop.run_until_complete(\n                            self.process_file(\n                                str(file.path), silent_errors=self.silent_errors\n                            )\n                        )\n                        processed_data.append(structured_data)\n                        all_plain_text.append(plain_text)\n                    except Exception as e:\n                        logger.error(f\"Error processing file {file.path}: {e!s}\")\n                        if not self.silent_errors:\n                            raise\n                        processed_data.append(None)\n                        all_plain_text.append(\"\")\n            finally:\n                loop.close()\n\n        # Store concatenated text content\n        self._text_content = \"\\n\\n=== NEW DOCUMENT ===\\n\\n\".join(all_plain_text)\n\n        return self.rollup_data(file_list, processed_data)\n\n    def __del__(self):\n        \"\"\"Cleanup temporary files and directory.\"\"\"\n        try:\n            if hasattr(self, \"temp_dir\") and os.path.exists(self.temp_dir):\n                # Remove downloaded files\n                for file_path in self._downloaded_files.values():\n                    if os.path.exists(file_path):\n                        os.unlink(file_path)\n                # Remove the temporary directory\n                os.rmdir(self.temp_dir)\n        except Exception as e:\n            logger.error(f\"Error cleaning up temporary files: {e!s}\")\n"
              },
              "concurrency_multithreading": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Processing Concurrency",
                "dynamic": false,
                "info": "Number of files to process concurrently",
                "list": false,
                "name": "concurrency_multithreading",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 2
              },
              "delete_server_file_after_processing": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Delete Server File After Processing",
                "dynamic": false,
                "info": "If true, the Server File Path will be deleted after processing.",
                "list": false,
                "name": "delete_server_file_after_processing",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "extract_tables": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Extract Tables",
                "dynamic": false,
                "info": "Extract and format tables from the document",
                "list": false,
                "name": "extract_tables",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "file_path": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "URL",
                "dynamic": false,
                "info": "Upload file via URL or local server path. Supports: \n1. Direct HTTP/HTTPS URLs for remote files\n2. Local server file paths\n3. Data objects with file path property\n4. Message objects containing file paths\n\nSupports the same file types as the Path input. Takes precedence over Path input when both are provided.",
                "input_types": [
                  "Data",
                  "Message"
                ],
                "list": true,
                "name": "file_path",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "ignore_unspecified_files": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Ignore Unspecified Files",
                "dynamic": false,
                "info": "If true, Data with no 'file_path' property will be ignored.",
                "list": false,
                "name": "ignore_unspecified_files",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "ignore_unsupported_extensions": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Ignore Unsupported Extensions",
                "dynamic": false,
                "info": "If true, files with unsupported extensions will not be processed.",
                "list": false,
                "name": "ignore_unsupported_extensions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "include_confidence": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Include Confidence Scores",
                "dynamic": false,
                "info": "Include confidence scores in the extracted text",
                "list": false,
                "name": "include_confidence",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "model_type": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Model Type",
                "dynamic": false,
                "info": "Choose the Form Recognizer model to use",
                "name": "model_type",
                "options": [
                  "prebuilt-document",
                  "prebuilt-read",
                  "prebuilt-layout"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "prebuilt-document"
              },
              "silent_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Silent Errors",
                "dynamic": false,
                "info": "If true, errors will not raise an exception.",
                "list": false,
                "name": "silent_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "use_multithreading": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Use Concurrent Processing",
                "dynamic": false,
                "info": "Enable concurrent processing of multiple files",
                "list": false,
                "name": "use_multithreading",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "azure_ocr"
        },
        "dragging": false,
        "id": "azure_ocr-KoHV8",
        "measured": {
          "height": 395,
          "width": 320
        },
        "position": {
          "x": 572.6399112675325,
          "y": -2.862058198044508
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "RelationExtraction-TvyqO",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Identifies and extracts relevant lab results from medical records.",
            "display_name": "Relation Extraction",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data"
            ],
            "frozen": false,
            "icon": "Autonomize",
            "legacy": false,
            "lf_version": "1.1.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "name": "data_list",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text_list\nfrom langflow.io import DataInput, Output\nfrom langflow.schema import Data\n\n\nclass RelationExtraction(Component):\n    display_name = \"Relation Extraction\"\n    description = \"Identifies and extracts relevant lab results from medical records.\"\n    icon = \"Autonomize\"\n    name = \"RelationExtraction\"\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = \"{value}\"\n        return data\n\n    def parse_data_as_list(self) -> Data:\n        data = self._clean_args()\n        text_list, data_list = data_to_text_list(\"{value}\", data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        extracted_values = self.extract_relations(data_list)\n        result = Data(value={\"data\": extracted_values})\n        return result\n\n    def extract_relations(self, data) -> list[Data]:\n        relations = []\n        for item in data:\n            for prediction in item.data[\"value\"][\"data\"].prediction:\n                attributes = prediction.Attributes\n                if attributes is not None and len(attributes) > 0:\n                    relations.append(prediction)\n        return relations\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "name": "data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "RelationExtraction"
        },
        "dragging": false,
        "id": "RelationExtraction-TvyqO",
        "measured": {
          "height": 216,
          "width": 320
        },
        "position": {
          "x": 2133.055996705636,
          "y": 130.71021965993916
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": -533.2080951986136,
      "y": 226.38671642955805,
      "zoom": 0.33885246599046315
    }
  },
  "description": "Identifies and extracts relationships between clinical entities, such as treatments, and their dates, from medical documents to support deeper data analysis and knowledge discovery",
  "endpoint_name": null,
  "id": "ad58a538-be66-4a71-88cf-ce0e8a151953",
  "is_component": false,
  "last_tested_version": "1.1.1",
  "name": "Relation Extraction Agent",
  "tags": [
    "chart-review"
  ]
}
