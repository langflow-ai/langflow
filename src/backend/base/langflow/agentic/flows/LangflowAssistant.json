{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-Ei6z8",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "Agent-aLzmq",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ChatInput-Ei6z8{œdataTypeœ:œChatInputœ,œidœ:œChatInput-Ei6z8œ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Agent-aLzmq{œfieldNameœ:œinput_valueœ,œidœ:œAgent-aLzmqœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ChatInput-Ei6z8",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-Ei6z8œ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Agent-aLzmq",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œAgent-aLzmqœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-3EeP1",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-aLzmq",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-Agent-3EeP1{œdataTypeœ:œAgentœ,œidœ:œAgent-3EeP1œ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}-Agent-aLzmq{œfieldNameœ:œtoolsœ,œidœ:œAgent-aLzmqœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "Agent-3EeP1",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-3EeP1œ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "Agent-aLzmq",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œAgent-aLzmqœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-aLzmq",
            "name": "response",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-GgTV3",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-Agent-aLzmq{œdataTypeœ:œAgentœ,œidœ:œAgent-aLzmqœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-GgTV3{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-GgTV3œ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "Agent-aLzmq",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-aLzmqœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-GgTV3",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-GgTV3œ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "UnifiedWebSearch",
            "id": "UnifiedWebSearch-iL7hT",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-aLzmq",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-UnifiedWebSearch-iL7hT{œdataTypeœ:œUnifiedWebSearchœ,œidœ:œUnifiedWebSearch-iL7hTœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}-Agent-aLzmq{œfieldNameœ:œtoolsœ,œidœ:œAgent-aLzmqœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "UnifiedWebSearch-iL7hT",
        "sourceHandle": "{œdataTypeœ:œUnifiedWebSearchœ,œidœ:œUnifiedWebSearch-iL7hTœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "Agent-aLzmq",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œAgent-aLzmqœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "UnifiedWebSearch",
            "id": "UnifiedWebSearch-iL7hT",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-3EeP1",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-UnifiedWebSearch-iL7hT{œdataTypeœ:œUnifiedWebSearchœ,œidœ:œUnifiedWebSearch-iL7hTœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}-Agent-3EeP1{œfieldNameœ:œtoolsœ,œidœ:œAgent-3EeP1œ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "UnifiedWebSearch-iL7hT",
        "sourceHandle": "{œdataTypeœ:œUnifiedWebSearchœ,œidœ:œUnifiedWebSearch-iL7hTœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "Agent-3EeP1",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œAgent-3EeP1œ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "URLComponent",
            "id": "URLComponent-UYnHu",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-3EeP1",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-URLComponent-UYnHu{œdataTypeœ:œURLComponentœ,œidœ:œURLComponent-UYnHuœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}-Agent-3EeP1{œfieldNameœ:œtoolsœ,œidœ:œAgent-3EeP1œ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "URLComponent-UYnHu",
        "sourceHandle": "{œdataTypeœ:œURLComponentœ,œidœ:œURLComponent-UYnHuœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "Agent-3EeP1",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œAgent-3EeP1œ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "URLComponent",
            "id": "URLComponent-UYnHu",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-aLzmq",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-URLComponent-UYnHu{œdataTypeœ:œURLComponentœ,œidœ:œURLComponent-UYnHuœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}-Agent-aLzmq{œfieldNameœ:œtoolsœ,œidœ:œAgent-aLzmqœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "URLComponent-UYnHu",
        "sourceHandle": "{œdataTypeœ:œURLComponentœ,œidœ:œURLComponent-UYnHuœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "Agent-aLzmq",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œAgent-aLzmqœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt Template",
            "id": "Prompt Template-GZj4p",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_prompt",
            "id": "Agent-03db7",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt Template-GZj4p{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-GZj4pœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-Agent-03db7{œfieldNameœ:œsystem_promptœ,œidœ:œAgent-03db7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt Template-GZj4p",
        "sourceHandle": "{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-GZj4pœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Agent-03db7",
        "targetHandle": "{œfieldNameœ:œsystem_promptœ,œidœ:œAgent-03db7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-03db7",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-aLzmq",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__Agent-03db7{œdataTypeœ:œAgentœ,œidœ:œAgent-03db7œ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}-Agent-aLzmq{œfieldNameœ:œtoolsœ,œidœ:œAgent-aLzmqœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "Agent-03db7",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-03db7œ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "Agent-aLzmq",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œAgent-aLzmqœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "data": {
          "sourceHandle": {
            "dataType": "URLComponent",
            "id": "URLComponent-UYnHu",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-03db7",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__URLComponent-UYnHu{œdataTypeœ:œURLComponentœ,œidœ:œURLComponent-UYnHuœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}-Agent-03db7{œfieldNameœ:œtoolsœ,œidœ:œAgent-03db7œ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "URLComponent-UYnHu",
        "sourceHandle": "{œdataTypeœ:œURLComponentœ,œidœ:œURLComponent-UYnHuœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "Agent-03db7",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œAgent-03db7œ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "Agent-3EeP1",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "display_name": "Agent",
            "documentation": "https://docs.langflow.org/agents",
            "edited": false,
            "field_order": [
              "model",
              "api_key",
              "system_prompt",
              "context_id",
              "n_messages",
              "format_instructions",
              "output_schema",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "add_current_date_tool"
            ],
            "frozen": false,
            "icon": "bot",
            "last_updated": "2026-01-16T18:59:16.435Z",
            "legacy": false,
            "lf_version": "1.8.0",
            "metadata": {
              "code_hash": "bdc309bc2d2a",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "pydantic",
                    "version": "2.11.10"
                  },
                  {
                    "name": "lfx",
                    "version": null
                  },
                  {
                    "name": "langchain_core",
                    "version": "0.3.80"
                  }
                ],
                "total_dependencies": 3
              },
              "module": "lfx.components.models_and_agents.agent.AgentComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "group_outputs": false,
                "hidden": null,
                "loop_types": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_frontend_node_flow_id": {
                "value": "66eb7678-93d8-450d-9ddf-0c09b8c1eee9"
              },
              "_frontend_node_folder_id": {
                "value": "9b756c37-4ddb-4a33-bb62-6d9ab7eec58c"
              },
              "_type": "Component",
              "add_current_date_tool": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Current Date",
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "add_current_date_tool",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": true,
                "display_name": "API Key",
                "dynamic": false,
                "info": "Model Provider API key",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": "ANTHROPIC_API_KEY"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from __future__ import annotations\n\nimport json\nimport re\nfrom typing import TYPE_CHECKING\n\nfrom pydantic import ValidationError\n\nfrom lfx.components.models_and_agents.memory import MemoryComponent\n\nif TYPE_CHECKING:\n    from langchain_core.tools import Tool\n\nfrom lfx.base.agents.agent import LCToolsAgentComponent\nfrom lfx.base.agents.events import ExceptionWithMessageError\nfrom lfx.base.models.unified_models import (\n    get_language_model_options,\n    get_llm,\n    update_model_options_in_build_config,\n)\nfrom lfx.components.helpers import CurrentDateComponent\nfrom lfx.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom lfx.custom.custom_component.component import get_component_toolkit\nfrom lfx.helpers.base_model import build_model_from_schema\nfrom lfx.inputs.inputs import BoolInput, ModelInput\nfrom lfx.io import IntInput, MessageTextInput, MultilineInput, Output, SecretStrInput, TableInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.dotdict import dotdict\nfrom lfx.schema.message import Message\nfrom lfx.schema.table import EditMode\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    documentation: str = \"https://docs.langflow.org/agents\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        ModelInput(\n            name=\"model\",\n            display_name=\"Language Model\",\n            info=\"Select your model provider\",\n            real_time_refresh=True,\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"API Key\",\n            info=\"Model Provider API key\",\n            real_time_refresh=True,\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        MessageTextInput(\n            name=\"context_id\",\n            display_name=\"Context ID\",\n            info=\"The context ID of the chat. Adds an extra layer to the local memory.\",\n            value=\"\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Chat History Messages\",\n            value=100,\n            info=\"Number of chat history messages to retrieve.\",\n            advanced=True,\n            show=True,\n        ),\n        MultilineInput(\n            name=\"format_instructions\",\n            display_name=\"Output Format Instructions\",\n            info=\"Generic Template for structured output formatting. Valid only with Structured response.\",\n            value=(\n                \"You are an AI that extracts structured JSON objects from unstructured text. \"\n                \"Use a predefined schema with expected types (str, int, float, bool, dict). \"\n                \"Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. \"\n                \"Fill missing or ambiguous values with defaults: null for missing values. \"\n                \"Remove exact duplicates but keep variations that have different field values. \"\n                \"Always return valid JSON in the expected format, never throw errors. \"\n                \"If multiple objects can be extracted, return them all in the structured format.\"\n            ),\n            advanced=True,\n        ),\n        TableInput(\n            name=\"output_schema\",\n            display_name=\"Output Schema\",\n            info=(\n                \"Schema Validation: Define the structure and data types for structured output. \"\n                \"No validation if no output schema.\"\n            ),\n            advanced=True,\n            required=False,\n            value=[],\n            table_schema=[\n                {\n                    \"name\": \"name\",\n                    \"display_name\": \"Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Specify the name of the output field.\",\n                    \"default\": \"field\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"description\",\n                    \"display_name\": \"Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Describe the purpose of the output field.\",\n                    \"default\": \"description of field\",\n                    \"edit_mode\": EditMode.POPOVER,\n                },\n                {\n                    \"name\": \"type\",\n                    \"display_name\": \"Type\",\n                    \"type\": \"str\",\n                    \"edit_mode\": EditMode.INLINE,\n                    \"description\": (\"Indicate the data type of the output field (e.g., str, int, float, bool, dict).\"),\n                    \"options\": [\"str\", \"int\", \"float\", \"bool\", \"dict\"],\n                    \"default\": \"str\",\n                },\n                {\n                    \"name\": \"multiple\",\n                    \"display_name\": \"As List\",\n                    \"type\": \"boolean\",\n                    \"description\": \"Set to True if this output field should be a list of the specified type.\",\n                    \"default\": \"False\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n            ],\n        ),\n        *LCToolsAgentComponent.get_base_inputs(),\n        # removed memory inputs from agent component\n        # *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [\n        Output(name=\"response\", display_name=\"Response\", method=\"message_response\"),\n    ]\n\n    async def get_agent_requirements(self):\n        \"\"\"Get the agent requirements for the agent.\"\"\"\n        from langchain_core.tools import StructuredTool\n\n        llm_model = get_llm(\n            model=self.model,\n            user_id=self.user_id,\n            api_key=self.api_key,\n        )\n        if llm_model is None:\n            msg = \"No language model selected. Please choose a model to proceed.\"\n            raise ValueError(msg)\n\n        # Get memory data\n        self.chat_history = await self.get_memory_data()\n        await logger.adebug(f\"Retrieved {len(self.chat_history)} chat history messages\")\n        if isinstance(self.chat_history, Message):\n            self.chat_history = [self.chat_history]\n\n        # Add current date tool if enabled\n        if self.add_current_date_tool:\n            if not isinstance(self.tools, list):  # type: ignore[has-type]\n                self.tools = []\n            current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n\n            if not isinstance(current_date_tool, StructuredTool):\n                msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                raise TypeError(msg)\n            self.tools.append(current_date_tool)\n\n        # Set shared callbacks for tracing the tools used by the agent\n        self.set_tools_callbacks(self.tools, self._get_shared_callbacks())\n\n        return llm_model, self.chat_history, self.tools\n\n    async def message_response(self) -> Message:\n        try:\n            llm_model, self.chat_history, self.tools = await self.get_agent_requirements()\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            result = await self.run_agent(agent)\n\n            # Store result for potential JSON output\n            self._agent_result = result\n\n        except (ValueError, TypeError, KeyError) as e:\n            await logger.aerror(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            await logger.aerror(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        # Avoid catching blind Exception; let truly unexpected exceptions propagate\n        except Exception as e:\n            await logger.aerror(f\"Unexpected error: {e!s}\")\n            raise\n        else:\n            return result\n\n    def _preprocess_schema(self, schema):\n        \"\"\"Preprocess schema to ensure correct data types for build_model_from_schema.\"\"\"\n        processed_schema = []\n        for field in schema:\n            processed_field = {\n                \"name\": str(field.get(\"name\", \"field\")),\n                \"type\": str(field.get(\"type\", \"str\")),\n                \"description\": str(field.get(\"description\", \"\")),\n                \"multiple\": field.get(\"multiple\", False),\n            }\n            # Ensure multiple is handled correctly\n            if isinstance(processed_field[\"multiple\"], str):\n                processed_field[\"multiple\"] = processed_field[\"multiple\"].lower() in [\n                    \"true\",\n                    \"1\",\n                    \"t\",\n                    \"y\",\n                    \"yes\",\n                ]\n            processed_schema.append(processed_field)\n        return processed_schema\n\n    async def build_structured_output_base(self, content: str):\n        \"\"\"Build structured output with optional BaseModel validation.\"\"\"\n        json_pattern = r\"\\{.*\\}\"\n        schema_error_msg = \"Try setting an output schema\"\n\n        # Try to parse content as JSON first\n        json_data = None\n        try:\n            json_data = json.loads(content)\n        except json.JSONDecodeError:\n            json_match = re.search(json_pattern, content, re.DOTALL)\n            if json_match:\n                try:\n                    json_data = json.loads(json_match.group())\n                except json.JSONDecodeError:\n                    return {\"content\": content, \"error\": schema_error_msg}\n            else:\n                return {\"content\": content, \"error\": schema_error_msg}\n\n        # If no output schema provided, return parsed JSON without validation\n        if not hasattr(self, \"output_schema\") or not self.output_schema or len(self.output_schema) == 0:\n            return json_data\n\n        # Use BaseModel validation with schema\n        try:\n            processed_schema = self._preprocess_schema(self.output_schema)\n            output_model = build_model_from_schema(processed_schema)\n\n            # Validate against the schema\n            if isinstance(json_data, list):\n                # Multiple objects\n                validated_objects = []\n                for item in json_data:\n                    try:\n                        validated_obj = output_model.model_validate(item)\n                        validated_objects.append(validated_obj.model_dump())\n                    except ValidationError as e:\n                        await logger.aerror(f\"Validation error for item: {e}\")\n                        # Include invalid items with error info\n                        validated_objects.append({\"data\": item, \"validation_error\": str(e)})\n                return validated_objects\n\n            # Single object\n            try:\n                validated_obj = output_model.model_validate(json_data)\n                return [validated_obj.model_dump()]  # Return as list for consistency\n            except ValidationError as e:\n                await logger.aerror(f\"Validation error: {e}\")\n                return [{\"data\": json_data, \"validation_error\": str(e)}]\n\n        except (TypeError, ValueError) as e:\n            await logger.aerror(f\"Error building structured output: {e}\")\n            # Fallback to parsed JSON without validation\n            return json_data\n\n    async def json_response(self) -> Data:\n        \"\"\"Convert agent response to structured JSON Data output with schema validation.\"\"\"\n        # Always use structured chat agent for JSON response mode for better JSON formatting\n        try:\n            system_components = []\n\n            # 1. Agent Instructions (system_prompt)\n            agent_instructions = getattr(self, \"system_prompt\", \"\") or \"\"\n            if agent_instructions:\n                system_components.append(f\"{agent_instructions}\")\n\n            # 2. Format Instructions\n            format_instructions = getattr(self, \"format_instructions\", \"\") or \"\"\n            if format_instructions:\n                system_components.append(f\"Format instructions: {format_instructions}\")\n\n            # 3. Schema Information from BaseModel\n            if hasattr(self, \"output_schema\") and self.output_schema and len(self.output_schema) > 0:\n                try:\n                    processed_schema = self._preprocess_schema(self.output_schema)\n                    output_model = build_model_from_schema(processed_schema)\n                    schema_dict = output_model.model_json_schema()\n                    schema_info = (\n                        \"You are given some text that may include format instructions, \"\n                        \"explanations, or other content alongside a JSON schema.\\n\\n\"\n                        \"Your task:\\n\"\n                        \"- Extract only the JSON schema.\\n\"\n                        \"- Return it as valid JSON.\\n\"\n                        \"- Do not include format instructions, explanations, or extra text.\\n\\n\"\n                        \"Input:\\n\"\n                        f\"{json.dumps(schema_dict, indent=2)}\\n\\n\"\n                        \"Output (only JSON schema):\"\n                    )\n                    system_components.append(schema_info)\n                except (ValidationError, ValueError, TypeError, KeyError) as e:\n                    await logger.aerror(f\"Could not build schema for prompt: {e}\", exc_info=True)\n\n            # Combine all components\n            combined_instructions = \"\\n\\n\".join(system_components) if system_components else \"\"\n            llm_model, self.chat_history, self.tools = await self.get_agent_requirements()\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=combined_instructions,\n            )\n\n            # Create and run structured chat agent\n            try:\n                structured_agent = self.create_agent_runnable()\n            except (NotImplementedError, ValueError, TypeError) as e:\n                await logger.aerror(f\"Error with structured chat agent: {e}\")\n                raise\n            try:\n                result = await self.run_agent(structured_agent)\n            except (\n                ExceptionWithMessageError,\n                ValueError,\n                TypeError,\n                RuntimeError,\n            ) as e:\n                await logger.aerror(f\"Error with structured agent result: {e}\")\n                raise\n            # Extract content from structured agent result\n            if hasattr(result, \"content\"):\n                content = result.content\n            elif hasattr(result, \"text\"):\n                content = result.text\n            else:\n                content = str(result)\n\n        except (\n            ExceptionWithMessageError,\n            ValueError,\n            TypeError,\n            NotImplementedError,\n            AttributeError,\n        ) as e:\n            await logger.aerror(f\"Error with structured chat agent: {e}\")\n            # Fallback to regular agent\n            content_str = \"No content returned from agent\"\n            return Data(data={\"content\": content_str, \"error\": str(e)})\n\n        # Process with structured output validation\n        try:\n            structured_output = await self.build_structured_output_base(content)\n\n            # Handle different output formats\n            if isinstance(structured_output, list) and structured_output:\n                if len(structured_output) == 1:\n                    return Data(data=structured_output[0])\n                return Data(data={\"results\": structured_output})\n            if isinstance(structured_output, dict):\n                return Data(data=structured_output)\n            return Data(data={\"content\": content})\n\n        except (ValueError, TypeError) as e:\n            await logger.aerror(f\"Error in structured output processing: {e}\")\n            return Data(data={\"content\": content, \"error\": str(e)})\n\n    async def get_memory_data(self):\n        # TODO: This is a temporary fix to avoid message duplication. We should develop a function for this.\n        messages = (\n            await MemoryComponent(**self.get_base_args())\n            .set(\n                session_id=self.graph.session_id,\n                context_id=self.context_id,\n                order=\"Ascending\",\n                n_messages=self.n_messages,\n            )\n            .retrieve_messages()\n        )\n        return [\n            message for message in messages if getattr(message, \"id\", None) != getattr(self.input_value, \"id\", None)\n        ]\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self,\n        build_config: dotdict,\n        field_value: list[dict],\n        field_name: str | None = None,\n    ) -> dotdict:\n        # Update model options with caching (for all field changes)\n        # Agents require tool calling, so filter for only tool-calling capable models\n        def get_tool_calling_model_options(user_id=None):\n            return get_language_model_options(user_id=user_id, tool_calling=True)\n\n        build_config = update_model_options_in_build_config(\n            component=self,\n            build_config=dict(build_config),\n            cache_key_prefix=\"language_model_options_tool_calling\",\n            get_options_func=get_tool_calling_model_options,\n            field_name=field_name,\n            field_value=field_value,\n        )\n        build_config = dotdict(build_config)\n\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        if field_name == \"model\":\n            self.log(str(field_value))\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"model\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n\n    async def _get_tools(self) -> list[Tool]:\n        component_toolkit = get_component_toolkit()\n        tools_names = self._build_tools_names()\n        agent_description = self.get_tool_description()\n        # TODO: Agent Description Depreciated Feature to be removed\n        description = f\"{agent_description}{tools_names}\"\n\n        tools = component_toolkit(component=self).get_tools(\n            tool_name=\"Call_Agent\",\n            tool_description=description,\n            # here we do not use the shared callbacks as we are exposing the agent as a tool\n            callbacks=self.get_langchain_callbacks(),\n        )\n        if hasattr(self, \"tools_metadata\"):\n            tools = component_toolkit(component=self, metadata=self.tools_metadata).update_tools_metadata(tools=tools)\n\n        return tools\n"
              },
              "context_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Context ID",
                "dynamic": false,
                "info": "The context ID of the chat. Adds an extra layer to the local memory.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "context_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "format_instructions": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Output Format Instructions",
                "dynamic": false,
                "info": "Generic Template for structured output formatting. Valid only with Structured response.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "format_instructions",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "You are an AI that extracts structured JSON objects from unstructured text. Use a predefined schema with expected types (str, int, float, bool, dict). Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. Fill missing or ambiguous values with defaults: null for missing values. Remove exact duplicates but keep variations that have different field values. Always return valid JSON in the expected format, never throw errors. If multiple objects can be extracted, return them all in the structured format."
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "handle_parsing_errors",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "is_refresh": false,
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": 15
              },
              "model": {
                "_input_type": "ModelInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "external_options": {
                  "fields": {
                    "data": {
                      "node": {
                        "display_name": "Connect other models",
                        "icon": "CornerDownLeft",
                        "name": "connect_other_models"
                      }
                    }
                  }
                },
                "info": "Select your model provider",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "model_type": "language",
                "name": "model",
                "options": [
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-opus-4-5-20251101",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-haiku-4-5-20251001",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-sonnet-4-5-20250929",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-opus-4-1-20250805",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-opus-4-20250514",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5.1"
                      ]
                    },
                    "name": "gpt-5.1",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5"
                      ]
                    },
                    "name": "gpt-5",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5-mini"
                      ]
                    },
                    "name": "gpt-5-mini",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5-nano"
                      ]
                    },
                    "name": "gpt-5-nano",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4o-mini",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "Google Generative AI",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "is_disabled_provider": true,
                      "variable_name": "GOOGLE_API_KEY"
                    },
                    "name": "__enable_provider_Google Generative AI__",
                    "provider": "Google Generative AI"
                  },
                  {
                    "category": "Ollama",
                    "icon": "Ollama",
                    "metadata": {
                      "is_disabled_provider": true,
                      "variable_name": "OLLAMA_BASE_URL"
                    },
                    "name": "__enable_provider_Ollama__",
                    "provider": "Ollama"
                  },
                  {
                    "category": "IBM WatsonX",
                    "icon": "WatsonxAI",
                    "metadata": {
                      "is_disabled_provider": true,
                      "variable_name": "WATSONX_APIKEY"
                    },
                    "name": "__enable_provider_IBM WatsonX__",
                    "provider": "IBM WatsonX"
                  }
                ],
                "override_skip": false,
                "placeholder": "Setup Provider",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "track_in_telemetry": false,
                "type": "model",
                "value": [
                  {
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-sonnet-4-5-20250929",
                    "provider": "Anthropic"
                  }
                ]
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Chat History Messages",
                "dynamic": false,
                "info": "Number of chat history messages to retrieve.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": 100
              },
              "output_schema": {
                "_input_type": "TableInput",
                "advanced": true,
                "display_name": "Output Schema",
                "dynamic": false,
                "info": "Schema Validation: Define the structure and data types for structured output. No validation if no output schema.",
                "input_types": [],
                "is_list": true,
                "list_add_label": "Add More",
                "name": "output_schema",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "table_icon": "Table",
                "table_schema": [
                  {
                    "default": "field",
                    "description": "Specify the name of the output field.",
                    "display_name": "Name",
                    "edit_mode": "inline",
                    "formatter": "text",
                    "name": "name",
                    "type": "str"
                  },
                  {
                    "default": "description of field",
                    "description": "Describe the purpose of the output field.",
                    "display_name": "Description",
                    "edit_mode": "popover",
                    "formatter": "text",
                    "name": "description",
                    "type": "str"
                  },
                  {
                    "default": "str",
                    "description": "Indicate the data type of the output field (e.g., str, int, float, bool, dict).",
                    "display_name": "Type",
                    "edit_mode": "inline",
                    "formatter": "text",
                    "name": "type",
                    "options": [
                      "str",
                      "int",
                      "float",
                      "bool",
                      "dict"
                    ],
                    "type": "str"
                  },
                  {
                    "default": "False",
                    "description": "Set to True if this output field should be a list of the specified type.",
                    "display_name": "As List",
                    "edit_mode": "inline",
                    "formatter": "text",
                    "name": "multiple",
                    "type": "boolean"
                  }
                ],
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": []
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Agent Instructions",
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "You are a helpful assistant to create Langflow custom components. Follow the instructions below and the examples.\n\n---\n\nCreate custom Python components\n\nCreate your own custom components to add any functionality you need to Langflow, from API integrations to data processing.\n\nIn Langflow's node-based environment, each node is a \"component\" that performs discrete functions. Custom components in Langflow are built upon:\n\nThe Python class that inherits from Component.\nClass-level attributes that identify and describe the component.\nInput and output lists that determine data flow.\nMethods that define the component's behavior and logic.\nInternal variables for Error handling and logging\nUse the Custom component quickstart to add an example component to Langflow, and then use the reference guide that follows for more advanced component customization.\n\nCustom component quickstart\n\nCreate a custom DataFrameProcessor component by creating a Python file, saving it in the correct folder, including an __init__.py file, and loading it into Langflow.\n\nCreate a Python file\n\nCreate a Python file for your component, such as dataframe_processor.py.\n\nWrite your component as an object of the Component class. Create a new class that inherits from Component and override the base class's methods.\n\nBACKWARDS COMPATIBILITY\nThe lfx import path replaced the import from langflow.custom import Component in Langflow 1.7, but the original input is still compatible and works the same way.\nfrom typing import Any, Dict, Optional\nimport pandas as pd\nfrom lfx.custom.custom_component.component import Component\n\nclass DataFrameProcessor(Component):\n    \"\"\"A component that processes pandas DataFrames with various operations.\"\"\"\n\nDefine class attributes to provide information about your custom component:\n\nfrom typing import Any, Dict, Optional\nimport pandas as pd\nfrom lfx.custom.custom_component.component import Component\n\nclass DataFrameProcessor(Component):\n    \"\"\"A component that processes pandas DataFrames with various operations.\"\"\"\n\n    display_name: str = \"DataFrame Processor\"\n    description: str = \"Process and transform pandas DataFrames with various operations like filtering, sorting, and aggregation.\"\n    documentation: str = \"https://docs.langflow.org/components-dataframe-processor\"\n    icon: str = \"DataframeIcon\"\n    priority: int = 100\n    name: str = \"dataframe_processor\"\n\ndisplay_name: A user-friendly name shown in the visual editor.\ndescription: A brief description of what your component does.\ndocumentation: A link to detailed documentation.\nicon: An emoji or icon identifier for visual representation. Langflow uses Lucide for icons. To assign an icon to your component, set the icon attribute to the name of a Lucide icon as a string, such as icon = \"file-text\". Langflow renders icons from the Lucide library automatically. For more information, see Contributing bundles.\npriority: An optional integer to control display order. Lower numbers appear first.\nname: An optional internal identifier that defaults to class name.\nDefine the component's interface by specifying its inputs, outputs, and the method that will process them. The method name must match the method field in your outputs list, as this is how Langflow knows which method to call to generate each output.\n\nThis example creates a minimal custom component skeleton.\n\nfrom typing import Any, Dict, Optional\nimport pandas as pd\nfrom lfx.custom.custom_component.component import Component\n\nclass DataFrameProcessor(Component):\n    \"\"\"A component that processes pandas DataFrames with various operations.\"\"\"\n\n    display_name: str = \"DataFrame Processor\"\n    description: str = \"Process and transform pandas DataFrames with various operations like filtering, sorting, and aggregation.\"\n    documentation: str = \"https://docs.langflow.org/components-dataframe-processor\"\n    icon: str = \"DataframeIcon\"\n    priority: int = 100\n    name: str = \"dataframe_processor\"\n\n    # input and output lists\n    inputs = []\n    outputs = []\n\n    # method\n    def some_output_method(self):\n        return ...\n\nSave the custom component\n\nSave the custom component in the Langflow directory where the UI will discover and load it.\n\nBy default, Langflow looks for custom components in the src/lfx/src/lfx/components directory.\n\nWhen saving components in the default directory, components must be organized in a specific directory structure to be properly loaded and displayed in the visual editor.\n\nComponents must be placed inside category folders, not directly in the base directory.\n\nThe category folder name determines where the component appears in the Langflow  Core components menu. For example, to add the example DataFrameProcessor component to the Data category, place it in the data subfolder:\n\nsrc/lfx/src/lfx/components/\n    └── data/                      # Category folder (determines menu location)\n        ├── __init__.py            # Required - makes it a Python package\n        └── dataframe_processor.py # Your custom component file\n\nIf you're creating custom components in a different location using the LANGFLOW_COMPONENTS_PATH environment variable, components must be similarly organized in a specific directory structure to be displayed in the visual editor.\n\n/your/custom/components/path/    # Base directory set by LANGFLOW_COMPONENTS_PATH\n    └── category_name/\n        ├── __init__.py\n        └── custom_component.py\n\nYou can have multiple category folders to organize components into different categories:\n\n/app/custom_components/\n    ├── data/\n    │   ├── __init__.py\n    │   └── dataframe_processor.py\n    └── tools/\n        ├── __init__.py\n        └── custom_tool.py\n\nCreate the __init__.py file\n\nEach category directory must contain an __init__.py file for Langflow to properly recognize and load the components. This is a Python package requirement that ensures the directory is treated as a module.\n\nTo include the DataFrameProcessor component, create a file named __init__.py in your component's directory with the following content.\n\nfrom .dataframe_processor import DataFrameProcessor\n\n__all__ = [\"DataFrameProcessor\"]\n\nLazy load the DataFrameProcessor component\nLoad your component\n\nEnsure the application builds your component.\n\nTo rebuild the backend and frontend, run make install_frontend && make build_frontend && make install_backend && uv run langflow run --port 7860.\n\nRefresh the frontend application. Your new DataFrameProcessor component is available in the  Core components menu under the Data category in the visual editor.\n\nDocker deployment\n\nWhen running Langflow in Docker, mount your custom components directory and set the LANGFLOW_COMPONENTS_PATH environment variable in the docker run command to point to the custom components directory.\n\ndocker run -d \\\n  --name langflow \\\n  -p 7860:7860 \\\n  -v ./custom_components:/app/custom_components \\\n  -e LANGFLOW_COMPONENTS_PATH=/app/custom_components \\\n  langflowai/langflow:latest\n\nCreate the same custom components directory structure as the example in Save the custom component.\n\n/app/custom_components/          # LANGFLOW_COMPONENTS_PATH\n    └── data/\n        ├── __init__.py\n        └── dataframe_processor.py\n\nHow components execute\n\nLangflow's engine manages:\n\nInstantiation: A component is created and internal structures are initialized.\nAssigning Inputs: Values from the visual editor or connections are assigned to component fields.\nValidation and Setup: Optional hooks like _pre_run_setup.\nOutputs Generation: run() or build_results() triggers output methods.\nYou can customize execution by overriding these optional hooks in your custom component code.\n\n_pre_run_setup() - Used during Validation and Setup. Add this method inside your component class to initialize component state before execution begins:\n\nclass MyComponent(Component):\n    # ... your inputs, outputs, and other attributes ...\n\n    def _pre_run_setup(self):\n        if not hasattr(self, \"_initialized\"):\n            self._initialized = True\n            self.iteration = 0\n\nOverride run or _run - Used during Outputs Generation. Add this method inside your component class to customize the main execution logic:\n\nclass MyComponent(Component):\n\n    async def_run(self):\n        # Custom execution logic here\n        # This runs instead of the default output method calls\n        pass\n\nStore data in self.ctx. Use self.ctx in any of your component methods to share data between method calls.\n\nclass MyComponent(Component):\n\n    def _pre_run_setup(self):\n        # Initialize counter in setup\n        self.ctx[\"processed_items\"] = 0\n\n    def process_data(self) -> Data:\n        # Increment counter during processing\n        self.ctx[\"processed_items\"] += 1\n        return Data(data={\"item\": f\"processed {self.ctx['processed_items']}\"})\n\n    def get_summary(self) -> Data:\n        # Access counter in different method\n        total = self.ctx[\"processed_items\"]\n        return Data(data={\"summary\": f\"Processed {total} items total\"})\n\nInputs and outputs\n\nInputs and outputs are class-level configurations that define how data flows through the component, how it appears in the visual editor, and how connections to other components are validated.\n\nInputs\n\nInputs are defined in a class-level inputs list. When Langflow loads the component, it uses this list to render component fields and ports in the visual editor. Users or other components provide values or connections to fill these inputs.\n\nAn input is usually an instance of a class from lfx.io (such as StrInput, DataInput, or MessageTextInput).\n\nFor example, this component has three inputs: a text field (StrInput), a Boolean toggle (BoolInput), and a dropdown selection (DropdownInput).\n\nfrom lfx.io import StrInput, BoolInput, DropdownInput\n\ninputs = [\n    StrInput(name=\"title\", display_name=\"Title\"),\n    BoolInput(name=\"enabled\", display_name=\"Enabled\", value=True),\n    DropdownInput(name=\"mode\", display_name=\"Mode\", options=[\"Fast\", \"Safe\", \"Experimental\"], value=\"Safe\")\n]\n\nThe StrInput creates a single-line text field for entering text. The name=\"title\" parameter means you access this value in your component methods with self.title, while display_name=\"Title\" shows \"Title\" as the label in the visual editor.\n\nThe BoolInput creates a boolean toggle that's enabled by default with value=True. Users can turn this on or off, and you access the current state with self.enabled.\n\nThe DropdownInput provides a selection menu with three predefined options: \"Fast\", \"Safe\", and \"Experimental\". The value=\"Safe\" sets \"Safe\" as the default selection, and you access the user's choice with self.mode.\n\nFor a list of all available parameters, see the BaseInputMixin definition in the Langflow codebase.\n\nFor a list of all available input types, see the input type definitions in the Langflow codebase.\n\nfrom lfx.io import StrInput, DataInput, MultilineInput, IntInput, BoolInput, DropdownInput, FileInput, CodeInput, ModelInput, HandleInput, Output\n\nOutputs\n\nOutputs are defined in a class-level outputs list. When Langflow renders a component, each output becomes a connector point in the visual editor. When you connect something to an output, Langflow automatically calls the corresponding method and passes the returned object to the next component.\n\nAn output is usually an instance of Output from lfx.io.\n\nFor example, this component has one output that returns a DataFrame:\n\nfrom lfx.io import Output\nfrom lfx.schema import DataFrame\n\noutputs = [\n    Output(\n        name=\"df_out\",\n        display_name=\"DataFrame Output\",\n        method=\"build_df\"\n    )\n]\n\ndef build_df(self) -> DataFrame:\n    # Process data and return DataFrame\n    df = DataFrame({\"col1\": [1, 2], \"col2\": [3, 4]})\n    self.status = f\"Built DataFrame with {len(df)} rows.\"\n    return df\n\nThe Output creates a connector point in the visual editor labeled DataFrame Output. The name=\"df_out\" parameter identifies this output, while display_name=\"DataFrame Output\" shows the label in the UI. The method=\"build_df\" parameter tells Langflow to call the build_df method when this output is connected to another component.\n\nThe build_df method processes data and returns a DataFrame. The -> DataFrame type annotation helps Langflow validate connections and provides color-coding in the visual editor. You can also set self.status to show progress messages in the UI.\n\nFor a complete list of all available parameters, see the Output class definition in the Langflow codebase. Common parameters include:\n\nAdditional return types:\n\nMessage: Structured chat messages\nData: Flexible object with .data and optional .text\nDataFrame: Tabular data (pandas DataFrame subclass)\nPrimitive types: str, int, bool, not recommended for type consistency\nAssociated methods\n\nEach output is linked to a method where the output method name must match the method name. The method typically returns objects like Message, Data, or DataFrame, and can use inputs with self.<input_name>.\n\nFor example, the Output defines a connector point called file_contents that will call the read_file method when connected. The read_file method accesses the filename input with self.filename, reads the file content, sets a status message, and returns the content wrapped in a Data object.\n\nOutput(\n    name=\"file_contents\",\n    display_name=\"File Contents\",\n    method=\"read_file\"\n)\n\ndef read_file(self) -> Data:\n    path = self.filename\n    with open(path, \"r\") as f:\n        content = f.read()\n    self.status = f\"Read {len(content)} chars from {path}\"\n    return Data(data={\"content\": content})\n\nComponents with multiple outputs\n\nA component can define multiple outputs. Each output can have a different corresponding method.\n\nFor example:\n\noutputs = [\n    Output(display_name=\"Processed Data\", name=\"processed_data\", method=\"process_data\"),\n    Output(display_name=\"Debug Info\", name=\"debug_info\", method=\"provide_debug_info\"),\n]\n\nBy default, components in Langflow that produce multiple outputs only allow one output selection in the visual editor. The component will have only one output port where the user can select the preferred output type.\n\nThis behavior is controlled by the group_outputs parameter:\n\ngroup_outputs=False (default): When a component has more than one output and group_outputs is false or not set, the outputs are grouped in the visual editor, and the user must select one.\n\nUse this option when the component is expected to return only one type of output when used in a flow.\n\ngroup_outputs=True: All outputs are available simultaneously in the visual editor. The component has one output port for each output, and the user can connect zero or more outputs to other components.\n\nUse this option when the component is expected to return multiple values that are used in parallel by downstream components or processes.\n\nFalse or not set\nTrue\nIn this example, the visual editor provides a single output port, and the user can select one of the outputs. Since group_outputs=False is the default behavior, it doesn't need to be explicitly set in the component, as shown in this example.\n\noutputs = [\n    Output(\n        name=\"structured_output\",\n        display_name=\"Structured Output\",\n        method=\"build_structured_output\",\n    ),\n    Output(\n        name=\"dataframe_output\",\n        display_name=\"DataFrame Output\",\n        method=\"build_structured_dataframe\",\n    ),\n]\n\nTool mode\n\nComponents that support Tool Mode can be used as standalone components (when not in Tool Mode) or as tools for other components with a Tools input, such as Agent components.\n\nYou can allow a custom component to support Tool Mode by setting tool_mode=True:\n\ninputs = [\n    MessageTextInput(\n        name=\"message\",\n        display_name=\"Mensage\",\n        info=\"Enter the message that will be processed directly by the tool\",\n        tool_mode=True,\n    ),\n]\n\nTyped annotations\n\nIn Langflow, typed annotations allow Langflow to visually guide users and maintain flow consistency. Always annotate your output methods with return types like -> Data, -> Message, or -> DataFrame to enable proper visual editor color-coding and validation. Use Data, Message, or DataFrame wrappers instead of returning plain structures for better consistency. Stay consistent with types across your components to make flows predictable and easier to build.\n\nTyped annotations provide color-coding where outputs like -> Data or -> Message get distinct colors, automatic validation that blocks incompatible connections, and improved readability for users to quickly understand data flow between components.\n\nCommon return types\n\nMessage\nData\nDataFrame\nPrimitive Types\nFor chat-style outputs. Connects to any of several Message-compatible inputs.\n\ndef produce_message(self) -> Message:\n    return Message(text=\"Hello! from typed method!\", sender=\"System\")\n\nEnable dynamic fields\n\nIn Langflow, dynamic fields allow inputs to change or appear based on user interactions. You can make an input dynamic by setting dynamic=True. Optionally, setting real_time_refresh=True triggers the update_build_config method to adjust the input's visibility or properties in real time, creating a contextual visual editor experience that only exposes relevant fields based on the user's choices.\n\nIn this example, the operator field triggers updates with real_time_refresh=True. The regex_pattern field is initially hidden and controlled with dynamic=True.\n\nfrom lfx.custom import Component\nfrom lfx.io import DropdownInput, StrInput\n\nclass RegexRouter(Component):\n    display_name = \"Regex Router\"\n    description = \"Demonstrates dynamic fields for regex input.\"\n\n    inputs = [\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"contains\", \"regex\"],\n            value=\"equals\",\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"regex_pattern\",\n            display_name=\"Regex Pattern\",\n            info=\"Used if operator='regex'\",\n            dynamic=True,\n            show=False,\n        ),\n    ]\n\nShow or hide fields based on user selections\n\nWhen a user changes a field with real_time_refresh=True, Langflow calls your update_build_config method.\n\nThis method lets you show, hide, or modify other fields based on what the user selected.\n\nThis example shows the regex_pattern field only when the user selects \"regex\" from the operator dropdown.\n\ndef update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n    if field_name == \"operator\":\n        if field_value == \"regex\":\n            build_config[\"regex_pattern\"][\"show\"] = True\n        else:\n            build_config[\"regex_pattern\"][\"show\"] = False\n    return build_config\n\nYou can modify additional field properties in update_build_config other than just show and hide.\n\nrequired: Make fields required or optional dynamically\n\nif field_value == \"regex\":\n    build_config[\"regex_pattern\"][\"required\"] = True\nelse:\n    build_config[\"regex_pattern\"][\"required\"] = False\n\nadvanced: Move fields to the \"Advanced\" section\n\nif field_value == \"experimental\":\n    build_config[\"regex_pattern\"][\"advanced\"] = False  # Show in main section\nelse:\n    build_config[\"regex_pattern\"][\"advanced\"] = True   # Hide in advanced\n\noptions: Change dropdown options based on other selections\n\nif field_value == \"regex\":\n    build_config[\"operator\"][\"options\"] = [\"regex\", \"contains\", \"starts_with\"]\nelse:\n    build_config[\"operator\"][\"options\"] = [\"equals\", \"contains\", \"not_equals\"]\n\nError handling and logging\n\nYou can raise standard Python exceptions such as ValueError or specialized exceptions like ToolException when validation fails. Langflow automatically catches these and displays appropriate error messages in the visual editor, helping users quickly identify what went wrong.\n\ndef compute_result(self) -> str:\n    if not self.user_input:\n        raise ValueError(\"No input provided.\")\n    # ...\n\nAlternatively, instead of stopping a flow abruptly, you can return a Data object containing an \"error\" field. This approach allows the flow to continue operating and enables downstream components to detect and handle the error gracefully.\n\ndef run_model(self) -> Data:\n    try:\n        # ...\n    except Exception as e:\n        return Data(data={\"error\": str(e)})\n\nLangflow provides several tools to help you debug and manage component execution. You can use self.status to display short messages about execution results directly in the visual editor, making troubleshooting easier for users.\n\ndef parse_data(self) -> Data:\n# ...\nself.status = f\"Parsed {len(rows)} rows successfully.\"\nreturn Data(data={\"rows\": rows})\n\nYou can halt individual output paths when certain conditions fail using self.stop(), without stopping other outputs from the same component.\n\nThis example stops the output if the user input is empty, preventing the component from processing invalid data.\n\ndef some_output(self) -> Data:\nif not self.user_input or len(self.user_input.strip()) == 0:\n    self.stop(\"some_output\")\n    return Data(data={\"error\": \"Empty input provided\"})\n\nYou can log key execution details inside components using self.log(). These logs are stored as structured data and displayed in the \"Logs\" or \"Events\" section of the component's detail view, and can be accessed later through the Logs button in the visual editor or exported files.\n\nComponent logs are distinct from Langflow's main application logging system. self.log() creates component-specific logs that appear in the UI, while Langflow's main logging system uses structlog for application-level logging that outputs to langflow.log files. For more information, see Logs.\n\n---\n\nBelow is the base class:\n\n\n\nfrom __future__ import annotations\n\nimport ast\nimport asyncio\nimport inspect\nfrom collections.abc import AsyncIterator, Iterator\nfrom copy import deepcopy\nfrom textwrap import dedent\nfrom typing import TYPE_CHECKING, Any, ClassVar, NamedTuple, get_type_hints\nfrom uuid import UUID\n\nimport nanoid\nimport pandas as pd\nimport yaml\nfrom langchain_core.tools import StructuredTool\nfrom pydantic import BaseModel, ValidationError\n\nfrom lfx.base.tools.constants import (\n    TOOL_OUTPUT_DISPLAY_NAME,\n    TOOL_OUTPUT_NAME,\n    TOOLS_METADATA_INFO,\n    TOOLS_METADATA_INPUT_NAME,\n)\nfrom lfx.custom.tree_visitor import RequiredInputsVisitor\nfrom lfx.exceptions.component import StreamingError\nfrom lfx.field_typing import Tool  # noqa: TC001\n\n# Lazy import to avoid circular dependency\n# from lfx.graph.state.model import create_state_model\n# Lazy import to avoid circular dependency\n# from lfx.graph.utils import has_chat_output\nfrom lfx.helpers.custom import format_type\nfrom lfx.memory import astore_message, aupdate_messages, delete_message\nfrom lfx.schema.artifact import get_artifact_type, post_process_raw\nfrom lfx.schema.data import Data\nfrom lfx.schema.log import Log\nfrom lfx.schema.message import ErrorMessage, Message\nfrom lfx.schema.properties import Source\nfrom lfx.serialization.serialization import serialize\nfrom lfx.template.field.base import UNDEFINED, Input, Output\nfrom lfx.template.frontend_node.custom_components import ComponentFrontendNode\nfrom lfx.utils.async_helpers import run_until_complete\nfrom lfx.utils.util import find_closest_match\n\nfrom .custom_component import CustomComponent\n\nif TYPE_CHECKING:\n    from collections.abc import Callable\n\n    from lfx.base.tools.component_tool import ComponentToolkit\n    from lfx.events.event_manager import EventManager\n    from lfx.graph.edge.schema import EdgeData\n    from lfx.graph.vertex.base import Vertex\n    from lfx.inputs.inputs import InputTypes\n    from lfx.schema.dataframe import DataFrame\n    from lfx.schema.log import LoggableType\n\n\n_ComponentToolkit = None\n\n\ndef get_component_toolkit():\n    global _ComponentToolkit  # noqa: PLW0603\n    if _ComponentToolkit is None:\n        from lfx.base.tools.component_tool import ComponentToolkit\n\n        _ComponentToolkit = ComponentToolkit\n    return _ComponentToolkit\n\n\nBACKWARDS_COMPATIBLE_ATTRIBUTES = [\"user_id\", \"vertex\", \"tracing_service\"]\nCONFIG_ATTRIBUTES = [\"_display_name\", \"_description\", \"_icon\", \"_name\", \"_metadata\"]\n\n\nclass PlaceholderGraph(NamedTuple):\n    \"\"\"A placeholder graph structure for components, providing backwards compatibility.\n\n    and enabling component execution without a full graph object.\n\n    This lightweight structure contains essential information typically found in a complete graph,\n    allowing components to function in isolation or in simplified contexts.\n\n    Attributes:\n        flow_id (str | None): Unique identifier for the flow, if applicable.\n        user_id (str | None): Identifier of the user associated with the flow, if any.\n        session_id (str | None): Identifier for the current session, if applicable.\n        context (dict): Additional contextual information for the component's execution.\n        flow_name (str | None): Name of the flow, if available.\n    \"\"\"\n\n    flow_id: str | None\n    user_id: str | None\n    session_id: str | None\n    context: dict\n    flow_name: str | None\n\n    def get_vertex_neighbors(self, _vertex) -> dict:\n        \"\"\"Returns an empty dictionary since PlaceholderGraph has no edges or neighbors.\n\n        This method exists for compatibility with real Graph objects, allowing components\n        to check graph connectivity even when running in isolation (e.g., in tests).\n\n        Args:\n            _vertex: The vertex to check neighbors for (ignored in placeholder context).\n\n        Returns:\n            An empty dictionary, indicating no neighbors exist.\n        \"\"\"\n        return {}\n\n\nclass Component(CustomComponent):\n    inputs: list[InputTypes] = []\n    outputs: list[Output] = []\n    selected_output: str | None = None\n    code_class_base_inheritance: ClassVar[str] = \"Component\"\n\n    def __init__(self, **kwargs) -> None:\n        # Initialize instance-specific attributes first\n        if overlap := self._there_is_overlap_in_inputs_and_outputs():\n            msg = f\"Inputs and outputs have overlapping names: {overlap}\"\n            raise ValueError(msg)\n        self._output_logs: dict[str, list[Log]] = {}\n        self._current_output: str = \"\"\n        self._metadata: dict = {}\n        self._ctx: dict = {}\n        self._code: str | None = None\n        self._logs: list[Log] = []\n\n        # Initialize component-specific collections\n        self._inputs: dict[str, InputTypes] = {}\n        self._outputs_map: dict[str, Output] = {}\n        self._results: dict[str, Any] = {}\n        self._attributes: dict[str, Any] = {}\n        self._edges: list[EdgeData] = []\n        self._components: list[Component] = []\n        self._event_manager: EventManager | None = None\n        self._state_model = None\n        self._telemetry_input_values: dict[str, Any] | None = None\n\n        # Process input kwargs\n        inputs = {}\n        config = {}\n        for key, value in kwargs.items():\n            if key.startswith(\"_\"):\n                config[key] = value\n            elif key in CONFIG_ATTRIBUTES:\n                config[key[1:]] = value\n            else:\n                inputs[key] = value\n\n        self._parameters = inputs or {}\n        self.set_attributes(self._parameters)\n\n        # Store original inputs and config for reference\n        self.__inputs = inputs\n        self.__config = config or {}\n\n        # Add unique ID if not provided\n        if \"_id\" not in self.__config:\n            self.__config |= {\"_id\": f\"{self.__class__.__name__}-{nanoid.generate(size=5)}\"}\n\n        # Initialize base class\n        super().__init__(**self.__config)\n\n        # Post-initialization setup\n        if hasattr(self, \"_trace_type\"):\n            self.trace_type = self._trace_type\n        if not hasattr(self, \"trace_type\"):\n            self.trace_type = \"chain\"\n\n        # Setup inputs and outputs\n        self.reset_all_output_values()\n        if self.inputs is not None:\n            self.map_inputs(self.inputs)\n        self.map_outputs()\n\n        # Final setup\n        self._set_output_types(list(self._outputs_map.values()))\n        self.set_class_code()\n\n    @classmethod\n    def get_base_inputs(cls):\n        if not hasattr(cls, \"_base_inputs\"):\n            return []\n        return cls._base_inputs\n\n    @classmethod\n    def get_base_outputs(cls):\n        if not hasattr(cls, \"_base_outputs\"):\n            return []\n        return cls._base_outputs\n\n    def get_results(self) -> dict[str, Any]:\n        return self._results\n\n    def get_artifacts(self) -> dict[str, Any]:\n        return self._artifacts\n\n    def get_event_manager(self) -> EventManager | None:\n        return self._event_manager\n\n    def get_undesrcore_inputs(self) -> dict[str, InputTypes]:\n        return self._inputs\n\n    def get_id(self) -> str:\n        return self._id\n\n    def set_id(self, id_: str) -> None:\n        self._id = id_\n\n    def get_edges(self) -> list[EdgeData]:\n        return self._edges\n\n    def get_components(self) -> list[Component]:\n        return self._components\n\n    def get_outputs_map(self) -> dict[str, Output]:\n        return self._outputs_map\n\n    def get_output_logs(self) -> dict[str, Any]:\n        return self._output_logs\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI and other models objects\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    def get_incoming_edge_by_target_param(self, target_param: str) -> str | None:\n        \"\"\"Get the source vertex ID for an incoming edge that targets a specific parameter.\n\n        This method delegates to the underlying vertex to find an incoming edge that connects\n        to the specified target parameter.\n\n        Args:\n            target_param (str): The name of the target parameter to find an incoming edge for\n\n        Returns:\n            str | None: The ID of the source vertex if an incoming edge is found, None otherwise\n        \"\"\"\n        if self._vertex is None:\n            msg = \"Vertex not found. Please build the graph first.\"\n            raise ValueError(msg)\n        return self._vertex.get_incoming_edge_by_target_param(target_param)\n\n    @property\n    def enabled_tools(self) -> list[str] | None:\n        \"\"\"Dynamically determine which tools should be enabled.\n\n        This property can be overridden by subclasses to provide custom tool filtering.\n        By default, it returns None, which means all tools are enabled.\n\n        Returns:\n            list[str] | None: List of tool names or tags to enable, or None to enable all tools.\n        \"\"\"\n        # Default implementation returns None (all tools enabled)\n        # Subclasses can override this to provide custom filtering\n        return None\n\n    def _there_is_overlap_in_inputs_and_outputs(self) -> set[str]:\n        \"\"\"Check the `.name` of inputs and outputs to see if there is overlap.\n\n        Returns:\n            set[str]: Set of names that overlap between inputs and outputs.\n        \"\"\"\n        # Create sets of input and output names for O(1) lookup\n        input_names = {input_.name for input_ in self.inputs if input_.name is not None}\n        output_names = {output.name for output in self.outputs}\n\n        # Return the intersection of the sets\n        return input_names & output_names\n\n    def get_base_args(self):\n        \"\"\"Get the base arguments required for component initialization.\n\n        Returns:\n            dict: A dictionary containing the base arguments:\n                - _user_id: The ID of the current user\n                - _session_id: The ID of the current session\n                - _tracing_service: The tracing service instance for logging/monitoring\n        \"\"\"\n        return {\n            \"_user_id\": self.user_id,\n            \"_session_id\": self.graph.session_id,\n            \"_tracing_service\": self.tracing_service,\n        }\n\n    @property\n    def ctx(self):\n        if not hasattr(self, \"graph\") or self.graph is None:\n            msg = \"Graph not found. Please build the graph first.\"\n            raise ValueError(msg)\n        return self.graph.context\n\n    def add_to_ctx(self, key: str, value: Any, *, overwrite: bool = False) -> None:\n        \"\"\"Add a key-value pair to the context.\n\n        Args:\n            key (str): The key to add.\n            value (Any): The value to associate with the key.\n            overwrite (bool, optional): Whether to overwrite the existing value. Defaults to False.\n\n        Raises:\n            ValueError: If the graph is not built.\n        \"\"\"\n        if not hasattr(self, \"graph\") or self.graph is None:\n            msg = \"Graph not found. Please build the graph first.\"\n            raise ValueError(msg)\n        if key in self.graph.context and not overwrite:\n            msg = f\"Key {key} already exists in context. Set overwrite=True to overwrite.\"\n            raise ValueError(msg)\n        self.graph.context.update({key: value})\n\n    def update_ctx(self, value_dict: dict[str, Any]) -> None:\n        \"\"\"Update the context with a dictionary of values.\n\n        Args:\n            value_dict (dict[str, Any]): The dictionary of values to update.\n\n        Raises:\n            ValueError: If the graph is not built.\n        \"\"\"\n        if not hasattr(self, \"graph\") or self.graph is None:\n            msg = \"Graph not found. Please build the graph first.\"\n            raise ValueError(msg)\n        if not isinstance(value_dict, dict):\n            msg = \"Value dict must be a dictionary\"\n            raise TypeError(msg)\n\n        self.graph.context.update(value_dict)\n\n    def _pre_run_setup(self):\n        pass\n\n    def set_event_manager(self, event_manager: EventManager | None = None) -> None:\n        self._event_manager = event_manager\n\n    def reset_all_output_values(self) -> None:\n        \"\"\"Reset all output values to UNDEFINED.\"\"\"\n        if isinstance(self._outputs_map, dict):\n            for output in self._outputs_map.values():\n                output.value = UNDEFINED\n\n    def _build_state_model(self):\n        if self._state_model:\n            return self._state_model\n        name = self.name or self.__class__.__name__\n        model_name = f\"{name}StateModel\"\n        fields = {}\n        for output in self._outputs_map.values():\n            fields[output.name] = getattr(self, output.method)\n        # Lazy import to avoid circular dependency\n        from lfx.graph.state.model import create_state_model\n\n        self._state_model = create_state_model(model_name=model_name, **fields)\n        return self._state_model\n\n    def get_state_model_instance_getter(self):\n        state_model = self._build_state_model()\n\n        def _instance_getter(_):\n            return state_model()\n\n        _instance_getter.__annotations__[\"return\"] = state_model\n        return _instance_getter\n\n    def __deepcopy__(self, memo: dict) -> Component:\n        if id(self) in memo:\n            return memo[id(self)]\n        kwargs = deepcopy(self.__config, memo)\n        kwargs[\"inputs\"] = deepcopy(self.__inputs, memo)\n        new_component = type(self)(**kwargs)\n        new_component._code = self._code\n        new_component._outputs_map = self._outputs_map\n        new_component._inputs = self._inputs\n        new_component._edges = self._edges\n        new_component._components = self._components\n        new_component._parameters = self._parameters\n        new_component._attributes = self._attributes\n        new_component._output_logs = self._output_logs\n        new_component._logs = self._logs  # type: ignore[attr-defined]\n        memo[id(self)] = new_component\n        return new_component\n\n    def set_class_code(self) -> None:\n        # Get the source code of the calling class\n        if self._code:\n            return\n        try:\n            module = inspect.getmodule(self.__class__)\n            if module is None:\n                msg = \"Could not find module for class\"\n                raise ValueError(msg)\n\n            class_code = inspect.getsource(module)\n            self._code = class_code\n        except (OSError, TypeError) as e:\n            msg = f\"Could not find source code for {self.__class__.__name__}\"\n            raise ValueError(msg) from e\n\n    def set(self, **kwargs):\n        \"\"\"Connects the component to other components or sets parameters and attributes.\n\n        Args:\n            **kwargs: Keyword arguments representing the connections, parameters, and attributes.\n\n        Returns:\n            None\n\n        Raises:\n            KeyError: If the specified input name does not exist.\n        \"\"\"\n        for key, value in kwargs.items():\n            self._process_connection_or_parameters(key, value)\n        return self\n\n    def list_inputs(self):\n        \"\"\"Returns a list of input names.\"\"\"\n        return [_input.name for _input in self.inputs]\n\n    def list_outputs(self):\n        \"\"\"Returns a list of output names.\"\"\"\n        return [_output.name for _output in self._outputs_map.values()]\n\n    async def run(self):\n        \"\"\"Executes the component's logic and returns the result.\n\n        Returns:\n            The result of executing the component's logic.\n        \"\"\"\n        return await self._run()\n\n    def set_vertex(self, vertex: Vertex) -> None:\n        \"\"\"Sets the vertex for the component.\n\n        Args:\n            vertex (Vertex): The vertex to set.\n\n        Returns:\n            None\n        \"\"\"\n        self._vertex = vertex\n\n    def get_input(self, name: str) -> Any:\n        \"\"\"Retrieves the value of the input with the specified name.\n\n        Args:\n            name (str): The name of the input.\n\n        Returns:\n            Any: The value of the input.\n\n        Raises:\n            ValueError: If the input with the specified name is not found.\n        \"\"\"\n        if name in self._inputs:\n            return self._inputs[name]\n        msg = f\"Input {name} not found in {self.__class__.__name__}\"\n        raise ValueError(msg)\n\n    def get_output(self, name: str) -> Any:\n        \"\"\"Retrieves the output with the specified name.\n\n        Args:\n            name (str): The name of the output to retrieve.\n\n        Returns:\n            Any: The output value.\n\n        Raises:\n            ValueError: If the output with the specified name is not found.\n        \"\"\"\n        if name in self._outputs_map:\n            return self._outputs_map[name]\n        msg = f\"Output {name} not found in {self.__class__.__name__}\"\n        raise ValueError(msg)\n\n    def set_on_output(self, name: str, **kwargs) -> None:\n        output = self.get_output(name)\n        for key, value in kwargs.items():\n            if not hasattr(output, key):\n                msg = f\"Output {name} does not have a method {key}\"\n                raise ValueError(msg)\n            setattr(output, key, value)\n\n    def set_output_value(self, name: str, value: Any) -> None:\n        if name in self._outputs_map:\n            self._outputs_map[name].value = value\n        else:\n            msg = f\"Output {name} not found in {self.__class__.__name__}\"\n            raise ValueError(msg)\n\n    def map_outputs(self) -> None:\n        \"\"\"Maps the given list of outputs to the component.\n\n        Args:\n            outputs (List[Output]): The list of outputs to be mapped.\n\n        Raises:\n            ValueError: If the output name is None.\n\n        Returns:\n            None\n        \"\"\"\n        # override outputs (generated from the class code) with vertex outputs\n        # if they exist (generated from the frontend)\n        outputs = []\n        if self._vertex and self._vertex.outputs:\n            for output in self._vertex.outputs:\n                try:\n                    output_ = Output(**output)\n                    outputs.append(output_)\n                except ValidationError as e:\n                    msg = f\"Invalid output: {e}\"\n                    raise ValueError(msg) from e\n        else:\n            outputs = self.outputs\n        for output in outputs:\n            if output.name is None:\n                msg = \"Output name cannot be None.\"\n                raise ValueError(msg)\n            # Deepcopy is required to avoid modifying the original component;\n            # allows each instance of each component to modify its own output\n            self._outputs_map[output.name] = deepcopy(output)\n\n    def map_inputs(self, inputs: list[InputTypes]) -> None:\n        \"\"\"Maps the given inputs to the component.\n\n        Args:\n            inputs (List[InputTypes]): A list of InputTypes objects representing the inputs.\n\n        Raises:\n            ValueError: If the input name is None.\n\n        \"\"\"\n        telemetry_values = {}\n\n        for input_ in inputs:\n            if input_.name is None:\n                msg = self.build_component_error_message(\"Input name cannot be None\")\n                raise ValueError(msg)\n            try:\n                self._inputs[input_.name] = deepcopy(input_)\n            except TypeError:\n                self._inputs[input_.name] = input_\n\n            # Build telemetry data during existing iteration (no performance impact)\n            if self._should_track_input(input_):\n                telemetry_values[input_.name] = serialize(input_.value)\n\n        # Cache for later O(1) retrieval\n        self._telemetry_input_values = telemetry_values if telemetry_values else None\n\n    def _should_track_input(self, input_obj: InputTypes) -> bool:\n        \"\"\"Check if input should be tracked in telemetry.\"\"\"\n        from lfx.inputs.input_mixin import SENSITIVE_FIELD_TYPES\n\n        # Respect opt-in flag (default: False for privacy)\n        if not getattr(input_obj, \"track_in_telemetry\", False):\n            return False\n        # Auto-exclude sensitive field types\n        return not (hasattr(input_obj, \"field_type\") and input_obj.field_type in SENSITIVE_FIELD_TYPES)\n\n    def get_telemetry_input_values(self) -> dict[str, Any] | None:\n        \"\"\"Get cached telemetry input values. O(1) lookup, no iteration.\"\"\"\n        # Return all values including descriptive strings and None\n        return self._telemetry_input_values if self._telemetry_input_values else None\n\n    def validate(self, params: dict) -> None:\n        \"\"\"Validates the component parameters.\n\n        Args:\n            params (dict): A dictionary containing the component parameters.\n\n        Raises:\n            ValueError: If the inputs are not valid.\n            ValueError: If the outputs are not valid.\n        \"\"\"\n        self._validate_inputs(params)\n        self._validate_outputs()\n\n    async def run_and_validate_update_outputs(self, frontend_node: dict, field_name: str, field_value: Any):\n        if inspect.iscoroutinefunction(self.update_outputs):\n            frontend_node = await self.update_outputs(frontend_node, field_name, field_value)\n        else:\n            frontend_node = self.update_outputs(frontend_node, field_name, field_value)\n        if field_name == \"tool_mode\" or frontend_node.get(\"tool_mode\"):\n            is_tool_mode = field_value or frontend_node.get(\"tool_mode\")\n            frontend_node[\"outputs\"] = [self._build_tool_output()] if is_tool_mode else frontend_node[\"outputs\"]\n            if is_tool_mode:\n                frontend_node.setdefault(\"template\", {})\n                frontend_node[\"tool_mode\"] = True\n                tools_metadata_input = await self._build_tools_metadata_input()\n                frontend_node[\"template\"][TOOLS_METADATA_INPUT_NAME] = tools_metadata_input.to_dict()\n                self._append_tool_to_outputs_map()\n            elif \"template\" in frontend_node:\n                frontend_node[\"template\"].pop(TOOLS_METADATA_INPUT_NAME, None)\n        self.tools_metadata = frontend_node.get(\"template\", {}).get(TOOLS_METADATA_INPUT_NAME, {}).get(\"value\")\n        return self._validate_frontend_node(frontend_node)\n\n    def _validate_frontend_node(self, frontend_node: dict):\n        # Check if all outputs are either Output or a valid Output model\n        for index, output in enumerate(frontend_node[\"outputs\"]):\n            if isinstance(output, dict):\n                try:\n                    output_ = Output(**output)\n                    self._set_output_return_type(output_)\n                    output_dict = output_.model_dump()\n                except ValidationError as e:\n                    msg = f\"Invalid output: {e}\"\n                    raise ValueError(msg) from e\n            elif isinstance(output, Output):\n                # we need to serialize it\n                self._set_output_return_type(output)\n                output_dict = output.model_dump()\n            else:\n                msg = f\"Invalid output type: {type(output)}\"\n                raise TypeError(msg)\n            frontend_node[\"outputs\"][index] = output_dict\n        return frontend_node\n\n    def update_outputs(self, frontend_node: dict, field_name: str, field_value: Any) -> dict:  # noqa: ARG002\n        \"\"\"Default implementation for updating outputs based on field changes.\n\n        Subclasses can override this to modify outputs based on field_name and field_value.\n        \"\"\"\n        return frontend_node\n\n    def _set_output_types(self, outputs: list[Output]) -> None:\n        for output in outputs:\n            self._set_output_return_type(output)\n\n    def _set_output_return_type(self, output: Output) -> None:\n        if output.method is None:\n            msg = f\"Output {output.name} does not have a method\"\n            raise ValueError(msg)\n        return_types = self._get_method_return_type(output.method)\n        output.add_types(return_types)\n\n    def _set_output_required_inputs(self) -> None:\n        for output in self.outputs:\n            if not output.method:\n                continue\n            method = getattr(self, output.method, None)\n            if not method or not callable(method):\n                continue\n            try:\n                source_code = inspect.getsource(method)\n                ast_tree = ast.parse(dedent(source_code))\n            except Exception:  # noqa: BLE001\n                ast_tree = ast.parse(dedent(self._code or \"\"))\n\n            visitor = RequiredInputsVisitor(self._inputs)\n            visitor.visit(ast_tree)\n            output.required_inputs = sorted(visitor.required_inputs)\n\n    def get_output_by_method(self, method: Callable):\n        # method is a callable and output.method is a string\n        # we need to find the output that has the same method\n        output = next((output for output in self._outputs_map.values() if output.method == method.__name__), None)\n        if output is None:\n            method_name = method.__name__ if hasattr(method, \"__name__\") else str(method)\n            msg = f\"Output with method {method_name} not found\"\n            raise ValueError(msg)\n        return output\n\n    def _inherits_from_component(self, method: Callable):\n        # check if the method is a method from a class that inherits from Component\n        # and that it is an output of that class\n        return hasattr(method, \"__self__\") and isinstance(method.__self__, Component)\n\n    def _method_is_valid_output(self, method: Callable):\n        # check if the method is a method from a class that inherits from Component\n        # and that it is an output of that class\n        return (\n            hasattr(method, \"__self__\")\n            and isinstance(method.__self__, Component)\n            and method.__self__.get_output_by_method(method)\n        )\n\n    def _build_error_string_from_matching_pairs(self, matching_pairs: list[tuple[Output, Input]]):\n        text = \"\"\n        for output, input_ in matching_pairs:\n            text += f\"{output.name}[{','.join(output.types)}]->{input_.name}[{','.join(input_.input_types or [])}]\\n\"\n        return text\n\n    def _find_matching_output_method(self, input_name: str, value: Component):\n        \"\"\"Find the output method from the given component and input name.\n\n        Find the output method from the given component (`value`) that matches the specified input (`input_name`)\n        in the current component.\n        This method searches through all outputs of the provided component to find outputs whose types match\n        the input types of the specified input in the current component. If exactly one matching output is found,\n        it returns the corresponding method. If multiple matching outputs are found, it raises an error indicating\n        ambiguity. If no matching outputs are found, it raises an error indicating that no suitable output was found.\n\n        Args:\n            input_name (str): The name of the input in the current component to match.\n            value (Component): The component whose outputs are to be considered.\n\n        Returns:\n            Callable: The method corresponding to the matching output.\n\n        Raises:\n            ValueError: If multiple matching outputs are found, if no matching outputs are found,\n                        or if the output method is invalid.\n        \"\"\"\n        # Retrieve all outputs from the given component\n        outputs = value._outputs_map.values()\n        # Prepare to collect matching output-input pairs\n        matching_pairs = []\n        # Get the input object from the current component\n        input_ = self._inputs[input_name]\n        # Iterate over outputs to find matches based on types\n        matching_pairs = [\n            (output, input_)\n            for output in outputs\n            for output_type in output.types\n            # Check if the output type matches the input's accepted types\n            if input_.input_types and output_type in input_.input_types\n        ]\n        # If multiple matches are found, raise an error indicating ambiguity\n        if len(matching_pairs) > 1:\n            matching_pairs_str = self._build_error_string_from_matching_pairs(matching_pairs)\n            msg = self.build_component_error_message(\n                f\"There are multiple outputs from {value.display_name} that can connect to inputs: {matching_pairs_str}\"\n            )\n            raise ValueError(msg)\n        # If no matches are found, raise an error indicating no suitable output\n        if not matching_pairs:\n            msg = self.build_input_error_message(input_name, f\"No matching output from {value.display_name} found\")\n            raise ValueError(msg)\n        # Get the matching output and input pair\n        output, input_ = matching_pairs[0]\n        # Ensure that the output method is a valid method name (string)\n        if not isinstance(output.method, str):\n            msg = self.build_component_error_message(\n                f\"Method {output.method} is not a valid output of {value.display_name}\"\n            )\n            raise TypeError(msg)\n        return getattr(value, output.method)\n\n    def _process_connection_or_parameter(self, key, value) -> None:\n        # Special handling for Loop components: check if we're setting a loop-enabled output\n        if self._is_loop_connection(key, value):\n            self._process_loop_connection(key, value)\n            return\n\n        input_ = self._get_or_create_input(key)\n        # We need to check if callable AND if it is a method from a class that inherits from Component\n        if isinstance(value, Component):\n            # We need to find the Output that can connect to an input of the current component\n            # if there's more than one output that matches, we need to raise an error\n            # because we don't know which one to connect to\n            value = self._find_matching_output_method(key, value)\n        if callable(value) and self._inherits_from_component(value):\n            try:\n                self._method_is_valid_output(value)\n            except ValueError as e:\n                msg = f\"Method {value.__name__} is not a valid output of {value.__self__.__class__.__name__}\"\n                raise ValueError(msg) from e\n            self._connect_to_component(key, value, input_)\n        else:\n            self._set_parameter_or_attribute(key, value)\n\n    def _is_loop_connection(self, key: str, value) -> bool:\n        \"\"\"Check if this is a loop feedback connection.\n\n        A loop connection occurs when:\n        1. The key matches an output name of this component\n        2. That output has allows_loop=True\n        3. The value is a callable method from another component\n        \"\"\"\n        # Check if key matches a loop-enabled output\n        if key not in self._outputs_map:\n            return False\n\n        output = self._outputs_map[key]\n        if not getattr(output, \"allows_loop\", False):\n            return False\n\n        # Check if value is a callable method from a Component\n        return callable(value) and self._inherits_from_component(value)\n\n    def _process_loop_connection(self, key: str, value) -> None:\n        \"\"\"Process a loop feedback connection.\n\n        Creates a special edge that connects the source component's output\n        to this Loop component's loop-enabled output (not an input).\n        \"\"\"\n        try:\n            self._method_is_valid_output(value)\n        except ValueError as e:\n            msg = f\"Method {value.__name__} is not a valid output of {value.__self__.__class__.__name__}\"\n            raise ValueError(msg) from e\n\n        source_component = value.__self__\n        self._components.append(source_component)\n        source_output = source_component.get_output_by_method(value)\n        target_output = self._outputs_map[key]\n\n        # Create special loop feedback edge\n        self._add_loop_edge(source_component, source_output, target_output)\n\n    def _add_loop_edge(self, source_component, source_output, target_output) -> None:\n        \"\"\"Add a special loop feedback edge that targets an output instead of an input.\"\"\"\n        self._edges.append(\n            {\n                \"source\": source_component._id,\n                \"target\": self._id,\n                \"data\": {\n                    \"sourceHandle\": {\n                        \"dataType\": source_component.name or source_component.__class__.__name__,\n                        \"id\": source_component._id,\n                        \"name\": source_output.name,\n                        \"output_types\": source_output.types,\n                    },\n                    \"targetHandle\": {\n                        # Special loop edge structure - targets an output, not an input\n                        \"dataType\": self.name or self.__class__.__name__,\n                        \"id\": self._id,\n                        \"name\": target_output.name,\n                        \"output_types\": target_output.types,\n                    },\n                },\n            }\n        )\n\n    def _process_connection_or_parameters(self, key, value) -> None:\n        # if value is a list of components, we need to process each component\n        # Note this update make sure it is not a list str | int | float | bool | type(None)\n        if isinstance(value, list) and not any(\n            isinstance(val, str | int | float | bool | type(None) | Message | Data | StructuredTool) for val in value\n        ):\n            for val in value:\n                self._process_connection_or_parameter(key, val)\n        else:\n            self._process_connection_or_parameter(key, value)\n\n    def _get_or_create_input(self, key):\n        try:\n            return self._inputs[key]\n        except KeyError:\n            input_ = self._get_fallback_input(name=key, display_name=key)\n            self._inputs[key] = input_\n            self.inputs.append(input_)\n            return input_\n\n    def _connect_to_component(self, key, value, input_) -> None:\n        component = value.__self__\n        self._components.append(component)\n        output = component.get_output_by_method(value)\n        self._add_edge(component, key, output, input_)\n\n    def _add_edge(self, component, key, output, input_) -> None:\n        self._edges.append(\n            {\n                \"source\": component._id,\n                \"target\": self._id,\n                \"data\": {\n                    \"sourceHandle\": {\n                        \"dataType\": component.name or component.__class__.__name__,\n                        \"id\": component._id,\n                        \"name\": output.name,\n                        \"output_types\": output.types,\n                    },\n                    \"targetHandle\": {\n                        \"fieldName\": key,\n                        \"id\": self._id,\n                        \"inputTypes\": input_.input_types,\n                        \"type\": input_.field_type,\n                    },\n                },\n            }\n        )\n\n    def _set_parameter_or_attribute(self, key, value) -> None:\n        if isinstance(value, Component):\n            methods = \", \".join([f\"'{output.method}'\" for output in value.outputs])\n            msg = f\"You set {value.display_name} as value for `{key}`. You should pass one of the following: {methods}\"\n            raise TypeError(msg)\n        self.set_input_value(key, value)\n        self._parameters[key] = value\n        self._attributes[key] = value\n\n    def __call__(self, **kwargs):\n        self.set(**kwargs)\n\n        return run_until_complete(self.run())\n\n    async def _run(self):\n        # Resolve callable inputs\n        for key, _input in self._inputs.items():\n            if asyncio.iscoroutinefunction(_input.value):\n                self._inputs[key].value = await _input.value()\n            elif callable(_input.value):\n                self._inputs[key].value = await asyncio.to_thread(_input.value)\n\n        self.set_attributes({})\n\n        return await self.build_results()\n\n    def __getattr__(self, name: str) -> Any:\n        if \"_attributes\" in self.__dict__ and name in self.__dict__[\"_attributes\"]:\n            # It is a dict of attributes that are not inputs or outputs all the raw data it should have the loop input.\n            return self.__dict__[\"_attributes\"][name]\n        if \"_inputs\" in self.__dict__ and name in self.__dict__[\"_inputs\"]:\n            return self.__dict__[\"_inputs\"][name].value\n        if \"_outputs_map\" in self.__dict__ and name in self.__dict__[\"_outputs_map\"]:\n            return self.__dict__[\"_outputs_map\"][name]\n        if name in BACKWARDS_COMPATIBLE_ATTRIBUTES:\n            return self.__dict__[f\"_{name}\"]\n        if name.startswith(\"_\") and name[1:] in BACKWARDS_COMPATIBLE_ATTRIBUTES:\n            return self.__dict__[name]\n        if name == \"graph\":\n            # If it got up to here it means it was going to raise\n            session_id = self._session_id if hasattr(self, \"_session_id\") else None\n            user_id = self._user_id if hasattr(self, \"_user_id\") else None\n            flow_name = self._flow_name if hasattr(self, \"_flow_name\") else None\n            flow_id = self._flow_id if hasattr(self, \"_flow_id\") else None\n            return PlaceholderGraph(\n                flow_id=flow_id, user_id=str(user_id), session_id=session_id, context={}, flow_name=flow_name\n            )\n        msg = f\"Attribute {name} not found in {self.__class__.__name__}\"\n        raise AttributeError(msg)\n\n    def set_input_value(self, name: str, value: Any) -> None:\n        if name in self._inputs:\n            input_value = self._inputs[name].value\n            if isinstance(input_value, Component):\n                methods = \", \".join([f\"'{output.method}'\" for output in input_value.outputs])\n                msg = self.build_input_error_message(\n                    name,\n                    f\"You set {input_value.display_name} as value. You should pass one of the following: {methods}\",\n                )\n                raise ValueError(msg)\n            if callable(input_value) and hasattr(input_value, \"__self__\"):\n                msg = self.build_input_error_message(\n                    name, f\"Input is connected to {input_value.__self__.display_name}.{input_value.__name__}\"\n                )\n                raise ValueError(msg)\n            try:\n                self._inputs[name].value = value\n            except Exception as e:\n                msg = f\"Error setting input value for {name}: {e}\"\n                raise ValueError(msg) from e\n            if hasattr(self._inputs[name], \"load_from_db\"):\n                self._inputs[name].load_from_db = False\n        else:\n            msg = self.build_component_error_message(f\"Input {name} not found\")\n            raise ValueError(msg)\n\n    def _validate_outputs(self) -> None:\n        # Raise Error if some rule isn't met\n        if self.selected_output is not None and self.selected_output not in self._outputs_map:\n            output_names = \", \".join(list(self._outputs_map.keys()))\n            msg = f\"selected_output '{self.selected_output}' is not valid. Must be one of: {output_names}\"\n            raise ValueError(msg)\n\n    def _map_parameters_on_frontend_node(self, frontend_node: ComponentFrontendNode) -> None:\n        for name, value in self._parameters.items():\n            frontend_node.set_field_value_in_template(name, value)\n\n    def _map_parameters_on_template(self, template: dict) -> None:\n        for name, value in self._parameters.items():\n            try:\n                template[name][\"value\"] = value\n            except KeyError as e:\n                close_match = find_closest_match(name, list(template.keys()))\n                if close_match:\n                    msg = f\"Parameter '{name}' not found in {self.__class__.__name__}. Did you mean '{close_match}'?\"\n                    raise ValueError(msg) from e\n                msg = f\"Parameter {name} not found in {self.__class__.__name__}. \"\n                raise ValueError(msg) from e\n\n    def _get_method_return_type(self, method_name: str) -> list[str]:\n        method = getattr(self, method_name)\n        return_type = get_type_hints(method).get(\"return\")\n        if return_type is None:\n            return []\n        extracted_return_types = self._extract_return_type(return_type)\n        return [format_type(extracted_return_type) for extracted_return_type in extracted_return_types]\n\n    def _update_template(self, frontend_node: dict):\n        return frontend_node\n\n    def to_frontend_node(self):\n        # ! This part here is clunky but we need it like this for\n        # ! backwards compatibility. We can change how prompt component\n        # ! works and then update this later\n        field_config = self.get_template_config(self)\n        frontend_node = ComponentFrontendNode.from_inputs(**field_config)\n        # for key in self._inputs:\n        #     frontend_node.set_field_load_from_db_in_template(key, value=False)\n        self._map_parameters_on_frontend_node(frontend_node)\n\n        frontend_node_dict = frontend_node.to_dict(keep_name=False)\n        frontend_node_dict = self._update_template(frontend_node_dict)\n        self._map_parameters_on_template(frontend_node_dict[\"template\"])\n\n        frontend_node = ComponentFrontendNode.from_dict(frontend_node_dict)\n        if not self._code:\n            self.set_class_code()\n        code_field = Input(\n            dynamic=True,\n            required=True,\n            placeholder=\"\",\n            multiline=True,\n            value=self._code,\n            password=False,\n            name=\"code\",\n            advanced=True,\n            field_type=\"code\",\n            is_list=False,\n        )\n        frontend_node.template.add_field(code_field)\n\n        for output in frontend_node.outputs:\n            if output.types:\n                continue\n            return_types = self._get_method_return_type(output.method)\n            output.add_types(return_types)\n\n        frontend_node.validate_component()\n        frontend_node.set_base_classes_from_outputs()\n\n        # Get the node dictionary and add selected_output if specified\n        node_dict = frontend_node.to_dict(keep_name=False)\n        if self.selected_output is not None:\n            node_dict[\"selected_output\"] = self.selected_output\n\n        return {\n            \"data\": {\n                \"node\": node_dict,\n                \"type\": self.name or self.__class__.__name__,\n                \"id\": self._id,\n            },\n            \"id\": self._id,\n        }\n\n    def _validate_inputs(self, params: dict) -> None:\n        # Params keys are the `name` attribute of the Input objects\n        \"\"\"Validates and assigns input values from the provided parameters dictionary.\n\n        For each parameter matching a defined input, sets the input's value and updates the parameter\n        dictionary with the validated value.\n        \"\"\"\n        for key, value in params.copy().items():\n            if key not in self._inputs:\n                continue\n            input_ = self._inputs[key]\n            # BaseInputMixin has a `validate_assignment=True`\n\n            input_.value = value\n            params[input_.name] = input_.value\n\n    def set_attributes(self, params: dict) -> None:\n        \"\"\"Sets component attributes from the given parameters, preventing conflicts with reserved attribute names.\n\n        Raises:\n            ValueError: If a parameter name matches a reserved attribute not managed in _attributes and its\n            value differs from the current attribute value.\n        \"\"\"\n        self._validate_inputs(params)\n        attributes = {}\n        for key, value in params.items():\n            if key in self.__dict__ and key not in self._attributes and value != getattr(self, key):\n                msg = (\n                    f\"{self.__class__.__name__} defines an input parameter named '{key}' \"\n                    f\"that is a reserved word and cannot be used.\"\n                )\n                raise ValueError(msg)\n            attributes[key] = value\n        for key, input_obj in self._inputs.items():\n            if key not in attributes and key not in self._attributes:\n                attributes[key] = input_obj.value or None\n\n        self._attributes.update(attributes)\n\n    def _set_outputs(self, outputs: list[dict]) -> None:\n        self.outputs = [Output(**output) for output in outputs]\n        for output in self.outputs:\n            setattr(self, output.name, output)\n            self._outputs_map[output.name] = output\n\n    def get_trace_as_inputs(self):\n        predefined_inputs = {\n            input_.name: input_.value\n            for input_ in self.inputs\n            if hasattr(input_, \"trace_as_input\") and input_.trace_as_input\n        }\n        # Runtime inputs\n        runtime_inputs = {name: input_.value for name, input_ in self._inputs.items() if hasattr(input_, \"value\")}\n        return {**predefined_inputs, **runtime_inputs}\n\n    def get_trace_as_metadata(self):\n        return {\n            input_.name: input_.value\n            for input_ in self.inputs\n            if hasattr(input_, \"trace_as_metadata\") and input_.trace_as_metadata\n        }\n\n    async def _build_with_tracing(self):\n        inputs = self.get_trace_as_inputs()\n        metadata = self.get_trace_as_metadata()\n        async with self.tracing_service.trace_component(self, self.trace_name, inputs, metadata):\n            results, artifacts = await self._build_results()\n            self.tracing_service.set_outputs(self.trace_name, results)\n\n        return results, artifacts\n\n    async def _build_without_tracing(self):\n        return await self._build_results()\n\n    async def build_results(self):\n        \"\"\"Build the results of the component.\"\"\"\n        if hasattr(self, \"graph\"):\n            session_id = self.graph.session_id\n        elif hasattr(self, \"_session_id\"):\n            session_id = self._session_id\n        else:\n            session_id = None\n        try:\n            if self.tracing_service:\n                return await self._build_with_tracing()\n            return await self._build_without_tracing()\n        except StreamingError as e:\n            await self.send_error(\n                exception=e.cause,\n                session_id=session_id,\n                trace_name=getattr(self, \"trace_name\", None),\n                source=e.source,\n            )\n            raise e.cause  # noqa: B904\n        except Exception as e:\n            await self.send_error(\n                exception=e,\n                session_id=session_id,\n                source=Source(id=self._id, display_name=self.display_name, source=self.display_name),\n                trace_name=getattr(self, \"trace_name\", None),\n            )\n            raise\n\n    async def _build_results(self) -> tuple[dict, dict]:\n        results, artifacts = {}, {}\n\n        self._pre_run_setup_if_needed()\n        self._handle_tool_mode()\n\n        for output in self._get_outputs_to_process():\n            self._current_output = output.name\n            result = await self._get_output_result(output)\n            results[output.name] = result\n            artifacts[output.name] = self._build_artifact(result)\n            self._log_output(output)\n\n        self._finalize_results(results, artifacts)\n        return results, artifacts\n\n    def _pre_run_setup_if_needed(self):\n        if hasattr(self, \"_pre_run_setup\"):\n            self._pre_run_setup()\n\n    def _handle_tool_mode(self):\n        if (\n            hasattr(self, \"outputs\") and any(getattr(_input, \"tool_mode\", False) for _input in self.inputs)\n        ) or self.add_tool_output:\n            self._append_tool_to_outputs_map()\n\n    def _should_process_output(self, output):\n        \"\"\"Determines whether a given output should be processed based on vertex edge configuration.\n\n        Returns True if the component has no vertex or outgoing edges, or if the output's name is among\n        the vertex's source edge names.\n        \"\"\"\n        if not self._vertex or not self._vertex.outgoing_edges:\n            return True\n        return output.name in self._vertex.edges_source_names\n\n    def _get_outputs_to_process(self):\n        \"\"\"Returns a list of outputs to process, ordered according to self.outputs.\n\n        Outputs are included only if they should be processed, as determined by _should_process_output.\n        First processes outputs in the order defined by self.outputs, then processes any remaining outputs\n        from _outputs_map that weren't in self.outputs.\n\n        Returns:\n            list: Outputs to be processed in the defined order.\n\n        Raises:\n            ValueError: If an output name in self.outputs is not present in _outputs_map.\n        \"\"\"\n        result = []\n        processed_names = set()\n\n        # First process outputs in the order defined by self.outputs\n        for output in self.outputs:\n            output_obj = self._outputs_map.get(output.name, deepcopy(output))\n            if self._should_process_output(output_obj):\n                result.append(output_obj)\n                processed_names.add(output_obj.name)\n\n        # Then process any remaining outputs from _outputs_map\n        for name, output_obj in self._outputs_map.items():\n            if name not in processed_names and self._should_process_output(output_obj):\n                result.append(output_obj)\n\n        return result\n\n    async def _get_output_result(self, output):\n        \"\"\"Computes and returns the result for a given output, applying caching and output options.\n\n        If the output is cached and a value is already defined, returns the cached value. Otherwise,\n        invokes the associated output method asynchronously, applies output options, updates the cache,\n        and returns the result. Raises a ValueError if the output method is not defined, or a TypeError\n        if the method invocation fails.\n        \"\"\"\n        if output.cache and output.value != UNDEFINED:\n            return output.value\n\n        if output.method is None:\n            msg = f'Output \"{output.name}\" does not have a method defined.'\n            raise ValueError(msg)\n\n        method = getattr(self, output.method)\n        try:\n            result = await method() if inspect.iscoroutinefunction(method) else await asyncio.to_thread(method)\n        except TypeError as e:\n            msg = f'Error running method \"{output.method}\": {e}'\n            raise TypeError(msg) from e\n\n        if (\n            self._vertex is not None\n            and isinstance(result, Message)\n            and result.flow_id is None\n            and self._vertex.graph.flow_id is not None\n        ):\n            result.set_flow_id(self._vertex.graph.flow_id)\n        result = output.apply_options(result)\n        output.value = result\n\n        return result\n\n    async def resolve_output(self, output_name: str) -> Any:\n        \"\"\"Resolves and returns the value for a specified output by name.\n\n        If output caching is enabled and a value is already available, returns the cached value;\n        otherwise, computes and returns the output result. Raises a KeyError if the output name\n        does not exist.\n        \"\"\"\n        output = self._outputs_map.get(output_name)\n        if output is None:\n            msg = (\n                f\"Sorry, an output named '{output_name}' could not be found. \"\n                \"Please ensure that the output is correctly configured and try again.\"\n            )\n            raise KeyError(msg)\n        if output.cache and output.value != UNDEFINED:\n            return output.value\n        return await self._get_output_result(output)\n\n    def _build_artifact(self, result):\n        \"\"\"Builds an artifact dictionary containing a string representation, raw data, and type for a result.\n\n        The artifact includes a human-readable representation, the processed raw result, and its determined type.\n        \"\"\"\n        custom_repr = self.custom_repr()\n        if custom_repr is None and isinstance(result, dict | Data | str):\n            custom_repr = result\n        if not isinstance(custom_repr, str):\n            custom_repr = str(custom_repr)\n\n        raw = self._process_raw_result(result)\n        artifact_type = get_artifact_type(self.status or raw, result)\n        raw, artifact_type = post_process_raw(raw, artifact_type)\n        return {\"repr\": custom_repr, \"raw\": raw, \"type\": artifact_type}\n\n    def _process_raw_result(self, result):\n        return self.extract_data(result)\n\n    def extract_data(self, result):\n        \"\"\"Extract the data from the result. this is where the self.status is set.\"\"\"\n        if isinstance(result, Message):\n            self.status = result.get_text()\n            return (\n                self.status if self.status is not None else \"No text available\"\n            )  # Provide a default message if .text_key is missing\n        if hasattr(result, \"data\"):\n            return result.data\n        if hasattr(result, \"model_dump\"):\n            return result.model_dump()\n        if isinstance(result, Data | dict | str):\n            return result.data if isinstance(result, Data) else result\n\n        if self.status:\n            return self.status\n        return result\n\n    def _log_output(self, output):\n        self._output_logs[output.name] = self._logs\n        self._logs = []\n        self._current_output = \"\"\n\n    def _finalize_results(self, results, artifacts):\n        self._artifacts = artifacts\n        self._results = results\n        if self.tracing_service:\n            self.tracing_service.set_outputs(self.trace_name, results)\n\n    def custom_repr(self):\n        if self.repr_value == \"\":\n            self.repr_value = self.status\n        if isinstance(self.repr_value, dict):\n            return yaml.dump(self.repr_value)\n        if isinstance(self.repr_value, str):\n            return self.repr_value\n        if isinstance(self.repr_value, BaseModel) and not isinstance(self.repr_value, Data):\n            return str(self.repr_value)\n        return self.repr_value\n\n    def build_inputs(self):\n        \"\"\"Builds the inputs for the custom component.\n\n        Returns:\n            List[Input]: The list of inputs.\n        \"\"\"\n        # This function is similar to build_config, but it will process the inputs\n        # and return them as a dict with keys being the Input.name and values being the Input.model_dump()\n        self.inputs = self.template_config.get(\"inputs\", [])\n        if not self.inputs:\n            return {}\n        return {_input.name: _input.model_dump(by_alias=True, exclude_none=True) for _input in self.inputs}\n\n    def _get_field_order(self):\n        try:\n            inputs = self.template_config[\"inputs\"]\n            return [field.name for field in inputs]\n        except KeyError:\n            return []\n\n    def build(self, **kwargs) -> None:\n        self.set_attributes(kwargs)\n\n    def _get_fallback_input(self, **kwargs):\n        return Input(**kwargs)\n\n    async def to_toolkit(self) -> list[Tool]:\n        \"\"\"Convert component to a list of tools.\n\n        This is a template method that defines the skeleton of the toolkit creation\n        algorithm. Subclasses can override _get_tools() to provide custom tool\n        implementations while maintaining the metadata update functionality.\n\n        Returns:\n            list[Tool]: A list of tools with updated metadata. Each tool contains:\n                - name: The name of the tool\n                - description: A description of what the tool does\n                - tags: List of tags associated with the tool\n        \"\"\"\n        # Get tools from subclass implementation\n        # Handle both sync and async _get_tools methods\n        if asyncio.iscoroutinefunction(self._get_tools):\n            tools = await self._get_tools()\n        else:\n            tools = self._get_tools()\n\n        if hasattr(self, TOOLS_METADATA_INPUT_NAME):\n            tools = self._filter_tools_by_status(tools=tools, metadata=self.tools_metadata)\n            return self._update_tools_with_metadata(tools=tools, metadata=self.tools_metadata)\n\n        # If no metadata exists yet, filter based on enabled_tools\n        return self._filter_tools_by_status(tools=tools, metadata=None)\n\n    async def _get_tools(self) -> list[Tool]:\n        \"\"\"Get the list of tools for this component.\n\n        This method can be overridden by subclasses to provide custom tool implementations.\n        The default implementation uses ComponentToolkit.\n\n        Returns:\n            list[Tool]: List of tools provided by this component\n        \"\"\"\n        component_toolkit: type[ComponentToolkit] = get_component_toolkit()\n        return component_toolkit(component=self).get_tools(callbacks=self.get_langchain_callbacks())\n\n    def _extract_tools_tags(self, tools_metadata: list[dict]) -> list[str]:\n        \"\"\"Extract the first tag from each tool's metadata.\"\"\"\n        return [tool[\"tags\"][0] for tool in tools_metadata if tool[\"tags\"]]\n\n    def _update_tools_with_metadata(self, tools: list[Tool], metadata: DataFrame | None) -> list[Tool]:\n        \"\"\"Update tools with provided metadata.\"\"\"\n        component_toolkit: type[ComponentToolkit] = get_component_toolkit()\n        return component_toolkit(component=self, metadata=metadata).update_tools_metadata(tools=tools)\n\n    def check_for_tool_tag_change(self, old_tags: list[str], new_tags: list[str]) -> bool:\n        # First check length - if different lengths, they can't be equal\n        if len(old_tags) != len(new_tags):\n            return True\n        # Use set comparison for O(n) average case complexity, earlier the old_tags.sort() != new_tags.sort() was used\n        return set(old_tags) != set(new_tags)\n\n    def _filter_tools_by_status(self, tools: list[Tool], metadata: pd.DataFrame | None) -> list[Tool]:\n        \"\"\"Filter tools based on their status in metadata.\n\n        Args:\n            tools (list[Tool]): List of tools to filter.\n            metadata (list[dict] | None): Tools metadata containing status information.\n\n        Returns:\n            list[Tool]: Filtered list of tools.\n        \"\"\"\n        # Convert metadata to a list of dicts if it's a DataFrame\n        metadata_dict = None  # Initialize as None to avoid lint issues with empty dict\n        if isinstance(metadata, pd.DataFrame):\n            metadata_dict = metadata.to_dict(orient=\"records\")\n\n        # If metadata is None or empty, use enabled_tools\n        if not metadata_dict:\n            enabled = self.enabled_tools\n            return (\n                tools\n                if enabled is None\n                else [\n                    tool for tool in tools if any(enabled_name in [tool.name, *tool.tags] for enabled_name in enabled)\n                ]\n            )\n\n        # Ensure metadata is a list of dicts\n        if not isinstance(metadata_dict, list):\n            return tools\n\n        # Create a mapping of tool names to their status\n        tool_status = {item[\"name\"]: item.get(\"status\", True) for item in metadata_dict}\n        return [tool for tool in tools if tool_status.get(tool.name, True)]\n\n    def _build_tool_data(self, tool: Tool) -> dict:\n        if tool.metadata is None:\n            tool.metadata = {}\n        return {\n            \"name\": tool.name,\n            \"description\": tool.description,\n            \"tags\": tool.tags if hasattr(tool, \"tags\") and tool.tags else [tool.name],\n            \"status\": True,  # Initialize all tools with status True\n            \"display_name\": tool.metadata.get(\"display_name\", tool.name),\n            \"display_description\": tool.metadata.get(\"display_description\", tool.description),\n            \"readonly\": tool.metadata.get(\"readonly\", False),\n            \"args\": tool.args,\n            # \"args_schema\": tool.args_schema,\n        }\n\n    async def _build_tools_metadata_input(self):\n        try:\n            from lfx.inputs.inputs import ToolsInput\n        except ImportError as e:\n            msg = \"Failed to import ToolsInput from lfx.inputs.inputs\"\n            raise ImportError(msg) from e\n        placeholder = None\n        tools = []\n        try:\n            # Handle both sync and async _get_tools methods\n            # TODO: this check can be remomved ince get tools is async\n            if asyncio.iscoroutinefunction(self._get_tools):\n                tools = await self._get_tools()\n            else:\n                tools = self._get_tools()\n\n            placeholder = \"Loading actions...\" if len(tools) == 0 else \"\"\n        except (TimeoutError, asyncio.TimeoutError):\n            placeholder = \"Timeout loading actions\"\n        except (ConnectionError, OSError, ValueError):\n            placeholder = \"Error loading actions\"\n        # Always use the latest tool data\n        tool_data = [self._build_tool_data(tool) for tool in tools]\n        # print(tool_data)\n        if hasattr(self, TOOLS_METADATA_INPUT_NAME):\n            old_tags = self._extract_tools_tags(self.tools_metadata)\n            new_tags = self._extract_tools_tags(tool_data)\n            if self.check_for_tool_tag_change(old_tags, new_tags):\n                # If enabled tools are set, update status based on them\n                enabled = self.enabled_tools\n                if enabled is not None:\n                    for item in tool_data:\n                        item[\"status\"] = any(enabled_name in [item[\"name\"], *item[\"tags\"]] for enabled_name in enabled)\n                self.tools_metadata = tool_data\n            else:\n                # Preserve existing status values\n                existing_status = {item[\"name\"]: item.get(\"status\", True) for item in self.tools_metadata}\n                for item in tool_data:\n                    item[\"status\"] = existing_status.get(item[\"name\"], True)\n                tool_data = self.tools_metadata\n        else:\n            # If enabled tools are set, update status based on them\n            enabled = self.enabled_tools\n            if enabled is not None:\n                for item in tool_data:\n                    item[\"status\"] = any(enabled_name in [item[\"name\"], *item[\"tags\"]] for enabled_name in enabled)\n            self.tools_metadata = tool_data\n\n        return ToolsInput(\n            name=TOOLS_METADATA_INPUT_NAME,\n            placeholder=placeholder,\n            display_name=\"Actions\",\n            info=TOOLS_METADATA_INFO,\n            value=tool_data,\n        )\n\n    def get_project_name(self):\n        if hasattr(self, \"_tracing_service\") and self.tracing_service:\n            return self.tracing_service.project_name\n        return \"Langflow\"\n\n    def log(self, message: LoggableType | list[LoggableType], name: str | None = None) -> None:\n        \"\"\"Logs a message.\n\n        Args:\n            message (LoggableType | list[LoggableType]): The message to log.\n            name (str, optional): The name of the log. Defaults to None.\n        \"\"\"\n        if name is None:\n            name = f\"Log {len(self._logs) + 1}\"\n        log = Log(message=message, type=get_artifact_type(message), name=name)\n        self._logs.append(log)\n        if self.tracing_service and self._vertex:\n            self.tracing_service.add_log(trace_name=self.trace_name, log=log)\n        if self._event_manager is not None and self._current_output:\n            data = log.model_dump()\n            data[\"output\"] = self._current_output\n            data[\"component_id\"] = self._id\n            self._event_manager.on_log(data=data)\n\n    def _append_tool_output(self) -> None:\n        if next((output for output in self.outputs if output.name == TOOL_OUTPUT_NAME), None) is None:\n            self.outputs.append(\n                Output(\n                    name=TOOL_OUTPUT_NAME,\n                    display_name=TOOL_OUTPUT_DISPLAY_NAME,\n                    method=\"to_toolkit\",\n                    types=[\"Tool\"],\n                )\n            )\n\n    def is_connected_to_chat_output(self) -> bool:\n        # Lazy import to avoid circular dependency\n        from lfx.graph.utils import has_chat_output\n\n        return has_chat_output(self.graph.get_vertex_neighbors(self._vertex))\n\n    def is_connected_to_chat_input(self) -> bool:\n        # Lazy import to avoid circular dependency\n        from lfx.graph.utils import has_chat_input\n\n        if self.graph is None:\n            return False\n        return has_chat_input(self.graph.get_vertex_neighbors(self._vertex))\n\n    def _should_skip_message(self, message: Message) -> bool:\n        \"\"\"Check if the message should be skipped based on vertex configuration and message type.\n\n        When a message is skipped:\n        - It is NOT stored in the database\n        - It will NOT have an ID (message.get_id() will return None)\n        - It is still returned to the caller, but no events are sent to the frontend\n\n        Messages are skipped when:\n        - The component is not an input or output vertex\n        - The component is not connected to a Chat Output\n        - The message is not an ErrorMessage\n\n        This prevents intermediate components from cluttering the database with messages\n        that aren't meant to be displayed in the chat UI.\n\n        Returns:\n            bool: True if the message should be skipped, False otherwise\n        \"\"\"\n        return (\n            self._vertex is not None\n            and not (self._vertex.is_output or self._vertex.is_input)\n            and not self.is_connected_to_chat_output()\n            and not isinstance(message, ErrorMessage)\n        )\n\n    def _ensure_message_required_fields(self, message: Message) -> None:\n        \"\"\"Ensure message has required fields for storage (session_id, sender, sender_name).\n\n        Only sets default values if the fields are not already provided.\n        \"\"\"\n        from lfx.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI\n\n        # Set default session_id from graph if not already set\n        if (\n            not message.session_id\n            and hasattr(self, \"graph\")\n            and hasattr(self.graph, \"session_id\")\n            and self.graph.session_id\n        ):\n            session_id = (\n                UUID(self.graph.session_id) if isinstance(self.graph.session_id, str) else self.graph.session_id\n            )\n            message.session_id = session_id\n\n        # Set default sender if not set (preserves existing values)\n        if not message.sender:\n            message.sender = MESSAGE_SENDER_AI\n\n        # Set default sender_name if not set (preserves existing values)\n        if not message.sender_name:\n            message.sender_name = MESSAGE_SENDER_NAME_AI\n\n    async def send_message(self, message: Message, id_: str | None = None, *, skip_db_update: bool = False):\n        \"\"\"Send a message with optional database update control.\n\n        This is the central method for sending messages in Langflow. It handles:\n        - Message storage in the database (unless skipped)\n        - Event emission to the frontend\n        - Streaming support\n        - Error handling and cleanup\n\n        Message ID Rules:\n        - Messages only have an ID after being stored in the database\n        - If _should_skip_message() returns True, the message is not stored and will not have an ID\n        - Always use message.get_id() or message.has_id() to safely check for ID existence\n        - Never access message.id directly without checking if it exists first\n\n        Args:\n            message: The message to send\n            id_: Optional message ID (used for event emission, not database storage)\n            skip_db_update: If True, only update in-memory and send event, skip DB write.\n                           Useful during streaming to avoid excessive DB round-trips.\n                           Note: When skip_db_update=True, the message must already have an ID\n                           (i.e., it must have been stored previously).\n\n        Returns:\n            Message: The stored message (with ID if stored in database, without ID if skipped)\n\n        Raises:\n            ValueError: If skip_db_update=True but message doesn't have an ID\n        \"\"\"\n        if self._should_skip_message(message):\n            return message\n\n        if hasattr(message, \"flow_id\") and isinstance(message.flow_id, str):\n            message.flow_id = UUID(message.flow_id)\n\n        # Ensure required fields for message storage are set\n        self._ensure_message_required_fields(message)\n\n        # If skip_db_update is True and message already has an ID, skip the DB write\n        # This path is used during agent streaming to avoid excessive DB round-trips\n        # When skip_db_update=True, we require the message to already have an ID\n        # because we're updating an existing message, not creating a new one\n        if skip_db_update:\n            if not message.has_id():\n                msg = (\n                    \"skip_db_update=True requires the message to already have an ID. \"\n                    \"The message must have been stored in the database previously.\"\n                )\n                raise ValueError(msg)\n            # Create a fresh Message instance for consistency with normal flow\n            stored_message = await Message.create(**message.model_dump())\n            self._stored_message_id = stored_message.get_id()\n            # Still send the event to update the client in real-time\n            # Note: If this fails, we don't need DB cleanup since we didn't write to DB\n            await self._send_message_event(stored_message, id_=id_)\n        else:\n            # Normal flow: store/update in database\n            stored_message = await self._store_message(message)\n\n            # After _store_message, the message should always have an ID\n            # but we use get_id() for safety\n            self._stored_message_id = stored_message.get_id()\n            try:\n                complete_message = \"\"\n                if (\n                    self._should_stream_message(stored_message, message)\n                    and message is not None\n                    and isinstance(message.text, AsyncIterator | Iterator)\n                ):\n                    complete_message = await self._stream_message(message.text, stored_message)\n                    stored_message.text = complete_message\n                    if complete_message:\n                        stored_message.properties.state = \"complete\"\n                    stored_message = await self._update_stored_message(stored_message)\n                    # Note: We intentionally do NOT send a message event here with state=\"complete\"\n                    # The frontend already has all the content from streaming tokens\n                    # Only the database is updated with the complete state\n                else:\n                    # Only send message event for non-streaming messages\n                    await self._send_message_event(stored_message, id_=id_)\n            except Exception:\n                # remove the message from the database\n                # Only delete if the message has an ID\n                message_id = stored_message.get_id()\n                if message_id:\n                    await delete_message(id_=message_id)\n                raise\n        self.status = stored_message\n        return stored_message\n\n    async def _store_message(self, message: Message) -> Message:\n        flow_id: str | None = None\n        if hasattr(self, \"graph\"):\n            # Convert UUID to str if needed\n            flow_id = str(self.graph.flow_id) if self.graph.flow_id else None\n        stored_messages = await astore_message(message, flow_id=flow_id)\n        if len(stored_messages) != 1:\n            msg = \"Only one message can be stored at a time.\"\n            raise ValueError(msg)\n        stored_message = stored_messages[0]\n        return await Message.create(**stored_message.model_dump())\n\n    async def _send_message_event(self, message: Message, id_: str | None = None, category: str | None = None) -> None:\n        if hasattr(self, \"_event_manager\") and self._event_manager:\n            data_dict = message.model_dump()[\"data\"] if hasattr(message, \"data\") else message.model_dump()\n            if id_ and not data_dict.get(\"id\"):\n                data_dict[\"id\"] = id_\n            category = category or data_dict.get(\"category\", None)\n\n            def _send_event():\n                match category:\n                    case \"error\":\n                        self._event_manager.on_error(data=data_dict)\n                    case \"remove_message\":\n                        # Check if id exists in data_dict before accessing it\n                        if \"id\" in data_dict:\n                            self._event_manager.on_remove_message(data={\"id\": data_dict[\"id\"]})\n                        else:\n                            # If no id, try to get it from the message object or id_ parameter\n                            message_id = getattr(message, \"id\", None) or id_\n                            if message_id:\n                                self._event_manager.on_remove_message(data={\"id\": message_id})\n                    case _:\n                        self._event_manager.on_message(data=data_dict)\n\n            await asyncio.to_thread(_send_event)\n\n    def _should_stream_message(self, stored_message: Message, original_message: Message) -> bool:\n        return bool(\n            hasattr(self, \"_event_manager\")\n            and self._event_manager\n            and stored_message.has_id()\n            and not isinstance(original_message.text, str)\n        )\n\n    async def _update_stored_message(self, message: Message) -> Message:\n        \"\"\"Update the stored message.\"\"\"\n        if hasattr(self, \"_vertex\") and self._vertex is not None and hasattr(self._vertex, \"graph\"):\n            flow_id = (\n                UUID(self._vertex.graph.flow_id)\n                if isinstance(self._vertex.graph.flow_id, str)\n                else self._vertex.graph.flow_id\n            )\n\n            message.flow_id = flow_id\n\n        message_tables = await aupdate_messages(message)\n        if not message_tables:\n            msg = \"Failed to update message\"\n            raise ValueError(msg)\n        message_table = message_tables[0]\n        return await Message.create(**message_table.model_dump())\n\n    async def _stream_message(self, iterator: AsyncIterator | Iterator, message: Message) -> str:\n        if not isinstance(iterator, AsyncIterator | Iterator):\n            msg = \"The message must be an iterator or an async iterator.\"\n            raise TypeError(msg)\n\n        # Get message ID safely - streaming requires an ID\n        message_id = message.get_id()\n        if not message_id:\n            msg = \"Message must have an ID to stream. Messages only have IDs after being stored in the database.\"\n            raise ValueError(msg)\n\n        if isinstance(iterator, AsyncIterator):\n            return await self._handle_async_iterator(iterator, message_id, message)\n        try:\n            complete_message = \"\"\n            first_chunk = True\n            for chunk in iterator:\n                complete_message = await self._process_chunk(\n                    chunk.content, complete_message, message_id, message, first_chunk=first_chunk\n                )\n                first_chunk = False\n        except Exception as e:\n            raise StreamingError(cause=e, source=message.properties.source) from e\n        else:\n            return complete_message\n\n    async def _handle_async_iterator(self, iterator: AsyncIterator, message_id: str, message: Message) -> str:\n        complete_message = \"\"\n        first_chunk = True\n        async for chunk in iterator:\n            complete_message = await self._process_chunk(\n                chunk.content, complete_message, message_id, message, first_chunk=first_chunk\n            )\n            first_chunk = False\n        return complete_message\n\n    async def _process_chunk(\n        self, chunk: str, complete_message: str, message_id: str, message: Message, *, first_chunk: bool = False\n    ) -> str:\n        complete_message += chunk\n        if self._event_manager:\n            if first_chunk:\n                # Send the initial message only on the first chunk\n                msg_copy = message.model_copy()\n                msg_copy.text = complete_message\n                await self._send_message_event(msg_copy, id_=message_id)\n            await asyncio.to_thread(\n                self._event_manager.on_token,\n                data={\n                    \"chunk\": chunk,\n                    \"id\": str(message_id),\n                },\n            )\n        return complete_message\n\n    async def send_error(\n        self,\n        exception: Exception,\n        session_id: str,\n        trace_name: str,\n        source: Source,\n    ) -> Message | None:\n        \"\"\"Send an error message to the frontend.\"\"\"\n        flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        if not session_id:\n            return None\n        error_message = ErrorMessage(\n            flow_id=flow_id,\n            exception=exception,\n            session_id=session_id,\n            trace_name=trace_name,\n            source=source,\n        )\n        await self.send_message(error_message)\n        return error_message\n\n    def _append_tool_to_outputs_map(self):\n        self._outputs_map[TOOL_OUTPUT_NAME] = self._build_tool_output()\n        # add a new input for the tool schema\n        # self.inputs.append(self._build_tool_schema())\n\n    def _build_tool_output(self) -> Output:\n        return Output(name=TOOL_OUTPUT_NAME, display_name=TOOL_OUTPUT_DISPLAY_NAME, method=\"to_toolkit\", types=[\"Tool\"])\n\n    def get_input_display_name(self, input_name: str) -> str:\n        \"\"\"Get the display name of an input.\n\n        This is a public utility method that subclasses can use to get user-friendly\n        display names for inputs when building error messages or UI elements.\n\n        Usage:\n            msg = f\"Input {self.get_input_display_name(input_name)} not found\"\n\n        Args:\n            input_name (str): The name of the input.\n\n        Returns:\n            str: The display name of the input, or the input name if not found.\n        \"\"\"\n        if input_name in self._inputs:\n            return getattr(self._inputs[input_name], \"display_name\", input_name)\n        return input_name\n\n    def get_output_display_name(self, output_name: str) -> str:\n        \"\"\"Get the display name of an output.\n\n        This is a public utility method that subclasses can use to get user-friendly\n        display names for outputs when building error messages or UI elements.\n\n        Args:\n            output_name (str): The name of the output.\n\n        Returns:\n            str: The display name of the output, or the output name if not found.\n        \"\"\"\n        if output_name in self._outputs_map:\n            return getattr(self._outputs_map[output_name], \"display_name\", output_name)\n        return output_name\n\n    def build_input_error_message(self, input_name: str, message: str) -> str:\n        \"\"\"Build an error message for an input.\n\n        This is a public utility method that subclasses can use to create consistent,\n        user-friendly error messages that reference inputs by their display names.\n        The input name is placed at the beginning to ensure it's visible even if the message is truncated.\n\n        Args:\n            input_name (str): The name of the input.\n            message (str): The error message.\n\n        Returns:\n            str: The formatted error message with display name.\n        \"\"\"\n        display_name = self.get_input_display_name(input_name)\n        return f\"[Input: {display_name}] {message}\"\n\n    def build_output_error_message(self, output_name: str, message: str) -> str:\n        \"\"\"Build an error message for an output.\n\n        This is a public utility method that subclasses can use to create consistent,\n        user-friendly error messages that reference outputs by their display names.\n        The output name is placed at the beginning to ensure it's visible even if the message is truncated.\n\n        Args:\n            output_name (str): The name of the output.\n            message (str): The error message.\n\n        Returns:\n            str: The formatted error message with display name.\n        \"\"\"\n        display_name = self.get_output_display_name(output_name)\n        return f\"[Output: {display_name}] {message}\"\n\n    def build_component_error_message(self, message: str) -> str:\n        \"\"\"Build an error message for the component.\n\n        This is a public utility method that subclasses can use to create consistent,\n        user-friendly error messages that reference the component by its display name.\n        The component name is placed at the beginning to ensure it's visible even if the message is truncated.\n\n        Args:\n            message (str): The error message.\n\n        Returns:\n            str: The formatted error message with component display name.\n        \"\"\"\n        return f\"[Component: {self.display_name or self.__class__.__name__}] {message}\"\n\n\ndef _get_component_toolkit():\n    from lfx.base.tools.component_tool import ComponentToolkit\n\n    return ComponentToolkit\n\n\n---\n\nThe user will ask you to create a component. Follow these rules:\n\n- Prioritize Message (MessageTextInput), Data, and DataFrame as input and output types\n- Ensure input parameters surely exist before adding them!!! Example of errors:\n\nError building Component: Extra inputs are not permitted\nTraceback (most recent call last):\n  File \"/Users/rodrigonader/Documents/langflow/src/lfx/src/lfx/custom/validate.py\", line 266, in create_class\n    exec_globals = prepare_global_scope(module)\n  File \"/Users/rodrigonader/Documents/langflow/src/lfx/src/lfx/custom/validate.py\", line 397, in prepare_global_scope\n    exec(compiled_code, exec_globals)\n    ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 60, in <module>\n  File \"<string>\", line 77, in YouTubeCommentsReader\n  File \"/Users/rodrigonader/Documents/langflow/.venv/lib/python3.13/site-packages/pydantic/main.py\", line 253, in __init__\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\npydantic_core._pydantic_core.ValidationError: 1 validation error for StrInput\npassword\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/rodrigonader/Documents/langflow/src/lfx/src/lfx/custom/utils.py\", line 557, in build_custom_component_template\n    has_template_config = hasattr(custom_component, \"template_config\")\n  File \"/Users/rodrigonader/Documents/langflow/src/lfx/src/lfx/custom/custom_component/custom_component.py\", line 443, in template_config\n    self._template_config = self.build_template_config()\n                            ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/Users/rodrigonader/Documents/langflow/src/lfx/src/lfx/custom/custom_component/base_component.py\", line 116, in build_template_config\n    cc_class = eval_custom_component_code(self._code)\n  File \"/Users/rodrigonader/Documents/langflow/src/lfx/src/lfx/custom/eval.py\", line 12, in eval_custom_component_code\n    return validate.create_class(code, class_name)\n           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n  File \"/Users/rodrigonader/Documents/langflow/src/lfx/src/lfx/custom/validate.py\", line 282, in create_class\n    raise ValueError(error_message) from e\nValueError: Extra inputs are not permitted\n\n\n- Ensure the output is the component code, and nothing else\n- Wrap the component code around ```\n"
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "tools",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "other",
                "value": ""
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "tools",
                "value": [
                  {
                    "_uniqueId": "Call_Agent_message_response_0",
                    "args": {
                      "input_value": {
                        "default": "",
                        "description": "The input provided by the user for the agent to process.",
                        "title": "Input Value",
                        "type": "string"
                      }
                    },
                    "description": "This tool is used to generate langflow components.",
                    "display_description": "Define the agent's instructions, then enter a task to complete using tools.",
                    "display_name": "message_response",
                    "name": "langflow_component_generation_tool",
                    "readonly": false,
                    "status": true,
                    "tags": [
                      "Call_Agent"
                    ]
                  }
                ]
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "verbose",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "Agent"
        },
        "dragging": false,
        "id": "Agent-3EeP1",
        "measured": {
          "height": 427,
          "width": 320
        },
        "position": {
          "x": 765.8003054408115,
          "y": 229.60407295536123
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatInput-Ei6z8",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "https://docs.langflow.org/chat-input-and-output",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "context_id",
              "files"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.8.0",
            "metadata": {
              "code_hash": "7a26c54d89ed",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 1
              },
              "module": "lfx.components.input_output.chat.ChatInput"
            },
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chat Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from lfx.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom lfx.base.io.chat import ChatComponent\nfrom lfx.inputs.inputs import BoolInput\nfrom lfx.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom lfx.schema.message import Message\nfrom lfx.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    documentation: str = \"https://docs.langflow.org/chat-input-and-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"context_id\",\n            display_name=\"Context ID\",\n            info=\"The context ID of the chat. Adds an extra layer to the local memory.\",\n            value=\"\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n            temp_file=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Chat Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        # Ensure files is a list and filter out empty/None values\n        files = self.files if self.files else []\n        if files and not isinstance(files, list):\n            files = [files]\n        # Filter out None/empty values\n        files = [f for f in files if f is not None and f != \"\"]\n\n        session_id = self.session_id or self.graph.session_id or \"\"\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=session_id,\n            context_id=self.context_id,\n            files=files,\n        )\n        if session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "context_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Context ID",
                "dynamic": false,
                "info": "The context ID of the chat. Adds an extra layer to the local memory.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "context_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "files": {
                "_input_type": "FileInput",
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "csv",
                  "json",
                  "pdf",
                  "txt",
                  "md",
                  "mdx",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "list_add_label": "Add More",
                "name": "files",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "temp_file": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Input Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatInput"
        },
        "dragging": false,
        "id": "ChatInput-Ei6z8",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": 1016.5268454333803,
          "y": 817.7505957464455
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Agent-aLzmq",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "display_name": "Agent",
            "documentation": "https://docs.langflow.org/agents",
            "edited": false,
            "field_order": [
              "model",
              "api_key",
              "system_prompt",
              "context_id",
              "n_messages",
              "format_instructions",
              "output_schema",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "add_current_date_tool"
            ],
            "frozen": false,
            "icon": "bot",
            "last_updated": "2026-01-16T18:59:23.606Z",
            "legacy": false,
            "lf_version": "1.8.0",
            "metadata": {
              "code_hash": "bdc309bc2d2a",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "pydantic",
                    "version": "2.11.10"
                  },
                  {
                    "name": "lfx",
                    "version": null
                  },
                  {
                    "name": "langchain_core",
                    "version": "0.3.80"
                  }
                ],
                "total_dependencies": 3
              },
              "module": "lfx.components.models_and_agents.agent.AgentComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Response",
                "group_outputs": false,
                "hidden": null,
                "loop_types": null,
                "method": "message_response",
                "name": "response",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_frontend_node_flow_id": {
                "value": "66eb7678-93d8-450d-9ddf-0c09b8c1eee9"
              },
              "_frontend_node_folder_id": {
                "value": "9b756c37-4ddb-4a33-bb62-6d9ab7eec58c"
              },
              "_type": "Component",
              "add_current_date_tool": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Current Date",
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "add_current_date_tool",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": true,
                "display_name": "API Key",
                "dynamic": false,
                "info": "Model Provider API key",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": "ANTHROPIC_API_KEY"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from __future__ import annotations\n\nimport json\nimport re\nfrom typing import TYPE_CHECKING\n\nfrom pydantic import ValidationError\n\nfrom lfx.components.models_and_agents.memory import MemoryComponent\n\nif TYPE_CHECKING:\n    from langchain_core.tools import Tool\n\nfrom lfx.base.agents.agent import LCToolsAgentComponent\nfrom lfx.base.agents.events import ExceptionWithMessageError\nfrom lfx.base.models.unified_models import (\n    get_language_model_options,\n    get_llm,\n    update_model_options_in_build_config,\n)\nfrom lfx.components.helpers import CurrentDateComponent\nfrom lfx.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom lfx.custom.custom_component.component import get_component_toolkit\nfrom lfx.helpers.base_model import build_model_from_schema\nfrom lfx.inputs.inputs import BoolInput, ModelInput\nfrom lfx.io import IntInput, MessageTextInput, MultilineInput, Output, SecretStrInput, TableInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.dotdict import dotdict\nfrom lfx.schema.message import Message\nfrom lfx.schema.table import EditMode\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    documentation: str = \"https://docs.langflow.org/agents\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        ModelInput(\n            name=\"model\",\n            display_name=\"Language Model\",\n            info=\"Select your model provider\",\n            real_time_refresh=True,\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"API Key\",\n            info=\"Model Provider API key\",\n            real_time_refresh=True,\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        MessageTextInput(\n            name=\"context_id\",\n            display_name=\"Context ID\",\n            info=\"The context ID of the chat. Adds an extra layer to the local memory.\",\n            value=\"\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Chat History Messages\",\n            value=100,\n            info=\"Number of chat history messages to retrieve.\",\n            advanced=True,\n            show=True,\n        ),\n        MultilineInput(\n            name=\"format_instructions\",\n            display_name=\"Output Format Instructions\",\n            info=\"Generic Template for structured output formatting. Valid only with Structured response.\",\n            value=(\n                \"You are an AI that extracts structured JSON objects from unstructured text. \"\n                \"Use a predefined schema with expected types (str, int, float, bool, dict). \"\n                \"Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. \"\n                \"Fill missing or ambiguous values with defaults: null for missing values. \"\n                \"Remove exact duplicates but keep variations that have different field values. \"\n                \"Always return valid JSON in the expected format, never throw errors. \"\n                \"If multiple objects can be extracted, return them all in the structured format.\"\n            ),\n            advanced=True,\n        ),\n        TableInput(\n            name=\"output_schema\",\n            display_name=\"Output Schema\",\n            info=(\n                \"Schema Validation: Define the structure and data types for structured output. \"\n                \"No validation if no output schema.\"\n            ),\n            advanced=True,\n            required=False,\n            value=[],\n            table_schema=[\n                {\n                    \"name\": \"name\",\n                    \"display_name\": \"Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Specify the name of the output field.\",\n                    \"default\": \"field\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"description\",\n                    \"display_name\": \"Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Describe the purpose of the output field.\",\n                    \"default\": \"description of field\",\n                    \"edit_mode\": EditMode.POPOVER,\n                },\n                {\n                    \"name\": \"type\",\n                    \"display_name\": \"Type\",\n                    \"type\": \"str\",\n                    \"edit_mode\": EditMode.INLINE,\n                    \"description\": (\"Indicate the data type of the output field (e.g., str, int, float, bool, dict).\"),\n                    \"options\": [\"str\", \"int\", \"float\", \"bool\", \"dict\"],\n                    \"default\": \"str\",\n                },\n                {\n                    \"name\": \"multiple\",\n                    \"display_name\": \"As List\",\n                    \"type\": \"boolean\",\n                    \"description\": \"Set to True if this output field should be a list of the specified type.\",\n                    \"default\": \"False\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n            ],\n        ),\n        *LCToolsAgentComponent.get_base_inputs(),\n        # removed memory inputs from agent component\n        # *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [\n        Output(name=\"response\", display_name=\"Response\", method=\"message_response\"),\n    ]\n\n    async def get_agent_requirements(self):\n        \"\"\"Get the agent requirements for the agent.\"\"\"\n        from langchain_core.tools import StructuredTool\n\n        llm_model = get_llm(\n            model=self.model,\n            user_id=self.user_id,\n            api_key=self.api_key,\n        )\n        if llm_model is None:\n            msg = \"No language model selected. Please choose a model to proceed.\"\n            raise ValueError(msg)\n\n        # Get memory data\n        self.chat_history = await self.get_memory_data()\n        await logger.adebug(f\"Retrieved {len(self.chat_history)} chat history messages\")\n        if isinstance(self.chat_history, Message):\n            self.chat_history = [self.chat_history]\n\n        # Add current date tool if enabled\n        if self.add_current_date_tool:\n            if not isinstance(self.tools, list):  # type: ignore[has-type]\n                self.tools = []\n            current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n\n            if not isinstance(current_date_tool, StructuredTool):\n                msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                raise TypeError(msg)\n            self.tools.append(current_date_tool)\n\n        # Set shared callbacks for tracing the tools used by the agent\n        self.set_tools_callbacks(self.tools, self._get_shared_callbacks())\n\n        return llm_model, self.chat_history, self.tools\n\n    async def message_response(self) -> Message:\n        try:\n            llm_model, self.chat_history, self.tools = await self.get_agent_requirements()\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            result = await self.run_agent(agent)\n\n            # Store result for potential JSON output\n            self._agent_result = result\n\n        except (ValueError, TypeError, KeyError) as e:\n            await logger.aerror(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            await logger.aerror(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        # Avoid catching blind Exception; let truly unexpected exceptions propagate\n        except Exception as e:\n            await logger.aerror(f\"Unexpected error: {e!s}\")\n            raise\n        else:\n            return result\n\n    def _preprocess_schema(self, schema):\n        \"\"\"Preprocess schema to ensure correct data types for build_model_from_schema.\"\"\"\n        processed_schema = []\n        for field in schema:\n            processed_field = {\n                \"name\": str(field.get(\"name\", \"field\")),\n                \"type\": str(field.get(\"type\", \"str\")),\n                \"description\": str(field.get(\"description\", \"\")),\n                \"multiple\": field.get(\"multiple\", False),\n            }\n            # Ensure multiple is handled correctly\n            if isinstance(processed_field[\"multiple\"], str):\n                processed_field[\"multiple\"] = processed_field[\"multiple\"].lower() in [\n                    \"true\",\n                    \"1\",\n                    \"t\",\n                    \"y\",\n                    \"yes\",\n                ]\n            processed_schema.append(processed_field)\n        return processed_schema\n\n    async def build_structured_output_base(self, content: str):\n        \"\"\"Build structured output with optional BaseModel validation.\"\"\"\n        json_pattern = r\"\\{.*\\}\"\n        schema_error_msg = \"Try setting an output schema\"\n\n        # Try to parse content as JSON first\n        json_data = None\n        try:\n            json_data = json.loads(content)\n        except json.JSONDecodeError:\n            json_match = re.search(json_pattern, content, re.DOTALL)\n            if json_match:\n                try:\n                    json_data = json.loads(json_match.group())\n                except json.JSONDecodeError:\n                    return {\"content\": content, \"error\": schema_error_msg}\n            else:\n                return {\"content\": content, \"error\": schema_error_msg}\n\n        # If no output schema provided, return parsed JSON without validation\n        if not hasattr(self, \"output_schema\") or not self.output_schema or len(self.output_schema) == 0:\n            return json_data\n\n        # Use BaseModel validation with schema\n        try:\n            processed_schema = self._preprocess_schema(self.output_schema)\n            output_model = build_model_from_schema(processed_schema)\n\n            # Validate against the schema\n            if isinstance(json_data, list):\n                # Multiple objects\n                validated_objects = []\n                for item in json_data:\n                    try:\n                        validated_obj = output_model.model_validate(item)\n                        validated_objects.append(validated_obj.model_dump())\n                    except ValidationError as e:\n                        await logger.aerror(f\"Validation error for item: {e}\")\n                        # Include invalid items with error info\n                        validated_objects.append({\"data\": item, \"validation_error\": str(e)})\n                return validated_objects\n\n            # Single object\n            try:\n                validated_obj = output_model.model_validate(json_data)\n                return [validated_obj.model_dump()]  # Return as list for consistency\n            except ValidationError as e:\n                await logger.aerror(f\"Validation error: {e}\")\n                return [{\"data\": json_data, \"validation_error\": str(e)}]\n\n        except (TypeError, ValueError) as e:\n            await logger.aerror(f\"Error building structured output: {e}\")\n            # Fallback to parsed JSON without validation\n            return json_data\n\n    async def json_response(self) -> Data:\n        \"\"\"Convert agent response to structured JSON Data output with schema validation.\"\"\"\n        # Always use structured chat agent for JSON response mode for better JSON formatting\n        try:\n            system_components = []\n\n            # 1. Agent Instructions (system_prompt)\n            agent_instructions = getattr(self, \"system_prompt\", \"\") or \"\"\n            if agent_instructions:\n                system_components.append(f\"{agent_instructions}\")\n\n            # 2. Format Instructions\n            format_instructions = getattr(self, \"format_instructions\", \"\") or \"\"\n            if format_instructions:\n                system_components.append(f\"Format instructions: {format_instructions}\")\n\n            # 3. Schema Information from BaseModel\n            if hasattr(self, \"output_schema\") and self.output_schema and len(self.output_schema) > 0:\n                try:\n                    processed_schema = self._preprocess_schema(self.output_schema)\n                    output_model = build_model_from_schema(processed_schema)\n                    schema_dict = output_model.model_json_schema()\n                    schema_info = (\n                        \"You are given some text that may include format instructions, \"\n                        \"explanations, or other content alongside a JSON schema.\\n\\n\"\n                        \"Your task:\\n\"\n                        \"- Extract only the JSON schema.\\n\"\n                        \"- Return it as valid JSON.\\n\"\n                        \"- Do not include format instructions, explanations, or extra text.\\n\\n\"\n                        \"Input:\\n\"\n                        f\"{json.dumps(schema_dict, indent=2)}\\n\\n\"\n                        \"Output (only JSON schema):\"\n                    )\n                    system_components.append(schema_info)\n                except (ValidationError, ValueError, TypeError, KeyError) as e:\n                    await logger.aerror(f\"Could not build schema for prompt: {e}\", exc_info=True)\n\n            # Combine all components\n            combined_instructions = \"\\n\\n\".join(system_components) if system_components else \"\"\n            llm_model, self.chat_history, self.tools = await self.get_agent_requirements()\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=combined_instructions,\n            )\n\n            # Create and run structured chat agent\n            try:\n                structured_agent = self.create_agent_runnable()\n            except (NotImplementedError, ValueError, TypeError) as e:\n                await logger.aerror(f\"Error with structured chat agent: {e}\")\n                raise\n            try:\n                result = await self.run_agent(structured_agent)\n            except (\n                ExceptionWithMessageError,\n                ValueError,\n                TypeError,\n                RuntimeError,\n            ) as e:\n                await logger.aerror(f\"Error with structured agent result: {e}\")\n                raise\n            # Extract content from structured agent result\n            if hasattr(result, \"content\"):\n                content = result.content\n            elif hasattr(result, \"text\"):\n                content = result.text\n            else:\n                content = str(result)\n\n        except (\n            ExceptionWithMessageError,\n            ValueError,\n            TypeError,\n            NotImplementedError,\n            AttributeError,\n        ) as e:\n            await logger.aerror(f\"Error with structured chat agent: {e}\")\n            # Fallback to regular agent\n            content_str = \"No content returned from agent\"\n            return Data(data={\"content\": content_str, \"error\": str(e)})\n\n        # Process with structured output validation\n        try:\n            structured_output = await self.build_structured_output_base(content)\n\n            # Handle different output formats\n            if isinstance(structured_output, list) and structured_output:\n                if len(structured_output) == 1:\n                    return Data(data=structured_output[0])\n                return Data(data={\"results\": structured_output})\n            if isinstance(structured_output, dict):\n                return Data(data=structured_output)\n            return Data(data={\"content\": content})\n\n        except (ValueError, TypeError) as e:\n            await logger.aerror(f\"Error in structured output processing: {e}\")\n            return Data(data={\"content\": content, \"error\": str(e)})\n\n    async def get_memory_data(self):\n        # TODO: This is a temporary fix to avoid message duplication. We should develop a function for this.\n        messages = (\n            await MemoryComponent(**self.get_base_args())\n            .set(\n                session_id=self.graph.session_id,\n                context_id=self.context_id,\n                order=\"Ascending\",\n                n_messages=self.n_messages,\n            )\n            .retrieve_messages()\n        )\n        return [\n            message for message in messages if getattr(message, \"id\", None) != getattr(self.input_value, \"id\", None)\n        ]\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self,\n        build_config: dotdict,\n        field_value: list[dict],\n        field_name: str | None = None,\n    ) -> dotdict:\n        # Update model options with caching (for all field changes)\n        # Agents require tool calling, so filter for only tool-calling capable models\n        def get_tool_calling_model_options(user_id=None):\n            return get_language_model_options(user_id=user_id, tool_calling=True)\n\n        build_config = update_model_options_in_build_config(\n            component=self,\n            build_config=dict(build_config),\n            cache_key_prefix=\"language_model_options_tool_calling\",\n            get_options_func=get_tool_calling_model_options,\n            field_name=field_name,\n            field_value=field_value,\n        )\n        build_config = dotdict(build_config)\n\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        if field_name == \"model\":\n            self.log(str(field_value))\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"model\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n\n    async def _get_tools(self) -> list[Tool]:\n        component_toolkit = get_component_toolkit()\n        tools_names = self._build_tools_names()\n        agent_description = self.get_tool_description()\n        # TODO: Agent Description Depreciated Feature to be removed\n        description = f\"{agent_description}{tools_names}\"\n\n        tools = component_toolkit(component=self).get_tools(\n            tool_name=\"Call_Agent\",\n            tool_description=description,\n            # here we do not use the shared callbacks as we are exposing the agent as a tool\n            callbacks=self.get_langchain_callbacks(),\n        )\n        if hasattr(self, \"tools_metadata\"):\n            tools = component_toolkit(component=self, metadata=self.tools_metadata).update_tools_metadata(tools=tools)\n\n        return tools\n"
              },
              "context_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Context ID",
                "dynamic": false,
                "info": "The context ID of the chat. Adds an extra layer to the local memory.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "context_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "format_instructions": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Output Format Instructions",
                "dynamic": false,
                "info": "Generic Template for structured output formatting. Valid only with Structured response.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "format_instructions",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "You are an AI that extracts structured JSON objects from unstructured text. Use a predefined schema with expected types (str, int, float, bool, dict). Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. Fill missing or ambiguous values with defaults: null for missing values. Remove exact duplicates but keep variations that have different field values. Always return valid JSON in the expected format, never throw errors. If multiple objects can be extracted, return them all in the structured format."
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "handle_parsing_errors",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "is_refresh": false,
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": 15
              },
              "model": {
                "_input_type": "ModelInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "external_options": {
                  "fields": {
                    "data": {
                      "node": {
                        "display_name": "Connect other models",
                        "icon": "CornerDownLeft",
                        "name": "connect_other_models"
                      }
                    }
                  }
                },
                "info": "Select your model provider",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "model_type": "language",
                "name": "model",
                "options": [
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-opus-4-5-20251101",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-haiku-4-5-20251001",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-sonnet-4-5-20250929",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-opus-4-1-20250805",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-opus-4-20250514",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5.1"
                      ]
                    },
                    "name": "gpt-5.1",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5"
                      ]
                    },
                    "name": "gpt-5",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5-mini"
                      ]
                    },
                    "name": "gpt-5-mini",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5-nano"
                      ]
                    },
                    "name": "gpt-5-nano",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4o-mini",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "Google Generative AI",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "is_disabled_provider": true,
                      "variable_name": "GOOGLE_API_KEY"
                    },
                    "name": "__enable_provider_Google Generative AI__",
                    "provider": "Google Generative AI"
                  },
                  {
                    "category": "Ollama",
                    "icon": "Ollama",
                    "metadata": {
                      "is_disabled_provider": true,
                      "variable_name": "OLLAMA_BASE_URL"
                    },
                    "name": "__enable_provider_Ollama__",
                    "provider": "Ollama"
                  },
                  {
                    "category": "IBM WatsonX",
                    "icon": "WatsonxAI",
                    "metadata": {
                      "is_disabled_provider": true,
                      "variable_name": "WATSONX_APIKEY"
                    },
                    "name": "__enable_provider_IBM WatsonX__",
                    "provider": "IBM WatsonX"
                  }
                ],
                "override_skip": false,
                "placeholder": "Setup Provider",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "track_in_telemetry": false,
                "type": "model",
                "value": [
                  {
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-sonnet-4-5-20250929",
                    "provider": "Anthropic"
                  }
                ]
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Chat History Messages",
                "dynamic": false,
                "info": "Number of chat history messages to retrieve.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": 100
              },
              "output_schema": {
                "_input_type": "TableInput",
                "advanced": true,
                "display_name": "Output Schema",
                "dynamic": false,
                "info": "Schema Validation: Define the structure and data types for structured output. No validation if no output schema.",
                "input_types": [],
                "is_list": true,
                "list_add_label": "Add More",
                "name": "output_schema",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "table_icon": "Table",
                "table_schema": [
                  {
                    "default": "field",
                    "description": "Specify the name of the output field.",
                    "display_name": "Name",
                    "edit_mode": "inline",
                    "formatter": "text",
                    "name": "name",
                    "type": "str"
                  },
                  {
                    "default": "description of field",
                    "description": "Describe the purpose of the output field.",
                    "display_name": "Description",
                    "edit_mode": "popover",
                    "formatter": "text",
                    "name": "description",
                    "type": "str"
                  },
                  {
                    "default": "str",
                    "description": "Indicate the data type of the output field (e.g., str, int, float, bool, dict).",
                    "display_name": "Type",
                    "edit_mode": "inline",
                    "formatter": "text",
                    "name": "type",
                    "options": [
                      "str",
                      "int",
                      "float",
                      "bool",
                      "dict"
                    ],
                    "type": "str"
                  },
                  {
                    "default": "False",
                    "description": "Set to True if this output field should be a list of the specified type.",
                    "display_name": "As List",
                    "edit_mode": "inline",
                    "formatter": "text",
                    "name": "multiple",
                    "type": "boolean"
                  }
                ],
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": []
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Agent Instructions",
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "\nYou are a **Langflow Assistant** and your role is to help the user by leveraging Langflow documentation, Langflow GitHub source code, and all available tools, including the Langflow Official Support Agent.\n\nYou must follow the rules below.\n\n***\n\n# **1. General Rules**\n\n*   Follow **Langflow best practices** from official documentation and GitHub.\n*   Use tools (web search, URL access, Support Agent) whenever they improve accuracy or alignment with Langflow standards.\n*   Prefer **documentation-backed answers** over assumptions.\n\n***\n\n# **2. Component Generation Rules**\n\nIf the user requests a **Langflow component**, you must:\n\n1.  **Ask exactly ONE clarifying question** if needed  \n    (only if the user hasn't provided enough information for proper component construction).\n\n2.  **Before generating the component**, produce a **TODO / implementation plan** containing:\n    *   Inputs\n    *   Outputs\n    *   Core logic\n    *   Assumptions\n    *   Relevant documentation or GitHub references\n\n3.  Ask for **explicit user approval** of the TODO.\n\n4.  After approval:\n    *   Generate the component **as a Python code block only**.\n    *   No explanations, no extra text, no markdown outside the code block.\n\n5.  If a tool is used to generate code:\n    *   Return the **tool output directly as the final answer**, unmodified.\n\n***\n\n# **3. Missing or Insufficient Information**\n\n*   If information is missing, ask **ONE** clear, precise question focused only on:\n    *   Required input fields\n    *   Output types\n    *   Behavior or logic needed\n\nDo **not** generate a component until the TODO is approved.\n\n***\n\n# **4. Langflow Official Support Agent Tool**\n\nYou have access to a dedicated **Support Agent** with the following role:\n\n### **Support Agent Role (Built-In Tool Prompt)**\n\n> **Role**  \n> You are the *Langflow Official Support Agent*. Your purpose is to assist with technical questions, troubleshooting, and implementation details regarding Langflow.\n>\n> **Capabilities**\n>\n> *   You may browse **one documentation URL** at a time from the official Langflow Documentation Index.\n>\n> **Instructions**\n>\n> 1.  Analyze the question.\n> 2.  Select the *single most relevant* documentation URL.\n> 3.  Browse it via the tool.\n> 4.  Provide a concise answer based only on that content.\n> 5.  End with \"Source: <URL>\".\n>\n> **Rules**\n>\n> *   Do not hallucinate.\n> *   Keep responses concise.\n> *   Only cite the page actually browsed.\n\nYou may call the Support Agent whenever it improves accuracy.\n\n***\n\n# **5. Documentation Resources**\n\nYou may browse:\n\n*   <https://docs.langflow.org/>\n*   <https://github.com/langflow-ai/langflow>\n*   And all sub-links and references\n\nUse these resources to answer correctly and ensure alignment with Langflow best practices.\n\n"
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "tools",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "other",
                "value": ""
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "verbose",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Agent"
        },
        "dragging": false,
        "id": "Agent-aLzmq",
        "measured": {
          "height": 429,
          "width": 320
        },
        "position": {
          "x": 1620.4432567807098,
          "y": 340.0454684830384
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-GgTV3",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "https://docs.langflow.org/chat-input-and-output",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "context_id",
              "data_template",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.8.0",
            "metadata": {
              "code_hash": "8c87e536cca4",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "orjson",
                    "version": "3.10.15"
                  },
                  {
                    "name": "fastapi",
                    "version": "0.128.0"
                  },
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 3
              },
              "module": "lfx.components.input_output.chat_output.ChatOutput"
            },
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean data before converting to string.",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom lfx.base.io.chat import ChatComponent\nfrom lfx.helpers.data import safe_convert\nfrom lfx.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.message import Message\nfrom lfx.schema.properties import Source\nfrom lfx.template.field.base import Output\nfrom lfx.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/chat-input-and-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"context_id\",\n            display_name=\"Context ID\",\n            info=\"The context ID of the chat. Adds an extra layer to the local memory.\",\n            value=\"\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            advanced=True,\n            info=\"Whether to clean data before converting to string.\",\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, _, display_name, source_id = self.get_properties_from_source_component()\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message) and not self.is_connected_to_chat_input():\n            message = self.input_value\n            # Update message properties\n            message.text = text\n            # Preserve existing session_id from the incoming message if it exists\n            existing_session_id = message.session_id\n        else:\n            message = Message(text=text)\n            existing_session_id = None\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        # Preserve session_id from incoming message, or use component/graph session_id\n        message.session_id = (\n            self.session_id or existing_session_id or (self.graph.session_id if hasattr(self, \"graph\") else None) or \"\"\n        )\n        message.context_id = self.context_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n\n        # Store message if needed\n        if message.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            clean_data: bool = getattr(self, \"clean_data\", False)\n            return \"\\n\".join([safe_convert(item, clean_data=clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "context_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Context ID",
                "dynamic": false,
                "info": "The context ID of the chat. Adds an extra layer to the local memory.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "context_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "override_skip": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-GgTV3",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": 2133.0993340570108,
          "y": 716.5238337563313
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "UnifiedWebSearch-iL7hT",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Search the web, news, or RSS feeds.",
            "display_name": "Web Search",
            "documentation": "https://docs.langflow.org/web-search",
            "edited": false,
            "field_order": [
              "search_mode",
              "query",
              "hl",
              "gl",
              "ceid",
              "topic",
              "location",
              "timeout"
            ],
            "frozen": false,
            "icon": "search",
            "last_updated": "2026-01-16T18:55:36.156Z",
            "legacy": false,
            "lf_version": "1.8.0",
            "metadata": {
              "code_hash": "cbeeaef8889a",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "pandas",
                    "version": "2.2.3"
                  },
                  {
                    "name": "requests",
                    "version": "2.32.5"
                  },
                  {
                    "name": "bs4",
                    "version": "4.12.3"
                  },
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 4
              },
              "module": "lfx.components.data_source.web_search.WebSearchComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "group_outputs": false,
                "hidden": null,
                "loop_types": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_frontend_node_flow_id": {
                "value": "66eb7678-93d8-450d-9ddf-0c09b8c1eee9"
              },
              "_frontend_node_folder_id": {
                "value": "9b756c37-4ddb-4a33-bb62-6d9ab7eec58c"
              },
              "_type": "Component",
              "ceid": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Country:Language (ceid)",
                "dynamic": false,
                "info": "e.g. US:en, FR:fr. Default: US:en.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "ceid",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "US:en"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "\"\"\"Unified Web Search Component.\n\nThis component consolidates Web Search, News Search, and RSS Reader into a single\ncomponent with tabs for different search modes.\n\"\"\"\n\nimport re\nfrom typing import Any\nfrom urllib.parse import parse_qs, quote_plus, unquote, urlparse\n\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\n\nfrom lfx.custom import Component\nfrom lfx.io import IntInput, MessageTextInput, Output, TabInput\nfrom lfx.schema import DataFrame\nfrom lfx.utils.request_utils import get_user_agent\n\n\nclass WebSearchComponent(Component):\n    display_name = \"Web Search\"\n    description = \"Search the web, news, or RSS feeds.\"\n    documentation: str = \"https://docs.langflow.org/web-search\"\n    icon = \"search\"\n    name = \"UnifiedWebSearch\"\n\n    inputs = [\n        TabInput(\n            name=\"search_mode\",\n            display_name=\"Search Mode\",\n            options=[\"Web\", \"News\", \"RSS\"],\n            info=\"Choose search mode: Web (DuckDuckGo), News (Google News), or RSS (Feed Reader)\",\n            value=\"Web\",\n            real_time_refresh=True,\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"Search Query\",\n            info=\"Search keywords for news articles.\",\n            tool_mode=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"hl\",\n            display_name=\"Language (hl)\",\n            info=\"Language code, e.g. en-US, fr, de. Default: en-US.\",\n            tool_mode=False,\n            input_types=[],\n            required=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"gl\",\n            display_name=\"Country (gl)\",\n            info=\"Country code, e.g. US, FR, DE. Default: US.\",\n            tool_mode=False,\n            input_types=[],\n            required=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"ceid\",\n            display_name=\"Country:Language (ceid)\",\n            info=\"e.g. US:en, FR:fr. Default: US:en.\",\n            tool_mode=False,\n            value=\"US:en\",\n            input_types=[],\n            required=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"topic\",\n            display_name=\"Topic\",\n            info=\"One of: WORLD, NATION, BUSINESS, TECHNOLOGY, ENTERTAINMENT, SCIENCE, SPORTS, HEALTH.\",\n            tool_mode=False,\n            input_types=[],\n            required=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"location\",\n            display_name=\"Location (Geo)\",\n            info=\"City, state, or country for location-based news. Leave blank for keyword search.\",\n            tool_mode=False,\n            input_types=[],\n            required=False,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"Timeout for the request in seconds.\",\n            value=5,\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [Output(name=\"results\", display_name=\"Results\", method=\"perform_search\")]\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        \"\"\"Update input visibility based on search mode.\"\"\"\n        if field_name == \"search_mode\":\n            # Show/hide inputs based on search mode\n            is_news = field_value == \"News\"\n            is_rss = field_value == \"RSS\"\n\n            # Update query field info based on mode\n            if is_rss:\n                build_config[\"query\"][\"info\"] = \"RSS feed URL to parse\"\n                build_config[\"query\"][\"display_name\"] = \"RSS Feed URL\"\n            elif is_news:\n                build_config[\"query\"][\"info\"] = \"Search keywords for news articles.\"\n                build_config[\"query\"][\"display_name\"] = \"Search Query\"\n            else:  # Web\n                build_config[\"query\"][\"info\"] = \"Keywords to search for\"\n                build_config[\"query\"][\"display_name\"] = \"Search Query\"\n\n            # Keep news-specific fields as advanced (matching original News Search component)\n            # They remain advanced=True in all modes, just like in the original component\n\n        return build_config\n\n    def validate_url(self, string: str) -> bool:\n        \"\"\"Validate URL format.\"\"\"\n        url_regex = re.compile(\n            r\"^(https?:\\/\\/)?\" r\"(www\\.)?\" r\"([a-zA-Z0-9.-]+)\" r\"(\\.[a-zA-Z]{2,})?\" r\"(:\\d+)?\" r\"(\\/[^\\s]*)?$\",\n            re.IGNORECASE,\n        )\n        return bool(url_regex.match(string))\n\n    def ensure_url(self, url: str) -> str:\n        \"\"\"Ensure URL has proper protocol.\"\"\"\n        if not url.startswith((\"http://\", \"https://\")):\n            url = \"https://\" + url\n        if not self.validate_url(url):\n            msg = f\"Invalid URL: {url}\"\n            raise ValueError(msg)\n        return url\n\n    def _sanitize_query(self, query: str) -> str:\n        \"\"\"Sanitize search query.\"\"\"\n        return re.sub(r'[<>\"\\']', \"\", query.strip())\n\n    def clean_html(self, html_string: str) -> str:\n        \"\"\"Remove HTML tags from text.\"\"\"\n        return BeautifulSoup(html_string, \"html.parser\").get_text(separator=\" \", strip=True)\n\n    def perform_web_search(self) -> DataFrame:\n        \"\"\"Perform DuckDuckGo web search.\"\"\"\n        query = self._sanitize_query(self.query)\n        if not query:\n            msg = \"Empty search query\"\n            raise ValueError(msg)\n\n        headers = {\"User-Agent\": get_user_agent()}\n        params = {\"q\": query, \"kl\": \"us-en\"}\n        url = \"https://html.duckduckgo.com/html/\"\n\n        try:\n            response = requests.get(url, params=params, headers=headers, timeout=self.timeout)\n            response.raise_for_status()\n        except requests.RequestException as e:\n            self.status = f\"Failed request: {e!s}\"\n            return DataFrame(pd.DataFrame([{\"title\": \"Error\", \"link\": \"\", \"snippet\": str(e), \"content\": \"\"}]))\n\n        if not response.text or \"text/html\" not in response.headers.get(\"content-type\", \"\").lower():\n            self.status = \"No results found\"\n            return DataFrame(\n                pd.DataFrame([{\"title\": \"Error\", \"link\": \"\", \"snippet\": \"No results found\", \"content\": \"\"}])\n            )\n\n        soup = BeautifulSoup(response.text, \"html.parser\")\n        results = []\n\n        for result in soup.select(\"div.result\"):\n            title_tag = result.select_one(\"a.result__a\")\n            snippet_tag = result.select_one(\"a.result__snippet\")\n            if title_tag:\n                raw_link = title_tag.get(\"href\", \"\")\n                parsed = urlparse(raw_link)\n                uddg = parse_qs(parsed.query).get(\"uddg\", [\"\"])[0]\n                decoded_link = unquote(uddg) if uddg else raw_link\n\n                try:\n                    final_url = self.ensure_url(decoded_link)\n                    page = requests.get(final_url, headers=headers, timeout=self.timeout)\n                    page.raise_for_status()\n                    content = BeautifulSoup(page.text, \"lxml\").get_text(separator=\" \", strip=True)\n                except requests.RequestException as e:\n                    final_url = decoded_link\n                    content = f\"(Failed to fetch: {e!s}\"\n\n                results.append(\n                    {\n                        \"title\": title_tag.get_text(strip=True),\n                        \"link\": final_url,\n                        \"snippet\": snippet_tag.get_text(strip=True) if snippet_tag else \"\",\n                        \"content\": content,\n                    }\n                )\n\n        return DataFrame(pd.DataFrame(results))\n\n    def perform_news_search(self) -> DataFrame:\n        \"\"\"Perform Google News search.\"\"\"\n        query = getattr(self, \"query\", \"\")\n        hl = getattr(self, \"hl\", \"en-US\") or \"en-US\"\n        gl = getattr(self, \"gl\", \"US\") or \"US\"\n        topic = getattr(self, \"topic\", None)\n        location = getattr(self, \"location\", None)\n\n        ceid = f\"{gl}:{hl.split('-')[0]}\"\n\n        # Build RSS URL based on parameters\n        if topic:\n            # Topic-based feed\n            base_url = f\"https://news.google.com/rss/headlines/section/topic/{quote_plus(topic.upper())}\"\n            params = f\"?hl={hl}&gl={gl}&ceid={ceid}\"\n            rss_url = base_url + params\n        elif location:\n            # Location-based feed\n            base_url = f\"https://news.google.com/rss/headlines/section/geo/{quote_plus(location)}\"\n            params = f\"?hl={hl}&gl={gl}&ceid={ceid}\"\n            rss_url = base_url + params\n        elif query:\n            # Keyword search feed\n            base_url = \"https://news.google.com/rss/search?q=\"\n            query_encoded = quote_plus(query)\n            params = f\"&hl={hl}&gl={gl}&ceid={ceid}\"\n            rss_url = f\"{base_url}{query_encoded}{params}\"\n        else:\n            self.status = \"No search query, topic, or location provided.\"\n            return DataFrame(\n                pd.DataFrame(\n                    [{\"title\": \"Error\", \"link\": \"\", \"published\": \"\", \"summary\": \"No search parameters provided\"}]\n                )\n            )\n\n        try:\n            response = requests.get(rss_url, timeout=self.timeout)\n            response.raise_for_status()\n            soup = BeautifulSoup(response.content, \"xml\")\n            items = soup.find_all(\"item\")\n        except requests.RequestException as e:\n            self.status = f\"Failed to fetch news: {e}\"\n            return DataFrame(pd.DataFrame([{\"title\": \"Error\", \"link\": \"\", \"published\": \"\", \"summary\": str(e)}]))\n\n        if not items:\n            self.status = \"No news articles found.\"\n            return DataFrame(pd.DataFrame([{\"title\": \"No articles found\", \"link\": \"\", \"published\": \"\", \"summary\": \"\"}]))\n\n        articles = []\n        for item in items:\n            try:\n                title = self.clean_html(item.title.text if item.title else \"\")\n                link = item.link.text if item.link else \"\"\n                published = item.pubDate.text if item.pubDate else \"\"\n                summary = self.clean_html(item.description.text if item.description else \"\")\n                articles.append({\"title\": title, \"link\": link, \"published\": published, \"summary\": summary})\n            except (AttributeError, ValueError, TypeError) as e:\n                self.log(f\"Error parsing article: {e!s}\")\n                continue\n\n        return DataFrame(pd.DataFrame(articles))\n\n    def perform_rss_read(self) -> DataFrame:\n        \"\"\"Read RSS feed.\"\"\"\n        rss_url = getattr(self, \"query\", \"\")\n        if not rss_url:\n            return DataFrame(\n                pd.DataFrame([{\"title\": \"Error\", \"link\": \"\", \"published\": \"\", \"summary\": \"No RSS URL provided\"}])\n            )\n\n        try:\n            response = requests.get(rss_url, timeout=self.timeout)\n            response.raise_for_status()\n            if not response.content.strip():\n                msg = \"Empty response received\"\n                raise ValueError(msg)\n\n            # Validate XML\n            try:\n                BeautifulSoup(response.content, \"xml\")\n            except Exception as e:\n                msg = f\"Invalid XML response: {e}\"\n                raise ValueError(msg) from e\n\n            soup = BeautifulSoup(response.content, \"xml\")\n            items = soup.find_all(\"item\")\n        except (requests.RequestException, ValueError) as e:\n            self.status = f\"Failed to fetch RSS: {e}\"\n            return DataFrame(pd.DataFrame([{\"title\": \"Error\", \"link\": \"\", \"published\": \"\", \"summary\": str(e)}]))\n\n        articles = [\n            {\n                \"title\": item.title.text if item.title else \"\",\n                \"link\": item.link.text if item.link else \"\",\n                \"published\": item.pubDate.text if item.pubDate else \"\",\n                \"summary\": item.description.text if item.description else \"\",\n            }\n            for item in items\n        ]\n\n        # Ensure DataFrame has correct columns even if empty\n        df_articles = pd.DataFrame(articles, columns=[\"title\", \"link\", \"published\", \"summary\"])\n        self.log(f\"Fetched {len(df_articles)} articles.\")\n        return DataFrame(df_articles)\n\n    def perform_search(self) -> DataFrame:\n        \"\"\"Main search method that routes to appropriate search function based on mode.\"\"\"\n        search_mode = getattr(self, \"search_mode\", \"Web\")\n\n        if search_mode == \"Web\":\n            return self.perform_web_search()\n        if search_mode == \"News\":\n            return self.perform_news_search()\n        if search_mode == \"RSS\":\n            return self.perform_rss_read()\n        # Fallback to web search\n        return self.perform_web_search()\n"
              },
              "gl": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Country (gl)",
                "dynamic": false,
                "info": "Country code, e.g. US, FR, DE. Default: US.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "gl",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "hl": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Language (hl)",
                "dynamic": false,
                "info": "Language code, e.g. en-US, fr, de. Default: en-US.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "hl",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "is_refresh": false,
              "location": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Location (Geo)",
                "dynamic": false,
                "info": "City, state, or country for location-based news. Leave blank for keyword search.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "location",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "query": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "Search keywords for news articles.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "query",
                "override_skip": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "search_mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Search Mode",
                "dynamic": false,
                "info": "Choose search mode: Web (DuckDuckGo), News (Google News), or RSS (Feed Reader)",
                "name": "search_mode",
                "options": [
                  "Web",
                  "News",
                  "RSS"
                ],
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "tab",
                "value": "Web"
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "Timeout for the request in seconds.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": 5
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "tools",
                "value": [
                  {
                    "args": {
                      "query": {
                        "description": "Search keywords for news articles.",
                        "title": "Query",
                        "type": "string"
                      },
                      "search_mode": {
                        "default": "Web",
                        "description": "Choose search mode: Web (DuckDuckGo), News (Google News), or RSS (Feed Reader)",
                        "enum": [
                          "Web",
                          "News",
                          "RSS"
                        ],
                        "title": "Search Mode",
                        "type": "string"
                      }
                    },
                    "description": "Search the web, news, or RSS feeds.",
                    "display_description": "Search the web, news, or RSS feeds.",
                    "display_name": "perform_search",
                    "name": "perform_search",
                    "readonly": false,
                    "status": true,
                    "tags": [
                      "perform_search"
                    ]
                  }
                ]
              },
              "topic": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Topic",
                "dynamic": false,
                "info": "One of: WORLD, NATION, BUSINESS, TECHNOLOGY, ENTERTAINMENT, SCIENCE, SPORTS, HEALTH.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "topic",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "UnifiedWebSearch"
        },
        "dragging": false,
        "id": "UnifiedWebSearch-iL7hT",
        "measured": {
          "height": 202,
          "width": 320
        },
        "position": {
          "x": 131.2452408448052,
          "y": 465.3404567558
        },
        "selected": true,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "URLComponent-UYnHu",
          "node": {
            "base_classes": [
              "DataFrame",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Fetch content from one or more web pages, following links recursively.",
            "display_name": "URL",
            "documentation": "https://docs.langflow.org/url",
            "edited": false,
            "field_order": [
              "urls",
              "max_depth",
              "prevent_outside",
              "use_async",
              "format",
              "timeout",
              "headers",
              "filter_text_html",
              "continue_on_failure",
              "check_response_status",
              "autoset_encoding"
            ],
            "frozen": false,
            "icon": "layout-template",
            "last_updated": "2026-01-16T18:55:36.156Z",
            "legacy": false,
            "lf_version": "1.8.0",
            "metadata": {
              "code_hash": "47d3ccb92d71",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "requests",
                    "version": "2.32.5"
                  },
                  {
                    "name": "bs4",
                    "version": "4.12.3"
                  },
                  {
                    "name": "langchain_community",
                    "version": "0.3.21"
                  },
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 4
              },
              "module": "lfx.components.data_source.url.URLComponent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "group_outputs": false,
                "hidden": null,
                "loop_types": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_frontend_node_flow_id": {
                "value": "66eb7678-93d8-450d-9ddf-0c09b8c1eee9"
              },
              "_frontend_node_folder_id": {
                "value": "9b756c37-4ddb-4a33-bb62-6d9ab7eec58c"
              },
              "_type": "Component",
              "autoset_encoding": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Autoset Encoding",
                "dynamic": false,
                "info": "If enabled, automatically sets the encoding of the request.",
                "list": false,
                "list_add_label": "Add More",
                "name": "autoset_encoding",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "check_response_status": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Check Response Status",
                "dynamic": false,
                "info": "If enabled, checks the response status of the request.",
                "list": false,
                "list_add_label": "Add More",
                "name": "check_response_status",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": false
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import importlib\nimport re\n\nimport requests\nfrom bs4 import BeautifulSoup\nfrom langchain_community.document_loaders import RecursiveUrlLoader\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.helpers.data import safe_convert\nfrom lfx.io import BoolInput, DropdownInput, IntInput, MessageTextInput, Output, SliderInput, TableInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.message import Message\nfrom lfx.utils.request_utils import get_user_agent\n\n# Constants\nDEFAULT_TIMEOUT = 30\nDEFAULT_MAX_DEPTH = 1\nDEFAULT_FORMAT = \"Text\"\n\n\nURL_REGEX = re.compile(\n    r\"^(https?:\\/\\/)?\" r\"(www\\.)?\" r\"([a-zA-Z0-9.-]+)\" r\"(\\.[a-zA-Z]{2,})?\" r\"(:\\d+)?\" r\"(\\/[^\\s]*)?$\",\n    re.IGNORECASE,\n)\n\nUSER_AGENT = None\n# Check if langflow is installed using importlib.util.find_spec(name))\nif importlib.util.find_spec(\"langflow\"):\n    langflow_installed = True\n    USER_AGENT = get_user_agent()\nelse:\n    langflow_installed = False\n    USER_AGENT = \"lfx\"\n\n\nclass URLComponent(Component):\n    \"\"\"A component that loads and parses content from web pages recursively.\n\n    This component allows fetching content from one or more URLs, with options to:\n    - Control crawl depth\n    - Prevent crawling outside the root domain\n    - Use async loading for better performance\n    - Extract either raw HTML or clean text\n    - Configure request headers and timeouts\n    \"\"\"\n\n    display_name = \"URL\"\n    description = \"Fetch content from one or more web pages, following links recursively.\"\n    documentation: str = \"https://docs.langflow.org/url\"\n    icon = \"layout-template\"\n    name = \"URLComponent\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"urls\",\n            display_name=\"URLs\",\n            info=\"Enter one or more URLs to crawl recursively, by clicking the '+' button.\",\n            is_list=True,\n            tool_mode=True,\n            placeholder=\"Enter a URL...\",\n            list_add_label=\"Add URL\",\n            input_types=[],\n        ),\n        SliderInput(\n            name=\"max_depth\",\n            display_name=\"Depth\",\n            info=(\n                \"Controls how many 'clicks' away from the initial page the crawler will go:\\n\"\n                \"- depth 1: only the initial page\\n\"\n                \"- depth 2: initial page + all pages linked directly from it\\n\"\n                \"- depth 3: initial page + direct links + links found on those direct link pages\\n\"\n                \"Note: This is about link traversal, not URL path depth.\"\n            ),\n            value=DEFAULT_MAX_DEPTH,\n            range_spec=RangeSpec(min=1, max=5, step=1),\n            required=False,\n            min_label=\" \",\n            max_label=\" \",\n            min_label_icon=\"None\",\n            max_label_icon=\"None\",\n            # slider_input=True\n        ),\n        BoolInput(\n            name=\"prevent_outside\",\n            display_name=\"Prevent Outside\",\n            info=(\n                \"If enabled, only crawls URLs within the same domain as the root URL. \"\n                \"This helps prevent the crawler from going to external websites.\"\n            ),\n            value=True,\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"use_async\",\n            display_name=\"Use Async\",\n            info=(\n                \"If enabled, uses asynchronous loading which can be significantly faster \"\n                \"but might use more system resources.\"\n            ),\n            value=True,\n            required=False,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"format\",\n            display_name=\"Output Format\",\n            info=\"Output Format. Use 'Text' to extract the text from the HTML or 'HTML' for the raw HTML content.\",\n            options=[\"Text\", \"HTML\"],\n            value=DEFAULT_FORMAT,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"Timeout for the request in seconds.\",\n            value=DEFAULT_TIMEOUT,\n            required=False,\n            advanced=True,\n        ),\n        TableInput(\n            name=\"headers\",\n            display_name=\"Headers\",\n            info=\"The headers to send with the request\",\n            table_schema=[\n                {\n                    \"name\": \"key\",\n                    \"display_name\": \"Header\",\n                    \"type\": \"str\",\n                    \"description\": \"Header name\",\n                },\n                {\n                    \"name\": \"value\",\n                    \"display_name\": \"Value\",\n                    \"type\": \"str\",\n                    \"description\": \"Header value\",\n                },\n            ],\n            value=[{\"key\": \"User-Agent\", \"value\": USER_AGENT}],\n            advanced=True,\n            input_types=[\"DataFrame\"],\n        ),\n        BoolInput(\n            name=\"filter_text_html\",\n            display_name=\"Filter Text/HTML\",\n            info=\"If enabled, filters out text/css content type from the results.\",\n            value=True,\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"continue_on_failure\",\n            display_name=\"Continue on Failure\",\n            info=\"If enabled, continues crawling even if some requests fail.\",\n            value=True,\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"check_response_status\",\n            display_name=\"Check Response Status\",\n            info=\"If enabled, checks the response status of the request.\",\n            value=False,\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"autoset_encoding\",\n            display_name=\"Autoset Encoding\",\n            info=\"If enabled, automatically sets the encoding of the request.\",\n            value=True,\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Extracted Pages\", name=\"page_results\", method=\"fetch_content\"),\n        Output(display_name=\"Raw Content\", name=\"raw_results\", method=\"fetch_content_as_message\", tool_mode=False),\n    ]\n\n    @staticmethod\n    def validate_url(url: str) -> bool:\n        \"\"\"Validates if the given string matches URL pattern.\n\n        Args:\n            url: The URL string to validate\n\n        Returns:\n            bool: True if the URL is valid, False otherwise\n        \"\"\"\n        return bool(URL_REGEX.match(url))\n\n    def ensure_url(self, url: str) -> str:\n        \"\"\"Ensures the given string is a valid URL.\n\n        Args:\n            url: The URL string to validate and normalize\n\n        Returns:\n            str: The normalized URL\n\n        Raises:\n            ValueError: If the URL is invalid\n        \"\"\"\n        url = url.strip()\n        if not url.startswith((\"http://\", \"https://\")):\n            url = \"https://\" + url\n\n        if not self.validate_url(url):\n            msg = f\"Invalid URL: {url}\"\n            raise ValueError(msg)\n\n        return url\n\n    def _create_loader(self, url: str) -> RecursiveUrlLoader:\n        \"\"\"Creates a RecursiveUrlLoader instance with the configured settings.\n\n        Args:\n            url: The URL to load\n\n        Returns:\n            RecursiveUrlLoader: Configured loader instance\n        \"\"\"\n        headers_dict = {header[\"key\"]: header[\"value\"] for header in self.headers if header[\"value\"] is not None}\n        extractor = (lambda x: x) if self.format == \"HTML\" else (lambda x: BeautifulSoup(x, \"lxml\").get_text())\n\n        return RecursiveUrlLoader(\n            url=url,\n            max_depth=self.max_depth,\n            prevent_outside=self.prevent_outside,\n            use_async=self.use_async,\n            extractor=extractor,\n            timeout=self.timeout,\n            headers=headers_dict,\n            check_response_status=self.check_response_status,\n            continue_on_failure=self.continue_on_failure,\n            base_url=url,  # Add base_url to ensure consistent domain crawling\n            autoset_encoding=self.autoset_encoding,  # Enable automatic encoding detection\n            exclude_dirs=[],  # Allow customization of excluded directories\n            link_regex=None,  # Allow customization of link filtering\n        )\n\n    def fetch_url_contents(self) -> list[dict]:\n        \"\"\"Load documents from the configured URLs.\n\n        Returns:\n            List[Data]: List of Data objects containing the fetched content\n\n        Raises:\n            ValueError: If no valid URLs are provided or if there's an error loading documents\n        \"\"\"\n        try:\n            urls = list({self.ensure_url(url) for url in self.urls if url.strip()})\n            logger.debug(f\"URLs: {urls}\")\n            if not urls:\n                msg = \"No valid URLs provided.\"\n                raise ValueError(msg)\n\n            all_docs = []\n            for url in urls:\n                logger.debug(f\"Loading documents from {url}\")\n\n                try:\n                    loader = self._create_loader(url)\n                    docs = loader.load()\n\n                    if not docs:\n                        logger.warning(f\"No documents found for {url}\")\n                        continue\n\n                    logger.debug(f\"Found {len(docs)} documents from {url}\")\n                    all_docs.extend(docs)\n\n                except requests.exceptions.RequestException as e:\n                    logger.exception(f\"Error loading documents from {url}: {e}\")\n                    continue\n\n            if not all_docs:\n                msg = \"No documents were successfully loaded from any URL\"\n                raise ValueError(msg)\n\n            # data = [Data(text=doc.page_content, **doc.metadata) for doc in all_docs]\n            data = [\n                {\n                    \"text\": safe_convert(doc.page_content, clean_data=True),\n                    \"url\": doc.metadata.get(\"source\", \"\"),\n                    \"title\": doc.metadata.get(\"title\", \"\"),\n                    \"description\": doc.metadata.get(\"description\", \"\"),\n                    \"content_type\": doc.metadata.get(\"content_type\", \"\"),\n                    \"language\": doc.metadata.get(\"language\", \"\"),\n                }\n                for doc in all_docs\n            ]\n        except Exception as e:\n            error_msg = e.message if hasattr(e, \"message\") else e\n            msg = f\"Error loading documents: {error_msg!s}\"\n            logger.exception(msg)\n            raise ValueError(msg) from e\n        return data\n\n    def fetch_content(self) -> DataFrame:\n        \"\"\"Convert the documents to a DataFrame.\"\"\"\n        return DataFrame(data=self.fetch_url_contents())\n\n    def fetch_content_as_message(self) -> Message:\n        \"\"\"Convert the documents to a Message.\"\"\"\n        url_contents = self.fetch_url_contents()\n        return Message(text=\"\\n\\n\".join([x[\"text\"] for x in url_contents]), data={\"data\": url_contents})\n"
              },
              "continue_on_failure": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Continue on Failure",
                "dynamic": false,
                "info": "If enabled, continues crawling even if some requests fail.",
                "list": false,
                "list_add_label": "Add More",
                "name": "continue_on_failure",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "filter_text_html": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Filter Text/HTML",
                "dynamic": false,
                "info": "If enabled, filters out text/css content type from the results.",
                "list": false,
                "list_add_label": "Add More",
                "name": "filter_text_html",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "format": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Output Format",
                "dynamic": false,
                "external_options": {},
                "info": "Output Format. Use 'Text' to extract the text from the HTML or 'HTML' for the raw HTML content.",
                "name": "format",
                "options": [
                  "Text",
                  "HTML"
                ],
                "options_metadata": [],
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "str",
                "value": "Text"
              },
              "headers": {
                "_input_type": "TableInput",
                "advanced": true,
                "display_name": "Headers",
                "dynamic": false,
                "info": "The headers to send with the request",
                "input_types": [
                  "DataFrame"
                ],
                "is_list": true,
                "list_add_label": "Add More",
                "name": "headers",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "table_icon": "Table",
                "table_schema": [
                  {
                    "description": "Header name",
                    "display_name": "Header",
                    "name": "key",
                    "type": "str"
                  },
                  {
                    "description": "Header value",
                    "display_name": "Value",
                    "name": "value",
                    "type": "str"
                  }
                ],
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": [
                  {
                    "key": "User-Agent",
                    "value": null
                  }
                ]
              },
              "is_refresh": false,
              "max_depth": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Depth",
                "dynamic": false,
                "info": "Controls how many 'clicks' away from the initial page the crawler will go:\n- depth 1: only the initial page\n- depth 2: initial page + all pages linked directly from it\n- depth 3: initial page + direct links + links found on those direct link pages\nNote: This is about link traversal, not URL path depth.",
                "max_label": " ",
                "max_label_icon": "None",
                "min_label": " ",
                "min_label_icon": "None",
                "name": "max_depth",
                "override_skip": false,
                "placeholder": "",
                "range_spec": {
                  "max": 5,
                  "min": 1,
                  "step": 1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "track_in_telemetry": false,
                "type": "slider",
                "value": 1
              },
              "prevent_outside": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Prevent Outside",
                "dynamic": false,
                "info": "If enabled, only crawls URLs within the same domain as the root URL. This helps prevent the crawler from going to external websites.",
                "list": false,
                "list_add_label": "Add More",
                "name": "prevent_outside",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "Timeout for the request in seconds.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": 30
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "tools",
                "value": [
                  {
                    "args": {
                      "urls": {
                        "default": "",
                        "description": "Enter one or more URLs to crawl recursively, by clicking the '+' button.",
                        "items": {
                          "type": "string"
                        },
                        "title": "Urls",
                        "type": "array"
                      }
                    },
                    "description": "Fetch content from one or more web pages, following links recursively.",
                    "display_description": "Fetch content from one or more web pages, following links recursively.",
                    "display_name": "fetch_content",
                    "name": "fetch_content",
                    "readonly": false,
                    "status": true,
                    "tags": [
                      "fetch_content"
                    ]
                  }
                ]
              },
              "urls": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "URLs",
                "dynamic": false,
                "info": "Enter one or more URLs to crawl recursively, by clicking the '+' button.",
                "input_types": [],
                "list": true,
                "list_add_label": "Add URL",
                "load_from_db": false,
                "name": "urls",
                "override_skip": false,
                "placeholder": "Enter a URL...",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "use_async": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Use Async",
                "dynamic": false,
                "info": "If enabled, uses asynchronous loading which can be significantly faster but might use more system resources.",
                "list": false,
                "list_add_label": "Add More",
                "name": "use_async",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": true
          },
          "selected_output": "page_results",
          "showNode": true,
          "type": "URLComponent"
        },
        "dragging": false,
        "id": "URLComponent-UYnHu",
        "measured": {
          "height": 290,
          "width": 320
        },
        "position": {
          "x": 119.22618575511757,
          "y": 798.4218689631639
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "description": "Define the agent's instructions, then enter a task to complete using tools.",
          "display_name": "Agent",
          "id": "Agent-03db7",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "display_name": "Agent",
            "documentation": "https://docs.langflow.org/agents",
            "edited": false,
            "field_order": [
              "model",
              "api_key",
              "system_prompt",
              "context_id",
              "n_messages",
              "format_instructions",
              "output_schema",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "add_current_date_tool"
            ],
            "frozen": false,
            "icon": "bot",
            "last_updated": "2026-01-16T19:00:00.518Z",
            "legacy": false,
            "lf_version": "1.8.0",
            "metadata": {
              "code_hash": "bdc309bc2d2a",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "pydantic",
                    "version": "2.11.10"
                  },
                  {
                    "name": "lfx",
                    "version": null
                  },
                  {
                    "name": "langchain_core",
                    "version": "0.3.81"
                  }
                ],
                "total_dependencies": 3
              },
              "module": "custom_components.agent"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "group_outputs": false,
                "hidden": null,
                "loop_types": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_frontend_node_flow_id": {
                "value": "66eb7678-93d8-450d-9ddf-0c09b8c1eee9"
              },
              "_frontend_node_folder_id": {
                "value": "9b756c37-4ddb-4a33-bb62-6d9ab7eec58c"
              },
              "_type": "Component",
              "add_current_date_tool": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Current Date",
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "add_current_date_tool",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": true,
                "display_name": "API Key",
                "dynamic": false,
                "info": "Model Provider API key",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "override_skip": false,
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "track_in_telemetry": false,
                "type": "str",
                "value": "ANTHROPIC_API_KEY"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from __future__ import annotations\n\nimport json\nimport re\nfrom typing import TYPE_CHECKING\n\nfrom pydantic import ValidationError\n\nfrom lfx.components.models_and_agents.memory import MemoryComponent\n\nif TYPE_CHECKING:\n    from langchain_core.tools import Tool\n\nfrom lfx.base.agents.agent import LCToolsAgentComponent\nfrom lfx.base.agents.events import ExceptionWithMessageError\nfrom lfx.base.models.unified_models import (\n    get_language_model_options,\n    get_llm,\n    update_model_options_in_build_config,\n)\nfrom lfx.components.helpers import CurrentDateComponent\nfrom lfx.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom lfx.custom.custom_component.component import get_component_toolkit\nfrom lfx.helpers.base_model import build_model_from_schema\nfrom lfx.inputs.inputs import BoolInput, ModelInput\nfrom lfx.io import IntInput, MessageTextInput, MultilineInput, Output, SecretStrInput, TableInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.dotdict import dotdict\nfrom lfx.schema.message import Message\nfrom lfx.schema.table import EditMode\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    documentation: str = \"https://docs.langflow.org/agents\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        ModelInput(\n            name=\"model\",\n            display_name=\"Language Model\",\n            info=\"Select your model provider\",\n            real_time_refresh=True,\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"API Key\",\n            info=\"Model Provider API key\",\n            real_time_refresh=True,\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        MessageTextInput(\n            name=\"context_id\",\n            display_name=\"Context ID\",\n            info=\"The context ID of the chat. Adds an extra layer to the local memory.\",\n            value=\"\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Chat History Messages\",\n            value=100,\n            info=\"Number of chat history messages to retrieve.\",\n            advanced=True,\n            show=True,\n        ),\n        MultilineInput(\n            name=\"format_instructions\",\n            display_name=\"Output Format Instructions\",\n            info=\"Generic Template for structured output formatting. Valid only with Structured response.\",\n            value=(\n                \"You are an AI that extracts structured JSON objects from unstructured text. \"\n                \"Use a predefined schema with expected types (str, int, float, bool, dict). \"\n                \"Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. \"\n                \"Fill missing or ambiguous values with defaults: null for missing values. \"\n                \"Remove exact duplicates but keep variations that have different field values. \"\n                \"Always return valid JSON in the expected format, never throw errors. \"\n                \"If multiple objects can be extracted, return them all in the structured format.\"\n            ),\n            advanced=True,\n        ),\n        TableInput(\n            name=\"output_schema\",\n            display_name=\"Output Schema\",\n            info=(\n                \"Schema Validation: Define the structure and data types for structured output. \"\n                \"No validation if no output schema.\"\n            ),\n            advanced=True,\n            required=False,\n            value=[],\n            table_schema=[\n                {\n                    \"name\": \"name\",\n                    \"display_name\": \"Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Specify the name of the output field.\",\n                    \"default\": \"field\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"description\",\n                    \"display_name\": \"Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Describe the purpose of the output field.\",\n                    \"default\": \"description of field\",\n                    \"edit_mode\": EditMode.POPOVER,\n                },\n                {\n                    \"name\": \"type\",\n                    \"display_name\": \"Type\",\n                    \"type\": \"str\",\n                    \"edit_mode\": EditMode.INLINE,\n                    \"description\": (\"Indicate the data type of the output field (e.g., str, int, float, bool, dict).\"),\n                    \"options\": [\"str\", \"int\", \"float\", \"bool\", \"dict\"],\n                    \"default\": \"str\",\n                },\n                {\n                    \"name\": \"multiple\",\n                    \"display_name\": \"As List\",\n                    \"type\": \"boolean\",\n                    \"description\": \"Set to True if this output field should be a list of the specified type.\",\n                    \"default\": \"False\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n            ],\n        ),\n        *LCToolsAgentComponent.get_base_inputs(),\n        # removed memory inputs from agent component\n        # *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [\n        Output(name=\"response\", display_name=\"Response\", method=\"message_response\"),\n    ]\n\n    async def get_agent_requirements(self):\n        \"\"\"Get the agent requirements for the agent.\"\"\"\n        from langchain_core.tools import StructuredTool\n\n        llm_model = get_llm(\n            model=self.model,\n            user_id=self.user_id,\n            api_key=self.api_key,\n        )\n        if llm_model is None:\n            msg = \"No language model selected. Please choose a model to proceed.\"\n            raise ValueError(msg)\n\n        # Get memory data\n        self.chat_history = await self.get_memory_data()\n        await logger.adebug(f\"Retrieved {len(self.chat_history)} chat history messages\")\n        if isinstance(self.chat_history, Message):\n            self.chat_history = [self.chat_history]\n\n        # Add current date tool if enabled\n        if self.add_current_date_tool:\n            if not isinstance(self.tools, list):  # type: ignore[has-type]\n                self.tools = []\n            current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n\n            if not isinstance(current_date_tool, StructuredTool):\n                msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                raise TypeError(msg)\n            self.tools.append(current_date_tool)\n\n        # Set shared callbacks for tracing the tools used by the agent\n        self.set_tools_callbacks(self.tools, self._get_shared_callbacks())\n\n        return llm_model, self.chat_history, self.tools\n\n    async def message_response(self) -> Message:\n        try:\n            llm_model, self.chat_history, self.tools = await self.get_agent_requirements()\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            result = await self.run_agent(agent)\n\n            # Store result for potential JSON output\n            self._agent_result = result\n\n        except (ValueError, TypeError, KeyError) as e:\n            await logger.aerror(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            await logger.aerror(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        # Avoid catching blind Exception; let truly unexpected exceptions propagate\n        except Exception as e:\n            await logger.aerror(f\"Unexpected error: {e!s}\")\n            raise\n        else:\n            return result\n\n    def _preprocess_schema(self, schema):\n        \"\"\"Preprocess schema to ensure correct data types for build_model_from_schema.\"\"\"\n        processed_schema = []\n        for field in schema:\n            processed_field = {\n                \"name\": str(field.get(\"name\", \"field\")),\n                \"type\": str(field.get(\"type\", \"str\")),\n                \"description\": str(field.get(\"description\", \"\")),\n                \"multiple\": field.get(\"multiple\", False),\n            }\n            # Ensure multiple is handled correctly\n            if isinstance(processed_field[\"multiple\"], str):\n                processed_field[\"multiple\"] = processed_field[\"multiple\"].lower() in [\n                    \"true\",\n                    \"1\",\n                    \"t\",\n                    \"y\",\n                    \"yes\",\n                ]\n            processed_schema.append(processed_field)\n        return processed_schema\n\n    async def build_structured_output_base(self, content: str):\n        \"\"\"Build structured output with optional BaseModel validation.\"\"\"\n        json_pattern = r\"\\{.*\\}\"\n        schema_error_msg = \"Try setting an output schema\"\n\n        # Try to parse content as JSON first\n        json_data = None\n        try:\n            json_data = json.loads(content)\n        except json.JSONDecodeError:\n            json_match = re.search(json_pattern, content, re.DOTALL)\n            if json_match:\n                try:\n                    json_data = json.loads(json_match.group())\n                except json.JSONDecodeError:\n                    return {\"content\": content, \"error\": schema_error_msg}\n            else:\n                return {\"content\": content, \"error\": schema_error_msg}\n\n        # If no output schema provided, return parsed JSON without validation\n        if not hasattr(self, \"output_schema\") or not self.output_schema or len(self.output_schema) == 0:\n            return json_data\n\n        # Use BaseModel validation with schema\n        try:\n            processed_schema = self._preprocess_schema(self.output_schema)\n            output_model = build_model_from_schema(processed_schema)\n\n            # Validate against the schema\n            if isinstance(json_data, list):\n                # Multiple objects\n                validated_objects = []\n                for item in json_data:\n                    try:\n                        validated_obj = output_model.model_validate(item)\n                        validated_objects.append(validated_obj.model_dump())\n                    except ValidationError as e:\n                        await logger.aerror(f\"Validation error for item: {e}\")\n                        # Include invalid items with error info\n                        validated_objects.append({\"data\": item, \"validation_error\": str(e)})\n                return validated_objects\n\n            # Single object\n            try:\n                validated_obj = output_model.model_validate(json_data)\n                return [validated_obj.model_dump()]  # Return as list for consistency\n            except ValidationError as e:\n                await logger.aerror(f\"Validation error: {e}\")\n                return [{\"data\": json_data, \"validation_error\": str(e)}]\n\n        except (TypeError, ValueError) as e:\n            await logger.aerror(f\"Error building structured output: {e}\")\n            # Fallback to parsed JSON without validation\n            return json_data\n\n    async def json_response(self) -> Data:\n        \"\"\"Convert agent response to structured JSON Data output with schema validation.\"\"\"\n        # Always use structured chat agent for JSON response mode for better JSON formatting\n        try:\n            system_components = []\n\n            # 1. Agent Instructions (system_prompt)\n            agent_instructions = getattr(self, \"system_prompt\", \"\") or \"\"\n            if agent_instructions:\n                system_components.append(f\"{agent_instructions}\")\n\n            # 2. Format Instructions\n            format_instructions = getattr(self, \"format_instructions\", \"\") or \"\"\n            if format_instructions:\n                system_components.append(f\"Format instructions: {format_instructions}\")\n\n            # 3. Schema Information from BaseModel\n            if hasattr(self, \"output_schema\") and self.output_schema and len(self.output_schema) > 0:\n                try:\n                    processed_schema = self._preprocess_schema(self.output_schema)\n                    output_model = build_model_from_schema(processed_schema)\n                    schema_dict = output_model.model_json_schema()\n                    schema_info = (\n                        \"You are given some text that may include format instructions, \"\n                        \"explanations, or other content alongside a JSON schema.\\n\\n\"\n                        \"Your task:\\n\"\n                        \"- Extract only the JSON schema.\\n\"\n                        \"- Return it as valid JSON.\\n\"\n                        \"- Do not include format instructions, explanations, or extra text.\\n\\n\"\n                        \"Input:\\n\"\n                        f\"{json.dumps(schema_dict, indent=2)}\\n\\n\"\n                        \"Output (only JSON schema):\"\n                    )\n                    system_components.append(schema_info)\n                except (ValidationError, ValueError, TypeError, KeyError) as e:\n                    await logger.aerror(f\"Could not build schema for prompt: {e}\", exc_info=True)\n\n            # Combine all components\n            combined_instructions = \"\\n\\n\".join(system_components) if system_components else \"\"\n            llm_model, self.chat_history, self.tools = await self.get_agent_requirements()\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=combined_instructions,\n            )\n\n            # Create and run structured chat agent\n            try:\n                structured_agent = self.create_agent_runnable()\n            except (NotImplementedError, ValueError, TypeError) as e:\n                await logger.aerror(f\"Error with structured chat agent: {e}\")\n                raise\n            try:\n                result = await self.run_agent(structured_agent)\n            except (\n                ExceptionWithMessageError,\n                ValueError,\n                TypeError,\n                RuntimeError,\n            ) as e:\n                await logger.aerror(f\"Error with structured agent result: {e}\")\n                raise\n            # Extract content from structured agent result\n            if hasattr(result, \"content\"):\n                content = result.content\n            elif hasattr(result, \"text\"):\n                content = result.text\n            else:\n                content = str(result)\n\n        except (\n            ExceptionWithMessageError,\n            ValueError,\n            TypeError,\n            NotImplementedError,\n            AttributeError,\n        ) as e:\n            await logger.aerror(f\"Error with structured chat agent: {e}\")\n            # Fallback to regular agent\n            content_str = \"No content returned from agent\"\n            return Data(data={\"content\": content_str, \"error\": str(e)})\n\n        # Process with structured output validation\n        try:\n            structured_output = await self.build_structured_output_base(content)\n\n            # Handle different output formats\n            if isinstance(structured_output, list) and structured_output:\n                if len(structured_output) == 1:\n                    return Data(data=structured_output[0])\n                return Data(data={\"results\": structured_output})\n            if isinstance(structured_output, dict):\n                return Data(data=structured_output)\n            return Data(data={\"content\": content})\n\n        except (ValueError, TypeError) as e:\n            await logger.aerror(f\"Error in structured output processing: {e}\")\n            return Data(data={\"content\": content, \"error\": str(e)})\n\n    async def get_memory_data(self):\n        # TODO: This is a temporary fix to avoid message duplication. We should develop a function for this.\n        messages = (\n            await MemoryComponent(**self.get_base_args())\n            .set(\n                session_id=self.graph.session_id,\n                context_id=self.context_id,\n                order=\"Ascending\",\n                n_messages=self.n_messages,\n            )\n            .retrieve_messages()\n        )\n        return [\n            message for message in messages if getattr(message, \"id\", None) != getattr(self.input_value, \"id\", None)\n        ]\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self,\n        build_config: dotdict,\n        field_value: list[dict],\n        field_name: str | None = None,\n    ) -> dotdict:\n        # Update model options with caching (for all field changes)\n        # Agents require tool calling, so filter for only tool-calling capable models\n        def get_tool_calling_model_options(user_id=None):\n            return get_language_model_options(user_id=user_id, tool_calling=True)\n\n        build_config = update_model_options_in_build_config(\n            component=self,\n            build_config=dict(build_config),\n            cache_key_prefix=\"language_model_options_tool_calling\",\n            get_options_func=get_tool_calling_model_options,\n            field_name=field_name,\n            field_value=field_value,\n        )\n        build_config = dotdict(build_config)\n\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        if field_name == \"model\":\n            self.log(str(field_value))\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"model\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n\n    async def _get_tools(self) -> list[Tool]:\n        component_toolkit = get_component_toolkit()\n        tools_names = self._build_tools_names()\n        agent_description = self.get_tool_description()\n        # TODO: Agent Description Depreciated Feature to be removed\n        description = f\"{agent_description}{tools_names}\"\n\n        tools = component_toolkit(component=self).get_tools(\n            tool_name=\"Call_Agent\",\n            tool_description=description,\n            # here we do not use the shared callbacks as we are exposing the agent as a tool\n            callbacks=self.get_langchain_callbacks(),\n        )\n        if hasattr(self, \"tools_metadata\"):\n            tools = component_toolkit(component=self, metadata=self.tools_metadata).update_tools_metadata(tools=tools)\n\n        return tools\n"
              },
              "context_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Context ID",
                "dynamic": false,
                "info": "The context ID of the chat. Adds an extra layer to the local memory.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "context_id",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "format_instructions": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Output Format Instructions",
                "dynamic": false,
                "info": "Generic Template for structured output formatting. Valid only with Structured response.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "format_instructions",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "You are an AI that extracts structured JSON objects from unstructured text. Use a predefined schema with expected types (str, int, float, bool, dict). Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. Fill missing or ambiguous values with defaults: null for missing values. Remove exact duplicates but keep variations that have different field values. Always return valid JSON in the expected format, never throw errors. If multiple objects can be extracted, return them all in the structured format."
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "handle_parsing_errors",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "is_refresh": false,
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": 15
              },
              "model": {
                "_input_type": "ModelInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "external_options": {
                  "fields": {
                    "data": {
                      "node": {
                        "display_name": "Connect other models",
                        "icon": "CornerDownLeft",
                        "name": "connect_other_models"
                      }
                    }
                  }
                },
                "info": "Select your model provider",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "model_type": "language",
                "name": "model",
                "options": [
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-opus-4-5-20251101",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-haiku-4-5-20251001",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-sonnet-4-5-20250929",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-opus-4-1-20250805",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-opus-4-20250514",
                    "provider": "Anthropic"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5.1"
                      ]
                    },
                    "name": "gpt-5.1",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5"
                      ]
                    },
                    "name": "gpt-5",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5-mini"
                      ]
                    },
                    "name": "gpt-5-mini",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model",
                      "reasoning_models": [
                        "gpt-5-nano"
                      ]
                    },
                    "name": "gpt-5-nano",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "OpenAI",
                    "icon": "OpenAI",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatOpenAI",
                      "model_name_param": "model"
                    },
                    "name": "gpt-4o-mini",
                    "provider": "OpenAI"
                  },
                  {
                    "category": "Google Generative AI",
                    "icon": "GoogleGenerativeAI",
                    "metadata": {
                      "is_disabled_provider": true,
                      "variable_name": "GOOGLE_API_KEY"
                    },
                    "name": "__enable_provider_Google Generative AI__",
                    "provider": "Google Generative AI"
                  },
                  {
                    "category": "Ollama",
                    "icon": "Ollama",
                    "metadata": {
                      "is_disabled_provider": true,
                      "variable_name": "OLLAMA_BASE_URL"
                    },
                    "name": "__enable_provider_Ollama__",
                    "provider": "Ollama"
                  },
                  {
                    "category": "IBM WatsonX",
                    "icon": "WatsonxAI",
                    "metadata": {
                      "is_disabled_provider": true,
                      "variable_name": "WATSONX_APIKEY"
                    },
                    "name": "__enable_provider_IBM WatsonX__",
                    "provider": "IBM WatsonX"
                  }
                ],
                "override_skip": false,
                "placeholder": "Setup Provider",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "track_in_telemetry": false,
                "type": "model",
                "value": [
                  {
                    "category": "Anthropic",
                    "icon": "Anthropic",
                    "metadata": {
                      "api_key_param": "api_key",
                      "context_length": 128000,
                      "model_class": "ChatAnthropic",
                      "model_name_param": "model"
                    },
                    "name": "claude-opus-4-5-20251101",
                    "provider": "Anthropic"
                  }
                ]
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Chat History Messages",
                "dynamic": false,
                "info": "Number of chat history messages to retrieve.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "int",
                "value": 100
              },
              "output_schema": {
                "_input_type": "TableInput",
                "advanced": true,
                "display_name": "Output Schema",
                "dynamic": false,
                "info": "Schema Validation: Define the structure and data types for structured output. No validation if no output schema.",
                "input_types": [],
                "is_list": true,
                "list_add_label": "Add More",
                "name": "output_schema",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "table_icon": "Table",
                "table_schema": [
                  {
                    "default": "field",
                    "description": "Specify the name of the output field.",
                    "display_name": "Name",
                    "edit_mode": "inline",
                    "formatter": "text",
                    "name": "name",
                    "type": "str"
                  },
                  {
                    "default": "description of field",
                    "description": "Describe the purpose of the output field.",
                    "display_name": "Description",
                    "edit_mode": "popover",
                    "formatter": "text",
                    "name": "description",
                    "type": "str"
                  },
                  {
                    "default": "str",
                    "description": "Indicate the data type of the output field (e.g., str, int, float, bool, dict).",
                    "display_name": "Type",
                    "edit_mode": "inline",
                    "formatter": "text",
                    "name": "type",
                    "options": [
                      "str",
                      "int",
                      "float",
                      "bool",
                      "dict"
                    ],
                    "type": "str"
                  },
                  {
                    "default": "False",
                    "description": "Set to True if this output field should be a list of the specified type.",
                    "display_name": "As List",
                    "edit_mode": "inline",
                    "formatter": "text",
                    "name": "multiple",
                    "type": "boolean"
                  }
                ],
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": []
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "ai_enabled": false,
                "copy_field": false,
                "display_name": "Agent Instructions",
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": "You are a helpful assistant that can use tools to answer questions and perform tasks."
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "tools",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "other",
                "value": ""
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "tools",
                "value": [
                  {
                    "_uniqueId": "Call_Agent_message_response_0",
                    "args": {
                      "input_value": {
                        "default": "",
                        "description": "The input provided by the user for the agent to process.",
                        "title": "Input Value",
                        "type": "string"
                      }
                    },
                    "description": "Use this tool to answer Langflow support based questions",
                    "display_description": "Define the agent's instructions, then enter a task to complete using tools.",
                    "display_name": "message_response",
                    "name": "langflow_support_tool",
                    "readonly": false,
                    "status": true,
                    "tags": [
                      "Call_Agent"
                    ]
                  }
                ]
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "name": "verbose",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "Agent"
        },
        "dragging": false,
        "id": "Agent-03db7",
        "measured": {
          "height": 427,
          "width": 320
        },
        "position": {
          "x": 952.8107306048541,
          "y": 985.6579967979163
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt Template",
          "id": "Prompt Template-GZj4p",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": []
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "field_order": [
              "template",
              "use_double_brackets",
              "tool_placeholder"
            ],
            "frozen": false,
            "icon": "prompts",
            "legacy": false,
            "lf_version": "1.8.0",
            "metadata": {
              "code_hash": "595f7c9c8463",
              "dependencies": {
                "dependencies": [
                  {
                    "name": "lfx",
                    "version": null
                  }
                ],
                "total_dependencies": 1
              },
              "module": "custom_components.prompt_template"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "loop_types": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom lfx.base.prompts.api_utils import process_prompt_template\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.input_mixin import FieldTypes\nfrom lfx.inputs.inputs import DefaultPromptField\nfrom lfx.io import BoolInput, MessageTextInput, Output, PromptInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.dotdict import dotdict\nfrom lfx.schema.message import Message\nfrom lfx.template.utils import update_template_values\nfrom lfx.utils.mustache_security import validate_mustache_template\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        BoolInput(\n            name=\"use_double_brackets\",\n            display_name=\"Use Double Brackets\",\n            value=False,\n            advanced=True,\n            info=\"Use {{variable}} syntax instead of {variable}.\",\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        \"\"\"Update the template field type based on the selected mode.\"\"\"\n        if field_name == \"use_double_brackets\":\n            # Change the template field type based on mode\n            is_mustache = field_value is True\n            if is_mustache:\n                build_config[\"template\"][\"type\"] = FieldTypes.MUSTACHE_PROMPT.value\n            else:\n                build_config[\"template\"][\"type\"] = FieldTypes.PROMPT.value\n\n            # Re-process the template to update variables when mode changes\n            template_value = build_config.get(\"template\", {}).get(\"value\", \"\")\n            if template_value:\n                # Ensure custom_fields is properly initialized\n                if \"custom_fields\" not in build_config:\n                    build_config[\"custom_fields\"] = {}\n\n                # Clean up fields from the OLD mode before processing with NEW mode\n                # This ensures we don't keep fields with wrong syntax even if validation fails\n                old_custom_fields = build_config[\"custom_fields\"].get(\"template\", [])\n                for old_field in list(old_custom_fields):\n                    # Remove the field from custom_fields and template\n                    if old_field in old_custom_fields:\n                        old_custom_fields.remove(old_field)\n                    build_config.pop(old_field, None)\n\n                # Try to process template with new mode to add new variables\n                # If validation fails, at least we cleaned up old fields\n                try:\n                    # Validate mustache templates for security\n                    if is_mustache:\n                        validate_mustache_template(template_value)\n\n                    # Re-process template with new mode to add new variables\n                    _ = process_prompt_template(\n                        template=template_value,\n                        name=\"template\",\n                        custom_fields=build_config[\"custom_fields\"],\n                        frontend_node_template=build_config,\n                        is_mustache=is_mustache,\n                    )\n                except ValueError as e:\n                    # If validation fails, we still updated the mode and cleaned old fields\n                    # User will see error when they try to save\n                    logger.debug(f\"Template validation failed during mode switch: {e}\")\n        return build_config\n\n    async def build_prompt(self) -> Message:\n        use_double_brackets = self.use_double_brackets if hasattr(self, \"use_double_brackets\") else False\n        template_format = \"mustache\" if use_double_brackets else \"f-string\"\n        prompt = await Message.from_template_and_variables(template_format=template_format, **self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        use_double_brackets = frontend_node[\"template\"].get(\"use_double_brackets\", {}).get(\"value\", False)\n        is_mustache = use_double_brackets is True\n\n        try:\n            # Validate mustache templates for security\n            if is_mustache:\n                validate_mustache_template(prompt_template)\n\n            custom_fields = frontend_node[\"custom_fields\"]\n            frontend_node_template = frontend_node[\"template\"]\n            _ = process_prompt_template(\n                template=prompt_template,\n                name=\"template\",\n                custom_fields=custom_fields,\n                frontend_node_template=frontend_node_template,\n                is_mustache=is_mustache,\n            )\n        except ValueError as e:\n            # If validation fails, don't add variables but allow component to be created\n            logger.debug(f\"Template validation failed in _update_template: {e}\")\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        use_double_brackets = frontend_node[\"template\"].get(\"use_double_brackets\", {}).get(\"value\", False)\n        is_mustache = use_double_brackets is True\n\n        try:\n            # Validate mustache templates for security\n            if is_mustache:\n                validate_mustache_template(template)\n\n            # Kept it duplicated for backwards compatibility\n            _ = process_prompt_template(\n                template=template,\n                name=\"template\",\n                custom_fields=frontend_node[\"custom_fields\"],\n                frontend_node_template=frontend_node[\"template\"],\n                is_mustache=is_mustache,\n            )\n        except ValueError as e:\n            # If validation fails, don't add variables but allow component to be updated\n            logger.debug(f\"Template validation failed in update_frontend_node: {e}\")\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "template",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "track_in_telemetry": false,
                "type": "prompt",
                "value": "# Role\nYou are the Langflow Official Support Agent. Your purpose is to assist users with technical questions, troubleshooting, and implementation details regarding Langflow.\n\n# Capabilities & Tools\nYou have access to a browsing tool that allows you to read external URLs. You must use this tool to fetch the content of the documentation pages listed below to provide accurate, up-to-date answers.\n\n# Instructions\n1. **Analyze:** specific topic of the user's query.\n2. **Select:** Identify the *single most relevant* URL from the \"Documentation Index\" below that answers the specific question. Do not browse multiple pages unless strictly necessary.\n3. **Browse:** Use the browsing tool to read the content of the selected URL.\n4. **Answer:** Provide a concise but informative summary based *only* on the retrieved content.\n5. **Cite:** You MUST end your response with the specific link used to source the information.\n\n# Response Guidelines\n- Keep answers brief and direct.\n- Do not halluncinate features; rely on the documentation text.\n- Format the citation clearly at the bottom, e.g., \"Source: [URL]\"\n\n# Documentation Index\nSelect the appropriate link from this list based on the user's intent:\n\n## Getting Started & Tutorials\n- https://docs.langflow.org/ : General introduction and home page.\n- https://docs.langflow.org/get-started-quickstart : Installation guide and first steps.\n- https://docs.langflow.org/chat-with-rag : Tutorial on building RAG (Retrieval-Augmented Generation) pipelines.\n- https://docs.langflow.org/chat-with-files : Guide on how to chat with uploaded files/documents.\n- https://docs.langflow.org/agent-tutorial : Step-by-step tutorial for building agents.\n\n## Core Concepts\n- https://docs.langflow.org/concepts-overview : High-level overview of Langflow architecture.\n- https://docs.langflow.org/concepts-flows : Explanation of Flow structure and logic.\n- https://docs.langflow.org/concepts-playground : How to use the UI Playground to test flows.\n- https://docs.langflow.org/concepts-components : Understanding individual components and nodes.\n- https://docs.langflow.org/data-types : details on data types passed between components.\n- https://docs.langflow.org/concepts-file-management : How Langflow handles file uploads and storage.\n- https://docs.langflow.org/concepts-voice-mode : Information on voice interaction capabilities.\n\n## Agents & MCP (Model Context Protocol)\n- https://docs.langflow.org/agents : General concepts of AI Agents in Langflow.\n- https://docs.langflow.org/agents-tools : How to equip agents with tools.\n- https://docs.langflow.org/mcp-client : Using Langflow as an MCP Client.\n- https://docs.langflow.org/mcp-server : Using Langflow as an MCP Server.\n- https://docs.langflow.org/mcp-component-astra : DataStax Astra DB MCP component details.\n\n## Configuration & Environment\n- https://docs.langflow.org/configuration-global-variables : Setting up global variables.\n- https://docs.langflow.org/environment-variables : List of supported environment variables.\n- https://docs.langflow.org/api-keys-and-authentication : Managing API keys and security.\n- https://docs.langflow.org/install-custom-dependencies : How to install Python packages/dependencies.\n- https://docs.langflow.org/configuration-cli : Command Line Interface (CLI) references.\n- https://docs.langflow.org/configuration-custom-database : Configuring external databases.\n- https://docs.langflow.org/enterprise-database-guide : Enterprise-grade database setups.\n\n## Features & Integrations\n- https://docs.langflow.org/webhook : How to use Webhooks to trigger flows.\n- https://docs.langflow.org/memory : Understanding conversational memory handling.\n- https://docs.langflow.org/session-id : Managing Session IDs for users.\n- https://docs.langflow.org/concepts-flows-import : Importing and exporting flows.\n- https://docs.langflow.org/concepts-publish : Publishing flows as services.\n- https://docs.langflow.org/logging : Logging and monitoring configurations.\n- https://docs.langflow.org/integrations-langsmith : Integration with LangSmith.\n- https://docs.langflow.org/integrations-langfuse : Integration with LangFuse.\n- https://docs.langflow.org/integrations-langwatch : Integration with LangWatch.\n\n## API & Deployment\n- https://docs.langflow.org/api-reference-api-examples : API endpoints and usage examples.\n- https://docs.langflow.org/deployment-overview : Strategies for deploying Langflow to production.\n\n## Advanced & Customization\n- https://docs.langflow.org/components-bundle-components : Creating bundled custom components.\n- https://docs.langflow.org/troubleshoot : Common issues and fixes.\n- https://docs.langflow.org/contributing-how-to-contribute : Guide for developers contributing to the code.\n- https://docs.langflow.org/contributing-github-issues : Reporting bugs on GitHub.\n- https://docs.langflow.org/contributing-telemetry : Information on data collection/telemetry.\n- https://docs.langflow.org/luna-for-langflow : Info about Luna, the AI assistant.\n- https://docs.langflow.org/release-notes : Latest updates and version history."
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "override_skip": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "track_in_telemetry": false,
                "type": "str",
                "value": ""
              },
              "use_double_brackets": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Use Double Brackets",
                "dynamic": false,
                "info": "Use {{variable}} syntax instead of {variable}.",
                "list": false,
                "list_add_label": "Add More",
                "name": "use_double_brackets",
                "override_skip": false,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "track_in_telemetry": true,
                "type": "bool",
                "value": false
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-GZj4p",
        "measured": {
          "height": 284,
          "width": 320
        },
        "position": {
          "x": 159.80101120943442,
          "y": 1212.580044324385
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": 156.3272154980083,
      "y": 114.42053898869298,
      "zoom": 0.3745858028672607
    }
  },
  "description": "Harness the Power of Conversational AI.",
  "endpoint_name": null,
  "id": "66eb7678-93d8-450d-9ddf-0c09b8c1eee9",
  "is_component": false,
  "last_tested_version": "1.8.0",
  "name": "LF Assistant",
  "tags": []
}