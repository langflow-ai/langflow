"""Langflow Assistant API router.

This module provides the HTTP endpoints for the Langflow Assistant.
All business logic is delegated to service modules.
"""

import uuid

from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
from lfx.base.models.unified_models import (
    get_model_provider_variable_mapping,
    get_unified_models_detailed,
)
from lfx.log.logger import logger

from langflow.agentic.api.schemas import AssistantRequest
from langflow.agentic.services.assistant_service import (
    LANGFLOW_ASSISTANT_FLOW,
    MAX_VALIDATION_RETRIES,
    execute_flow_with_validation,
    execute_flow_with_validation_streaming,
)
from langflow.agentic.services.flow_executor import execute_flow_file
from langflow.agentic.services.provider_service import (
    DEFAULT_MODELS,
    PREFERRED_PROVIDERS,
    check_api_key,
    get_enabled_providers_for_user,
)
from langflow.api.utils.core import CurrentActiveUser, DbSession
from langflow.services.deps import get_variable_service
from langflow.services.variable.constants import CREDENTIAL_TYPE
from langflow.services.variable.service import DatabaseVariableService

router = APIRouter(prefix="/agentic", tags=["Agentic"])


@router.post("/execute/{flow_name}")
async def execute_named_flow(
    flow_name: str,
    request: AssistantRequest,
    current_user: CurrentActiveUser,
    session: DbSession,
) -> dict:
    """Execute a named flow from the flows directory."""
    variable_service = get_variable_service()
    user_id = current_user.id

    global_vars = {
        "USER_ID": str(user_id),
        "FLOW_ID": request.flow_id,
    }

    if request.component_id:
        global_vars["COMPONENT_ID"] = request.component_id
    if request.field_name:
        global_vars["FIELD_NAME"] = request.field_name

    try:
        openai_key = await variable_service.get_variable(user_id, "OPENAI_API_KEY", "", session)
        global_vars["OPENAI_API_KEY"] = openai_key
    except (ValueError, HTTPException):
        logger.debug("OPENAI_API_KEY not configured, continuing without it")

    flow_filename = f"{flow_name}.json"
    # Generate unique session_id per request to isolate memory
    session_id = str(uuid.uuid4())

    return await execute_flow_file(
        flow_filename=flow_filename,
        input_value=request.input_value,
        global_variables=global_vars,
        verbose=True,
        session_id=session_id,
    )


@router.get("/check-config")
async def check_assistant_config(
    current_user: CurrentActiveUser,
    session: DbSession,
) -> dict:
    """Check if the Langflow Assistant is properly configured.

    Returns available providers with their configured status and available models.
    """
    user_id = current_user.id
    variable_service = get_variable_service()

    enabled_providers: list[str] = []
    if isinstance(variable_service, DatabaseVariableService):
        all_variables = await variable_service.get_all(user_id=user_id, session=session)
        credential_names = {var.name for var in all_variables if var.type == CREDENTIAL_TYPE}

        if credential_names:
            provider_variable_map = get_model_provider_variable_mapping()
            for provider, var_name in provider_variable_map.items():
                if var_name in credential_names:
                    enabled_providers.append(provider)

    all_providers = []

    if enabled_providers:
        models_by_provider = get_unified_models_detailed(
            providers=enabled_providers,
            include_unsupported=False,
            include_deprecated=False,
            model_type="language",
        )

        for provider_dict in models_by_provider:
            provider_name = provider_dict.get("provider")
            models = provider_dict.get("models", [])

            model_list = []
            for model in models:
                model_name = model.get("model_name")
                display_name = model.get("display_name", model_name)
                metadata = model.get("metadata", {})

                is_deprecated = metadata.get("deprecated", False)
                is_not_supported = metadata.get("not_supported", False)

                if not is_deprecated and not is_not_supported:
                    model_list.append(
                        {
                            "name": model_name,
                            "display_name": display_name,
                        }
                    )

            default_model = DEFAULT_MODELS.get(provider_name)
            if not default_model and model_list:
                default_model = model_list[0]["name"]

            if model_list:
                all_providers.append(
                    {
                        "name": provider_name,
                        "configured": True,
                        "default_model": default_model,
                        "models": model_list,
                    }
                )

    default_provider = None
    default_model = None

    providers_with_models = [p["name"] for p in all_providers]

    for preferred in PREFERRED_PROVIDERS:
        if preferred in providers_with_models:
            default_provider = preferred
            for p in all_providers:
                if p["name"] == preferred:
                    default_model = p["default_model"]
                    break
            break

    if not default_provider and all_providers:
        default_provider = all_providers[0]["name"]
        default_model = all_providers[0]["default_model"]

    return {
        "configured": len(enabled_providers) > 0,
        "configured_providers": enabled_providers,
        "providers": all_providers,
        "default_provider": default_provider,
        "default_model": default_model,
    }


@router.post("/assist")
async def assist(
    request: AssistantRequest,
    current_user: CurrentActiveUser,
    session: DbSession,
) -> dict:
    """Chat with the Langflow Assistant.

    This endpoint executes the LangflowAssistant.json flow to help users with
    Langflow-related questions, guidance, and component creation.
    """
    variable_service = get_variable_service()
    user_id = current_user.id

    provider_variable_map = get_model_provider_variable_mapping()
    enabled_providers, _ = await get_enabled_providers_for_user(user_id, session)

    if not enabled_providers:
        raise HTTPException(
            status_code=400,
            detail="No model provider is configured. Please configure at least one model provider in Settings.",
        )

    provider = request.provider
    if not provider:
        for preferred in PREFERRED_PROVIDERS:
            if preferred in enabled_providers:
                provider = preferred
                break
        if not provider:
            provider = enabled_providers[0]

    if provider not in enabled_providers:
        raise HTTPException(
            status_code=400,
            detail=f"Provider '{provider}' is not configured. Available providers: {enabled_providers}",
        )

    api_key_name = provider_variable_map.get(provider)
    if not api_key_name:
        raise HTTPException(
            status_code=400,
            detail=f"Unknown provider: {provider}",
        )

    model_name = request.model_name or DEFAULT_MODELS.get(provider) or ""

    api_key = await check_api_key(variable_service, user_id, api_key_name, session)

    if not api_key:
        raise HTTPException(
            status_code=400,
            detail=(
                f"{api_key_name} is required for the Langflow Assistant with {provider}. "
                "Please configure it in Settings > Model Providers."
            ),
        )

    global_vars: dict[str, str] = {
        "USER_ID": str(user_id),
        "FLOW_ID": request.flow_id,
        api_key_name: api_key,
        "MODEL_NAME": model_name,
        "PROVIDER": provider,
    }

    # Use session_id from request if provided, otherwise generate new one
    session_id = request.session_id or str(uuid.uuid4())

    input_preview = request.input_value[:50] if request.input_value else "None"
    logger.info(f"Executing {LANGFLOW_ASSISTANT_FLOW} with {provider}/{model_name}, input: {input_preview}...")

    max_retries = request.max_retries if request.max_retries is not None else MAX_VALIDATION_RETRIES
    return await execute_flow_with_validation(
        flow_filename=LANGFLOW_ASSISTANT_FLOW,
        input_value=request.input_value or "",
        global_variables=global_vars,
        max_retries=max_retries,
        user_id=str(user_id),
        session_id=session_id,
        provider=provider,
        model_name=model_name,
        api_key_var=api_key_name,
    )


@router.post("/assist/stream")
async def assist_stream(
    request: AssistantRequest,
    current_user: CurrentActiveUser,
    session: DbSession,
) -> StreamingResponse:
    """Chat with the Langflow Assistant with streaming progress updates.

    Returns Server-Sent Events (SSE) with progress updates during generation
    and validation.
    """
    variable_service = get_variable_service()
    user_id = current_user.id

    provider_variable_map = get_model_provider_variable_mapping()
    enabled_providers, _ = await get_enabled_providers_for_user(user_id, session)

    if not enabled_providers:
        raise HTTPException(
            status_code=400,
            detail="No model provider is configured. Please configure at least one model provider in Settings.",
        )

    provider = request.provider
    if not provider:
        for preferred in PREFERRED_PROVIDERS:
            if preferred in enabled_providers:
                provider = preferred
                break
        if not provider:
            provider = enabled_providers[0]

    if provider not in enabled_providers:
        raise HTTPException(
            status_code=400,
            detail=f"Provider '{provider}' is not configured. Available providers: {enabled_providers}",
        )

    api_key_name = provider_variable_map.get(provider)
    if not api_key_name:
        raise HTTPException(
            status_code=400,
            detail=f"Unknown provider: {provider}",
        )

    model_name = request.model_name or DEFAULT_MODELS.get(provider) or ""

    api_key = await check_api_key(variable_service, user_id, api_key_name, session)

    if not api_key:
        raise HTTPException(
            status_code=400,
            detail=(
                f"{api_key_name} is required for the Langflow Assistant with {provider}. "
                "Please configure it in Settings > Model Providers."
            ),
        )

    global_vars: dict[str, str] = {
        "USER_ID": str(user_id),
        "FLOW_ID": request.flow_id,
        api_key_name: api_key,
        "MODEL_NAME": model_name,
        "PROVIDER": provider,
    }

    # Use session_id from request if provided, otherwise generate new one
    session_id = request.session_id or str(uuid.uuid4())

    max_retries = request.max_retries if request.max_retries is not None else MAX_VALIDATION_RETRIES

    return StreamingResponse(
        execute_flow_with_validation_streaming(
            flow_filename=LANGFLOW_ASSISTANT_FLOW,
            input_value=request.input_value or "",
            global_variables=global_vars,
            max_retries=max_retries,
            user_id=str(user_id),
            session_id=session_id,
            provider=provider,
            model_name=model_name,
            api_key_var=api_key_name,
        ),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
        },
    )
