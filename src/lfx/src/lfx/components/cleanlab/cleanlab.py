from cleanlab_codex import Project

from lfx.custom import Component
from lfx.io import (
    MessageTextInput,
    Output,
    PromptInput,
    SecretStrInput,
)
from lfx.schema.message import Message


class Cleanlab(Component):
    """The Cleanlab AI Platform is an end-to-end safety and reliability layer for your AI application.

    It enables both technical and non-technical team members to monitor, guardrail, evaluate,
    and directly remediate critical AI failures, gaps, and safety risks.

    Easily integrated into any AI application, Cleanlab:
      - Logs and scores every AI input and output in real time.
      - Surfaces consumable analytics to continuously monitor overall AI performance.
      - Prioritizes issues for SMEs to provide answers and patches.
      - Unblocks teams of all skill levels to safeguard AI systems with guardrails.

    Cleanlab is the leading platform to detect, prioritize, resolve,
    and prevent bad responses from any AI Agent or RAG application.

    This component validates an AI response using Cleanlab
    and provides expert remediations or fallback text if necessary.

    Sign up for a Cleanlab account here: https://codex.cleanlab.ai/

    Inputs:
        - api_key (SecretStrInput): Your Cleanlab access key.
        - system_message (MessageTextInput): Optional system instructions (prepended as first message).
        - input (MessageTextInput): User input message to include in messages.
        - query (MessageTextInput): The user's query (core user question).
        - response (MessageTextInput): The generated response from your RAG system.
        - context (MessageTextInput, optional): Retrieved context for the user's query. Defaults to "" if not provided.
        - fallback_text (PromptInput): Text to use if the response is flagged as bad and no expert answer is available.
        - quality_preset (DropdownInput, optional): Quality preset to use for evaluation. Defaults to 'best'.

    Output:
        - final_response (Message): Either the original response, an expert remediated answer, or fallback text.
    """

    display_name = "Cleanlab"
    description = (
        "Monitors, guardrails, evaluates, and directly remediates critical AI failures, gaps, and safety risks."
    )
    icon = "Cleanlab"
    name = "Cleanlab"

    inputs = [
        SecretStrInput(
            name="api_key",
            display_name="API Key",
            info="Your Cleanlab access key.",
            required=True,
        ),
        MessageTextInput(
            name="input",
            display_name="Input",
            info="The complete input message passed into the LLM to produce the response.",
            required=True,
        ),
        MessageTextInput(
            name="query",
            display_name="User Query",
            info="The user's core query (output of Chat Input component). "
            "This should not include any system message, context, etc.",
            required=True,
        ),
        MessageTextInput(
            name="response",
            display_name="Model Response",
            info="The final response generated by your LLM, Agent, etc.",
            required=True,
        ),
        MessageTextInput(
            name="context",
            display_name="Context (Optional)",
            info="The context retrieved for the user's query. Defaults to empty string if not provided.",
            required=False,
        ),
        MessageTextInput(
            name="system_message",
            display_name="System Message (Optional)",
            info="Any system instructions or messages given to the LLM, Agent, etc.",
            required=False,
        ),
        PromptInput(
            name="fallback_text",
            display_name="Fallback Answer",
            info="Fallback message used when response is bad and no expert answer is returned.",
            value="Sorry, I cannot provide a reliable answer to your question based on the current context.",
        ),
    ]

    outputs = [
        Output(
            display_name="Final Response",
            name="final_response",
            method="get_final_response",
            types=["Message"],
        ),
    ]

    def get_final_response(self) -> Message:
        project = Project.from_access_key(self.api_key)

        # Build messages for validate()
        messages = []
        if getattr(self, "system_message", None):
            messages.append({"role": "system", "content": self.system_message})
        messages.append({"role": "user", "content": self.input})

        result = project.validate(
            messages=messages,
            response=self.response,
            query=self.query,
            context=self.context if getattr(self, "context", None) else "",
        )

        if result.is_bad_response:
            if result.expert_answer:
                self.status = "Bad response replaced with expert answer."
                return Message(text=result.expert_answer)
            self.status = "Bad response with no expert answer. Using fallback."
            return Message(text=self.fallback_text)

        self.status = "Original response accepted."
        return Message(text=self.response)
