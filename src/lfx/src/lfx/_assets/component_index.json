{"entries":[["FAISS",{"FAISS":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"FAISS Vector Store with search capabilities","display_name":"FAISS","documentation":"","edited":false,"field_order":["index_name","persist_directory","ingest_data","search_query","should_cache_vector_store","allow_dangerous_deserialization","embedding","number_of_results"],"frozen":false,"icon":"FAISS","legacy":false,"metadata":{"code_hash":"2bd7a064d724","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.FAISS.faiss.FaissVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","allow_dangerous_deserialization":{"_input_type":"BoolInput","advanced":true,"display_name":"Allow Dangerous Deserialization","dynamic":false,"info":"Set to True to allow loading pickle files from untrusted sources. Only enable this if you trust the source of the data.","list":false,"list_add_label":"Add More","name":"allow_dangerous_deserialization","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from pathlib import Path\n\nfrom langchain_community.vectorstores import FAISS\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.io import BoolInput, HandleInput, IntInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass FaissVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"FAISS Vector Store with search capabilities.\"\"\"\n\n    display_name: str = \"FAISS\"\n    description: str = \"FAISS Vector Store with search capabilities\"\n    name = \"FAISS\"\n    icon = \"FAISS\"\n\n    inputs = [\n        StrInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            value=\"langflow_index\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"Persist Directory\",\n            info=\"Path to save the FAISS index. It will be relative to where Langflow is running.\",\n        ),\n        *LCVectorStoreComponent.inputs,\n        BoolInput(\n            name=\"allow_dangerous_deserialization\",\n            display_name=\"Allow Dangerous Deserialization\",\n            info=\"Set to True to allow loading pickle files from untrusted sources. \"\n            \"Only enable this if you trust the source of the data.\",\n            advanced=True,\n            value=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n    ]\n\n    @staticmethod\n    def resolve_path(path: str) -> str:\n        \"\"\"Resolve the path relative to the Langflow root.\n\n        Args:\n            path: The path to resolve\n        Returns:\n            str: The resolved path as a string\n        \"\"\"\n        return str(Path(path).resolve())\n\n    def get_persist_directory(self) -> Path:\n        \"\"\"Returns the resolved persist directory path or the current directory if not set.\"\"\"\n        if self.persist_directory:\n            return Path(self.resolve_path(self.persist_directory))\n        return Path()\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> FAISS:\n        \"\"\"Builds the FAISS object.\"\"\"\n        path = self.get_persist_directory()\n        path.mkdir(parents=True, exist_ok=True)\n\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        faiss = FAISS.from_documents(documents=documents, embedding=self.embedding)\n        faiss.save_local(str(path), self.index_name)\n        return faiss\n\n    def search_documents(self) -> list[Data]:\n        \"\"\"Search for documents in the FAISS vector store.\"\"\"\n        path = self.get_persist_directory()\n        index_path = path / f\"{self.index_name}.faiss\"\n\n        if not index_path.exists():\n            vector_store = self.build_vector_store()\n        else:\n            vector_store = FAISS.load_local(\n                folder_path=str(path),\n                embeddings=self.embedding,\n                index_name=self.index_name,\n                allow_dangerous_deserialization=self.allow_dangerous_deserialization,\n            )\n\n        if not vector_store:\n            msg = \"Failed to load the FAISS index.\"\n            raise ValueError(msg)\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n            return docs_to_data(docs)\n        return []\n"},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"index_name":{"_input_type":"StrInput","advanced":false,"display_name":"Index Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"index_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"langflow_index"},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"persist_directory":{"_input_type":"StrInput","advanced":false,"display_name":"Persist Directory","dynamic":false,"info":"Path to save the FAISS index. It will be relative to where Langflow is running.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"persist_directory","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false}}],["Notion",{"AddContentToPage":{"base_classes":["Data","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Convert markdown text to Notion blocks and append them to a Notion page.","display_name":"Add Content to Page ","documentation":"https://developers.notion.com/reference/patch-block-children","edited":false,"field_order":["markdown_text","block_id","notion_secret"],"frozen":false,"icon":"NotionDirectoryLoader","legacy":false,"metadata":{"code_hash":"ffcd44201c09","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"bs4","version":"4.12.3"},{"name":"langchain","version":"0.3.23"},{"name":"markdown","version":"3.7"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":6},"module":"lfx.components.Notion.add_content_to_page.AddContentToPage"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"run_model","name":"api_run_model","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"api_build_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","block_id":{"_input_type":"StrInput","advanced":false,"display_name":"Page/Block ID","dynamic":false,"info":"The ID of the page/block to add the content.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"block_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nfrom typing import Any\n\nimport requests\nfrom bs4 import BeautifulSoup\nfrom langchain.tools import StructuredTool\nfrom markdown import markdown\nfrom pydantic import BaseModel, Field\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.field_typing import Tool\nfrom lfx.inputs.inputs import MultilineInput, SecretStrInput, StrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\n\nMIN_ROWS_IN_TABLE = 3\n\n\nclass AddContentToPage(LCToolComponent):\n    display_name: str = \"Add Content to Page \"\n    description: str = \"Convert markdown text to Notion blocks and append them to a Notion page.\"\n    documentation: str = \"https://developers.notion.com/reference/patch-block-children\"\n    icon = \"NotionDirectoryLoader\"\n\n    inputs = [\n        MultilineInput(\n            name=\"markdown_text\",\n            display_name=\"Markdown Text\",\n            info=\"The markdown text to convert to Notion blocks.\",\n        ),\n        StrInput(\n            name=\"block_id\",\n            display_name=\"Page/Block ID\",\n            info=\"The ID of the page/block to add the content.\",\n        ),\n        SecretStrInput(\n            name=\"notion_secret\",\n            display_name=\"Notion Secret\",\n            info=\"The Notion integration token.\",\n            required=True,\n        ),\n    ]\n\n    class AddContentToPageSchema(BaseModel):\n        markdown_text: str = Field(..., description=\"The markdown text to convert to Notion blocks.\")\n        block_id: str = Field(..., description=\"The ID of the page/block to add the content.\")\n\n    def run_model(self) -> Data:\n        result = self._add_content_to_page(self.markdown_text, self.block_id)\n        return Data(data=result, text=json.dumps(result))\n\n    def build_tool(self) -> Tool:\n        return StructuredTool.from_function(\n            name=\"add_content_to_notion_page\",\n            description=\"Convert markdown text to Notion blocks and append them to a Notion page.\",\n            func=self._add_content_to_page,\n            args_schema=self.AddContentToPageSchema,\n        )\n\n    def _add_content_to_page(self, markdown_text: str, block_id: str) -> dict[str, Any] | str:\n        try:\n            html_text = markdown(markdown_text)\n            soup = BeautifulSoup(html_text, \"html.parser\")\n            blocks = self.process_node(soup)\n\n            url = f\"https://api.notion.com/v1/blocks/{block_id}/children\"\n            headers = {\n                \"Authorization\": f\"Bearer {self.notion_secret}\",\n                \"Content-Type\": \"application/json\",\n                \"Notion-Version\": \"2022-06-28\",\n            }\n\n            data = {\n                \"children\": blocks,\n            }\n\n            response = requests.patch(url, headers=headers, json=data, timeout=10)\n            response.raise_for_status()\n\n            return response.json()\n        except requests.exceptions.RequestException as e:\n            error_message = f\"Error: Failed to add content to Notion page. {e}\"\n            if hasattr(e, \"response\") and e.response is not None:\n                error_message += f\" Status code: {e.response.status_code}, Response: {e.response.text}\"\n            return error_message\n        except Exception as e:  # noqa: BLE001\n            logger.debug(\"Error adding content to Notion page\", exc_info=True)\n            return f\"Error: An unexpected error occurred while adding content to Notion page. {e}\"\n\n    def process_node(self, node):\n        blocks = []\n        if isinstance(node, str):\n            text = node.strip()\n            if text:\n                if text.startswith(\"#\"):\n                    heading_level = text.count(\"#\", 0, 6)\n                    heading_text = text[heading_level:].strip()\n                    if heading_level in range(3):\n                        blocks.append(self.create_block(f\"heading_{heading_level + 1}\", heading_text))\n                else:\n                    blocks.append(self.create_block(\"paragraph\", text))\n        elif node.name == \"h1\":\n            blocks.append(self.create_block(\"heading_1\", node.get_text(strip=True)))\n        elif node.name == \"h2\":\n            blocks.append(self.create_block(\"heading_2\", node.get_text(strip=True)))\n        elif node.name == \"h3\":\n            blocks.append(self.create_block(\"heading_3\", node.get_text(strip=True)))\n        elif node.name == \"p\":\n            code_node = node.find(\"code\")\n            if code_node:\n                code_text = code_node.get_text()\n                language, code = self.extract_language_and_code(code_text)\n                blocks.append(self.create_block(\"code\", code, language=language))\n            elif self.is_table(str(node)):\n                blocks.extend(self.process_table(node))\n            else:\n                blocks.append(self.create_block(\"paragraph\", node.get_text(strip=True)))\n        elif node.name == \"ul\":\n            blocks.extend(self.process_list(node, \"bulleted_list_item\"))\n        elif node.name == \"ol\":\n            blocks.extend(self.process_list(node, \"numbered_list_item\"))\n        elif node.name == \"blockquote\":\n            blocks.append(self.create_block(\"quote\", node.get_text(strip=True)))\n        elif node.name == \"hr\":\n            blocks.append(self.create_block(\"divider\", \"\"))\n        elif node.name == \"img\":\n            blocks.append(self.create_block(\"image\", \"\", image_url=node.get(\"src\")))\n        elif node.name == \"a\":\n            blocks.append(self.create_block(\"bookmark\", node.get_text(strip=True), link_url=node.get(\"href\")))\n        elif node.name == \"table\":\n            blocks.extend(self.process_table(node))\n\n        for child in node.children:\n            if isinstance(child, str):\n                continue\n            blocks.extend(self.process_node(child))\n\n        return blocks\n\n    def extract_language_and_code(self, code_text):\n        lines = code_text.split(\"\\n\")\n        language = lines[0].strip()\n        code = \"\\n\".join(lines[1:]).strip()\n        return language, code\n\n    def is_code_block(self, text):\n        return text.startswith(\"```\")\n\n    def extract_code_block(self, text):\n        lines = text.split(\"\\n\")\n        language = lines[0].strip(\"`\").strip()\n        code = \"\\n\".join(lines[1:]).strip(\"`\").strip()\n        return language, code\n\n    def is_table(self, text):\n        rows = text.split(\"\\n\")\n        if len(rows) < MIN_ROWS_IN_TABLE:\n            return False\n\n        has_separator = False\n        for i, row in enumerate(rows):\n            if \"|\" in row:\n                cells = [cell.strip() for cell in row.split(\"|\")]\n                cells = [cell for cell in cells if cell]  # Remove empty cells\n                if i == 1 and all(set(cell) <= set(\"-|\") for cell in cells):\n                    has_separator = True\n                elif not cells:\n                    return False\n\n        return has_separator\n\n    def process_list(self, node, list_type):\n        blocks = []\n        for item in node.find_all(\"li\"):\n            item_text = item.get_text(strip=True)\n            checked = item_text.startswith(\"[x]\")\n            is_checklist = item_text.startswith(\"[ ]\") or checked\n\n            if is_checklist:\n                item_text = item_text.replace(\"[x]\", \"\").replace(\"[ ]\", \"\").strip()\n                blocks.append(self.create_block(\"to_do\", item_text, checked=checked))\n            else:\n                blocks.append(self.create_block(list_type, item_text))\n        return blocks\n\n    def process_table(self, node):\n        blocks = []\n        header_row = node.find(\"thead\").find(\"tr\") if node.find(\"thead\") else None\n        body_rows = node.find(\"tbody\").find_all(\"tr\") if node.find(\"tbody\") else []\n\n        if header_row or body_rows:\n            table_width = max(\n                len(header_row.find_all([\"th\", \"td\"])) if header_row else 0,\n                *(len(row.find_all([\"th\", \"td\"])) for row in body_rows),\n            )\n\n            table_block = self.create_block(\"table\", \"\", table_width=table_width, has_column_header=bool(header_row))\n            blocks.append(table_block)\n\n            if header_row:\n                header_cells = [cell.get_text(strip=True) for cell in header_row.find_all([\"th\", \"td\"])]\n                header_row_block = self.create_block(\"table_row\", header_cells)\n                blocks.append(header_row_block)\n\n            for row in body_rows:\n                cells = [cell.get_text(strip=True) for cell in row.find_all([\"th\", \"td\"])]\n                row_block = self.create_block(\"table_row\", cells)\n                blocks.append(row_block)\n\n        return blocks\n\n    def create_block(self, block_type: str, content: str, **kwargs) -> dict[str, Any]:\n        block: dict[str, Any] = {\n            \"object\": \"block\",\n            \"type\": block_type,\n            block_type: {},\n        }\n\n        if block_type in {\n            \"paragraph\",\n            \"heading_1\",\n            \"heading_2\",\n            \"heading_3\",\n            \"bulleted_list_item\",\n            \"numbered_list_item\",\n            \"quote\",\n        }:\n            block[block_type][\"rich_text\"] = [\n                {\n                    \"type\": \"text\",\n                    \"text\": {\n                        \"content\": content,\n                    },\n                }\n            ]\n        elif block_type == \"to_do\":\n            block[block_type][\"rich_text\"] = [\n                {\n                    \"type\": \"text\",\n                    \"text\": {\n                        \"content\": content,\n                    },\n                }\n            ]\n            block[block_type][\"checked\"] = kwargs.get(\"checked\", False)\n        elif block_type == \"code\":\n            block[block_type][\"rich_text\"] = [\n                {\n                    \"type\": \"text\",\n                    \"text\": {\n                        \"content\": content,\n                    },\n                }\n            ]\n            block[block_type][\"language\"] = kwargs.get(\"language\", \"plain text\")\n        elif block_type == \"image\":\n            block[block_type] = {\"type\": \"external\", \"external\": {\"url\": kwargs.get(\"image_url\", \"\")}}\n        elif block_type == \"divider\":\n            pass\n        elif block_type == \"bookmark\":\n            block[block_type][\"url\"] = kwargs.get(\"link_url\", \"\")\n        elif block_type == \"table\":\n            block[block_type][\"table_width\"] = kwargs.get(\"table_width\", 0)\n            block[block_type][\"has_column_header\"] = kwargs.get(\"has_column_header\", False)\n            block[block_type][\"has_row_header\"] = kwargs.get(\"has_row_header\", False)\n        elif block_type == \"table_row\":\n            block[block_type][\"cells\"] = [[{\"type\": \"text\", \"text\": {\"content\": cell}} for cell in content]]\n\n        return block\n"},"markdown_text":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Markdown Text","dynamic":false,"info":"The markdown text to convert to Notion blocks.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"markdown_text","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"notion_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Notion Secret","dynamic":false,"info":"The Notion integration token.","input_types":[],"load_from_db":true,"name":"notion_secret","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""}},"tool_mode":false},"NotionDatabaseProperties":{"base_classes":["Data","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Retrieve properties of a Notion database.","display_name":"List Database Properties ","documentation":"https://docs.langflow.org/integrations/notion/list-database-properties","edited":false,"field_order":["database_id","notion_secret"],"frozen":false,"icon":"NotionDirectoryLoader","legacy":false,"metadata":{"code_hash":"10e5883790bc","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"langchain","version":"0.3.23"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.Notion.list_database_properties.NotionDatabaseProperties"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"run_model","name":"api_run_model","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"api_build_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import requests\nfrom langchain.tools import StructuredTool\nfrom pydantic import BaseModel, Field\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.field_typing import Tool\nfrom lfx.inputs.inputs import SecretStrInput, StrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\n\n\nclass NotionDatabaseProperties(LCToolComponent):\n    display_name: str = \"List Database Properties \"\n    description: str = \"Retrieve properties of a Notion database.\"\n    documentation: str = \"https://docs.langflow.org/integrations/notion/list-database-properties\"\n    icon = \"NotionDirectoryLoader\"\n\n    inputs = [\n        StrInput(\n            name=\"database_id\",\n            display_name=\"Database ID\",\n            info=\"The ID of the Notion database.\",\n        ),\n        SecretStrInput(\n            name=\"notion_secret\",\n            display_name=\"Notion Secret\",\n            info=\"The Notion integration token.\",\n            required=True,\n        ),\n    ]\n\n    class NotionDatabasePropertiesSchema(BaseModel):\n        database_id: str = Field(..., description=\"The ID of the Notion database.\")\n\n    def run_model(self) -> Data:\n        result = self._fetch_database_properties(self.database_id)\n        if isinstance(result, str):\n            # An error occurred, return it as text\n            return Data(text=result)\n        # Success, return the properties\n        return Data(text=str(result), data=result)\n\n    def build_tool(self) -> Tool:\n        return StructuredTool.from_function(\n            name=\"notion_database_properties\",\n            description=\"Retrieve properties of a Notion database. Input should include the database ID.\",\n            func=self._fetch_database_properties,\n            args_schema=self.NotionDatabasePropertiesSchema,\n        )\n\n    def _fetch_database_properties(self, database_id: str) -> dict | str:\n        url = f\"https://api.notion.com/v1/databases/{database_id}\"\n        headers = {\n            \"Authorization\": f\"Bearer {self.notion_secret}\",\n            \"Notion-Version\": \"2022-06-28\",  # Use the latest supported version\n        }\n        try:\n            response = requests.get(url, headers=headers, timeout=10)\n            response.raise_for_status()\n            data = response.json()\n            return data.get(\"properties\", {})\n        except requests.exceptions.RequestException as e:\n            return f\"Error fetching Notion database properties: {e}\"\n        except ValueError as e:\n            return f\"Error parsing Notion API response: {e}\"\n        except Exception as e:  # noqa: BLE001\n            logger.debug(\"Error fetching Notion database properties\", exc_info=True)\n            return f\"An unexpected error occurred: {e}\"\n"},"database_id":{"_input_type":"StrInput","advanced":false,"display_name":"Database ID","dynamic":false,"info":"The ID of the Notion database.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"database_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"notion_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Notion Secret","dynamic":false,"info":"The Notion integration token.","input_types":[],"load_from_db":true,"name":"notion_secret","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""}},"tool_mode":false},"NotionListPages":{"base_classes":["Data","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Query a Notion database with filtering and sorting. The input should be a JSON string containing the 'filter' and 'sorts' objects. Example input:\n{\"filter\": {\"property\": \"Status\", \"select\": {\"equals\": \"Done\"}}, \"sorts\": [{\"timestamp\": \"created_time\", \"direction\": \"descending\"}]}","display_name":"List Pages ","documentation":"https://docs.langflow.org/integrations/notion/list-pages","edited":false,"field_order":["notion_secret","database_id","query_json"],"frozen":false,"icon":"NotionDirectoryLoader","legacy":false,"metadata":{"code_hash":"6b649a872172","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"langchain","version":"0.3.23"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.Notion.list_pages.NotionListPages"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"run_model","name":"api_run_model","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"api_build_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nfrom typing import Any\n\nimport requests\nfrom langchain.tools import StructuredTool\nfrom pydantic import BaseModel, Field\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.field_typing import Tool\nfrom lfx.inputs.inputs import MultilineInput, SecretStrInput, StrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\n\n\nclass NotionListPages(LCToolComponent):\n    display_name: str = \"List Pages \"\n    description: str = (\n        \"Query a Notion database with filtering and sorting. \"\n        \"The input should be a JSON string containing the 'filter' and 'sorts' objects. \"\n        \"Example input:\\n\"\n        '{\"filter\": {\"property\": \"Status\", \"select\": {\"equals\": \"Done\"}}, '\n        '\"sorts\": [{\"timestamp\": \"created_time\", \"direction\": \"descending\"}]}'\n    )\n    documentation: str = \"https://docs.langflow.org/integrations/notion/list-pages\"\n    icon = \"NotionDirectoryLoader\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"notion_secret\",\n            display_name=\"Notion Secret\",\n            info=\"The Notion integration token.\",\n            required=True,\n        ),\n        StrInput(\n            name=\"database_id\",\n            display_name=\"Database ID\",\n            info=\"The ID of the Notion database to query.\",\n        ),\n        MultilineInput(\n            name=\"query_json\",\n            display_name=\"Database query (JSON)\",\n            info=\"A JSON string containing the filters and sorts that will be used for querying the database. \"\n            \"Leave empty for no filters or sorts.\",\n        ),\n    ]\n\n    class NotionListPagesSchema(BaseModel):\n        database_id: str = Field(..., description=\"The ID of the Notion database to query.\")\n        query_json: str | None = Field(\n            default=\"\",\n            description=\"A JSON string containing the filters and sorts for querying the database. \"\n            \"Leave empty for no filters or sorts.\",\n        )\n\n    def run_model(self) -> list[Data]:\n        result = self._query_notion_database(self.database_id, self.query_json)\n\n        if isinstance(result, str):\n            # An error occurred, return it as a single record\n            return [Data(text=result)]\n\n        records = []\n        combined_text = f\"Pages found: {len(result)}\\n\\n\"\n\n        for page in result:\n            page_data = {\n                \"id\": page[\"id\"],\n                \"url\": page[\"url\"],\n                \"created_time\": page[\"created_time\"],\n                \"last_edited_time\": page[\"last_edited_time\"],\n                \"properties\": page[\"properties\"],\n            }\n\n            text = (\n                f\"id: {page['id']}\\n\"\n                f\"url: {page['url']}\\n\"\n                f\"created_time: {page['created_time']}\\n\"\n                f\"last_edited_time: {page['last_edited_time']}\\n\"\n                f\"properties: {json.dumps(page['properties'], indent=2)}\\n\\n\"\n            )\n\n            combined_text += text\n            records.append(Data(text=text, **page_data))\n\n        self.status = records\n        return records\n\n    def build_tool(self) -> Tool:\n        return StructuredTool.from_function(\n            name=\"notion_list_pages\",\n            description=self.description,\n            func=self._query_notion_database,\n            args_schema=self.NotionListPagesSchema,\n        )\n\n    def _query_notion_database(self, database_id: str, query_json: str | None = None) -> list[dict[str, Any]] | str:\n        url = f\"https://api.notion.com/v1/databases/{database_id}/query\"\n        headers = {\n            \"Authorization\": f\"Bearer {self.notion_secret}\",\n            \"Content-Type\": \"application/json\",\n            \"Notion-Version\": \"2022-06-28\",\n        }\n\n        query_payload = {}\n        if query_json and query_json.strip():\n            try:\n                query_payload = json.loads(query_json)\n            except json.JSONDecodeError as e:\n                return f\"Invalid JSON format for query: {e}\"\n\n        try:\n            response = requests.post(url, headers=headers, json=query_payload, timeout=10)\n            response.raise_for_status()\n            results = response.json()\n            return results[\"results\"]\n        except requests.exceptions.RequestException as e:\n            return f\"Error querying Notion database: {e}\"\n        except KeyError:\n            return \"Unexpected response format from Notion API\"\n        except Exception as e:  # noqa: BLE001\n            logger.debug(\"Error querying Notion database\", exc_info=True)\n            return f\"An unexpected error occurred: {e}\"\n"},"database_id":{"_input_type":"StrInput","advanced":false,"display_name":"Database ID","dynamic":false,"info":"The ID of the Notion database to query.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"database_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"notion_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Notion Secret","dynamic":false,"info":"The Notion integration token.","input_types":[],"load_from_db":true,"name":"notion_secret","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"query_json":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Database query (JSON)","dynamic":false,"info":"A JSON string containing the filters and sorts that will be used for querying the database. Leave empty for no filters or sorts.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"query_json","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"NotionPageContent":{"base_classes":["Data","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Retrieve the content of a Notion page as plain text.","display_name":"Page Content Viewer ","documentation":"https://docs.langflow.org/integrations/notion/page-content-viewer","edited":false,"field_order":["page_id","notion_secret"],"frozen":false,"icon":"NotionDirectoryLoader","legacy":false,"metadata":{"code_hash":"72e657df5236","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"langchain","version":"0.3.23"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.Notion.page_content_viewer.NotionPageContent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"run_model","name":"api_run_model","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"api_build_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import requests\nfrom langchain.tools import StructuredTool\nfrom pydantic import BaseModel, Field\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.field_typing import Tool\nfrom lfx.inputs.inputs import SecretStrInput, StrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\n\n\nclass NotionPageContent(LCToolComponent):\n    display_name = \"Page Content Viewer \"\n    description = \"Retrieve the content of a Notion page as plain text.\"\n    documentation = \"https://docs.langflow.org/integrations/notion/page-content-viewer\"\n    icon = \"NotionDirectoryLoader\"\n\n    inputs = [\n        StrInput(\n            name=\"page_id\",\n            display_name=\"Page ID\",\n            info=\"The ID of the Notion page to retrieve.\",\n        ),\n        SecretStrInput(\n            name=\"notion_secret\",\n            display_name=\"Notion Secret\",\n            info=\"The Notion integration token.\",\n            required=True,\n        ),\n    ]\n\n    class NotionPageContentSchema(BaseModel):\n        page_id: str = Field(..., description=\"The ID of the Notion page to retrieve.\")\n\n    def run_model(self) -> Data:\n        result = self._retrieve_page_content(self.page_id)\n        if isinstance(result, str) and result.startswith(\"Error:\"):\n            # An error occurred, return it as text\n            return Data(text=result)\n        # Success, return the content\n        return Data(text=result, data={\"content\": result})\n\n    def build_tool(self) -> Tool:\n        return StructuredTool.from_function(\n            name=\"notion_page_content\",\n            description=\"Retrieve the content of a Notion page as plain text.\",\n            func=self._retrieve_page_content,\n            args_schema=self.NotionPageContentSchema,\n        )\n\n    def _retrieve_page_content(self, page_id: str) -> str:\n        blocks_url = f\"https://api.notion.com/v1/blocks/{page_id}/children?page_size=100\"\n        headers = {\n            \"Authorization\": f\"Bearer {self.notion_secret}\",\n            \"Notion-Version\": \"2022-06-28\",\n        }\n        try:\n            blocks_response = requests.get(blocks_url, headers=headers, timeout=10)\n            blocks_response.raise_for_status()\n            blocks_data = blocks_response.json()\n            return self.parse_blocks(blocks_data.get(\"results\", []))\n        except requests.exceptions.RequestException as e:\n            error_message = f\"Error: Failed to retrieve Notion page content. {e}\"\n            if hasattr(e, \"response\") and e.response is not None:\n                error_message += f\" Status code: {e.response.status_code}, Response: {e.response.text}\"\n            return error_message\n        except Exception as e:  # noqa: BLE001\n            logger.debug(\"Error retrieving Notion page content\", exc_info=True)\n            return f\"Error: An unexpected error occurred while retrieving Notion page content. {e}\"\n\n    def parse_blocks(self, blocks: list) -> str:\n        content = \"\"\n        for block in blocks:\n            block_type = block.get(\"type\")\n            if block_type in {\"paragraph\", \"heading_1\", \"heading_2\", \"heading_3\", \"quote\"}:\n                content += self.parse_rich_text(block[block_type].get(\"rich_text\", [])) + \"\\n\\n\"\n            elif block_type in {\"bulleted_list_item\", \"numbered_list_item\"}:\n                content += self.parse_rich_text(block[block_type].get(\"rich_text\", [])) + \"\\n\"\n            elif block_type == \"to_do\":\n                content += self.parse_rich_text(block[\"to_do\"].get(\"rich_text\", [])) + \"\\n\"\n            elif block_type == \"code\":\n                content += self.parse_rich_text(block[\"code\"].get(\"rich_text\", [])) + \"\\n\\n\"\n            elif block_type == \"image\":\n                content += f\"[Image: {block['image'].get('external', {}).get('url', 'No URL')}]\\n\\n\"\n            elif block_type == \"divider\":\n                content += \"---\\n\\n\"\n        return content.strip()\n\n    def parse_rich_text(self, rich_text: list) -> str:\n        return \"\".join(segment.get(\"plain_text\", \"\") for segment in rich_text)\n\n    def __call__(self, *args, **kwargs):\n        return self._retrieve_page_content(*args, **kwargs)\n"},"notion_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Notion Secret","dynamic":false,"info":"The Notion integration token.","input_types":[],"load_from_db":true,"name":"notion_secret","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"page_id":{"_input_type":"StrInput","advanced":false,"display_name":"Page ID","dynamic":false,"info":"The ID of the Notion page to retrieve.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"page_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"NotionPageCreator":{"base_classes":["Data","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"A component for creating Notion pages.","display_name":"Create Page ","documentation":"https://docs.langflow.org/integrations/notion/page-create","edited":false,"field_order":["database_id","notion_secret","properties_json"],"frozen":false,"icon":"NotionDirectoryLoader","legacy":false,"metadata":{"code_hash":"a561b9f6a4b2","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"langchain","version":"0.3.23"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.Notion.create_page.NotionPageCreator"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"run_model","name":"api_run_model","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"api_build_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nfrom typing import Any\n\nimport requests\nfrom langchain.tools import StructuredTool\nfrom pydantic import BaseModel, Field\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.field_typing import Tool\nfrom lfx.inputs.inputs import MultilineInput, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass NotionPageCreator(LCToolComponent):\n    display_name: str = \"Create Page \"\n    description: str = \"A component for creating Notion pages.\"\n    documentation: str = \"https://docs.langflow.org/integrations/notion/page-create\"\n    icon = \"NotionDirectoryLoader\"\n\n    inputs = [\n        StrInput(\n            name=\"database_id\",\n            display_name=\"Database ID\",\n            info=\"The ID of the Notion database.\",\n        ),\n        SecretStrInput(\n            name=\"notion_secret\",\n            display_name=\"Notion Secret\",\n            info=\"The Notion integration token.\",\n            required=True,\n        ),\n        MultilineInput(\n            name=\"properties_json\",\n            display_name=\"Properties (JSON)\",\n            info=\"The properties of the new page as a JSON string.\",\n        ),\n    ]\n\n    class NotionPageCreatorSchema(BaseModel):\n        database_id: str = Field(..., description=\"The ID of the Notion database.\")\n        properties_json: str = Field(..., description=\"The properties of the new page as a JSON string.\")\n\n    def run_model(self) -> Data:\n        result = self._create_notion_page(self.database_id, self.properties_json)\n        if isinstance(result, str):\n            # An error occurred, return it as text\n            return Data(text=result)\n        # Success, return the created page data\n        output = \"Created page properties:\\n\"\n        for prop_name, prop_value in result.get(\"properties\", {}).items():\n            output += f\"{prop_name}: {prop_value}\\n\"\n        return Data(text=output, data=result)\n\n    def build_tool(self) -> Tool:\n        return StructuredTool.from_function(\n            name=\"create_notion_page\",\n            description=\"Create a new page in a Notion database. \"\n            \"IMPORTANT: Use the tool to check the Database properties for more details before using this tool.\",\n            func=self._create_notion_page,\n            args_schema=self.NotionPageCreatorSchema,\n        )\n\n    def _create_notion_page(self, database_id: str, properties_json: str) -> dict[str, Any] | str:\n        if not database_id or not properties_json:\n            return \"Invalid input. Please provide 'database_id' and 'properties_json'.\"\n\n        try:\n            properties = json.loads(properties_json)\n        except json.JSONDecodeError as e:\n            return f\"Invalid properties format. Please provide a valid JSON string. Error: {e}\"\n\n        headers = {\n            \"Authorization\": f\"Bearer {self.notion_secret}\",\n            \"Content-Type\": \"application/json\",\n            \"Notion-Version\": \"2022-06-28\",\n        }\n\n        data = {\n            \"parent\": {\"database_id\": database_id},\n            \"properties\": properties,\n        }\n\n        try:\n            response = requests.post(\"https://api.notion.com/v1/pages\", headers=headers, json=data, timeout=10)\n            response.raise_for_status()\n            return response.json()\n        except requests.exceptions.RequestException as e:\n            error_message = f\"Failed to create Notion page. Error: {e}\"\n            if hasattr(e, \"response\") and e.response is not None:\n                error_message += f\" Status code: {e.response.status_code}, Response: {e.response.text}\"\n            return error_message\n\n    def __call__(self, *args, **kwargs):\n        return self._create_notion_page(*args, **kwargs)\n"},"database_id":{"_input_type":"StrInput","advanced":false,"display_name":"Database ID","dynamic":false,"info":"The ID of the Notion database.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"database_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"notion_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Notion Secret","dynamic":false,"info":"The Notion integration token.","input_types":[],"load_from_db":true,"name":"notion_secret","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"properties_json":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Properties (JSON)","dynamic":false,"info":"The properties of the new page as a JSON string.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"properties_json","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"NotionPageUpdate":{"base_classes":["Data","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Update the properties of a Notion page.","display_name":"Update Page Property ","documentation":"https://docs.langflow.org/integrations/notion/page-update","edited":false,"field_order":["page_id","properties","notion_secret"],"frozen":false,"icon":"NotionDirectoryLoader","legacy":false,"metadata":{"code_hash":"b6098f31b0f5","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"langchain","version":"0.3.23"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.Notion.update_page_property.NotionPageUpdate"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"run_model","name":"api_run_model","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"api_build_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nfrom typing import Any\n\nimport requests\nfrom langchain.tools import StructuredTool\nfrom pydantic import BaseModel, Field\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.field_typing import Tool\nfrom lfx.inputs.inputs import MultilineInput, SecretStrInput, StrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\n\n\nclass NotionPageUpdate(LCToolComponent):\n    display_name: str = \"Update Page Property \"\n    description: str = \"Update the properties of a Notion page.\"\n    documentation: str = \"https://docs.langflow.org/integrations/notion/page-update\"\n    icon = \"NotionDirectoryLoader\"\n\n    inputs = [\n        StrInput(\n            name=\"page_id\",\n            display_name=\"Page ID\",\n            info=\"The ID of the Notion page to update.\",\n        ),\n        MultilineInput(\n            name=\"properties\",\n            display_name=\"Properties\",\n            info=\"The properties to update on the page (as a JSON string or a dictionary).\",\n        ),\n        SecretStrInput(\n            name=\"notion_secret\",\n            display_name=\"Notion Secret\",\n            info=\"The Notion integration token.\",\n            required=True,\n        ),\n    ]\n\n    class NotionPageUpdateSchema(BaseModel):\n        page_id: str = Field(..., description=\"The ID of the Notion page to update.\")\n        properties: str | dict[str, Any] = Field(\n            ..., description=\"The properties to update on the page (as a JSON string or a dictionary).\"\n        )\n\n    def run_model(self) -> Data:\n        result = self._update_notion_page(self.page_id, self.properties)\n        if isinstance(result, str):\n            # An error occurred, return it as text\n            return Data(text=result)\n        # Success, return the updated page data\n        output = \"Updated page properties:\\n\"\n        for prop_name, prop_value in result.get(\"properties\", {}).items():\n            output += f\"{prop_name}: {prop_value}\\n\"\n        return Data(text=output, data=result)\n\n    def build_tool(self) -> Tool:\n        return StructuredTool.from_function(\n            name=\"update_notion_page\",\n            description=\"Update the properties of a Notion page. \"\n            \"IMPORTANT: Use the tool to check the Database properties for more details before using this tool.\",\n            func=self._update_notion_page,\n            args_schema=self.NotionPageUpdateSchema,\n        )\n\n    def _update_notion_page(self, page_id: str, properties: str | dict[str, Any]) -> dict[str, Any] | str:\n        url = f\"https://api.notion.com/v1/pages/{page_id}\"\n        headers = {\n            \"Authorization\": f\"Bearer {self.notion_secret}\",\n            \"Content-Type\": \"application/json\",\n            \"Notion-Version\": \"2022-06-28\",  # Use the latest supported version\n        }\n\n        # Parse properties if it's a string\n        if isinstance(properties, str):\n            try:\n                parsed_properties = json.loads(properties)\n            except json.JSONDecodeError as e:\n                error_message = f\"Invalid JSON format for properties: {e}\"\n                logger.exception(error_message)\n                return error_message\n\n        else:\n            parsed_properties = properties\n\n        data = {\"properties\": parsed_properties}\n\n        try:\n            logger.info(f\"Sending request to Notion API: URL: {url}, Data: {json.dumps(data)}\")\n            response = requests.patch(url, headers=headers, json=data, timeout=10)\n            response.raise_for_status()\n            updated_page = response.json()\n\n            logger.info(f\"Successfully updated Notion page. Response: {json.dumps(updated_page)}\")\n        except requests.exceptions.HTTPError as e:\n            error_message = f\"HTTP Error occurred: {e}\"\n            if e.response is not None:\n                error_message += f\"\\nStatus code: {e.response.status_code}\"\n                error_message += f\"\\nResponse body: {e.response.text}\"\n            logger.exception(error_message)\n            return error_message\n        except requests.exceptions.RequestException as e:\n            error_message = f\"An error occurred while making the request: {e}\"\n            logger.exception(error_message)\n            return error_message\n        except Exception as e:  # noqa: BLE001\n            error_message = f\"An unexpected error occurred: {e}\"\n            logger.exception(error_message)\n            return error_message\n\n        return updated_page\n\n    def __call__(self, *args, **kwargs):\n        return self._update_notion_page(*args, **kwargs)\n"},"notion_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Notion Secret","dynamic":false,"info":"The Notion integration token.","input_types":[],"load_from_db":true,"name":"notion_secret","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"page_id":{"_input_type":"StrInput","advanced":false,"display_name":"Page ID","dynamic":false,"info":"The ID of the Notion page to update.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"page_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"properties":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Properties","dynamic":false,"info":"The properties to update on the page (as a JSON string or a dictionary).","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"properties","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"NotionSearch":{"base_classes":["Data","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Searches all pages and databases that have been shared with an integration.","display_name":"Search ","documentation":"https://docs.langflow.org/integrations/notion/search","edited":false,"field_order":["notion_secret","query","filter_value","sort_direction"],"frozen":false,"icon":"NotionDirectoryLoader","legacy":false,"metadata":{"code_hash":"5840d86cda2d","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"langchain","version":"0.3.23"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.Notion.search.NotionSearch"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"run_model","name":"api_run_model","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"api_build_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nimport requests\nfrom langchain.tools import StructuredTool\nfrom pydantic import BaseModel, Field\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.field_typing import Tool\nfrom lfx.inputs.inputs import DropdownInput, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass NotionSearch(LCToolComponent):\n    display_name: str = \"Search \"\n    description: str = \"Searches all pages and databases that have been shared with an integration.\"\n    documentation: str = \"https://docs.langflow.org/integrations/notion/search\"\n    icon = \"NotionDirectoryLoader\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"notion_secret\",\n            display_name=\"Notion Secret\",\n            info=\"The Notion integration token.\",\n            required=True,\n        ),\n        StrInput(\n            name=\"query\",\n            display_name=\"Search Query\",\n            info=\"The text that the API compares page and database titles against.\",\n        ),\n        DropdownInput(\n            name=\"filter_value\",\n            display_name=\"Filter Type\",\n            info=\"Limits the results to either only pages or only databases.\",\n            options=[\"page\", \"database\"],\n            value=\"page\",\n        ),\n        DropdownInput(\n            name=\"sort_direction\",\n            display_name=\"Sort Direction\",\n            info=\"The direction to sort the results.\",\n            options=[\"ascending\", \"descending\"],\n            value=\"descending\",\n        ),\n    ]\n\n    class NotionSearchSchema(BaseModel):\n        query: str = Field(..., description=\"The search query text.\")\n        filter_value: str = Field(default=\"page\", description=\"Filter type: 'page' or 'database'.\")\n        sort_direction: str = Field(default=\"descending\", description=\"Sort direction: 'ascending' or 'descending'.\")\n\n    def run_model(self) -> list[Data]:\n        results = self._search_notion(self.query, self.filter_value, self.sort_direction)\n        records = []\n        combined_text = f\"Results found: {len(results)}\\n\\n\"\n\n        for result in results:\n            result_data = {\n                \"id\": result[\"id\"],\n                \"type\": result[\"object\"],\n                \"last_edited_time\": result[\"last_edited_time\"],\n            }\n\n            if result[\"object\"] == \"page\":\n                result_data[\"title_or_url\"] = result[\"url\"]\n                text = f\"id: {result['id']}\\ntitle_or_url: {result['url']}\\n\"\n            elif result[\"object\"] == \"database\":\n                if \"title\" in result and isinstance(result[\"title\"], list) and len(result[\"title\"]) > 0:\n                    result_data[\"title_or_url\"] = result[\"title\"][0][\"plain_text\"]\n                    text = f\"id: {result['id']}\\ntitle_or_url: {result['title'][0]['plain_text']}\\n\"\n                else:\n                    result_data[\"title_or_url\"] = \"N/A\"\n                    text = f\"id: {result['id']}\\ntitle_or_url: N/A\\n\"\n\n            text += f\"type: {result['object']}\\nlast_edited_time: {result['last_edited_time']}\\n\\n\"\n            combined_text += text\n            records.append(Data(text=text, data=result_data))\n\n        self.status = records\n        return records\n\n    def build_tool(self) -> Tool:\n        return StructuredTool.from_function(\n            name=\"notion_search\",\n            description=\"Search Notion pages and databases. \"\n            \"Input should include the search query and optionally filter type and sort direction.\",\n            func=self._search_notion,\n            args_schema=self.NotionSearchSchema,\n        )\n\n    def _search_notion(\n        self, query: str, filter_value: str = \"page\", sort_direction: str = \"descending\"\n    ) -> list[dict[str, Any]]:\n        url = \"https://api.notion.com/v1/search\"\n        headers = {\n            \"Authorization\": f\"Bearer {self.notion_secret}\",\n            \"Content-Type\": \"application/json\",\n            \"Notion-Version\": \"2022-06-28\",\n        }\n\n        data = {\n            \"query\": query,\n            \"filter\": {\"value\": filter_value, \"property\": \"object\"},\n            \"sort\": {\"direction\": sort_direction, \"timestamp\": \"last_edited_time\"},\n        }\n\n        response = requests.post(url, headers=headers, json=data, timeout=10)\n        response.raise_for_status()\n\n        results = response.json()\n        return results[\"results\"]\n"},"filter_value":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Filter Type","dynamic":false,"external_options":{},"info":"Limits the results to either only pages or only databases.","name":"filter_value","options":["page","database"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"page"},"notion_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Notion Secret","dynamic":false,"info":"The Notion integration token.","input_types":[],"load_from_db":true,"name":"notion_secret","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"query":{"_input_type":"StrInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"The text that the API compares page and database titles against.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"query","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"sort_direction":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Sort Direction","dynamic":false,"external_options":{},"info":"The direction to sort the results.","name":"sort_direction","options":["ascending","descending"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"descending"}},"tool_mode":false},"NotionUserList":{"base_classes":["Data","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Retrieve users from Notion.","display_name":"List Users ","documentation":"https://docs.langflow.org/integrations/notion/list-users","edited":false,"field_order":["notion_secret"],"frozen":false,"icon":"NotionDirectoryLoader","legacy":false,"metadata":{"code_hash":"adc59c2d29d8","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"langchain","version":"0.3.23"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.Notion.list_users.NotionUserList"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"run_model","name":"api_run_model","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"api_build_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import requests\nfrom langchain.tools import StructuredTool\nfrom pydantic import BaseModel\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.field_typing import Tool\nfrom lfx.inputs.inputs import SecretStrInput\nfrom lfx.schema.data import Data\n\n\nclass NotionUserList(LCToolComponent):\n    display_name = \"List Users \"\n    description = \"Retrieve users from Notion.\"\n    documentation = \"https://docs.langflow.org/integrations/notion/list-users\"\n    icon = \"NotionDirectoryLoader\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"notion_secret\",\n            display_name=\"Notion Secret\",\n            info=\"The Notion integration token.\",\n            required=True,\n        ),\n    ]\n\n    class NotionUserListSchema(BaseModel):\n        pass\n\n    def run_model(self) -> list[Data]:\n        users = self._list_users()\n        records = []\n        combined_text = \"\"\n\n        for user in users:\n            output = \"User:\\n\"\n            for key, value in user.items():\n                output += f\"{key.replace('_', ' ').title()}: {value}\\n\"\n            output += \"________________________\\n\"\n\n            combined_text += output\n            records.append(Data(text=output, data=user))\n\n        self.status = records\n        return records\n\n    def build_tool(self) -> Tool:\n        return StructuredTool.from_function(\n            name=\"notion_list_users\",\n            description=\"Retrieve users from Notion.\",\n            func=self._list_users,\n            args_schema=self.NotionUserListSchema,\n        )\n\n    def _list_users(self) -> list[dict]:\n        url = \"https://api.notion.com/v1/users\"\n        headers = {\n            \"Authorization\": f\"Bearer {self.notion_secret}\",\n            \"Notion-Version\": \"2022-06-28\",\n        }\n\n        response = requests.get(url, headers=headers, timeout=10)\n        response.raise_for_status()\n\n        data = response.json()\n        results = data[\"results\"]\n\n        users = []\n        for user in results:\n            user_data = {\n                \"id\": user[\"id\"],\n                \"type\": user[\"type\"],\n                \"name\": user.get(\"name\", \"\"),\n                \"avatar_url\": user.get(\"avatar_url\", \"\"),\n            }\n            users.append(user_data)\n\n        return users\n"},"notion_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Notion Secret","dynamic":false,"info":"The Notion integration token.","input_types":[],"load_from_db":true,"name":"notion_secret","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""}},"tool_mode":false}}],["agentql",{"AgentQL":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Extracts structured data from a web page using an AgentQL query or a Natural Language description.","display_name":"Extract Web Data","documentation":"https://docs.agentql.com/rest-api/api-reference","edited":false,"field_order":["api_key","url","query","prompt","is_stealth_mode_enabled","timeout","mode","wait_for","is_scroll_to_bottom_enabled","is_screenshot_enabled"],"frozen":false,"icon":"AgentQL","legacy":false,"metadata":{"code_hash":"37de3210aed9","dependencies":{"dependencies":[{"name":"httpx","version":"0.28.1"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.agentql.agentql_api.AgentQL"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"build_output","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"AgentQL API Key","dynamic":false,"info":"Your AgentQL API key from dev.agentql.com","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import httpx\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.io import BoolInput, DropdownInput, IntInput, MessageTextInput, MultilineInput, Output, SecretStrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\n\n\nclass AgentQL(Component):\n    display_name = \"Extract Web Data\"\n    description = \"Extracts structured data from a web page using an AgentQL query or a Natural Language description.\"\n    documentation: str = \"https://docs.agentql.com/rest-api/api-reference\"\n    icon = \"AgentQL\"\n    name = \"AgentQL\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"AgentQL API Key\",\n            required=True,\n            password=True,\n            info=\"Your AgentQL API key from dev.agentql.com\",\n        ),\n        MessageTextInput(\n            name=\"url\",\n            display_name=\"URL\",\n            required=True,\n            info=\"The URL of the public web page you want to extract data from.\",\n            tool_mode=True,\n        ),\n        MultilineInput(\n            name=\"query\",\n            display_name=\"AgentQL Query\",\n            required=False,\n            info=\"The AgentQL query to execute. Learn more at https://docs.agentql.com/agentql-query or use a prompt.\",\n            tool_mode=True,\n        ),\n        MultilineInput(\n            name=\"prompt\",\n            display_name=\"Prompt\",\n            required=False,\n            info=\"A Natural Language description of the data to extract from the page. Alternative to AgentQL query.\",\n            tool_mode=True,\n        ),\n        BoolInput(\n            name=\"is_stealth_mode_enabled\",\n            display_name=\"Enable Stealth Mode (Beta)\",\n            info=\"Enable experimental anti-bot evasion strategies. May not work for all websites at all times.\",\n            value=False,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"Seconds to wait for a request.\",\n            value=900,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"mode\",\n            display_name=\"Request Mode\",\n            info=\"'standard' uses deep data analysis, while 'fast' trades some depth of analysis for speed.\",\n            options=[\"fast\", \"standard\"],\n            value=\"fast\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"wait_for\",\n            display_name=\"Wait For\",\n            info=\"Seconds to wait for the page to load before extracting data.\",\n            value=0,\n            range_spec=RangeSpec(min=0, max=10, step_type=\"int\"),\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"is_scroll_to_bottom_enabled\",\n            display_name=\"Enable scroll to bottom\",\n            info=\"Scroll to bottom of the page before extracting data.\",\n            value=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"is_screenshot_enabled\",\n            display_name=\"Enable screenshot\",\n            info=\"Take a screenshot before extracting data. Returned in 'metadata' as a Base64 string.\",\n            value=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Data:\n        endpoint = \"https://api.agentql.com/v1/query-data\"\n        headers = {\n            \"X-API-Key\": self.api_key,\n            \"Content-Type\": \"application/json\",\n            \"X-TF-Request-Origin\": \"langflow\",\n        }\n\n        payload = {\n            \"url\": self.url,\n            \"query\": self.query,\n            \"prompt\": self.prompt,\n            \"params\": {\n                \"mode\": self.mode,\n                \"wait_for\": self.wait_for,\n                \"is_scroll_to_bottom_enabled\": self.is_scroll_to_bottom_enabled,\n                \"is_screenshot_enabled\": self.is_screenshot_enabled,\n            },\n            \"metadata\": {\n                \"experimental_stealth_mode_enabled\": self.is_stealth_mode_enabled,\n            },\n        }\n\n        if not self.prompt and not self.query:\n            self.status = \"Either Query or Prompt must be provided.\"\n            raise ValueError(self.status)\n        if self.prompt and self.query:\n            self.status = \"Both Query and Prompt can't be provided at the same time.\"\n            raise ValueError(self.status)\n\n        try:\n            response = httpx.post(endpoint, headers=headers, json=payload, timeout=self.timeout)\n            response.raise_for_status()\n\n            json = response.json()\n            data = Data(result=json[\"data\"], metadata=json[\"metadata\"])\n\n        except httpx.HTTPStatusError as e:\n            response = e.response\n            if response.status_code == httpx.codes.UNAUTHORIZED:\n                self.status = \"Please, provide a valid API Key. You can create one at https://dev.agentql.com.\"\n            else:\n                try:\n                    error_json = response.json()\n                    logger.error(\n                        f\"Failure response: '{response.status_code} {response.reason_phrase}' with body: {error_json}\"\n                    )\n                    msg = error_json[\"error_info\"] if \"error_info\" in error_json else error_json[\"detail\"]\n                except (ValueError, TypeError):\n                    msg = f\"HTTP {e}.\"\n                self.status = msg\n            raise ValueError(self.status) from e\n\n        else:\n            self.status = data\n            return data\n"},"is_screenshot_enabled":{"_input_type":"BoolInput","advanced":true,"display_name":"Enable screenshot","dynamic":false,"info":"Take a screenshot before extracting data. Returned in 'metadata' as a Base64 string.","list":false,"list_add_label":"Add More","name":"is_screenshot_enabled","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"is_scroll_to_bottom_enabled":{"_input_type":"BoolInput","advanced":true,"display_name":"Enable scroll to bottom","dynamic":false,"info":"Scroll to bottom of the page before extracting data.","list":false,"list_add_label":"Add More","name":"is_scroll_to_bottom_enabled","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"is_stealth_mode_enabled":{"_input_type":"BoolInput","advanced":true,"display_name":"Enable Stealth Mode (Beta)","dynamic":false,"info":"Enable experimental anti-bot evasion strategies. May not work for all websites at all times.","list":false,"list_add_label":"Add More","name":"is_stealth_mode_enabled","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"mode":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Request Mode","dynamic":false,"external_options":{},"info":"'standard' uses deep data analysis, while 'fast' trades some depth of analysis for speed.","name":"mode","options":["fast","standard"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"fast"},"prompt":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Prompt","dynamic":false,"info":"A Natural Language description of the data to extract from the page. Alternative to AgentQL query.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"prompt","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"query":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"AgentQL Query","dynamic":false,"info":"The AgentQL query to execute. Learn more at https://docs.agentql.com/agentql-query or use a prompt.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"query","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"timeout":{"_input_type":"IntInput","advanced":true,"display_name":"Timeout","dynamic":false,"info":"Seconds to wait for a request.","list":false,"list_add_label":"Add More","name":"timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":900},"url":{"_input_type":"MessageTextInput","advanced":false,"display_name":"URL","dynamic":false,"info":"The URL of the public web page you want to extract data from.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"wait_for":{"_input_type":"IntInput","advanced":true,"display_name":"Wait For","dynamic":false,"info":"Seconds to wait for the page to load before extracting data.","list":false,"list_add_label":"Add More","name":"wait_for","placeholder":"","range_spec":{"max":10.0,"min":0.0,"step":0.1,"step_type":"int"},"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":0}},"tool_mode":false}}],["agents",{"Agent":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Define the agent's instructions, then enter a task to complete using tools.","display_name":"Agent","documentation":"https://docs.langflow.org/agents","edited":false,"field_order":["agent_llm","max_tokens","model_kwargs","model_name","openai_api_base","api_key","temperature","seed","max_retries","timeout","system_prompt","context_id","n_messages","format_instructions","output_schema","tools","input_value","handle_parsing_errors","verbose","max_iterations","agent_description","add_current_date_tool"],"frozen":false,"icon":"bot","legacy":false,"metadata":{"code_hash":"bdb8b8db6375","dependencies":{"dependencies":[{"name":"langchain_core","version":"0.3.79"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.agents.agent.AgentComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Response","group_outputs":false,"method":"message_response","name":"response","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","add_current_date_tool":{"_input_type":"BoolInput","advanced":true,"display_name":"Current Date","dynamic":false,"info":"If true, will add a tool to the agent that returns the current date.","list":false,"list_add_label":"Add More","name":"add_current_date_tool","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"agent_description":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"Agent Description [Deprecated]","dynamic":false,"info":"The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"agent_description","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"A helpful assistant with access to the following tools:"},"agent_llm":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model Provider","dynamic":false,"external_options":{"fields":{"data":{"node":{"display_name":"Connect other models","icon":"CornerDownLeft","name":"connect_other_models"}}}},"info":"The provider of the language model that the agent will use to generate responses.","input_types":[],"name":"agent_llm","options":["Anthropic","Google Generative AI","OpenAI"],"options_metadata":[{"icon":"Anthropic"},{"icon":"GoogleGenerativeAI"},{"icon":"OpenAI"}],"placeholder":"","real_time_refresh":true,"refresh_button":false,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"OpenAI"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"OpenAI API Key","dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","input_types":[],"load_from_db":false,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nimport re\n\nfrom langchain_core.tools import StructuredTool, Tool\nfrom pydantic import ValidationError\n\nfrom lfx.base.agents.agent import LCToolsAgentComponent\nfrom lfx.base.agents.events import ExceptionWithMessageError\nfrom lfx.base.models.model_input_constants import (\n    ALL_PROVIDER_FIELDS,\n    MODEL_DYNAMIC_UPDATE_FIELDS,\n    MODEL_PROVIDERS_DICT,\n    MODEL_PROVIDERS_LIST,\n    MODELS_METADATA,\n)\nfrom lfx.base.models.model_utils import get_model_name\nfrom lfx.components.helpers.current_date import CurrentDateComponent\nfrom lfx.components.helpers.memory import MemoryComponent\nfrom lfx.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom lfx.custom.custom_component.component import get_component_toolkit\nfrom lfx.custom.utils import update_component_build_config\nfrom lfx.helpers.base_model import build_model_from_schema\nfrom lfx.inputs.inputs import BoolInput\nfrom lfx.io import DropdownInput, IntInput, MessageTextInput, MultilineInput, Output, TableInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.dotdict import dotdict\nfrom lfx.schema.message import Message\nfrom lfx.schema.table import EditMode\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    documentation: str = \"https://docs.langflow.org/agents\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    # Filter out json_mode from OpenAI inputs since we handle structured output differently\n    if \"OpenAI\" in MODEL_PROVIDERS_DICT:\n        openai_inputs_filtered = [\n            input_field\n            for input_field in MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"]\n            if not (hasattr(input_field, \"name\") and input_field.name == \"json_mode\")\n        ]\n    else:\n        openai_inputs_filtered = []\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*MODEL_PROVIDERS_LIST],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            refresh_button=False,\n            input_types=[],\n            options_metadata=[MODELS_METADATA[key] for key in MODEL_PROVIDERS_LIST if key in MODELS_METADATA],\n            external_options={\n                \"fields\": {\n                    \"data\": {\n                        \"node\": {\n                            \"name\": \"connect_other_models\",\n                            \"display_name\": \"Connect other models\",\n                            \"icon\": \"CornerDownLeft\",\n                        }\n                    }\n                },\n            },\n        ),\n        *openai_inputs_filtered,\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        MessageTextInput(\n            name=\"context_id\",\n            display_name=\"Context ID\",\n            info=\"The context ID of the chat. Adds an extra layer to the local memory.\",\n            value=\"\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Chat History Messages\",\n            value=100,\n            info=\"Number of chat history messages to retrieve.\",\n            advanced=True,\n            show=True,\n        ),\n        MultilineInput(\n            name=\"format_instructions\",\n            display_name=\"Output Format Instructions\",\n            info=\"Generic Template for structured output formatting. Valid only with Structured response.\",\n            value=(\n                \"You are an AI that extracts structured JSON objects from unstructured text. \"\n                \"Use a predefined schema with expected types (str, int, float, bool, dict). \"\n                \"Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. \"\n                \"Fill missing or ambiguous values with defaults: null for missing values. \"\n                \"Remove exact duplicates but keep variations that have different field values. \"\n                \"Always return valid JSON in the expected format, never throw errors. \"\n                \"If multiple objects can be extracted, return them all in the structured format.\"\n            ),\n            advanced=True,\n        ),\n        TableInput(\n            name=\"output_schema\",\n            display_name=\"Output Schema\",\n            info=(\n                \"Schema Validation: Define the structure and data types for structured output. \"\n                \"No validation if no output schema.\"\n            ),\n            advanced=True,\n            required=False,\n            value=[],\n            table_schema=[\n                {\n                    \"name\": \"name\",\n                    \"display_name\": \"Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Specify the name of the output field.\",\n                    \"default\": \"field\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"description\",\n                    \"display_name\": \"Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Describe the purpose of the output field.\",\n                    \"default\": \"description of field\",\n                    \"edit_mode\": EditMode.POPOVER,\n                },\n                {\n                    \"name\": \"type\",\n                    \"display_name\": \"Type\",\n                    \"type\": \"str\",\n                    \"edit_mode\": EditMode.INLINE,\n                    \"description\": (\"Indicate the data type of the output field (e.g., str, int, float, bool, dict).\"),\n                    \"options\": [\"str\", \"int\", \"float\", \"bool\", \"dict\"],\n                    \"default\": \"str\",\n                },\n                {\n                    \"name\": \"multiple\",\n                    \"display_name\": \"As List\",\n                    \"type\": \"boolean\",\n                    \"description\": \"Set to True if this output field should be a list of the specified type.\",\n                    \"default\": \"False\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n            ],\n        ),\n        *LCToolsAgentComponent._base_inputs,\n        # removed memory inputs from agent component\n        # *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [\n        Output(name=\"response\", display_name=\"Response\", method=\"message_response\"),\n    ]\n\n    async def get_agent_requirements(self):\n        \"\"\"Get the agent requirements for the agent.\"\"\"\n        llm_model, display_name = await self.get_llm()\n        if llm_model is None:\n            msg = \"No language model selected. Please choose a model to proceed.\"\n            raise ValueError(msg)\n        self.model_name = get_model_name(llm_model, display_name=display_name)\n\n        # Get memory data\n        self.chat_history = await self.get_memory_data()\n        await logger.adebug(f\"Retrieved {len(self.chat_history)} chat history messages\")\n        if isinstance(self.chat_history, Message):\n            self.chat_history = [self.chat_history]\n\n        # Add current date tool if enabled\n        if self.add_current_date_tool:\n            if not isinstance(self.tools, list):  # type: ignore[has-type]\n                self.tools = []\n            current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n            if not isinstance(current_date_tool, StructuredTool):\n                msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                raise TypeError(msg)\n            self.tools.append(current_date_tool)\n        return llm_model, self.chat_history, self.tools\n\n    async def message_response(self) -> Message:\n        try:\n            llm_model, self.chat_history, self.tools = await self.get_agent_requirements()\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            result = await self.run_agent(agent)\n\n            # Store result for potential JSON output\n            self._agent_result = result\n\n        except (ValueError, TypeError, KeyError) as e:\n            await logger.aerror(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            await logger.aerror(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        # Avoid catching blind Exception; let truly unexpected exceptions propagate\n        except Exception as e:\n            await logger.aerror(f\"Unexpected error: {e!s}\")\n            raise\n        else:\n            return result\n\n    def _preprocess_schema(self, schema):\n        \"\"\"Preprocess schema to ensure correct data types for build_model_from_schema.\"\"\"\n        processed_schema = []\n        for field in schema:\n            processed_field = {\n                \"name\": str(field.get(\"name\", \"field\")),\n                \"type\": str(field.get(\"type\", \"str\")),\n                \"description\": str(field.get(\"description\", \"\")),\n                \"multiple\": field.get(\"multiple\", False),\n            }\n            # Ensure multiple is handled correctly\n            if isinstance(processed_field[\"multiple\"], str):\n                processed_field[\"multiple\"] = processed_field[\"multiple\"].lower() in [\n                    \"true\",\n                    \"1\",\n                    \"t\",\n                    \"y\",\n                    \"yes\",\n                ]\n            processed_schema.append(processed_field)\n        return processed_schema\n\n    async def build_structured_output_base(self, content: str):\n        \"\"\"Build structured output with optional BaseModel validation.\"\"\"\n        json_pattern = r\"\\{.*\\}\"\n        schema_error_msg = \"Try setting an output schema\"\n\n        # Try to parse content as JSON first\n        json_data = None\n        try:\n            json_data = json.loads(content)\n        except json.JSONDecodeError:\n            json_match = re.search(json_pattern, content, re.DOTALL)\n            if json_match:\n                try:\n                    json_data = json.loads(json_match.group())\n                except json.JSONDecodeError:\n                    return {\"content\": content, \"error\": schema_error_msg}\n            else:\n                return {\"content\": content, \"error\": schema_error_msg}\n\n        # If no output schema provided, return parsed JSON without validation\n        if not hasattr(self, \"output_schema\") or not self.output_schema or len(self.output_schema) == 0:\n            return json_data\n\n        # Use BaseModel validation with schema\n        try:\n            processed_schema = self._preprocess_schema(self.output_schema)\n            output_model = build_model_from_schema(processed_schema)\n\n            # Validate against the schema\n            if isinstance(json_data, list):\n                # Multiple objects\n                validated_objects = []\n                for item in json_data:\n                    try:\n                        validated_obj = output_model.model_validate(item)\n                        validated_objects.append(validated_obj.model_dump())\n                    except ValidationError as e:\n                        await logger.aerror(f\"Validation error for item: {e}\")\n                        # Include invalid items with error info\n                        validated_objects.append({\"data\": item, \"validation_error\": str(e)})\n                return validated_objects\n\n            # Single object\n            try:\n                validated_obj = output_model.model_validate(json_data)\n                return [validated_obj.model_dump()]  # Return as list for consistency\n            except ValidationError as e:\n                await logger.aerror(f\"Validation error: {e}\")\n                return [{\"data\": json_data, \"validation_error\": str(e)}]\n\n        except (TypeError, ValueError) as e:\n            await logger.aerror(f\"Error building structured output: {e}\")\n            # Fallback to parsed JSON without validation\n            return json_data\n\n    async def json_response(self) -> Data:\n        \"\"\"Convert agent response to structured JSON Data output with schema validation.\"\"\"\n        # Always use structured chat agent for JSON response mode for better JSON formatting\n        try:\n            system_components = []\n\n            # 1. Agent Instructions (system_prompt)\n            agent_instructions = getattr(self, \"system_prompt\", \"\") or \"\"\n            if agent_instructions:\n                system_components.append(f\"{agent_instructions}\")\n\n            # 2. Format Instructions\n            format_instructions = getattr(self, \"format_instructions\", \"\") or \"\"\n            if format_instructions:\n                system_components.append(f\"Format instructions: {format_instructions}\")\n\n            # 3. Schema Information from BaseModel\n            if hasattr(self, \"output_schema\") and self.output_schema and len(self.output_schema) > 0:\n                try:\n                    processed_schema = self._preprocess_schema(self.output_schema)\n                    output_model = build_model_from_schema(processed_schema)\n                    schema_dict = output_model.model_json_schema()\n                    schema_info = (\n                        \"You are given some text that may include format instructions, \"\n                        \"explanations, or other content alongside a JSON schema.\\n\\n\"\n                        \"Your task:\\n\"\n                        \"- Extract only the JSON schema.\\n\"\n                        \"- Return it as valid JSON.\\n\"\n                        \"- Do not include format instructions, explanations, or extra text.\\n\\n\"\n                        \"Input:\\n\"\n                        f\"{json.dumps(schema_dict, indent=2)}\\n\\n\"\n                        \"Output (only JSON schema):\"\n                    )\n                    system_components.append(schema_info)\n                except (ValidationError, ValueError, TypeError, KeyError) as e:\n                    await logger.aerror(f\"Could not build schema for prompt: {e}\", exc_info=True)\n\n            # Combine all components\n            combined_instructions = \"\\n\\n\".join(system_components) if system_components else \"\"\n            llm_model, self.chat_history, self.tools = await self.get_agent_requirements()\n            self.set(\n                llm=llm_model,\n                tools=self.tools or [],\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=combined_instructions,\n            )\n\n            # Create and run structured chat agent\n            try:\n                structured_agent = self.create_agent_runnable()\n            except (NotImplementedError, ValueError, TypeError) as e:\n                await logger.aerror(f\"Error with structured chat agent: {e}\")\n                raise\n            try:\n                result = await self.run_agent(structured_agent)\n            except (\n                ExceptionWithMessageError,\n                ValueError,\n                TypeError,\n                RuntimeError,\n            ) as e:\n                await logger.aerror(f\"Error with structured agent result: {e}\")\n                raise\n            # Extract content from structured agent result\n            if hasattr(result, \"content\"):\n                content = result.content\n            elif hasattr(result, \"text\"):\n                content = result.text\n            else:\n                content = str(result)\n\n        except (\n            ExceptionWithMessageError,\n            ValueError,\n            TypeError,\n            NotImplementedError,\n            AttributeError,\n        ) as e:\n            await logger.aerror(f\"Error with structured chat agent: {e}\")\n            # Fallback to regular agent\n            content_str = \"No content returned from agent\"\n            return Data(data={\"content\": content_str, \"error\": str(e)})\n\n        # Process with structured output validation\n        try:\n            structured_output = await self.build_structured_output_base(content)\n\n            # Handle different output formats\n            if isinstance(structured_output, list) and structured_output:\n                if len(structured_output) == 1:\n                    return Data(data=structured_output[0])\n                return Data(data={\"results\": structured_output})\n            if isinstance(structured_output, dict):\n                return Data(data=structured_output)\n            return Data(data={\"content\": content})\n\n        except (ValueError, TypeError) as e:\n            await logger.aerror(f\"Error in structured output processing: {e}\")\n            return Data(data={\"content\": content, \"error\": str(e)})\n\n    async def get_memory_data(self):\n        # TODO: This is a temporary fix to avoid message duplication. We should develop a function for this.\n        messages = (\n            await MemoryComponent(**self.get_base_args())\n            .set(\n                session_id=self.graph.session_id,\n                context_id=self.context_id,\n                order=\"Ascending\",\n                n_messages=self.n_messages,\n            )\n            .retrieve_messages()\n        )\n        return [\n            message for message in messages if getattr(message, \"id\", None) != getattr(self.input_value, \"id\", None)\n        ]\n\n    async def get_llm(self):\n        if not isinstance(self.agent_llm, str):\n            return self.agent_llm, None\n\n        try:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if not provider_info:\n                msg = f\"Invalid model provider: {self.agent_llm}\"\n                raise ValueError(msg)\n\n            component_class = provider_info.get(\"component_class\")\n            display_name = component_class.display_name\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\", \"\")\n\n            return self._build_llm_model(component_class, inputs, prefix), display_name\n\n        except (AttributeError, ValueError, TypeError, RuntimeError) as e:\n            await logger.aerror(f\"Error building {self.agent_llm} language model: {e!s}\")\n            msg = f\"Failed to initialize language model: {e!s}\"\n            raise ValueError(msg) from e\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {}\n        for input_ in inputs:\n            if hasattr(self, f\"{prefix}{input_.name}\"):\n                model_kwargs[input_.name] = getattr(self, f\"{prefix}{input_.name}\")\n        return component.set(**model_kwargs).build_model()\n\n    def set_component_params(self, component):\n        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n        if provider_info:\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\")\n            # Filter out json_mode and only use attributes that exist on this component\n            model_kwargs = {}\n            for input_ in inputs:\n                if hasattr(self, f\"{prefix}{input_.name}\"):\n                    model_kwargs[input_.name] = getattr(self, f\"{prefix}{input_.name}\")\n\n            return component.set(**model_kwargs)\n        return component\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self, build_config: dotdict, field_value: str, field_name: str | None = None\n    ) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name in (\"agent_llm\",):\n            build_config[\"agent_llm\"][\"value\"] = field_value\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n                build_config[\"agent_llm\"][\"display_name\"] = \"Model Provider\"\n            elif field_value == \"connect_other_models\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    info=\"The provider of the language model that the agent will use to generate responses.\",\n                    options=[*MODEL_PROVIDERS_LIST],\n                    real_time_refresh=True,\n                    refresh_button=False,\n                    input_types=[\"LanguageModel\"],\n                    placeholder=\"Awaiting model input.\",\n                    options_metadata=[MODELS_METADATA[key] for key in MODEL_PROVIDERS_LIST if key in MODELS_METADATA],\n                    external_options={\n                        \"fields\": {\n                            \"data\": {\n                                \"node\": {\n                                    \"name\": \"connect_other_models\",\n                                    \"display_name\": \"Connect other models\",\n                                    \"icon\": \"CornerDownLeft\",\n                                },\n                            }\n                        },\n                    },\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if (\n            isinstance(self.agent_llm, str)\n            and self.agent_llm in MODEL_PROVIDERS_DICT\n            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS\n        ):\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                component_class = self.set_component_params(component_class)\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n\n    async def _get_tools(self) -> list[Tool]:\n        component_toolkit = get_component_toolkit()\n        tools_names = self._build_tools_names()\n        agent_description = self.get_tool_description()\n        # TODO: Agent Description Depreciated Feature to be removed\n        description = f\"{agent_description}{tools_names}\"\n        tools = component_toolkit(component=self).get_tools(\n            tool_name=\"Call_Agent\",\n            tool_description=description,\n            callbacks=self.get_langchain_callbacks(),\n        )\n        if hasattr(self, \"tools_metadata\"):\n            tools = component_toolkit(component=self, metadata=self.tools_metadata).update_tools_metadata(tools=tools)\n        return tools\n"},"context_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Context ID","dynamic":false,"info":"The context ID of the chat. Adds an extra layer to the local memory.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"context_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"format_instructions":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"Output Format Instructions","dynamic":false,"info":"Generic Template for structured output formatting. Valid only with Structured response.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"format_instructions","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"You are an AI that extracts structured JSON objects from unstructured text. Use a predefined schema with expected types (str, int, float, bool, dict). Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. Fill missing or ambiguous values with defaults: null for missing values. Remove exact duplicates but keep variations that have different field values. Always return valid JSON in the expected format, never throw errors. If multiple objects can be extracted, return them all in the structured format."},"handle_parsing_errors":{"_input_type":"BoolInput","advanced":true,"display_name":"Handle Parse Errors","dynamic":false,"info":"Should the Agent fix errors when reading user input for better processing?","list":false,"list_add_label":"Add More","name":"handle_parsing_errors","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"The input provided by the user for the agent to process.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"max_iterations":{"_input_type":"IntInput","advanced":true,"display_name":"Max Iterations","dynamic":false,"info":"The maximum number of attempts the agent can make to complete its task before it stops.","list":false,"list_add_label":"Add More","name":"max_iterations","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":15},"max_retries":{"_input_type":"IntInput","advanced":true,"display_name":"Max Retries","dynamic":false,"info":"The maximum number of retries to make when generating.","list":false,"list_add_label":"Add More","name":"max_retries","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5},"max_tokens":{"_input_type":"IntInput","advanced":true,"display_name":"Max Tokens","dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","list":false,"list_add_label":"Add More","name":"max_tokens","placeholder":"","range_spec":{"max":128000.0,"min":0.0,"step":0.1,"step_type":"float"},"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"model_kwargs":{"_input_type":"DictInput","advanced":true,"display_name":"Model Kwargs","dynamic":false,"info":"Additional keyword arguments to pass to the model.","list":false,"list_add_label":"Add More","name":"model_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":true,"dialog_inputs":{},"display_name":"Model Name","dynamic":false,"external_options":{},"info":"To see the model names, first choose a provider. Then, enter your API key and click the refresh button next to the model name.","name":"model_name","options":["gpt-4o-mini","gpt-4o","gpt-4.1","gpt-4.1-mini","gpt-4.1-nano","gpt-4-turbo","gpt-4-turbo-preview","gpt-4","gpt-3.5-turbo","gpt-5","gpt-5-mini","gpt-5-nano","gpt-5-chat-latest","o1","o3-mini","o3","o3-pro","o4-mini","o4-mini-high"],"options_metadata":[],"placeholder":"","real_time_refresh":false,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"gpt-4o-mini"},"n_messages":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Chat History Messages","dynamic":false,"info":"Number of chat history messages to retrieve.","list":false,"list_add_label":"Add More","name":"n_messages","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":100},"openai_api_base":{"_input_type":"StrInput","advanced":true,"display_name":"OpenAI API Base","dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"openai_api_base","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"output_schema":{"_input_type":"TableInput","advanced":true,"display_name":"Output Schema","dynamic":false,"info":"Schema Validation: Define the structure and data types for structured output. No validation if no output schema.","is_list":true,"list_add_label":"Add More","name":"output_schema","placeholder":"","required":false,"show":true,"table_icon":"Table","table_schema":[{"default":"field","description":"Specify the name of the output field.","display_name":"Name","edit_mode":"inline","name":"name","type":"str"},{"default":"description of field","description":"Describe the purpose of the output field.","display_name":"Description","edit_mode":"popover","name":"description","type":"str"},{"default":"str","description":"Indicate the data type of the output field (e.g., str, int, float, bool, dict).","display_name":"Type","edit_mode":"inline","name":"type","options":["str","int","float","bool","dict"],"type":"str"},{"default":"False","description":"Set to True if this output field should be a list of the specified type.","display_name":"As List","edit_mode":"inline","name":"multiple","type":"boolean"}],"title_case":false,"tool_mode":false,"trace_as_metadata":true,"trigger_icon":"Table","trigger_text":"Open table","type":"table","value":[]},"seed":{"_input_type":"IntInput","advanced":true,"display_name":"Seed","dynamic":false,"info":"The seed controls the reproducibility of the job.","list":false,"list_add_label":"Add More","name":"seed","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1},"system_prompt":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Agent Instructions","dynamic":false,"info":"System Prompt: Initial instructions and context provided to guide the agent's behavior.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_prompt","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"You are a helpful assistant that can use tools to answer questions and perform tasks."},"temperature":{"_input_type":"SliderInput","advanced":true,"display_name":"Temperature","dynamic":false,"info":"","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"temperature","placeholder":"","range_spec":{"max":1.0,"min":0.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":0.1},"timeout":{"_input_type":"IntInput","advanced":true,"display_name":"Timeout","dynamic":false,"info":"The timeout for requests to OpenAI completion API.","list":false,"list_add_label":"Add More","name":"timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":700},"tools":{"_input_type":"HandleInput","advanced":false,"display_name":"Tools","dynamic":false,"info":"These are the tools that the agent can use to help with tasks.","input_types":["Tool"],"list":true,"list_add_label":"Add More","name":"tools","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"verbose":{"_input_type":"BoolInput","advanced":true,"display_name":"Verbose","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"verbose","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false},"Cuga":{"base_classes":["Data","Message"],"beta":true,"conditional_paths":[],"custom_fields":{},"description":"Define the Cuga agent's policies, then assign it a task.","display_name":"Cuga","documentation":"https://docs.langflow.org/agents","edited":false,"field_order":["agent_llm","max_tokens","model_kwargs","model_name","openai_api_base","api_key","temperature","seed","max_retries","timeout","policies","n_messages","format_instructions","output_schema","tools","input_value","handle_parsing_errors","verbose","max_iterations","agent_description","add_current_date_tool","browser_enabled","web_apps","API"],"frozen":false,"icon":"bot","legacy":false,"metadata":{"code_hash":"affdf8d8bbde","dependencies":{"dependencies":[{"name":"langchain_core","version":"0.3.79"},{"name":"langflow","version":null},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null},{"name":"cuga","version":"0.1.2"}],"total_dependencies":5},"module":"lfx.components.agents.cuga_agent.CugaComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Response","group_outputs":false,"method":"message_response","name":"response","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Structured Response","group_outputs":false,"method":"json_response","name":"structured_response","selected":"Data","tool_mode":false,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"API":{"_input_type":"BoolInput","advanced":true,"display_name":"Enable API Sub-agent","dynamic":false,"info":"Toggle to enable a built-in sub-agent specialized for API interactions.","list":false,"list_add_label":"Add More","name":"API","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"_type":"Component","add_current_date_tool":{"_input_type":"BoolInput","advanced":true,"display_name":"Current Date","dynamic":false,"info":"If true, will add a tool to the agent that returns the current date.","list":false,"list_add_label":"Add More","name":"add_current_date_tool","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"agent_description":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"Agent Description [Deprecated]","dynamic":false,"info":"The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"agent_description","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"A helpful assistant with access to the following tools:"},"agent_llm":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model Provider","dynamic":false,"external_options":{},"info":"The provider of the language model that the agent will use to generate responses.","input_types":[],"name":"agent_llm","options":["OpenAI","Custom"],"options_metadata":[{"icon":"OpenAI"},{"icon":"brain"}],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"OpenAI"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"OpenAI API Key","dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","input_types":[],"load_from_db":false,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"type":"str","value":""},"browser_enabled":{"_input_type":"BoolInput","advanced":false,"display_name":"Enable Browser","dynamic":false,"info":"Toggle to enable a built-in browser tool for web scraping and searching.","list":false,"list_add_label":"Add More","name":"browser_enabled","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import asyncio\nimport json\nimport os\nimport re\nimport traceback\nimport uuid\nfrom collections.abc import AsyncIterator\nfrom typing import TYPE_CHECKING, Any, cast\n\nfrom langchain_core.agents import AgentFinish\nfrom langchain_core.messages import AIMessage, HumanMessage\nfrom langchain_core.tools import StructuredTool\nfrom langflow.field_typing import Tool\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MultilineInput, Output, TableInput\n\n# from langflow.logging import logger\nfrom langflow.schema.data import Data\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\nfrom langflow.schema.table import EditMode\nfrom pydantic import ValidationError\n\nfrom lfx.base.agents.events import ExceptionWithMessageError\nfrom lfx.base.models.model_input_constants import (\n    ALL_PROVIDER_FIELDS,\n    MODEL_DYNAMIC_UPDATE_FIELDS,\n    MODEL_PROVIDERS,\n    MODEL_PROVIDERS_DICT,\n    MODELS_METADATA,\n)\nfrom lfx.base.models.model_utils import get_model_name\nfrom lfx.components.agents.agent import LCToolsAgentComponent\nfrom lfx.components.helpers.current_date import CurrentDateComponent\nfrom lfx.components.helpers.memory import MemoryComponent\nfrom lfx.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom lfx.custom.custom_component.component import _get_component_toolkit\nfrom lfx.custom.utils import update_component_build_config\nfrom lfx.helpers.base_model import build_model_from_schema\nfrom lfx.log.logger import logger\n\nif TYPE_CHECKING:\n    from langflow.schema.log import SendMessageFunctionType\n\n\ndef set_advanced_true(component_input):\n    \"\"\"Set the advanced flag to True for a component input.\n\n    Args:\n        component_input: The component input to modify\n\n    Returns:\n        The modified component input with advanced=True\n    \"\"\"\n    component_input.advanced = True\n    return component_input\n\n\nMODEL_PROVIDERS_LIST = [\"OpenAI\"]\n\n\nclass CugaComponent(ToolCallingAgentComponent):\n    \"\"\"Cuga Agent Component for advanced AI task execution.\n\n    The Cuga component is an advanced AI agent that can execute complex tasks using\n    various tools, browser automation, and structured output generation. It supports\n    custom policies, web applications, and API interactions.\n\n    Attributes:\n        display_name: Human-readable name for the component\n        description: Brief description of the component's purpose\n        documentation: URL to component documentation\n        icon: Icon identifier for the UI\n        beta: Whether the component is in beta status\n        name: Internal component name\n    \"\"\"\n\n    display_name: str = \"Cuga\"\n    description: str = \"Define the Cuga agent's policies, then assign it a task.\"\n    documentation: str = \"https://docs.langflow.org/agents\"\n    icon = \"bot\"\n    beta = True\n    name = \"Cuga\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    # Filter out json_mode from OpenAI inputs since we handle structured output differently\n    openai_inputs_filtered = [\n        input_field\n        for input_field in MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"]\n        if not (hasattr(input_field, \"name\") and input_field.name == \"json_mode\")\n    ]\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*MODEL_PROVIDERS_LIST, \"Custom\"],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            input_types=[],\n            options_metadata=[MODELS_METADATA[key] for key in MODEL_PROVIDERS_LIST] + [{\"icon\": \"brain\"}],\n        ),\n        *openai_inputs_filtered,\n        MultilineInput(\n            name=\"policies\",\n            display_name=\"Policies\",\n            info=(\n                \"Custom instructions or policies for the agent to adhere to during its operation.\\n\"\n                \"Example:\\n\"\n                \"# Plan\\n\"\n                \"< planning instructions e.g. which tools and when to use>\\n\"\n                \"# Answer\\n\"\n                \"< final answer instructions how to answer>\"\n            ),\n            value=\"\",\n            advanced=False,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Chat History Messages\",\n            value=100,\n            info=\"Number of chat history messages to retrieve.\",\n            advanced=True,\n            show=True,\n        ),\n        MultilineInput(\n            name=\"format_instructions\",\n            display_name=\"Output Format Instructions\",\n            info=\"Generic Template for structured output formatting. Valid only with Structured response.\",\n            value=(\n                \"You are an AI that extracts structured JSON objects from unstructured text. \"\n                \"Use a predefined schema with expected types (str, int, float, bool, dict). \"\n                \"Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. \"\n                \"Fill missing or ambiguous values with defaults: null for missing values. \"\n                \"Remove exact duplicates but keep variations that have different field values. \"\n                \"Always return valid JSON in the expected format, never throw errors. \"\n                \"If multiple objects can be extracted, return them all in the structured format.\"\n            ),\n            advanced=True,\n        ),\n        TableInput(\n            name=\"output_schema\",\n            display_name=\"Output Schema\",\n            info=(\n                \"Schema Validation: Define the structure and data types for structured output. \"\n                \"No validation if no output schema.\"\n            ),\n            advanced=True,\n            required=False,\n            value=[],\n            table_schema=[\n                {\n                    \"name\": \"name\",\n                    \"display_name\": \"Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Specify the name of the output field.\",\n                    \"default\": \"field\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"description\",\n                    \"display_name\": \"Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Describe the purpose of the output field.\",\n                    \"default\": \"description of field\",\n                    \"edit_mode\": EditMode.POPOVER,\n                },\n                {\n                    \"name\": \"type\",\n                    \"display_name\": \"Type\",\n                    \"type\": \"str\",\n                    \"edit_mode\": EditMode.INLINE,\n                    \"description\": (\"Indicate the data type of the output field (e.g., str, int, float, bool, dict).\"),\n                    \"options\": [\"str\", \"int\", \"float\", \"bool\", \"dict\"],\n                    \"default\": \"str\",\n                },\n                {\n                    \"name\": \"multiple\",\n                    \"display_name\": \"As List\",\n                    \"type\": \"boolean\",\n                    \"description\": \"Set to True if this output field should be a list of the specified type.\",\n                    \"default\": \"False\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n            ],\n        ),\n        *LCToolsAgentComponent._base_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"browser_enabled\",\n            display_name=\"Enable Browser\",\n            info=\"Toggle to enable a built-in browser tool for web scraping and searching.\",\n            value=False,\n            advanced=False,\n        ),\n        MultilineInput(\n            name=\"web_apps\",\n            display_name=\"Web applications\",\n            info=(\n                \"Define a list of web applications that cuga will open when enable browser is true. \"\n                \"Currently only supports one web application. Example: https://example.com\"\n            ),\n            value=\"\",\n            advanced=False,\n        ),\n        BoolInput(\n            name=\"API\",\n            display_name=\"Enable API Sub-agent\",\n            info=\"Toggle to enable a built-in sub-agent specialized for API interactions.\",\n            value=False,\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(name=\"response\", display_name=\"Response\", method=\"message_response\"),\n        Output(name=\"structured_response\", display_name=\"Structured Response\", method=\"json_response\", tool_mode=False),\n    ]\n\n    async def call_agent(\n        self, current_input: str, tools: list[Tool], history_messages: list[Message], llm\n    ) -> AsyncIterator[dict[str, Any]]:\n        \"\"\"Execute the Cuga agent with the given input and tools.\n\n        This method initializes and runs the Cuga agent, processing the input through\n        the agent's workflow and yielding events for real-time monitoring.\n\n        Args:\n            current_input: The user input to process\n            tools: List of available tools for the agent\n            history_messages: Previous conversation history\n            llm: The language model instance to use\n\n        Yields:\n            dict: Agent events including tool usage, thinking, and final results\n\n        Raises:\n            ValueError: If there's an error in agent initialization\n            TypeError: If there's a type error in processing\n            RuntimeError: If there's a runtime error during execution\n            ConnectionError: If there's a connection issue\n        \"\"\"\n        yield {\n            \"event\": \"on_chain_start\",\n            \"run_id\": str(uuid.uuid4()),\n            \"name\": \"CUGA_initializing\",\n            \"data\": {\"input\": {\"input\": current_input, \"chat_history\": []}},\n        }\n        logger.debug(f\"LLM MODEL TYPE: {type(llm)}\")\n        if current_input:\n            try:\n                from cuga.config import settings as cuga_settings\n\n                logger.info(\"Updating cuga settings programmatically\")\n                cuga_settings.set(\"advanced_features.registry\", False)  # noqa: FBT003\n\n                if self.browser_enabled:\n                    logger.info(\"browser_enabled is true, setting mode to hybrid\")\n                    cuga_settings.set(\"advanced_features.mode\", \"hybrid\")\n                    cuga_settings.set(\"advanced_features.use_vision\", False)  # noqa: FBT003\n                else:\n                    logger.info(\"browser_enabled is false, setting mode to api\")\n                    cuga_settings.set(\"advanced_features.mode\", \"api\")\n\n                logger.info(f\"Cuga settings updated - MODE: {cuga_settings.get('advanced_features.mode')}\")\n            except (ImportError, AttributeError) as e:\n                logger.warning(f\"Could not update cuga settings: {e}\")\n                os.environ[\"DYNACONF_ADVANCED_FEATURES__REGISTRY\"] = \"false\"\n                if self.browser_enabled:\n                    logger.info(\"browser_enabled is true, setting env to hybrid\")\n                    os.environ[\"DYNACONF_ADVANCED_FEATURES__MODE\"] = \"hybrid\"\n                    os.environ[\"DYNACONF_ADVANCED_FEATURES__USE_VISION\"] = \"false\"\n                else:\n                    logger.info(\"browser_enabled is false, setting env to api\")\n                    os.environ[\"DYNACONF_ADVANCED_FEATURES__MODE\"] = \"api\"\n\n            from cuga.backend.activity_tracker.tracker import ActivityTracker\n            from cuga.backend.cuga_graph.utils.agent_loop import StreamEvent\n            from cuga.backend.cuga_graph.utils.controller import (\n                AgentRunner as CugaAgent,\n            )\n            from cuga.backend.cuga_graph.utils.controller import (\n                ExperimentResult as AgentResult,\n            )\n            from cuga.backend.llm.models import LLMManager\n            from cuga.configurations.instructions_manager import InstructionsManager\n\n            llm_manager = LLMManager()\n            llm_manager.set_llm(llm)\n            instructions_manager = InstructionsManager()\n            if self.policies:\n                logger.info(f\"policies are: {self.policies}\")\n                instructions_manager.set_instructions_from_one_file(self.policies)\n            tracker = ActivityTracker()\n            tracker.set_tools(tools)\n            cuga_agent = CugaAgent(browser_enabled=self.browser_enabled)\n            if self.browser_enabled:\n                await cuga_agent.initialize_freemode_env(start_url=self.web_apps.strip(), interface_mode=\"browser_only\")\n            else:\n                await cuga_agent.initialize_appworld_env()\n        yield {\n            \"event\": \"on_chain_start\",\n            \"run_id\": str(uuid.uuid4()),\n            \"name\": \"CUGA_thinking...\",\n            \"data\": {\"input\": {\"input\": current_input, \"chat_history\": []}},\n        }\n        logger.info(f\"[CUGA] current web apps are {self.web_apps}\")\n        logger.info(f\"[CUGA] Processing input: {current_input}\")\n        try:\n            # Convert history to LangChain format for the event\n            lc_messages = []\n            for msg in history_messages:\n                if hasattr(msg, \"sender\") and msg.sender == \"Human\":\n                    lc_messages.append(HumanMessage(content=msg.text))\n                else:\n                    lc_messages.append(AIMessage(content=msg.text))\n\n            await asyncio.sleep(0.5)\n\n            tools_used = []\n\n            # Simulate browser tool usage\n            if getattr(self, \"BROWSER\", False) and any(\n                word in current_input.lower() for word in [\"search\", \"web\", \"browse\"]\n            ):\n                tool_run_id = str(uuid.uuid4())\n\n                yield {\n                    \"event\": \"on_tool_start\",\n                    \"run_id\": tool_run_id,\n                    \"name\": \"BrowserTool\",\n                    \"data\": {\"input\": {\"query\": current_input}},\n                }\n                await asyncio.sleep(0.3)\n\n                yield {\n                    \"event\": \"on_tool_end\",\n                    \"run_id\": tool_run_id,\n                    \"name\": \"BrowserTool\",\n                    \"data\": {\"output\": \"Simulated web search results for: \" + current_input},\n                }\n                tools_used.append(\"Performed web search\")\n\n            # 2. Build final response\n            response_parts = []\n\n            response_parts.append(f\"Processed input: '{current_input}'\")\n            response_parts.append(f\"Available tools: {len(tools)}\")\n            # final_response = \"CUGA Agent Response:\\n\" + \"\\n\".join(response_parts)\n            last_event: StreamEvent = None\n            tool_run_id = None\n            # 3. Chain end event with AgentFinish\n            async for event in cuga_agent.run_task_generic_yield(eval_mode=False, goal=current_input):\n                logger.debug(f\"recieved event {event}\")\n                if last_event is not None and tool_run_id is not None:\n                    logger.debug(f\"last event {last_event}\")\n                    try:\n                        # TODO: Extract data\n                        data_dict = json.loads(last_event.data)\n                    except json.JSONDecodeError:\n                        data_dict = last_event.data\n                    if last_event.name == \"CodeAgent\":\n                        data_dict = data_dict[\"code\"]\n                    yield {\n                        \"event\": \"on_tool_end\",\n                        \"run_id\": tool_run_id,\n                        \"name\": last_event.name,\n                        \"data\": {\"output\": data_dict},\n                    }\n                if isinstance(event, StreamEvent):\n                    tool_run_id = str(uuid.uuid4())\n                    last_event = StreamEvent(name=event.name, data=event.data)\n                    tool_event = {\n                        \"event\": \"on_tool_start\",\n                        \"run_id\": tool_run_id,\n                        \"name\": event.name,\n                        \"data\": {\"input\": {}},\n                    }\n                    logger.debug(f\"[CUGA] Yielding tool_start event: {event.name}\")\n                    yield tool_event\n\n                if isinstance(event, AgentResult):\n                    task_result = event\n                    end_event = {\n                        \"event\": \"on_chain_end\",\n                        \"run_id\": str(uuid.uuid4()),\n                        \"name\": \"CugaAgent\",\n                        \"data\": {\"output\": AgentFinish(return_values={\"output\": task_result.answer}, log=\"\")},\n                    }\n                    answer_preview = task_result.answer[:100] if task_result.answer else \"None\"\n                    logger.info(f\"[CUGA] Yielding chain_end event with answer: {answer_preview}...\")\n                    yield end_event\n            # task_result: AgentResult = await cuga_agent.run_task_generic_yield(\n            #     eval_mode=False, goal=current_input, on_progress=on_progress\n            # )\n\n        except (ValueError, TypeError, RuntimeError, ConnectionError) as e:\n            logger.error(f\"An error occurred: {e!s}\")\n            logger.error(f\"Traceback: {traceback.format_exc()}\")\n            error_msg = f\"CUGA Agent error: {e!s}\"\n            logger.error(f\"[CUGA] Error occurred: {error_msg}\")\n\n            # Emit error event\n            yield {\n                \"event\": \"on_chain_error\",\n                \"run_id\": str(uuid.uuid4()),\n                \"name\": \"CugaAgent\",\n                \"data\": {\"error\": error_msg},\n            }\n\n    async def message_response(self) -> Message:\n        \"\"\"Generate a message response using the Cuga agent.\n\n        This method processes the input through the Cuga agent and returns a structured\n        message response. It handles agent initialization, tool setup, and event processing.\n\n        Returns:\n            Message: The agent's response message\n\n        Raises:\n            Exception: If there's an error during agent execution\n        \"\"\"\n        logger.info(\"[CUGA] Starting Cuga agent run for message_response.\")\n        logger.info(f\"[CUGA] Agent input value: {self.input_value}\")\n\n        # Validate input is not empty\n        if not self.input_value or not str(self.input_value).strip():\n            msg = \"Message cannot be empty. Please provide a valid message.\"\n            raise ValueError(msg)\n\n        try:\n            llm_model, self.chat_history, self.tools = await self.get_agent_requirements()\n\n            # Create agent message for event processing\n            from lfx.schema.content_block import ContentBlock\n            from lfx.schema.message import MESSAGE_SENDER_AI\n\n            agent_message = Message(\n                sender=MESSAGE_SENDER_AI,\n                sender_name=\"Cuga\",\n                properties={\"icon\": \"Bot\", \"state\": \"partial\"},\n                content_blocks=[ContentBlock(title=\"Agent Steps\", contents=[])],\n                session_id=self.graph.session_id,\n            )\n\n            # Get input text\n            input_text = self.input_value.text if hasattr(self.input_value, \"text\") else str(self.input_value)\n\n            # Create event iterator from call_agent\n            event_iterator = self.call_agent(\n                current_input=input_text, tools=self.tools or [], history_messages=self.chat_history, llm=llm_model\n            )\n\n            # Process events using the existing event processing system\n            from lfx.base.agents.events import process_agent_events\n\n            # Create a wrapper that forces DB updates for event handlers\n            # This ensures the UI can see loading steps in real-time via polling\n            async def force_db_update_send_message(message, id_=None, *, skip_db_update=False):  # noqa: ARG001\n                # Always persist to DB so polling-based UI shows loading steps in real-time\n                content_blocks_len = len(message.content_blocks[0].contents) if message.content_blocks else 0\n                logger.debug(\n                    f\"[CUGA] Sending message update - state: {message.properties.state}, \"\n                    f\"content_blocks: {content_blocks_len}\"\n                )\n                result = await self.send_message(message, id_=id_, skip_db_update=False)\n                logger.debug(f\"[CUGA] Message saved to DB with ID: {result.id if result else 'None'}\")\n                return result\n\n            result = await process_agent_events(\n                event_iterator, agent_message, cast(\"SendMessageFunctionType\", force_db_update_send_message)\n            )\n\n            logger.info(\"[CUGA] Agent run finished successfully.\")\n            logger.info(f\"[CUGA] Agent output: {result}\")\n\n            # Store result for potential JSON output\n            self._agent_result = result\n\n        except Exception as e:\n            logger.error(f\"[CUGA] Error in message_response: {e}\")\n            logger.error(f\"An error occurred: {e!s}\")\n            logger.error(f\"Traceback: {traceback.format_exc()}\")\n\n            # Check if error is related to Playwright installation\n            error_str = str(e).lower()\n            if \"playwright install\" in error_str:\n                msg = (\n                    \"Playwright is not installed. Please install Playwright Chromium using: \"\n                    \"uv run -m playwright install chromium\"\n                )\n                raise ValueError(msg) from e\n\n            raise\n        else:\n            return result\n\n    async def get_agent_requirements(self):\n        \"\"\"Get the agent requirements for the Cuga agent.\n\n        This method retrieves and configures all necessary components for the agent\n        including the language model, chat history, and tools.\n\n        Returns:\n            tuple: A tuple containing (llm_model, chat_history, tools)\n\n        Raises:\n            ValueError: If no language model is selected or if there's an error\n                in model initialization\n        \"\"\"\n        llm_model, display_name = await self.get_llm()\n        if llm_model is None:\n            msg = \"No language model selected. Please choose a model to proceed.\"\n            raise ValueError(msg)\n        self.model_name = get_model_name(llm_model, display_name=display_name)\n\n        # Get memory data\n        self.chat_history = await self.get_memory_data()\n        if isinstance(self.chat_history, Message):\n            self.chat_history = [self.chat_history]\n\n        # Add current date tool if enabled\n        if self.add_current_date_tool:\n            if not isinstance(self.tools, list):\n                self.tools = []\n            current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n            if not isinstance(current_date_tool, StructuredTool):\n                msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                raise TypeError(msg)\n            self.tools.append(current_date_tool)\n\n        # --- ADDED LOGGING START ---\n        logger.info(\"[CUGA] Retrieved agent requirements: LLM, chat history, and tools.\")\n        logger.info(f\"[CUGA] LLM model: {self.model_name}\")\n        logger.info(f\"[CUGA] Number of chat history messages: {len(self.chat_history)}\")\n        logger.info(f\"[CUGA] Tools available: {[tool.name for tool in self.tools]}\")\n        logger.info(f\"[CUGA] metadata: {[tool.metadata for tool in self.tools]}\")\n        # --- ADDED LOGGING END ---\n\n        return llm_model, self.chat_history, self.tools\n\n    def _preprocess_schema(self, schema):\n        \"\"\"Preprocess schema to ensure correct data types for build_model_from_schema.\n\n        This method validates and normalizes the output schema to ensure it's compatible\n        with the Pydantic model building process.\n\n        Args:\n            schema: List of schema field definitions\n\n        Returns:\n            list: Processed schema with validated data types\n        \"\"\"\n        processed_schema = []\n        for field in schema:\n            processed_field = {\n                \"name\": str(field.get(\"name\", \"field\")),\n                \"type\": str(field.get(\"type\", \"str\")),\n                \"description\": str(field.get(\"description\", \"\")),\n                \"multiple\": field.get(\"multiple\", False),\n            }\n            # Ensure multiple is handled correctly\n            if isinstance(processed_field[\"multiple\"], str):\n                processed_field[\"multiple\"] = processed_field[\"multiple\"].lower() in [\"true\", \"1\", \"t\", \"y\", \"yes\"]\n            processed_schema.append(processed_field)\n        return processed_schema\n\n    async def build_structured_output_base(self, content: str):\n        \"\"\"Build structured output with optional BaseModel validation.\n\n        This method parses JSON content from the agent response and optionally validates\n        it against a provided schema using Pydantic models.\n\n        Args:\n            content: The raw content from the agent response\n\n        Returns:\n            dict or list: Parsed and optionally validated JSON data\n        \"\"\"\n        # --- ADDED LOGGING START ---\n        logger.info(f\"[CUGA] Attempting to build structured output from content: {content}\")\n        # --- ADDED LOGGING END ---\n\n        json_pattern = r\"\\{.*\\}\"\n        schema_error_msg = \"Try setting an output schema\"\n\n        # Try to parse content as JSON first\n        json_data = None\n        try:\n            json_data = json.loads(content)\n        except json.JSONDecodeError:\n            json_match = re.search(json_pattern, content, re.DOTALL)\n            if json_match:\n                try:\n                    json_data = json.loads(json_match.group())\n                except json.JSONDecodeError:\n                    logger.warning(\"[CUGA] Could not parse content as JSON even with regex match.\")\n                    return {\"content\": content, \"error\": schema_error_msg}\n            else:\n                logger.warning(\"[CUGA] No JSON pattern found in the content.\")\n                return {\"content\": content, \"error\": schema_error_msg}\n\n        # If no output schema provided, return parsed JSON without validation\n        if not hasattr(self, \"output_schema\") or not self.output_schema or len(self.output_schema) == 0:\n            logger.info(\"[CUGA] No output schema provided. Returning parsed JSON without validation.\")\n            return json_data\n\n        # Use BaseModel validation with schema\n        try:\n            logger.info(\"[CUGA] Output schema detected. Validating structured output against schema.\")\n            processed_schema = self._preprocess_schema(self.output_schema)\n            output_model = build_model_from_schema(processed_schema)\n\n            # Validate against the schema\n            if isinstance(json_data, list):\n                # Multiple objects\n                validated_objects = []\n                for item in json_data:\n                    try:\n                        validated_obj = output_model.model_validate(item)\n                        validated_objects.append(validated_obj.model_dump())\n                    except ValidationError as e:\n                        await logger.aerror(f\"[CUGA] Validation error for item: {e}\")\n                        validated_objects.append({\"data\": item, \"validation_error\": str(e)})\n                return validated_objects\n\n            # Single object\n            try:\n                validated_obj = output_model.model_validate(json_data)\n                return [validated_obj.model_dump()]\n            except ValidationError as e:\n                await logger.aerror(f\"[CUGA] Validation error: {e}\")\n                return [{\"data\": json_data, \"validation_error\": str(e)}]\n\n        except (TypeError, ValueError) as e:\n            await logger.aerror(f\"[CUGA] Error building structured output: {e}\")\n            return json_data\n\n    async def json_response(self) -> Data:\n        \"\"\"Convert agent response to structured JSON Data output with schema validation.\n\n        This method generates a structured JSON response by combining system instructions,\n        format instructions, and schema information, then processing the agent's response\n        through structured output validation.\n\n        Returns:\n            Data: Structured data object containing the validated JSON response\n\n        Raises:\n            ExceptionWithMessageError: If there's an error in structured processing\n            ValueError: If there's a validation error\n            TypeError: If there's a type error in processing\n        \"\"\"\n        # --- ADDED LOGGING START ---\n        logger.info(\"[CUGA] Starting Cuga agent run for json_response.\")\n        logger.info(f\"[CUGA] Agent input value: {self.input_value}\")\n        # --- ADDED LOGGING END ---\n\n        try:\n            system_components = []\n\n            # 1. Agent Instructions\n            agent_instructions = getattr(self, \"instructions\", \"\") or \"\"\n            if agent_instructions:\n                system_components.append(f\"{agent_instructions}\")\n\n            # 3. Format Instructions\n            format_instructions = getattr(self, \"format_instructions\", \"\") or \"\"\n            if format_instructions:\n                system_components.append(f\"Format instructions: {format_instructions}\")\n\n            # 4. Schema Information\n            if hasattr(self, \"output_schema\") and self.output_schema and len(self.output_schema) > 0:\n                try:\n                    processed_schema = self._preprocess_schema(self.output_schema)\n                    output_model = build_model_from_schema(processed_schema)\n                    schema_dict = output_model.model_json_schema()\n                    schema_info = (\n                        \"You are given some text that may include format instructions, \"\n                        \"explanations, or other content alongside a JSON schema.\\n\\n\"\n                        \"Your task:\\n\"\n                        \"- Extract only the JSON schema.\\n\"\n                        \"- Return it as valid JSON.\\n\"\n                        \"- Do not include format instructions, explanations, or extra text.\\n\\n\"\n                        \"Input:\\n\"\n                        f\"{json.dumps(schema_dict, indent=2)}\\n\\n\"\n                        \"Output (only JSON schema):\"\n                    )\n                    system_components.append(schema_info)\n                except (ValidationError, ValueError, TypeError, KeyError) as e:\n                    await logger.aerror(f\"[CUGA] Could not build schema for prompt: {e}\", exc_info=True)\n\n            # Combine all components\n            combined_instructions = \"\\n\\n\".join(system_components) if system_components else \"\"\n\n            llm_model, self.chat_history, self.tools = await self.get_agent_requirements()\n\n            # Use call_agent for structured response\n            input_text = self.input_value.text if hasattr(self.input_value, \"text\") else str(self.input_value)\n\n            # Modify the input to include structured output requirements\n            structured_input = (\n                f\"{combined_instructions}\\n\\nUser Input: {input_text}\\n\\nPlease provide a structured JSON response.\"\n            )\n\n            logger.info(f\"[CUGA] Combined system prompt for structured agent: {combined_instructions}\")\n\n            content = await self.call_agent(\n                current_input=structured_input,\n                tools=self.tools or [],\n                history_messages=self.chat_history,\n                llm=llm_model,\n            )\n\n            logger.info(f\"[CUGA] Structured agent result: {content}\")\n\n        except (ExceptionWithMessageError, ValueError, TypeError, NotImplementedError, AttributeError) as e:\n            await logger.aerror(f\"[CUGA] Error with structured agent: {e}\")\n            content_str = \"No content returned from Cuga agent\"\n            return Data(data={\"content\": content_str, \"error\": str(e)})\n\n        # Process with structured output validation\n        try:\n            structured_output = await self.build_structured_output_base(content)\n\n            # Handle different output formats\n            if isinstance(structured_output, list) and structured_output:\n                if len(structured_output) == 1:\n                    logger.info(\"[CUGA] Structured output is a single object in a list.\")\n                    logger.info(f\"[CUGA] Final structured output: {structured_output[0]}\")\n                    return Data(data=structured_output[0])\n                logger.info(\"[CUGA] Structured output is a list of multiple objects.\")\n                logger.info(f\"[CUGA] Final structured output: {structured_output}\")\n                return Data(data={\"results\": structured_output})\n            if isinstance(structured_output, dict):\n                logger.info(\"[CUGA] Structured output is a single dictionary.\")\n                logger.info(f\"[CUGA] Final structured output: {structured_output}\")\n                return Data(data=structured_output)\n            logger.info(\"[CUGA] Structured output is not a list or dictionary. Returning raw content.\")\n            logger.info(f\"[CUGA] Final output content: {content}\")\n            return Data(data={\"content\": content})\n\n        except (ValueError, TypeError) as e:\n            await logger.aerror(f\"[CUGA] Error in structured output processing: {e}\")\n            return Data(data={\"content\": content, \"error\": str(e)})\n\n    async def get_memory_data(self):\n        \"\"\"Retrieve chat history messages.\n\n        This method fetches the conversation history from memory, excluding the current\n        input message to avoid duplication.\n\n        Returns:\n            list: List of Message objects representing the chat history\n        \"\"\"\n        logger.info(\"[CUGA] Retrieving chat history messages.\")\n        messages = (\n            await MemoryComponent(**self.get_base_args())\n            .set(session_id=self.graph.session_id, order=\"Ascending\", n_messages=self.n_messages)\n            .retrieve_messages()\n        )\n        return [\n            message for message in messages if getattr(message, \"id\", None) != getattr(self.input_value, \"id\", None)\n        ]\n\n    async def get_llm(self):\n        \"\"\"Get language model for the Cuga agent.\n\n        This method initializes and configures the language model based on the\n        selected provider and parameters.\n\n        Returns:\n            tuple: A tuple containing (llm_model, display_name)\n\n        Raises:\n            ValueError: If the model provider is invalid or model initialization fails\n        \"\"\"\n        logger.info(\"[CUGA] Getting language model for the agent.\")\n        logger.info(f\"[CUGA] Requested LLM provider: {self.agent_llm}\")\n\n        if not isinstance(self.agent_llm, str):\n            logger.info(\"[CUGA] Agent LLM is already a model instance.\")\n            return self.agent_llm, None\n\n        try:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if not provider_info:\n                msg = f\"Invalid model provider: {self.agent_llm}\"\n                raise ValueError(msg)\n\n            component_class = provider_info.get(\"component_class\")\n            display_name = component_class.display_name\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\", \"\")\n            logger.info(f\"[CUGA] Successfully built LLM model from provider: {self.agent_llm}\")\n            return self._build_llm_model(component_class, inputs, prefix), display_name\n\n        except (AttributeError, ValueError, TypeError, RuntimeError) as e:\n            await logger.aerror(f\"[CUGA] Error building {self.agent_llm} language model: {e!s}\")\n            msg = f\"Failed to initialize language model: {e!s}\"\n            raise ValueError(msg) from e\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        \"\"\"Build LLM model with parameters.\n\n        This method constructs a language model instance using the provided component\n        class and input parameters.\n\n        Args:\n            component: The LLM component class to instantiate\n            inputs: List of input field definitions\n            prefix: Optional prefix for parameter names\n\n        Returns:\n            The configured LLM model instance\n        \"\"\"\n        model_kwargs = {}\n        for input_ in inputs:\n            if hasattr(self, f\"{prefix}{input_.name}\"):\n                model_kwargs[input_.name] = getattr(self, f\"{prefix}{input_.name}\")\n        return component.set(**model_kwargs).build_model()\n\n    def set_component_params(self, component):\n        \"\"\"Set component parameters based on provider.\n\n        This method configures component parameters according to the selected\n        model provider's requirements.\n\n        Args:\n            component: The component to configure\n\n        Returns:\n            The configured component\n        \"\"\"\n        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n        if provider_info:\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\")\n            model_kwargs = {}\n            for input_ in inputs:\n                if hasattr(self, f\"{prefix}{input_.name}\"):\n                    model_kwargs[input_.name] = getattr(self, f\"{prefix}{input_.name}\")\n            return component.set(**model_kwargs)\n        return component\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\n\n        This method removes unwanted fields from the build configuration.\n\n        Args:\n            build_config: The build configuration dictionary\n            fields: Fields to remove (can be dict or list of strings)\n        \"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\n\n        This method ensures all fields in the build configuration have proper\n        input types defined.\n\n        Args:\n            build_config: The build configuration to update\n\n        Returns:\n            dotdict: Updated build configuration with input types\n        \"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self, build_config: dotdict, field_value: str, field_name: str | None = None\n    ) -> dotdict:\n        \"\"\"Update build configuration based on field changes.\n\n        This method dynamically updates the component's build configuration when\n        certain fields change, particularly the model provider selection.\n\n        Args:\n            build_config: The current build configuration\n            field_value: The new value for the field\n            field_name: The name of the field being changed\n\n        Returns:\n            dotdict: Updated build configuration\n\n        Raises:\n            ValueError: If required keys are missing from the configuration\n        \"\"\"\n        if field_name in (\"agent_llm\",):\n            build_config[\"agent_llm\"][\"value\"] = field_value\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                build_config[\"agent_llm\"][\"input_types\"] = []\n            elif field_value == \"Custom\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    options=[*sorted(MODEL_PROVIDERS), \"Custom\"],\n                    value=\"Custom\",\n                    real_time_refresh=True,\n                    input_types=[\"LanguageModel\"],\n                    options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())]\n                    + [{\"icon\": \"brain\"}],\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"policies\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n\n        if (\n            isinstance(self.agent_llm, str)\n            and self.agent_llm in MODEL_PROVIDERS_DICT\n            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS\n        ):\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                component_class = self.set_component_params(component_class)\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n\n    async def _get_tools(self) -> list[Tool]:\n        \"\"\"Build agent tools.\n\n        This method constructs the list of tools available to the Cuga agent,\n        including component tools and any additional configured tools.\n\n        Returns:\n            list[Tool]: List of available tools for the agent\n        \"\"\"\n        logger.info(\"[CUGA] Building agent tools.\")\n        component_toolkit = _get_component_toolkit()\n        tools_names = self._build_tools_names()\n        agent_description = self.get_tool_description()\n        description = f\"{agent_description}{tools_names}\"\n        tools = component_toolkit(component=self).get_tools(\n            tool_name=\"Call_CugaAgent\", tool_description=description, callbacks=self.get_langchain_callbacks()\n        )\n        if hasattr(self, \"tools_metadata\"):\n            tools = component_toolkit(component=self, metadata=self.tools_metadata).update_tools_metadata(tools=tools)\n        logger.info(f\"[CUGA] Tools built: {[tool.name for tool in tools]}\")\n        return tools\n"},"format_instructions":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"Output Format Instructions","dynamic":false,"info":"Generic Template for structured output formatting. Valid only with Structured response.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"format_instructions","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"You are an AI that extracts structured JSON objects from unstructured text. Use a predefined schema with expected types (str, int, float, bool, dict). Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. Fill missing or ambiguous values with defaults: null for missing values. Remove exact duplicates but keep variations that have different field values. Always return valid JSON in the expected format, never throw errors. If multiple objects can be extracted, return them all in the structured format."},"handle_parsing_errors":{"_input_type":"BoolInput","advanced":true,"display_name":"Handle Parse Errors","dynamic":false,"info":"Should the Agent fix errors when reading user input for better processing?","list":false,"list_add_label":"Add More","name":"handle_parsing_errors","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"The input provided by the user for the agent to process.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"max_iterations":{"_input_type":"IntInput","advanced":true,"display_name":"Max Iterations","dynamic":false,"info":"The maximum number of attempts the agent can make to complete its task before it stops.","list":false,"list_add_label":"Add More","name":"max_iterations","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":15},"max_retries":{"_input_type":"IntInput","advanced":true,"display_name":"Max Retries","dynamic":false,"info":"The maximum number of retries to make when generating.","list":false,"list_add_label":"Add More","name":"max_retries","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5},"max_tokens":{"_input_type":"IntInput","advanced":true,"display_name":"Max Tokens","dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","list":false,"list_add_label":"Add More","name":"max_tokens","placeholder":"","range_spec":{"max":128000.0,"min":0.0,"step":0.1,"step_type":"float"},"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"model_kwargs":{"_input_type":"DictInput","advanced":true,"display_name":"Model Kwargs","dynamic":false,"info":"Additional keyword arguments to pass to the model.","list":false,"list_add_label":"Add More","name":"model_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":true,"dialog_inputs":{},"display_name":"Model Name","dynamic":false,"external_options":{},"info":"To see the model names, first choose a provider. Then, enter your API key and click the refresh button next to the model name.","name":"model_name","options":["gpt-4o-mini","gpt-4o","gpt-4.1","gpt-4.1-mini","gpt-4.1-nano","gpt-4-turbo","gpt-4-turbo-preview","gpt-4","gpt-3.5-turbo","gpt-5","gpt-5-mini","gpt-5-nano","gpt-5-chat-latest","o1","o3-mini","o3","o3-pro","o4-mini","o4-mini-high"],"options_metadata":[],"placeholder":"","real_time_refresh":false,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"gpt-4o-mini"},"n_messages":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Chat History Messages","dynamic":false,"info":"Number of chat history messages to retrieve.","list":false,"list_add_label":"Add More","name":"n_messages","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":100},"openai_api_base":{"_input_type":"StrInput","advanced":true,"display_name":"OpenAI API Base","dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"openai_api_base","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"output_schema":{"_input_type":"TableInput","advanced":true,"display_name":"Output Schema","dynamic":false,"info":"Schema Validation: Define the structure and data types for structured output. No validation if no output schema.","is_list":true,"list_add_label":"Add More","name":"output_schema","placeholder":"","required":false,"show":true,"table_icon":"Table","table_schema":[{"default":"field","description":"Specify the name of the output field.","display_name":"Name","edit_mode":"inline","name":"name","type":"str"},{"default":"description of field","description":"Describe the purpose of the output field.","display_name":"Description","edit_mode":"popover","name":"description","type":"str"},{"default":"str","description":"Indicate the data type of the output field (e.g., str, int, float, bool, dict).","display_name":"Type","edit_mode":"inline","name":"type","options":["str","int","float","bool","dict"],"type":"str"},{"default":"False","description":"Set to True if this output field should be a list of the specified type.","display_name":"As List","edit_mode":"inline","name":"multiple","type":"boolean"}],"title_case":false,"tool_mode":false,"trace_as_metadata":true,"trigger_icon":"Table","trigger_text":"Open table","type":"table","value":[]},"policies":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Policies","dynamic":false,"info":"Custom instructions or policies for the agent to adhere to during its operation.\nExample:\n# Plan\n< planning instructions e.g. which tools and when to use>\n# Answer\n< final answer instructions how to answer>","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"policies","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"seed":{"_input_type":"IntInput","advanced":true,"display_name":"Seed","dynamic":false,"info":"The seed controls the reproducibility of the job.","list":false,"list_add_label":"Add More","name":"seed","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1},"temperature":{"_input_type":"SliderInput","advanced":true,"display_name":"Temperature","dynamic":false,"info":"","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"temperature","placeholder":"","range_spec":{"max":1.0,"min":0.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":0.1},"timeout":{"_input_type":"IntInput","advanced":true,"display_name":"Timeout","dynamic":false,"info":"The timeout for requests to OpenAI completion API.","list":false,"list_add_label":"Add More","name":"timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":700},"tools":{"_input_type":"HandleInput","advanced":false,"display_name":"Tools","dynamic":false,"info":"These are the tools that the agent can use to help with tasks.","input_types":["Tool"],"list":true,"list_add_label":"Add More","name":"tools","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"verbose":{"_input_type":"BoolInput","advanced":true,"display_name":"Verbose","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"verbose","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"web_apps":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Web applications","dynamic":false,"info":"Define a list of web applications that cuga will open when enable browser is true. Currently only supports one web application. Example: https://example.com","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"web_apps","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"MCPTools":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Connect to an MCP server to use its tools.","display_name":"MCP Tools","documentation":"https://docs.langflow.org/mcp-client","edited":false,"field_order":["mcp_server","use_cache","tool","tool_placeholder"],"frozen":false,"icon":"Mcp","legacy":false,"metadata":{"code_hash":"984d87bdb1dc","dependencies":{"dependencies":[{"name":"langchain_core","version":"0.3.79"},{"name":"lfx","version":null},{"name":"langflow","version":null}],"total_dependencies":3},"module":"lfx.components.agents.mcp_component.MCPToolsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Response","group_outputs":false,"method":"build_output","name":"response","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from __future__ import annotations\n\nimport asyncio\nimport uuid\nfrom typing import Any\n\nfrom langchain_core.tools import StructuredTool  # noqa: TC002\n\nfrom lfx.base.agents.utils import maybe_unflatten_dict, safe_cache_get, safe_cache_set\nfrom lfx.base.mcp.util import (\n    MCPStdioClient,\n    MCPStreamableHttpClient,\n    create_input_schema_from_json_schema,\n    update_tools,\n)\nfrom lfx.custom.custom_component.component_with_cache import ComponentWithCache\nfrom lfx.inputs.inputs import InputTypes  # noqa: TC001\nfrom lfx.io import BoolInput, DropdownInput, McpInput, MessageTextInput, Output\nfrom lfx.io.schema import flatten_schema, schema_to_langflow_inputs\nfrom lfx.log.logger import logger\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.message import Message\nfrom lfx.services.deps import get_settings_service, get_storage_service, session_scope\n\n\nclass MCPToolsComponent(ComponentWithCache):\n    schema_inputs: list = []\n    tools: list[StructuredTool] = []\n    _not_load_actions: bool = False\n    _tool_cache: dict = {}\n    _last_selected_server: str | None = None  # Cache for the last selected server\n\n    def __init__(self, **data) -> None:\n        super().__init__(**data)\n        # Initialize cache keys to avoid CacheMiss when accessing them\n        self._ensure_cache_structure()\n\n        # Initialize clients with access to the component cache\n        self.stdio_client: MCPStdioClient = MCPStdioClient(component_cache=self._shared_component_cache)\n        self.streamable_http_client: MCPStreamableHttpClient = MCPStreamableHttpClient(\n            component_cache=self._shared_component_cache\n        )\n\n    def _ensure_cache_structure(self):\n        \"\"\"Ensure the cache has the required structure.\"\"\"\n        # Check if servers key exists and is not CacheMiss\n        servers_value = safe_cache_get(self._shared_component_cache, \"servers\")\n        if servers_value is None:\n            safe_cache_set(self._shared_component_cache, \"servers\", {})\n\n        # Check if last_selected_server key exists and is not CacheMiss\n        last_server_value = safe_cache_get(self._shared_component_cache, \"last_selected_server\")\n        if last_server_value is None:\n            safe_cache_set(self._shared_component_cache, \"last_selected_server\", \"\")\n\n    default_keys: list[str] = [\n        \"code\",\n        \"_type\",\n        \"tool_mode\",\n        \"tool_placeholder\",\n        \"mcp_server\",\n        \"tool\",\n        \"use_cache\",\n    ]\n\n    display_name = \"MCP Tools\"\n    description = \"Connect to an MCP server to use its tools.\"\n    documentation: str = \"https://docs.langflow.org/mcp-client\"\n    icon = \"Mcp\"\n    name = \"MCPTools\"\n\n    inputs = [\n        McpInput(\n            name=\"mcp_server\",\n            display_name=\"MCP Server\",\n            info=\"Select the MCP Server that will be used by this component\",\n            real_time_refresh=True,\n        ),\n        BoolInput(\n            name=\"use_cache\",\n            display_name=\"Use Cached Server\",\n            info=(\n                \"Enable caching of MCP Server and tools to improve performance. \"\n                \"Disable to always fetch fresh tools and server updates.\"\n            ),\n            value=False,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"tool\",\n            display_name=\"Tool\",\n            options=[],\n            value=\"\",\n            info=\"Select the tool to execute\",\n            show=False,\n            required=True,\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            info=\"Placeholder for the tool\",\n            value=\"\",\n            show=False,\n            tool_mode=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Response\", name=\"response\", method=\"build_output\"),\n    ]\n\n    async def _validate_schema_inputs(self, tool_obj) -> list[InputTypes]:\n        \"\"\"Validate and process schema inputs for a tool.\"\"\"\n        try:\n            if not tool_obj or not hasattr(tool_obj, \"args_schema\"):\n                msg = \"Invalid tool object or missing input schema\"\n                raise ValueError(msg)\n\n            flat_schema = flatten_schema(tool_obj.args_schema.schema())\n            input_schema = create_input_schema_from_json_schema(flat_schema)\n            if not input_schema:\n                msg = f\"Empty input schema for tool '{tool_obj.name}'\"\n                raise ValueError(msg)\n\n            schema_inputs = schema_to_langflow_inputs(input_schema)\n            if not schema_inputs:\n                msg = f\"No input parameters defined for tool '{tool_obj.name}'\"\n                await logger.awarning(msg)\n                return []\n\n        except Exception as e:\n            msg = f\"Error validating schema inputs: {e!s}\"\n            await logger.aexception(msg)\n            raise ValueError(msg) from e\n        else:\n            return schema_inputs\n\n    async def update_tool_list(self, mcp_server_value=None):\n        # Accepts mcp_server_value as dict {name, config} or uses self.mcp_server\n        mcp_server = mcp_server_value if mcp_server_value is not None else getattr(self, \"mcp_server\", None)\n        server_name = None\n        server_config_from_value = None\n        if isinstance(mcp_server, dict):\n            server_name = mcp_server.get(\"name\")\n            server_config_from_value = mcp_server.get(\"config\")\n        else:\n            server_name = mcp_server\n        if not server_name:\n            self.tools = []\n            return [], {\"name\": server_name, \"config\": server_config_from_value}\n\n        # Check if caching is enabled, default to False\n        use_cache = getattr(self, \"use_cache\", False)\n\n        # Use shared cache if available and caching is enabled\n        cached = None\n        if use_cache:\n            servers_cache = safe_cache_get(self._shared_component_cache, \"servers\", {})\n            cached = servers_cache.get(server_name) if isinstance(servers_cache, dict) else None\n\n        if cached is not None:\n            try:\n                self.tools = cached[\"tools\"]\n                self.tool_names = cached[\"tool_names\"]\n                self._tool_cache = cached[\"tool_cache\"]\n                server_config_from_value = cached[\"config\"]\n            except (TypeError, KeyError, AttributeError) as e:\n                # Handle corrupted cache data by clearing it and continuing to fetch fresh tools\n                msg = f\"Unable to use cached data for MCP Server{server_name}: {e}\"\n                await logger.awarning(msg)\n                # Clear the corrupted cache entry\n                current_servers_cache = safe_cache_get(self._shared_component_cache, \"servers\", {})\n                if isinstance(current_servers_cache, dict) and server_name in current_servers_cache:\n                    current_servers_cache.pop(server_name)\n                    safe_cache_set(self._shared_component_cache, \"servers\", current_servers_cache)\n            else:\n                return self.tools, {\"name\": server_name, \"config\": server_config_from_value}\n\n        try:\n            try:\n                from langflow.api.v2.mcp import get_server\n                from langflow.services.database.models.user.crud import get_user_by_id\n            except ImportError as e:\n                msg = (\n                    \"Langflow MCP server functionality is not available. \"\n                    \"This feature requires the full Langflow installation.\"\n                )\n                raise ImportError(msg) from e\n            async with session_scope() as db:\n                if not self.user_id:\n                    msg = \"User ID is required for fetching MCP tools.\"\n                    raise ValueError(msg)\n                current_user = await get_user_by_id(db, self.user_id)\n\n                # Try to get server config from DB/API\n                server_config = await get_server(\n                    server_name,\n                    current_user,\n                    db,\n                    storage_service=get_storage_service(),\n                    settings_service=get_settings_service(),\n                )\n\n            # If get_server returns empty but we have a config, use it\n            if not server_config and server_config_from_value:\n                server_config = server_config_from_value\n\n            if not server_config:\n                self.tools = []\n                return [], {\"name\": server_name, \"config\": server_config}\n\n            _, tool_list, tool_cache = await update_tools(\n                server_name=server_name,\n                server_config=server_config,\n                mcp_stdio_client=self.stdio_client,\n                mcp_streamable_http_client=self.streamable_http_client,\n            )\n\n            self.tool_names = [tool.name for tool in tool_list if hasattr(tool, \"name\")]\n            self._tool_cache = tool_cache\n            self.tools = tool_list\n\n            # Cache the result only if caching is enabled\n            if use_cache:\n                cache_data = {\n                    \"tools\": tool_list,\n                    \"tool_names\": self.tool_names,\n                    \"tool_cache\": tool_cache,\n                    \"config\": server_config,\n                }\n\n                # Safely update the servers cache\n                current_servers_cache = safe_cache_get(self._shared_component_cache, \"servers\", {})\n                if isinstance(current_servers_cache, dict):\n                    current_servers_cache[server_name] = cache_data\n                    safe_cache_set(self._shared_component_cache, \"servers\", current_servers_cache)\n\n        except (TimeoutError, asyncio.TimeoutError) as e:\n            msg = f\"Timeout updating tool list: {e!s}\"\n            await logger.aexception(msg)\n            raise TimeoutError(msg) from e\n        except Exception as e:\n            msg = f\"Error updating tool list: {e!s}\"\n            await logger.aexception(msg)\n            raise ValueError(msg) from e\n        else:\n            return tool_list, {\"name\": server_name, \"config\": server_config}\n\n    async def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        \"\"\"Toggle the visibility of connection-specific fields based on the selected mode.\"\"\"\n        try:\n            if field_name == \"tool\":\n                try:\n                    if len(self.tools) == 0:\n                        try:\n                            self.tools, build_config[\"mcp_server\"][\"value\"] = await self.update_tool_list()\n                            build_config[\"tool\"][\"options\"] = [tool.name for tool in self.tools]\n                            build_config[\"tool\"][\"placeholder\"] = \"Select a tool\"\n                        except (TimeoutError, asyncio.TimeoutError) as e:\n                            msg = f\"Timeout updating tool list: {e!s}\"\n                            await logger.aexception(msg)\n                            if not build_config[\"tools_metadata\"][\"show\"]:\n                                build_config[\"tool\"][\"show\"] = True\n                                build_config[\"tool\"][\"options\"] = []\n                                build_config[\"tool\"][\"value\"] = \"\"\n                                build_config[\"tool\"][\"placeholder\"] = \"Timeout on MCP server\"\n                            else:\n                                build_config[\"tool\"][\"show\"] = False\n                        except ValueError:\n                            if not build_config[\"tools_metadata\"][\"show\"]:\n                                build_config[\"tool\"][\"show\"] = True\n                                build_config[\"tool\"][\"options\"] = []\n                                build_config[\"tool\"][\"value\"] = \"\"\n                                build_config[\"tool\"][\"placeholder\"] = \"Error on MCP Server\"\n                            else:\n                                build_config[\"tool\"][\"show\"] = False\n\n                    if field_value == \"\":\n                        return build_config\n                    tool_obj = None\n                    for tool in self.tools:\n                        if tool.name == field_value:\n                            tool_obj = tool\n                            break\n                    if tool_obj is None:\n                        msg = f\"Tool {field_value} not found in available tools: {self.tools}\"\n                        await logger.awarning(msg)\n                        return build_config\n                    await self._update_tool_config(build_config, field_value)\n                except Exception as e:\n                    build_config[\"tool\"][\"options\"] = []\n                    msg = f\"Failed to update tools: {e!s}\"\n                    raise ValueError(msg) from e\n                else:\n                    return build_config\n            elif field_name == \"mcp_server\":\n                if not field_value:\n                    build_config[\"tool\"][\"show\"] = False\n                    build_config[\"tool\"][\"options\"] = []\n                    build_config[\"tool\"][\"value\"] = \"\"\n                    build_config[\"tool\"][\"placeholder\"] = \"\"\n                    build_config[\"tool_placeholder\"][\"tool_mode\"] = False\n                    self.remove_non_default_keys(build_config)\n                    return build_config\n\n                build_config[\"tool_placeholder\"][\"tool_mode\"] = True\n\n                current_server_name = field_value.get(\"name\") if isinstance(field_value, dict) else field_value\n                _last_selected_server = safe_cache_get(self._shared_component_cache, \"last_selected_server\", \"\")\n\n                # To avoid unnecessary updates, only proceed if the server has actually changed\n                if (_last_selected_server in (current_server_name, \"\")) and build_config[\"tool\"][\"show\"]:\n                    if current_server_name:\n                        servers_cache = safe_cache_get(self._shared_component_cache, \"servers\", {})\n                        if isinstance(servers_cache, dict):\n                            cached = servers_cache.get(current_server_name)\n                            if cached is not None and cached.get(\"tool_names\"):\n                                cached_tools = cached[\"tool_names\"]\n                                current_tools = build_config[\"tool\"][\"options\"]\n                                if current_tools == cached_tools:\n                                    return build_config\n                    else:\n                        return build_config\n\n                # Determine if \"Tool Mode\" is active by checking if the tool dropdown is hidden.\n                is_in_tool_mode = build_config[\"tools_metadata\"][\"show\"]\n                safe_cache_set(self._shared_component_cache, \"last_selected_server\", current_server_name)\n\n                # Check if tools are already cached for this server before clearing\n                cached_tools = None\n                if current_server_name:\n                    use_cache = getattr(self, \"use_cache\", True)\n                    if use_cache:\n                        servers_cache = safe_cache_get(self._shared_component_cache, \"servers\", {})\n                        if isinstance(servers_cache, dict):\n                            cached = servers_cache.get(current_server_name)\n                            if cached is not None:\n                                try:\n                                    cached_tools = cached[\"tools\"]\n                                    self.tools = cached_tools\n                                    self.tool_names = cached[\"tool_names\"]\n                                    self._tool_cache = cached[\"tool_cache\"]\n                                except (TypeError, KeyError, AttributeError) as e:\n                                    # Handle corrupted cache data by ignoring it\n                                    msg = f\"Unable to use cached data for MCP Server,{current_server_name}: {e}\"\n                                    await logger.awarning(msg)\n                                    cached_tools = None\n\n                # Only clear tools if we don't have cached tools for the current server\n                if not cached_tools:\n                    self.tools = []  # Clear previous tools only if no cache\n\n                self.remove_non_default_keys(build_config)  # Clear previous tool inputs\n\n                # Only show the tool dropdown if not in tool_mode\n                if not is_in_tool_mode:\n                    build_config[\"tool\"][\"show\"] = True\n                    if cached_tools:\n                        # Use cached tools to populate options immediately\n                        build_config[\"tool\"][\"options\"] = [tool.name for tool in cached_tools]\n                        build_config[\"tool\"][\"placeholder\"] = \"Select a tool\"\n                    else:\n                        # Show loading state only when we need to fetch tools\n                        build_config[\"tool\"][\"placeholder\"] = \"Loading tools...\"\n                        build_config[\"tool\"][\"options\"] = []\n                    build_config[\"tool\"][\"value\"] = uuid.uuid4()\n                else:\n                    # Keep the tool dropdown hidden if in tool_mode\n                    self._not_load_actions = True\n                    build_config[\"tool\"][\"show\"] = False\n\n            elif field_name == \"tool_mode\":\n                build_config[\"tool\"][\"placeholder\"] = \"\"\n                build_config[\"tool\"][\"show\"] = not bool(field_value) and bool(build_config[\"mcp_server\"])\n                self.remove_non_default_keys(build_config)\n                self.tool = build_config[\"tool\"][\"value\"]\n                if field_value:\n                    self._not_load_actions = True\n                else:\n                    build_config[\"tool\"][\"value\"] = uuid.uuid4()\n                    build_config[\"tool\"][\"options\"] = []\n                    build_config[\"tool\"][\"show\"] = True\n                    build_config[\"tool\"][\"placeholder\"] = \"Loading tools...\"\n            elif field_name == \"tools_metadata\":\n                self._not_load_actions = False\n\n        except Exception as e:\n            msg = f\"Error in update_build_config: {e!s}\"\n            await logger.aexception(msg)\n            raise ValueError(msg) from e\n        else:\n            return build_config\n\n    def get_inputs_for_all_tools(self, tools: list) -> dict:\n        \"\"\"Get input schemas for all tools.\"\"\"\n        inputs = {}\n        for tool in tools:\n            if not tool or not hasattr(tool, \"name\"):\n                continue\n            try:\n                flat_schema = flatten_schema(tool.args_schema.schema())\n                input_schema = create_input_schema_from_json_schema(flat_schema)\n                langflow_inputs = schema_to_langflow_inputs(input_schema)\n                inputs[tool.name] = langflow_inputs\n            except (AttributeError, ValueError, TypeError, KeyError) as e:\n                msg = f\"Error getting inputs for tool {getattr(tool, 'name', 'unknown')}: {e!s}\"\n                logger.exception(msg)\n                continue\n        return inputs\n\n    def remove_input_schema_from_build_config(\n        self, build_config: dict, tool_name: str, input_schema: dict[list[InputTypes], Any]\n    ):\n        \"\"\"Remove the input schema for the tool from the build config.\"\"\"\n        # Keep only schemas that don't belong to the current tool\n        input_schema = {k: v for k, v in input_schema.items() if k != tool_name}\n        # Remove all inputs from other tools\n        for value in input_schema.values():\n            for _input in value:\n                if _input.name in build_config:\n                    build_config.pop(_input.name)\n\n    def remove_non_default_keys(self, build_config: dict) -> None:\n        \"\"\"Remove non-default keys from the build config.\"\"\"\n        for key in list(build_config.keys()):\n            if key not in self.default_keys:\n                build_config.pop(key)\n\n    async def _update_tool_config(self, build_config: dict, tool_name: str) -> None:\n        \"\"\"Update tool configuration with proper error handling.\"\"\"\n        if not self.tools:\n            self.tools, build_config[\"mcp_server\"][\"value\"] = await self.update_tool_list()\n\n        if not tool_name:\n            return\n\n        tool_obj = next((tool for tool in self.tools if tool.name == tool_name), None)\n        if not tool_obj:\n            msg = f\"Tool {tool_name} not found in available tools: {self.tools}\"\n            self.remove_non_default_keys(build_config)\n            build_config[\"tool\"][\"value\"] = \"\"\n            await logger.awarning(msg)\n            return\n\n        try:\n            # Store current values before removing inputs\n            current_values = {}\n            for key, value in build_config.items():\n                if key not in self.default_keys and isinstance(value, dict) and \"value\" in value:\n                    current_values[key] = value[\"value\"]\n\n            # Get all tool inputs and remove old ones\n            input_schema_for_all_tools = self.get_inputs_for_all_tools(self.tools)\n            self.remove_input_schema_from_build_config(build_config, tool_name, input_schema_for_all_tools)\n\n            # Get and validate new inputs\n            self.schema_inputs = await self._validate_schema_inputs(tool_obj)\n            if not self.schema_inputs:\n                msg = f\"No input parameters to configure for tool '{tool_name}'\"\n                await logger.ainfo(msg)\n                return\n\n            # Add new inputs to build config\n            for schema_input in self.schema_inputs:\n                if not schema_input or not hasattr(schema_input, \"name\"):\n                    msg = \"Invalid schema input detected, skipping\"\n                    await logger.awarning(msg)\n                    continue\n\n                try:\n                    name = schema_input.name\n                    input_dict = schema_input.to_dict()\n                    input_dict.setdefault(\"value\", None)\n                    input_dict.setdefault(\"required\", True)\n\n                    build_config[name] = input_dict\n\n                    # Preserve existing value if the parameter name exists in current_values\n                    if name in current_values:\n                        build_config[name][\"value\"] = current_values[name]\n\n                except (AttributeError, KeyError, TypeError) as e:\n                    msg = f\"Error processing schema input {schema_input}: {e!s}\"\n                    await logger.aexception(msg)\n                    continue\n        except ValueError as e:\n            msg = f\"Schema validation error for tool {tool_name}: {e!s}\"\n            await logger.aexception(msg)\n            self.schema_inputs = []\n            return\n        except (AttributeError, KeyError, TypeError) as e:\n            msg = f\"Error updating tool config: {e!s}\"\n            await logger.aexception(msg)\n            raise ValueError(msg) from e\n\n    async def build_output(self) -> DataFrame:\n        \"\"\"Build output with improved error handling and validation.\"\"\"\n        try:\n            self.tools, _ = await self.update_tool_list()\n            if self.tool != \"\":\n                # Set session context for persistent MCP sessions using Langflow session ID\n                session_context = self._get_session_context()\n                if session_context:\n                    self.stdio_client.set_session_context(session_context)\n                    self.streamable_http_client.set_session_context(session_context)\n\n                exec_tool = self._tool_cache[self.tool]\n                tool_args = self.get_inputs_for_all_tools(self.tools)[self.tool]\n                kwargs = {}\n                for arg in tool_args:\n                    value = getattr(self, arg.name, None)\n                    if value is not None:\n                        if isinstance(value, Message):\n                            kwargs[arg.name] = value.text\n                        else:\n                            kwargs[arg.name] = value\n\n                unflattened_kwargs = maybe_unflatten_dict(kwargs)\n\n                output = await exec_tool.coroutine(**unflattened_kwargs)\n\n                tool_content = []\n                for item in output.content:\n                    item_dict = item.model_dump()\n                    tool_content.append(item_dict)\n                return DataFrame(data=tool_content)\n            return DataFrame(data=[{\"error\": \"You must select a tool\"}])\n        except Exception as e:\n            msg = f\"Error in build_output: {e!s}\"\n            await logger.aexception(msg)\n            raise ValueError(msg) from e\n\n    def _get_session_context(self) -> str | None:\n        \"\"\"Get the Langflow session ID for MCP session caching.\"\"\"\n        # Try to get session ID from the component's execution context\n        if hasattr(self, \"graph\") and hasattr(self.graph, \"session_id\"):\n            session_id = self.graph.session_id\n            # Include server name to ensure different servers get different sessions\n            server_name = \"\"\n            mcp_server = getattr(self, \"mcp_server\", None)\n            if isinstance(mcp_server, dict):\n                server_name = mcp_server.get(\"name\", \"\")\n            elif mcp_server:\n                server_name = str(mcp_server)\n            return f\"{session_id}_{server_name}\" if session_id else None\n        return None\n\n    async def _get_tools(self):\n        \"\"\"Get cached tools or update if necessary.\"\"\"\n        mcp_server = getattr(self, \"mcp_server\", None)\n        if not self._not_load_actions:\n            tools, _ = await self.update_tool_list(mcp_server)\n            return tools\n        return []\n"},"mcp_server":{"_input_type":"McpInput","advanced":false,"display_name":"MCP Server","dynamic":false,"info":"Select the MCP Server that will be used by this component","name":"mcp_server","placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"mcp","value":{}},"tool":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Tool","dynamic":false,"external_options":{},"info":"Select the tool to execute","name":"tool","options":[],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":true,"show":false,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tool_placeholder":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Tool Placeholder","dynamic":false,"info":"Placeholder for the tool","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"tool_placeholder","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"use_cache":{"_input_type":"BoolInput","advanced":true,"display_name":"Use Cached Server","dynamic":false,"info":"Enable caching of MCP Server and tools to improve performance. Disable to always fetch fresh tools and server updates.","list":false,"list_add_label":"Add More","name":"use_cache","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false}}],["aiml",{"AIMLEmbeddings":{"base_classes":["Embeddings"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate embeddings using the AI/ML API.","display_name":"AI/ML API Embeddings","documentation":"","edited":false,"field_order":["model_name","aiml_api_key"],"frozen":false,"icon":"AIML","legacy":false,"metadata":{"code_hash":"dae370391ba3","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.aiml.aiml_embeddings.AIMLEmbeddingsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Embedding Model","group_outputs":false,"method":"build_embeddings","name":"embeddings","selected":"Embeddings","tool_mode":true,"types":["Embeddings"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","aiml_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"AI/ML API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"aiml_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"AIML_API_KEY"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.embeddings.aiml_embeddings import AIMLEmbeddingsImpl\nfrom lfx.base.embeddings.model import LCEmbeddingsModel\nfrom lfx.field_typing import Embeddings\nfrom lfx.inputs.inputs import DropdownInput\nfrom lfx.io import SecretStrInput\n\n\nclass AIMLEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"AI/ML API Embeddings\"\n    description = \"Generate embeddings using the AI/ML API.\"\n    icon = \"AIML\"\n    name = \"AIMLEmbeddings\"\n\n    inputs = [\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            options=[\n                \"text-embedding-3-small\",\n                \"text-embedding-3-large\",\n                \"text-embedding-ada-002\",\n            ],\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"aiml_api_key\",\n            display_name=\"AI/ML API Key\",\n            value=\"AIML_API_KEY\",\n            required=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return AIMLEmbeddingsImpl(\n            api_key=self.aiml_api_key,\n            model=self.model_name,\n        )\n"},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model Name","dynamic":false,"external_options":{},"info":"","name":"model_name","options":["text-embedding-3-small","text-embedding-3-large","text-embedding-ada-002"],"options_metadata":[],"placeholder":"","required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"AIMLModel":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generates text using AI/ML API LLMs.","display_name":"AI/ML API","documentation":"https://docs.aimlapi.com/api-reference","edited":false,"field_order":["input_value","system_message","stream","max_tokens","model_kwargs","model_name","aiml_api_base","api_key","temperature"],"frozen":false,"icon":"AIML","legacy":false,"metadata":{"code_hash":"db72277a0d5a","dependencies":{"dependencies":[{"name":"langchain_openai","version":"0.3.23"},{"name":"pydantic","version":"2.10.6"},{"name":"typing_extensions","version":"4.15.0"},{"name":"lfx","version":null},{"name":"openai","version":"1.82.1"}],"total_dependencies":5},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.aiml.aiml.AIMLModelComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","aiml_api_base":{"_input_type":"StrInput","advanced":true,"display_name":"AI/ML API Base","dynamic":false,"info":"The base URL of the API. Defaults to https://api.aimlapi.com . You can change this to use other APIs like JinaChat, LocalAI and Prem.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"aiml_api_base","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"AI/ML API Key","dynamic":false,"info":"The AI/ML API Key to use for the OpenAI model.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"AIML_API_KEY"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\nfrom typing_extensions import override\n\nfrom lfx.base.models.aiml_constants import AimlModels\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.inputs.inputs import (\n    DictInput,\n    DropdownInput,\n    IntInput,\n    SecretStrInput,\n    SliderInput,\n    StrInput,\n)\n\n\nclass AIMLModelComponent(LCModelComponent):\n    display_name = \"AI/ML API\"\n    description = \"Generates text using AI/ML API LLMs.\"\n    icon = \"AIML\"\n    name = \"AIMLModel\"\n    documentation = \"https://docs.aimlapi.com/api-reference\"\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=[],\n            refresh_button=True,\n        ),\n        StrInput(\n            name=\"aiml_api_base\",\n            display_name=\"AI/ML API Base\",\n            advanced=True,\n            info=\"The base URL of the API. Defaults to https://api.aimlapi.com . \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"AI/ML API Key\",\n            info=\"The AI/ML API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"AIML_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\n        ),\n    ]\n\n    @override\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\n        if field_name in {\"api_key\", \"aiml_api_base\", \"model_name\"}:\n            aiml = AimlModels()\n            aiml.get_aiml_models()\n            build_config[\"model_name\"][\"options\"] = aiml.chat_models\n        return build_config\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        aiml_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        aiml_api_base = self.aiml_api_base or \"https://api.aimlapi.com/v2\"\n\n        openai_api_key = aiml_api_key.get_secret_value() if isinstance(aiml_api_key, SecretStr) else aiml_api_key\n\n        # TODO: Once OpenAI fixes their o1 models, this part will need to be removed\n        # to work correctly with o1 temperature settings.\n        if \"o1\" in model_name:\n            temperature = 1\n\n        return ChatOpenAI(\n            model=model_name,\n            temperature=temperature,\n            api_key=openai_api_key,\n            base_url=aiml_api_base,\n            max_tokens=max_tokens or None,\n            **model_kwargs,\n        )\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai.error import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.json_body.get(\"error\", {}).get(\"message\", \"\")\n            if message:\n                return message\n        return None\n"},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"max_tokens":{"_input_type":"IntInput","advanced":true,"display_name":"Max Tokens","dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","list":false,"list_add_label":"Add More","name":"max_tokens","placeholder":"","range_spec":{"max":128000.0,"min":0.0,"step":0.1,"step_type":"float"},"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"model_kwargs":{"_input_type":"DictInput","advanced":true,"display_name":"Model Kwargs","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"model_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model Name","dynamic":false,"external_options":{},"info":"","name":"model_name","options":[],"options_metadata":[],"placeholder":"","refresh_button":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"SliderInput","advanced":false,"display_name":"Temperature","dynamic":false,"info":"","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"temperature","placeholder":"","range_spec":{"max":2.0,"min":0.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":0.1}},"tool_mode":false}}],["amazon",{"AmazonBedrockConverseModel":{"base_classes":["LanguageModel","Message"],"beta":true,"conditional_paths":[],"custom_fields":{},"description":"Generate text using Amazon Bedrock LLMs with the modern Converse API for improved conversation handling.","display_name":"Amazon Bedrock Converse","documentation":"","edited":false,"field_order":["input_value","system_message","stream","model_id","aws_access_key_id","aws_secret_access_key","aws_session_token","credentials_profile_name","region_name","endpoint_url","temperature","max_tokens","top_p","top_k","disable_streaming","additional_model_fields"],"frozen":false,"icon":"Amazon","legacy":false,"metadata":{"code_hash":"58fa3fe56b23","dependencies":{"dependencies":[{"name":"langflow","version":null},{"name":"lfx","version":null},{"name":"langchain_aws","version":"0.2.33"}],"total_dependencies":3},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.amazon.amazon_bedrock_converse.AmazonBedrockConverseComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","additional_model_fields":{"_input_type":"DictInput","advanced":true,"display_name":"Additional Model Fields","dynamic":false,"info":"Additional model-specific parameters for fine-tuning behavior.","list":true,"list_add_label":"Add More","name":"additional_model_fields","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"aws_access_key_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"AWS Access Key ID","dynamic":false,"info":"The access key for your AWS account. Usually set in Python code as the environment variable 'AWS_ACCESS_KEY_ID'.","input_types":[],"load_from_db":true,"name":"aws_access_key_id","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"AWS_ACCESS_KEY_ID"},"aws_secret_access_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"AWS Secret Access Key","dynamic":false,"info":"The secret key for your AWS account. Usually set in Python code as the environment variable 'AWS_SECRET_ACCESS_KEY'.","input_types":[],"load_from_db":true,"name":"aws_secret_access_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"AWS_SECRET_ACCESS_KEY"},"aws_session_token":{"_input_type":"SecretStrInput","advanced":true,"display_name":"AWS Session Token","dynamic":false,"info":"The session key for your AWS account. Only needed for temporary credentials. Usually set in Python code as the environment variable 'AWS_SESSION_TOKEN'.","input_types":[],"load_from_db":false,"name":"aws_session_token","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langflow.field_typing import LanguageModel\nfrom langflow.inputs.inputs import BoolInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\nfrom langflow.io import DictInput, DropdownInput\n\nfrom lfx.base.models.aws_constants import AWS_REGIONS, AWS_MODEL_IDs\nfrom lfx.base.models.model import LCModelComponent\n\n\nclass AmazonBedrockConverseComponent(LCModelComponent):\n    display_name: str = \"Amazon Bedrock Converse\"\n    description: str = (\n        \"Generate text using Amazon Bedrock LLMs with the modern Converse API for improved conversation handling.\"\n    )\n    icon = \"Amazon\"\n    name = \"AmazonBedrockConverseModel\"\n    beta = True\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        DropdownInput(\n            name=\"model_id\",\n            display_name=\"Model ID\",\n            options=AWS_MODEL_IDs,\n            value=\"anthropic.claude-3-5-sonnet-20241022-v2:0\",\n            info=\"List of available model IDs to choose from.\",\n        ),\n        SecretStrInput(\n            name=\"aws_access_key_id\",\n            display_name=\"AWS Access Key ID\",\n            info=\"The access key for your AWS account. \"\n            \"Usually set in Python code as the environment variable 'AWS_ACCESS_KEY_ID'.\",\n            value=\"AWS_ACCESS_KEY_ID\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"aws_secret_access_key\",\n            display_name=\"AWS Secret Access Key\",\n            info=\"The secret key for your AWS account. \"\n            \"Usually set in Python code as the environment variable 'AWS_SECRET_ACCESS_KEY'.\",\n            value=\"AWS_SECRET_ACCESS_KEY\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"aws_session_token\",\n            display_name=\"AWS Session Token\",\n            advanced=True,\n            info=\"The session key for your AWS account. \"\n            \"Only needed for temporary credentials. \"\n            \"Usually set in Python code as the environment variable 'AWS_SESSION_TOKEN'.\",\n            load_from_db=False,\n        ),\n        SecretStrInput(\n            name=\"credentials_profile_name\",\n            display_name=\"Credentials Profile Name\",\n            advanced=True,\n            info=\"The name of the profile to use from your \"\n            \"~/.aws/credentials file. \"\n            \"If not provided, the default profile will be used.\",\n            load_from_db=False,\n        ),\n        DropdownInput(\n            name=\"region_name\",\n            display_name=\"Region Name\",\n            value=\"us-east-1\",\n            options=AWS_REGIONS,\n            info=\"The AWS region where your Bedrock resources are located.\",\n        ),\n        MessageTextInput(\n            name=\"endpoint_url\",\n            display_name=\"Endpoint URL\",\n            advanced=True,\n            info=\"The URL of the Bedrock endpoint to use.\",\n        ),\n        # Model-specific parameters for fine control\n        FloatInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.7,\n            info=\"Controls randomness in output. Higher values make output more random.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            value=4096,\n            info=\"Maximum number of tokens to generate.\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            value=0.9,\n            info=\"Nucleus sampling parameter. Controls diversity of output.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            value=250,\n            info=\"Limits the number of highest probability vocabulary tokens to consider. \"\n            \"Note: Not all models support top_k. Use 'Additional Model Fields' for manual configuration if needed.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"disable_streaming\",\n            display_name=\"Disable Streaming\",\n            value=False,\n            info=\"If True, disables streaming responses. Useful for batch processing.\",\n            advanced=True,\n        ),\n        DictInput(\n            name=\"additional_model_fields\",\n            display_name=\"Additional Model Fields\",\n            advanced=True,\n            is_list=True,\n            info=\"Additional model-specific parameters for fine-tuning behavior.\",\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_aws.chat_models.bedrock_converse import ChatBedrockConverse\n        except ImportError as e:\n            msg = \"langchain_aws is not installed. Please install it with `pip install langchain_aws`.\"\n            raise ImportError(msg) from e\n\n        # Prepare initialization parameters\n        init_params = {\n            \"model\": self.model_id,\n            \"region_name\": self.region_name,\n        }\n\n        # Add AWS credentials if provided\n        if self.aws_access_key_id:\n            init_params[\"aws_access_key_id\"] = self.aws_access_key_id\n        if self.aws_secret_access_key:\n            init_params[\"aws_secret_access_key\"] = self.aws_secret_access_key\n        if self.aws_session_token:\n            init_params[\"aws_session_token\"] = self.aws_session_token\n        if self.credentials_profile_name:\n            init_params[\"credentials_profile_name\"] = self.credentials_profile_name\n        if self.endpoint_url:\n            init_params[\"endpoint_url\"] = self.endpoint_url\n\n        # Add model parameters directly as supported by ChatBedrockConverse\n        if hasattr(self, \"temperature\") and self.temperature is not None:\n            init_params[\"temperature\"] = self.temperature\n        if hasattr(self, \"max_tokens\") and self.max_tokens is not None:\n            init_params[\"max_tokens\"] = self.max_tokens\n        if hasattr(self, \"top_p\") and self.top_p is not None:\n            init_params[\"top_p\"] = self.top_p\n\n        # Handle streaming - only disable if explicitly requested\n        if hasattr(self, \"disable_streaming\") and self.disable_streaming:\n            init_params[\"disable_streaming\"] = True\n\n        # Handle additional model request fields carefully\n        # Based on the error, inferenceConfig should not be passed as additional fields for some models\n        additional_model_request_fields = {}\n\n        # Only add top_k if user explicitly provided additional fields or if needed for specific models\n        if hasattr(self, \"additional_model_fields\") and self.additional_model_fields:\n            for field in self.additional_model_fields:\n                if isinstance(field, dict):\n                    additional_model_request_fields.update(field)\n\n        # For now, don't automatically add inferenceConfig for top_k to avoid validation errors\n        # Users can manually add it via additional_model_fields if their model supports it\n\n        # Only add if we have actual additional fields\n        if additional_model_request_fields:\n            init_params[\"additional_model_request_fields\"] = additional_model_request_fields\n\n        try:\n            output = ChatBedrockConverse(**init_params)\n        except Exception as e:\n            # Provide helpful error message with fallback suggestions\n            error_details = str(e)\n            if \"validation error\" in error_details.lower():\n                msg = (\n                    f\"ChatBedrockConverse validation error: {error_details}. \"\n                    f\"This may be due to incompatible parameters for model '{self.model_id}'. \"\n                    f\"Consider adjusting the model parameters or trying the legacy Amazon Bedrock component.\"\n                )\n            elif \"converse api\" in error_details.lower():\n                msg = (\n                    f\"Converse API error: {error_details}. \"\n                    f\"The model '{self.model_id}' may not support the Converse API. \"\n                    f\"Try using the legacy Amazon Bedrock component instead.\"\n                )\n            else:\n                msg = f\"Could not initialize ChatBedrockConverse: {error_details}\"\n            raise ValueError(msg) from e\n\n        return output\n"},"credentials_profile_name":{"_input_type":"SecretStrInput","advanced":true,"display_name":"Credentials Profile Name","dynamic":false,"info":"The name of the profile to use from your ~/.aws/credentials file. If not provided, the default profile will be used.","input_types":[],"load_from_db":false,"name":"credentials_profile_name","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"disable_streaming":{"_input_type":"BoolInput","advanced":true,"display_name":"Disable Streaming","dynamic":false,"info":"If True, disables streaming responses. Useful for batch processing.","list":false,"list_add_label":"Add More","name":"disable_streaming","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"endpoint_url":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Endpoint URL","dynamic":false,"info":"The URL of the Bedrock endpoint to use.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"endpoint_url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"max_tokens":{"_input_type":"IntInput","advanced":true,"display_name":"Max Tokens","dynamic":false,"info":"Maximum number of tokens to generate.","list":false,"list_add_label":"Add More","name":"max_tokens","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4096},"model_id":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model ID","dynamic":false,"external_options":{},"info":"List of available model IDs to choose from.","name":"model_id","options":["amazon.titan-text-express-v1","amazon.titan-text-lite-v1","amazon.titan-text-premier-v1:0","anthropic.claude-v2","anthropic.claude-v2:1","anthropic.claude-3-sonnet-20240229-v1:0","anthropic.claude-3-5-sonnet-20240620-v1:0","anthropic.claude-3-5-sonnet-20241022-v2:0","anthropic.claude-3-haiku-20240307-v1:0","anthropic.claude-3-5-haiku-20241022-v1:0","anthropic.claude-3-opus-20240229-v1:0","anthropic.claude-instant-v1","ai21.jamba-instruct-v1:0","ai21.j2-mid-v1","ai21.j2-ultra-v1","ai21.jamba-1-5-large-v1:0","ai21.jamba-1-5-mini-v1:0","cohere.command-text-v14","cohere.command-light-text-v14","cohere.command-r-v1:0","cohere.command-r-plus-v1:0","meta.llama2-13b-chat-v1","meta.llama2-70b-chat-v1","meta.llama3-8b-instruct-v1:0","meta.llama3-70b-instruct-v1:0","meta.llama3-1-8b-instruct-v1:0","meta.llama3-1-70b-instruct-v1:0","meta.llama3-1-405b-instruct-v1:0","meta.llama3-2-1b-instruct-v1:0","meta.llama3-2-3b-instruct-v1:0","meta.llama3-2-11b-instruct-v1:0","meta.llama3-2-90b-instruct-v1:0","mistral.mistral-7b-instruct-v0:2","mistral.mixtral-8x7b-instruct-v0:1","mistral.mistral-large-2402-v1:0","mistral.mistral-large-2407-v1:0","mistral.mistral-small-2402-v1:0"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"anthropic.claude-3-5-sonnet-20241022-v2:0"},"region_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Region Name","dynamic":false,"external_options":{},"info":"The AWS region where your Bedrock resources are located.","name":"region_name","options":["us-west-2","us-west-1","us-gov-west-1","us-gov-east-1","us-east-2","us-east-1","sa-east-1","me-south-1","me-central-1","il-central-1","eu-west-3","eu-west-2","eu-west-1","eu-south-2","eu-south-1","eu-north-1","eu-central-2","eu-central-1","cn-northwest-1","cn-north-1","ca-west-1","ca-central-1","ap-southeast-5","ap-southeast-4","ap-southeast-3","ap-southeast-2","ap-southeast-1","ap-south-2","ap-south-1","ap-northeast-3","ap-northeast-2","ap-northeast-1","ap-east-1","af-south-1"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"us-east-1"},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"FloatInput","advanced":true,"display_name":"Temperature","dynamic":false,"info":"Controls randomness in output. Higher values make output more random.","list":false,"list_add_label":"Add More","name":"temperature","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.7},"top_k":{"_input_type":"IntInput","advanced":true,"display_name":"Top K","dynamic":false,"info":"Limits the number of highest probability vocabulary tokens to consider. Note: Not all models support top_k. Use 'Additional Model Fields' for manual configuration if needed.","list":false,"list_add_label":"Add More","name":"top_k","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":250},"top_p":{"_input_type":"FloatInput","advanced":true,"display_name":"Top P","dynamic":false,"info":"Nucleus sampling parameter. Controls diversity of output.","list":false,"list_add_label":"Add More","name":"top_p","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.9}},"tool_mode":false},"AmazonBedrockEmbeddings":{"base_classes":["Embeddings"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate embeddings using Amazon Bedrock models.","display_name":"Amazon Bedrock Embeddings","documentation":"","edited":false,"field_order":["model_id","aws_access_key_id","aws_secret_access_key","aws_session_token","credentials_profile_name","region_name","endpoint_url"],"frozen":false,"icon":"Amazon","legacy":false,"metadata":{"code_hash":"70d039ff79f0","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"langchain_aws","version":"0.2.33"},{"name":"boto3","version":"1.40.52"}],"total_dependencies":3},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.amazon.amazon_bedrock_embedding.AmazonBedrockEmbeddingsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Embeddings","group_outputs":false,"method":"build_embeddings","name":"embeddings","selected":"Embeddings","tool_mode":true,"types":["Embeddings"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","aws_access_key_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"AWS Access Key ID","dynamic":false,"info":"The access key for your AWS account.Usually set in Python code as the environment variable 'AWS_ACCESS_KEY_ID'.","input_types":[],"load_from_db":true,"name":"aws_access_key_id","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"AWS_ACCESS_KEY_ID"},"aws_secret_access_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"AWS Secret Access Key","dynamic":false,"info":"The secret key for your AWS account. Usually set in Python code as the environment variable 'AWS_SECRET_ACCESS_KEY'.","input_types":[],"load_from_db":true,"name":"aws_secret_access_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"AWS_SECRET_ACCESS_KEY"},"aws_session_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"AWS Session Token","dynamic":false,"info":"The session key for your AWS account. Only needed for temporary credentials. Usually set in Python code as the environment variable 'AWS_SESSION_TOKEN'.","input_types":[],"load_from_db":true,"name":"aws_session_token","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":"AWS_SESSION_TOKEN"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.models.aws_constants import AWS_EMBEDDING_MODEL_IDS, AWS_REGIONS\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import Embeddings\nfrom lfx.inputs.inputs import SecretStrInput\nfrom lfx.io import DropdownInput, MessageTextInput, Output\n\n\nclass AmazonBedrockEmbeddingsComponent(LCModelComponent):\n    display_name: str = \"Amazon Bedrock Embeddings\"\n    description: str = \"Generate embeddings using Amazon Bedrock models.\"\n    icon = \"Amazon\"\n    name = \"AmazonBedrockEmbeddings\"\n\n    inputs = [\n        DropdownInput(\n            name=\"model_id\",\n            display_name=\"Model Id\",\n            options=AWS_EMBEDDING_MODEL_IDS,\n            value=\"amazon.titan-embed-text-v1\",\n        ),\n        SecretStrInput(\n            name=\"aws_access_key_id\",\n            display_name=\"AWS Access Key ID\",\n            info=\"The access key for your AWS account.\"\n            \"Usually set in Python code as the environment variable 'AWS_ACCESS_KEY_ID'.\",\n            value=\"AWS_ACCESS_KEY_ID\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"aws_secret_access_key\",\n            display_name=\"AWS Secret Access Key\",\n            info=\"The secret key for your AWS account. \"\n            \"Usually set in Python code as the environment variable 'AWS_SECRET_ACCESS_KEY'.\",\n            value=\"AWS_SECRET_ACCESS_KEY\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"aws_session_token\",\n            display_name=\"AWS Session Token\",\n            advanced=False,\n            info=\"The session key for your AWS account. \"\n            \"Only needed for temporary credentials. \"\n            \"Usually set in Python code as the environment variable 'AWS_SESSION_TOKEN'.\",\n            value=\"AWS_SESSION_TOKEN\",\n        ),\n        SecretStrInput(\n            name=\"credentials_profile_name\",\n            display_name=\"Credentials Profile Name\",\n            advanced=True,\n            info=\"The name of the profile to use from your \"\n            \"~/.aws/credentials file. \"\n            \"If not provided, the default profile will be used.\",\n            value=\"AWS_CREDENTIALS_PROFILE_NAME\",\n        ),\n        DropdownInput(\n            name=\"region_name\",\n            display_name=\"Region Name\",\n            value=\"us-east-1\",\n            options=AWS_REGIONS,\n            info=\"The AWS region where your Bedrock resources are located.\",\n        ),\n        MessageTextInput(\n            name=\"endpoint_url\",\n            display_name=\"Endpoint URL\",\n            advanced=True,\n            info=\"The URL of the AWS Bedrock endpoint to use.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        try:\n            from langchain_aws import BedrockEmbeddings\n        except ImportError as e:\n            msg = \"langchain_aws is not installed. Please install it with `pip install langchain_aws`.\"\n            raise ImportError(msg) from e\n        try:\n            import boto3\n        except ImportError as e:\n            msg = \"boto3 is not installed. Please install it with `pip install boto3`.\"\n            raise ImportError(msg) from e\n        if self.aws_access_key_id or self.aws_secret_access_key:\n            session = boto3.Session(\n                aws_access_key_id=self.aws_access_key_id,\n                aws_secret_access_key=self.aws_secret_access_key,\n                aws_session_token=self.aws_session_token,\n            )\n        elif self.credentials_profile_name:\n            session = boto3.Session(profile_name=self.credentials_profile_name)\n        else:\n            session = boto3.Session()\n\n        client_params = {}\n        if self.endpoint_url:\n            client_params[\"endpoint_url\"] = self.endpoint_url\n        if self.region_name:\n            client_params[\"region_name\"] = self.region_name\n\n        boto3_client = session.client(\"bedrock-runtime\", **client_params)\n        return BedrockEmbeddings(\n            credentials_profile_name=self.credentials_profile_name,\n            client=boto3_client,\n            model_id=self.model_id,\n            endpoint_url=self.endpoint_url,\n            region_name=self.region_name,\n        )\n"},"credentials_profile_name":{"_input_type":"SecretStrInput","advanced":true,"display_name":"Credentials Profile Name","dynamic":false,"info":"The name of the profile to use from your ~/.aws/credentials file. If not provided, the default profile will be used.","input_types":[],"load_from_db":true,"name":"credentials_profile_name","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":"AWS_CREDENTIALS_PROFILE_NAME"},"endpoint_url":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Endpoint URL","dynamic":false,"info":"The URL of the AWS Bedrock endpoint to use.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"endpoint_url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"model_id":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model Id","dynamic":false,"external_options":{},"info":"","name":"model_id","options":["amazon.titan-embed-text-v1","amazon.titan-embed-text-v2:0","cohere.embed-english-v3","cohere.embed-multilingual-v3"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"amazon.titan-embed-text-v1"},"region_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Region Name","dynamic":false,"external_options":{},"info":"The AWS region where your Bedrock resources are located.","name":"region_name","options":["us-west-2","us-west-1","us-gov-west-1","us-gov-east-1","us-east-2","us-east-1","sa-east-1","me-south-1","me-central-1","il-central-1","eu-west-3","eu-west-2","eu-west-1","eu-south-2","eu-south-1","eu-north-1","eu-central-2","eu-central-1","cn-northwest-1","cn-north-1","ca-west-1","ca-central-1","ap-southeast-5","ap-southeast-4","ap-southeast-3","ap-southeast-2","ap-southeast-1","ap-south-2","ap-south-1","ap-northeast-3","ap-northeast-2","ap-northeast-1","ap-east-1","af-south-1"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"us-east-1"}},"tool_mode":false},"AmazonBedrockModel":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate text using Amazon Bedrock LLMs with the legacy ChatBedrock API. This component is deprecated. Please use Amazon Bedrock Converse instead for better compatibility, newer features, and improved conversation handling.","display_name":"Amazon Bedrock","documentation":"","edited":false,"field_order":["input_value","system_message","stream","model_id","aws_access_key_id","aws_secret_access_key","aws_session_token","credentials_profile_name","region_name","model_kwargs","endpoint_url"],"frozen":false,"icon":"Amazon","legacy":true,"metadata":{"code_hash":"922093a831b6","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"langchain_aws","version":"0.2.33"},{"name":"boto3","version":"1.40.52"}],"total_dependencies":3},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.amazon.amazon_bedrock_model.AmazonBedrockComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":[],"template":{"_type":"Component","aws_access_key_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"AWS Access Key ID","dynamic":false,"info":"The access key for your AWS account.Usually set in Python code as the environment variable 'AWS_ACCESS_KEY_ID'.","input_types":[],"load_from_db":true,"name":"aws_access_key_id","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"AWS_ACCESS_KEY_ID"},"aws_secret_access_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"AWS Secret Access Key","dynamic":false,"info":"The secret key for your AWS account. Usually set in Python code as the environment variable 'AWS_SECRET_ACCESS_KEY'.","input_types":[],"load_from_db":true,"name":"aws_secret_access_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"AWS_SECRET_ACCESS_KEY"},"aws_session_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"AWS Session Token","dynamic":false,"info":"The session key for your AWS account. Only needed for temporary credentials. Usually set in Python code as the environment variable 'AWS_SESSION_TOKEN'.","input_types":[],"load_from_db":false,"name":"aws_session_token","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.models.aws_constants import AWS_REGIONS, AWS_MODEL_IDs\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import LanguageModel\nfrom lfx.inputs.inputs import MessageTextInput, SecretStrInput\nfrom lfx.io import DictInput, DropdownInput\n\n\nclass AmazonBedrockComponent(LCModelComponent):\n    display_name: str = \"Amazon Bedrock\"\n    description: str = (\n        \"Generate text using Amazon Bedrock LLMs with the legacy ChatBedrock API. \"\n        \"This component is deprecated. Please use Amazon Bedrock Converse instead \"\n        \"for better compatibility, newer features, and improved conversation handling.\"\n    )\n    icon = \"Amazon\"\n    name = \"AmazonBedrockModel\"\n    legacy = True\n    replacement = \"amazon.AmazonBedrockConverseModel\"\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        DropdownInput(\n            name=\"model_id\",\n            display_name=\"Model ID\",\n            options=AWS_MODEL_IDs,\n            value=\"anthropic.claude-3-haiku-20240307-v1:0\",\n            info=\"List of available model IDs to choose from.\",\n        ),\n        SecretStrInput(\n            name=\"aws_access_key_id\",\n            display_name=\"AWS Access Key ID\",\n            info=\"The access key for your AWS account.\"\n            \"Usually set in Python code as the environment variable 'AWS_ACCESS_KEY_ID'.\",\n            value=\"AWS_ACCESS_KEY_ID\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"aws_secret_access_key\",\n            display_name=\"AWS Secret Access Key\",\n            info=\"The secret key for your AWS account. \"\n            \"Usually set in Python code as the environment variable 'AWS_SECRET_ACCESS_KEY'.\",\n            value=\"AWS_SECRET_ACCESS_KEY\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"aws_session_token\",\n            display_name=\"AWS Session Token\",\n            advanced=False,\n            info=\"The session key for your AWS account. \"\n            \"Only needed for temporary credentials. \"\n            \"Usually set in Python code as the environment variable 'AWS_SESSION_TOKEN'.\",\n            load_from_db=False,\n        ),\n        SecretStrInput(\n            name=\"credentials_profile_name\",\n            display_name=\"Credentials Profile Name\",\n            advanced=True,\n            info=\"The name of the profile to use from your \"\n            \"~/.aws/credentials file. \"\n            \"If not provided, the default profile will be used.\",\n            load_from_db=False,\n        ),\n        DropdownInput(\n            name=\"region_name\",\n            display_name=\"Region Name\",\n            value=\"us-east-1\",\n            options=AWS_REGIONS,\n            info=\"The AWS region where your Bedrock resources are located.\",\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            is_list=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        MessageTextInput(\n            name=\"endpoint_url\",\n            display_name=\"Endpoint URL\",\n            advanced=True,\n            info=\"The URL of the Bedrock endpoint to use.\",\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_aws import ChatBedrock\n        except ImportError as e:\n            msg = \"langchain_aws is not installed. Please install it with `pip install langchain_aws`.\"\n            raise ImportError(msg) from e\n        try:\n            import boto3\n        except ImportError as e:\n            msg = \"boto3 is not installed. Please install it with `pip install boto3`.\"\n            raise ImportError(msg) from e\n        if self.aws_access_key_id or self.aws_secret_access_key:\n            try:\n                session = boto3.Session(\n                    aws_access_key_id=self.aws_access_key_id,\n                    aws_secret_access_key=self.aws_secret_access_key,\n                    aws_session_token=self.aws_session_token,\n                )\n            except Exception as e:\n                msg = \"Could not create a boto3 session.\"\n                raise ValueError(msg) from e\n        elif self.credentials_profile_name:\n            session = boto3.Session(profile_name=self.credentials_profile_name)\n        else:\n            session = boto3.Session()\n\n        client_params = {}\n        if self.endpoint_url:\n            client_params[\"endpoint_url\"] = self.endpoint_url\n        if self.region_name:\n            client_params[\"region_name\"] = self.region_name\n\n        boto3_client = session.client(\"bedrock-runtime\", **client_params)\n        try:\n            output = ChatBedrock(\n                client=boto3_client,\n                model_id=self.model_id,\n                region_name=self.region_name,\n                model_kwargs=self.model_kwargs,\n                endpoint_url=self.endpoint_url,\n                streaming=self.stream,\n            )\n        except Exception as e:\n            msg = \"Could not connect to AmazonBedrock API.\"\n            raise ValueError(msg) from e\n        return output\n"},"credentials_profile_name":{"_input_type":"SecretStrInput","advanced":true,"display_name":"Credentials Profile Name","dynamic":false,"info":"The name of the profile to use from your ~/.aws/credentials file. If not provided, the default profile will be used.","input_types":[],"load_from_db":false,"name":"credentials_profile_name","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"endpoint_url":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Endpoint URL","dynamic":false,"info":"The URL of the Bedrock endpoint to use.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"endpoint_url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"model_id":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model ID","dynamic":false,"external_options":{},"info":"List of available model IDs to choose from.","name":"model_id","options":["amazon.titan-text-express-v1","amazon.titan-text-lite-v1","amazon.titan-text-premier-v1:0","anthropic.claude-v2","anthropic.claude-v2:1","anthropic.claude-3-sonnet-20240229-v1:0","anthropic.claude-3-5-sonnet-20240620-v1:0","anthropic.claude-3-5-sonnet-20241022-v2:0","anthropic.claude-3-haiku-20240307-v1:0","anthropic.claude-3-5-haiku-20241022-v1:0","anthropic.claude-3-opus-20240229-v1:0","anthropic.claude-instant-v1","ai21.jamba-instruct-v1:0","ai21.j2-mid-v1","ai21.j2-ultra-v1","ai21.jamba-1-5-large-v1:0","ai21.jamba-1-5-mini-v1:0","cohere.command-text-v14","cohere.command-light-text-v14","cohere.command-r-v1:0","cohere.command-r-plus-v1:0","meta.llama2-13b-chat-v1","meta.llama2-70b-chat-v1","meta.llama3-8b-instruct-v1:0","meta.llama3-70b-instruct-v1:0","meta.llama3-1-8b-instruct-v1:0","meta.llama3-1-70b-instruct-v1:0","meta.llama3-1-405b-instruct-v1:0","meta.llama3-2-1b-instruct-v1:0","meta.llama3-2-3b-instruct-v1:0","meta.llama3-2-11b-instruct-v1:0","meta.llama3-2-90b-instruct-v1:0","mistral.mistral-7b-instruct-v0:2","mistral.mixtral-8x7b-instruct-v0:1","mistral.mistral-large-2402-v1:0","mistral.mistral-large-2407-v1:0","mistral.mistral-small-2402-v1:0"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"anthropic.claude-3-haiku-20240307-v1:0"},"model_kwargs":{"_input_type":"DictInput","advanced":true,"display_name":"Model Kwargs","dynamic":false,"info":"Additional keyword arguments to pass to the model.","list":true,"list_add_label":"Add More","name":"model_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"region_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Region Name","dynamic":false,"external_options":{},"info":"The AWS region where your Bedrock resources are located.","name":"region_name","options":["us-west-2","us-west-1","us-gov-west-1","us-gov-east-1","us-east-2","us-east-1","sa-east-1","me-south-1","me-central-1","il-central-1","eu-west-3","eu-west-2","eu-west-1","eu-south-2","eu-south-1","eu-north-1","eu-central-2","eu-central-1","cn-northwest-1","cn-north-1","ca-west-1","ca-central-1","ap-southeast-5","ap-southeast-4","ap-southeast-3","ap-southeast-2","ap-southeast-1","ap-south-2","ap-south-1","ap-northeast-3","ap-northeast-2","ap-northeast-1","ap-east-1","af-south-1"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"us-east-1"},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"s3bucketuploader":{"base_classes":["NoneType"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Uploads files to S3 bucket.","display_name":"S3 Bucket Uploader","documentation":"","edited":false,"field_order":["aws_access_key_id","aws_secret_access_key","bucket_name","strategy","data_inputs","s3_prefix","strip_path"],"frozen":false,"icon":"Amazon","legacy":false,"metadata":{"code_hash":"6e4ba2dafc3c","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"boto3","version":"1.40.52"}],"total_dependencies":2},"module":"lfx.components.amazon.s3_bucket_uploader.S3BucketUploaderComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Writes to AWS Bucket","group_outputs":false,"method":"process_files","name":"data","selected":"NoneType","tool_mode":true,"types":["NoneType"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","aws_access_key_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"AWS Access Key ID","dynamic":false,"info":"AWS Access key ID.","input_types":[],"load_from_db":true,"name":"aws_access_key_id","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"aws_secret_access_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"AWS Secret Key","dynamic":false,"info":"AWS Secret Key.","input_types":[],"load_from_db":true,"name":"aws_secret_access_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"bucket_name":{"_input_type":"StrInput","advanced":false,"display_name":"Bucket Name","dynamic":false,"info":"Enter the name of the bucket.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"bucket_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from pathlib import Path\nfrom typing import Any\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import (\n    BoolInput,\n    DropdownInput,\n    HandleInput,\n    Output,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass S3BucketUploaderComponent(Component):\n    \"\"\"S3BucketUploaderComponent is a component responsible for uploading files to an S3 bucket.\n\n    It provides two strategies for file upload: \"By Data\" and \"By File Name\". The component\n    requires AWS credentials and bucket details as inputs and processes files accordingly.\n\n    Attributes:\n        display_name (str): The display name of the component.\n        description (str): A brief description of the components functionality.\n        icon (str): The icon representing the component.\n        name (str): The internal name of the component.\n        inputs (list): A list of input configurations required by the component.\n        outputs (list): A list of output configurations provided by the component.\n\n    Methods:\n        process_files() -> None:\n            Processes files based on the selected strategy. Calls the appropriate method\n            based on the strategy attribute.\n        process_files_by_data() -> None:\n            Processes and uploads files to an S3 bucket based on the data inputs. Iterates\n            over the data inputs, logs the file path and text content, and uploads each file\n            to the specified S3 bucket if both file path and text content are available.\n        process_files_by_name() -> None:\n            Processes and uploads files to an S3 bucket based on their names. Iterates through\n            the list of data inputs, retrieves the file path from each data item, and uploads\n            the file to the specified S3 bucket if the file path is available. Logs the file\n            path being uploaded.\n        _s3_client() -> Any:\n            Creates and returns an S3 client using the provided AWS access key ID and secret\n            access key.\n\n        Please note that this component requires the boto3 library to be installed. It is designed\n        to work with File and Director components as inputs\n    \"\"\"\n\n    display_name = \"S3 Bucket Uploader\"\n    description = \"Uploads files to S3 bucket.\"\n    icon = \"Amazon\"\n    name = \"s3bucketuploader\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"aws_access_key_id\",\n            display_name=\"AWS Access Key ID\",\n            required=True,\n            password=True,\n            info=\"AWS Access key ID.\",\n        ),\n        SecretStrInput(\n            name=\"aws_secret_access_key\",\n            display_name=\"AWS Secret Key\",\n            required=True,\n            password=True,\n            info=\"AWS Secret Key.\",\n        ),\n        StrInput(\n            name=\"bucket_name\",\n            display_name=\"Bucket Name\",\n            info=\"Enter the name of the bucket.\",\n            advanced=False,\n        ),\n        DropdownInput(\n            name=\"strategy\",\n            display_name=\"Strategy for file upload\",\n            options=[\"Store Data\", \"Store Original File\"],\n            value=\"By Data\",\n            info=(\n                \"Choose the strategy to upload the file. By Data means that the source file \"\n                \"is parsed and stored as LangFlow data. By File Name means that the source \"\n                \"file is uploaded as is.\"\n            ),\n        ),\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Data Inputs\",\n            info=\"The data to split.\",\n            input_types=[\"Data\"],\n            is_list=True,\n            required=True,\n        ),\n        StrInput(\n            name=\"s3_prefix\",\n            display_name=\"S3 Prefix\",\n            info=\"Prefix for all files.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"strip_path\",\n            display_name=\"Strip Path\",\n            info=\"Removes path from file path.\",\n            required=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Writes to AWS Bucket\", name=\"data\", method=\"process_files\"),\n    ]\n\n    def process_files(self) -> None:\n        \"\"\"Process files based on the selected strategy.\n\n        This method uses a strategy pattern to process files. The strategy is determined\n        by the `self.strategy` attribute, which can be either \"By Data\" or \"By File Name\".\n        Depending on the strategy, the corresponding method (`process_files_by_data` or\n        `process_files_by_name`) is called. If an invalid strategy is provided, an error\n        is logged.\n\n        Returns:\n            None\n        \"\"\"\n        strategy_methods = {\n            \"Store Data\": self.process_files_by_data,\n            \"Store Original File\": self.process_files_by_name,\n        }\n        strategy_methods.get(self.strategy, lambda: self.log(\"Invalid strategy\"))()\n\n    def process_files_by_data(self) -> None:\n        \"\"\"Processes and uploads files to an S3 bucket based on the data inputs.\n\n        This method iterates over the data inputs, logs the file path and text content,\n        and uploads each file to the specified S3 bucket if both file path and text content\n        are available.\n\n        Args:\n            None\n\n        Returns:\n            None\n        \"\"\"\n        for data_item in self.data_inputs:\n            file_path = data_item.data.get(\"file_path\")\n            text_content = data_item.data.get(\"text\")\n\n            if file_path and text_content:\n                self._s3_client().put_object(\n                    Bucket=self.bucket_name, Key=self._normalize_path(file_path), Body=text_content\n                )\n\n    def process_files_by_name(self) -> None:\n        \"\"\"Processes and uploads files to an S3 bucket based on their names.\n\n        Iterates through the list of data inputs, retrieves the file path from each data item,\n        and uploads the file to the specified S3 bucket if the file path is available.\n        Logs the file path being uploaded.\n\n        Returns:\n            None\n        \"\"\"\n        for data_item in self.data_inputs:\n            file_path = data_item.data.get(\"file_path\")\n            self.log(f\"Uploading file: {file_path}\")\n            if file_path:\n                self._s3_client().upload_file(file_path, Bucket=self.bucket_name, Key=self._normalize_path(file_path))\n\n    def _s3_client(self) -> Any:\n        \"\"\"Creates and returns an S3 client using the provided AWS access key ID and secret access key.\n\n        Returns:\n            Any: A boto3 S3 client instance.\n        \"\"\"\n        try:\n            import boto3\n        except ImportError as e:\n            msg = \"boto3 is not installed. Please install it using `uv pip install boto3`.\"\n            raise ImportError(msg) from e\n\n        return boto3.client(\n            \"s3\",\n            aws_access_key_id=self.aws_access_key_id,\n            aws_secret_access_key=self.aws_secret_access_key,\n        )\n\n    def _normalize_path(self, file_path) -> str:\n        \"\"\"Process the file path based on the s3_prefix and path_as_prefix.\n\n        Args:\n            file_path (str): The original file path.\n            s3_prefix (str): The S3 prefix to use.\n            path_as_prefix (bool): Whether to use the file path as the S3 prefix.\n\n        Returns:\n            str: The processed file path.\n        \"\"\"\n        prefix = self.s3_prefix\n        strip_path = self.strip_path\n        processed_path: str = file_path\n\n        if strip_path:\n            # Filename only\n            processed_path = Path(file_path).name\n\n        # Concatenate the s3_prefix if it exists\n        if prefix:\n            processed_path = str(Path(prefix) / processed_path)\n\n        return processed_path\n"},"data_inputs":{"_input_type":"HandleInput","advanced":false,"display_name":"Data Inputs","dynamic":false,"info":"The data to split.","input_types":["Data"],"list":true,"list_add_label":"Add More","name":"data_inputs","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"s3_prefix":{"_input_type":"StrInput","advanced":true,"display_name":"S3 Prefix","dynamic":false,"info":"Prefix for all files.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"s3_prefix","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"strategy":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Strategy for file upload","dynamic":false,"external_options":{},"info":"Choose the strategy to upload the file. By Data means that the source file is parsed and stored as LangFlow data. By File Name means that the source file is uploaded as is.","name":"strategy","options":["Store Data","Store Original File"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"By Data"},"strip_path":{"_input_type":"BoolInput","advanced":true,"display_name":"Strip Path","dynamic":false,"info":"Removes path from file path.","list":false,"list_add_label":"Add More","name":"strip_path","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false}}],["anthropic",{"AnthropicModel":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate text using Anthropic's Messages API and models.","display_name":"Anthropic","documentation":"","edited":false,"field_order":["input_value","system_message","stream","max_tokens","model_name","api_key","temperature","base_url","tool_model_enabled"],"frozen":false,"icon":"Anthropic","legacy":false,"metadata":{"code_hash":"7c894c5a66ba","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null},{"name":"langchain_anthropic","version":"0.3.14"},{"name":"anthropic","version":"0.69.0"}],"total_dependencies":5},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.anthropic.anthropic.AnthropicModelComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Anthropic API Key","dynamic":false,"info":"Your Anthropic API key.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str"},"base_url":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Anthropic API URL","dynamic":false,"info":"Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"https://api.anthropic.com"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any, cast\n\nimport requests\nfrom pydantic import ValidationError\n\nfrom lfx.base.models.anthropic_constants import (\n    ANTHROPIC_MODELS,\n    DEFAULT_ANTHROPIC_API_URL,\n    TOOL_CALLING_SUPPORTED_ANTHROPIC_MODELS,\n    TOOL_CALLING_UNSUPPORTED_ANTHROPIC_MODELS,\n)\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.io import BoolInput, DropdownInput, IntInput, MessageTextInput, SecretStrInput, SliderInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.dotdict import dotdict\n\n\nclass AnthropicModelComponent(LCModelComponent):\n    display_name = \"Anthropic\"\n    description = \"Generate text using Anthropic's Messages API and models.\"\n    icon = \"Anthropic\"\n    name = \"AnthropicModel\"\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            value=4096,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            options=ANTHROPIC_MODELS,\n            refresh_button=True,\n            value=ANTHROPIC_MODELS[0],\n            combobox=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Anthropic API Key\",\n            info=\"Your Anthropic API key.\",\n            value=None,\n            required=True,\n            real_time_refresh=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            info=\"Run inference with this temperature. Must by in the closed interval [0.0, 1.0].\",\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"base_url\",\n            display_name=\"Anthropic API URL\",\n            info=\"Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.\",\n            value=DEFAULT_ANTHROPIC_API_URL,\n            real_time_refresh=True,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tool_model_enabled\",\n            display_name=\"Enable Tool Models\",\n            info=(\n                \"Select if you want to use models that can work with tools. If yes, only those models will be shown.\"\n            ),\n            advanced=False,\n            value=False,\n            real_time_refresh=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_anthropic.chat_models import ChatAnthropic\n        except ImportError as e:\n            msg = \"langchain_anthropic is not installed. Please install it with `pip install langchain_anthropic`.\"\n            raise ImportError(msg) from e\n        try:\n            max_tokens_value = getattr(self, \"max_tokens\", \"\")\n            max_tokens_value = 4096 if max_tokens_value == \"\" else int(max_tokens_value)\n            output = ChatAnthropic(\n                model=self.model_name,\n                anthropic_api_key=self.api_key,\n                max_tokens=max_tokens_value,\n                temperature=self.temperature,\n                anthropic_api_url=self.base_url or DEFAULT_ANTHROPIC_API_URL,\n                streaming=self.stream,\n            )\n        except ValidationError:\n            raise\n        except Exception as e:\n            msg = \"Could not connect to Anthropic API.\"\n            raise ValueError(msg) from e\n\n        return output\n\n    def get_models(self, *, tool_model_enabled: bool | None = None) -> list[str]:\n        try:\n            import anthropic\n\n            client = anthropic.Anthropic(api_key=self.api_key)\n            models = client.models.list(limit=20).data\n            model_ids = ANTHROPIC_MODELS + [model.id for model in models]\n        except (ImportError, ValueError, requests.exceptions.RequestException) as e:\n            logger.exception(f\"Error getting model names: {e}\")\n            model_ids = ANTHROPIC_MODELS\n\n        if tool_model_enabled:\n            try:\n                from langchain_anthropic.chat_models import ChatAnthropic\n            except ImportError as e:\n                msg = \"langchain_anthropic is not installed. Please install it with `pip install langchain_anthropic`.\"\n                raise ImportError(msg) from e\n\n            # Create a new list instead of modifying while iterating\n            filtered_models = []\n            for model in model_ids:\n                if model in TOOL_CALLING_SUPPORTED_ANTHROPIC_MODELS:\n                    filtered_models.append(model)\n                    continue\n\n                model_with_tool = ChatAnthropic(\n                    model=model,  # Use the current model being checked\n                    anthropic_api_key=self.api_key,\n                    anthropic_api_url=cast(\"str\", self.base_url) or DEFAULT_ANTHROPIC_API_URL,\n                )\n\n                if (\n                    not self.supports_tool_calling(model_with_tool)\n                    or model in TOOL_CALLING_UNSUPPORTED_ANTHROPIC_MODELS\n                ):\n                    continue\n\n                filtered_models.append(model)\n\n            return filtered_models\n\n        return model_ids\n\n    def _get_exception_message(self, exception: Exception) -> str | None:\n        \"\"\"Get a message from an Anthropic exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from anthropic import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(exception, BadRequestError):\n            message = exception.body.get(\"error\", {}).get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if \"base_url\" in build_config and build_config[\"base_url\"][\"value\"] is None:\n            build_config[\"base_url\"][\"value\"] = DEFAULT_ANTHROPIC_API_URL\n            self.base_url = DEFAULT_ANTHROPIC_API_URL\n        if field_name in {\"base_url\", \"model_name\", \"tool_model_enabled\", \"api_key\"} and field_value:\n            try:\n                if len(self.api_key) == 0:\n                    ids = ANTHROPIC_MODELS\n                else:\n                    try:\n                        ids = self.get_models(tool_model_enabled=self.tool_model_enabled)\n                    except (ImportError, ValueError, requests.exceptions.RequestException) as e:\n                        logger.exception(f\"Error getting model names: {e}\")\n                        ids = ANTHROPIC_MODELS\n                build_config.setdefault(\"model_name\", {})\n                build_config[\"model_name\"][\"options\"] = ids\n                build_config[\"model_name\"].setdefault(\"value\", ids[0])\n                build_config[\"model_name\"][\"combobox\"] = True\n            except Exception as e:\n                msg = f\"Error getting model names: {e}\"\n                raise ValueError(msg) from e\n        return build_config\n"},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"max_tokens":{"_input_type":"IntInput","advanced":true,"display_name":"Max Tokens","dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","list":false,"list_add_label":"Add More","name":"max_tokens","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4096},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":true,"dialog_inputs":{},"display_name":"Model Name","dynamic":false,"external_options":{},"info":"","name":"model_name","options":["claude-sonnet-4-5-20250929","claude-opus-4-1-20250805","claude-opus-4-20250514","claude-sonnet-4-20250514","claude-3-7-sonnet-latest","claude-3-5-sonnet-latest","claude-3-5-haiku-latest","claude-3-opus-latest"],"options_metadata":[],"placeholder":"","refresh_button":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"claude-sonnet-4-5-20250929"},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"SliderInput","advanced":true,"display_name":"Temperature","dynamic":false,"info":"Run inference with this temperature. Must by in the closed interval [0.0, 1.0].","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"temperature","placeholder":"","range_spec":{"max":1.0,"min":0.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":0.1},"tool_model_enabled":{"_input_type":"BoolInput","advanced":false,"display_name":"Enable Tool Models","dynamic":false,"info":"Select if you want to use models that can work with tools. If yes, only those models will be shown.","list":false,"list_add_label":"Add More","name":"tool_model_enabled","placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false}}],["apify",{"ApifyActors":{"base_classes":["Data","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Use Apify Actors to extract data from hundreds of places fast. This component can be used in a flow to retrieve data or as a tool with an agent.","display_name":"Apify Actors","documentation":"http://docs.langflow.org/integrations-apify","edited":false,"field_order":["apify_token","actor_id","run_input","dataset_fields","flatten_dataset"],"frozen":false,"icon":"Apify","legacy":false,"metadata":{"code_hash":"3bc6aee68a53","dependencies":{"dependencies":[{"name":"apify_client","version":"1.12.2"},{"name":"langchain_community","version":"0.3.21"},{"name":"langchain_core","version":"0.3.79"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":5},"module":"lfx.components.apify.apify_actor.ApifyActorsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Output","group_outputs":false,"method":"run_model","name":"output","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","actor_id":{"_input_type":"StrInput","advanced":false,"display_name":"Actor","dynamic":false,"info":"Actor name from Apify store to run. For example 'apify/website-content-crawler' to use the Website Content Crawler Actor.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"actor_id","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"apify/website-content-crawler"},"apify_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Apify Token","dynamic":false,"info":"The API token for the Apify account.","input_types":[],"load_from_db":true,"name":"apify_token","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nimport string\nfrom typing import Any, cast\n\nfrom apify_client import ApifyClient\nfrom langchain_community.document_loaders.apify_dataset import ApifyDatasetLoader\nfrom langchain_core.tools import BaseTool\nfrom pydantic import BaseModel, Field, field_serializer\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.field_typing import Tool\nfrom lfx.inputs.inputs import BoolInput\nfrom lfx.io import MultilineInput, Output, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\nMAX_DESCRIPTION_LEN = 250\n\n\nclass ApifyActorsComponent(Component):\n    display_name = \"Apify Actors\"\n    description = (\n        \"Use Apify Actors to extract data from hundreds of places fast. \"\n        \"This component can be used in a flow to retrieve data or as a tool with an agent.\"\n    )\n    documentation: str = \"http://docs.langflow.org/integrations-apify\"\n    icon = \"Apify\"\n    name = \"ApifyActors\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"apify_token\",\n            display_name=\"Apify Token\",\n            info=\"The API token for the Apify account.\",\n            required=True,\n            password=True,\n        ),\n        StrInput(\n            name=\"actor_id\",\n            display_name=\"Actor\",\n            info=(\n                \"Actor name from Apify store to run. For example 'apify/website-content-crawler' \"\n                \"to use the Website Content Crawler Actor.\"\n            ),\n            value=\"apify/website-content-crawler\",\n            required=True,\n        ),\n        # multiline input is more pleasant to use than the nested dict input\n        MultilineInput(\n            name=\"run_input\",\n            display_name=\"Run input\",\n            info=(\n                'The JSON input for the Actor run. For example for the \"apify/website-content-crawler\" Actor: '\n                '{\"startUrls\":[{\"url\":\"https://docs.apify.com/academy/web-scraping-for-beginners\"}],\"maxCrawlDepth\":0}'\n            ),\n            value='{\"startUrls\":[{\"url\":\"https://docs.apify.com/academy/web-scraping-for-beginners\"}],\"maxCrawlDepth\":0}',\n            required=True,\n        ),\n        MultilineInput(\n            name=\"dataset_fields\",\n            display_name=\"Output fields\",\n            info=(\n                \"Fields to extract from the dataset, split by commas. \"\n                \"Other fields will be ignored. Dots in nested structures will be replaced by underscores. \"\n                \"Sample input: 'text, metadata.title'. \"\n                \"Sample output: {'text': 'page content here', 'metadata_title': 'page title here'}. \"\n                \"For example, for the 'apify/website-content-crawler' Actor, you can extract the 'markdown' field, \"\n                \"which is the content of the website in markdown format.\"\n            ),\n        ),\n        BoolInput(\n            name=\"flatten_dataset\",\n            display_name=\"Flatten output\",\n            info=(\n                \"The output dataset will be converted from a nested format to a flat structure. \"\n                \"Dots in nested structure will be replaced by underscores. \"\n                \"This is useful for further processing of the Data object. \"\n                \"For example, {'a': {'b': 1}} will be flattened to {'a_b': 1}.\"\n            ),\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", type_=list[Data], method=\"run_model\"),\n        Output(display_name=\"Tool\", name=\"tool\", type_=Tool, method=\"build_tool\"),\n    ]\n\n    def __init__(self, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n        self._apify_client: ApifyClient | None = None\n\n    def run_model(self) -> list[Data]:\n        \"\"\"Run the Actor and return node output.\"\"\"\n        input_ = json.loads(self.run_input)\n        fields = ApifyActorsComponent.parse_dataset_fields(self.dataset_fields) if self.dataset_fields else None\n        res = self._run_actor(self.actor_id, input_, fields=fields)\n        if self.flatten_dataset:\n            res = [ApifyActorsComponent.flatten(item) for item in res]\n        data = [Data(data=item) for item in res]\n\n        self.status = data\n        return data\n\n    def build_tool(self) -> Tool:\n        \"\"\"Build a tool for an agent that runs the Apify Actor.\"\"\"\n        actor_id = self.actor_id\n\n        build = self._get_actor_latest_build(actor_id)\n        readme = build.get(\"readme\", \"\")[:250] + \"...\"\n        if not (input_schema_str := build.get(\"inputSchema\")):\n            msg = \"Input schema not found\"\n            raise ValueError(msg)\n        input_schema = json.loads(input_schema_str)\n        properties, required = ApifyActorsComponent.get_actor_input_schema_from_build(input_schema)\n        properties = {\"run_input\": properties}\n\n        # works from input schema\n        info_ = [\n            (\n                \"JSON encoded as a string with input schema (STRICTLY FOLLOW JSON FORMAT AND SCHEMA):\\n\\n\"\n                f\"{json.dumps(properties, separators=(',', ':'))}\"\n            )\n        ]\n        if required:\n            info_.append(\"\\n\\nRequired fields:\\n\" + \"\\n\".join(required))\n\n        info = \"\".join(info_)\n\n        input_model_cls = ApifyActorsComponent.create_input_model_class(info)\n        tool_cls = ApifyActorsComponent.create_tool_class(self, readme, input_model_cls, actor_id)\n\n        return cast(\"Tool\", tool_cls())\n\n    @staticmethod\n    def create_tool_class(\n        parent: \"ApifyActorsComponent\", readme: str, input_model: type[BaseModel], actor_id: str\n    ) -> type[BaseTool]:\n        \"\"\"Create a tool class that runs an Apify Actor.\"\"\"\n\n        class ApifyActorRun(BaseTool):\n            \"\"\"Tool that runs Apify Actors.\"\"\"\n\n            name: str = f\"apify_actor_{ApifyActorsComponent.actor_id_to_tool_name(actor_id)}\"\n            description: str = (\n                \"Run an Apify Actor with the given input. \"\n                \"Here is a part of the currently loaded Actor README:\\n\\n\"\n                f\"{readme}\\n\\n\"\n            )\n\n            args_schema: type[BaseModel] = input_model\n\n            @field_serializer(\"args_schema\")\n            def serialize_args_schema(self, args_schema):\n                return args_schema.schema()\n\n            def _run(self, run_input: str | dict) -> str:\n                \"\"\"Use the Apify Actor.\"\"\"\n                input_dict = json.loads(run_input) if isinstance(run_input, str) else run_input\n\n                # retrieve if nested, just in case\n                input_dict = input_dict.get(\"run_input\", input_dict)\n\n                res = parent._run_actor(actor_id, input_dict)\n                return \"\\n\\n\".join([ApifyActorsComponent.dict_to_json_str(item) for item in res])\n\n        return ApifyActorRun\n\n    @staticmethod\n    def create_input_model_class(description: str) -> type[BaseModel]:\n        \"\"\"Create a Pydantic model class for the Actor input.\"\"\"\n\n        class ActorInput(BaseModel):\n            \"\"\"Input for the Apify Actor tool.\"\"\"\n\n            run_input: str = Field(..., description=description)\n\n        return ActorInput\n\n    def _get_apify_client(self) -> ApifyClient:\n        \"\"\"Get the Apify client.\n\n        Is created if not exists or token changes.\n        \"\"\"\n        if not self.apify_token:\n            msg = \"API token is required.\"\n            raise ValueError(msg)\n        # when token changes, create a new client\n        if self._apify_client is None or self._apify_client.token != self.apify_token:\n            self._apify_client = ApifyClient(self.apify_token)\n            if httpx_client := self._apify_client.http_client.httpx_client:\n                httpx_client.headers[\"user-agent\"] += \"; Origin/langflow\"\n        return self._apify_client\n\n    def _get_actor_latest_build(self, actor_id: str) -> dict:\n        \"\"\"Get the latest build of an Actor from the default build tag.\"\"\"\n        client = self._get_apify_client()\n        actor = client.actor(actor_id=actor_id)\n        if not (actor_info := actor.get()):\n            msg = f\"Actor {actor_id} not found.\"\n            raise ValueError(msg)\n\n        default_build_tag = actor_info.get(\"defaultRunOptions\", {}).get(\"build\")\n        latest_build_id = actor_info.get(\"taggedBuilds\", {}).get(default_build_tag, {}).get(\"buildId\")\n\n        if (build := client.build(latest_build_id).get()) is None:\n            msg = f\"Build {latest_build_id} not found.\"\n            raise ValueError(msg)\n\n        return build\n\n    @staticmethod\n    def get_actor_input_schema_from_build(input_schema: dict) -> tuple[dict, list[str]]:\n        \"\"\"Get the input schema from the Actor build.\n\n        Trim the description to 250 characters.\n        \"\"\"\n        properties = input_schema.get(\"properties\", {})\n        required = input_schema.get(\"required\", [])\n\n        properties_out: dict = {}\n        for item, meta in properties.items():\n            properties_out[item] = {}\n            if desc := meta.get(\"description\"):\n                properties_out[item][\"description\"] = (\n                    desc[:MAX_DESCRIPTION_LEN] + \"...\" if len(desc) > MAX_DESCRIPTION_LEN else desc\n                )\n            for key_name in (\"type\", \"default\", \"prefill\", \"enum\"):\n                if value := meta.get(key_name):\n                    properties_out[item][key_name] = value\n\n        return properties_out, required\n\n    def _get_run_dataset_id(self, run_id: str) -> str:\n        \"\"\"Get the dataset id from the run id.\"\"\"\n        client = self._get_apify_client()\n        run = client.run(run_id=run_id)\n        if (dataset := run.dataset().get()) is None:\n            msg = \"Dataset not found\"\n            raise ValueError(msg)\n        if (did := dataset.get(\"id\")) is None:\n            msg = \"Dataset id not found\"\n            raise ValueError(msg)\n        return did\n\n    @staticmethod\n    def dict_to_json_str(d: dict) -> str:\n        \"\"\"Convert a dictionary to a JSON string.\"\"\"\n        return json.dumps(d, separators=(\",\", \":\"), default=lambda _: \"<n/a>\")\n\n    @staticmethod\n    def actor_id_to_tool_name(actor_id: str) -> str:\n        \"\"\"Turn actor_id into a valid tool name.\n\n        Tool name must only contain letters, numbers, underscores, dashes,\n            and cannot contain spaces.\n        \"\"\"\n        valid_chars = string.ascii_letters + string.digits + \"_-\"\n        return \"\".join(char if char in valid_chars else \"_\" for char in actor_id)\n\n    def _run_actor(self, actor_id: str, run_input: dict, fields: list[str] | None = None) -> list[dict]:\n        \"\"\"Run an Apify Actor and return the output dataset.\n\n        Args:\n            actor_id: Actor name from Apify store to run.\n            run_input: JSON input for the Actor.\n            fields: List of fields to extract from the dataset. Other fields will be ignored.\n        \"\"\"\n        client = self._get_apify_client()\n        if (details := client.actor(actor_id=actor_id).call(run_input=run_input, wait_secs=1)) is None:\n            msg = \"Actor run details not found\"\n            raise ValueError(msg)\n        if (run_id := details.get(\"id\")) is None:\n            msg = \"Run id not found\"\n            raise ValueError(msg)\n\n        if (run_client := client.run(run_id)) is None:\n            msg = \"Run client not found\"\n            raise ValueError(msg)\n\n        # stream logs\n        with run_client.log().stream() as response:\n            if response:\n                for line in response.iter_lines():\n                    self.log(line)\n        run_client.wait_for_finish()\n\n        dataset_id = self._get_run_dataset_id(run_id)\n\n        loader = ApifyDatasetLoader(\n            dataset_id=dataset_id,\n            dataset_mapping_function=lambda item: item\n            if not fields\n            else {k.replace(\".\", \"_\"): ApifyActorsComponent.get_nested_value(item, k) for k in fields},\n        )\n        return loader.load()\n\n    @staticmethod\n    def get_nested_value(data: dict[str, Any], key: str) -> Any:\n        \"\"\"Get a nested value from a dictionary.\"\"\"\n        keys = key.split(\".\")\n        value = data\n        for k in keys:\n            if not isinstance(value, dict) or k not in value:\n                return None\n            value = value[k]\n        return value\n\n    @staticmethod\n    def parse_dataset_fields(dataset_fields: str) -> list[str]:\n        \"\"\"Convert a string of comma-separated fields into a list of fields.\"\"\"\n        dataset_fields = dataset_fields.replace(\"'\", \"\").replace('\"', \"\").replace(\"`\", \"\")\n        return [field.strip() for field in dataset_fields.split(\",\")]\n\n    @staticmethod\n    def flatten(d: dict) -> dict:\n        \"\"\"Flatten a nested dictionary.\"\"\"\n\n        def items():\n            for key, value in d.items():\n                if isinstance(value, dict):\n                    for subkey, subvalue in ApifyActorsComponent.flatten(value).items():\n                        yield key + \"_\" + subkey, subvalue\n                else:\n                    yield key, value\n\n        return dict(items())\n"},"dataset_fields":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Output fields","dynamic":false,"info":"Fields to extract from the dataset, split by commas. Other fields will be ignored. Dots in nested structures will be replaced by underscores. Sample input: 'text, metadata.title'. Sample output: {'text': 'page content here', 'metadata_title': 'page title here'}. For example, for the 'apify/website-content-crawler' Actor, you can extract the 'markdown' field, which is the content of the website in markdown format.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"dataset_fields","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"flatten_dataset":{"_input_type":"BoolInput","advanced":false,"display_name":"Flatten output","dynamic":false,"info":"The output dataset will be converted from a nested format to a flat structure. Dots in nested structure will be replaced by underscores. This is useful for further processing of the Data object. For example, {'a': {'b': 1}} will be flattened to {'a_b': 1}.","list":false,"list_add_label":"Add More","name":"flatten_dataset","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"run_input":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Run input","dynamic":false,"info":"The JSON input for the Actor run. For example for the \"apify/website-content-crawler\" Actor: {\"startUrls\":[{\"url\":\"https://docs.apify.com/academy/web-scraping-for-beginners\"}],\"maxCrawlDepth\":0}","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"run_input","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"{\"startUrls\":[{\"url\":\"https://docs.apify.com/academy/web-scraping-for-beginners\"}],\"maxCrawlDepth\":0}"}},"tool_mode":false}}],["arxiv",{"ArXivComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Search and retrieve papers from arXiv.org","display_name":"arXiv","documentation":"","edited":false,"field_order":["search_query","search_type","max_results"],"frozen":false,"icon":"arXiv","legacy":false,"metadata":{"code_hash":"219239ee2b48","dependencies":{"dependencies":[{"name":"defusedxml","version":"0.7.1"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.arxiv.arxiv.ArXivComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"search_papers_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import urllib.request\nfrom urllib.parse import urlparse\nfrom xml.etree.ElementTree import Element\n\nfrom defusedxml.ElementTree import fromstring\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import DropdownInput, IntInput, MessageTextInput, Output\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\n\n\nclass ArXivComponent(Component):\n    display_name = \"arXiv\"\n    description = \"Search and retrieve papers from arXiv.org\"\n    icon = \"arXiv\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n            info=\"The search query for arXiv papers (e.g., 'quantum computing')\",\n            tool_mode=True,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Field\",\n            info=\"The field to search in\",\n            options=[\"all\", \"title\", \"abstract\", \"author\", \"cat\"],  # cat is for category\n            value=\"all\",\n        ),\n        IntInput(\n            name=\"max_results\",\n            display_name=\"Max Results\",\n            info=\"Maximum number of results to return\",\n            value=10,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"search_papers_dataframe\"),\n    ]\n\n    def build_query_url(self) -> str:\n        \"\"\"Build the arXiv API query URL.\"\"\"\n        base_url = \"http://export.arxiv.org/api/query?\"\n\n        # Build the search query based on search type\n        if self.search_type == \"all\":\n            search_query = self.search_query  # No prefix for all fields\n        else:\n            # Map dropdown values to ArXiv API prefixes\n            prefix_map = {\"title\": \"ti\", \"abstract\": \"abs\", \"author\": \"au\", \"cat\": \"cat\"}\n            prefix = prefix_map.get(self.search_type, \"\")\n            search_query = f\"{prefix}:{self.search_query}\"\n\n        # URL parameters\n        params = {\n            \"search_query\": search_query,\n            \"max_results\": str(self.max_results),\n        }\n\n        # Convert params to URL query string\n        query_string = \"&\".join([f\"{k}={urllib.parse.quote(str(v))}\" for k, v in params.items()])\n\n        return base_url + query_string\n\n    def parse_atom_response(self, response_text: str) -> list[dict]:\n        \"\"\"Parse the Atom XML response from arXiv.\"\"\"\n        # Parse XML safely using defusedxml\n        root = fromstring(response_text)\n\n        # Define namespace dictionary for XML parsing\n        ns = {\"atom\": \"http://www.w3.org/2005/Atom\", \"arxiv\": \"http://arxiv.org/schemas/atom\"}\n\n        papers = []\n        # Process each entry (paper)\n        for entry in root.findall(\"atom:entry\", ns):\n            paper = {\n                \"id\": self._get_text(entry, \"atom:id\", ns),\n                \"title\": self._get_text(entry, \"atom:title\", ns),\n                \"summary\": self._get_text(entry, \"atom:summary\", ns),\n                \"published\": self._get_text(entry, \"atom:published\", ns),\n                \"updated\": self._get_text(entry, \"atom:updated\", ns),\n                \"authors\": [author.find(\"atom:name\", ns).text for author in entry.findall(\"atom:author\", ns)],\n                \"arxiv_url\": self._get_link(entry, \"alternate\", ns),\n                \"pdf_url\": self._get_link(entry, \"related\", ns),\n                \"comment\": self._get_text(entry, \"arxiv:comment\", ns),\n                \"journal_ref\": self._get_text(entry, \"arxiv:journal_ref\", ns),\n                \"primary_category\": self._get_category(entry, ns),\n                \"categories\": [cat.get(\"term\") for cat in entry.findall(\"atom:category\", ns)],\n            }\n            papers.append(paper)\n\n        return papers\n\n    def _get_text(self, element: Element, path: str, ns: dict) -> str | None:\n        \"\"\"Safely extract text from an XML element.\"\"\"\n        el = element.find(path, ns)\n        return el.text.strip() if el is not None and el.text else None\n\n    def _get_link(self, element: Element, rel: str, ns: dict) -> str | None:\n        \"\"\"Get link URL based on relation type.\"\"\"\n        for link in element.findall(\"atom:link\", ns):\n            if link.get(\"rel\") == rel:\n                return link.get(\"href\")\n        return None\n\n    def _get_category(self, element: Element, ns: dict) -> str | None:\n        \"\"\"Get primary category.\"\"\"\n        cat = element.find(\"arxiv:primary_category\", ns)\n        return cat.get(\"term\") if cat is not None else None\n\n    def run_model(self) -> DataFrame:\n        return self.search_papers_dataframe()\n\n    def search_papers(self) -> list[Data]:\n        \"\"\"Search arXiv and return results.\"\"\"\n        try:\n            # Build the query URL\n            url = self.build_query_url()\n\n            # Validate URL scheme and host\n            parsed_url = urlparse(url)\n            if parsed_url.scheme not in {\"http\", \"https\"}:\n                error_msg = f\"Invalid URL scheme: {parsed_url.scheme}\"\n                raise ValueError(error_msg)\n            if parsed_url.hostname != \"export.arxiv.org\":\n                error_msg = f\"Invalid host: {parsed_url.hostname}\"\n                raise ValueError(error_msg)\n\n            # Create a custom opener that only allows http/https schemes\n            class RestrictedHTTPHandler(urllib.request.HTTPHandler):\n                def http_open(self, req):\n                    return super().http_open(req)\n\n            class RestrictedHTTPSHandler(urllib.request.HTTPSHandler):\n                def https_open(self, req):\n                    return super().https_open(req)\n\n            # Build opener with restricted handlers\n            opener = urllib.request.build_opener(RestrictedHTTPHandler, RestrictedHTTPSHandler)\n            urllib.request.install_opener(opener)\n\n            # Make the request with validated URL using restricted opener\n            response = opener.open(url)\n            response_text = response.read().decode(\"utf-8\")\n\n            # Parse the response\n            papers = self.parse_atom_response(response_text)\n\n            # Convert to Data objects\n            results = [Data(data=paper) for paper in papers]\n            self.status = results\n        except (urllib.error.URLError, ValueError) as e:\n            error_data = Data(data={\"error\": f\"Request error: {e!s}\"})\n            self.status = error_data\n            return [error_data]\n        else:\n            return results\n\n    def search_papers_dataframe(self) -> DataFrame:\n        \"\"\"Convert the Arxiv search results to a DataFrame.\n\n        Returns:\n            DataFrame: A DataFrame containing the search results.\n        \"\"\"\n        data = self.search_papers()\n        return DataFrame(data)\n"},"max_results":{"_input_type":"IntInput","advanced":false,"display_name":"Max Results","dynamic":false,"info":"Maximum number of results to return","list":false,"list_add_label":"Add More","name":"max_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":10},"search_query":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"The search query for arXiv papers (e.g., 'quantum computing')","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"search_type":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Search Field","dynamic":false,"external_options":{},"info":"The field to search in","name":"search_type","options":["all","title","abstract","author","cat"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"all"}},"tool_mode":false}}],["assemblyai",{"AssemblyAIGetSubtitles":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Export your transcript in SRT or VTT format for subtitles and closed captions","display_name":"AssemblyAI Get Subtitles","documentation":"https://www.assemblyai.com/docs","edited":false,"field_order":["api_key","transcription_result","subtitle_format","chars_per_caption"],"frozen":false,"icon":"AssemblyAI","legacy":false,"metadata":{"code_hash":"533d1fcf7c7a","dependencies":{"dependencies":[{"name":"assemblyai","version":"0.35.1"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.assemblyai.assemblyai_get_subtitles.AssemblyAIGetSubtitles"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Subtitles","group_outputs":false,"method":"get_subtitles","name":"subtitles","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Assembly API Key","dynamic":false,"info":"Your AssemblyAI API key. You can get one from https://www.assemblyai.com/","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"chars_per_caption":{"_input_type":"IntInput","advanced":true,"display_name":"Characters per Caption","dynamic":false,"info":"The maximum number of characters per caption (0 for no limit)","list":false,"list_add_label":"Add More","name":"chars_per_caption","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":0},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import assemblyai as aai\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import DataInput, DropdownInput, IntInput, Output, SecretStrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\n\n\nclass AssemblyAIGetSubtitles(Component):\n    display_name = \"AssemblyAI Get Subtitles\"\n    description = \"Export your transcript in SRT or VTT format for subtitles and closed captions\"\n    documentation = \"https://www.assemblyai.com/docs\"\n    icon = \"AssemblyAI\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Assembly API Key\",\n            info=\"Your AssemblyAI API key. You can get one from https://www.assemblyai.com/\",\n            required=True,\n        ),\n        DataInput(\n            name=\"transcription_result\",\n            display_name=\"Transcription Result\",\n            info=\"The transcription result from AssemblyAI\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"subtitle_format\",\n            display_name=\"Subtitle Format\",\n            options=[\"srt\", \"vtt\"],\n            value=\"srt\",\n            info=\"The format of the captions (SRT or VTT)\",\n        ),\n        IntInput(\n            name=\"chars_per_caption\",\n            display_name=\"Characters per Caption\",\n            info=\"The maximum number of characters per caption (0 for no limit)\",\n            value=0,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Subtitles\", name=\"subtitles\", method=\"get_subtitles\"),\n    ]\n\n    def get_subtitles(self) -> Data:\n        aai.settings.api_key = self.api_key\n\n        # check if it's an error message from the previous step\n        if self.transcription_result.data.get(\"error\"):\n            self.status = self.transcription_result.data[\"error\"]\n            return self.transcription_result\n\n        try:\n            transcript_id = self.transcription_result.data[\"id\"]\n            transcript = aai.Transcript.get_by_id(transcript_id)\n        except Exception as e:  # noqa: BLE001\n            error = f\"Getting transcription failed: {e}\"\n            logger.debug(error, exc_info=True)\n            self.status = error\n            return Data(data={\"error\": error})\n\n        if transcript.status == aai.TranscriptStatus.completed:\n            subtitles = None\n            chars_per_caption = self.chars_per_caption if self.chars_per_caption > 0 else None\n            if self.subtitle_format == \"srt\":\n                subtitles = transcript.export_subtitles_srt(chars_per_caption)\n            else:\n                subtitles = transcript.export_subtitles_vtt(chars_per_caption)\n\n            result = Data(\n                subtitles=subtitles,\n                format=self.subtitle_format,\n                transcript_id=transcript_id,\n                chars_per_caption=chars_per_caption,\n            )\n\n            self.status = result\n            return result\n        self.status = transcript.error\n        return Data(data={\"error\": transcript.error})\n"},"subtitle_format":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Subtitle Format","dynamic":false,"external_options":{},"info":"The format of the captions (SRT or VTT)","name":"subtitle_format","options":["srt","vtt"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"srt"},"transcription_result":{"_input_type":"DataInput","advanced":false,"display_name":"Transcription Result","dynamic":false,"info":"The transcription result from AssemblyAI","input_types":["Data"],"list":false,"list_add_label":"Add More","name":"transcription_result","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""}},"tool_mode":false},"AssemblyAILeMUR":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Apply Large Language Models to spoken data using the AssemblyAI LeMUR framework","display_name":"AssemblyAI LeMUR","documentation":"https://www.assemblyai.com/docs/lemur","edited":false,"field_order":["api_key","transcription_result","prompt","final_model","temperature","max_output_size","endpoint","questions","transcript_ids"],"frozen":false,"icon":"AssemblyAI","legacy":false,"metadata":{"code_hash":"8c96738ab967","dependencies":{"dependencies":[{"name":"assemblyai","version":"0.35.1"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.assemblyai.assemblyai_lemur.AssemblyAILeMUR"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"LeMUR Response","group_outputs":false,"method":"run_lemur","name":"lemur_response","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Assembly API Key","dynamic":false,"info":"Your AssemblyAI API key. You can get one from https://www.assemblyai.com/","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import assemblyai as aai\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import DataInput, DropdownInput, FloatInput, IntInput, MultilineInput, Output, SecretStrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\n\n\nclass AssemblyAILeMUR(Component):\n    display_name = \"AssemblyAI LeMUR\"\n    description = \"Apply Large Language Models to spoken data using the AssemblyAI LeMUR framework\"\n    documentation = \"https://www.assemblyai.com/docs/lemur\"\n    icon = \"AssemblyAI\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Assembly API Key\",\n            info=\"Your AssemblyAI API key. You can get one from https://www.assemblyai.com/\",\n            advanced=False,\n            required=True,\n        ),\n        DataInput(\n            name=\"transcription_result\",\n            display_name=\"Transcription Result\",\n            info=\"The transcription result from AssemblyAI\",\n            required=True,\n        ),\n        MultilineInput(name=\"prompt\", display_name=\"Input Prompt\", info=\"The text to prompt the model\", required=True),\n        DropdownInput(\n            name=\"final_model\",\n            display_name=\"Final Model\",\n            options=[\"claude3_5_sonnet\", \"claude3_opus\", \"claude3_haiku\", \"claude3_sonnet\"],\n            value=\"claude3_5_sonnet\",\n            info=\"The model that is used for the final prompt after compression is performed\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            advanced=True,\n            value=0.0,\n            info=\"The temperature to use for the model\",\n        ),\n        IntInput(\n            name=\"max_output_size\",\n            display_name=\" Max Output Size\",\n            advanced=True,\n            value=2000,\n            info=\"Max output size in tokens, up to 4000\",\n        ),\n        DropdownInput(\n            name=\"endpoint\",\n            display_name=\"Endpoint\",\n            options=[\"task\", \"summary\", \"question-answer\"],\n            value=\"task\",\n            info=(\n                \"The LeMUR endpoint to use. For 'summary' and 'question-answer',\"\n                \" no prompt input is needed. See https://www.assemblyai.com/docs/api-reference/lemur/ for more info.\"\n            ),\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"questions\",\n            display_name=\"Questions\",\n            info=\"Comma-separated list of your questions. Only used if Endpoint is 'question-answer'\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"transcript_ids\",\n            display_name=\"Transcript IDs\",\n            info=(\n                \"Comma-separated list of transcript IDs. LeMUR can perform actions over multiple transcripts.\"\n                \" If provided, the Transcription Result is ignored.\"\n            ),\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"LeMUR Response\", name=\"lemur_response\", method=\"run_lemur\"),\n    ]\n\n    def run_lemur(self) -> Data:\n        \"\"\"Use the LeMUR task endpoint to input the LLM prompt.\"\"\"\n        aai.settings.api_key = self.api_key\n\n        if not self.transcription_result and not self.transcript_ids:\n            error = \"Either a Transcription Result or Transcript IDs must be provided\"\n            self.status = error\n            return Data(data={\"error\": error})\n        if self.transcription_result and self.transcription_result.data.get(\"error\"):\n            # error message from the previous step\n            self.status = self.transcription_result.data[\"error\"]\n            return self.transcription_result\n        if self.endpoint == \"task\" and not self.prompt:\n            self.status = \"No prompt specified for the task endpoint\"\n            return Data(data={\"error\": \"No prompt specified\"})\n        if self.endpoint == \"question-answer\" and not self.questions:\n            error = \"No Questions were provided for the question-answer endpoint\"\n            self.status = error\n            return Data(data={\"error\": error})\n\n        # Check for valid transcripts\n        transcript_ids = None\n        if self.transcription_result and \"id\" in self.transcription_result.data:\n            transcript_ids = [self.transcription_result.data[\"id\"]]\n        elif self.transcript_ids:\n            transcript_ids = self.transcript_ids.split(\",\") or []\n            transcript_ids = [t.strip() for t in transcript_ids]\n\n        if not transcript_ids:\n            error = \"Either a valid Transcription Result or valid Transcript IDs must be provided\"\n            self.status = error\n            return Data(data={\"error\": error})\n\n        # Get TranscriptGroup and check if there is any error\n        transcript_group = aai.TranscriptGroup(transcript_ids=transcript_ids)\n        transcript_group, failures = transcript_group.wait_for_completion(return_failures=True)\n        if failures:\n            error = f\"Getting transcriptions failed: {failures[0]}\"\n            self.status = error\n            return Data(data={\"error\": error})\n\n        for t in transcript_group.transcripts:\n            if t.status == aai.TranscriptStatus.error:\n                self.status = t.error\n                return Data(data={\"error\": t.error})\n\n        # Perform LeMUR action\n        try:\n            response = self.perform_lemur_action(transcript_group, self.endpoint)\n        except Exception as e:  # noqa: BLE001\n            logger.debug(\"Error running LeMUR\", exc_info=True)\n            error = f\"An Error happened: {e}\"\n            self.status = error\n            return Data(data={\"error\": error})\n\n        result = Data(data=response)\n        self.status = result\n        return result\n\n    def perform_lemur_action(self, transcript_group: aai.TranscriptGroup, endpoint: str) -> dict:\n        logger.info(\"Endpoint:\", endpoint, type(endpoint))\n        if endpoint == \"task\":\n            result = transcript_group.lemur.task(\n                prompt=self.prompt,\n                final_model=self.get_final_model(self.final_model),\n                temperature=self.temperature,\n                max_output_size=self.max_output_size,\n            )\n        elif endpoint == \"summary\":\n            result = transcript_group.lemur.summarize(\n                final_model=self.get_final_model(self.final_model),\n                temperature=self.temperature,\n                max_output_size=self.max_output_size,\n            )\n        elif endpoint == \"question-answer\":\n            questions = self.questions.split(\",\")\n            questions = [aai.LemurQuestion(question=q) for q in questions]\n            result = transcript_group.lemur.question(\n                questions=questions,\n                final_model=self.get_final_model(self.final_model),\n                temperature=self.temperature,\n                max_output_size=self.max_output_size,\n            )\n        else:\n            msg = f\"Endpoint not supported: {endpoint}\"\n            raise ValueError(msg)\n\n        return result.dict()\n\n    def get_final_model(self, model_name: str) -> aai.LemurModel:\n        if model_name == \"claude3_5_sonnet\":\n            return aai.LemurModel.claude3_5_sonnet\n        if model_name == \"claude3_opus\":\n            return aai.LemurModel.claude3_opus\n        if model_name == \"claude3_haiku\":\n            return aai.LemurModel.claude3_haiku\n        if model_name == \"claude3_sonnet\":\n            return aai.LemurModel.claude3_sonnet\n        msg = f\"Model name not supported: {model_name}\"\n        raise ValueError(msg)\n"},"endpoint":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Endpoint","dynamic":false,"external_options":{},"info":"The LeMUR endpoint to use. For 'summary' and 'question-answer', no prompt input is needed. See https://www.assemblyai.com/docs/api-reference/lemur/ for more info.","name":"endpoint","options":["task","summary","question-answer"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"task"},"final_model":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Final Model","dynamic":false,"external_options":{},"info":"The model that is used for the final prompt after compression is performed","name":"final_model","options":["claude3_5_sonnet","claude3_opus","claude3_haiku","claude3_sonnet"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"claude3_5_sonnet"},"max_output_size":{"_input_type":"IntInput","advanced":true,"display_name":" Max Output Size","dynamic":false,"info":"Max output size in tokens, up to 4000","list":false,"list_add_label":"Add More","name":"max_output_size","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":2000},"prompt":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Input Prompt","dynamic":false,"info":"The text to prompt the model","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"prompt","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"questions":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"Questions","dynamic":false,"info":"Comma-separated list of your questions. Only used if Endpoint is 'question-answer'","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"questions","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"FloatInput","advanced":true,"display_name":"Temperature","dynamic":false,"info":"The temperature to use for the model","list":false,"list_add_label":"Add More","name":"temperature","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.0},"transcript_ids":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"Transcript IDs","dynamic":false,"info":"Comma-separated list of transcript IDs. LeMUR can perform actions over multiple transcripts. If provided, the Transcription Result is ignored.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"transcript_ids","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"transcription_result":{"_input_type":"DataInput","advanced":false,"display_name":"Transcription Result","dynamic":false,"info":"The transcription result from AssemblyAI","input_types":["Data"],"list":false,"list_add_label":"Add More","name":"transcription_result","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""}},"tool_mode":false},"AssemblyAIListTranscripts":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Retrieve a list of transcripts from AssemblyAI with filtering options","display_name":"AssemblyAI List Transcripts","documentation":"https://www.assemblyai.com/docs","edited":false,"field_order":["api_key","limit","status_filter","created_on","throttled_only"],"frozen":false,"icon":"AssemblyAI","legacy":false,"metadata":{"code_hash":"267dcda48ad4","dependencies":{"dependencies":[{"name":"assemblyai","version":"0.35.1"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.assemblyai.assemblyai_list_transcripts.AssemblyAIListTranscripts"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Transcript List","group_outputs":false,"method":"list_transcripts","name":"transcript_list","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Assembly API Key","dynamic":false,"info":"Your AssemblyAI API key. You can get one from https://www.assemblyai.com/","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import assemblyai as aai\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import BoolInput, DropdownInput, IntInput, MessageTextInput, Output, SecretStrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\n\n\nclass AssemblyAIListTranscripts(Component):\n    display_name = \"AssemblyAI List Transcripts\"\n    description = \"Retrieve a list of transcripts from AssemblyAI with filtering options\"\n    documentation = \"https://www.assemblyai.com/docs\"\n    icon = \"AssemblyAI\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Assembly API Key\",\n            info=\"Your AssemblyAI API key. You can get one from https://www.assemblyai.com/\",\n            required=True,\n        ),\n        IntInput(\n            name=\"limit\",\n            display_name=\"Limit\",\n            info=\"Maximum number of transcripts to retrieve (default: 20, use 0 for all)\",\n            value=20,\n        ),\n        DropdownInput(\n            name=\"status_filter\",\n            display_name=\"Status Filter\",\n            options=[\"all\", \"queued\", \"processing\", \"completed\", \"error\"],\n            value=\"all\",\n            info=\"Filter by transcript status\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"created_on\",\n            display_name=\"Created On\",\n            info=\"Only get transcripts created on this date (YYYY-MM-DD)\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"throttled_only\",\n            display_name=\"Throttled Only\",\n            info=\"Only get throttled transcripts, overrides the status filter\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Transcript List\", name=\"transcript_list\", method=\"list_transcripts\"),\n    ]\n\n    def list_transcripts(self) -> list[Data]:\n        aai.settings.api_key = self.api_key\n\n        params = aai.ListTranscriptParameters()\n        if self.limit:\n            params.limit = self.limit\n        if self.status_filter != \"all\":\n            params.status = self.status_filter\n        if self.created_on and self.created_on.text:\n            params.created_on = self.created_on.text\n        if self.throttled_only:\n            params.throttled_only = True\n\n        try:\n            transcriber = aai.Transcriber()\n\n            def convert_page_to_data_list(page):\n                return [Data(**t.dict()) for t in page.transcripts]\n\n            if self.limit == 0:\n                # paginate over all pages\n                params.limit = 100\n                page = transcriber.list_transcripts(params)\n                transcripts = convert_page_to_data_list(page)\n\n                while page.page_details.before_id_of_prev_url is not None:\n                    params.before_id = page.page_details.before_id_of_prev_url\n                    page = transcriber.list_transcripts(params)\n                    transcripts.extend(convert_page_to_data_list(page))\n            else:\n                # just one page\n                page = transcriber.list_transcripts(params)\n                transcripts = convert_page_to_data_list(page)\n\n        except Exception as e:  # noqa: BLE001\n            logger.debug(\"Error listing transcripts\", exc_info=True)\n            error_data = Data(data={\"error\": f\"An error occurred: {e}\"})\n            self.status = [error_data]\n            return [error_data]\n\n        self.status = transcripts\n        return transcripts\n"},"created_on":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Created On","dynamic":false,"info":"Only get transcripts created on this date (YYYY-MM-DD)","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"created_on","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"limit":{"_input_type":"IntInput","advanced":false,"display_name":"Limit","dynamic":false,"info":"Maximum number of transcripts to retrieve (default: 20, use 0 for all)","list":false,"list_add_label":"Add More","name":"limit","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":20},"status_filter":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Status Filter","dynamic":false,"external_options":{},"info":"Filter by transcript status","name":"status_filter","options":["all","queued","processing","completed","error"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"all"},"throttled_only":{"_input_type":"BoolInput","advanced":true,"display_name":"Throttled Only","dynamic":false,"info":"Only get throttled transcripts, overrides the status filter","list":false,"list_add_label":"Add More","name":"throttled_only","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false},"AssemblyAITranscriptionJobCreator":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Create a transcription job for an audio file using AssemblyAI with advanced options","display_name":"AssemblyAI Start Transcript","documentation":"https://www.assemblyai.com/docs","edited":false,"field_order":["api_key","audio_file","audio_file_url","speech_model","language_detection","language_code","speaker_labels","speakers_expected","punctuate","format_text"],"frozen":false,"icon":"AssemblyAI","legacy":false,"metadata":{"code_hash":"7ff7b3f90298","dependencies":{"dependencies":[{"name":"assemblyai","version":"0.35.1"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.assemblyai.assemblyai_start_transcript.AssemblyAITranscriptionJobCreator"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Transcript ID","group_outputs":false,"method":"create_transcription_job","name":"transcript_id","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Assembly API Key","dynamic":false,"info":"Your AssemblyAI API key. You can get one from https://www.assemblyai.com/","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"audio_file":{"_input_type":"FileInput","advanced":false,"display_name":"Audio File","dynamic":false,"fileTypes":["3ga","8svx","aac","ac3","aif","aiff","alac","amr","ape","au","dss","flac","flv","m4a","m4b","m4p","m4r","mp3","mpga","ogg","oga","mogg","opus","qcp","tta","voc","wav","wma","wv","webm","mts","m2ts","ts","mov","mp2","mp4","m4p","m4v","mxf"],"file_path":"","info":"The audio file to transcribe","list":false,"list_add_label":"Add More","name":"audio_file","placeholder":"","required":true,"show":true,"temp_file":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"file","value":""},"audio_file_url":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Audio File URL","dynamic":false,"info":"The URL of the audio file to transcribe (Can be used instead of a File)","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"audio_file_url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from pathlib import Path\n\nimport assemblyai as aai\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import BoolInput, DropdownInput, FileInput, MessageTextInput, Output, SecretStrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\n\n\nclass AssemblyAITranscriptionJobCreator(Component):\n    display_name = \"AssemblyAI Start Transcript\"\n    description = \"Create a transcription job for an audio file using AssemblyAI with advanced options\"\n    documentation = \"https://www.assemblyai.com/docs\"\n    icon = \"AssemblyAI\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Assembly API Key\",\n            info=\"Your AssemblyAI API key. You can get one from https://www.assemblyai.com/\",\n            required=True,\n        ),\n        FileInput(\n            name=\"audio_file\",\n            display_name=\"Audio File\",\n            file_types=[\n                \"3ga\",\n                \"8svx\",\n                \"aac\",\n                \"ac3\",\n                \"aif\",\n                \"aiff\",\n                \"alac\",\n                \"amr\",\n                \"ape\",\n                \"au\",\n                \"dss\",\n                \"flac\",\n                \"flv\",\n                \"m4a\",\n                \"m4b\",\n                \"m4p\",\n                \"m4r\",\n                \"mp3\",\n                \"mpga\",\n                \"ogg\",\n                \"oga\",\n                \"mogg\",\n                \"opus\",\n                \"qcp\",\n                \"tta\",\n                \"voc\",\n                \"wav\",\n                \"wma\",\n                \"wv\",\n                \"webm\",\n                \"mts\",\n                \"m2ts\",\n                \"ts\",\n                \"mov\",\n                \"mp2\",\n                \"mp4\",\n                \"m4p\",\n                \"m4v\",\n                \"mxf\",\n            ],\n            info=\"The audio file to transcribe\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"audio_file_url\",\n            display_name=\"Audio File URL\",\n            info=\"The URL of the audio file to transcribe (Can be used instead of a File)\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"speech_model\",\n            display_name=\"Speech Model\",\n            options=[\n                \"best\",\n                \"nano\",\n            ],\n            value=\"best\",\n            info=\"The speech model to use for the transcription\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"language_detection\",\n            display_name=\"Automatic Language Detection\",\n            info=\"Enable automatic language detection\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"language_code\",\n            display_name=\"Language\",\n            info=(\n                \"\"\"\n            The language of the audio file. Can be set manually if automatic language detection is disabled.\n            See https://www.assemblyai.com/docs/getting-started/supported-languages \"\"\"\n                \"for a list of supported language codes.\"\n            ),\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"speaker_labels\",\n            display_name=\"Enable Speaker Labels\",\n            info=\"Enable speaker diarization\",\n        ),\n        MessageTextInput(\n            name=\"speakers_expected\",\n            display_name=\"Expected Number of Speakers\",\n            info=\"Set the expected number of speakers (optional, enter a number)\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"punctuate\",\n            display_name=\"Punctuate\",\n            info=\"Enable automatic punctuation\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"format_text\",\n            display_name=\"Format Text\",\n            info=\"Enable text formatting\",\n            advanced=True,\n            value=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Transcript ID\", name=\"transcript_id\", method=\"create_transcription_job\"),\n    ]\n\n    def create_transcription_job(self) -> Data:\n        aai.settings.api_key = self.api_key\n\n        # Convert speakers_expected to int if it's not empty\n        speakers_expected = None\n        if self.speakers_expected and self.speakers_expected.strip():\n            try:\n                speakers_expected = int(self.speakers_expected)\n            except ValueError:\n                self.status = \"Error: Expected Number of Speakers must be a valid integer\"\n                return Data(data={\"error\": \"Error: Expected Number of Speakers must be a valid integer\"})\n\n        language_code = self.language_code or None\n\n        config = aai.TranscriptionConfig(\n            speech_model=self.speech_model,\n            language_detection=self.language_detection,\n            language_code=language_code,\n            speaker_labels=self.speaker_labels,\n            speakers_expected=speakers_expected,\n            punctuate=self.punctuate,\n            format_text=self.format_text,\n        )\n\n        audio = None\n        if self.audio_file:\n            if self.audio_file_url:\n                logger.warning(\"Both an audio file an audio URL were specified. The audio URL was ignored.\")\n\n            # Check if the file exists\n            if not Path(self.audio_file).exists():\n                self.status = \"Error: Audio file not found\"\n                return Data(data={\"error\": \"Error: Audio file not found\"})\n            audio = self.audio_file\n        elif self.audio_file_url:\n            audio = self.audio_file_url\n        else:\n            self.status = \"Error: Either an audio file or an audio URL must be specified\"\n            return Data(data={\"error\": \"Error: Either an audio file or an audio URL must be specified\"})\n\n        try:\n            transcript = aai.Transcriber().submit(audio, config=config)\n        except Exception as e:  # noqa: BLE001\n            logger.debug(\"Error submitting transcription job\", exc_info=True)\n            self.status = f\"An error occurred: {e}\"\n            return Data(data={\"error\": f\"An error occurred: {e}\"})\n\n        if transcript.error:\n            self.status = transcript.error\n            return Data(data={\"error\": transcript.error})\n        result = Data(data={\"transcript_id\": transcript.id})\n        self.status = result\n        return result\n"},"format_text":{"_input_type":"BoolInput","advanced":true,"display_name":"Format Text","dynamic":false,"info":"Enable text formatting","list":false,"list_add_label":"Add More","name":"format_text","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"language_code":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Language","dynamic":false,"info":"\n            The language of the audio file. Can be set manually if automatic language detection is disabled.\n            See https://www.assemblyai.com/docs/getting-started/supported-languages for a list of supported language codes.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"language_code","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"language_detection":{"_input_type":"BoolInput","advanced":true,"display_name":"Automatic Language Detection","dynamic":false,"info":"Enable automatic language detection","list":false,"list_add_label":"Add More","name":"language_detection","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"punctuate":{"_input_type":"BoolInput","advanced":true,"display_name":"Punctuate","dynamic":false,"info":"Enable automatic punctuation","list":false,"list_add_label":"Add More","name":"punctuate","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"speaker_labels":{"_input_type":"BoolInput","advanced":false,"display_name":"Enable Speaker Labels","dynamic":false,"info":"Enable speaker diarization","list":false,"list_add_label":"Add More","name":"speaker_labels","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"speakers_expected":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Expected Number of Speakers","dynamic":false,"info":"Set the expected number of speakers (optional, enter a number)","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"speakers_expected","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"speech_model":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Speech Model","dynamic":false,"external_options":{},"info":"The speech model to use for the transcription","name":"speech_model","options":["best","nano"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"best"}},"tool_mode":false},"AssemblyAITranscriptionJobPoller":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Poll for the status of a transcription job using AssemblyAI","display_name":"AssemblyAI Poll Transcript","documentation":"https://www.assemblyai.com/docs","edited":false,"field_order":["api_key","transcript_id","polling_interval"],"frozen":false,"icon":"AssemblyAI","legacy":false,"metadata":{"code_hash":"935c9296b149","dependencies":{"dependencies":[{"name":"assemblyai","version":"0.35.1"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.assemblyai.assemblyai_poll_transcript.AssemblyAITranscriptionJobPoller"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Transcription Result","group_outputs":false,"method":"poll_transcription_job","name":"transcription_result","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Assembly API Key","dynamic":false,"info":"Your AssemblyAI API key. You can get one from https://www.assemblyai.com/","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import assemblyai as aai\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.io import DataInput, FloatInput, Output, SecretStrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\n\n\nclass AssemblyAITranscriptionJobPoller(Component):\n    display_name = \"AssemblyAI Poll Transcript\"\n    description = \"Poll for the status of a transcription job using AssemblyAI\"\n    documentation = \"https://www.assemblyai.com/docs\"\n    icon = \"AssemblyAI\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Assembly API Key\",\n            info=\"Your AssemblyAI API key. You can get one from https://www.assemblyai.com/\",\n            required=True,\n        ),\n        DataInput(\n            name=\"transcript_id\",\n            display_name=\"Transcript ID\",\n            info=\"The ID of the transcription job to poll\",\n            required=True,\n        ),\n        FloatInput(\n            name=\"polling_interval\",\n            display_name=\"Polling Interval\",\n            value=3.0,\n            info=\"The polling interval in seconds\",\n            advanced=True,\n            range_spec=RangeSpec(min=3, max=30),\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Transcription Result\", name=\"transcription_result\", method=\"poll_transcription_job\"),\n    ]\n\n    def poll_transcription_job(self) -> Data:\n        \"\"\"Polls the transcription status until completion and returns the Data.\"\"\"\n        aai.settings.api_key = self.api_key\n        aai.settings.polling_interval = self.polling_interval\n\n        # check if it's an error message from the previous step\n        if self.transcript_id.data.get(\"error\"):\n            self.status = self.transcript_id.data[\"error\"]\n            return self.transcript_id\n\n        try:\n            transcript = aai.Transcript.get_by_id(self.transcript_id.data[\"transcript_id\"])\n        except Exception as e:  # noqa: BLE001\n            error = f\"Getting transcription failed: {e}\"\n            logger.debug(error, exc_info=True)\n            self.status = error\n            return Data(data={\"error\": error})\n\n        if transcript.status == aai.TranscriptStatus.completed:\n            json_response = transcript.json_response\n            text = json_response.pop(\"text\", None)\n            utterances = json_response.pop(\"utterances\", None)\n            transcript_id = json_response.pop(\"id\", None)\n            sorted_data = {\"text\": text, \"utterances\": utterances, \"id\": transcript_id}\n            sorted_data.update(json_response)\n            data = Data(data=sorted_data)\n            self.status = data\n            return data\n        self.status = transcript.error\n        return Data(data={\"error\": transcript.error})\n"},"polling_interval":{"_input_type":"FloatInput","advanced":true,"display_name":"Polling Interval","dynamic":false,"info":"The polling interval in seconds","list":false,"list_add_label":"Add More","name":"polling_interval","placeholder":"","range_spec":{"max":30.0,"min":3.0,"step":0.1,"step_type":"float"},"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":3.0},"transcript_id":{"_input_type":"DataInput","advanced":false,"display_name":"Transcript ID","dynamic":false,"info":"The ID of the transcription job to poll","input_types":["Data"],"list":false,"list_add_label":"Add More","name":"transcript_id","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""}},"tool_mode":false}}],["azure",{"AzureOpenAIEmbeddings":{"base_classes":["Embeddings"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate embeddings using Azure OpenAI models.","display_name":"Azure OpenAI Embeddings","documentation":"https://python.langchain.com/docs/integrations/text_embedding/azureopenai","edited":false,"field_order":["model","azure_endpoint","azure_deployment","api_version","api_key","dimensions"],"frozen":false,"icon":"Azure","legacy":false,"metadata":{"code_hash":"6b54f3243a6a","dependencies":{"dependencies":[{"name":"langchain_openai","version":"0.3.23"},{"name":"lfx","version":null}],"total_dependencies":2},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.azure.azure_openai_embeddings.AzureOpenAIEmbeddingsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Embeddings","group_outputs":false,"method":"build_embeddings","name":"embeddings","selected":"Embeddings","tool_mode":true,"types":["Embeddings"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Azure OpenAI API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"api_version":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"API Version","dynamic":false,"external_options":{},"info":"","name":"api_version","options":["2022-12-01","2023-03-15-preview","2023-05-15","2023-06-01-preview","2023-07-01-preview","2023-08-01-preview"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"2023-08-01-preview"},"azure_deployment":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Deployment Name","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"azure_deployment","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"azure_endpoint":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Azure Endpoint","dynamic":false,"info":"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"azure_endpoint","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_openai import AzureOpenAIEmbeddings\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom lfx.field_typing import Embeddings\nfrom lfx.io import DropdownInput, IntInput, MessageTextInput, Output, SecretStrInput\n\n\nclass AzureOpenAIEmbeddingsComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI Embeddings\"\n    description: str = \"Generate embeddings using Azure OpenAI models.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/text_embedding/azureopenai\"\n    icon = \"Azure\"\n    name = \"AzureOpenAIEmbeddings\"\n\n    API_VERSION_OPTIONS = [\n        \"2022-12-01\",\n        \"2023-03-15-preview\",\n        \"2023-05-15\",\n        \"2023-06-01-preview\",\n        \"2023-07-01-preview\",\n        \"2023-08-01-preview\",\n    ]\n\n    inputs = [\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=OPENAI_EMBEDDING_MODEL_NAMES[0],\n        ),\n        MessageTextInput(\n            name=\"azure_endpoint\",\n            display_name=\"Azure Endpoint\",\n            required=True,\n            info=\"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`\",\n        ),\n        MessageTextInput(\n            name=\"azure_deployment\",\n            display_name=\"Deployment Name\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"api_version\",\n            display_name=\"API Version\",\n            options=API_VERSION_OPTIONS,\n            value=API_VERSION_OPTIONS[-1],\n            advanced=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Azure OpenAI API Key\",\n            required=True,\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. \"\n            \"Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        try:\n            embeddings = AzureOpenAIEmbeddings(\n                model=self.model,\n                azure_endpoint=self.azure_endpoint,\n                azure_deployment=self.azure_deployment,\n                api_version=self.api_version,\n                api_key=self.api_key,\n                dimensions=self.dimensions or None,\n            )\n        except Exception as e:\n            msg = f\"Could not connect to AzureOpenAIEmbeddings API: {e}\"\n            raise ValueError(msg) from e\n\n        return embeddings\n"},"dimensions":{"_input_type":"IntInput","advanced":true,"display_name":"Dimensions","dynamic":false,"info":"The number of dimensions the resulting output embeddings should have. Only supported by certain models.","list":false,"list_add_label":"Add More","name":"dimensions","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"model":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model","dynamic":false,"external_options":{},"info":"","name":"model","options":["text-embedding-3-small","text-embedding-3-large","text-embedding-ada-002"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"text-embedding-3-small"}},"tool_mode":false},"AzureOpenAIModel":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate text using Azure OpenAI LLMs.","display_name":"Azure OpenAI","documentation":"https://python.langchain.com/docs/integrations/llms/azure_openai","edited":false,"field_order":["input_value","system_message","stream","azure_endpoint","azure_deployment","api_key","api_version","temperature","max_tokens"],"frozen":false,"icon":"Azure","legacy":false,"metadata":{"code_hash":"cc8d003556d8","dependencies":{"dependencies":[{"name":"langchain_openai","version":"0.3.23"},{"name":"lfx","version":null}],"total_dependencies":2},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.azure.azure_openai.AzureChatOpenAIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Azure Chat OpenAI API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"api_version":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"API Version","dynamic":false,"external_options":{},"info":"","name":"api_version","options":["2025-02-01-preview","2025-01-01-preview","2024-12-01-preview","2024-10-01-preview","2024-09-01-preview","2024-08-01-preview","2024-07-01-preview","2024-06-01","2024-03-01-preview","2024-02-15-preview","2023-12-01-preview","2023-05-15"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"2024-06-01"},"azure_deployment":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Deployment Name","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"azure_deployment","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"azure_endpoint":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Azure Endpoint","dynamic":false,"info":"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"azure_endpoint","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_openai import AzureChatOpenAI\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.inputs.inputs import MessageTextInput\nfrom lfx.io import DropdownInput, IntInput, SecretStrInput, SliderInput\n\n\nclass AzureChatOpenAIComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI\"\n    description: str = \"Generate text using Azure OpenAI LLMs.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/llms/azure_openai\"\n    beta = False\n    icon = \"Azure\"\n    name = \"AzureOpenAIModel\"\n\n    AZURE_OPENAI_API_VERSIONS = [\n        \"2024-06-01\",\n        \"2024-07-01-preview\",\n        \"2024-08-01-preview\",\n        \"2024-09-01-preview\",\n        \"2024-10-01-preview\",\n        \"2023-05-15\",\n        \"2023-12-01-preview\",\n        \"2024-02-15-preview\",\n        \"2024-03-01-preview\",\n        \"2024-12-01-preview\",\n        \"2025-01-01-preview\",\n        \"2025-02-01-preview\",\n    ]\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        MessageTextInput(\n            name=\"azure_endpoint\",\n            display_name=\"Azure Endpoint\",\n            info=\"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`\",\n            required=True,\n        ),\n        MessageTextInput(name=\"azure_deployment\", display_name=\"Deployment Name\", required=True),\n        SecretStrInput(name=\"api_key\", display_name=\"Azure Chat OpenAI API Key\", required=True),\n        DropdownInput(\n            name=\"api_version\",\n            display_name=\"API Version\",\n            options=sorted(AZURE_OPENAI_API_VERSIONS, reverse=True),\n            value=next(\n                (\n                    version\n                    for version in sorted(AZURE_OPENAI_API_VERSIONS, reverse=True)\n                    if not version.endswith(\"-preview\")\n                ),\n                AZURE_OPENAI_API_VERSIONS[0],\n            ),\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.7,\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\n            info=\"Controls randomness. Lower values are more deterministic, higher values are more creative.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        azure_endpoint = self.azure_endpoint\n        azure_deployment = self.azure_deployment\n        api_version = self.api_version\n        api_key = self.api_key\n        temperature = self.temperature\n        max_tokens = self.max_tokens\n        stream = self.stream\n\n        try:\n            output = AzureChatOpenAI(\n                azure_endpoint=azure_endpoint,\n                azure_deployment=azure_deployment,\n                api_version=api_version,\n                api_key=api_key,\n                temperature=temperature,\n                max_tokens=max_tokens or None,\n                streaming=stream,\n            )\n        except Exception as e:\n            msg = f\"Could not connect to AzureOpenAI API: {e}\"\n            raise ValueError(msg) from e\n\n        return output\n"},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"max_tokens":{"_input_type":"IntInput","advanced":true,"display_name":"Max Tokens","dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","list":false,"list_add_label":"Add More","name":"max_tokens","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"SliderInput","advanced":true,"display_name":"Temperature","dynamic":false,"info":"Controls randomness. Lower values are more deterministic, higher values are more creative.","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"temperature","placeholder":"","range_spec":{"max":2.0,"min":0.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":0.7}},"tool_mode":false}}],["baidu",{"BaiduQianfanChatModel":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate text using Baidu Qianfan LLMs.","display_name":"Qianfan","documentation":"https://python.langchain.com/docs/integrations/chat/baidu_qianfan_endpoint","edited":false,"field_order":["input_value","system_message","stream","model","qianfan_ak","qianfan_sk","top_p","temperature","penalty_score","endpoint"],"frozen":false,"icon":"BaiduQianfan","legacy":false,"metadata":{"code_hash":"a5fdfdb5757f","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":2},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.baidu.baidu_qianfan_chat.QianfanChatEndpointComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_community.chat_models.baidu_qianfan_endpoint import QianfanChatEndpoint\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing.constants import LanguageModel\nfrom lfx.io import DropdownInput, FloatInput, MessageTextInput, SecretStrInput\n\n\nclass QianfanChatEndpointComponent(LCModelComponent):\n    display_name: str = \"Qianfan\"\n    description: str = \"Generate text using Baidu Qianfan LLMs.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/chat/baidu_qianfan_endpoint\"\n    icon = \"BaiduQianfan\"\n    name = \"BaiduQianfanChatModel\"\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model Name\",\n            options=[\n                \"EB-turbo-AppBuilder\",\n                \"Llama-2-70b-chat\",\n                \"ERNIE-Bot-turbo-AI\",\n                \"ERNIE-Lite-8K-0308\",\n                \"ERNIE-Speed\",\n                \"Qianfan-Chinese-Llama-2-13B\",\n                \"ERNIE-3.5-8K\",\n                \"BLOOMZ-7B\",\n                \"Qianfan-Chinese-Llama-2-7B\",\n                \"XuanYuan-70B-Chat-4bit\",\n                \"AquilaChat-7B\",\n                \"ERNIE-Bot-4\",\n                \"Llama-2-13b-chat\",\n                \"ChatGLM2-6B-32K\",\n                \"ERNIE-Bot\",\n                \"ERNIE-Speed-128k\",\n                \"ERNIE-4.0-8K\",\n                \"Qianfan-BLOOMZ-7B-compressed\",\n                \"ERNIE Speed\",\n                \"Llama-2-7b-chat\",\n                \"Mixtral-8x7B-Instruct\",\n                \"ERNIE 3.5\",\n                \"ERNIE Speed-AppBuilder\",\n                \"ERNIE-Speed-8K\",\n                \"Yi-34B-Chat\",\n            ],\n            info=\"https://python.langchain.com/docs/integrations/chat/baidu_qianfan_endpoint\",\n            value=\"ERNIE-4.0-8K\",\n        ),\n        SecretStrInput(\n            name=\"qianfan_ak\",\n            display_name=\"Qianfan Ak\",\n            info=\"which you could get from  https://cloud.baidu.com/product/wenxinworkshop\",\n        ),\n        SecretStrInput(\n            name=\"qianfan_sk\",\n            display_name=\"Qianfan Sk\",\n            info=\"which you could get from  https://cloud.baidu.com/product/wenxinworkshop\",\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top p\",\n            info=\"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo\",\n            value=0.8,\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            info=\"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo\",\n            value=0.95,\n        ),\n        FloatInput(\n            name=\"penalty_score\",\n            display_name=\"Penalty Score\",\n            info=\"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo\",\n            value=1.0,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"endpoint\", display_name=\"Endpoint\", info=\"Endpoint of the Qianfan LLM, required if custom model used.\"\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        model = self.model\n        qianfan_ak = self.qianfan_ak\n        qianfan_sk = self.qianfan_sk\n        top_p = self.top_p\n        temperature = self.temperature\n        penalty_score = self.penalty_score\n        endpoint = self.endpoint\n\n        try:\n            kwargs = {\n                \"model\": model,\n                \"qianfan_ak\": qianfan_ak or None,\n                \"qianfan_sk\": qianfan_sk or None,\n                \"top_p\": top_p,\n                \"temperature\": temperature,\n                \"penalty_score\": penalty_score,\n            }\n\n            if endpoint:  # Only add endpoint if it has a value\n                kwargs[\"endpoint\"] = endpoint\n\n            output = QianfanChatEndpoint(**kwargs)\n\n        except Exception as e:\n            msg = \"Could not connect to Baidu Qianfan API.\"\n            raise ValueError(msg) from e\n\n        return output\n"},"endpoint":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Endpoint","dynamic":false,"info":"Endpoint of the Qianfan LLM, required if custom model used.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"endpoint","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"model":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model Name","dynamic":false,"external_options":{},"info":"https://python.langchain.com/docs/integrations/chat/baidu_qianfan_endpoint","name":"model","options":["EB-turbo-AppBuilder","Llama-2-70b-chat","ERNIE-Bot-turbo-AI","ERNIE-Lite-8K-0308","ERNIE-Speed","Qianfan-Chinese-Llama-2-13B","ERNIE-3.5-8K","BLOOMZ-7B","Qianfan-Chinese-Llama-2-7B","XuanYuan-70B-Chat-4bit","AquilaChat-7B","ERNIE-Bot-4","Llama-2-13b-chat","ChatGLM2-6B-32K","ERNIE-Bot","ERNIE-Speed-128k","ERNIE-4.0-8K","Qianfan-BLOOMZ-7B-compressed","ERNIE Speed","Llama-2-7b-chat","Mixtral-8x7B-Instruct","ERNIE 3.5","ERNIE Speed-AppBuilder","ERNIE-Speed-8K","Yi-34B-Chat"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"ERNIE-4.0-8K"},"penalty_score":{"_input_type":"FloatInput","advanced":true,"display_name":"Penalty Score","dynamic":false,"info":"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo","list":false,"list_add_label":"Add More","name":"penalty_score","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":1.0},"qianfan_ak":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Qianfan Ak","dynamic":false,"info":"which you could get from  https://cloud.baidu.com/product/wenxinworkshop","input_types":[],"load_from_db":true,"name":"qianfan_ak","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"qianfan_sk":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Qianfan Sk","dynamic":false,"info":"which you could get from  https://cloud.baidu.com/product/wenxinworkshop","input_types":[],"load_from_db":true,"name":"qianfan_sk","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"FloatInput","advanced":false,"display_name":"Temperature","dynamic":false,"info":"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo","list":false,"list_add_label":"Add More","name":"temperature","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.95},"top_p":{"_input_type":"FloatInput","advanced":true,"display_name":"Top p","dynamic":false,"info":"Model params, only supported in ERNIE-Bot and ERNIE-Bot-turbo","list":false,"list_add_label":"Add More","name":"top_p","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.8}},"tool_mode":false}}],["bing",{"BingSearchAPI":{"base_classes":["DataFrame","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Call the Bing Search API.","display_name":"Bing Search API","documentation":"","edited":false,"field_order":["bing_subscription_key","input_value","bing_search_url","k"],"frozen":false,"icon":"Bing","legacy":false,"metadata":{"code_hash":"84334607b325","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.bing.bing_search_api.BingSearchAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"fetch_content_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","bing_search_url":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Bing Search URL","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"bing_search_url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"bing_subscription_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bing Subscription Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bing_subscription_key","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import cast\n\nfrom langchain_community.tools.bing_search import BingSearchResults\nfrom langchain_community.utilities import BingSearchAPIWrapper\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.field_typing import Tool\nfrom lfx.inputs.inputs import IntInput, MessageTextInput, MultilineInput, SecretStrInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.template.field.base import Output\n\n\nclass BingSearchAPIComponent(LCToolComponent):\n    display_name = \"Bing Search API\"\n    description = \"Call the Bing Search API.\"\n    name = \"BingSearchAPI\"\n    icon = \"Bing\"\n\n    inputs = [\n        SecretStrInput(name=\"bing_subscription_key\", display_name=\"Bing Subscription Key\"),\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n        ),\n        MessageTextInput(name=\"bing_search_url\", display_name=\"Bing Search URL\", advanced=True),\n        IntInput(name=\"k\", display_name=\"Number of results\", value=4, required=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"fetch_content_dataframe\"),\n        Output(display_name=\"Tool\", name=\"tool\", method=\"build_tool\"),\n    ]\n\n    def run_model(self) -> DataFrame:\n        return self.fetch_content_dataframe()\n\n    def fetch_content(self) -> list[Data]:\n        if self.bing_search_url:\n            wrapper = BingSearchAPIWrapper(\n                bing_search_url=self.bing_search_url, bing_subscription_key=self.bing_subscription_key\n            )\n        else:\n            wrapper = BingSearchAPIWrapper(bing_subscription_key=self.bing_subscription_key)\n        results = wrapper.results(query=self.input_value, num_results=self.k)\n        data = [Data(data=result, text=result[\"snippet\"]) for result in results]\n        self.status = data\n        return data\n\n    def fetch_content_dataframe(self) -> DataFrame:\n        data = self.fetch_content()\n        return DataFrame(data)\n\n    def build_tool(self) -> Tool:\n        if self.bing_search_url:\n            wrapper = BingSearchAPIWrapper(\n                bing_search_url=self.bing_search_url, bing_subscription_key=self.bing_subscription_key\n            )\n        else:\n            wrapper = BingSearchAPIWrapper(bing_subscription_key=self.bing_subscription_key)\n        return cast(\"Tool\", BingSearchResults(api_wrapper=wrapper, num_results=self.k))\n"},"input_value":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"k":{"_input_type":"IntInput","advanced":false,"display_name":"Number of results","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"k","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4}},"tool_mode":false}}],["cassandra",{"Cassandra":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Cassandra Vector Store with search capabilities","display_name":"Cassandra","documentation":"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/cassandra","edited":false,"field_order":["database_ref","username","token","keyspace","table_name","ttl_seconds","batch_size","setup_mode","cluster_kwargs","ingest_data","search_query","should_cache_vector_store","embedding","number_of_results","search_type","search_score_threshold","search_filter","body_search","enable_body_search"],"frozen":false,"icon":"Cassandra","legacy":false,"metadata":{"code_hash":"833f277daab7","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null},{"name":"cassio","version":null}],"total_dependencies":3},"module":"lfx.components.cassandra.cassandra.CassandraVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","batch_size":{"_input_type":"IntInput","advanced":true,"display_name":"Batch Size","dynamic":false,"info":"Optional number of data to process in a single batch.","list":false,"list_add_label":"Add More","name":"batch_size","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":16},"body_search":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Search Body","dynamic":false,"info":"Document textual search terms to apply to the search query.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"body_search","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"cluster_kwargs":{"_input_type":"DictInput","advanced":true,"display_name":"Cluster arguments","dynamic":false,"info":"Optional dictionary of additional keyword arguments for the Cassandra cluster.","list":true,"list_add_label":"Add More","name":"cluster_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_community.vectorstores import Cassandra\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.inputs.inputs import BoolInput, DictInput, FloatInput\nfrom lfx.io import (\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    MessageTextInput,\n    SecretStrInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass CassandraVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Cassandra\"\n    description = \"Cassandra Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/cassandra\"\n    name = \"Cassandra\"\n    icon = \"Cassandra\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"database_ref\",\n            display_name=\"Contact Points / Astra Database ID\",\n            info=\"Contact points for the database (or Astra DB database ID)\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"username\", display_name=\"Username\", info=\"Username for the database (leave empty for Astra DB).\"\n        ),\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Password / Astra DB Token\",\n            info=\"User password for the database (or Astra DB token).\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"keyspace\",\n            display_name=\"Keyspace\",\n            info=\"Table Keyspace (or Astra DB namespace).\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"table_name\",\n            display_name=\"Table Name\",\n            info=\"The name of the table (or Astra DB collection) where vectors will be stored.\",\n            required=True,\n        ),\n        IntInput(\n            name=\"ttl_seconds\",\n            display_name=\"TTL Seconds\",\n            info=\"Optional time-to-live for the added texts.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"batch_size\",\n            display_name=\"Batch Size\",\n            info=\"Optional number of data to process in a single batch.\",\n            value=16,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"setup_mode\",\n            display_name=\"Setup Mode\",\n            info=\"Configuration mode for setting up the Cassandra table, with options like 'Sync', 'Async', or 'Off'.\",\n            options=[\"Sync\", \"Async\", \"Off\"],\n            value=\"Sync\",\n            advanced=True,\n        ),\n        DictInput(\n            name=\"cluster_kwargs\",\n            display_name=\"Cluster arguments\",\n            info=\"Optional dictionary of additional keyword arguments for the Cassandra cluster.\",\n            advanced=True,\n            list=True,\n        ),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            info=\"Search type to use\",\n            options=[\"Similarity\", \"Similarity with score threshold\", \"MMR (Max Marginal Relevance)\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results. \"\n            \"(when using 'Similarity with score threshold')\",\n            value=0,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"search_filter\",\n            display_name=\"Search Metadata Filter\",\n            info=\"Optional dictionary of filters to apply to the search query.\",\n            advanced=True,\n            list=True,\n        ),\n        MessageTextInput(\n            name=\"body_search\",\n            display_name=\"Search Body\",\n            info=\"Document textual search terms to apply to the search query.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"enable_body_search\",\n            display_name=\"Enable Body Search\",\n            info=\"Flag to enable body search. This must be enabled BEFORE the table is created.\",\n            value=False,\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> Cassandra:\n        try:\n            import cassio\n            from langchain_community.utilities.cassandra import SetupMode\n        except ImportError as e:\n            msg = \"Could not import cassio integration package. Please install it with `pip install cassio`.\"\n            raise ImportError(msg) from e\n\n        from uuid import UUID\n\n        database_ref = self.database_ref\n\n        try:\n            UUID(self.database_ref)\n            is_astra = True\n        except ValueError:\n            is_astra = False\n            if \",\" in self.database_ref:\n                # use a copy because we can't change the type of the parameter\n                database_ref = self.database_ref.split(\",\")\n\n        if is_astra:\n            cassio.init(\n                database_id=database_ref,\n                token=self.token,\n                cluster_kwargs=self.cluster_kwargs,\n            )\n        else:\n            cassio.init(\n                contact_points=database_ref,\n                username=self.username,\n                password=self.token,\n                cluster_kwargs=self.cluster_kwargs,\n            )\n\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        body_index_options = [(\"index_analyzer\", \"STANDARD\")] if self.enable_body_search else None\n\n        if self.setup_mode == \"Off\":\n            setup_mode = SetupMode.OFF\n        elif self.setup_mode == \"Sync\":\n            setup_mode = SetupMode.SYNC\n        else:\n            setup_mode = SetupMode.ASYNC\n\n        if documents:\n            self.log(f\"Adding {len(documents)} documents to the Vector Store.\")\n            table = Cassandra.from_documents(\n                documents=documents,\n                embedding=self.embedding,\n                table_name=self.table_name,\n                keyspace=self.keyspace,\n                ttl_seconds=self.ttl_seconds or None,\n                batch_size=self.batch_size,\n                body_index_options=body_index_options,\n            )\n        else:\n            self.log(\"No documents to add to the Vector Store.\")\n            table = Cassandra(\n                embedding=self.embedding,\n                table_name=self.table_name,\n                keyspace=self.keyspace,\n                ttl_seconds=self.ttl_seconds or None,\n                body_index_options=body_index_options,\n                setup_mode=setup_mode,\n            )\n        return table\n\n    def _map_search_type(self) -> str:\n        if self.search_type == \"Similarity with score threshold\":\n            return \"similarity_score_threshold\"\n        if self.search_type == \"MMR (Max Marginal Relevance)\":\n            return \"mmr\"\n        return \"similarity\"\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        self.log(f\"Search input: {self.search_query}\")\n        self.log(f\"Search type: {self.search_type}\")\n        self.log(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            try:\n                search_type = self._map_search_type()\n                search_args = self._build_search_args()\n\n                self.log(f\"Search args: {search_args}\")\n\n                docs = vector_store.search(query=self.search_query, search_type=search_type, **search_args)\n            except KeyError as e:\n                if \"content\" in str(e):\n                    msg = (\n                        \"You should ingest data through Langflow (or LangChain) to query it in Langflow. \"\n                        \"Your collection does not contain a field name 'content'.\"\n                    )\n                    raise ValueError(msg) from e\n                raise\n\n            self.log(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n\n    def _build_search_args(self):\n        args = {\n            \"k\": self.number_of_results,\n            \"score_threshold\": self.search_score_threshold,\n        }\n\n        if self.search_filter:\n            clean_filter = {k: v for k, v in self.search_filter.items() if k and v}\n            if len(clean_filter) > 0:\n                args[\"filter\"] = clean_filter\n        if self.body_search:\n            if not self.enable_body_search:\n                msg = \"You should enable body search when creating the table to search the body field.\"\n                raise ValueError(msg)\n            args[\"body_search\"] = self.body_search\n        return args\n\n    def get_retriever_kwargs(self):\n        search_args = self._build_search_args()\n        return {\n            \"search_type\": self._map_search_type(),\n            \"search_kwargs\": search_args,\n        }\n"},"database_ref":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Contact Points / Astra Database ID","dynamic":false,"info":"Contact points for the database (or Astra DB database ID)","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"database_ref","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"enable_body_search":{"_input_type":"BoolInput","advanced":true,"display_name":"Enable Body Search","dynamic":false,"info":"Flag to enable body search. This must be enabled BEFORE the table is created.","list":false,"list_add_label":"Add More","name":"enable_body_search","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"keyspace":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Keyspace","dynamic":false,"info":"Table Keyspace (or Astra DB namespace).","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"keyspace","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"search_filter":{"_input_type":"DictInput","advanced":true,"display_name":"Search Metadata Filter","dynamic":false,"info":"Optional dictionary of filters to apply to the search query.","list":true,"list_add_label":"Add More","name":"search_filter","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"search_score_threshold":{"_input_type":"FloatInput","advanced":true,"display_name":"Search Score Threshold","dynamic":false,"info":"Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')","list":false,"list_add_label":"Add More","name":"search_score_threshold","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.0},"search_type":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Search Type","dynamic":false,"external_options":{},"info":"Search type to use","name":"search_type","options":["Similarity","Similarity with score threshold","MMR (Max Marginal Relevance)"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Similarity"},"setup_mode":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Setup Mode","dynamic":false,"external_options":{},"info":"Configuration mode for setting up the Cassandra table, with options like 'Sync', 'Async', or 'Off'.","name":"setup_mode","options":["Sync","Async","Off"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Sync"},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"table_name":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Table Name","dynamic":false,"info":"The name of the table (or Astra DB collection) where vectors will be stored.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"table_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password / Astra DB Token","dynamic":false,"info":"User password for the database (or Astra DB token).","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"ttl_seconds":{"_input_type":"IntInput","advanced":true,"display_name":"TTL Seconds","dynamic":false,"info":"Optional time-to-live for the added texts.","list":false,"list_add_label":"Add More","name":"ttl_seconds","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"username":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Username","dynamic":false,"info":"Username for the database (leave empty for Astra DB).","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"CassandraChatMemory":{"base_classes":["Memory"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Retrieves and store chat messages from Apache Cassandra.","display_name":"Cassandra Chat Memory","documentation":"","edited":false,"field_order":["database_ref","username","token","keyspace","table_name","session_id","cluster_kwargs"],"frozen":false,"icon":"Cassandra","legacy":false,"metadata":{"code_hash":"f6497182984e","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"langchain_community","version":"0.3.21"},{"name":"cassio","version":null}],"total_dependencies":3},"module":"lfx.components.cassandra.cassandra_chat.CassandraChatMemory"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Memory","group_outputs":false,"method":"build_message_history","name":"memory","selected":"Memory","tool_mode":true,"types":["Memory"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","cluster_kwargs":{"_input_type":"DictInput","advanced":true,"display_name":"Cluster arguments","dynamic":false,"info":"Optional dictionary of additional keyword arguments for the Cassandra cluster.","list":true,"list_add_label":"Add More","name":"cluster_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.memory.model import LCChatMemoryComponent\nfrom lfx.field_typing.constants import Memory\nfrom lfx.inputs.inputs import DictInput, MessageTextInput, SecretStrInput\n\n\nclass CassandraChatMemory(LCChatMemoryComponent):\n    display_name = \"Cassandra Chat Memory\"\n    description = \"Retrieves and store chat messages from Apache Cassandra.\"\n    name = \"CassandraChatMemory\"\n    icon = \"Cassandra\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"database_ref\",\n            display_name=\"Contact Points / Astra Database ID\",\n            info=\"Contact points for the database (or Astra DB database ID)\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"username\", display_name=\"Username\", info=\"Username for the database (leave empty for Astra DB).\"\n        ),\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Password / Astra DB Token\",\n            info=\"User password for the database (or Astra DB token).\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"keyspace\",\n            display_name=\"Keyspace\",\n            info=\"Table Keyspace (or Astra DB namespace).\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"table_name\",\n            display_name=\"Table Name\",\n            info=\"The name of the table (or Astra DB collection) where vectors will be stored.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        DictInput(\n            name=\"cluster_kwargs\",\n            display_name=\"Cluster arguments\",\n            info=\"Optional dictionary of additional keyword arguments for the Cassandra cluster.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n\n    def build_message_history(self) -> Memory:\n        from langchain_community.chat_message_histories import CassandraChatMessageHistory\n\n        try:\n            import cassio\n        except ImportError as e:\n            msg = \"Could not import cassio integration package. Please install it with `pip install cassio`.\"\n            raise ImportError(msg) from e\n\n        from uuid import UUID\n\n        database_ref = self.database_ref\n\n        try:\n            UUID(self.database_ref)\n            is_astra = True\n        except ValueError:\n            is_astra = False\n            if \",\" in self.database_ref:\n                # use a copy because we can't change the type of the parameter\n                database_ref = self.database_ref.split(\",\")\n\n        if is_astra:\n            cassio.init(\n                database_id=database_ref,\n                token=self.token,\n                cluster_kwargs=self.cluster_kwargs,\n            )\n        else:\n            cassio.init(\n                contact_points=database_ref,\n                username=self.username,\n                password=self.token,\n                cluster_kwargs=self.cluster_kwargs,\n            )\n\n        return CassandraChatMessageHistory(\n            session_id=self.session_id,\n            table_name=self.table_name,\n            keyspace=self.keyspace,\n        )\n"},"database_ref":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Contact Points / Astra Database ID","dynamic":false,"info":"Contact points for the database (or Astra DB database ID)","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"database_ref","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"keyspace":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Keyspace","dynamic":false,"info":"Table Keyspace (or Astra DB namespace).","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"keyspace","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"session_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Session ID","dynamic":false,"info":"Session ID for the message.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"session_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"table_name":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Table Name","dynamic":false,"info":"The name of the table (or Astra DB collection) where vectors will be stored.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"table_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password / Astra DB Token","dynamic":false,"info":"User password for the database (or Astra DB token).","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"username":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Username","dynamic":false,"info":"Username for the database (leave empty for Astra DB).","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"CassandraGraph":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Cassandra Graph Vector Store","display_name":"Cassandra Graph","documentation":"","edited":false,"field_order":["database_ref","username","token","keyspace","table_name","setup_mode","cluster_kwargs","ingest_data","search_query","should_cache_vector_store","embedding","number_of_results","search_type","depth","search_score_threshold","search_filter"],"frozen":false,"icon":"Cassandra","legacy":false,"metadata":{"code_hash":"26c63f80745e","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null},{"name":"cassio","version":null}],"total_dependencies":3},"module":"lfx.components.cassandra.cassandra_graph.CassandraGraphVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","cluster_kwargs":{"_input_type":"DictInput","advanced":true,"display_name":"Cluster arguments","dynamic":false,"info":"Optional dictionary of additional keyword arguments for the Cassandra cluster.","list":true,"list_add_label":"Add More","name":"cluster_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from uuid import UUID\n\nfrom langchain_community.graph_vectorstores import CassandraGraphVectorStore\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.inputs.inputs import DictInput, FloatInput\nfrom lfx.io import (\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    MessageTextInput,\n    SecretStrInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass CassandraGraphVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Cassandra Graph\"\n    description = \"Cassandra Graph Vector Store\"\n    name = \"CassandraGraph\"\n    icon = \"Cassandra\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"database_ref\",\n            display_name=\"Contact Points / Astra Database ID\",\n            info=\"Contact points for the database (or Astra DB database ID)\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"username\", display_name=\"Username\", info=\"Username for the database (leave empty for Astra DB).\"\n        ),\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Password / Astra DB Token\",\n            info=\"User password for the database (or Astra DB token).\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"keyspace\",\n            display_name=\"Keyspace\",\n            info=\"Table Keyspace (or Astra DB namespace).\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"table_name\",\n            display_name=\"Table Name\",\n            info=\"The name of the table (or Astra DB collection) where vectors will be stored.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"setup_mode\",\n            display_name=\"Setup Mode\",\n            info=\"Configuration mode for setting up the Cassandra table, with options like 'Sync' or 'Off'.\",\n            options=[\"Sync\", \"Off\"],\n            value=\"Sync\",\n            advanced=True,\n        ),\n        DictInput(\n            name=\"cluster_kwargs\",\n            display_name=\"Cluster arguments\",\n            info=\"Optional dictionary of additional keyword arguments for the Cassandra cluster.\",\n            advanced=True,\n            list=True,\n        ),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            info=\"Search type to use\",\n            options=[\n                \"Traversal\",\n                \"MMR traversal\",\n                \"Similarity\",\n                \"Similarity with score threshold\",\n                \"MMR (Max Marginal Relevance)\",\n            ],\n            value=\"Traversal\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"depth\",\n            display_name=\"Depth of traversal\",\n            info=\"The maximum depth of edges to traverse. (when using 'Traversal' or 'MMR traversal')\",\n            value=1,\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results. \"\n            \"(when using 'Similarity with score threshold')\",\n            value=0,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"search_filter\",\n            display_name=\"Search Metadata Filter\",\n            info=\"Optional dictionary of filters to apply to the search query.\",\n            advanced=True,\n            list=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> CassandraGraphVectorStore:\n        try:\n            import cassio\n            from langchain_community.utilities.cassandra import SetupMode\n        except ImportError as e:\n            msg = \"Could not import cassio integration package. Please install it with `pip install cassio`.\"\n            raise ImportError(msg) from e\n\n        database_ref = self.database_ref\n\n        try:\n            UUID(self.database_ref)\n            is_astra = True\n        except ValueError:\n            is_astra = False\n            if \",\" in self.database_ref:\n                # use a copy because we can't change the type of the parameter\n                database_ref = self.database_ref.split(\",\")\n\n        if is_astra:\n            cassio.init(\n                database_id=database_ref,\n                token=self.token,\n                cluster_kwargs=self.cluster_kwargs,\n            )\n        else:\n            cassio.init(\n                contact_points=database_ref,\n                username=self.username,\n                password=self.token,\n                cluster_kwargs=self.cluster_kwargs,\n            )\n\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        setup_mode = SetupMode.OFF if self.setup_mode == \"Off\" else SetupMode.SYNC\n\n        if documents:\n            self.log(f\"Adding {len(documents)} documents to the Vector Store.\")\n            store = CassandraGraphVectorStore.from_documents(\n                documents=documents,\n                embedding=self.embedding,\n                node_table=self.table_name,\n                keyspace=self.keyspace,\n            )\n        else:\n            self.log(\"No documents to add to the Vector Store.\")\n            store = CassandraGraphVectorStore(\n                embedding=self.embedding,\n                node_table=self.table_name,\n                keyspace=self.keyspace,\n                setup_mode=setup_mode,\n            )\n        return store\n\n    def _map_search_type(self) -> str:\n        if self.search_type == \"Similarity\":\n            return \"similarity\"\n        if self.search_type == \"Similarity with score threshold\":\n            return \"similarity_score_threshold\"\n        if self.search_type == \"MMR (Max Marginal Relevance)\":\n            return \"mmr\"\n        if self.search_type == \"MMR Traversal\":\n            return \"mmr_traversal\"\n        return \"traversal\"\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        self.log(f\"Search input: {self.search_query}\")\n        self.log(f\"Search type: {self.search_type}\")\n        self.log(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            try:\n                search_type = self._map_search_type()\n                search_args = self._build_search_args()\n\n                self.log(f\"Search args: {search_args}\")\n\n                docs = vector_store.search(query=self.search_query, search_type=search_type, **search_args)\n            except KeyError as e:\n                if \"content\" in str(e):\n                    msg = (\n                        \"You should ingest data through Langflow (or LangChain) to query it in Langflow. \"\n                        \"Your collection does not contain a field name 'content'.\"\n                    )\n                    raise ValueError(msg) from e\n                raise\n\n            self.log(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n\n    def _build_search_args(self):\n        args = {\n            \"k\": self.number_of_results,\n            \"score_threshold\": self.search_score_threshold,\n            \"depth\": self.depth,\n        }\n\n        if self.search_filter:\n            clean_filter = {k: v for k, v in self.search_filter.items() if k and v}\n            if len(clean_filter) > 0:\n                args[\"filter\"] = clean_filter\n        return args\n\n    def get_retriever_kwargs(self):\n        search_args = self._build_search_args()\n        return {\n            \"search_type\": self._map_search_type(),\n            \"search_kwargs\": search_args,\n        }\n"},"database_ref":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Contact Points / Astra Database ID","dynamic":false,"info":"Contact points for the database (or Astra DB database ID)","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"database_ref","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"depth":{"_input_type":"IntInput","advanced":true,"display_name":"Depth of traversal","dynamic":false,"info":"The maximum depth of edges to traverse. (when using 'Traversal' or 'MMR traversal')","list":false,"list_add_label":"Add More","name":"depth","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"keyspace":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Keyspace","dynamic":false,"info":"Table Keyspace (or Astra DB namespace).","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"keyspace","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"search_filter":{"_input_type":"DictInput","advanced":true,"display_name":"Search Metadata Filter","dynamic":false,"info":"Optional dictionary of filters to apply to the search query.","list":true,"list_add_label":"Add More","name":"search_filter","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"search_score_threshold":{"_input_type":"FloatInput","advanced":true,"display_name":"Search Score Threshold","dynamic":false,"info":"Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')","list":false,"list_add_label":"Add More","name":"search_score_threshold","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.0},"search_type":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Search Type","dynamic":false,"external_options":{},"info":"Search type to use","name":"search_type","options":["Traversal","MMR traversal","Similarity","Similarity with score threshold","MMR (Max Marginal Relevance)"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Traversal"},"setup_mode":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Setup Mode","dynamic":false,"external_options":{},"info":"Configuration mode for setting up the Cassandra table, with options like 'Sync' or 'Off'.","name":"setup_mode","options":["Sync","Off"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Sync"},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"table_name":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Table Name","dynamic":false,"info":"The name of the table (or Astra DB collection) where vectors will be stored.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"table_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password / Astra DB Token","dynamic":false,"info":"User password for the database (or Astra DB token).","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"username":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Username","dynamic":false,"info":"Username for the database (leave empty for Astra DB).","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["chroma",{"Chroma":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Chroma Vector Store with search capabilities","display_name":"Chroma DB","documentation":"","edited":false,"field_order":["collection_name","persist_directory","ingest_data","search_query","should_cache_vector_store","embedding","chroma_server_cors_allow_origins","chroma_server_host","chroma_server_http_port","chroma_server_grpc_port","chroma_server_ssl_enabled","allow_duplicates","search_type","number_of_results","limit"],"frozen":false,"icon":"Chroma","legacy":false,"metadata":{"code_hash":"82d38624f19a","dependencies":{"dependencies":[{"name":"chromadb","version":"1.1.1"},{"name":"langchain_chroma","version":"0.2.6"},{"name":"typing_extensions","version":"4.15.0"},{"name":"lfx","version":null},{"name":"langchain_community","version":"0.3.21"}],"total_dependencies":5},"module":"lfx.components.chroma.chroma.ChromaVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","allow_duplicates":{"_input_type":"BoolInput","advanced":true,"display_name":"Allow Duplicates","dynamic":false,"info":"If false, will not add documents that are already in the Vector Store.","list":false,"list_add_label":"Add More","name":"allow_duplicates","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"chroma_server_cors_allow_origins":{"_input_type":"StrInput","advanced":true,"display_name":"Server CORS Allow Origins","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"chroma_server_cors_allow_origins","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"chroma_server_grpc_port":{"_input_type":"IntInput","advanced":true,"display_name":"Server gRPC Port","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"chroma_server_grpc_port","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"chroma_server_host":{"_input_type":"StrInput","advanced":true,"display_name":"Server Host","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"chroma_server_host","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"chroma_server_http_port":{"_input_type":"IntInput","advanced":true,"display_name":"Server HTTP Port","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"chroma_server_http_port","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"chroma_server_ssl_enabled":{"_input_type":"BoolInput","advanced":true,"display_name":"Server SSL Enabled","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"chroma_server_ssl_enabled","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from copy import deepcopy\nfrom typing import TYPE_CHECKING\n\nfrom chromadb.config import Settings\nfrom langchain_chroma import Chroma\nfrom typing_extensions import override\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.base.vectorstores.utils import chroma_collection_to_data\nfrom lfx.inputs.inputs import BoolInput, DropdownInput, HandleInput, IntInput, StrInput\nfrom lfx.schema.data import Data\n\nif TYPE_CHECKING:\n    from lfx.schema.dataframe import DataFrame\n\n\nclass ChromaVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"Chroma Vector Store with search capabilities.\"\"\"\n\n    display_name: str = \"Chroma DB\"\n    description: str = \"Chroma Vector Store with search capabilities\"\n    name = \"Chroma\"\n    icon = \"Chroma\"\n\n    inputs = [\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            value=\"langflow\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"Persist Directory\",\n        ),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        StrInput(\n            name=\"chroma_server_cors_allow_origins\",\n            display_name=\"Server CORS Allow Origins\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"chroma_server_host\",\n            display_name=\"Server Host\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chroma_server_http_port\",\n            display_name=\"Server HTTP Port\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chroma_server_grpc_port\",\n            display_name=\"Server gRPC Port\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"chroma_server_ssl_enabled\",\n            display_name=\"Server SSL Enabled\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"allow_duplicates\",\n            display_name=\"Allow Duplicates\",\n            advanced=True,\n            info=\"If false, will not add documents that are already in the Vector Store.\",\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            options=[\"Similarity\", \"MMR\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=10,\n        ),\n        IntInput(\n            name=\"limit\",\n            display_name=\"Limit\",\n            advanced=True,\n            info=\"Limit the number of records to compare when Allow Duplicates is False.\",\n        ),\n    ]\n\n    @override\n    @check_cached_vector_store\n    def build_vector_store(self) -> Chroma:\n        \"\"\"Builds the Chroma object.\"\"\"\n        try:\n            from chromadb import Client\n            from langchain_chroma import Chroma\n        except ImportError as e:\n            msg = \"Could not import Chroma integration package. Please install it with `pip install langchain-chroma`.\"\n            raise ImportError(msg) from e\n        # Chroma settings\n        chroma_settings = None\n        client = None\n        if self.chroma_server_host:\n            chroma_settings = Settings(\n                chroma_server_cors_allow_origins=self.chroma_server_cors_allow_origins or [],\n                chroma_server_host=self.chroma_server_host,\n                chroma_server_http_port=self.chroma_server_http_port or None,\n                chroma_server_grpc_port=self.chroma_server_grpc_port or None,\n                chroma_server_ssl_enabled=self.chroma_server_ssl_enabled,\n            )\n            client = Client(settings=chroma_settings)\n\n        # Check persist_directory and expand it if it is a relative path\n        persist_directory = self.resolve_path(self.persist_directory) if self.persist_directory is not None else None\n\n        chroma = Chroma(\n            persist_directory=persist_directory,\n            client=client,\n            embedding_function=self.embedding,\n            collection_name=self.collection_name,\n        )\n\n        self._add_documents_to_vector_store(chroma)\n        limit = int(self.limit) if self.limit is not None and str(self.limit).strip() else None\n        self.status = chroma_collection_to_data(chroma.get(limit=limit))\n        return chroma\n\n    def _add_documents_to_vector_store(self, vector_store: \"Chroma\") -> None:\n        \"\"\"Adds documents to the Vector Store.\"\"\"\n        ingest_data: list | Data | DataFrame = self.ingest_data\n        if not ingest_data:\n            self.status = \"\"\n            return\n\n        # Convert DataFrame to Data if needed using parent's method\n        ingest_data = self._prepare_ingest_data()\n\n        stored_documents_without_id = []\n        if self.allow_duplicates:\n            stored_data = []\n        else:\n            limit = int(self.limit) if self.limit is not None and str(self.limit).strip() else None\n            stored_data = chroma_collection_to_data(vector_store.get(limit=limit))\n            for value in deepcopy(stored_data):\n                del value.id\n                stored_documents_without_id.append(value)\n\n        documents = []\n        for _input in ingest_data or []:\n            if isinstance(_input, Data):\n                if _input not in stored_documents_without_id:\n                    documents.append(_input.to_lc_document())\n            else:\n                msg = \"Vector Store Inputs must be Data objects.\"\n                raise TypeError(msg)\n\n        if documents and self.embedding is not None:\n            self.log(f\"Adding {len(documents)} documents to the Vector Store.\")\n            # Filter complex metadata to prevent ChromaDB errors\n            try:\n                from langchain_community.vectorstores.utils import filter_complex_metadata\n\n                filtered_documents = filter_complex_metadata(documents)\n                vector_store.add_documents(filtered_documents)\n            except ImportError:\n                self.log(\"Warning: Could not import filter_complex_metadata. Adding documents without filtering.\")\n                vector_store.add_documents(documents)\n        else:\n            self.log(\"No documents to add to the Vector Store.\")\n"},"collection_name":{"_input_type":"StrInput","advanced":false,"display_name":"Collection Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"langflow"},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"limit":{"_input_type":"IntInput","advanced":true,"display_name":"Limit","dynamic":false,"info":"Limit the number of records to compare when Allow Duplicates is False.","list":false,"list_add_label":"Add More","name":"limit","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":10},"persist_directory":{"_input_type":"StrInput","advanced":false,"display_name":"Persist Directory","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"persist_directory","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"search_type":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Search Type","dynamic":false,"external_options":{},"info":"","name":"search_type","options":["Similarity","MMR"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Similarity"},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false}}],["cleanlab",{"CleanlabEvaluator":{"base_classes":["float","Message","number"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Evaluates any LLM response using Cleanlab and outputs trust score and explanation.","display_name":"Cleanlab Evaluator","documentation":"","edited":false,"field_order":["system_prompt","prompt","response","api_key","model","quality_preset"],"frozen":false,"icon":"Cleanlab","legacy":false,"metadata":{"code_hash":"06963c804ffe","dependencies":{"dependencies":[{"name":"cleanlab_tlm","version":"1.1.36"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.cleanlab.cleanlab_evaluator.CleanlabEvaluator"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Response","group_outputs":false,"method":"pass_response","name":"response_passthrough","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Trust Score","group_outputs":false,"method":"get_score","name":"score","selected":"number","tool_mode":true,"types":["number","float"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Explanation","group_outputs":false,"method":"get_explanation","name":"explanation","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Cleanlab API Key","dynamic":false,"info":"Your Cleanlab API key.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from cleanlab_tlm import TLM\n\nfrom lfx.custom import Component\nfrom lfx.io import (\n    DropdownInput,\n    MessageTextInput,\n    Output,\n    SecretStrInput,\n)\nfrom lfx.schema.message import Message\n\n\nclass CleanlabEvaluator(Component):\n    \"\"\"A component that evaluates the trustworthiness of LLM responses using Cleanlab.\n\n    This component takes a prompt and response pair, along with optional system instructions,\n    and uses Cleanlab's evaluation algorithms to generate a trust score and explanation.\n\n    Inputs:\n        - system_prompt (MessageTextInput): Optional system-level instructions prepended to the user prompt.\n        - prompt (MessageTextInput): The user's prompt or query sent to the LLM.\n        - response (MessageTextInput): The response generated by the LLM to be evaluated. This should come from the\n          LLM component, i.e. OpenAI, Gemini, etc.\n        - api_key (SecretStrInput): Your Cleanlab API key.\n        - model (DropdownInput): The model used by Cleanlab to evaluate the response (can differ from the\n          generation model).\n        - quality_preset (DropdownInput): Tradeoff setting for accuracy vs. speed and cost. Higher presets are\n          slower but more accurate.\n\n    Outputs:\n        - response_passthrough (Message): The original response, passed through for downstream use.\n        - score (number): A float between 0 and 1 indicating Cleanlab's trustworthiness score for the response.\n        - explanation (Message): A textual explanation of why the response received its score.\n\n    This component works well in conjunction with the CleanlabRemediator to create a complete trust evaluation\n    and remediation pipeline.\n\n    More details on the evaluation metrics can be found here: https://help.cleanlab.ai/tlm/tutorials/tlm/\n    \"\"\"\n\n    display_name = \"Cleanlab Evaluator\"\n    description = \"Evaluates any LLM response using Cleanlab and outputs trust score and explanation.\"\n    icon = \"Cleanlab\"\n    name = \"CleanlabEvaluator\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"system_prompt\",\n            display_name=\"System Message\",\n            info=\"System-level instructions prepended to the user query.\",\n            value=\"\",\n        ),\n        MessageTextInput(\n            name=\"prompt\",\n            display_name=\"Prompt\",\n            info=\"The user's query to the model.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"response\",\n            display_name=\"Response\",\n            info=\"The response to the user's query.\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Cleanlab API Key\",\n            info=\"Your Cleanlab API key.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Cleanlab Evaluation Model\",\n            options=[\n                \"gpt-4.1\",\n                \"gpt-4.1-mini\",\n                \"gpt-4.1-nano\",\n                \"o4-mini\",\n                \"o3\",\n                \"gpt-4.5-preview\",\n                \"gpt-4o-mini\",\n                \"gpt-4o\",\n                \"o3-mini\",\n                \"o1\",\n                \"o1-mini\",\n                \"gpt-4\",\n                \"gpt-3.5-turbo-16k\",\n                \"claude-3.7-sonnet\",\n                \"claude-3.5-sonnet-v2\",\n                \"claude-3.5-sonnet\",\n                \"claude-3.5-haiku\",\n                \"claude-3-haiku\",\n                \"nova-micro\",\n                \"nova-lite\",\n                \"nova-pro\",\n            ],\n            info=\"The model Cleanlab uses to evaluate the response. This does NOT need to be the same model that \"\n            \"generated the response.\",\n            value=\"gpt-4o-mini\",\n            required=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"quality_preset\",\n            display_name=\"Quality Preset\",\n            options=[\"base\", \"low\", \"medium\", \"high\", \"best\"],\n            value=\"medium\",\n            info=\"This determines the accuracy, latency, and cost of the evaluation. Higher quality is generally \"\n            \"slower but more accurate.\",\n            required=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Response\",\n            name=\"response_passthrough\",\n            method=\"pass_response\",\n            types=[\"Message\"],\n        ),\n        Output(display_name=\"Trust Score\", name=\"score\", method=\"get_score\", types=[\"number\"]),\n        Output(\n            display_name=\"Explanation\",\n            name=\"explanation\",\n            method=\"get_explanation\",\n            types=[\"Message\"],\n        ),\n    ]\n\n    def _evaluate_once(self):\n        if not hasattr(self, \"_cached_result\"):\n            full_prompt = f\"{self.system_prompt}\\n\\n{self.prompt}\" if self.system_prompt else self.prompt\n            tlm = TLM(\n                api_key=self.api_key,\n                options={\"log\": [\"explanation\"], \"model\": self.model},\n                quality_preset=self.quality_preset,\n            )\n            self._cached_result = tlm.get_trustworthiness_score(full_prompt, self.response)\n        return self._cached_result\n\n    def get_score(self) -> float:\n        result = self._evaluate_once()\n        score = result.get(\"trustworthiness_score\", 0.0)\n        self.status = f\"Trust score: {score:.2f}\"\n        return score\n\n    def get_explanation(self) -> Message:\n        result = self._evaluate_once()\n        explanation = result.get(\"log\", {}).get(\"explanation\", \"No explanation returned.\")\n        return Message(text=explanation)\n\n    def pass_response(self) -> Message:\n        self.status = \"Passing through response.\"\n        return Message(text=self.response)\n"},"model":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Cleanlab Evaluation Model","dynamic":false,"external_options":{},"info":"The model Cleanlab uses to evaluate the response. This does NOT need to be the same model that generated the response.","name":"model","options":["gpt-4.1","gpt-4.1-mini","gpt-4.1-nano","o4-mini","o3","gpt-4.5-preview","gpt-4o-mini","gpt-4o","o3-mini","o1","o1-mini","gpt-4","gpt-3.5-turbo-16k","claude-3.7-sonnet","claude-3.5-sonnet-v2","claude-3.5-sonnet","claude-3.5-haiku","claude-3-haiku","nova-micro","nova-lite","nova-pro"],"options_metadata":[],"placeholder":"","required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"gpt-4o-mini"},"prompt":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Prompt","dynamic":false,"info":"The user's query to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"prompt","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"quality_preset":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Quality Preset","dynamic":false,"external_options":{},"info":"This determines the accuracy, latency, and cost of the evaluation. Higher quality is generally slower but more accurate.","name":"quality_preset","options":["base","low","medium","high","best"],"options_metadata":[],"placeholder":"","required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"medium"},"response":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Response","dynamic":false,"info":"The response to the user's query.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"response","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"system_prompt":{"_input_type":"MessageTextInput","advanced":false,"display_name":"System Message","dynamic":false,"info":"System-level instructions prepended to the user query.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"system_prompt","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"CleanlabRAGEvaluator":{"base_classes":["Data","dict","float","Message","number"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Evaluates context, query, and response from a RAG pipeline using Cleanlab and outputs trust metrics.","display_name":"Cleanlab RAG Evaluator","documentation":"","edited":false,"field_order":["api_key","model","quality_preset","context","query","response","run_context_sufficiency","run_response_groundedness","run_response_helpfulness","run_query_ease"],"frozen":false,"icon":"Cleanlab","legacy":false,"metadata":{"code_hash":"f48b57ff7ca3","dependencies":{"dependencies":[{"name":"cleanlab_tlm","version":"1.1.36"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.cleanlab.cleanlab_rag_evaluator.CleanlabRAGEvaluator"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Response","group_outputs":false,"method":"pass_response","name":"response_passthrough","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Trust Score","group_outputs":false,"method":"get_trust_score","name":"trust_score","selected":"number","tool_mode":true,"types":["number","float"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Explanation","group_outputs":false,"method":"get_trust_explanation","name":"trust_explanation","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Other Evals","group_outputs":false,"method":"get_other_scores","name":"other_scores","selected":"Data","tool_mode":true,"types":["Data","dict"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Evaluation Summary","group_outputs":false,"method":"get_evaluation_summary","name":"evaluation_summary","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Cleanlab API Key","dynamic":false,"info":"Your Cleanlab API key.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from cleanlab_tlm import TrustworthyRAG, get_default_evals\n\nfrom lfx.custom import Component\nfrom lfx.io import (\n    BoolInput,\n    DropdownInput,\n    MessageTextInput,\n    Output,\n    SecretStrInput,\n)\nfrom lfx.schema.message import Message\n\n\nclass CleanlabRAGEvaluator(Component):\n    \"\"\"A component that evaluates the quality of RAG (Retrieval-Augmented Generation) outputs using Cleanlab.\n\n    This component takes a query, retrieved context, and generated response from a RAG pipeline,\n    and uses Cleanlab's evaluation algorithms to assess various aspects of the RAG system's performance.\n\n    The component can evaluate:\n    - Overall trustworthiness of the LLM generated response\n    - Context sufficiency (whether the retrieved context contains information needed to answer the query)\n    - Response groundedness (whether the response is supported directly by the context)\n    - Response helpfulness (whether the response effectively addresses the user's query)\n    - Query ease (whether the user query seems easy for an AI system to properly handle, useful to diagnose\n      queries that are: complex, vague, tricky, or disgruntled-sounding)\n\n    Outputs:\n        - Trust Score: A score between 0-1 corresponding to the trustworthiness of the response. A higher score\n          indicates a higher confidence that the response is correct/good.\n        - Explanation: An LLM generated explanation of the trustworthiness assessment\n        - Other Evals: Additional evaluation metrics for selected evaluation types in the \"Controls\" tab\n        - Evaluation Summary: A comprehensive summary of context, query, response, and selected evaluation results\n\n    This component works well in conjunction with the CleanlabRemediator to create a complete trust evaluation\n    and remediation pipeline.\n\n    More details on the evaluation metrics can be found here: https://help.cleanlab.ai/tlm/use-cases/tlm_rag/\n    \"\"\"\n\n    display_name = \"Cleanlab RAG Evaluator\"\n    description = \"Evaluates context, query, and response from a RAG pipeline using Cleanlab and outputs trust metrics.\"\n    icon = \"Cleanlab\"\n    name = \"CleanlabRAGEvaluator\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Cleanlab API Key\",\n            info=\"Your Cleanlab API key.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Cleanlab Evaluation Model\",\n            options=[\n                \"gpt-4.1\",\n                \"gpt-4.1-mini\",\n                \"gpt-4.1-nano\",\n                \"o4-mini\",\n                \"o3\",\n                \"gpt-4.5-preview\",\n                \"gpt-4o-mini\",\n                \"gpt-4o\",\n                \"o3-mini\",\n                \"o1\",\n                \"o1-mini\",\n                \"gpt-4\",\n                \"gpt-3.5-turbo-16k\",\n                \"claude-3.7-sonnet\",\n                \"claude-3.5-sonnet-v2\",\n                \"claude-3.5-sonnet\",\n                \"claude-3.5-haiku\",\n                \"claude-3-haiku\",\n                \"nova-micro\",\n                \"nova-lite\",\n                \"nova-pro\",\n            ],\n            info=\"The model Cleanlab uses to evaluate the context, query, and response. This does NOT need to be \"\n            \"the same model that generated the response.\",\n            value=\"gpt-4o-mini\",\n            required=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"quality_preset\",\n            display_name=\"Quality Preset\",\n            options=[\"base\", \"low\", \"medium\"],\n            value=\"medium\",\n            info=\"This determines the accuracy, latency, and cost of the evaluation. Higher quality is generally \"\n            \"slower but more accurate.\",\n            required=True,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"context\",\n            display_name=\"Context\",\n            info=\"The context retrieved for the given query.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"Query\",\n            info=\"The user's query.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"response\",\n            display_name=\"Response\",\n            info=\"The response generated by the LLM.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"run_context_sufficiency\",\n            display_name=\"Run Context Sufficiency\",\n            value=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"run_response_groundedness\",\n            display_name=\"Run Response Groundedness\",\n            value=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"run_response_helpfulness\",\n            display_name=\"Run Response Helpfulness\",\n            value=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"run_query_ease\",\n            display_name=\"Run Query Ease\",\n            value=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Response\", name=\"response_passthrough\", method=\"pass_response\", types=[\"Message\"]),\n        Output(display_name=\"Trust Score\", name=\"trust_score\", method=\"get_trust_score\", types=[\"number\"]),\n        Output(display_name=\"Explanation\", name=\"trust_explanation\", method=\"get_trust_explanation\", types=[\"Message\"]),\n        Output(display_name=\"Other Evals\", name=\"other_scores\", method=\"get_other_scores\", types=[\"Data\"]),\n        Output(\n            display_name=\"Evaluation Summary\",\n            name=\"evaluation_summary\",\n            method=\"get_evaluation_summary\",\n            types=[\"Message\"],\n        ),\n    ]\n\n    def _evaluate_once(self):\n        if not hasattr(self, \"_cached_result\"):\n            try:\n                self.status = \"Configuring selected evals...\"\n                default_evals = get_default_evals()\n                enabled_names = []\n                if self.run_context_sufficiency:\n                    enabled_names.append(\"context_sufficiency\")\n                if self.run_response_groundedness:\n                    enabled_names.append(\"response_groundedness\")\n                if self.run_response_helpfulness:\n                    enabled_names.append(\"response_helpfulness\")\n                if self.run_query_ease:\n                    enabled_names.append(\"query_ease\")\n\n                selected_evals = [e for e in default_evals if e.name in enabled_names]\n\n                validator = TrustworthyRAG(\n                    api_key=self.api_key,\n                    quality_preset=self.quality_preset,\n                    options={\"log\": [\"explanation\"], \"model\": self.model},\n                    evals=selected_evals,\n                )\n\n                self.status = f\"Running evals: {[e.name for e in selected_evals]}\"\n                self._cached_result = validator.score(\n                    query=self.query,\n                    context=self.context,\n                    response=self.response,\n                )\n                self.status = \"Evaluation complete.\"\n\n            except Exception as e:  # noqa: BLE001\n                self.status = f\"Evaluation failed: {e!s}\"\n                self._cached_result = {}\n        return self._cached_result\n\n    def pass_response(self) -> Message:\n        self.status = \"Passing through response.\"\n        return Message(text=self.response)\n\n    def get_trust_score(self) -> float:\n        score = self._evaluate_once().get(\"trustworthiness\", {}).get(\"score\", 0.0)\n        self.status = f\"Trust Score: {score:.3f}\"\n        return score\n\n    def get_trust_explanation(self) -> Message:\n        explanation = self._evaluate_once().get(\"trustworthiness\", {}).get(\"log\", {}).get(\"explanation\", \"\")\n        self.status = \"Trust explanation extracted.\"\n        return Message(text=explanation)\n\n    def get_other_scores(self) -> dict:\n        result = self._evaluate_once()\n\n        selected = {\n            \"context_sufficiency\": self.run_context_sufficiency,\n            \"response_groundedness\": self.run_response_groundedness,\n            \"response_helpfulness\": self.run_response_helpfulness,\n            \"query_ease\": self.run_query_ease,\n        }\n\n        filtered_scores = {key: result[key][\"score\"] for key, include in selected.items() if include and key in result}\n\n        self.status = f\"{len(filtered_scores)} other evals returned.\"\n        return filtered_scores\n\n    def get_evaluation_summary(self) -> Message:\n        result = self._evaluate_once()\n\n        query_text = self.query.strip()\n        context_text = self.context.strip()\n        response_text = self.response.strip()\n\n        trust = result.get(\"trustworthiness\", {}).get(\"score\", 0.0)\n        trust_exp = result.get(\"trustworthiness\", {}).get(\"log\", {}).get(\"explanation\", \"\")\n\n        selected = {\n            \"context_sufficiency\": self.run_context_sufficiency,\n            \"response_groundedness\": self.run_response_groundedness,\n            \"response_helpfulness\": self.run_response_helpfulness,\n            \"query_ease\": self.run_query_ease,\n        }\n\n        other_scores = {key: result[key][\"score\"] for key, include in selected.items() if include and key in result}\n\n        metrics = f\"Trustworthiness: {trust:.3f}\"\n        if trust_exp:\n            metrics += f\"\\nExplanation: {trust_exp}\"\n        if other_scores:\n            metrics += \"\\n\" + \"\\n\".join(f\"{k.replace('_', ' ').title()}: {v:.3f}\" for k, v in other_scores.items())\n\n        summary = (\n            f\"Query:\\n{query_text}\\n\"\n            \"-----\\n\"\n            f\"Context:\\n{context_text}\\n\"\n            \"-----\\n\"\n            f\"Response:\\n{response_text}\\n\"\n            \"------------------------------\\n\"\n            f\"{metrics}\"\n        )\n\n        self.status = \"Evaluation summary built.\"\n        return Message(text=summary)\n"},"context":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Context","dynamic":false,"info":"The context retrieved for the given query.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"context","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"model":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Cleanlab Evaluation Model","dynamic":false,"external_options":{},"info":"The model Cleanlab uses to evaluate the context, query, and response. This does NOT need to be the same model that generated the response.","name":"model","options":["gpt-4.1","gpt-4.1-mini","gpt-4.1-nano","o4-mini","o3","gpt-4.5-preview","gpt-4o-mini","gpt-4o","o3-mini","o1","o1-mini","gpt-4","gpt-3.5-turbo-16k","claude-3.7-sonnet","claude-3.5-sonnet-v2","claude-3.5-sonnet","claude-3.5-haiku","claude-3-haiku","nova-micro","nova-lite","nova-pro"],"options_metadata":[],"placeholder":"","required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"gpt-4o-mini"},"quality_preset":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Quality Preset","dynamic":false,"external_options":{},"info":"This determines the accuracy, latency, and cost of the evaluation. Higher quality is generally slower but more accurate.","name":"quality_preset","options":["base","low","medium"],"options_metadata":[],"placeholder":"","required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"medium"},"query":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Query","dynamic":false,"info":"The user's query.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"query","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"response":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Response","dynamic":false,"info":"The response generated by the LLM.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"response","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"run_context_sufficiency":{"_input_type":"BoolInput","advanced":true,"display_name":"Run Context Sufficiency","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"run_context_sufficiency","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"run_query_ease":{"_input_type":"BoolInput","advanced":true,"display_name":"Run Query Ease","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"run_query_ease","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"run_response_groundedness":{"_input_type":"BoolInput","advanced":true,"display_name":"Run Response Groundedness","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"run_response_groundedness","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"run_response_helpfulness":{"_input_type":"BoolInput","advanced":true,"display_name":"Run Response Helpfulness","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"run_response_helpfulness","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false},"CleanlabRemediator":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Remediates an untrustworthy response based on trust score from the Cleanlab Evaluator, score threshold, and message handling settings.","display_name":"Cleanlab Remediator","documentation":"","edited":false,"field_order":["response","score","explanation","threshold","show_untrustworthy_response","untrustworthy_warning_text","fallback_text"],"frozen":false,"icon":"Cleanlab","legacy":false,"metadata":{"code_hash":"a5b19d338991","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.cleanlab.cleanlab_remediator.CleanlabRemediator"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Remediated Message","group_outputs":false,"method":"remediate_response","name":"remediated_response","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom import Component\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.io import BoolInput, FloatInput, HandleInput, MessageTextInput, Output, PromptInput\nfrom lfx.schema.message import Message\n\n\nclass CleanlabRemediator(Component):\n    \"\"\"Remediates potentially untrustworthy LLM responses based on trust scores computed by the Cleanlab Evaluator.\n\n    This component takes a response and its associated trust score,\n    and applies remediation strategies based on configurable thresholds and settings.\n\n    Inputs:\n        - response (MessageTextInput): The original LLM-generated response to be evaluated and possibly remediated.\n          The CleanlabEvaluator passes this response through.\n        - score (HandleInput): The trust score output from CleanlabEvaluator (expected to be a float between 0 and 1).\n        - explanation (MessageTextInput): Optional textual explanation for the trust score, to be included in the\n          output.\n        - threshold (Input[float]): Minimum trust score required to accept the response. If the score is lower, the\n          response is remediated.\n        - show_untrustworthy_response (BoolInput): If true, returns the original response with a warning; if false,\n          returns fallback text.\n        - untrustworthy_warning_text (PromptInput): Text warning to append to responses deemed untrustworthy (when\n          showing them).\n        - fallback_text (PromptInput): Replacement message returned if the response is untrustworthy and should be\n          hidden.\n\n    Outputs:\n        - remediated_response (Message): Either:\n            • the original response,\n            • the original response with appended warning, or\n            • the fallback response,\n          depending on the trust score and configuration.\n\n    This component is typically used downstream of CleanlabEvaluator or CleanlabRagValidator\n    to take appropriate action on low-trust responses and inform users accordingly.\n    \"\"\"\n\n    display_name = \"Cleanlab Remediator\"\n    description = (\n        \"Remediates an untrustworthy response based on trust score from the Cleanlab Evaluator, \"\n        \"score threshold, and message handling settings.\"\n    )\n    icon = \"Cleanlab\"\n    name = \"CleanlabRemediator\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"response\",\n            display_name=\"Response\",\n            info=\"The response to the user's query.\",\n            required=True,\n        ),\n        HandleInput(\n            name=\"score\",\n            display_name=\"Trust Score\",\n            info=\"The trustworthiness score output from the Cleanlab Evaluator.\",\n            input_types=[\"number\"],\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"explanation\",\n            display_name=\"Explanation\",\n            info=\"The explanation from the Cleanlab Evaluator.\",\n            required=False,\n        ),\n        FloatInput(\n            name=\"threshold\",\n            display_name=\"Threshold\",\n            field_type=\"float\",\n            value=0.7,\n            range_spec=RangeSpec(min=0.0, max=1.0, step=0.05),\n            info=\"Minimum score required to show the response unmodified. Reponses with scores above this threshold \"\n            \"are considered trustworthy. Reponses with scores below this threshold are considered untrustworthy and \"\n            \"will be remediated based on the settings below.\",\n            required=True,\n            show=True,\n        ),\n        BoolInput(\n            name=\"show_untrustworthy_response\",\n            display_name=\"Show Untrustworthy Response\",\n            info=\"If enabled, and the trust score is below the threshold, the original response is shown with the \"\n            \"added warning. If disabled, and the trust score is below the threshold, the fallback answer is returned.\",\n            value=True,\n        ),\n        PromptInput(\n            name=\"untrustworthy_warning_text\",\n            display_name=\"Warning for Untrustworthy Response\",\n            info=\"Warning to append to the response if Show Untrustworthy Response is enabled and trust score is \"\n            \"below the threshold.\",\n            value=\"⚠️ WARNING: The following response is potentially untrustworthy.\",\n        ),\n        PromptInput(\n            name=\"fallback_text\",\n            display_name=\"Fallback Answer\",\n            info=\"Response returned if the trust score is below the threshold and 'Show Untrustworthy Response' is \"\n            \"disabled.\",\n            value=\"Based on the available information, I cannot provide a complete answer to this question.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Remediated Message\",\n            name=\"remediated_response\",\n            method=\"remediate_response\",\n            types=[\"Message\"],\n        ),\n    ]\n\n    def remediate_response(self) -> Message:\n        if self.score >= self.threshold:\n            self.status = f\"Score {self.score:.2f} ≥ threshold {self.threshold:.2f} → accepted\"\n            return Message(\n                text=f\"{self.response}\\n\\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\n\\n**Trust Score:** {self.score:.2f}\"\n            )\n\n        self.status = f\"Score {self.score:.2f} < threshold {self.threshold:.2f} → flagged\"\n\n        if self.show_untrustworthy_response:\n            parts = [\n                self.response,\n                \"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\",\n                f\"**{self.untrustworthy_warning_text.strip()}**\",\n                f\"**Trust Score:** {self.score:.2f}\",\n            ]\n            if self.explanation:\n                parts.append(f\"**Explanation:** {self.explanation}\")\n            return Message(text=\"\\n\\n\".join(parts))\n\n        return Message(text=self.fallback_text)\n"},"explanation":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Explanation","dynamic":false,"info":"The explanation from the Cleanlab Evaluator.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"explanation","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"fallback_text":{"_input_type":"PromptInput","advanced":false,"display_name":"Fallback Answer","dynamic":false,"info":"Response returned if the trust score is below the threshold and 'Show Untrustworthy Response' is disabled.","list":false,"list_add_label":"Add More","name":"fallback_text","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"prompt","value":"Based on the available information, I cannot provide a complete answer to this question."},"response":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Response","dynamic":false,"info":"The response to the user's query.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"response","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"score":{"_input_type":"HandleInput","advanced":false,"display_name":"Trust Score","dynamic":false,"info":"The trustworthiness score output from the Cleanlab Evaluator.","input_types":["number"],"list":false,"list_add_label":"Add More","name":"score","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"show_untrustworthy_response":{"_input_type":"BoolInput","advanced":false,"display_name":"Show Untrustworthy Response","dynamic":false,"info":"If enabled, and the trust score is below the threshold, the original response is shown with the added warning. If disabled, and the trust score is below the threshold, the fallback answer is returned.","list":false,"list_add_label":"Add More","name":"show_untrustworthy_response","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"threshold":{"_input_type":"FloatInput","advanced":false,"display_name":"Threshold","dynamic":false,"info":"Minimum score required to show the response unmodified. Reponses with scores above this threshold are considered trustworthy. Reponses with scores below this threshold are considered untrustworthy and will be remediated based on the settings below.","list":false,"list_add_label":"Add More","name":"threshold","placeholder":"","range_spec":{"max":1.0,"min":0.0,"step":0.05,"step_type":"float"},"required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.7},"untrustworthy_warning_text":{"_input_type":"PromptInput","advanced":false,"display_name":"Warning for Untrustworthy Response","dynamic":false,"info":"Warning to append to the response if Show Untrustworthy Response is enabled and trust score is below the threshold.","list":false,"list_add_label":"Add More","name":"untrustworthy_warning_text","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"prompt","value":"⚠️ WARNING: The following response is potentially untrustworthy."}},"tool_mode":false}}],["clickhouse",{"Clickhouse":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"ClickHouse Vector Store with search capabilities","display_name":"ClickHouse","documentation":"","edited":false,"field_order":["host","port","database","table","username","password","index_type","metric","secure","index_param","index_query_params","ingest_data","search_query","should_cache_vector_store","embedding","number_of_results","score_threshold"],"frozen":false,"icon":"Clickhouse","legacy":false,"metadata":{"code_hash":"ab991e83da44","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null},{"name":"clickhouse_connect","version":"0.7.19"}],"total_dependencies":3},"module":"lfx.components.clickhouse.clickhouse.ClickhouseVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_community.vectorstores import Clickhouse, ClickhouseSettings\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.inputs.inputs import BoolInput, FloatInput\nfrom lfx.io import (\n    DictInput,\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass ClickhouseVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"ClickHouse\"\n    description = \"ClickHouse Vector Store with search capabilities\"\n    name = \"Clickhouse\"\n    icon = \"Clickhouse\"\n\n    inputs = [\n        StrInput(name=\"host\", display_name=\"hostname\", required=True, value=\"localhost\"),\n        IntInput(name=\"port\", display_name=\"port\", required=True, value=8123),\n        StrInput(name=\"database\", display_name=\"database\", required=True),\n        StrInput(name=\"table\", display_name=\"Table name\", required=True),\n        StrInput(name=\"username\", display_name=\"The ClickHouse user name.\", required=True),\n        SecretStrInput(name=\"password\", display_name=\"Clickhouse Password\", required=True),\n        DropdownInput(\n            name=\"index_type\",\n            display_name=\"index_type\",\n            options=[\"annoy\", \"vector_similarity\"],\n            info=\"Type of the index.\",\n            value=\"annoy\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"metric\",\n            display_name=\"metric\",\n            options=[\"angular\", \"euclidean\", \"manhattan\", \"hamming\", \"dot\"],\n            info=\"Metric to compute distance.\",\n            value=\"angular\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"secure\",\n            display_name=\"Use https/TLS. This overrides inferred values from the interface or port arguments.\",\n            value=False,\n            advanced=True,\n        ),\n        StrInput(name=\"index_param\", display_name=\"Param of the index\", value=\"100,'L2Distance'\", advanced=True),\n        DictInput(name=\"index_query_params\", display_name=\"index query params\", advanced=True),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n        FloatInput(name=\"score_threshold\", display_name=\"Score threshold\", advanced=True),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> Clickhouse:\n        try:\n            import clickhouse_connect\n        except ImportError as e:\n            msg = (\n                \"Failed to import ClickHouse dependencies. \"\n                \"Install it using `uv pip install langflow[clickhouse-connect] --pre`\"\n            )\n            raise ImportError(msg) from e\n\n        try:\n            client = clickhouse_connect.get_client(\n                host=self.host, port=self.port, username=self.username, password=self.password\n            )\n            client.command(\"SELECT 1\")\n        except Exception as e:\n            msg = f\"Failed to connect to Clickhouse: {e}\"\n            raise ValueError(msg) from e\n\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        kwargs = {}\n        if self.index_param:\n            kwargs[\"index_param\"] = self.index_param.split(\",\")\n        if self.index_query_params:\n            kwargs[\"index_query_params\"] = self.index_query_params\n\n        settings = ClickhouseSettings(\n            table=self.table,\n            database=self.database,\n            host=self.host,\n            index_type=self.index_type,\n            metric=self.metric,\n            password=self.password,\n            port=self.port,\n            secure=self.secure,\n            username=self.username,\n            **kwargs,\n        )\n        if documents:\n            clickhouse_vs = Clickhouse.from_documents(documents=documents, embedding=self.embedding, config=settings)\n\n        else:\n            clickhouse_vs = Clickhouse(embedding=self.embedding, config=settings)\n\n        return clickhouse_vs\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            kwargs = {}\n            if self.score_threshold:\n                kwargs[\"score_threshold\"] = self.score_threshold\n\n            docs = vector_store.similarity_search(query=self.search_query, k=self.number_of_results, **kwargs)\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n"},"database":{"_input_type":"StrInput","advanced":false,"display_name":"database","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"database","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"host":{"_input_type":"StrInput","advanced":false,"display_name":"hostname","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"host","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"localhost"},"index_param":{"_input_type":"StrInput","advanced":true,"display_name":"Param of the index","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"index_param","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"100,'L2Distance'"},"index_query_params":{"_input_type":"DictInput","advanced":true,"display_name":"index query params","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"index_query_params","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"index_type":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"index_type","dynamic":false,"external_options":{},"info":"Type of the index.","name":"index_type","options":["annoy","vector_similarity"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"annoy"},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"metric":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"metric","dynamic":false,"external_options":{},"info":"Metric to compute distance.","name":"metric","options":["angular","euclidean","manhattan","hamming","dot"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"angular"},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Clickhouse Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"port":{"_input_type":"IntInput","advanced":false,"display_name":"port","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"port","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":8123},"score_threshold":{"_input_type":"FloatInput","advanced":true,"display_name":"Score threshold","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"score_threshold","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":""},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"secure":{"_input_type":"BoolInput","advanced":true,"display_name":"Use https/TLS. This overrides inferred values from the interface or port arguments.","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"secure","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"table":{"_input_type":"StrInput","advanced":false,"display_name":"Table name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"table","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"The ClickHouse user name.","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["cloudflare",{"CloudflareWorkersAIEmbeddings":{"base_classes":["Embeddings"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate embeddings using Cloudflare Workers AI models.","display_name":"Cloudflare Workers AI Embeddings","documentation":"https://python.langchain.com/docs/integrations/text_embedding/cloudflare_workersai/","edited":false,"field_order":["account_id","api_token","model_name","strip_new_lines","batch_size","api_base_url","headers"],"frozen":false,"icon":"Cloudflare","legacy":false,"metadata":{"code_hash":"1ea6e4857c14","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":2},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.cloudflare.cloudflare.CloudflareWorkersAIEmbeddingsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Embeddings","group_outputs":false,"method":"build_embeddings","name":"embeddings","selected":"Embeddings","tool_mode":true,"types":["Embeddings"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","account_id":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Cloudflare account ID","dynamic":false,"info":"Find your account ID https://developers.cloudflare.com/fundamentals/setup/find-account-and-zone-ids/#find-account-id-workers-and-pages","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"account_id","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"api_base_url":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Cloudflare API base URL","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"api_base_url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"https://api.cloudflare.com/client/v4/accounts"},"api_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Cloudflare API token","dynamic":false,"info":"Create an API token https://developers.cloudflare.com/fundamentals/api/get-started/create-token/","input_types":[],"load_from_db":true,"name":"api_token","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"batch_size":{"_input_type":"IntInput","advanced":true,"display_name":"Batch Size","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"batch_size","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":50},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_community.embeddings.cloudflare_workersai import CloudflareWorkersAIEmbeddings\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import Embeddings\nfrom lfx.io import BoolInput, DictInput, IntInput, MessageTextInput, Output, SecretStrInput\n\n\nclass CloudflareWorkersAIEmbeddingsComponent(LCModelComponent):\n    display_name: str = \"Cloudflare Workers AI Embeddings\"\n    description: str = \"Generate embeddings using Cloudflare Workers AI models.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/text_embedding/cloudflare_workersai/\"\n    icon = \"Cloudflare\"\n    name = \"CloudflareWorkersAIEmbeddings\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"account_id\",\n            display_name=\"Cloudflare account ID\",\n            info=\"Find your account ID https://developers.cloudflare.com/fundamentals/setup/find-account-and-zone-ids/#find-account-id-workers-and-pages\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_token\",\n            display_name=\"Cloudflare API token\",\n            info=\"Create an API token https://developers.cloudflare.com/fundamentals/api/get-started/create-token/\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            info=\"List of supported models https://developers.cloudflare.com/workers-ai/models/#text-embeddings\",\n            required=True,\n            value=\"@cf/baai/bge-base-en-v1.5\",\n        ),\n        BoolInput(\n            name=\"strip_new_lines\",\n            display_name=\"Strip New Lines\",\n            advanced=True,\n            value=True,\n        ),\n        IntInput(\n            name=\"batch_size\",\n            display_name=\"Batch Size\",\n            advanced=True,\n            value=50,\n        ),\n        MessageTextInput(\n            name=\"api_base_url\",\n            display_name=\"Cloudflare API base URL\",\n            advanced=True,\n            value=\"https://api.cloudflare.com/client/v4/accounts\",\n        ),\n        DictInput(\n            name=\"headers\",\n            display_name=\"Headers\",\n            info=\"Additional request headers\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        try:\n            embeddings = CloudflareWorkersAIEmbeddings(\n                account_id=self.account_id,\n                api_base_url=self.api_base_url,\n                api_token=self.api_token,\n                batch_size=self.batch_size,\n                headers=self.headers,\n                model_name=self.model_name,\n                strip_new_lines=self.strip_new_lines,\n            )\n        except Exception as e:\n            msg = f\"Could not connect to CloudflareWorkersAIEmbeddings API: {e!s}\"\n            raise ValueError(msg) from e\n\n        return embeddings\n"},"headers":{"_input_type":"DictInput","advanced":true,"display_name":"Headers","dynamic":false,"info":"Additional request headers","list":true,"list_add_label":"Add More","name":"headers","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"model_name":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Model Name","dynamic":false,"info":"List of supported models https://developers.cloudflare.com/workers-ai/models/#text-embeddings","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"model_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"@cf/baai/bge-base-en-v1.5"},"strip_new_lines":{"_input_type":"BoolInput","advanced":true,"display_name":"Strip New Lines","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"strip_new_lines","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false}}],["cohere",{"CohereEmbeddings":{"base_classes":["Embeddings"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate embeddings using Cohere models.","display_name":"Cohere Embeddings","documentation":"","edited":false,"field_order":["api_key","model_name","truncate","max_retries","user_agent","request_timeout"],"frozen":false,"icon":"Cohere","legacy":false,"metadata":{"code_hash":"9c0f413a2c64","dependencies":{"dependencies":[{"name":"cohere","version":"5.18.0"},{"name":"langchain_cohere","version":"0.3.3"},{"name":"lfx","version":null}],"total_dependencies":3},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.cohere.cohere_embeddings.CohereEmbeddingsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Embeddings","group_outputs":false,"method":"build_embeddings","name":"embeddings","selected":"Embeddings","tool_mode":true,"types":["Embeddings"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Cohere API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nimport cohere\nfrom langchain_cohere import CohereEmbeddings\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import Embeddings\nfrom lfx.io import DropdownInput, FloatInput, IntInput, MessageTextInput, Output, SecretStrInput\n\nHTTP_STATUS_OK = 200\n\n\nclass CohereEmbeddingsComponent(LCModelComponent):\n    display_name = \"Cohere Embeddings\"\n    description = \"Generate embeddings using Cohere models.\"\n    icon = \"Cohere\"\n    name = \"CohereEmbeddings\"\n\n    inputs = [\n        SecretStrInput(name=\"api_key\", display_name=\"Cohere API Key\", required=True, real_time_refresh=True),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model\",\n            advanced=False,\n            options=[\n                \"embed-english-v2.0\",\n                \"embed-multilingual-v2.0\",\n                \"embed-english-light-v2.0\",\n                \"embed-multilingual-light-v2.0\",\n            ],\n            value=\"embed-english-v2.0\",\n            refresh_button=True,\n            combobox=True,\n        ),\n        MessageTextInput(name=\"truncate\", display_name=\"Truncate\", advanced=True),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        MessageTextInput(name=\"user_agent\", display_name=\"User Agent\", advanced=True, value=\"langchain\"),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        data = None\n        try:\n            data = CohereEmbeddings(\n                cohere_api_key=self.api_key,\n                model=self.model_name,\n                truncate=self.truncate,\n                max_retries=self.max_retries,\n                user_agent=self.user_agent,\n                request_timeout=self.request_timeout or None,\n            )\n        except Exception as e:\n            msg = (\n                \"Unable to create Cohere Embeddings. \",\n                \"Please verify the API key and model parameters, and try again.\",\n            )\n            raise ValueError(msg) from e\n        # added status if not the return data would be serialised to create the status\n        return data\n\n    def get_model(self):\n        try:\n            co = cohere.ClientV2(self.api_key)\n            response = co.models.list(endpoint=\"embed\")\n            models = response.models\n            return [model.name for model in models]\n        except Exception as e:\n            msg = f\"Failed to fetch Cohere models. Error: {e}\"\n            raise ValueError(msg) from e\n\n    async def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None):\n        if field_name in {\"model_name\", \"api_key\"}:\n            if build_config.get(\"api_key\", {}).get(\"value\", None):\n                build_config[\"model_name\"][\"options\"] = self.get_model()\n        else:\n            build_config[\"model_name\"][\"options\"] = field_value\n        return build_config\n"},"max_retries":{"_input_type":"IntInput","advanced":true,"display_name":"Max Retries","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"max_retries","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":3},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":true,"dialog_inputs":{},"display_name":"Model","dynamic":false,"external_options":{},"info":"","name":"model_name","options":["embed-english-v2.0","embed-multilingual-v2.0","embed-english-light-v2.0","embed-multilingual-light-v2.0"],"options_metadata":[],"placeholder":"","refresh_button":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"embed-english-v2.0"},"request_timeout":{"_input_type":"FloatInput","advanced":true,"display_name":"Request Timeout","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"request_timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":""},"truncate":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Truncate","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"truncate","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"user_agent":{"_input_type":"MessageTextInput","advanced":true,"display_name":"User Agent","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"user_agent","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"langchain"}},"tool_mode":false},"CohereModel":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate text using Cohere LLMs.","display_name":"Cohere Language Models","documentation":"https://python.langchain.com/docs/integrations/llms/cohere/","edited":false,"field_order":["input_value","system_message","stream","cohere_api_key","temperature"],"frozen":false,"icon":"Cohere","legacy":false,"metadata":{"code_hash":"594852e1d706","dependencies":{"dependencies":[{"name":"langchain_cohere","version":"0.3.3"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":3},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.cohere.cohere_models.CohereComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_cohere import ChatCohere\nfrom pydantic.v1 import SecretStr\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.io import SecretStrInput, SliderInput\n\n\nclass CohereComponent(LCModelComponent):\n    display_name = \"Cohere Language Models\"\n    description = \"Generate text using Cohere LLMs.\"\n    documentation = \"https://python.langchain.com/docs/integrations/llms/cohere/\"\n    icon = \"Cohere\"\n    name = \"CohereModel\"\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        SecretStrInput(\n            name=\"cohere_api_key\",\n            display_name=\"Cohere API Key\",\n            info=\"The Cohere API Key to use for the Cohere model.\",\n            advanced=False,\n            value=\"COHERE_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.75,\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\n            info=\"Controls randomness. Lower values are more deterministic, higher values are more creative.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        cohere_api_key = self.cohere_api_key\n        temperature = self.temperature\n\n        api_key = SecretStr(cohere_api_key).get_secret_value() if cohere_api_key else None\n\n        return ChatCohere(\n            temperature=temperature or 0.75,\n            cohere_api_key=api_key,\n        )\n"},"cohere_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Cohere API Key","dynamic":false,"info":"The Cohere API Key to use for the Cohere model.","input_types":[],"load_from_db":true,"name":"cohere_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"COHERE_API_KEY"},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"SliderInput","advanced":true,"display_name":"Temperature","dynamic":false,"info":"Controls randomness. Lower values are more deterministic, higher values are more creative.","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"temperature","placeholder":"","range_spec":{"max":2.0,"min":0.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":0.75}},"tool_mode":false},"CohereRerank":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Rerank documents using the Cohere API.","display_name":"Cohere Rerank","documentation":"","edited":false,"field_order":["search_query","search_results","top_n","api_key","model"],"frozen":false,"icon":"Cohere","legacy":false,"metadata":{"code_hash":"a94a0d11eeac","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"langchain_cohere","version":"0.3.3"}],"total_dependencies":2},"module":"lfx.components.cohere.cohere_rerank.CohereRerankComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Reranked Documents","group_outputs":false,"method":"compress_documents","name":"reranked_documents","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Cohere API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.compressors.model import LCCompressorComponent\nfrom lfx.field_typing import BaseDocumentCompressor\nfrom lfx.inputs.inputs import SecretStrInput\nfrom lfx.io import DropdownInput\nfrom lfx.template.field.base import Output\n\n\nclass CohereRerankComponent(LCCompressorComponent):\n    display_name = \"Cohere Rerank\"\n    description = \"Rerank documents using the Cohere API.\"\n    name = \"CohereRerank\"\n    icon = \"Cohere\"\n\n    inputs = [\n        *LCCompressorComponent.inputs,\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Cohere API Key\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\n                \"rerank-english-v3.0\",\n                \"rerank-multilingual-v3.0\",\n                \"rerank-english-v2.0\",\n                \"rerank-multilingual-v2.0\",\n            ],\n            value=\"rerank-english-v3.0\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Reranked Documents\",\n            name=\"reranked_documents\",\n            method=\"compress_documents\",\n        ),\n    ]\n\n    def build_compressor(self) -> BaseDocumentCompressor:  # type: ignore[type-var]\n        try:\n            from langchain_cohere import CohereRerank\n        except ImportError as e:\n            msg = \"Please install langchain-cohere to use the Cohere model.\"\n            raise ImportError(msg) from e\n        return CohereRerank(\n            cohere_api_key=self.api_key,\n            model=self.model,\n            top_n=self.top_n,\n        )\n"},"model":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model","dynamic":false,"external_options":{},"info":"","name":"model","options":["rerank-english-v3.0","rerank-multilingual-v3.0","rerank-english-v2.0","rerank-multilingual-v2.0"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"rerank-english-v3.0"},"search_query":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Search Query","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"search_query","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"search_results":{"_input_type":"DataInput","advanced":false,"display_name":"Search Results","dynamic":false,"info":"Search Results from a Vector Store.","input_types":["Data"],"list":true,"list_add_label":"Add More","name":"search_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"top_n":{"_input_type":"IntInput","advanced":true,"display_name":"Top N","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"top_n","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":3}},"tool_mode":false}}],["cometapi",{"CometAPIModel":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"All AI Models in One API 500+ AI Models","display_name":"CometAPI","documentation":"","edited":false,"field_order":["input_value","system_message","stream","api_key","app_name","model_name","model_kwargs","temperature","max_tokens","seed","json_mode"],"frozen":false,"icon":"CometAPI","legacy":false,"metadata":{"code_hash":"4ec4a8852e9c","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"langchain_openai","version":"0.3.23"},{"name":"pydantic","version":"2.10.6"},{"name":"typing_extensions","version":"4.15.0"},{"name":"lfx","version":null}],"total_dependencies":5},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.cometapi.cometapi.CometAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"CometAPI Key","dynamic":false,"info":"Your CometAPI key","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":""},"app_name":{"_input_type":"StrInput","advanced":true,"display_name":"App Name","dynamic":false,"info":"Your app name for CometAPI rankings","list":false,"list_add_label":"Add More","load_from_db":false,"name":"app_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\n\nimport requests\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\nfrom typing_extensions import override\n\nfrom lfx.base.models.cometapi_constants import MODEL_NAMES\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.inputs.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    IntInput,\n    SecretStrInput,\n    SliderInput,\n    StrInput,\n)\n\n\nclass CometAPIComponent(LCModelComponent):\n    \"\"\"CometAPI component for language models.\"\"\"\n\n    display_name = \"CometAPI\"\n    description = \"All AI Models in One API 500+ AI Models\"\n    icon = \"CometAPI\"\n    name = \"CometAPIModel\"\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"CometAPI Key\",\n            required=True,\n            info=\"Your CometAPI key\",\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"app_name\",\n            display_name=\"App Name\",\n            info=\"Your app name for CometAPI rankings\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model\",\n            info=\"The model to use for chat completion\",\n            options=[\"Select a model\"],\n            value=\"Select a model\",\n            real_time_refresh=True,\n            required=True,\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            info=\"Additional keyword arguments to pass to the model.\",\n            advanced=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.7,\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\n            info=\"Controls randomness. Lower values are more deterministic, higher values are more creative.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            info=\"Maximum number of tokens to generate\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"Seed for reproducible outputs.\",\n            value=1,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            info=\"If enabled, the model will be asked to return a JSON object.\",\n            advanced=True,\n        ),\n    ]\n\n    def get_models(self, token_override: str | None = None) -> list[str]:\n        base_url = \"https://api.cometapi.com/v1\"\n        url = f\"{base_url}/models\"\n\n        headers = {\"Content-Type\": \"application/json\"}\n        # Add Bearer Authorization when API key is available\n        api_key_source = token_override if token_override else getattr(self, \"api_key\", None)\n        if api_key_source:\n            token = api_key_source.get_secret_value() if isinstance(api_key_source, SecretStr) else str(api_key_source)\n            headers[\"Authorization\"] = f\"Bearer {token}\"\n\n        try:\n            response = requests.get(url, headers=headers, timeout=10)\n            response.raise_for_status()\n            # Safely parse JSON; fallback to defaults on failure\n            try:\n                model_list = response.json()\n            except (json.JSONDecodeError, ValueError) as e:\n                self.status = f\"Error decoding models response: {e}\"\n                return MODEL_NAMES\n            return [model[\"id\"] for model in model_list.get(\"data\", [])]\n        except requests.RequestException as e:\n            self.status = f\"Error fetching models: {e}\"\n            return MODEL_NAMES\n\n    @override\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\n        if field_name == \"api_key\":\n            models = self.get_models(field_value)\n            model_cfg = build_config.get(\"model_name\", {})\n            # Preserve placeholder (fallback to existing value or a generic prompt)\n            placeholder = model_cfg.get(\"placeholder\", model_cfg.get(\"value\", \"Select a model\"))\n            current_value = model_cfg.get(\"value\")\n\n            options = list(models) if models else []\n            # Ensure current value stays visible even if not present in fetched options\n            if current_value and current_value not in options:\n                options = [current_value, *options]\n\n            model_cfg[\"options\"] = options\n            model_cfg[\"placeholder\"] = placeholder\n            build_config[\"model_name\"] = model_cfg\n        return build_config\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = getattr(self, \"model_kwargs\", {}) or {}\n        json_mode = self.json_mode\n        seed = self.seed\n        # Ensure a valid model was selected\n        if not model_name or model_name == \"Select a model\":\n            msg = \"Please select a valid CometAPI model.\"\n            raise ValueError(msg)\n        try:\n            # Extract raw API key safely\n            _api_key = api_key.get_secret_value() if isinstance(api_key, SecretStr) else api_key\n            output = ChatOpenAI(\n                model=model_name,\n                api_key=_api_key or None,\n                max_tokens=max_tokens or None,\n                temperature=temperature,\n                model_kwargs=model_kwargs,\n                streaming=bool(self.stream),\n                seed=seed,\n                base_url=\"https://api.cometapi.com/v1\",\n            )\n        except (TypeError, ValueError) as e:\n            msg = \"Could not connect to CometAPI.\"\n            raise ValueError(msg) from e\n\n        if json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n"},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"json_mode":{"_input_type":"BoolInput","advanced":true,"display_name":"JSON Mode","dynamic":false,"info":"If enabled, the model will be asked to return a JSON object.","list":false,"list_add_label":"Add More","name":"json_mode","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"max_tokens":{"_input_type":"IntInput","advanced":true,"display_name":"Max Tokens","dynamic":false,"info":"Maximum number of tokens to generate","list":false,"list_add_label":"Add More","name":"max_tokens","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"model_kwargs":{"_input_type":"DictInput","advanced":true,"display_name":"Model Kwargs","dynamic":false,"info":"Additional keyword arguments to pass to the model.","list":false,"list_add_label":"Add More","name":"model_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model","dynamic":false,"external_options":{},"info":"The model to use for chat completion","name":"model_name","options":["Select a model"],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Select a model"},"seed":{"_input_type":"IntInput","advanced":true,"display_name":"Seed","dynamic":false,"info":"Seed for reproducible outputs.","list":false,"list_add_label":"Add More","name":"seed","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"SliderInput","advanced":true,"display_name":"Temperature","dynamic":false,"info":"Controls randomness. Lower values are more deterministic, higher values are more creative.","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"temperature","placeholder":"","range_spec":{"max":2.0,"min":0.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":0.7}},"tool_mode":false}}],["composio",{"ComposioAPI":{"base_classes":["Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Use Composio toolset to run actions with your agent","display_name":"Composio Tools","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","tool_name","actions"],"frozen":false,"icon":"Composio","legacy":false,"metadata":{"code_hash":"c41cf13f84ff","dependencies":{"dependencies":[{"name":"composio","version":"0.8.5"},{"name":"composio_langchain","version":"0.8.5"},{"name":"langchain_core","version":"0.3.79"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.composio.composio_api.ComposioAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Tools","group_outputs":false,"method":"build_tool","name":"tools","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","actions":{"_input_type":"SortableListInput","advanced":false,"display_name":"Actions","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"icon":"OctagonAlert","variant":"destructive"},"info":"The actions to use","limit":1,"name":"actions","options":[],"placeholder":"Select action","required":false,"search_category":[],"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":""},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"Refer to https://docs.composio.dev/faq/api_key/api_key","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"# Standard library imports\nfrom collections.abc import Sequence\nfrom typing import Any\n\nfrom composio import Composio\nfrom composio_langchain import LangchainProvider\n\n# Third-party imports\nfrom langchain_core.tools import Tool\n\n# Local imports\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.inputs.inputs import (\n    ConnectionInput,\n    MessageTextInput,\n    SecretStrInput,\n    SortableListInput,\n)\nfrom lfx.io import Output\n\n# TODO: We get the list from the API but we need to filter it\nenabled_tools = [\"confluence\", \"discord\", \"dropbox\", \"github\", \"gmail\", \"linkedin\", \"notion\", \"slack\", \"youtube\"]\n\n\nclass ComposioAPIComponent(LCToolComponent):\n    display_name: str = \"Composio Tools\"\n    description: str = \"Use Composio toolset to run actions with your agent\"\n    name = \"ComposioAPI\"\n    icon = \"Composio\"\n    documentation: str = \"https://docs.composio.dev\"\n\n    inputs = [\n        # Basic configuration inputs\n        MessageTextInput(name=\"entity_id\", display_name=\"Entity ID\", value=\"default\", advanced=True),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Composio API Key\",\n            required=True,\n            info=\"Refer to https://docs.composio.dev/faq/api_key/api_key\",\n            real_time_refresh=True,\n        ),\n        ConnectionInput(\n            name=\"tool_name\",\n            display_name=\"Tool Name\",\n            placeholder=\"Select a tool...\",\n            button_metadata={\"icon\": \"unplug\", \"variant\": \"destructive\"},\n            options=[],\n            search_category=[],\n            value=\"\",\n            connection_link=\"\",\n            info=\"The name of the tool to use\",\n            real_time_refresh=True,\n        ),\n        SortableListInput(\n            name=\"actions\",\n            display_name=\"Actions\",\n            placeholder=\"Select action\",\n            helper_text=\"Please connect before selecting actions.\",\n            helper_text_metadata={\"icon\": \"OctagonAlert\", \"variant\": \"destructive\"},\n            options=[],\n            value=\"\",\n            info=\"The actions to use\",\n            limit=1,\n            show=False,\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"tools\", display_name=\"Tools\", method=\"build_tool\"),\n    ]\n\n    def validate_tool(self, build_config: dict, field_value: Any, tool_name: str | None = None) -> dict:\n        # Get the index of the selected tool in the list of options\n        selected_tool_index = next(\n            (\n                ind\n                for ind, tool in enumerate(build_config[\"tool_name\"][\"options\"])\n                if tool[\"name\"] == field_value\n                or (\"validate\" in field_value and tool[\"name\"] == field_value[\"validate\"])\n            ),\n            None,\n        )\n\n        # Set the link to be the text 'validated'\n        build_config[\"tool_name\"][\"options\"][selected_tool_index][\"link\"] = \"validated\"\n\n        # Set the helper text and helper text metadata field of the actions now\n        build_config[\"actions\"][\"helper_text\"] = \"\"\n        build_config[\"actions\"][\"helper_text_metadata\"] = {\"icon\": \"Check\", \"variant\": \"success\"}\n\n        try:\n            composio = self._build_wrapper()\n            current_tool = tool_name or getattr(self, \"tool_name\", None)\n            if not current_tool:\n                self.log(\"No tool name available for validate_tool\")\n                return build_config\n\n            toolkit_slug = current_tool.lower()\n\n            tools = composio.tools.get(user_id=self.entity_id, toolkits=[toolkit_slug])\n\n            authenticated_actions = []\n            for tool in tools:\n                if hasattr(tool, \"name\"):\n                    action_name = tool.name\n                    display_name = action_name.replace(\"_\", \" \").title()\n                    authenticated_actions.append({\"name\": action_name, \"display_name\": display_name})\n        except (ValueError, ConnectionError, AttributeError) as e:\n            self.log(f\"Error getting actions for {current_tool or 'unknown tool'}: {e}\")\n            authenticated_actions = []\n\n        build_config[\"actions\"][\"options\"] = [\n            {\n                \"name\": action[\"name\"],\n            }\n            for action in authenticated_actions\n        ]\n\n        build_config[\"actions\"][\"show\"] = True\n        return build_config\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name == \"api_key\" or (self.api_key and not build_config[\"tool_name\"][\"options\"]):\n            if field_name == \"api_key\" and not field_value:\n                build_config[\"tool_name\"][\"options\"] = []\n                build_config[\"tool_name\"][\"value\"] = \"\"\n\n                # Reset the list of actions\n                build_config[\"actions\"][\"show\"] = False\n                build_config[\"actions\"][\"options\"] = []\n                build_config[\"actions\"][\"value\"] = \"\"\n\n                return build_config\n\n            # Build the list of available tools\n            build_config[\"tool_name\"][\"options\"] = [\n                {\n                    \"name\": app.title(),\n                    \"icon\": app,\n                    \"link\": (\n                        build_config[\"tool_name\"][\"options\"][ind][\"link\"]\n                        if build_config[\"tool_name\"][\"options\"]\n                        else \"\"\n                    ),\n                }\n                for ind, app in enumerate(enabled_tools)\n            ]\n\n            return build_config\n\n        if field_name == \"tool_name\" and field_value:\n            composio = self._build_wrapper()\n\n            current_tool_name = (\n                field_value\n                if isinstance(field_value, str)\n                else field_value.get(\"validate\")\n                if isinstance(field_value, dict) and \"validate\" in field_value\n                else getattr(self, \"tool_name\", None)\n            )\n\n            if not current_tool_name:\n                self.log(\"No tool name available for connection check\")\n                return build_config\n\n            try:\n                toolkit_slug = current_tool_name.lower()\n\n                connection_list = composio.connected_accounts.list(\n                    user_ids=[self.entity_id], toolkit_slugs=[toolkit_slug]\n                )\n\n                # Check for active connections\n                has_active_connections = False\n                if (\n                    connection_list\n                    and hasattr(connection_list, \"items\")\n                    and connection_list.items\n                    and isinstance(connection_list.items, list)\n                    and len(connection_list.items) > 0\n                ):\n                    for connection in connection_list.items:\n                        if getattr(connection, \"status\", None) == \"ACTIVE\":\n                            has_active_connections = True\n                            break\n\n                # Get the index of the selected tool in the list of options\n                selected_tool_index = next(\n                    (\n                        ind\n                        for ind, tool in enumerate(build_config[\"tool_name\"][\"options\"])\n                        if tool[\"name\"] == current_tool_name.title()\n                    ),\n                    None,\n                )\n\n                if has_active_connections:\n                    # User has active connection\n                    if selected_tool_index is not None:\n                        build_config[\"tool_name\"][\"options\"][selected_tool_index][\"link\"] = \"validated\"\n\n                    # If it's a validation request, validate the tool\n                    if (isinstance(field_value, dict) and \"validate\" in field_value) or isinstance(field_value, str):\n                        return self.validate_tool(build_config, field_value, current_tool_name)\n                else:\n                    # No active connection - create OAuth connection\n                    try:\n                        connection = composio.toolkits.authorize(user_id=self.entity_id, toolkit=toolkit_slug)\n                        redirect_url = getattr(connection, \"redirect_url\", None)\n\n                        if redirect_url and redirect_url.startswith((\"http://\", \"https://\")):\n                            if selected_tool_index is not None:\n                                build_config[\"tool_name\"][\"options\"][selected_tool_index][\"link\"] = redirect_url\n                        elif selected_tool_index is not None:\n                            build_config[\"tool_name\"][\"options\"][selected_tool_index][\"link\"] = \"error\"\n                    except (ValueError, ConnectionError, AttributeError) as e:\n                        self.log(f\"Error creating OAuth connection: {e}\")\n                        if selected_tool_index is not None:\n                            build_config[\"tool_name\"][\"options\"][selected_tool_index][\"link\"] = \"error\"\n\n            except (ValueError, ConnectionError, AttributeError) as e:\n                self.log(f\"Error checking connection status: {e}\")\n\n        return build_config\n\n    def build_tool(self) -> Sequence[Tool]:\n        \"\"\"Build Composio tools based on selected actions.\n\n        Returns:\n            Sequence[Tool]: List of configured Composio tools.\n        \"\"\"\n        composio = self._build_wrapper()\n        action_names = [action[\"name\"] for action in self.actions]\n\n        # Get toolkits from action names\n        toolkits = set()\n        for action_name in action_names:\n            if \"_\" in action_name:\n                toolkit = action_name.split(\"_\")[0].lower()\n                toolkits.add(toolkit)\n\n        if not toolkits:\n            return []\n\n        # Get all tools for the relevant toolkits\n        all_tools = composio.tools.get(user_id=self.entity_id, toolkits=list(toolkits))\n\n        # Filter to only the specific actions we want using list comprehension\n        return [tool for tool in all_tools if hasattr(tool, \"name\") and tool.name in action_names]\n\n    def _build_wrapper(self) -> Composio:\n        \"\"\"Build the Composio wrapper using new SDK.\n\n        Returns:\n            Composio: The initialized Composio client.\n\n        Raises:\n            ValueError: If the API key is not found or invalid.\n        \"\"\"\n        try:\n            if not self.api_key:\n                msg = \"Composio API Key is required\"\n                raise ValueError(msg)\n            return Composio(api_key=self.api_key, provider=LangchainProvider())\n        except ValueError as e:\n            self.log(f\"Error building Composio wrapper: {e}\")\n            msg = \"Please provide a valid Composio API Key in the component settings\"\n            raise ValueError(msg) from e\n"},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"tool_name":{"_input_type":"ConnectionInput","advanced":false,"button_metadata":{"icon":"unplug","variant":"destructive"},"connection_link":"","display_name":"Tool Name","dynamic":false,"info":"The name of the tool to use","name":"tool_name","options":[],"placeholder":"Select a tool...","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"connect","value":""}},"tool_mode":false},"ComposioAgentQLAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"AgentQL","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"AgentQL","legacy":false,"metadata":{"code_hash":"cca708a10ab6","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.agentql_composio.ComposioAgentQLAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioAgentQLAPIComponent(ComposioBaseComponent):\n    display_name: str = \"AgentQL\"\n    icon = \"AgentQL\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"agentql\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for AgentQL component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioAgiledAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Agiled","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Agiled","legacy":false,"metadata":{"code_hash":"3294a951a1a8","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.agiled_composio.ComposioAgiledAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioAgiledAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Agiled\"\n    icon = \"Agiled\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"agiled\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Agiled component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioAirtableAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Airtable","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Airtable","legacy":false,"metadata":{"code_hash":"e47ad011c33c","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.airtable_composio.ComposioAirtableAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioAirtableAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Airtable\"\n    icon = \"Airtable\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"airtable\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Airtable component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioAsanaAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Asana","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Asana","legacy":false,"metadata":{"code_hash":"290d6d61d049","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.asana_composio.ComposioAsanaAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioAsanaAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Asana\"\n    icon = \"Asana\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"asana\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Asana component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioAttioAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Attio","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Attio","legacy":false,"metadata":{"code_hash":"de43b3cf5671","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.attio_composio.ComposioAttioAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioAttioAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Attio\"\n    icon = \"Attio\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"attio\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Attio component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioBolnaAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Bolna","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Bolna","legacy":false,"metadata":{"code_hash":"dde7d2ee80a2","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.bolna_composio.ComposioBolnaAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioBolnaAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Bolna\"\n    icon = \"Bolna\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"bolna\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Bolna component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioBrightdataAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Brightdata","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Brightdata","legacy":false,"metadata":{"code_hash":"49a04c5a23cb","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.brightdata_composio.ComposioBrightdataAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioBrightdataAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Brightdata\"\n    icon = \"Brightdata\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"brightdata\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Brightdata component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioCalendlyAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Calendly","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Calendly","legacy":false,"metadata":{"code_hash":"4a282e413d55","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.calendly_composio.ComposioCalendlyAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioCalendlyAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Calendly\"\n    icon = \"Calendly\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"calendly\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Calendly component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioCanvasAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Canvas","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Canvas","legacy":false,"metadata":{"code_hash":"6510d212a720","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.canvas_composio.ComposioCanvasAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioCanvasAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Canvas\"\n    icon = \"Canvas\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"canvas\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Canvaas component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioContentfulAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Contentful","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Contentful","legacy":false,"metadata":{"code_hash":"36befb1ec8fc","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.contentful_composio.ComposioContentfulAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioContentfulAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Contentful\"\n    icon = \"Contentful\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"contentful\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Contentful component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioDigicertAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Digicert","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Digicert","legacy":false,"metadata":{"code_hash":"0fcbc1b899f8","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.digicert_composio.ComposioDigicertAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioDigicertAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Digicert\"\n    icon = \"Digicert\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"digicert\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Digicert component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioDiscordAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Discord","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Discord","legacy":false,"metadata":{"code_hash":"dd7e1bed6ba7","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.discord_composio.ComposioDiscordAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioDiscordAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Discord\"\n    icon = \"Discord\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"discord\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Discord component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioDropboxAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Dropbox","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Dropbox","legacy":false,"metadata":{"code_hash":"d05825599def","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.dropbox_compnent.ComposioDropboxAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioDropboxAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Dropbox\"\n    icon = \"Dropbox\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"dropbox\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Dropbox component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioFigmaAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Figma","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Figma","legacy":false,"metadata":{"code_hash":"7443d213546b","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.figma_composio.ComposioFigmaAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioFigmaAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Figma\"\n    icon = \"Figma\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"figma\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Figma component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioFinageAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Finage","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Finage","legacy":false,"metadata":{"code_hash":"50a2bdee4cd1","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.finage_composio.ComposioFinageAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioFinageAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Finage\"\n    icon = \"Finage\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"finage\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Finage component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioFixerAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Fixer","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Fixer","legacy":false,"metadata":{"code_hash":"9e4c00f9dcd8","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.fixer_composio.ComposioFixerAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioFixerAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Fixer\"\n    icon = \"Fixer\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"fixer\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Fixer component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioFlexisignAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Flexisign","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Flexisign","legacy":false,"metadata":{"code_hash":"c69bbee0005d","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.flexisign_composio.ComposioFlexisignAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioFlexisignAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Flexisign\"\n    icon = \"Flexisign\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"flexisign\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Flexisign component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioFreshdeskAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Freshdesk","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Freshdesk","legacy":false,"metadata":{"code_hash":"1dde03d615ca","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.freshdesk_composio.ComposioFreshdeskAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioFreshdeskAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Freshdesk\"\n    icon = \"Freshdesk\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"freshdesk\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Freshdesk component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioGitHubAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"GitHub","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Github","legacy":false,"metadata":{"code_hash":"f8abad5de5fd","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.github_composio.ComposioGitHubAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioGitHubAPIComponent(ComposioBaseComponent):\n    display_name: str = \"GitHub\"\n    icon = \"Github\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"github\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for GitHub component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioGmailAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Gmail","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Google","legacy":false,"metadata":{"code_hash":"550884222de1","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.gmail_composio.ComposioGmailAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioGmailAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Gmail\"\n    icon = \"Google\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"gmail\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.post_processors = {\n            \"GMAIL_SEND_EMAIL\": self._process_send_email_response,\n            \"GMAIL_FETCH_EMAILS\": self._process_fetch_emails_response,\n        }\n\n    def _process_send_email_response(self, raw_data):\n        \"\"\"Post-processor for GMAIL_SEND_EMAIL action.\"\"\"\n        if isinstance(raw_data, dict):\n            response_data = raw_data.get(\"response_data\", raw_data)\n\n            return {\n                \"message_id\": response_data.get(\"id\"),\n                \"thread_id\": response_data.get(\"threadId\"),\n                \"label_ids\": response_data.get(\"labelIds\", []),\n            }\n        return raw_data\n\n    def _process_fetch_emails_response(self, raw_data):\n        \"\"\"Post-processor for GMAIL_FETCH_EMAILS action.\"\"\"\n        if isinstance(raw_data, dict):\n            messages = raw_data.get(\"messages\", [])\n            if messages:\n                return messages\n        return raw_data\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Gmail component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioGoogleCalendarAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Google Calendar","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Googlecalendar","legacy":false,"metadata":{"code_hash":"8723320b6c9b","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.googlecalendar_composio.ComposioGoogleCalendarAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioGoogleCalendarAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Google Calendar\"\n    icon = \"Googlecalendar\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"googlecalendar\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Google Calendar component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioGoogleDocsAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Google Docs","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Googledocs","legacy":false,"metadata":{"code_hash":"fc420f66a780","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.googledocs_composio.ComposioGoogleDocsAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioGoogleDocsAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Google Docs\"\n    icon = \"Googledocs\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"googledocs\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Google Docs component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioGoogleSheetsAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Google Sheets","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Googlesheets","legacy":false,"metadata":{"code_hash":"a3ef38681708","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.googlesheets_composio.ComposioGoogleSheetsAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioGoogleSheetsAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Google Sheets\"\n    icon = \"Googlesheets\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"googlesheets\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Google Sheets component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioGoogleTasksAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Google Tasks","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"GoogleTasks","legacy":false,"metadata":{"code_hash":"ddb9b20c05fc","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.googletasks_composio.ComposioGoogleTasksAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioGoogleTasksAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Google Tasks\"\n    icon = \"GoogleTasks\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"googletasks\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioGoogleclassroomAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Google Classroom","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Classroom","legacy":false,"metadata":{"code_hash":"85a5c37c13f6","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.googleclassroom_composio.ComposioGoogleclassroomAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioGoogleclassroomAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Google Classroom\"\n    icon = \"Classroom\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"GOOGLE_CLASSROOM\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Google Classroom component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioGooglemeetAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Google Meet","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Googlemeet","legacy":false,"metadata":{"code_hash":"c54db98a21d1","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.googlemeet_composio.ComposioGooglemeetAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioGooglemeetAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Google Meet\"\n    icon = \"Googlemeet\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"googlemeet\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Google Calendar component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioInstagramAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Instagram","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Instagram","legacy":false,"metadata":{"code_hash":"a6691c905833","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.instagram_composio.ComposioInstagramAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioInstagramAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Instagram\"\n    icon = \"Instagram\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"instagram\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Instagram component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioJiraAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Jira","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Jira","legacy":false,"metadata":{"code_hash":"3e62396f3868","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.jira_composio.ComposioJiraAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioJiraAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Jira\"\n    icon = \"Jira\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"jira\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Jira component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioJotformAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Jotform","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Jotform","legacy":false,"metadata":{"code_hash":"7c1c6a676814","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.jotform_composio.ComposioJotformAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioJotformAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Jotform\"\n    icon = \"Jotform\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"jotform\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Jotform component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioKlaviyoAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Klaviyo","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Klaviyo","legacy":false,"metadata":{"code_hash":"3be7e8a5e3fe","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.klaviyo_composio.ComposioKlaviyoAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioKlaviyoAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Klaviyo\"\n    icon = \"Klaviyo\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"klaviyo\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Klaviyo component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioLinearAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Linear","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Linear","legacy":false,"metadata":{"code_hash":"be2b2ebbeea7","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.linear_composio.ComposioLinearAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioLinearAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Linear\"\n    icon = \"Linear\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"linear\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Linear component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioListennotesAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Listennotes","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Listennotes","legacy":false,"metadata":{"code_hash":"b85f2fe51906","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.listennotes_composio.ComposioListennotesAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioListennotesAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Listennotes\"\n    icon = \"Listennotes\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"listennotes\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Listennotes component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioMiroAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Miro","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Miro","legacy":false,"metadata":{"code_hash":"1e9c421e1ac4","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.miro_composio.ComposioMiroAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioMiroAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Miro\"\n    icon = \"Miro\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"miro\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Miro component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioMissiveAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Missive","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Missive","legacy":false,"metadata":{"code_hash":"6def944a7739","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.missive_composio.ComposioMissiveAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioMissiveAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Missive\"\n    icon = \"Missive\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"missive\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Missive component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioNotionAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Notion","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Notion","legacy":false,"metadata":{"code_hash":"590aa6ff30d1","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.notion_composio.ComposioNotionAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioNotionAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Notion\"\n    icon = \"Notion\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"notion\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Notion component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioOneDriveAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"OneDrive","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"One_Drive","legacy":false,"metadata":{"code_hash":"497cc4625121","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.onedrive_composio.ComposioOneDriveAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioOneDriveAPIComponent(ComposioBaseComponent):\n    display_name: str = \"OneDrive\"\n    icon = \"One_Drive\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"one_drive\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for OneDrive component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioOutlookAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Outlook","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Outlook","legacy":false,"metadata":{"code_hash":"bf6998d60b63","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.outlook_composio.ComposioOutlookAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioOutlookAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Outlook\"\n    icon = \"Outlook\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"outlook\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Gmail component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioPandadocAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Pandadoc","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Pandadoc","legacy":false,"metadata":{"code_hash":"21d92aabc1bf","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.pandadoc_composio.ComposioPandadocAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioPandadocAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Pandadoc\"\n    icon = \"Pandadoc\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"pandadoc\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Pandadoc component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioRedditAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Reddit","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Reddit","legacy":false,"metadata":{"code_hash":"a86794073c22","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.reddit_composio.ComposioRedditAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioRedditAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Reddit\"\n    icon = \"Reddit\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"reddit\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Reddit component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioSlackAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Slack","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button","SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_limit","SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_cursor","SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_include_locale","SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_as_user","SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_attachments","SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_blocks","SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_channel","SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_icon_emoji","SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_icon_url","SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_link_names","SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_mrkdwn","SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_parse","SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_reply_broadcast","SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_text","SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_thread_ts","SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_unfurl_links","SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_unfurl_media","SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_username","SLACK_UPDATES_A_SLACK_MESSAGE_as_user","SLACK_UPDATES_A_SLACK_MESSAGE_attachments","SLACK_UPDATES_A_SLACK_MESSAGE_blocks","SLACK_UPDATES_A_SLACK_MESSAGE_channel","SLACK_UPDATES_A_SLACK_MESSAGE_link_names","SLACK_UPDATES_A_SLACK_MESSAGE_parse","SLACK_UPDATES_A_SLACK_MESSAGE_text","SLACK_UPDATES_A_SLACK_MESSAGE_ts","SLACK_FETCH_CONVERSATION_HISTORY_channel","SLACK_FETCH_CONVERSATION_HISTORY_latest","SLACK_FETCH_CONVERSATION_HISTORY_oldest","SLACK_FETCH_CONVERSATION_HISTORY_inclusive","SLACK_FETCH_CONVERSATION_HISTORY_limit","SLACK_FETCH_CONVERSATION_HISTORY_cursor","SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_as_user","SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_attachments","SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_blocks","SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_channel","SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_link_names","SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_parse","SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_post_at","SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_reply_broadcast","SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_text","SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_thread_ts","SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_unfurl_links","SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_unfurl_media","SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_exclude_archived","SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_types","SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_limit","SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_cursor","SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_count","SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_highlight","SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_page","SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_query","SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_sort","SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_sort_dir","SLACK_CREATE_A_REMINDER_text","SLACK_CREATE_A_REMINDER_time","SLACK_CREATE_A_REMINDER_user"],"frozen":false,"icon":"Slack","legacy":false,"metadata":{"code_hash":"db5adee4a80d","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"composio","version":"0.8.5"}],"total_dependencies":2},"module":"lfx.components.composio.slack_composio.ComposioSlackAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"SLACK_CREATE_A_REMINDER_text":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Text","dynamic":false,"info":"The content of the reminder","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_CREATE_A_REMINDER_text","placeholder":"","required":true,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_CREATE_A_REMINDER_time":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Time","dynamic":false,"info":"When this reminder should happen: the Unix timestamp (up to five years from now), the number of seconds until the reminder (if within 24 hours), or a natural language description (Ex. 'in 15 minutes,' or 'every Thursday') ","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_CREATE_A_REMINDER_time","placeholder":"","required":true,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_CREATE_A_REMINDER_user":{"_input_type":"MessageTextInput","advanced":false,"display_name":"User","dynamic":false,"info":"The user who will receive the reminder. If no user is specified, the reminder will go to user who created it. ","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_CREATE_A_REMINDER_user","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_FETCH_CONVERSATION_HISTORY_channel":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Channel ID","dynamic":false,"info":"Channel ID to fetch history for.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_FETCH_CONVERSATION_HISTORY_channel","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_FETCH_CONVERSATION_HISTORY_cursor":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Cursor","dynamic":false,"info":"Paginate through collections of data by setting the `cursor` parameter to a `next_cursor` attribute returned by a previous request's `response_metadata`. Default value fetches the first 'page' of the collection. ","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_FETCH_CONVERSATION_HISTORY_cursor","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_FETCH_CONVERSATION_HISTORY_inclusive":{"_input_type":"BoolInput","advanced":true,"display_name":"Inclusive","dynamic":false,"info":"Include messages with latest or oldest timestamp in results only when either timestamp is specified. ","list":false,"list_add_label":"Add More","name":"SLACK_FETCH_CONVERSATION_HISTORY_inclusive","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"SLACK_FETCH_CONVERSATION_HISTORY_latest":{"_input_type":"IntInput","advanced":true,"display_name":"Latest","dynamic":false,"info":"End of time range of messages to include in results.","list":false,"list_add_label":"Add More","name":"SLACK_FETCH_CONVERSATION_HISTORY_latest","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"SLACK_FETCH_CONVERSATION_HISTORY_limit":{"_input_type":"IntInput","advanced":true,"display_name":"Limit","dynamic":false,"info":"The maximum number of items to return. Fewer than the requested number of items may be returned, even if the end of the users list hasn't been reached. ","list":false,"list_add_label":"Add More","name":"SLACK_FETCH_CONVERSATION_HISTORY_limit","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"SLACK_FETCH_CONVERSATION_HISTORY_oldest":{"_input_type":"IntInput","advanced":true,"display_name":"Oldest","dynamic":false,"info":"Start of time range of messages to include in results.","list":false,"list_add_label":"Add More","name":"SLACK_FETCH_CONVERSATION_HISTORY_oldest","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_cursor":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Cursor","dynamic":false,"info":"Paginate through collections of data by setting the `cursor` parameter to a `next_cursor` attribute returned by a previous request's `response_metadata`. Default value fetches the first 'page' of the collection","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_cursor","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_exclude_archived":{"_input_type":"BoolInput","advanced":false,"display_name":"Exclude Archived","dynamic":false,"info":"Set to `true` to exclude archived channels from the list","list":false,"list_add_label":"Add More","name":"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_exclude_archived","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_limit":{"_input_type":"IntInput","advanced":false,"display_name":"Limit","dynamic":false,"info":"The maximum number of items to return. Fewer than the requested number of items may be returned, even if the end of the list hasn't been reached. Must be an integer no larger than 1000. ","list":false,"list_add_label":"Add More","name":"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_limit","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1},"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_types":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Types","dynamic":false,"info":"Mix and match channel types by providing a comma-separated list of any combination of `public_channel`, `private_channel`, `mpim`, `im` ","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_types","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_cursor":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Cursor","dynamic":false,"info":"Paginate through collections of data by setting the `cursor` parameter to a `next_cursor` attribute returned by a previous request's `response_metadata`. Default value fetches the first `page` of the collection","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_cursor","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_include_locale":{"_input_type":"BoolInput","advanced":false,"display_name":"Include Locale","dynamic":false,"info":"Set this to `true` to receive the locale for users. Defaults to `false`","list":false,"list_add_label":"Add More","name":"SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_include_locale","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_limit":{"_input_type":"IntInput","advanced":false,"display_name":"Limit","dynamic":false,"info":"The maximum number of items to return. Fewer than the requested number of items may be returned, even if the end of the users list hasn't been reached. Providing no `limit` value will result in Slack attempting to deliver you the entire result set. If the collection is too large you may experience `limit_required` or HTTP 500 errors. ","list":false,"list_add_label":"Add More","name":"SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_limit","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1},"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_as_user":{"_input_type":"BoolInput","advanced":true,"display_name":"As User","dynamic":false,"info":"Pass true to post the message as the authed user, instead of as a bot. Defaults to false","list":false,"list_add_label":"Add More","name":"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_as_user","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_attachments":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Attachments","dynamic":false,"info":"A JSON-based array of structured attachments, presented as a URL-encoded string. ","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_attachments","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_blocks":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Blocks","dynamic":false,"info":"A JSON-based array of structured blocks, presented as a URL-encoded string. ","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_blocks","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_channel":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Channel","dynamic":false,"info":"Channel, private group, or DM channel to send message to. Can be an encoded ID, or a name","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_channel","placeholder":"","required":true,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_link_names":{"_input_type":"BoolInput","advanced":true,"display_name":"Link Names","dynamic":false,"info":"Find and link channel names and usernames.","list":false,"list_add_label":"Add More","name":"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_link_names","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_parse":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Parse","dynamic":false,"info":"Change how messages are treated. Defaults to `none`","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_parse","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_post_at":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Post At","dynamic":false,"info":"Unix EPOCH timestamp of time in future to send the message.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_post_at","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_reply_broadcast":{"_input_type":"BoolInput","advanced":true,"display_name":"Reply Broadcast","dynamic":false,"info":"Used in conjunction with `thread_ts` and indicates whether reply should be made visible to everyone in the channel or conversation. Defaults to `false`. ","list":false,"list_add_label":"Add More","name":"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_reply_broadcast","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_text":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Text","dynamic":false,"info":"How this field works and whether it is required depends on other fields you use in your API call","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_text","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_thread_ts":{"_input_type":"IntInput","advanced":true,"display_name":"Thread Ts","dynamic":false,"info":"Provide another message's `ts` value to make this message a reply. Avoid using a reply's `ts` value; use its parent instead. ","list":false,"list_add_label":"Add More","name":"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_thread_ts","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_unfurl_links":{"_input_type":"BoolInput","advanced":true,"display_name":"Unfurl Links","dynamic":false,"info":"Pass true to enable unfurling of primarily text-based content.","list":false,"list_add_label":"Add More","name":"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_unfurl_links","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_unfurl_media":{"_input_type":"BoolInput","advanced":true,"display_name":"Unfurl Media","dynamic":false,"info":"Pass false to disable unfurling of media content.","list":false,"list_add_label":"Add More","name":"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_unfurl_media","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_count":{"_input_type":"IntInput","advanced":true,"display_name":"Count","dynamic":false,"info":"Pass the number of results you want per 'page'. Maximum of `100`.","list":false,"list_add_label":"Add More","name":"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_count","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1},"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_highlight":{"_input_type":"BoolInput","advanced":true,"display_name":"Highlight","dynamic":false,"info":"Pass a value of `true` to enable query highlight markers","list":false,"list_add_label":"Add More","name":"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_highlight","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_page":{"_input_type":"IntInput","advanced":true,"display_name":"Page","dynamic":false,"info":"Page","list":false,"list_add_label":"Add More","name":"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_page","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_query":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Query","dynamic":false,"info":"Search query.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_query","placeholder":"","required":true,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_sort":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Sort","dynamic":false,"info":"Return matches sorted by either `score` or `timestamp`.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_sort","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_sort_dir":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Sort Dir","dynamic":false,"info":"Change sort direction to ascending (`asc`) or descending (`desc`).","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_sort_dir","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_as_user":{"_input_type":"BoolInput","advanced":true,"display_name":"As User","dynamic":false,"info":"Pass true to post the message as the authed user, instead of as a bot. Defaults to false","list":false,"list_add_label":"Add More","name":"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_as_user","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_attachments":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Attachments","dynamic":false,"info":"A JSON-based array of structured attachments, presented as a URL-encoded string. ","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_attachments","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_blocks":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Blocks","dynamic":false,"info":"A JSON-based array of structured blocks, presented as a URL-encoded string. ","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_blocks","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_channel":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Channel","dynamic":false,"info":"Channel, private group, or IM channel to send message to. Can be an encoded ID, or a name ","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_channel","placeholder":"","required":true,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_icon_emoji":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Icon Emoji","dynamic":false,"info":"Emoji to use as the icon for this message. Overrides `icon_url`. Must be used in conjunction with `as_user` set to `false`, otherwise ignored","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_icon_emoji","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_icon_url":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Icon Url","dynamic":false,"info":"URL to an image to use as the icon for this message. Must be used in conjunction with `as_user` set to false, otherwise ignored","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_icon_url","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_link_names":{"_input_type":"BoolInput","advanced":true,"display_name":"Link Names","dynamic":false,"info":"Find and link channel names and usernames.","list":false,"list_add_label":"Add More","name":"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_link_names","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_mrkdwn":{"_input_type":"BoolInput","advanced":true,"display_name":"Mrkdwn","dynamic":false,"info":"Disable Slack markup parsing by setting to `false`. Enabled by default.","list":false,"list_add_label":"Add More","name":"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_mrkdwn","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_parse":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Parse","dynamic":false,"info":"Change how messages are treated. Defaults to `none` ","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_parse","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_reply_broadcast":{"_input_type":"BoolInput","advanced":true,"display_name":"Reply Broadcast","dynamic":false,"info":"Used in conjunction with `thread_ts` and indicates whether reply should be made visible to everyone in the channel or conversation. Defaults to `false`. ","list":false,"list_add_label":"Add More","name":"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_reply_broadcast","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_text":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Text","dynamic":false,"info":"How this field works and whether it is required depends on other fields you use in your API call","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_text","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_thread_ts":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Thread Ts","dynamic":false,"info":"Provide another message's `ts` value to make this message a reply. Avoid using a reply's `ts` value; use its parent instead. ","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_thread_ts","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_unfurl_links":{"_input_type":"BoolInput","advanced":true,"display_name":"Unfurl Links","dynamic":false,"info":"Pass true to enable unfurling of primarily text-based content.","list":false,"list_add_label":"Add More","name":"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_unfurl_links","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_unfurl_media":{"_input_type":"BoolInput","advanced":true,"display_name":"Unfurl Media","dynamic":false,"info":"Pass false to disable unfurling of media content.","list":false,"list_add_label":"Add More","name":"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_unfurl_media","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_username":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Username","dynamic":false,"info":"Set your bot's user name. Must be used in conjunction with `as_user` set to false, otherwise ignored","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_username","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_UPDATES_A_SLACK_MESSAGE_as_user":{"_input_type":"MessageTextInput","advanced":true,"display_name":"As User","dynamic":false,"info":"Pass true to update the message as the authed user","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_UPDATES_A_SLACK_MESSAGE_as_user","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_UPDATES_A_SLACK_MESSAGE_attachments":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Attachments","dynamic":false,"info":"A JSON-based array of structured attachments, presented as a URL-encoded string. This field is required when not presenting `text`. If you don't include this field, the message's previous `attachments` will be retained. To remove previous `attachments`, include an empty array for this field. ","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_UPDATES_A_SLACK_MESSAGE_attachments","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_UPDATES_A_SLACK_MESSAGE_blocks":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Blocks","dynamic":false,"info":"A JSON-based array of structured blocks, presented as a URL-encoded string. If you don't include this field, the message's previous `blocks` will be retained. To remove previous `blocks`, include an empty array for this field. ","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_UPDATES_A_SLACK_MESSAGE_blocks","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_UPDATES_A_SLACK_MESSAGE_channel":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Channel ID","dynamic":false,"info":"Channel ID containing the message to be updated.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_UPDATES_A_SLACK_MESSAGE_channel","placeholder":"","required":true,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_UPDATES_A_SLACK_MESSAGE_link_names":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Link Names","dynamic":false,"info":"Find and link channel names and usernames. Defaults to `none`. If you do not specify a value for this field, the original value set for the message will be overwritten with the default, `none`. ","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_UPDATES_A_SLACK_MESSAGE_link_names","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_UPDATES_A_SLACK_MESSAGE_parse":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Parse","dynamic":false,"info":"Change how messages are treated. Defaults to `client`, unlike `chat.postMessage`. Accepts either `none` or `full`. If you do not specify a value for this field, the original value set for the message will be overwritten with the default, `client`. ","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_UPDATES_A_SLACK_MESSAGE_parse","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_UPDATES_A_SLACK_MESSAGE_text":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Text","dynamic":false,"info":"New text for the message, using the default formatting rules. It's not required when presenting `blocks` or `attachments`. ","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_UPDATES_A_SLACK_MESSAGE_text","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"SLACK_UPDATES_A_SLACK_MESSAGE_ts":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Ts","dynamic":false,"info":"Timestamp of the message to be updated.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"SLACK_UPDATES_A_SLACK_MESSAGE_ts","placeholder":"","required":true,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom lfx.base.composio.composio_base import ComposioBaseComponent\nfrom lfx.inputs import BoolInput, IntInput, MessageTextInput\nfrom lfx.log.logger import logger\n\n\nclass ComposioSlackAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Slack\"\n    icon = \"Slack\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"slack\"\n\n    _actions_data: dict = {\n        \"SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION\": {\n            \"display_name\": \"List Users\",\n            \"action_fields\": [\n                \"SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_limit\",\n                \"SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_cursor\",\n                \"SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_include_locale\",\n            ],\n        },\n        \"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS\": {\n            \"display_name\": \"List Channels\",\n            \"action_fields\": [\n                \"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_exclude_archived\",\n                \"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_types\",\n                \"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_limit\",\n                \"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_cursor\",\n            ],\n        },\n        \"SLACK_UPDATES_A_SLACK_MESSAGE\": {\n            \"display_name\": \"Update Slack Chat Message\",\n            \"action_fields\": [\n                \"SLACK_UPDATES_A_SLACK_MESSAGE_as_user\",\n                \"SLACK_UPDATES_A_SLACK_MESSAGE_attachments\",\n                \"SLACK_UPDATES_A_SLACK_MESSAGE_blocks\",\n                \"SLACK_UPDATES_A_SLACK_MESSAGE_channel\",\n                \"SLACK_UPDATES_A_SLACK_MESSAGE_link_names\",\n                \"SLACK_UPDATES_A_SLACK_MESSAGE_parse\",\n                \"SLACK_UPDATES_A_SLACK_MESSAGE_text\",\n                \"SLACK_UPDATES_A_SLACK_MESSAGE_ts\",\n            ],\n        },\n        \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL\": {\n            \"display_name\": \"Post Message To Channel\",\n            \"action_fields\": [\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_as_user\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_attachments\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_blocks\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_channel\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_icon_emoji\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_icon_url\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_link_names\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_mrkdwn\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_parse\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_reply_broadcast\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_text\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_thread_ts\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_unfurl_links\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_unfurl_media\",\n                \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_username\",\n            ],\n        },\n        \"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY\": {\n            \"display_name\": \"Search Messages Endpoint\",\n            \"action_fields\": [\n                \"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_count\",\n                \"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_highlight\",\n                \"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_page\",\n                \"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_query\",\n                \"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_sort\",\n                \"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_sort_dir\",\n            ],\n        },\n        \"SLACK_FETCH_CONVERSATION_HISTORY\": {\n            \"display_name\": \"Retrieve conversation history\",\n            \"action_fields\": [\n                \"SLACK_FETCH_CONVERSATION_HISTORY_channel\",\n                \"SLACK_FETCH_CONVERSATION_HISTORY_latest\",\n                \"SLACK_FETCH_CONVERSATION_HISTORY_oldest\",\n                \"SLACK_FETCH_CONVERSATION_HISTORY_inclusive\",\n                \"SLACK_FETCH_CONVERSATION_HISTORY_limit\",\n                \"SLACK_FETCH_CONVERSATION_HISTORY_cursor\",\n            ],\n        },\n        \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME\": {\n            \"display_name\": \"Schedule Message In Chat\",\n            \"action_fields\": [\n                \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_as_user\",\n                \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_attachments\",\n                \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_blocks\",\n                \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_channel\",\n                \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_link_names\",\n                \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_parse\",\n                \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_post_at\",\n                \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_reply_broadcast\",\n                \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_text\",\n                \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_thread_ts\",\n                \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_unfurl_links\",\n                \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_unfurl_media\",\n            ],\n        },\n        \"SLACK_CREATE_A_REMINDER\": {\n            \"display_name\": \"Add Reminder For User\",\n            \"action_fields\": [\n                \"SLACK_CREATE_A_REMINDER_text\",\n                \"SLACK_CREATE_A_REMINDER_time\",\n                \"SLACK_CREATE_A_REMINDER_user\",\n            ],\n        },\n    }\n\n    _all_fields = {field for action_data in _actions_data.values() for field in action_data[\"action_fields\"]}\n    _bool_variables = {\n        \"SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_include_locale\",\n        \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_as_user\",\n        \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_link_names\",\n        \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_mrkdwn\",\n        \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_reply_broadcast\",\n        \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_unfurl_links\",\n        \"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_unfurl_media\",\n        \"SLACK_FETCH_CONVERSATION_HISTORY_inclusive\",\n        \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_as_user\",\n        \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_link_names\",\n        \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_reply_broadcast\",\n        \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_unfurl_links\",\n        \"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_unfurl_media\",\n        \"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_exclude_archived\",\n        \"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_highlight\",\n    }\n\n    inputs = [\n        *ComposioBaseComponent.get_base_inputs(),\n        IntInput(\n            name=\"SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_limit\",\n            display_name=\"Limit\",\n            info=\"The maximum number of items to return. Fewer than the requested number of items may be returned, even if the end of the users list hasn't been reached. Providing no `limit` value will result in Slack attempting to deliver you the entire result set. If the collection is too large you may experience `limit_required` or HTTP 500 errors. \",  # noqa: E501\n            show=False,\n            value=1,\n        ),\n        MessageTextInput(\n            name=\"SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_cursor\",\n            display_name=\"Cursor\",\n            info=\"Paginate through collections of data by setting the `cursor` parameter to a `next_cursor` attribute returned by a previous request's `response_metadata`. Default value fetches the first `page` of the collection\",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"SLACK_LIST_ALL_SLACK_TEAM_USERS_WITH_PAGINATION_include_locale\",\n            display_name=\"Include Locale\",\n            info=\"Set this to `true` to receive the locale for users. Defaults to `false`\",\n            show=False,\n        ),\n        BoolInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_as_user\",\n            display_name=\"As User\",\n            info=\"Pass true to post the message as the authed user, instead of as a bot. Defaults to false\",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_attachments\",\n            display_name=\"Attachments\",\n            info=\"A JSON-based array of structured attachments, presented as a URL-encoded string. \",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_blocks\",\n            display_name=\"Blocks\",\n            info=\"A JSON-based array of structured blocks, presented as a URL-encoded string. \",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_channel\",\n            display_name=\"Channel\",\n            info=\"Channel, private group, or IM channel to send message to. Can be an encoded ID, or a name \",\n            show=False,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_icon_emoji\",\n            display_name=\"Icon Emoji\",\n            info=\"Emoji to use as the icon for this message. Overrides `icon_url`. Must be used in conjunction with `as_user` set to `false`, otherwise ignored\",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_icon_url\",\n            display_name=\"Icon Url\",\n            info=\"URL to an image to use as the icon for this message. Must be used in conjunction with `as_user` set to false, otherwise ignored\",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_link_names\",\n            display_name=\"Link Names\",\n            info=\"Find and link channel names and usernames.\",\n            show=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_mrkdwn\",\n            display_name=\"Mrkdwn\",\n            info=\"Disable Slack markup parsing by setting to `false`. Enabled by default.\",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_parse\",\n            display_name=\"Parse\",\n            info=\"Change how messages are treated. Defaults to `none` \",\n            show=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_reply_broadcast\",\n            display_name=\"Reply Broadcast\",\n            info=\"Used in conjunction with `thread_ts` and indicates whether reply should be made visible to everyone in the channel or conversation. Defaults to `false`. \",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_text\",\n            display_name=\"Text\",\n            info=\"How this field works and whether it is required depends on other fields you use in your API call\",\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_thread_ts\",\n            display_name=\"Thread Ts\",\n            info=\"Provide another message's `ts` value to make this message a reply. Avoid using a reply's `ts` value; use its parent instead. \",  # noqa: E501\n            show=False,\n        ),\n        BoolInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_unfurl_links\",\n            display_name=\"Unfurl Links\",\n            info=\"Pass true to enable unfurling of primarily text-based content.\",\n            show=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_unfurl_media\",\n            display_name=\"Unfurl Media\",\n            info=\"Pass false to disable unfurling of media content.\",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SENDS_A_MESSAGE_TO_A_SLACK_CHANNEL_username\",\n            display_name=\"Username\",\n            info=\"Set your bot's user name. Must be used in conjunction with `as_user` set to false, otherwise ignored\",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_UPDATES_A_SLACK_MESSAGE_as_user\",\n            display_name=\"As User\",\n            info=\"Pass true to update the message as the authed user\",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_UPDATES_A_SLACK_MESSAGE_attachments\",\n            display_name=\"Attachments\",\n            info=\"A JSON-based array of structured attachments, presented as a URL-encoded string. This field is required when not presenting `text`. If you don't include this field, the message's previous `attachments` will be retained. To remove previous `attachments`, include an empty array for this field. \",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_UPDATES_A_SLACK_MESSAGE_blocks\",\n            display_name=\"Blocks\",\n            info=\"A JSON-based array of structured blocks, presented as a URL-encoded string. If you don't include this field, the message's previous `blocks` will be retained. To remove previous `blocks`, include an empty array for this field. \",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_UPDATES_A_SLACK_MESSAGE_channel\",\n            display_name=\"Channel ID\",\n            info=\"Channel ID containing the message to be updated.\",\n            show=False,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_UPDATES_A_SLACK_MESSAGE_link_names\",\n            display_name=\"Link Names\",\n            info=\"Find and link channel names and usernames. Defaults to `none`. If you do not specify a value for this field, the original value set for the message will be overwritten with the default, `none`. \",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_UPDATES_A_SLACK_MESSAGE_parse\",\n            display_name=\"Parse\",\n            info=\"Change how messages are treated. Defaults to `client`, unlike `chat.postMessage`. Accepts either `none` or `full`. If you do not specify a value for this field, the original value set for the message will be overwritten with the default, `client`. \",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_UPDATES_A_SLACK_MESSAGE_text\",\n            display_name=\"Text\",\n            info=\"New text for the message, using the default formatting rules. It's not required when presenting `blocks` or `attachments`. \",  # noqa: E501\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"SLACK_UPDATES_A_SLACK_MESSAGE_ts\",\n            display_name=\"Ts\",\n            info=\"Timestamp of the message to be updated.\",\n            show=False,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_FETCH_CONVERSATION_HISTORY_channel\",\n            display_name=\"Channel ID\",\n            info=\"Channel ID to fetch history for.\",\n            show=False,\n        ),\n        IntInput(\n            name=\"SLACK_FETCH_CONVERSATION_HISTORY_latest\",\n            display_name=\"Latest\",\n            info=\"End of time range of messages to include in results.\",\n            show=False,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"SLACK_FETCH_CONVERSATION_HISTORY_oldest\",\n            display_name=\"Oldest\",\n            info=\"Start of time range of messages to include in results.\",\n            show=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"SLACK_FETCH_CONVERSATION_HISTORY_inclusive\",\n            display_name=\"Inclusive\",\n            info=\"Include messages with latest or oldest timestamp in results only when either timestamp is specified. \",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"SLACK_FETCH_CONVERSATION_HISTORY_limit\",\n            display_name=\"Limit\",\n            info=\"The maximum number of items to return. Fewer than the requested number of items may be returned, even if the end of the users list hasn't been reached. \",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_FETCH_CONVERSATION_HISTORY_cursor\",\n            display_name=\"Cursor\",\n            info=\"Paginate through collections of data by setting the `cursor` parameter to a `next_cursor` attribute returned by a previous request's `response_metadata`. Default value fetches the first 'page' of the collection. \",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_as_user\",\n            display_name=\"As User\",\n            info=\"Pass true to post the message as the authed user, instead of as a bot. Defaults to false\",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_attachments\",\n            display_name=\"Attachments\",\n            info=\"A JSON-based array of structured attachments, presented as a URL-encoded string. \",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_blocks\",\n            display_name=\"Blocks\",\n            info=\"A JSON-based array of structured blocks, presented as a URL-encoded string. \",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_channel\",\n            display_name=\"Channel\",\n            info=\"Channel, private group, or DM channel to send message to. Can be an encoded ID, or a name\",\n            show=False,\n            required=True,\n        ),\n        BoolInput(\n            name=\"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_link_names\",\n            display_name=\"Link Names\",\n            info=\"Find and link channel names and usernames.\",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_parse\",\n            display_name=\"Parse\",\n            info=\"Change how messages are treated. Defaults to `none`\",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_post_at\",\n            display_name=\"Post At\",\n            info=\"Unix EPOCH timestamp of time in future to send the message.\",\n            show=False,\n        ),\n        BoolInput(\n            name=\"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_reply_broadcast\",\n            display_name=\"Reply Broadcast\",\n            info=\"Used in conjunction with `thread_ts` and indicates whether reply should be made visible to everyone in the channel or conversation. Defaults to `false`. \",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_text\",\n            display_name=\"Text\",\n            info=\"How this field works and whether it is required depends on other fields you use in your API call\",\n            show=False,\n        ),\n        IntInput(\n            name=\"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_thread_ts\",\n            display_name=\"Thread Ts\",\n            info=\"Provide another message's `ts` value to make this message a reply. Avoid using a reply's `ts` value; use its parent instead. \",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_unfurl_links\",\n            display_name=\"Unfurl Links\",\n            info=\"Pass true to enable unfurling of primarily text-based content.\",\n            show=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"SLACK_SCHEDULES_A_MESSAGE_TO_A_CHANNEL_AT_A_SPECIFIED_TIME_unfurl_media\",\n            display_name=\"Unfurl Media\",\n            info=\"Pass false to disable unfurling of media content.\",\n            show=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_exclude_archived\",\n            display_name=\"Exclude Archived\",\n            info=\"Set to `true` to exclude archived channels from the list\",\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_types\",\n            display_name=\"Types\",\n            info=\"Mix and match channel types by providing a comma-separated list of any combination of `public_channel`, `private_channel`, `mpim`, `im` \",  # noqa: E501\n            show=False,\n        ),\n        IntInput(\n            name=\"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_limit\",\n            display_name=\"Limit\",\n            info=\"The maximum number of items to return. Fewer than the requested number of items may be returned, even if the end of the list hasn't been reached. Must be an integer no larger than 1000. \",  # noqa: E501\n            show=False,\n            value=1,\n        ),\n        MessageTextInput(\n            name=\"SLACK_LIST_ALL_SLACK_TEAM_CHANNELS_WITH_VARIOUS_FILTERS_cursor\",\n            display_name=\"Cursor\",\n            info=\"Paginate through collections of data by setting the `cursor` parameter to a `next_cursor` attribute returned by a previous request's `response_metadata`. Default value fetches the first 'page' of the collection\",  # noqa: E501\n            show=False,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_count\",\n            display_name=\"Count\",\n            info=\"Pass the number of results you want per 'page'. Maximum of `100`.\",\n            show=False,\n            value=1,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_highlight\",\n            display_name=\"Highlight\",\n            info=\"Pass a value of `true` to enable query highlight markers\",\n            show=False,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_page\",\n            display_name=\"Page\",\n            info=\"Page\",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_query\",\n            display_name=\"Query\",\n            info=\"Search query.\",\n            show=False,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_sort\",\n            display_name=\"Sort\",\n            info=\"Return matches sorted by either `score` or `timestamp`.\",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_SEARCH_FOR_MESSAGES_WITH_QUERY_sort_dir\",\n            display_name=\"Sort Dir\",\n            info=\"Change sort direction to ascending (`asc`) or descending (`desc`).\",\n            show=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_CREATE_A_REMINDER_text\",\n            display_name=\"Text\",\n            info=\"The content of the reminder\",\n            show=False,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_CREATE_A_REMINDER_time\",\n            display_name=\"Time\",\n            info=\"When this reminder should happen: the Unix timestamp (up to five years from now), the number of seconds until the reminder (if within 24 hours), or a natural language description (Ex. 'in 15 minutes,' or 'every Thursday') \",  # noqa: E501\n            show=False,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"SLACK_CREATE_A_REMINDER_user\",\n            display_name=\"User\",\n            info=\"The user who will receive the reminder. If no user is specified, the reminder will go to user who created it. \",  # noqa: E501\n            show=False,\n        ),\n    ]\n\n    def execute_action(self):\n        \"\"\"Execute action and return response as Message.\"\"\"\n        try:\n            from composio.client.enums import Action\n        except ImportError:\n            try:\n                from composio import Action\n            except ImportError:\n                msg = \"Composio Action class is not available. Please install composio package with correct version.\"\n                raise RuntimeError(msg) from None\n\n        toolset = self._build_wrapper()\n\n        try:\n            self._build_action_maps()\n            display_name = self.action[0][\"name\"] if isinstance(self.action, list) and self.action else self.action\n            action_key = self._display_to_key_map.get(display_name)\n            if not action_key:\n                msg = f\"Invalid action: {display_name}\"\n                raise ValueError(msg)\n\n            enum_name = getattr(Action, action_key)\n            params = {}\n            if action_key in self._actions_data:\n                for field in self._actions_data[action_key][\"action_fields\"]:\n                    value = getattr(self, field)\n\n                    if value is None or value == \"\":\n                        continue\n\n                    if field in self._bool_variables:\n                        value = bool(value)\n\n                    param_name = field.replace(action_key + \"_\", \"\")\n\n                    if param_name == \"as_user\":\n                        value = True\n\n                    params[param_name] = value\n\n            result = toolset.execute_action(\n                action=enum_name,\n                params=params,\n            )\n            if not result.get(\"successful\"):\n                return {\"error\": result.get(\"error\", \"No response\")}\n\n            return result.get(\"data\", [])\n        except Exception as e:\n            logger.error(f\"Error executing action: {e}\")\n            display_name = self.action[0][\"name\"] if isinstance(self.action, list) and self.action else str(self.action)\n            msg = f\"Failed to execute {display_name}: {e!s}\"\n            raise ValueError(msg) from e\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        return super().update_build_config(build_config, field_value, field_name)\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioSlackbotAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Slackbot","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Slack","legacy":false,"metadata":{"code_hash":"b132fa55bcee","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.slackbot_composio.ComposioSlackbotAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioSlackbotAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Slackbot\"\n    icon = \"Slack\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"slackbot\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Slackbot component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioSupabaseAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Supabase","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Supabase","legacy":false,"metadata":{"code_hash":"7ad58ce34cc0","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.supabase_composio.ComposioSupabaseAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioSupabaseAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Supabase\"\n    icon = \"Supabase\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"supabase\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Supabase component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioTimelinesAIAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"TimelinesAI","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Timelinesai","legacy":false,"metadata":{"code_hash":"76e70e2de4d3","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.timelinesai_composio.ComposioTimelinesAIAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioTimelinesAIAPIComponent(ComposioBaseComponent):\n    display_name: str = \"TimelinesAI\"\n    icon = \"Timelinesai\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"timelinesai\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for TimelinesAI component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioTodoistAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Todoist","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Todoist","legacy":false,"metadata":{"code_hash":"4dd9852f2058","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.todoist_composio.ComposioTodoistAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioTodoistAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Todoist\"\n    icon = \"Todoist\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"todoist\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Todoist component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioWrikeAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Wrike","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Wrike","legacy":false,"metadata":{"code_hash":"a5f2cf00ca08","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.wrike_composio.ComposioWrikeAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioWrikeAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Wrike\"\n    icon = \"Wrike\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"wrike\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Wrike component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ComposioYoutubeAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Youtube","documentation":"https://docs.composio.dev","edited":false,"field_order":["entity_id","api_key","auth_mode","auth_link","client_id","client_secret","verification_token","redirect_uri","authorization_url","token_url","api_key_field","generic_api_key","token","access_token","refresh_token","username","password","domain","base_url","bearer_token","authorization_code","scopes","subdomain","instance_url","tenant_id","action_button"],"frozen":false,"icon":"Youtube","legacy":false,"metadata":{"code_hash":"11a5b77fc0ad","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.composio.youtube_composio.ComposioYoutubeAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataFrame","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"access_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"action_button":{"_input_type":"SortableListInput","advanced":false,"display_name":"Action","dynamic":false,"helper_text":"Please connect before selecting actions.","helper_text_metadata":{"variant":"destructive"},"info":"","limit":1,"name":"action_button","options":[],"placeholder":"Select action","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":"disabled"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Composio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"COMPOSIO_API_KEY"},"api_key_field":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key_field","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"auth_link":{"_input_type":"AuthInput","advanced":false,"auth_tooltip":"Please insert a valid Composio API Key.","dynamic":false,"info":"","name":"auth_link","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"auth","value":""},"auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Auth Mode","dynamic":false,"external_options":{},"helper_text":"Choose how to authenticate with the toolkit.","info":"","name":"auth_mode","options":[],"options_metadata":[],"placeholder":"Select auth mode","real_time_refresh":true,"required":false,"show":false,"title_case":false,"toggle":true,"toggle_disable":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"authorization_code":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Authorization Code","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"authorization_code","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"authorization_url":{"_input_type":"StrInput","advanced":false,"display_name":"Authorization URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"authorization_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"bearer_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Bearer Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"bearer_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_id","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"client_secret":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Client Secret","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"client_secret","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.composio.composio_base import ComposioBaseComponent\n\n\nclass ComposioYoutubeAPIComponent(ComposioBaseComponent):\n    display_name: str = \"Youtube\"\n    icon = \"Youtube\"\n    documentation: str = \"https://docs.composio.dev\"\n    app_name = \"youtube\"\n\n    def set_default_tools(self):\n        \"\"\"Set the default tools for Youtube component.\"\"\"\n"},"domain":{"_input_type":"StrInput","advanced":false,"display_name":"Domain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"domain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"entity_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Entity ID","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"default"},"generic_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"generic_api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"instance_url":{"_input_type":"StrInput","advanced":false,"display_name":"Instance URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instance_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"redirect_uri":{"_input_type":"StrInput","advanced":false,"display_name":"Redirect URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redirect_uri","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"refresh_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Refresh Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"refresh_token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"scopes":{"_input_type":"StrInput","advanced":false,"display_name":"Scopes","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scopes","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"subdomain":{"_input_type":"StrInput","advanced":false,"display_name":"Subdomain","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"subdomain","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tenant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Tenant ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tenant_id","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"type":"str","value":""},"token_url":{"_input_type":"StrInput","advanced":false,"display_name":"Token URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"token_url","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verification_token":{"_input_type":"StrInput","advanced":false,"display_name":"Verification Token","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"verification_token","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["confluence",{"Confluence":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Confluence wiki collaboration platform","display_name":"Confluence","documentation":"https://python.langchain.com/v0.2/docs/integrations/document_loaders/confluence/","edited":false,"field_order":["url","username","api_key","space_key","cloud","content_format","max_pages"],"frozen":false,"icon":"Confluence","legacy":false,"metadata":{"code_hash":"8a7ef34b66e4","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.confluence.confluence.ConfluenceComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"load_documents","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Confluence API Key","dynamic":false,"info":"Atlassian Key. Create at: https://id.atlassian.com/manage-profile/security/api-tokens","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"cloud":{"_input_type":"BoolInput","advanced":true,"display_name":"Use Cloud?","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"cloud","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_community.document_loaders import ConfluenceLoader\nfrom langchain_community.document_loaders.confluence import ContentFormat\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import BoolInput, DropdownInput, IntInput, Output, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass ConfluenceComponent(Component):\n    display_name = \"Confluence\"\n    description = \"Confluence wiki collaboration platform\"\n    documentation = \"https://python.langchain.com/v0.2/docs/integrations/document_loaders/confluence/\"\n    trace_type = \"tool\"\n    icon = \"Confluence\"\n    name = \"Confluence\"\n\n    inputs = [\n        StrInput(\n            name=\"url\",\n            display_name=\"Site URL\",\n            required=True,\n            info=\"The base URL of the Confluence Space. Example: https://<company>.atlassian.net/wiki.\",\n        ),\n        StrInput(\n            name=\"username\",\n            display_name=\"Username\",\n            required=True,\n            info=\"Atlassian User E-mail. Example: email@example.com\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Confluence API Key\",\n            required=True,\n            info=\"Atlassian Key. Create at: https://id.atlassian.com/manage-profile/security/api-tokens\",\n        ),\n        StrInput(name=\"space_key\", display_name=\"Space Key\", required=True),\n        BoolInput(name=\"cloud\", display_name=\"Use Cloud?\", required=True, value=True, advanced=True),\n        DropdownInput(\n            name=\"content_format\",\n            display_name=\"Content Format\",\n            options=[\n                ContentFormat.EDITOR.value,\n                ContentFormat.EXPORT_VIEW.value,\n                ContentFormat.ANONYMOUS_EXPORT_VIEW.value,\n                ContentFormat.STORAGE.value,\n                ContentFormat.VIEW.value,\n            ],\n            value=ContentFormat.STORAGE.value,\n            required=True,\n            advanced=True,\n            info=\"Specify content format, defaults to ContentFormat.STORAGE\",\n        ),\n        IntInput(\n            name=\"max_pages\",\n            display_name=\"Max Pages\",\n            required=False,\n            value=1000,\n            advanced=True,\n            info=\"Maximum number of pages to retrieve in total, defaults 1000\",\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"data\", display_name=\"Data\", method=\"load_documents\"),\n    ]\n\n    def build_confluence(self) -> ConfluenceLoader:\n        content_format = ContentFormat(self.content_format)\n        return ConfluenceLoader(\n            url=self.url,\n            username=self.username,\n            api_key=self.api_key,\n            cloud=self.cloud,\n            space_key=self.space_key,\n            content_format=content_format,\n            max_pages=self.max_pages,\n        )\n\n    def load_documents(self) -> list[Data]:\n        confluence = self.build_confluence()\n        documents = confluence.load()\n        data = [Data.from_document(doc) for doc in documents]  # Using the from_document method of Data\n        self.status = data\n        return data\n"},"content_format":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Content Format","dynamic":false,"external_options":{},"info":"Specify content format, defaults to ContentFormat.STORAGE","name":"content_format","options":["body.editor","body.export_view","body.anonymous_export_view","body.storage","body.view"],"options_metadata":[],"placeholder":"","required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"body.storage"},"max_pages":{"_input_type":"IntInput","advanced":true,"display_name":"Max Pages","dynamic":false,"info":"Maximum number of pages to retrieve in total, defaults 1000","list":false,"list_add_label":"Add More","name":"max_pages","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1000},"space_key":{"_input_type":"StrInput","advanced":false,"display_name":"Space Key","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"space_key","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"url":{"_input_type":"StrInput","advanced":false,"display_name":"Site URL","dynamic":false,"info":"The base URL of the Confluence Space. Example: https://<company>.atlassian.net/wiki.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"Atlassian User E-mail. Example: email@example.com","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["couchbase",{"Couchbase":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Couchbase Vector Store with search capabilities","display_name":"Couchbase","documentation":"","edited":false,"field_order":["couchbase_connection_string","couchbase_username","couchbase_password","bucket_name","scope_name","collection_name","index_name","ingest_data","search_query","should_cache_vector_store","embedding","number_of_results"],"frozen":false,"icon":"Couchbase","legacy":false,"metadata":{"code_hash":"70ed475a6f48","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null},{"name":"couchbase","version":null}],"total_dependencies":3},"module":"lfx.components.couchbase.couchbase.CouchbaseVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","bucket_name":{"_input_type":"StrInput","advanced":false,"display_name":"Bucket Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"bucket_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from datetime import timedelta\n\nfrom langchain_community.vectorstores import CouchbaseVectorStore\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.io import HandleInput, IntInput, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass CouchbaseVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Couchbase\"\n    description = \"Couchbase Vector Store with search capabilities\"\n    name = \"Couchbase\"\n    icon = \"Couchbase\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"couchbase_connection_string\", display_name=\"Couchbase Cluster connection string\", required=True\n        ),\n        StrInput(name=\"couchbase_username\", display_name=\"Couchbase username\", required=True),\n        SecretStrInput(name=\"couchbase_password\", display_name=\"Couchbase password\", required=True),\n        StrInput(name=\"bucket_name\", display_name=\"Bucket Name\", required=True),\n        StrInput(name=\"scope_name\", display_name=\"Scope Name\", required=True),\n        StrInput(name=\"collection_name\", display_name=\"Collection Name\", required=True),\n        StrInput(name=\"index_name\", display_name=\"Index Name\", required=True),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> CouchbaseVectorStore:\n        try:\n            from couchbase.auth import PasswordAuthenticator\n            from couchbase.cluster import Cluster\n            from couchbase.options import ClusterOptions\n        except ImportError as e:\n            msg = \"Failed to import Couchbase dependencies. Install it using `uv pip install langflow[couchbase] --pre`\"\n            raise ImportError(msg) from e\n\n        try:\n            auth = PasswordAuthenticator(self.couchbase_username, self.couchbase_password)\n            options = ClusterOptions(auth)\n            cluster = Cluster(self.couchbase_connection_string, options)\n\n            cluster.wait_until_ready(timedelta(seconds=5))\n        except Exception as e:\n            msg = f\"Failed to connect to Couchbase: {e}\"\n            raise ValueError(msg) from e\n\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents:\n            couchbase_vs = CouchbaseVectorStore.from_documents(\n                documents=documents,\n                cluster=cluster,\n                bucket_name=self.bucket_name,\n                scope_name=self.scope_name,\n                collection_name=self.collection_name,\n                embedding=self.embedding,\n                index_name=self.index_name,\n            )\n\n        else:\n            couchbase_vs = CouchbaseVectorStore(\n                cluster=cluster,\n                bucket_name=self.bucket_name,\n                scope_name=self.scope_name,\n                collection_name=self.collection_name,\n                embedding=self.embedding,\n                index_name=self.index_name,\n            )\n\n        return couchbase_vs\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n"},"collection_name":{"_input_type":"StrInput","advanced":false,"display_name":"Collection Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"couchbase_connection_string":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Couchbase Cluster connection string","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"couchbase_connection_string","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"couchbase_password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Couchbase password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"couchbase_password","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"couchbase_username":{"_input_type":"StrInput","advanced":false,"display_name":"Couchbase username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"couchbase_username","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"index_name":{"_input_type":"StrInput","advanced":false,"display_name":"Index Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"index_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"scope_name":{"_input_type":"StrInput","advanced":false,"display_name":"Scope Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scope_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false}}],["crewai",{"CrewAIAgentComponent":{"base_classes":["NoneType"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Represents an agent of CrewAI.","display_name":"CrewAI Agent","documentation":"https://docs.crewai.com/how-to/LLM-Connections/","edited":false,"field_order":["role","goal","backstory","tools","llm","memory","verbose","allow_delegation","allow_code_execution","kwargs"],"frozen":false,"icon":"CrewAI","legacy":true,"metadata":{"code_hash":"a23f0923049d","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"crewai","version":null}],"total_dependencies":2},"module":"lfx.components.crewai.crewai.CrewAIAgentComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Agent","group_outputs":false,"method":"build_output","name":"output","selected":"NoneType","tool_mode":true,"types":["NoneType"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":[],"template":{"_type":"Component","allow_code_execution":{"_input_type":"BoolInput","advanced":true,"display_name":"Allow Code Execution","dynamic":false,"info":"Whether the agent is allowed to execute code.","list":false,"list_add_label":"Add More","name":"allow_code_execution","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"allow_delegation":{"_input_type":"BoolInput","advanced":false,"display_name":"Allow Delegation","dynamic":false,"info":"Whether the agent is allowed to delegate tasks to other agents.","list":false,"list_add_label":"Add More","name":"allow_delegation","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"backstory":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Backstory","dynamic":false,"info":"The backstory of the agent.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"backstory","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.agents.crewai.crew import convert_llm, convert_tools\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\n\n\nclass CrewAIAgentComponent(Component):\n    \"\"\"Component for creating a CrewAI agent.\n\n    This component allows you to create a CrewAI agent with the specified role, goal, backstory, tools,\n    and language model.\n\n    Args:\n        Component (Component): Base class for all components.\n\n    Returns:\n        Agent: CrewAI agent.\n    \"\"\"\n\n    display_name = \"CrewAI Agent\"\n    description = \"Represents an agent of CrewAI.\"\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n    legacy = True\n    replacement = \"agents.Agent\"\n\n    inputs = [\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agents disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=False,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"kwargs\",\n            display_name=\"kwargs\",\n            info=\"kwargs of agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Agent\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self):\n        try:\n            from crewai import Agent\n        except ImportError as e:\n            msg = \"CrewAI is not installed. Please install it with `uv pip install crewai`.\"\n            raise ImportError(msg) from e\n\n        kwargs = self.kwargs or {}\n\n        # Define the Agent\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=convert_llm(self.llm),\n            verbose=self.verbose,\n            memory=self.memory,\n            tools=convert_tools(self.tools),\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **kwargs,\n        )\n\n        self.status = repr(agent)\n\n        return agent\n"},"goal":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Goal","dynamic":false,"info":"The objective of the agent.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"goal","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"kwargs":{"_input_type":"DictInput","advanced":true,"display_name":"kwargs","dynamic":false,"info":"kwargs of agent.","list":true,"list_add_label":"Add More","name":"kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"llm":{"_input_type":"HandleInput","advanced":false,"display_name":"Language Model","dynamic":false,"info":"Language model that will run the agent.","input_types":["LanguageModel"],"list":false,"list_add_label":"Add More","name":"llm","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"memory":{"_input_type":"BoolInput","advanced":true,"display_name":"Memory","dynamic":false,"info":"Whether the agent should have memory or not","list":false,"list_add_label":"Add More","name":"memory","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"role":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Role","dynamic":false,"info":"The role of the agent.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"role","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"tools":{"_input_type":"HandleInput","advanced":false,"display_name":"Tools","dynamic":false,"info":"Tools at agents disposal","input_types":["Tool"],"list":true,"list_add_label":"Add More","name":"tools","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":[]},"verbose":{"_input_type":"BoolInput","advanced":true,"display_name":"Verbose","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"verbose","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false},"HierarchicalCrewComponent":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Represents a group of agents, defining how they should collaborate and the tasks they should perform.","display_name":"Hierarchical Crew","documentation":"https://docs.crewai.com/how-to/Hierarchical/","edited":false,"field_order":["verbose","memory","use_cache","max_rpm","share_crew","function_calling_llm","agents","tasks","manager_llm","manager_agent"],"frozen":false,"icon":"CrewAI","legacy":true,"metadata":{"code_hash":"144be482cfb0","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"crewai","version":null}],"total_dependencies":2},"module":"lfx.components.crewai.hierarchical_crew.HierarchicalCrewComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Output","group_outputs":false,"method":"build_output","name":"output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":[],"template":{"_type":"Component","agents":{"_input_type":"HandleInput","advanced":false,"display_name":"Agents","dynamic":false,"info":"","input_types":["Agent"],"list":true,"list_add_label":"Add More","name":"agents","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.agents.crewai.crew import BaseCrewComponent\nfrom lfx.io import HandleInput\n\n\nclass HierarchicalCrewComponent(BaseCrewComponent):\n    display_name: str = \"Hierarchical Crew\"\n    description: str = (\n        \"Represents a group of agents, defining how they should collaborate and the tasks they should perform.\"\n    )\n    documentation: str = \"https://docs.crewai.com/how-to/Hierarchical/\"\n    icon = \"CrewAI\"\n    legacy = True\n    replacement = \"agents.Agent\"\n\n    inputs = [\n        *BaseCrewComponent.get_base_inputs(),\n        HandleInput(name=\"agents\", display_name=\"Agents\", input_types=[\"Agent\"], is_list=True),\n        HandleInput(name=\"tasks\", display_name=\"Tasks\", input_types=[\"HierarchicalTask\"], is_list=True),\n        HandleInput(name=\"manager_llm\", display_name=\"Manager LLM\", input_types=[\"LanguageModel\"], required=False),\n        HandleInput(name=\"manager_agent\", display_name=\"Manager Agent\", input_types=[\"Agent\"], required=False),\n    ]\n\n    def build_crew(self):\n        try:\n            from crewai import Crew, Process\n        except ImportError as e:\n            msg = \"CrewAI is not installed. Please install it with `uv pip install crewai`.\"\n            raise ImportError(msg) from e\n\n        tasks, agents = self.get_tasks_and_agents()\n        manager_llm = self.get_manager_llm()\n\n        return Crew(\n            agents=agents,\n            tasks=tasks,\n            process=Process.hierarchical,\n            verbose=self.verbose,\n            memory=self.memory,\n            cache=self.use_cache,\n            max_rpm=self.max_rpm,\n            share_crew=self.share_crew,\n            function_calling_llm=self.function_calling_llm,\n            manager_agent=self.manager_agent,\n            manager_llm=manager_llm,\n            step_callback=self.get_step_callback(),\n            task_callback=self.get_task_callback(),\n        )\n"},"function_calling_llm":{"_input_type":"HandleInput","advanced":true,"display_name":"Function Calling LLM","dynamic":false,"info":"Turns the ReAct CrewAI agent into a function-calling agent","input_types":["LanguageModel"],"list":false,"list_add_label":"Add More","name":"function_calling_llm","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"manager_agent":{"_input_type":"HandleInput","advanced":false,"display_name":"Manager Agent","dynamic":false,"info":"","input_types":["Agent"],"list":false,"list_add_label":"Add More","name":"manager_agent","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"manager_llm":{"_input_type":"HandleInput","advanced":false,"display_name":"Manager LLM","dynamic":false,"info":"","input_types":["LanguageModel"],"list":false,"list_add_label":"Add More","name":"manager_llm","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"max_rpm":{"_input_type":"IntInput","advanced":true,"display_name":"Max RPM","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"max_rpm","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":100},"memory":{"_input_type":"BoolInput","advanced":true,"display_name":"Memory","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"memory","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"share_crew":{"_input_type":"BoolInput","advanced":true,"display_name":"Share Crew","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"share_crew","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"tasks":{"_input_type":"HandleInput","advanced":false,"display_name":"Tasks","dynamic":false,"info":"","input_types":["HierarchicalTask"],"list":true,"list_add_label":"Add More","name":"tasks","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"use_cache":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"use_cache","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"verbose":{"_input_type":"IntInput","advanced":true,"display_name":"Verbose","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"verbose","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":0}},"tool_mode":false},"HierarchicalTaskComponent":{"base_classes":["HierarchicalTask"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Each task must have a description, an expected output and an agent responsible for execution.","display_name":"Hierarchical Task","documentation":"","edited":false,"field_order":["task_description","expected_output","tools"],"frozen":false,"icon":"CrewAI","legacy":true,"metadata":{"code_hash":"25071652dc20","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.crewai.hierarchical_task.HierarchicalTaskComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Task","group_outputs":false,"method":"build_task","name":"task_output","selected":"HierarchicalTask","tool_mode":true,"types":["HierarchicalTask"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":[],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.agents.crewai.tasks import HierarchicalTask\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import HandleInput, MultilineInput, Output\n\n\nclass HierarchicalTaskComponent(Component):\n    display_name: str = \"Hierarchical Task\"\n    description: str = \"Each task must have a description, an expected output and an agent responsible for execution.\"\n    icon = \"CrewAI\"\n    legacy = True\n    replacement = \"agents.Agent\"\n    inputs = [\n        MultilineInput(\n            name=\"task_description\",\n            display_name=\"Description\",\n            info=\"Descriptive text detailing task's purpose and execution.\",\n        ),\n        MultilineInput(\n            name=\"expected_output\",\n            display_name=\"Expected Output\",\n            info=\"Clear definition of expected task outcome.\",\n        ),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"List of tools/resources limited for task execution. Uses the Agent tools by default.\",\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Task\", name=\"task_output\", method=\"build_task\"),\n    ]\n\n    def build_task(self) -> HierarchicalTask:\n        task = HierarchicalTask(\n            description=self.task_description,\n            expected_output=self.expected_output,\n            tools=self.tools or [],\n        )\n        self.status = task\n        return task\n"},"expected_output":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Expected Output","dynamic":false,"info":"Clear definition of expected task outcome.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"expected_output","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"task_description":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Description","dynamic":false,"info":"Descriptive text detailing task's purpose and execution.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"task_description","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"tools":{"_input_type":"HandleInput","advanced":true,"display_name":"Tools","dynamic":false,"info":"List of tools/resources limited for task execution. Uses the Agent tools by default.","input_types":["Tool"],"list":true,"list_add_label":"Add More","name":"tools","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""}},"tool_mode":false},"SequentialCrewComponent":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Represents a group of agents with tasks that are executed sequentially.","display_name":"Sequential Crew","documentation":"https://docs.crewai.com/how-to/Sequential/","edited":false,"field_order":["verbose","memory","use_cache","max_rpm","share_crew","function_calling_llm","tasks"],"frozen":false,"icon":"CrewAI","legacy":true,"metadata":{"code_hash":"42e59f6d6572","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"crewai","version":null}],"total_dependencies":2},"module":"lfx.components.crewai.sequential_crew.SequentialCrewComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Output","group_outputs":false,"method":"build_output","name":"output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":[],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.agents.crewai.crew import BaseCrewComponent\nfrom lfx.io import HandleInput\nfrom lfx.schema.message import Message\n\n\nclass SequentialCrewComponent(BaseCrewComponent):\n    display_name: str = \"Sequential Crew\"\n    description: str = \"Represents a group of agents with tasks that are executed sequentially.\"\n    documentation: str = \"https://docs.crewai.com/how-to/Sequential/\"\n    icon = \"CrewAI\"\n    legacy = True\n    replacement = \"agents.Agent\"\n\n    inputs = [\n        *BaseCrewComponent.get_base_inputs(),\n        HandleInput(name=\"tasks\", display_name=\"Tasks\", input_types=[\"SequentialTask\"], is_list=True),\n    ]\n\n    @property\n    def agents(self: \"SequentialCrewComponent\") -> list:\n        # Derive agents directly from linked tasks\n        return [task.agent for task in self.tasks if hasattr(task, \"agent\")]\n\n    def get_tasks_and_agents(self, agents_list=None) -> tuple[list, list]:\n        # Use the agents property to derive agents\n        if not agents_list:\n            existing_agents = self.agents\n            agents_list = existing_agents + (agents_list or [])\n\n        return super().get_tasks_and_agents(agents_list=agents_list)\n\n    def build_crew(self) -> Message:\n        try:\n            from crewai import Crew, Process\n        except ImportError as e:\n            msg = \"CrewAI is not installed. Please install it with `uv pip install crewai`.\"\n            raise ImportError(msg) from e\n\n        tasks, agents = self.get_tasks_and_agents()\n\n        return Crew(\n            agents=agents,\n            tasks=tasks,\n            process=Process.sequential,\n            verbose=self.verbose,\n            memory=self.memory,\n            cache=self.use_cache,\n            max_rpm=self.max_rpm,\n            share_crew=self.share_crew,\n            function_calling_llm=self.function_calling_llm,\n            step_callback=self.get_step_callback(),\n            task_callback=self.get_task_callback(),\n        )\n"},"function_calling_llm":{"_input_type":"HandleInput","advanced":true,"display_name":"Function Calling LLM","dynamic":false,"info":"Turns the ReAct CrewAI agent into a function-calling agent","input_types":["LanguageModel"],"list":false,"list_add_label":"Add More","name":"function_calling_llm","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"max_rpm":{"_input_type":"IntInput","advanced":true,"display_name":"Max RPM","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"max_rpm","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":100},"memory":{"_input_type":"BoolInput","advanced":true,"display_name":"Memory","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"memory","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"share_crew":{"_input_type":"BoolInput","advanced":true,"display_name":"Share Crew","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"share_crew","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"tasks":{"_input_type":"HandleInput","advanced":false,"display_name":"Tasks","dynamic":false,"info":"","input_types":["SequentialTask"],"list":true,"list_add_label":"Add More","name":"tasks","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"use_cache":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"use_cache","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"verbose":{"_input_type":"IntInput","advanced":true,"display_name":"Verbose","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"verbose","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":0}},"tool_mode":false},"SequentialTaskAgentComponent":{"base_classes":["SequentialTask"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Creates a CrewAI Task and its associated Agent.","display_name":"Sequential Task Agent","documentation":"https://docs.crewai.com/how-to/LLM-Connections/","edited":false,"field_order":["role","goal","backstory","tools","llm","memory","verbose","allow_delegation","allow_code_execution","agent_kwargs","task_description","expected_output","async_execution","previous_task"],"frozen":false,"icon":"CrewAI","legacy":true,"metadata":{"code_hash":"0a5483ef82c3","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"crewai","version":null}],"total_dependencies":2},"module":"lfx.components.crewai.sequential_task_agent.SequentialTaskAgentComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Sequential Task","group_outputs":false,"method":"build_agent_and_task","name":"task_output","selected":"SequentialTask","tool_mode":true,"types":["SequentialTask"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":[],"template":{"_type":"Component","agent_kwargs":{"_input_type":"DictInput","advanced":true,"display_name":"Agent kwargs","dynamic":false,"info":"Additional kwargs for the agent.","list":true,"list_add_label":"Add More","name":"agent_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"allow_code_execution":{"_input_type":"BoolInput","advanced":true,"display_name":"Allow Code Execution","dynamic":false,"info":"Whether the agent is allowed to execute code.","list":false,"list_add_label":"Add More","name":"allow_code_execution","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"allow_delegation":{"_input_type":"BoolInput","advanced":true,"display_name":"Allow Delegation","dynamic":false,"info":"Whether the agent is allowed to delegate tasks to other agents.","list":false,"list_add_label":"Add More","name":"allow_delegation","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"async_execution":{"_input_type":"BoolInput","advanced":true,"display_name":"Async Execution","dynamic":false,"info":"Boolean flag indicating asynchronous task execution.","list":false,"list_add_label":"Add More","name":"async_execution","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"backstory":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Backstory","dynamic":false,"info":"The backstory of the agent.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"backstory","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.agents.crewai.tasks import SequentialTask\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\n\n\nclass SequentialTaskAgentComponent(Component):\n    display_name = \"Sequential Task Agent\"\n    description = \"Creates a CrewAI Task and its associated Agent.\"\n    documentation = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n    legacy = True\n    replacement = \"agents.Agent\"\n\n    inputs = [\n        # Agent inputs\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MultilineInput(\n            name=\"backstory\",\n            display_name=\"Backstory\",\n            info=\"The backstory of the agent.\",\n        ),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agent's disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"agent_kwargs\",\n            display_name=\"Agent kwargs\",\n            info=\"Additional kwargs for the agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n        # Task inputs\n        MultilineInput(\n            name=\"task_description\",\n            display_name=\"Task Description\",\n            info=\"Descriptive text detailing task's purpose and execution.\",\n        ),\n        MultilineInput(\n            name=\"expected_output\",\n            display_name=\"Expected Task Output\",\n            info=\"Clear definition of expected task outcome.\",\n        ),\n        BoolInput(\n            name=\"async_execution\",\n            display_name=\"Async Execution\",\n            value=False,\n            advanced=True,\n            info=\"Boolean flag indicating asynchronous task execution.\",\n        ),\n        # Chaining input\n        HandleInput(\n            name=\"previous_task\",\n            display_name=\"Previous Task\",\n            input_types=[\"SequentialTask\"],\n            info=\"The previous task in the sequence (for chaining).\",\n            required=False,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Sequential Task\",\n            name=\"task_output\",\n            method=\"build_agent_and_task\",\n        ),\n    ]\n\n    def build_agent_and_task(self) -> list[SequentialTask]:\n        try:\n            from crewai import Agent, Task\n        except ImportError as e:\n            msg = \"CrewAI is not installed. Please install it with `uv pip install crewai`.\"\n            raise ImportError(msg) from e\n\n        # Build the agent\n        agent_kwargs = self.agent_kwargs or {}\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=self.llm,\n            verbose=self.verbose,\n            memory=self.memory,\n            tools=self.tools or [],\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **agent_kwargs,\n        )\n\n        # Build the task\n        task = Task(\n            description=self.task_description,\n            expected_output=self.expected_output,\n            agent=agent,\n            async_execution=self.async_execution,\n        )\n\n        # If there's a previous task, create a list of tasks\n        if self.previous_task:\n            tasks = [*self.previous_task, task] if isinstance(self.previous_task, list) else [self.previous_task, task]\n        else:\n            tasks = [task]\n\n        self.status = f\"Agent: {agent!r}\\nTask: {task!r}\"\n        return tasks\n"},"expected_output":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Expected Task Output","dynamic":false,"info":"Clear definition of expected task outcome.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"expected_output","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"goal":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Goal","dynamic":false,"info":"The objective of the agent.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"goal","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"llm":{"_input_type":"HandleInput","advanced":false,"display_name":"Language Model","dynamic":false,"info":"Language model that will run the agent.","input_types":["LanguageModel"],"list":false,"list_add_label":"Add More","name":"llm","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"memory":{"_input_type":"BoolInput","advanced":true,"display_name":"Memory","dynamic":false,"info":"Whether the agent should have memory or not","list":false,"list_add_label":"Add More","name":"memory","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"previous_task":{"_input_type":"HandleInput","advanced":false,"display_name":"Previous Task","dynamic":false,"info":"The previous task in the sequence (for chaining).","input_types":["SequentialTask"],"list":false,"list_add_label":"Add More","name":"previous_task","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"role":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Role","dynamic":false,"info":"The role of the agent.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"role","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"task_description":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Task Description","dynamic":false,"info":"Descriptive text detailing task's purpose and execution.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"task_description","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"tools":{"_input_type":"HandleInput","advanced":false,"display_name":"Tools","dynamic":false,"info":"Tools at agent's disposal","input_types":["Tool"],"list":true,"list_add_label":"Add More","name":"tools","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":[]},"verbose":{"_input_type":"BoolInput","advanced":true,"display_name":"Verbose","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"verbose","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false},"SequentialTaskComponent":{"base_classes":["SequentialTask"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Each task must have a description, an expected output and an agent responsible for execution.","display_name":"Sequential Task","documentation":"","edited":false,"field_order":["task_description","expected_output","tools","agent","task","async_execution"],"frozen":false,"icon":"CrewAI","legacy":true,"metadata":{"code_hash":"b1f17b8fcc5c","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.crewai.sequential_task.SequentialTaskComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Task","group_outputs":false,"method":"build_task","name":"task_output","selected":"SequentialTask","tool_mode":true,"types":["SequentialTask"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":[],"template":{"_type":"Component","agent":{"_input_type":"HandleInput","advanced":false,"display_name":"Agent","dynamic":false,"info":"CrewAI Agent that will perform the task","input_types":["Agent"],"list":false,"list_add_label":"Add More","name":"agent","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"async_execution":{"_input_type":"BoolInput","advanced":true,"display_name":"Async Execution","dynamic":false,"info":"Boolean flag indicating asynchronous task execution.","list":false,"list_add_label":"Add More","name":"async_execution","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.agents.crewai.tasks import SequentialTask\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import BoolInput, HandleInput, MultilineInput, Output\n\n\nclass SequentialTaskComponent(Component):\n    display_name: str = \"Sequential Task\"\n    description: str = \"Each task must have a description, an expected output and an agent responsible for execution.\"\n    icon = \"CrewAI\"\n    legacy = True\n    replacement = \"agents.Agent\"\n    inputs = [\n        MultilineInput(\n            name=\"task_description\",\n            display_name=\"Description\",\n            info=\"Descriptive text detailing task's purpose and execution.\",\n        ),\n        MultilineInput(\n            name=\"expected_output\",\n            display_name=\"Expected Output\",\n            info=\"Clear definition of expected task outcome.\",\n        ),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"List of tools/resources limited for task execution. Uses the Agent tools by default.\",\n            required=False,\n            advanced=True,\n        ),\n        HandleInput(\n            name=\"agent\",\n            display_name=\"Agent\",\n            input_types=[\"Agent\"],\n            info=\"CrewAI Agent that will perform the task\",\n            required=True,\n        ),\n        HandleInput(\n            name=\"task\",\n            display_name=\"Task\",\n            input_types=[\"SequentialTask\"],\n            info=\"CrewAI Task that will perform the task\",\n        ),\n        BoolInput(\n            name=\"async_execution\",\n            display_name=\"Async Execution\",\n            value=True,\n            advanced=True,\n            info=\"Boolean flag indicating asynchronous task execution.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Task\", name=\"task_output\", method=\"build_task\"),\n    ]\n\n    def build_task(self) -> list[SequentialTask]:\n        tasks: list[SequentialTask] = []\n        task = SequentialTask(\n            description=self.task_description,\n            expected_output=self.expected_output,\n            tools=self.agent.tools,\n            async_execution=False,\n            agent=self.agent,\n        )\n        tasks.append(task)\n        self.status = task\n        if self.task:\n            if isinstance(self.task, list) and all(isinstance(task_item, SequentialTask) for task_item in self.task):\n                tasks = self.task + tasks\n            elif isinstance(self.task, SequentialTask):\n                tasks = [self.task, *tasks]\n        return tasks\n"},"expected_output":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Expected Output","dynamic":false,"info":"Clear definition of expected task outcome.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"expected_output","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"task":{"_input_type":"HandleInput","advanced":false,"display_name":"Task","dynamic":false,"info":"CrewAI Task that will perform the task","input_types":["SequentialTask"],"list":false,"list_add_label":"Add More","name":"task","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"task_description":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Description","dynamic":false,"info":"Descriptive text detailing task's purpose and execution.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"task_description","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"tools":{"_input_type":"HandleInput","advanced":true,"display_name":"Tools","dynamic":false,"info":"List of tools/resources limited for task execution. Uses the Agent tools by default.","input_types":["Tool"],"list":true,"list_add_label":"Add More","name":"tools","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""}},"tool_mode":false}}],["custom_component",{"CustomComponent":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Use as a template to create your own component.","display_name":"Custom Component","documentation":"https://docs.langflow.org/components-custom-components","edited":false,"field_order":["input_value"],"frozen":false,"icon":"code","legacy":false,"metadata":{"code_hash":"d50a68a6fa57","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.custom_component.custom_component.CustomComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Output","group_outputs":false,"method":"build_output","name":"output","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"# from lfx.field_typing import Data\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import MessageTextInput, Output\nfrom lfx.schema.data import Data\n\n\nclass CustomComponent(Component):\n    display_name = \"Custom Component\"\n    description = \"Use as a template to create your own component.\"\n    documentation: str = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"code\"\n    name = \"CustomComponent\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Input Value\",\n            info=\"This is a custom component Input\",\n            value=\"Hello, World!\",\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Data:\n        data = Data(value=self.input_value)\n        self.status = data\n        return data\n"},"input_value":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Input Value","dynamic":false,"info":"This is a custom component Input","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"Hello, World!"}},"tool_mode":false}}],["data",{"APIRequest":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Make HTTP requests using URL or cURL commands.","display_name":"API Request","documentation":"https://docs.langflow.org/components-data#api-request","edited":false,"field_order":["url_input","curl_input","method","mode","query_params","body","headers","timeout","follow_redirects","save_to_file","include_httpx_metadata"],"frozen":false,"icon":"Globe","legacy":false,"metadata":{"code_hash":"80a56d261133","dependencies":{"dependencies":[{"name":"aiofiles","version":"24.1.0"},{"name":"httpx","version":"0.28.1"},{"name":"validators","version":"0.34.0"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.data.api_request.APIRequestComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"API Response","group_outputs":false,"method":"make_api_request","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","body":{"_input_type":"TableInput","advanced":true,"display_name":"Body","dynamic":false,"info":"The body to send with the request as a dictionary (for POST, PATCH, PUT).","input_types":["Data"],"is_list":true,"list_add_label":"Add More","name":"body","placeholder":"","real_time_refresh":true,"required":false,"show":true,"table_icon":"Table","table_schema":[{"description":"Parameter name","display_name":"Key","name":"key","type":"str"},{"description":"Parameter value","display_name":"Value","name":"value"}],"title_case":false,"tool_mode":false,"trace_as_metadata":true,"trigger_icon":"Table","trigger_text":"Open table","type":"table","value":[]},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nimport re\nimport tempfile\nfrom datetime import datetime, timezone\nfrom pathlib import Path\nfrom typing import Any\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport aiofiles\nimport aiofiles.os as aiofiles_os\nimport httpx\nimport validators\n\nfrom lfx.base.curl.parse import parse_context\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import TabInput\nfrom lfx.io import (\n    BoolInput,\n    DataInput,\n    DropdownInput,\n    IntInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n    TableInput,\n)\nfrom lfx.schema.data import Data\nfrom lfx.schema.dotdict import dotdict\nfrom lfx.utils.component_utils import set_current_fields, set_field_advanced, set_field_display\n\n# Define fields for each mode\nMODE_FIELDS = {\n    \"URL\": [\n        \"url_input\",\n        \"method\",\n    ],\n    \"cURL\": [\"curl_input\"],\n}\n\n# Fields that should always be visible\nDEFAULT_FIELDS = [\"mode\"]\n\n\nclass APIRequestComponent(Component):\n    display_name = \"API Request\"\n    description = \"Make HTTP requests using URL or cURL commands.\"\n    documentation: str = \"https://docs.langflow.org/components-data#api-request\"\n    icon = \"Globe\"\n    name = \"APIRequest\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"url_input\",\n            display_name=\"URL\",\n            info=\"Enter the URL for the request.\",\n            advanced=False,\n            tool_mode=True,\n        ),\n        MultilineInput(\n            name=\"curl_input\",\n            display_name=\"cURL\",\n            info=(\n                \"Paste a curl command to populate the fields. \"\n                \"This will fill in the dictionary fields for headers and body.\"\n            ),\n            real_time_refresh=True,\n            tool_mode=True,\n            advanced=True,\n            show=False,\n        ),\n        DropdownInput(\n            name=\"method\",\n            display_name=\"Method\",\n            options=[\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"],\n            value=\"GET\",\n            info=\"The HTTP method to use.\",\n            real_time_refresh=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"URL\", \"cURL\"],\n            value=\"URL\",\n            info=\"Enable cURL mode to populate fields from a cURL command.\",\n            real_time_refresh=True,\n        ),\n        DataInput(\n            name=\"query_params\",\n            display_name=\"Query Parameters\",\n            info=\"The query parameters to append to the URL.\",\n            advanced=True,\n        ),\n        TableInput(\n            name=\"body\",\n            display_name=\"Body\",\n            info=\"The body to send with the request as a dictionary (for POST, PATCH, PUT).\",\n            table_schema=[\n                {\n                    \"name\": \"key\",\n                    \"display_name\": \"Key\",\n                    \"type\": \"str\",\n                    \"description\": \"Parameter name\",\n                },\n                {\n                    \"name\": \"value\",\n                    \"display_name\": \"Value\",\n                    \"description\": \"Parameter value\",\n                },\n            ],\n            value=[],\n            input_types=[\"Data\"],\n            advanced=True,\n            real_time_refresh=True,\n        ),\n        TableInput(\n            name=\"headers\",\n            display_name=\"Headers\",\n            info=\"The headers to send with the request\",\n            table_schema=[\n                {\n                    \"name\": \"key\",\n                    \"display_name\": \"Header\",\n                    \"type\": \"str\",\n                    \"description\": \"Header name\",\n                },\n                {\n                    \"name\": \"value\",\n                    \"display_name\": \"Value\",\n                    \"type\": \"str\",\n                    \"description\": \"Header value\",\n                },\n            ],\n            value=[{\"key\": \"User-Agent\", \"value\": \"Langflow/1.0\"}],\n            advanced=True,\n            input_types=[\"Data\"],\n            real_time_refresh=True,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            value=30,\n            info=\"The timeout to use for the request.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"follow_redirects\",\n            display_name=\"Follow Redirects\",\n            value=True,\n            info=\"Whether to follow http redirects.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"save_to_file\",\n            display_name=\"Save to File\",\n            value=False,\n            info=\"Save the API response to a temporary file\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_httpx_metadata\",\n            display_name=\"Include HTTPx Metadata\",\n            value=False,\n            info=(\n                \"Include properties such as headers, status_code, response_headers, \"\n                \"and redirection_history in the output.\"\n            ),\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"API Response\", name=\"data\", method=\"make_api_request\"),\n    ]\n\n    def _parse_json_value(self, value: Any) -> Any:\n        \"\"\"Parse a value that might be a JSON string.\"\"\"\n        if not isinstance(value, str):\n            return value\n\n        try:\n            parsed = json.loads(value)\n        except json.JSONDecodeError:\n            return value\n        else:\n            return parsed\n\n    def _process_body(self, body: Any) -> dict:\n        \"\"\"Process the body input into a valid dictionary.\"\"\"\n        if body is None:\n            return {}\n        if hasattr(body, \"data\"):\n            body = body.data\n        if isinstance(body, dict):\n            return self._process_dict_body(body)\n        if isinstance(body, str):\n            return self._process_string_body(body)\n        if isinstance(body, list):\n            return self._process_list_body(body)\n        return {}\n\n    def _process_dict_body(self, body: dict) -> dict:\n        \"\"\"Process dictionary body by parsing JSON values.\"\"\"\n        return {k: self._parse_json_value(v) for k, v in body.items()}\n\n    def _process_string_body(self, body: str) -> dict:\n        \"\"\"Process string body by attempting JSON parse.\"\"\"\n        try:\n            return self._process_body(json.loads(body))\n        except json.JSONDecodeError:\n            return {\"data\": body}\n\n    def _process_list_body(self, body: list) -> dict:\n        \"\"\"Process list body by converting to key-value dictionary.\"\"\"\n        processed_dict = {}\n        try:\n            for item in body:\n                # Unwrap Data objects\n                current_item = item\n                if hasattr(item, \"data\"):\n                    unwrapped_data = item.data\n                    # If the unwrapped data is a dict but not key-value format, use it directly\n                    if isinstance(unwrapped_data, dict) and not self._is_valid_key_value_item(unwrapped_data):\n                        return unwrapped_data\n                    current_item = unwrapped_data\n                if not self._is_valid_key_value_item(current_item):\n                    continue\n                key = current_item[\"key\"]\n                value = self._parse_json_value(current_item[\"value\"])\n                processed_dict[key] = value\n        except (KeyError, TypeError, ValueError) as e:\n            self.log(f\"Failed to process body list: {e}\")\n            return {}\n        return processed_dict\n\n    def _is_valid_key_value_item(self, item: Any) -> bool:\n        \"\"\"Check if an item is a valid key-value dictionary.\"\"\"\n        return isinstance(item, dict) and \"key\" in item and \"value\" in item\n\n    def parse_curl(self, curl: str, build_config: dotdict) -> dotdict:\n        \"\"\"Parse a cURL command and update build configuration.\"\"\"\n        try:\n            parsed = parse_context(curl)\n\n            # Update basic configuration\n            url = parsed.url\n            # Normalize URL before setting it\n            url = self._normalize_url(url)\n\n            build_config[\"url_input\"][\"value\"] = url\n            build_config[\"method\"][\"value\"] = parsed.method.upper()\n\n            # Process headers\n            headers_list = [{\"key\": k, \"value\": v} for k, v in parsed.headers.items()]\n            build_config[\"headers\"][\"value\"] = headers_list\n\n            # Process body data\n            if not parsed.data:\n                build_config[\"body\"][\"value\"] = []\n            elif parsed.data:\n                try:\n                    json_data = json.loads(parsed.data)\n                    if isinstance(json_data, dict):\n                        body_list = [\n                            {\"key\": k, \"value\": json.dumps(v) if isinstance(v, dict | list) else str(v)}\n                            for k, v in json_data.items()\n                        ]\n                        build_config[\"body\"][\"value\"] = body_list\n                    else:\n                        build_config[\"body\"][\"value\"] = [{\"key\": \"data\", \"value\": json.dumps(json_data)}]\n                except json.JSONDecodeError:\n                    build_config[\"body\"][\"value\"] = [{\"key\": \"data\", \"value\": parsed.data}]\n\n        except Exception as exc:\n            msg = f\"Error parsing curl: {exc}\"\n            self.log(msg)\n            raise ValueError(msg) from exc\n\n        return build_config\n\n    def _normalize_url(self, url: str) -> str:\n        \"\"\"Normalize URL by adding https:// if no protocol is specified.\"\"\"\n        if not url or not isinstance(url, str):\n            msg = \"URL cannot be empty\"\n            raise ValueError(msg)\n\n        url = url.strip()\n        if url.startswith((\"http://\", \"https://\")):\n            return url\n        return f\"https://{url}\"\n\n    async def make_request(\n        self,\n        client: httpx.AsyncClient,\n        method: str,\n        url: str,\n        headers: dict | None = None,\n        body: Any = None,\n        timeout: int = 5,\n        *,\n        follow_redirects: bool = True,\n        save_to_file: bool = False,\n        include_httpx_metadata: bool = False,\n    ) -> Data:\n        method = method.upper()\n        if method not in {\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"}:\n            msg = f\"Unsupported method: {method}\"\n            raise ValueError(msg)\n\n        processed_body = self._process_body(body)\n        redirection_history = []\n\n        try:\n            # Prepare request parameters\n            request_params = {\n                \"method\": method,\n                \"url\": url,\n                \"headers\": headers,\n                \"json\": processed_body,\n                \"timeout\": timeout,\n                \"follow_redirects\": follow_redirects,\n            }\n            response = await client.request(**request_params)\n\n            redirection_history = [\n                {\n                    \"url\": redirect.headers.get(\"Location\", str(redirect.url)),\n                    \"status_code\": redirect.status_code,\n                }\n                for redirect in response.history\n            ]\n\n            is_binary, file_path = await self._response_info(response, with_file_path=save_to_file)\n            response_headers = self._headers_to_dict(response.headers)\n\n            # Base metadata\n            metadata = {\n                \"source\": url,\n                \"status_code\": response.status_code,\n                \"response_headers\": response_headers,\n            }\n\n            if redirection_history:\n                metadata[\"redirection_history\"] = redirection_history\n\n            if save_to_file:\n                mode = \"wb\" if is_binary else \"w\"\n                encoding = response.encoding if mode == \"w\" else None\n                if file_path:\n                    await aiofiles_os.makedirs(file_path.parent, exist_ok=True)\n                    if is_binary:\n                        async with aiofiles.open(file_path, \"wb\") as f:\n                            await f.write(response.content)\n                            await f.flush()\n                    else:\n                        async with aiofiles.open(file_path, \"w\", encoding=encoding) as f:\n                            await f.write(response.text)\n                            await f.flush()\n                    metadata[\"file_path\"] = str(file_path)\n\n                if include_httpx_metadata:\n                    metadata.update({\"headers\": headers})\n                return Data(data=metadata)\n\n            # Handle response content\n            if is_binary:\n                result = response.content\n            else:\n                try:\n                    result = response.json()\n                except json.JSONDecodeError:\n                    self.log(\"Failed to decode JSON response\")\n                    result = response.text.encode(\"utf-8\")\n\n            metadata[\"result\"] = result\n\n            if include_httpx_metadata:\n                metadata.update({\"headers\": headers})\n\n            return Data(data=metadata)\n        except (httpx.HTTPError, httpx.RequestError, httpx.TimeoutException) as exc:\n            self.log(f\"Error making request to {url}\")\n            return Data(\n                data={\n                    \"source\": url,\n                    \"headers\": headers,\n                    \"status_code\": 500,\n                    \"error\": str(exc),\n                    **({\"redirection_history\": redirection_history} if redirection_history else {}),\n                },\n            )\n\n    def add_query_params(self, url: str, params: dict) -> str:\n        \"\"\"Add query parameters to URL efficiently.\"\"\"\n        if not params:\n            return url\n        url_parts = list(urlparse(url))\n        query = dict(parse_qsl(url_parts[4]))\n        query.update(params)\n        url_parts[4] = urlencode(query)\n        return urlunparse(url_parts)\n\n    def _headers_to_dict(self, headers: httpx.Headers) -> dict[str, str]:\n        \"\"\"Convert HTTP headers to a dictionary with lowercased keys.\"\"\"\n        return {k.lower(): v for k, v in headers.items()}\n\n    def _process_headers(self, headers: Any) -> dict:\n        \"\"\"Process the headers input into a valid dictionary.\"\"\"\n        if headers is None:\n            return {}\n        if isinstance(headers, dict):\n            return headers\n        if isinstance(headers, list):\n            return {item[\"key\"]: item[\"value\"] for item in headers if self._is_valid_key_value_item(item)}\n        return {}\n\n    async def make_api_request(self) -> Data:\n        \"\"\"Make HTTP request with optimized parameter handling.\"\"\"\n        method = self.method\n        url = self.url_input.strip() if isinstance(self.url_input, str) else \"\"\n        headers = self.headers or {}\n        body = self.body or {}\n        timeout = self.timeout\n        follow_redirects = self.follow_redirects\n        save_to_file = self.save_to_file\n        include_httpx_metadata = self.include_httpx_metadata\n\n        # if self.mode == \"cURL\" and self.curl_input:\n        #     self._build_config = self.parse_curl(self.curl_input, dotdict())\n        #     # After parsing curl, get the normalized URL\n        #     url = self._build_config[\"url_input\"][\"value\"]\n\n        # Normalize URL before validation\n        url = self._normalize_url(url)\n\n        # Validate URL\n        if not validators.url(url):\n            msg = f\"Invalid URL provided: {url}\"\n            raise ValueError(msg)\n\n        # Process query parameters\n        if isinstance(self.query_params, str):\n            query_params = dict(parse_qsl(self.query_params))\n        else:\n            query_params = self.query_params.data if self.query_params else {}\n\n        # Process headers and body\n        headers = self._process_headers(headers)\n        body = self._process_body(body)\n        url = self.add_query_params(url, query_params)\n\n        async with httpx.AsyncClient() as client:\n            result = await self.make_request(\n                client,\n                method,\n                url,\n                headers,\n                body,\n                timeout,\n                follow_redirects=follow_redirects,\n                save_to_file=save_to_file,\n                include_httpx_metadata=include_httpx_metadata,\n            )\n        self.status = result\n        return result\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        \"\"\"Update the build config based on the selected mode.\"\"\"\n        if field_name != \"mode\":\n            if field_name == \"curl_input\" and self.mode == \"cURL\" and self.curl_input:\n                return self.parse_curl(self.curl_input, build_config)\n            return build_config\n\n        # print(f\"Current mode: {field_value}\")\n        if field_value == \"cURL\":\n            set_field_display(build_config, \"curl_input\", value=True)\n            if build_config[\"curl_input\"][\"value\"]:\n                build_config = self.parse_curl(build_config[\"curl_input\"][\"value\"], build_config)\n        else:\n            set_field_display(build_config, \"curl_input\", value=False)\n\n        return set_current_fields(\n            build_config=build_config,\n            action_fields=MODE_FIELDS,\n            selected_action=field_value,\n            default_fields=DEFAULT_FIELDS,\n            func=set_field_advanced,\n            default_value=True,\n        )\n\n    async def _response_info(\n        self, response: httpx.Response, *, with_file_path: bool = False\n    ) -> tuple[bool, Path | None]:\n        \"\"\"Determine the file path and whether the response content is binary.\n\n        Args:\n            response (Response): The HTTP response object.\n            with_file_path (bool): Whether to save the response content to a file.\n\n        Returns:\n            Tuple[bool, Path | None]:\n                A tuple containing a boolean indicating if the content is binary and the full file path (if applicable).\n        \"\"\"\n        content_type = response.headers.get(\"Content-Type\", \"\")\n        is_binary = \"application/octet-stream\" in content_type or \"application/binary\" in content_type\n\n        if not with_file_path:\n            return is_binary, None\n\n        component_temp_dir = Path(tempfile.gettempdir()) / self.__class__.__name__\n\n        # Create directory asynchronously\n        await aiofiles_os.makedirs(component_temp_dir, exist_ok=True)\n\n        filename = None\n        if \"Content-Disposition\" in response.headers:\n            content_disposition = response.headers[\"Content-Disposition\"]\n            filename_match = re.search(r'filename=\"(.+?)\"', content_disposition)\n            if filename_match:\n                extracted_filename = filename_match.group(1)\n                filename = extracted_filename\n\n        # Step 3: Infer file extension or use part of the request URL if no filename\n        if not filename:\n            # Extract the last segment of the URL path\n            url_path = urlparse(str(response.request.url) if response.request else \"\").path\n            base_name = Path(url_path).name  # Get the last segment of the path\n            if not base_name:  # If the path ends with a slash or is empty\n                base_name = \"response\"\n\n            # Infer file extension\n            content_type_to_extension = {\n                \"text/plain\": \".txt\",\n                \"application/json\": \".json\",\n                \"image/jpeg\": \".jpg\",\n                \"image/png\": \".png\",\n                \"application/octet-stream\": \".bin\",\n            }\n            extension = content_type_to_extension.get(content_type, \".bin\" if is_binary else \".txt\")\n            filename = f\"{base_name}{extension}\"\n\n        # Step 4: Define the full file path\n        file_path = component_temp_dir / filename\n\n        # Step 5: Check if file exists asynchronously and handle accordingly\n        try:\n            # Try to create the file exclusively (x mode) to check existence\n            async with aiofiles.open(file_path, \"x\") as _:\n                pass  # File created successfully, we can use this path\n        except FileExistsError:\n            # If file exists, append a timestamp to the filename\n            timestamp = datetime.now(timezone.utc).strftime(\"%Y%m%d%H%M%S%f\")\n            file_path = component_temp_dir / f\"{timestamp}-{filename}\"\n\n        return is_binary, file_path\n"},"curl_input":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"cURL","dynamic":false,"info":"Paste a curl command to populate the fields. This will fill in the dictionary fields for headers and body.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"curl_input","placeholder":"","real_time_refresh":true,"required":false,"show":false,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"follow_redirects":{"_input_type":"BoolInput","advanced":true,"display_name":"Follow Redirects","dynamic":false,"info":"Whether to follow http redirects.","list":false,"list_add_label":"Add More","name":"follow_redirects","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"headers":{"_input_type":"TableInput","advanced":true,"display_name":"Headers","dynamic":false,"info":"The headers to send with the request","input_types":["Data"],"is_list":true,"list_add_label":"Add More","name":"headers","placeholder":"","real_time_refresh":true,"required":false,"show":true,"table_icon":"Table","table_schema":[{"description":"Header name","display_name":"Header","name":"key","type":"str"},{"description":"Header value","display_name":"Value","name":"value","type":"str"}],"title_case":false,"tool_mode":false,"trace_as_metadata":true,"trigger_icon":"Table","trigger_text":"Open table","type":"table","value":[{"key":"User-Agent","value":"Langflow/1.0"}]},"include_httpx_metadata":{"_input_type":"BoolInput","advanced":true,"display_name":"Include HTTPx Metadata","dynamic":false,"info":"Include properties such as headers, status_code, response_headers, and redirection_history in the output.","list":false,"list_add_label":"Add More","name":"include_httpx_metadata","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"method":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Method","dynamic":false,"external_options":{},"info":"The HTTP method to use.","name":"method","options":["GET","POST","PATCH","PUT","DELETE"],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"GET"},"mode":{"_input_type":"TabInput","advanced":false,"display_name":"Mode","dynamic":false,"info":"Enable cURL mode to populate fields from a cURL command.","name":"mode","options":["URL","cURL"],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"tab","value":"URL"},"query_params":{"_input_type":"DataInput","advanced":true,"display_name":"Query Parameters","dynamic":false,"info":"The query parameters to append to the URL.","input_types":["Data"],"list":false,"list_add_label":"Add More","name":"query_params","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"save_to_file":{"_input_type":"BoolInput","advanced":true,"display_name":"Save to File","dynamic":false,"info":"Save the API response to a temporary file","list":false,"list_add_label":"Add More","name":"save_to_file","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"timeout":{"_input_type":"IntInput","advanced":true,"display_name":"Timeout","dynamic":false,"info":"The timeout to use for the request.","list":false,"list_add_label":"Add More","name":"timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":30},"url_input":{"_input_type":"MessageTextInput","advanced":false,"display_name":"URL","dynamic":false,"info":"Enter the URL for the request.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"url_input","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"CSVtoData":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Load a CSV file, CSV from a file path, or a valid CSV string and convert it to a list of Data","display_name":"Load CSV","documentation":"","edited":false,"field_order":["csv_file","csv_path","csv_string","text_key"],"frozen":false,"icon":"file-spreadsheet","legacy":true,"metadata":{"code_hash":"36c35ef2b65d","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.data.csv_to_data.CSVToDataComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data List","group_outputs":false,"method":"load_csv_to_data","name":"data_list","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["data.File"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import csv\nimport io\nfrom pathlib import Path\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import FileInput, MessageTextInput, MultilineInput, Output\nfrom lfx.schema.data import Data\n\n\nclass CSVToDataComponent(Component):\n    display_name = \"Load CSV\"\n    description = \"Load a CSV file, CSV from a file path, or a valid CSV string and convert it to a list of Data\"\n    icon = \"file-spreadsheet\"\n    name = \"CSVtoData\"\n    legacy = True\n    replacement = [\"data.File\"]\n\n    inputs = [\n        FileInput(\n            name=\"csv_file\",\n            display_name=\"CSV File\",\n            file_types=[\"csv\"],\n            info=\"Upload a CSV file to convert to a list of Data objects\",\n        ),\n        MessageTextInput(\n            name=\"csv_path\",\n            display_name=\"CSV File Path\",\n            info=\"Provide the path to the CSV file as pure text\",\n        ),\n        MultilineInput(\n            name=\"csv_string\",\n            display_name=\"CSV String\",\n            info=\"Paste a CSV string directly to convert to a list of Data objects\",\n        ),\n        MessageTextInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"The key to use for the text column. Defaults to 'text'.\",\n            value=\"text\",\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"data_list\", display_name=\"Data List\", method=\"load_csv_to_data\"),\n    ]\n\n    def load_csv_to_data(self) -> list[Data]:\n        if sum(bool(field) for field in [self.csv_file, self.csv_path, self.csv_string]) != 1:\n            msg = \"Please provide exactly one of: CSV file, file path, or CSV string.\"\n            raise ValueError(msg)\n\n        csv_data = None\n        try:\n            if self.csv_file:\n                resolved_path = self.resolve_path(self.csv_file)\n                file_path = Path(resolved_path)\n                if file_path.suffix.lower() != \".csv\":\n                    self.status = \"The provided file must be a CSV file.\"\n                else:\n                    with file_path.open(newline=\"\", encoding=\"utf-8\") as csvfile:\n                        csv_data = csvfile.read()\n\n            elif self.csv_path:\n                file_path = Path(self.csv_path)\n                if file_path.suffix.lower() != \".csv\":\n                    self.status = \"The provided file must be a CSV file.\"\n                else:\n                    with file_path.open(newline=\"\", encoding=\"utf-8\") as csvfile:\n                        csv_data = csvfile.read()\n\n            else:\n                csv_data = self.csv_string\n\n            if csv_data:\n                csv_reader = csv.DictReader(io.StringIO(csv_data))\n                result = [Data(data=row, text_key=self.text_key) for row in csv_reader]\n\n                if not result:\n                    self.status = \"The CSV data is empty.\"\n                    return []\n\n                self.status = result\n                return result\n\n        except csv.Error as e:\n            error_message = f\"CSV parsing error: {e}\"\n            self.status = error_message\n            raise ValueError(error_message) from e\n\n        except Exception as e:\n            error_message = f\"An error occurred: {e}\"\n            self.status = error_message\n            raise ValueError(error_message) from e\n\n        # An error occurred\n        raise ValueError(self.status)\n"},"csv_file":{"_input_type":"FileInput","advanced":false,"display_name":"CSV File","dynamic":false,"fileTypes":["csv"],"file_path":"","info":"Upload a CSV file to convert to a list of Data objects","list":false,"list_add_label":"Add More","name":"csv_file","placeholder":"","required":false,"show":true,"temp_file":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"file","value":""},"csv_path":{"_input_type":"MessageTextInput","advanced":false,"display_name":"CSV File Path","dynamic":false,"info":"Provide the path to the CSV file as pure text","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"csv_path","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"csv_string":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"CSV String","dynamic":false,"info":"Paste a CSV string directly to convert to a list of Data objects","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"csv_string","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"text_key":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Text Key","dynamic":false,"info":"The key to use for the text column. Defaults to 'text'.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"text_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"text"}},"tool_mode":false},"Directory":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Recursively load files from a directory.","display_name":"Directory","documentation":"https://docs.langflow.org/components-data#directory","edited":false,"field_order":["path","types","depth","max_concurrency","load_hidden","recursive","silent_errors","use_multithreading"],"frozen":false,"icon":"folder","legacy":false,"metadata":{"code_hash":"8aa20dc71cb9","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.data.directory.DirectoryComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Loaded Files","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.data.utils import TEXT_FILE_TYPES, parallel_load_data, parse_text_file_to_data, retrieve_file_paths\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import BoolInput, IntInput, MessageTextInput, MultiselectInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.template.field.base import Output\n\n\nclass DirectoryComponent(Component):\n    display_name = \"Directory\"\n    description = \"Recursively load files from a directory.\"\n    documentation: str = \"https://docs.langflow.org/components-data#directory\"\n    icon = \"folder\"\n    name = \"Directory\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"path\",\n            display_name=\"Path\",\n            info=\"Path to the directory to load files from. Defaults to current directory ('.')\",\n            value=\".\",\n            tool_mode=True,\n        ),\n        MultiselectInput(\n            name=\"types\",\n            display_name=\"File Types\",\n            info=\"File types to load. Select one or more types or leave empty to load all supported types.\",\n            options=TEXT_FILE_TYPES,\n            value=[],\n        ),\n        IntInput(\n            name=\"depth\",\n            display_name=\"Depth\",\n            info=\"Depth to search for files.\",\n            value=0,\n        ),\n        IntInput(\n            name=\"max_concurrency\",\n            display_name=\"Max Concurrency\",\n            advanced=True,\n            info=\"Maximum concurrency for loading files.\",\n            value=2,\n        ),\n        BoolInput(\n            name=\"load_hidden\",\n            display_name=\"Load Hidden\",\n            advanced=True,\n            info=\"If true, hidden files will be loaded.\",\n        ),\n        BoolInput(\n            name=\"recursive\",\n            display_name=\"Recursive\",\n            advanced=True,\n            info=\"If true, the search will be recursive.\",\n        ),\n        BoolInput(\n            name=\"silent_errors\",\n            display_name=\"Silent Errors\",\n            advanced=True,\n            info=\"If true, errors will not raise an exception.\",\n        ),\n        BoolInput(\n            name=\"use_multithreading\",\n            display_name=\"Use Multithreading\",\n            advanced=True,\n            info=\"If true, multithreading will be used.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Loaded Files\", name=\"dataframe\", method=\"as_dataframe\"),\n    ]\n\n    def load_directory(self) -> list[Data]:\n        path = self.path\n        types = self.types\n        depth = self.depth\n        max_concurrency = self.max_concurrency\n        load_hidden = self.load_hidden\n        recursive = self.recursive\n        silent_errors = self.silent_errors\n        use_multithreading = self.use_multithreading\n\n        resolved_path = self.resolve_path(path)\n\n        # If no types are specified, use all supported types\n        if not types:\n            types = TEXT_FILE_TYPES\n\n        # Check if all specified types are valid\n        invalid_types = [t for t in types if t not in TEXT_FILE_TYPES]\n        if invalid_types:\n            msg = f\"Invalid file types specified: {invalid_types}. Valid types are: {TEXT_FILE_TYPES}\"\n            raise ValueError(msg)\n\n        valid_types = types\n\n        file_paths = retrieve_file_paths(\n            resolved_path, load_hidden=load_hidden, recursive=recursive, depth=depth, types=valid_types\n        )\n\n        loaded_data = []\n        if use_multithreading:\n            loaded_data = parallel_load_data(file_paths, silent_errors=silent_errors, max_concurrency=max_concurrency)\n        else:\n            loaded_data = [parse_text_file_to_data(file_path, silent_errors=silent_errors) for file_path in file_paths]\n\n        valid_data = [x for x in loaded_data if x is not None and isinstance(x, Data)]\n        self.status = valid_data\n        return valid_data\n\n    def as_dataframe(self) -> DataFrame:\n        return DataFrame(self.load_directory())\n"},"depth":{"_input_type":"IntInput","advanced":false,"display_name":"Depth","dynamic":false,"info":"Depth to search for files.","list":false,"list_add_label":"Add More","name":"depth","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":0},"load_hidden":{"_input_type":"BoolInput","advanced":true,"display_name":"Load Hidden","dynamic":false,"info":"If true, hidden files will be loaded.","list":false,"list_add_label":"Add More","name":"load_hidden","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"max_concurrency":{"_input_type":"IntInput","advanced":true,"display_name":"Max Concurrency","dynamic":false,"info":"Maximum concurrency for loading files.","list":false,"list_add_label":"Add More","name":"max_concurrency","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":2},"path":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Path","dynamic":false,"info":"Path to the directory to load files from. Defaults to current directory ('.')","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"path","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"."},"recursive":{"_input_type":"BoolInput","advanced":true,"display_name":"Recursive","dynamic":false,"info":"If true, the search will be recursive.","list":false,"list_add_label":"Add More","name":"recursive","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"silent_errors":{"_input_type":"BoolInput","advanced":true,"display_name":"Silent Errors","dynamic":false,"info":"If true, errors will not raise an exception.","list":false,"list_add_label":"Add More","name":"silent_errors","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"types":{"_input_type":"MultiselectInput","advanced":false,"combobox":false,"display_name":"File Types","dynamic":false,"info":"File types to load. Select one or more types or leave empty to load all supported types.","list":true,"list_add_label":"Add More","name":"types","options":["csv","json","pdf","txt","md","mdx","yaml","yml","xml","html","htm","docx","py","sh","sql","js","ts","tsx"],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":[]},"use_multithreading":{"_input_type":"BoolInput","advanced":true,"display_name":"Use Multithreading","dynamic":false,"info":"If true, multithreading will be used.","list":false,"list_add_label":"Add More","name":"use_multithreading","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false},"File":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Loads content from one or more files.","display_name":"Read File","documentation":"https://docs.langflow.org/components-data#file","edited":false,"field_order":["path","file_path","separator","silent_errors","delete_server_file_after_processing","ignore_unsupported_extensions","ignore_unspecified_files","advanced_mode","pipeline","ocr_engine","md_image_placeholder","md_page_break_placeholder","doc_key","use_multithreading","concurrency_multithreading","markdown"],"frozen":false,"icon":"file-text","legacy":false,"metadata":{"code_hash":"85abc1094130","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.data.file.FileComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Raw Content","group_outputs":false,"method":"load_files_message","name":"message","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","advanced_mode":{"_input_type":"BoolInput","advanced":false,"display_name":"Advanced Parser","dynamic":false,"info":"Enable advanced document processing and export with Docling for PDFs, images, and office documents. Note that advanced document processing can consume significant resources.","list":false,"list_add_label":"Add More","name":"advanced_mode","placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"\"\"\"Enhanced file component with Docling support and process isolation.\n\nNotes:\n-----\n- ALL Docling parsing/export runs in a separate OS process to prevent memory\n  growth and native library state from impacting the main Langflow process.\n- Standard text/structured parsing continues to use existing BaseFileComponent\n  utilities (and optional threading via `parallel_load_data`).\n\"\"\"\n\nfrom __future__ import annotations\n\nimport json\nimport subprocess\nimport sys\nimport textwrap\nfrom copy import deepcopy\nfrom typing import Any\n\nfrom lfx.base.data.base_file import BaseFileComponent\nfrom lfx.base.data.utils import TEXT_FILE_TYPES, parallel_load_data, parse_text_file_to_data\nfrom lfx.inputs.inputs import DropdownInput, MessageTextInput, StrInput\nfrom lfx.io import BoolInput, FileInput, IntInput, Output\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame  # noqa: TC001\nfrom lfx.schema.message import Message\n\n\nclass FileComponent(BaseFileComponent):\n    \"\"\"File component with optional Docling processing (isolated in a subprocess).\"\"\"\n\n    display_name = \"Read File\"\n    description = \"Loads content from one or more files.\"\n    documentation: str = \"https://docs.langflow.org/components-data#file\"\n    icon = \"file-text\"\n    name = \"File\"\n\n    # Docling-supported/compatible extensions; TEXT_FILE_TYPES are supported by the base loader.\n    VALID_EXTENSIONS = [\n        *TEXT_FILE_TYPES,\n        \"adoc\",\n        \"asciidoc\",\n        \"asc\",\n        \"bmp\",\n        \"dotx\",\n        \"dotm\",\n        \"docm\",\n        \"jpg\",\n        \"jpeg\",\n        \"png\",\n        \"potx\",\n        \"ppsx\",\n        \"pptm\",\n        \"potm\",\n        \"ppsm\",\n        \"pptx\",\n        \"tiff\",\n        \"xls\",\n        \"xlsx\",\n        \"xhtml\",\n        \"webp\",\n    ]\n\n    # Fixed export settings used when markdown export is requested.\n    EXPORT_FORMAT = \"Markdown\"\n    IMAGE_MODE = \"placeholder\"\n\n    _base_inputs = deepcopy(BaseFileComponent.get_base_inputs())\n\n    for input_item in _base_inputs:\n        if isinstance(input_item, FileInput) and input_item.name == \"path\":\n            input_item.real_time_refresh = True\n            break\n\n    inputs = [\n        *_base_inputs,\n        BoolInput(\n            name=\"advanced_mode\",\n            display_name=\"Advanced Parser\",\n            value=False,\n            real_time_refresh=True,\n            info=(\n                \"Enable advanced document processing and export with Docling for PDFs, images, and office documents. \"\n                \"Note that advanced document processing can consume significant resources.\"\n            ),\n            show=True,\n        ),\n        DropdownInput(\n            name=\"pipeline\",\n            display_name=\"Pipeline\",\n            info=\"Docling pipeline to use\",\n            options=[\"standard\", \"vlm\"],\n            value=\"standard\",\n            advanced=True,\n            real_time_refresh=True,\n        ),\n        DropdownInput(\n            name=\"ocr_engine\",\n            display_name=\"OCR Engine\",\n            info=\"OCR engine to use. Only available when pipeline is set to 'standard'.\",\n            options=[\"None\", \"easyocr\"],\n            value=\"easyocr\",\n            show=False,\n            advanced=True,\n        ),\n        StrInput(\n            name=\"md_image_placeholder\",\n            display_name=\"Image placeholder\",\n            info=\"Specify the image placeholder for markdown exports.\",\n            value=\"<!-- image -->\",\n            advanced=True,\n            show=False,\n        ),\n        StrInput(\n            name=\"md_page_break_placeholder\",\n            display_name=\"Page break placeholder\",\n            info=\"Add this placeholder between pages in the markdown output.\",\n            value=\"\",\n            advanced=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"doc_key\",\n            display_name=\"Doc Key\",\n            info=\"The key to use for the DoclingDocument column.\",\n            value=\"doc\",\n            advanced=True,\n            show=False,\n        ),\n        # Deprecated input retained for backward-compatibility.\n        BoolInput(\n            name=\"use_multithreading\",\n            display_name=\"[Deprecated] Use Multithreading\",\n            advanced=True,\n            value=True,\n            info=\"Set 'Processing Concurrency' greater than 1 to enable multithreading.\",\n        ),\n        IntInput(\n            name=\"concurrency_multithreading\",\n            display_name=\"Processing Concurrency\",\n            advanced=True,\n            info=\"When multiple files are being processed, the number of files to process concurrently.\",\n            value=1,\n        ),\n        BoolInput(\n            name=\"markdown\",\n            display_name=\"Markdown Export\",\n            info=\"Export processed documents to Markdown format. Only available when advanced mode is enabled.\",\n            value=False,\n            show=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Raw Content\", name=\"message\", method=\"load_files_message\"),\n    ]\n\n    # ------------------------------ UI helpers --------------------------------------\n\n    def _path_value(self, template: dict) -> list[str]:\n        \"\"\"Return the list of currently selected file paths from the template.\"\"\"\n        return template.get(\"path\", {}).get(\"file_path\", [])\n\n    def update_build_config(\n        self,\n        build_config: dict[str, Any],\n        field_value: Any,\n        field_name: str | None = None,\n    ) -> dict[str, Any]:\n        \"\"\"Show/hide Advanced Parser and related fields based on selection context.\"\"\"\n        if field_name == \"path\":\n            paths = self._path_value(build_config)\n\n            # If all files can be processed by docling, do so\n            allow_advanced = all(not file_path.endswith((\".csv\", \".xlsx\", \".parquet\")) for file_path in paths)\n            build_config[\"advanced_mode\"][\"show\"] = allow_advanced\n            if not allow_advanced:\n                build_config[\"advanced_mode\"][\"value\"] = False\n                for f in (\"pipeline\", \"ocr_engine\", \"doc_key\", \"md_image_placeholder\", \"md_page_break_placeholder\"):\n                    if f in build_config:\n                        build_config[f][\"show\"] = False\n\n        # Docling Processing\n        elif field_name == \"advanced_mode\":\n            for f in (\"pipeline\", \"ocr_engine\", \"doc_key\", \"md_image_placeholder\", \"md_page_break_placeholder\"):\n                if f in build_config:\n                    build_config[f][\"show\"] = bool(field_value)\n                    if f == \"pipeline\":\n                        build_config[f][\"advanced\"] = not bool(field_value)\n\n        elif field_name == \"pipeline\":\n            if field_value == \"standard\":\n                build_config[\"ocr_engine\"][\"show\"] = True\n                build_config[\"ocr_engine\"][\"value\"] = \"easyocr\"\n            else:\n                build_config[\"ocr_engine\"][\"show\"] = False\n                build_config[\"ocr_engine\"][\"value\"] = \"None\"\n\n        return build_config\n\n    def update_outputs(self, frontend_node: dict[str, Any], field_name: str, field_value: Any) -> dict[str, Any]:  # noqa: ARG002\n        \"\"\"Dynamically show outputs based on file count/type and advanced mode.\"\"\"\n        if field_name not in [\"path\", \"advanced_mode\", \"pipeline\"]:\n            return frontend_node\n\n        template = frontend_node.get(\"template\", {})\n        paths = self._path_value(template)\n        if not paths:\n            return frontend_node\n\n        frontend_node[\"outputs\"] = []\n        if len(paths) == 1:\n            file_path = paths[0] if field_name == \"path\" else frontend_node[\"template\"][\"path\"][\"file_path\"][0]\n            if file_path.endswith((\".csv\", \".xlsx\", \".parquet\")):\n                frontend_node[\"outputs\"].append(\n                    Output(display_name=\"Structured Content\", name=\"dataframe\", method=\"load_files_structured\"),\n                )\n            elif file_path.endswith(\".json\"):\n                frontend_node[\"outputs\"].append(\n                    Output(display_name=\"Structured Content\", name=\"json\", method=\"load_files_json\"),\n                )\n\n            advanced_mode = frontend_node.get(\"template\", {}).get(\"advanced_mode\", {}).get(\"value\", False)\n            if advanced_mode:\n                frontend_node[\"outputs\"].append(\n                    Output(display_name=\"Structured Output\", name=\"advanced_dataframe\", method=\"load_files_dataframe\"),\n                )\n                frontend_node[\"outputs\"].append(\n                    Output(display_name=\"Markdown\", name=\"advanced_markdown\", method=\"load_files_markdown\"),\n                )\n                frontend_node[\"outputs\"].append(\n                    Output(display_name=\"File Path\", name=\"path\", method=\"load_files_path\"),\n                )\n            else:\n                frontend_node[\"outputs\"].append(\n                    Output(display_name=\"Raw Content\", name=\"message\", method=\"load_files_message\"),\n                )\n                frontend_node[\"outputs\"].append(\n                    Output(display_name=\"File Path\", name=\"path\", method=\"load_files_path\"),\n                )\n        else:\n            # Multiple files => DataFrame output; advanced parser disabled\n            frontend_node[\"outputs\"].append(Output(display_name=\"Files\", name=\"dataframe\", method=\"load_files\"))\n\n        return frontend_node\n\n    # ------------------------------ Core processing ----------------------------------\n\n    def _is_docling_compatible(self, file_path: str) -> bool:\n        \"\"\"Lightweight extension gate for Docling-compatible types.\"\"\"\n        docling_exts = (\n            \".adoc\",\n            \".asciidoc\",\n            \".asc\",\n            \".bmp\",\n            \".csv\",\n            \".dotx\",\n            \".dotm\",\n            \".docm\",\n            \".docx\",\n            \".htm\",\n            \".html\",\n            \".jpg\",\n            \".jpeg\",\n            \".json\",\n            \".md\",\n            \".pdf\",\n            \".png\",\n            \".potx\",\n            \".ppsx\",\n            \".pptm\",\n            \".potm\",\n            \".ppsm\",\n            \".pptx\",\n            \".tiff\",\n            \".txt\",\n            \".xls\",\n            \".xlsx\",\n            \".xhtml\",\n            \".xml\",\n            \".webp\",\n        )\n        return file_path.lower().endswith(docling_exts)\n\n    def _process_docling_in_subprocess(self, file_path: str) -> Data | None:\n        \"\"\"Run Docling in a separate OS process and map the result to a Data object.\n\n        We avoid multiprocessing pickling by launching `python -c \"<script>\"` and\n        passing JSON config via stdin. The child prints a JSON result to stdout.\n        \"\"\"\n        if not file_path:\n            return None\n\n        args: dict[str, Any] = {\n            \"file_path\": file_path,\n            \"markdown\": bool(self.markdown),\n            \"image_mode\": str(self.IMAGE_MODE),\n            \"md_image_placeholder\": str(self.md_image_placeholder),\n            \"md_page_break_placeholder\": str(self.md_page_break_placeholder),\n            \"pipeline\": str(self.pipeline),\n            \"ocr_engine\": (\n                self.ocr_engine if self.ocr_engine and self.ocr_engine != \"None\" and self.pipeline != \"vlm\" else None\n            ),\n        }\n\n        self.log(f\"Starting Docling subprocess for file: {file_path}\")\n        self.log(args)\n\n        # Child script for isolating the docling processing\n        child_script = textwrap.dedent(\n            r\"\"\"\n            import json, sys\n\n            def try_imports():\n                try:\n                    from docling.datamodel.base_models import ConversionStatus, InputFormat  # type: ignore\n                    from docling.document_converter import DocumentConverter  # type: ignore\n                    from docling_core.types.doc import ImageRefMode  # type: ignore\n                    return ConversionStatus, InputFormat, DocumentConverter, ImageRefMode, \"latest\"\n                except Exception as e:\n                    raise e\n\n            def create_converter(strategy, input_format, DocumentConverter, pipeline, ocr_engine):\n                # --- Standard PDF/IMAGE pipeline (your existing behavior), with optional OCR ---\n                if pipeline == \"standard\":\n                    try:\n                        from docling.datamodel.pipeline_options import PdfPipelineOptions  # type: ignore\n                        from docling.document_converter import PdfFormatOption  # type: ignore\n\n                        pipe = PdfPipelineOptions()\n                        pipe.do_ocr = False\n\n                        if ocr_engine:\n                            try:\n                                from docling.models.factories import get_ocr_factory  # type: ignore\n                                pipe.do_ocr = True\n                                fac = get_ocr_factory(allow_external_plugins=False)\n                                pipe.ocr_options = fac.create_options(kind=ocr_engine)\n                            except Exception:\n                                # If OCR setup fails, disable it\n                                pipe.do_ocr = False\n\n                        fmt = {}\n                        if hasattr(input_format, \"PDF\"):\n                            fmt[getattr(input_format, \"PDF\")] = PdfFormatOption(pipeline_options=pipe)\n                        if hasattr(input_format, \"IMAGE\"):\n                            fmt[getattr(input_format, \"IMAGE\")] = PdfFormatOption(pipeline_options=pipe)\n\n                        return DocumentConverter(format_options=fmt)\n                    except Exception:\n                        return DocumentConverter()\n\n                # --- Vision-Language Model (VLM) pipeline ---\n                if pipeline == \"vlm\":\n                    try:\n                        from docling.datamodel.pipeline_options import VlmPipelineOptions\n                        from docling.datamodel.vlm_model_specs import GRANITEDOCLING_MLX, GRANITEDOCLING_TRANSFORMERS\n                        from docling.document_converter import PdfFormatOption\n                        from docling.pipeline.vlm_pipeline import VlmPipeline\n\n                        vl_pipe = VlmPipelineOptions(\n                            vlm_options=GRANITEDOCLING_TRANSFORMERS,\n                        )\n\n                        if sys.platform == \"darwin\":\n                            try:\n                                import mlx_vlm\n                                vl_pipe.vlm_options = GRANITEDOCLING_MLX\n                            except ImportError as e:\n                                raise e\n\n                        # VLM paths generally don't need OCR; keep OCR off by default here.\n                        fmt = {}\n                        if hasattr(input_format, \"PDF\"):\n                            fmt[getattr(input_format, \"PDF\")] = PdfFormatOption(\n                            pipeline_cls=VlmPipeline,\n                            pipeline_options=vl_pipe\n                        )\n                        if hasattr(input_format, \"IMAGE\"):\n                            fmt[getattr(input_format, \"IMAGE\")] = PdfFormatOption(\n                            pipeline_cls=VlmPipeline,\n                            pipeline_options=vl_pipe\n                        )\n\n                        return DocumentConverter(format_options=fmt)\n                    except Exception as e:\n                        raise e\n\n                # --- Fallback: default converter with no special options ---\n                return DocumentConverter()\n\n            def export_markdown(document, ImageRefMode, image_mode, img_ph, pg_ph):\n                try:\n                    mode = getattr(ImageRefMode, image_mode.upper(), image_mode)\n                    return document.export_to_markdown(\n                        image_mode=mode,\n                        image_placeholder=img_ph,\n                        page_break_placeholder=pg_ph,\n                    )\n                except Exception:\n                    try:\n                        return document.export_to_text()\n                    except Exception:\n                        return str(document)\n\n            def to_rows(doc_dict):\n                rows = []\n                for t in doc_dict.get(\"texts\", []):\n                    prov = t.get(\"prov\") or []\n                    page_no = None\n                    if prov and isinstance(prov, list) and isinstance(prov[0], dict):\n                        page_no = prov[0].get(\"page_no\")\n                    rows.append({\n                        \"page_no\": page_no,\n                        \"label\": t.get(\"label\"),\n                        \"text\": t.get(\"text\"),\n                        \"level\": t.get(\"level\"),\n                    })\n                return rows\n\n            def main():\n                cfg = json.loads(sys.stdin.read())\n                file_path = cfg[\"file_path\"]\n                markdown = cfg[\"markdown\"]\n                image_mode = cfg[\"image_mode\"]\n                img_ph = cfg[\"md_image_placeholder\"]\n                pg_ph = cfg[\"md_page_break_placeholder\"]\n                pipeline = cfg[\"pipeline\"]\n                ocr_engine = cfg.get(\"ocr_engine\")\n                meta = {\"file_path\": file_path}\n\n                try:\n                    ConversionStatus, InputFormat, DocumentConverter, ImageRefMode, strategy = try_imports()\n                    converter = create_converter(strategy, InputFormat, DocumentConverter, pipeline, ocr_engine)\n                    try:\n                        res = converter.convert(file_path)\n                    except Exception as e:\n                        print(json.dumps({\"ok\": False, \"error\": f\"Docling conversion error: {e}\", \"meta\": meta}))\n                        return\n\n                    ok = False\n                    if hasattr(res, \"status\"):\n                        try:\n                            ok = (res.status == ConversionStatus.SUCCESS) or (str(res.status).lower() == \"success\")\n                        except Exception:\n                            ok = (str(res.status).lower() == \"success\")\n                    if not ok and hasattr(res, \"document\"):\n                        ok = getattr(res, \"document\", None) is not None\n                    if not ok:\n                        print(json.dumps({\"ok\": False, \"error\": \"Docling conversion failed\", \"meta\": meta}))\n                        return\n\n                    doc = getattr(res, \"document\", None)\n                    if doc is None:\n                        print(json.dumps({\"ok\": False, \"error\": \"Docling produced no document\", \"meta\": meta}))\n                        return\n\n                    if markdown:\n                        text = export_markdown(doc, ImageRefMode, image_mode, img_ph, pg_ph)\n                        print(json.dumps({\"ok\": True, \"mode\": \"markdown\", \"text\": text, \"meta\": meta}))\n                        return\n\n                    # structured\n                    try:\n                        doc_dict = doc.export_to_dict()\n                    except Exception as e:\n                        print(json.dumps({\"ok\": False, \"error\": f\"Docling export_to_dict failed: {e}\", \"meta\": meta}))\n                        return\n\n                    rows = to_rows(doc_dict)\n                    print(json.dumps({\"ok\": True, \"mode\": \"structured\", \"doc\": rows, \"meta\": meta}))\n                except Exception as e:\n                    print(\n                        json.dumps({\n                            \"ok\": False,\n                            \"error\": f\"Docling processing error: {e}\",\n                            \"meta\": {\"file_path\": file_path},\n                        })\n                    )\n\n            if __name__ == \"__main__\":\n                main()\n            \"\"\"\n        )\n\n        # Validate file_path to avoid command injection or unsafe input\n        if not isinstance(args[\"file_path\"], str) or any(c in args[\"file_path\"] for c in [\";\", \"|\", \"&\", \"$\", \"`\"]):\n            return Data(data={\"error\": \"Unsafe file path detected.\", \"file_path\": args[\"file_path\"]})\n\n        proc = subprocess.run(  # noqa: S603\n            [sys.executable, \"-u\", \"-c\", child_script],\n            input=json.dumps(args).encode(\"utf-8\"),\n            capture_output=True,\n            check=False,\n        )\n\n        if not proc.stdout:\n            err_msg = proc.stderr.decode(\"utf-8\", errors=\"replace\") or \"no output from child process\"\n            return Data(data={\"error\": f\"Docling subprocess error: {err_msg}\", \"file_path\": file_path})\n\n        try:\n            result = json.loads(proc.stdout.decode(\"utf-8\"))\n        except Exception as e:  # noqa: BLE001\n            err_msg = proc.stderr.decode(\"utf-8\", errors=\"replace\")\n            return Data(\n                data={\"error\": f\"Invalid JSON from Docling subprocess: {e}. stderr={err_msg}\", \"file_path\": file_path},\n            )\n\n        if not result.get(\"ok\"):\n            return Data(data={\"error\": result.get(\"error\", \"Unknown Docling error\"), **result.get(\"meta\", {})})\n\n        meta = result.get(\"meta\", {})\n        if result.get(\"mode\") == \"markdown\":\n            exported_content = str(result.get(\"text\", \"\"))\n            return Data(\n                text=exported_content,\n                data={\"exported_content\": exported_content, \"export_format\": self.EXPORT_FORMAT, **meta},\n            )\n\n        rows = list(result.get(\"doc\", []))\n        return Data(data={\"doc\": rows, \"export_format\": self.EXPORT_FORMAT, **meta})\n\n    def process_files(\n        self,\n        file_list: list[BaseFileComponent.BaseFile],\n    ) -> list[BaseFileComponent.BaseFile]:\n        \"\"\"Process input files.\n\n        - advanced_mode => Docling in a separate process.\n        - Otherwise => standard parsing in current process (optionally threaded).\n        \"\"\"\n        if not file_list:\n            msg = \"No files to process.\"\n            raise ValueError(msg)\n\n        def process_file_standard(file_path: str, *, silent_errors: bool = False) -> Data | None:\n            try:\n                return parse_text_file_to_data(file_path, silent_errors=silent_errors)\n            except FileNotFoundError as e:\n                self.log(f\"File not found: {file_path}. Error: {e}\")\n                if not silent_errors:\n                    raise\n                return None\n            except Exception as e:\n                self.log(f\"Unexpected error processing {file_path}: {e}\")\n                if not silent_errors:\n                    raise\n                return None\n\n        docling_compatible = all(self._is_docling_compatible(str(f.path)) for f in file_list)\n\n        # Advanced path: Check if ALL files are compatible with Docling\n        if self.advanced_mode and docling_compatible:\n            final_return: list[BaseFileComponent.BaseFile] = []\n            for file in file_list:\n                file_path = str(file.path)\n                advanced_data: Data | None = self._process_docling_in_subprocess(file_path)\n\n                # --- UNNEST: expand each element in `doc` to its own Data row\n                payload = getattr(advanced_data, \"data\", {}) or {}\n                doc_rows = payload.get(\"doc\")\n                if isinstance(doc_rows, list):\n                    rows: list[Data | None] = [\n                        Data(\n                            data={\n                                \"file_path\": file_path,\n                                **(item if isinstance(item, dict) else {\"value\": item}),\n                            },\n                        )\n                        for item in doc_rows\n                    ]\n                    final_return.extend(self.rollup_data(file_list, rows))\n                else:\n                    # If not structured, keep as-is (e.g., markdown export or error dict)\n                    final_return.extend(self.rollup_data(file_list, [advanced_data]))\n            return final_return\n\n        # Standard multi-file (or single non-advanced) path\n        concurrency = 1 if not self.use_multithreading else max(1, self.concurrency_multithreading)\n        file_paths = [str(f.path) for f in file_list]\n        self.log(f\"Starting parallel processing of {len(file_paths)} files with concurrency: {concurrency}.\")\n        my_data = parallel_load_data(\n            file_paths,\n            silent_errors=self.silent_errors,\n            load_function=process_file_standard,\n            max_concurrency=concurrency,\n        )\n        return self.rollup_data(file_list, my_data)\n\n    # ------------------------------ Output helpers -----------------------------------\n\n    def load_files_helper(self) -> DataFrame:\n        result = self.load_files()\n\n        # Error condition - raise error if no text and an error is present\n        if not hasattr(result, \"text\"):\n            if hasattr(result, \"error\"):\n                raise ValueError(result.error[0])\n            msg = \"Could not extract content from the provided file(s).\"\n            raise ValueError(msg)\n\n        return result\n\n    def load_files_dataframe(self) -> DataFrame:\n        \"\"\"Load files using advanced Docling processing and export to DataFrame format.\"\"\"\n        self.markdown = False\n        return self.load_files_helper()\n\n    def load_files_markdown(self) -> Message:\n        \"\"\"Load files using advanced Docling processing and export to Markdown format.\"\"\"\n        self.markdown = True\n        result = self.load_files_helper()\n        return Message(text=str(result.text[0]))\n"},"concurrency_multithreading":{"_input_type":"IntInput","advanced":true,"display_name":"Processing Concurrency","dynamic":false,"info":"When multiple files are being processed, the number of files to process concurrently.","list":false,"list_add_label":"Add More","name":"concurrency_multithreading","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1},"delete_server_file_after_processing":{"_input_type":"BoolInput","advanced":true,"display_name":"Delete Server File After Processing","dynamic":false,"info":"If true, the Server File Path will be deleted after processing.","list":false,"list_add_label":"Add More","name":"delete_server_file_after_processing","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"doc_key":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Doc Key","dynamic":false,"info":"The key to use for the DoclingDocument column.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"doc_key","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"doc"},"file_path":{"_input_type":"HandleInput","advanced":true,"display_name":"Server File Path","dynamic":false,"info":"Data object with a 'file_path' property pointing to server file or a Message object with a path to the file. Supercedes 'Path' but supports same file types.","input_types":["Data","Message"],"list":true,"list_add_label":"Add More","name":"file_path","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"ignore_unspecified_files":{"_input_type":"BoolInput","advanced":true,"display_name":"Ignore Unspecified Files","dynamic":false,"info":"If true, Data with no 'file_path' property will be ignored.","list":false,"list_add_label":"Add More","name":"ignore_unspecified_files","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"ignore_unsupported_extensions":{"_input_type":"BoolInput","advanced":true,"display_name":"Ignore Unsupported Extensions","dynamic":false,"info":"If true, files with unsupported extensions will not be processed.","list":false,"list_add_label":"Add More","name":"ignore_unsupported_extensions","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"markdown":{"_input_type":"BoolInput","advanced":false,"display_name":"Markdown Export","dynamic":false,"info":"Export processed documents to Markdown format. Only available when advanced mode is enabled.","list":false,"list_add_label":"Add More","name":"markdown","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"md_image_placeholder":{"_input_type":"StrInput","advanced":true,"display_name":"Image placeholder","dynamic":false,"info":"Specify the image placeholder for markdown exports.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"md_image_placeholder","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"<!-- image -->"},"md_page_break_placeholder":{"_input_type":"StrInput","advanced":true,"display_name":"Page break placeholder","dynamic":false,"info":"Add this placeholder between pages in the markdown output.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"md_page_break_placeholder","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"ocr_engine":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"OCR Engine","dynamic":false,"external_options":{},"info":"OCR engine to use. Only available when pipeline is set to 'standard'.","name":"ocr_engine","options":["None","easyocr"],"options_metadata":[],"placeholder":"","required":false,"show":false,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"easyocr"},"path":{"_input_type":"FileInput","advanced":false,"display_name":"Files","dynamic":false,"fileTypes":["csv","json","pdf","txt","md","mdx","yaml","yml","xml","html","htm","docx","py","sh","sql","js","ts","tsx","adoc","asciidoc","asc","bmp","dotx","dotm","docm","jpg","jpeg","png","potx","ppsx","pptm","potm","ppsm","pptx","tiff","xls","xlsx","xhtml","webp","zip","tar","tgz","bz2","gz"],"file_path":"","info":"Supported file extensions: csv, json, pdf, txt, md, mdx, yaml, yml, xml, html, htm, docx, py, sh, sql, js, ts, tsx, adoc, asciidoc, asc, bmp, dotx, dotm, docm, jpg, jpeg, png, potx, ppsx, pptm, potm, ppsm, pptx, tiff, xls, xlsx, xhtml, webp; optionally bundled in file extensions: zip, tar, tgz, bz2, gz","list":true,"list_add_label":"Add More","name":"path","placeholder":"","real_time_refresh":true,"required":false,"show":true,"temp_file":false,"title_case":false,"tool_mode":true,"trace_as_metadata":true,"type":"file","value":[]},"pipeline":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Pipeline","dynamic":false,"external_options":{},"info":"Docling pipeline to use","name":"pipeline","options":["standard","vlm"],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"standard"},"separator":{"_input_type":"StrInput","advanced":true,"display_name":"Separator","dynamic":false,"info":"Specify the separator to use between multiple outputs in Message format.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"separator","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"\n\n"},"silent_errors":{"_input_type":"BoolInput","advanced":true,"display_name":"Silent Errors","dynamic":false,"info":"If true, errors will not raise an exception.","list":false,"list_add_label":"Add More","name":"silent_errors","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"use_multithreading":{"_input_type":"BoolInput","advanced":true,"display_name":"[Deprecated] Use Multithreading","dynamic":false,"info":"Set 'Processing Concurrency' greater than 1 to enable multithreading.","list":false,"list_add_label":"Add More","name":"use_multithreading","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false},"JSONtoData":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Convert a JSON file, JSON from a file path, or a JSON string to a Data object or a list of Data objects","display_name":"Load JSON","documentation":"","edited":false,"field_order":["json_file","json_path","json_string"],"frozen":false,"icon":"braces","legacy":true,"metadata":{"code_hash":"a7a30fc94803","dependencies":{"dependencies":[{"name":"json_repair","version":"0.30.3"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.data.json_to_data.JSONToDataComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"convert_json_to_data","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["data.File"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nfrom pathlib import Path\n\nfrom json_repair import repair_json\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import FileInput, MessageTextInput, MultilineInput, Output\nfrom lfx.schema.data import Data\n\n\nclass JSONToDataComponent(Component):\n    display_name = \"Load JSON\"\n    description = (\n        \"Convert a JSON file, JSON from a file path, or a JSON string to a Data object or a list of Data objects\"\n    )\n    icon = \"braces\"\n    name = \"JSONtoData\"\n    legacy = True\n    replacement = [\"data.File\"]\n\n    inputs = [\n        FileInput(\n            name=\"json_file\",\n            display_name=\"JSON File\",\n            file_types=[\"json\"],\n            info=\"Upload a JSON file to convert to a Data object or list of Data objects\",\n        ),\n        MessageTextInput(\n            name=\"json_path\",\n            display_name=\"JSON File Path\",\n            info=\"Provide the path to the JSON file as pure text\",\n        ),\n        MultilineInput(\n            name=\"json_string\",\n            display_name=\"JSON String\",\n            info=\"Enter a valid JSON string (object or array) to convert to a Data object or list of Data objects\",\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"data\", display_name=\"Data\", method=\"convert_json_to_data\"),\n    ]\n\n    def convert_json_to_data(self) -> Data | list[Data]:\n        if sum(bool(field) for field in [self.json_file, self.json_path, self.json_string]) != 1:\n            msg = \"Please provide exactly one of: JSON file, file path, or JSON string.\"\n            self.status = msg\n            raise ValueError(msg)\n\n        json_data = None\n\n        try:\n            if self.json_file:\n                resolved_path = self.resolve_path(self.json_file)\n                file_path = Path(resolved_path)\n                if file_path.suffix.lower() != \".json\":\n                    self.status = \"The provided file must be a JSON file.\"\n                else:\n                    json_data = file_path.read_text(encoding=\"utf-8\")\n\n            elif self.json_path:\n                file_path = Path(self.json_path)\n                if file_path.suffix.lower() != \".json\":\n                    self.status = \"The provided file must be a JSON file.\"\n                else:\n                    json_data = file_path.read_text(encoding=\"utf-8\")\n\n            else:\n                json_data = self.json_string\n\n            if json_data:\n                # Try to parse the JSON string\n                try:\n                    parsed_data = json.loads(json_data)\n                except json.JSONDecodeError:\n                    # If JSON parsing fails, try to repair the JSON string\n                    repaired_json_string = repair_json(json_data)\n                    parsed_data = json.loads(repaired_json_string)\n\n                # Check if the parsed data is a list\n                if isinstance(parsed_data, list):\n                    result = [Data(data=item) for item in parsed_data]\n                else:\n                    result = Data(data=parsed_data)\n                self.status = result\n                return result\n\n        except (json.JSONDecodeError, SyntaxError, ValueError) as e:\n            error_message = f\"Invalid JSON or Python literal: {e}\"\n            self.status = error_message\n            raise ValueError(error_message) from e\n\n        except Exception as e:\n            error_message = f\"An error occurred: {e}\"\n            self.status = error_message\n            raise ValueError(error_message) from e\n\n        # An error occurred\n        raise ValueError(self.status)\n"},"json_file":{"_input_type":"FileInput","advanced":false,"display_name":"JSON File","dynamic":false,"fileTypes":["json"],"file_path":"","info":"Upload a JSON file to convert to a Data object or list of Data objects","list":false,"list_add_label":"Add More","name":"json_file","placeholder":"","required":false,"show":true,"temp_file":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"file","value":""},"json_path":{"_input_type":"MessageTextInput","advanced":false,"display_name":"JSON File Path","dynamic":false,"info":"Provide the path to the JSON file as pure text","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"json_path","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"json_string":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"JSON String","dynamic":false,"info":"Enter a valid JSON string (object or array) to convert to a Data object or list of Data objects","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"json_string","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"MockDataGenerator":{"base_classes":["Data","DataFrame","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate mock data for testing and development.","display_name":"Mock Data","documentation":"","edited":false,"field_order":[],"frozen":false,"icon":"database","legacy":false,"metadata":{"code_hash":"d21dce7b329b","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"pandas","version":"2.2.3"}],"total_dependencies":2},"module":"lfx.components.data.mock_data.MockDataGeneratorComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Result","group_outputs":false,"method":"generate_dataframe_output","name":"dataframe_output","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Result","group_outputs":false,"method":"generate_message_output","name":"message_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Result","group_outputs":false,"method":"generate_data_output","name":"data_output","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import secrets\nfrom datetime import datetime, timedelta, timezone\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import Output\nfrom lfx.schema import Data, DataFrame\nfrom lfx.schema.message import Message\n\n\nclass MockDataGeneratorComponent(Component):\n    \"\"\"Mock Data Generator Component.\n\n    Generates sample data for testing and development purposes. Supports three main\n    Langflow output types: Message (text), Data (JSON), and DataFrame (tabular data).\n\n    This component is useful for:\n    - Testing workflows without real data sources\n    - Prototyping data processing pipelines\n    - Creating sample data for demonstrations\n    - Development and debugging of Langflow components\n    \"\"\"\n\n    display_name = \"Mock Data\"\n    description = \"Generate mock data for testing and development.\"\n    icon = \"database\"\n    name = \"MockDataGenerator\"\n\n    inputs = []\n\n    outputs = [\n        Output(display_name=\"Result\", name=\"dataframe_output\", method=\"generate_dataframe_output\"),\n        Output(display_name=\"Result\", name=\"message_output\", method=\"generate_message_output\"),\n        Output(display_name=\"Result\", name=\"data_output\", method=\"generate_data_output\"),\n    ]\n\n    def build(self) -> DataFrame:\n        \"\"\"Default build method - returns DataFrame when component is standalone.\"\"\"\n        return self.generate_dataframe_output()\n\n    def generate_message_output(self) -> Message:\n        \"\"\"Generate Message output specifically.\n\n        Returns:\n            Message: A Message object containing Lorem Ipsum text\n        \"\"\"\n        try:\n            self.log(\"Generating Message mock data\")\n            message = self._generate_message()\n            self.status = f\"Generated Lorem Ipsum message ({len(message.text)} characters)\"\n        except (ValueError, TypeError) as e:\n            error_msg = f\"Error generating Message data: {e!s}\"\n            self.log(error_msg)\n            self.status = f\"Error: {error_msg}\"\n            return Message(text=f\"Error: {error_msg}\")\n        else:\n            return message\n\n    def generate_data_output(self) -> Data:\n        \"\"\"Generate Data output specifically.\n\n        Returns:\n            Data: A Data object containing sample JSON data (1 record)\n        \"\"\"\n        try:\n            record_count = 1  # Fixed to 1 record for Data output\n            self.log(f\"Generating Data mock data with {record_count} record\")\n            data = self._generate_data(record_count)\n            self.status = f\"Generated JSON data with {len(data.data.get('records', []))} record(s)\"\n        except (ValueError, TypeError) as e:\n            error_msg = f\"Error generating Data: {e!s}\"\n            self.log(error_msg)\n            self.status = f\"Error: {error_msg}\"\n            return Data(data={\"error\": error_msg, \"success\": False})\n        else:\n            return data\n\n    def generate_dataframe_output(self) -> DataFrame:\n        \"\"\"Generate DataFrame output specifically.\n\n        Returns:\n            DataFrame: A Langflow DataFrame with sample data (50 records)\n        \"\"\"\n        try:\n            record_count = 50  # Fixed to 50 records for DataFrame output\n            self.log(f\"Generating DataFrame mock data with {record_count} records\")\n            return self._generate_dataframe(record_count)\n        except (ValueError, TypeError) as e:\n            error_msg = f\"Error generating DataFrame: {e!s}\"\n            self.log(error_msg)\n\n            try:\n                import pandas as pd\n\n                error_df = pd.DataFrame({\"error\": [error_msg]})\n                return DataFrame(error_df)\n            except ImportError:\n                # Even without pandas, return DataFrame wrapper\n                return DataFrame({\"error\": [error_msg]})\n\n    def _generate_message(self) -> Message:\n        \"\"\"Generate a sample Message with Lorem Ipsum text.\n\n        Returns:\n            Message: A Message object containing Lorem Ipsum text\n        \"\"\"\n        lorem_ipsum_texts = [\n            (\n                \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor \"\n                \"incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud \"\n                \"exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\"\n            ),\n            (\n                \"Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla \"\n                \"pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt \"\n                \"mollit anim id est laborum.\"\n            ),\n            (\n                \"Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, \"\n                \"totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto \"\n                \"beatae vitae dicta sunt explicabo.\"\n            ),\n            (\n                \"Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, \"\n                \"sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt.\"\n            ),\n            (\n                \"Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, \"\n                \"adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore \"\n                \"magnam aliquam quaerat voluptatem.\"\n            ),\n        ]\n\n        selected_text = secrets.choice(lorem_ipsum_texts)\n        return Message(text=selected_text)\n\n    def _generate_data(self, record_count: int) -> Data:\n        \"\"\"Generate sample Data with JSON structure.\n\n        Args:\n            record_count: Number of records to generate\n\n        Returns:\n            Data: A Data object containing sample JSON data\n        \"\"\"\n        # Sample data categories\n        companies = [\n            \"TechCorp\",\n            \"DataSystems\",\n            \"CloudWorks\",\n            \"InnovateLab\",\n            \"DigitalFlow\",\n            \"SmartSolutions\",\n            \"FutureTech\",\n            \"NextGen\",\n        ]\n        departments = [\"Engineering\", \"Sales\", \"Marketing\", \"HR\", \"Finance\", \"Operations\", \"Support\", \"Research\"]\n        statuses = [\"active\", \"pending\", \"completed\", \"cancelled\", \"in_progress\"]\n        categories = [\"A\", \"B\", \"C\", \"D\"]\n\n        # Generate sample records\n        records = []\n        base_date = datetime.now(tz=timezone.utc) - timedelta(days=365)\n\n        for i in range(record_count):\n            record = {\n                \"id\": f\"REC-{1000 + i}\",\n                \"name\": f\"Sample Record {i + 1}\",\n                \"company\": secrets.choice(companies),\n                \"department\": secrets.choice(departments),\n                \"status\": secrets.choice(statuses),\n                \"category\": secrets.choice(categories),\n                \"value\": round(secrets.randbelow(9901) + 100 + secrets.randbelow(100) / 100, 2),\n                \"quantity\": secrets.randbelow(100) + 1,\n                \"rating\": round(secrets.randbelow(41) / 10 + 1, 1),\n                \"is_active\": secrets.choice([True, False]),\n                \"created_date\": (base_date + timedelta(days=secrets.randbelow(366))).isoformat(),\n                \"tags\": [\n                    secrets.choice(\n                        [\n                            \"important\",\n                            \"urgent\",\n                            \"review\",\n                            \"approved\",\n                            \"draft\",\n                            \"final\",\n                        ]\n                    )\n                    for _ in range(secrets.randbelow(3) + 1)\n                ],\n            }\n            records.append(record)\n\n        # Create the main data structure\n        data_structure = {\n            \"records\": records,\n            \"summary\": {\n                \"total_count\": record_count,\n                \"active_count\": sum(1 for r in records if r[\"is_active\"]),\n                \"total_value\": sum(r[\"value\"] for r in records),\n                \"average_rating\": round(sum(r[\"rating\"] for r in records) / record_count, 2),\n                \"categories\": list({r[\"category\"] for r in records}),\n                \"companies\": list({r[\"company\"] for r in records}),\n            },\n        }\n\n        return Data(data=data_structure)\n\n    def _generate_dataframe(self, record_count: int) -> DataFrame:\n        \"\"\"Generate sample DataFrame with realistic business data.\n\n        Args:\n            record_count: Number of rows to generate\n\n        Returns:\n            DataFrame: A Langflow DataFrame with sample data\n        \"\"\"\n        try:\n            import pandas as pd\n\n            self.log(f\"pandas imported successfully, version: {pd.__version__}\")\n        except ImportError as e:\n            self.log(f\"pandas not available: {e!s}, creating simple DataFrame fallback\")\n            # Create a simple DataFrame-like structure without pandas\n            data_result = self._generate_data(record_count)\n            # Convert Data to simple DataFrame format\n            try:\n                # Create a basic DataFrame structure from the Data\n                records = data_result.data.get(\"records\", [])\n                if records:\n                    # Use first record to get column names\n                    columns = list(records[0].keys()) if records else [\"error\"]\n                    rows = [list(record.values()) for record in records]\n                else:\n                    columns = [\"error\"]\n                    rows = [[\"pandas not available\"]]\n\n                # Create a simple dict-based DataFrame representation\n                simple_df_data = {\n                    col: [row[i] if i < len(row) else None for row in rows] for i, col in enumerate(columns)\n                }\n\n                # Return as DataFrame wrapper (Langflow will handle the display)\n                return DataFrame(simple_df_data)\n            except (ValueError, TypeError):\n                # Ultimate fallback - return the Data as DataFrame\n                return DataFrame({\"data\": [str(data_result.data)]})\n\n        try:\n            self.log(f\"Starting DataFrame generation with {record_count} records\")\n\n            # Sample data for realistic business dataset\n            first_names = [\n                \"John\",\n                \"Jane\",\n                \"Michael\",\n                \"Sarah\",\n                \"David\",\n                \"Emily\",\n                \"Robert\",\n                \"Lisa\",\n                \"William\",\n                \"Jennifer\",\n            ]\n            last_names = [\n                \"Smith\",\n                \"Johnson\",\n                \"Williams\",\n                \"Brown\",\n                \"Jones\",\n                \"Garcia\",\n                \"Miller\",\n                \"Davis\",\n                \"Rodriguez\",\n                \"Martinez\",\n            ]\n            cities = [\n                \"New York\",\n                \"Los Angeles\",\n                \"Chicago\",\n                \"Houston\",\n                \"Phoenix\",\n                \"Philadelphia\",\n                \"San Antonio\",\n                \"San Diego\",\n                \"Dallas\",\n                \"San Jose\",\n            ]\n            countries = [\"USA\", \"Canada\", \"UK\", \"Germany\", \"France\", \"Australia\", \"Japan\", \"Brazil\", \"India\", \"Mexico\"]\n            products = [\n                \"Product A\",\n                \"Product B\",\n                \"Product C\",\n                \"Product D\",\n                \"Product E\",\n                \"Service X\",\n                \"Service Y\",\n                \"Service Z\",\n            ]\n\n            # Generate DataFrame data\n            data = []\n            base_date = datetime.now(tz=timezone.utc) - timedelta(days=365)\n\n            self.log(\"Generating row data...\")\n            for i in range(record_count):\n                row = {\n                    \"customer_id\": f\"CUST-{10000 + i}\",\n                    \"first_name\": secrets.choice(first_names),\n                    \"last_name\": secrets.choice(last_names),\n                    \"email\": f\"user{i + 1}@example.com\",\n                    \"age\": secrets.randbelow(63) + 18,\n                    \"city\": secrets.choice(cities),\n                    \"country\": secrets.choice(countries),\n                    \"product\": secrets.choice(products),\n                    \"order_date\": (base_date + timedelta(days=secrets.randbelow(366))).strftime(\"%Y-%m-%d\"),\n                    \"order_value\": round(secrets.randbelow(991) + 10 + secrets.randbelow(100) / 100, 2),\n                    \"quantity\": secrets.randbelow(10) + 1,\n                    \"discount\": round(secrets.randbelow(31) / 100, 2),\n                    \"is_premium\": secrets.choice([True, False]),\n                    \"satisfaction_score\": secrets.randbelow(10) + 1,\n                    \"last_contact\": (base_date + timedelta(days=secrets.randbelow(366))).strftime(\"%Y-%m-%d\"),\n                }\n                data.append(row)\n            # Create DataFrame\n            self.log(\"Creating pandas DataFrame...\")\n            df = pd.DataFrame(data)\n            self.log(f\"DataFrame created with shape: {df.shape}\")\n\n            # Add calculated columns\n            self.log(\"Adding calculated columns...\")\n            df[\"full_name\"] = df[\"first_name\"] + \" \" + df[\"last_name\"]\n            df[\"discounted_value\"] = df[\"order_value\"] * (1 - df[\"discount\"])\n            df[\"total_value\"] = df[\"discounted_value\"] * df[\"quantity\"]\n\n            # Age group boundaries as constants\n            age_group_18_25 = 25\n            age_group_26_35 = 35\n            age_group_36_50 = 50\n            age_group_51_65 = 65\n\n            # Create age groups with better error handling\n            try:\n                df[\"age_group\"] = pd.cut(\n                    df[\"age\"],\n                    bins=[\n                        0,\n                        age_group_18_25,\n                        age_group_26_35,\n                        age_group_36_50,\n                        age_group_51_65,\n                        100,\n                    ],\n                    labels=[\n                        \"18-25\",\n                        \"26-35\",\n                        \"36-50\",\n                        \"51-65\",\n                        \"65+\",\n                    ],\n                )\n            except (ValueError, TypeError) as e:\n                self.log(f\"Error creating age groups with pd.cut: {e!s}, using simple categorization\")\n                df[\"age_group\"] = df[\"age\"].apply(\n                    lambda x: \"18-25\"\n                    if x <= age_group_18_25\n                    else \"26-35\"\n                    if x <= age_group_26_35\n                    else \"36-50\"\n                    if x <= age_group_36_50\n                    else \"51-65\"\n                    if x <= age_group_51_65\n                    else \"65+\"\n                )\n\n            self.log(f\"Successfully generated DataFrame with shape: {df.shape}, columns: {list(df.columns)}\")\n            # CRITICAL: Use DataFrame wrapper from Langflow\n            # DO NOT set self.status when returning DataFrames - it interferes with display\n            return DataFrame(df)\n\n        except (ValueError, TypeError) as e:\n            error_msg = f\"Error generating DataFrame: {e!s}\"\n            self.log(error_msg)\n            # DO NOT set self.status when returning DataFrames - it interferes with display\n            # Return a fallback DataFrame with error info using Langflow wrapper\n            try:\n                error_df = pd.DataFrame(\n                    {\n                        \"error\": [error_msg],\n                        \"timestamp\": [datetime.now(tz=timezone.utc).isoformat()],\n                        \"attempted_records\": [record_count],\n                    }\n                )\n                return DataFrame(error_df)\n            except (ValueError, TypeError) as fallback_error:\n                # Last resort: return simple error DataFrame\n                self.log(f\"Fallback also failed: {fallback_error!s}\")\n                simple_error_df = pd.DataFrame({\"error\": [error_msg]})\n                return DataFrame(simple_error_df)\n"}},"tool_mode":false},"NewsSearch":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Searches Google News via RSS. Returns clean article data.","display_name":"News Search","documentation":"https://docs.langflow.org/components-data#news-search","edited":false,"field_order":["query","hl","gl","ceid","topic","location","timeout"],"frozen":false,"icon":"newspaper","legacy":true,"metadata":{"code_hash":"acdef6d4ecde","dependencies":{"dependencies":[{"name":"pandas","version":"2.2.3"},{"name":"requests","version":"2.32.5"},{"name":"bs4","version":"4.12.3"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.data.news_search.NewsSearchComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"News Articles","group_outputs":false,"method":"search_news","name":"articles","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":[],"template":{"_type":"Component","ceid":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Country:Language (ceid)","dynamic":false,"info":"e.g. US:en, FR:fr. Default: US:en.","input_types":[],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"ceid","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"US:en"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from urllib.parse import quote_plus\n\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\n\nfrom lfx.custom import Component\nfrom lfx.io import IntInput, MessageTextInput, Output\nfrom lfx.schema import DataFrame\n\n\nclass NewsSearchComponent(Component):\n    display_name = \"News Search\"\n    description = \"Searches Google News via RSS. Returns clean article data.\"\n    documentation: str = \"https://docs.langflow.org/components-data#news-search\"\n    icon = \"newspaper\"\n    name = \"NewsSearch\"\n    legacy = True\n    replacement = \"data.WebSearch\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"Search Query\",\n            info=\"Search keywords for news articles.\",\n            tool_mode=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"hl\",\n            display_name=\"Language (hl)\",\n            info=\"Language code, e.g. en-US, fr, de. Default: en-US.\",\n            tool_mode=False,\n            input_types=[],\n            required=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"gl\",\n            display_name=\"Country (gl)\",\n            info=\"Country code, e.g. US, FR, DE. Default: US.\",\n            tool_mode=False,\n            input_types=[],\n            required=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"ceid\",\n            display_name=\"Country:Language (ceid)\",\n            info=\"e.g. US:en, FR:fr. Default: US:en.\",\n            tool_mode=False,\n            value=\"US:en\",\n            input_types=[],\n            required=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"topic\",\n            display_name=\"Topic\",\n            info=\"One of: WORLD, NATION, BUSINESS, TECHNOLOGY, ENTERTAINMENT, SCIENCE, SPORTS, HEALTH.\",\n            tool_mode=False,\n            input_types=[],\n            required=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"location\",\n            display_name=\"Location (Geo)\",\n            info=\"City, state, or country for location-based news. Leave blank for keyword search.\",\n            tool_mode=False,\n            input_types=[],\n            required=False,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"Timeout for the request in seconds.\",\n            value=5,\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [Output(name=\"articles\", display_name=\"News Articles\", method=\"search_news\")]\n\n    def search_news(self) -> DataFrame:\n        # Defaults\n        hl = getattr(self, \"hl\", None) or \"en-US\"\n        gl = getattr(self, \"gl\", None) or \"US\"\n        ceid = getattr(self, \"ceid\", None) or f\"{gl}:{hl.split('-')[0]}\"\n        topic = getattr(self, \"topic\", None)\n        location = getattr(self, \"location\", None)\n        query = getattr(self, \"query\", None)\n\n        # Build base URL\n        if topic:\n            # Topic-based feed\n            base_url = f\"https://news.google.com/rss/headlines/section/topic/{quote_plus(topic.upper())}\"\n            params = f\"?hl={hl}&gl={gl}&ceid={ceid}\"\n            rss_url = base_url + params\n        elif location:\n            # Location-based feed\n            base_url = f\"https://news.google.com/rss/headlines/section/geo/{quote_plus(location)}\"\n            params = f\"?hl={hl}&gl={gl}&ceid={ceid}\"\n            rss_url = base_url + params\n        elif query:\n            # Keyword search feed\n            base_url = \"https://news.google.com/rss/search?q=\"\n            query_parts = [query]\n            query_encoded = quote_plus(\" \".join(query_parts))\n            params = f\"&hl={hl}&gl={gl}&ceid={ceid}\"\n            rss_url = f\"{base_url}{query_encoded}{params}\"\n        else:\n            self.status = \"No search query, topic, or location provided.\"\n            self.log(self.status)\n            return DataFrame(\n                pd.DataFrame(\n                    [\n                        {\n                            \"title\": \"Error\",\n                            \"link\": \"\",\n                            \"published\": \"\",\n                            \"summary\": \"No search query, topic, or location provided.\",\n                        }\n                    ]\n                )\n            )\n\n        try:\n            response = requests.get(rss_url, timeout=self.timeout)\n            response.raise_for_status()\n            soup = BeautifulSoup(response.content, \"xml\")\n            items = soup.find_all(\"item\")\n        except requests.RequestException as e:\n            self.status = f\"Failed to fetch news: {e}\"\n            self.log(self.status)\n            return DataFrame(pd.DataFrame([{\"title\": \"Error\", \"link\": \"\", \"published\": \"\", \"summary\": str(e)}]))\n        except (AttributeError, ValueError, TypeError) as e:\n            self.status = f\"Unexpected error: {e!s}\"\n            self.log(self.status)\n            return DataFrame(pd.DataFrame([{\"title\": \"Error\", \"link\": \"\", \"published\": \"\", \"summary\": str(e)}]))\n\n        if not items:\n            self.status = \"No news articles found.\"\n            self.log(self.status)\n            return DataFrame(pd.DataFrame([{\"title\": \"No articles found\", \"link\": \"\", \"published\": \"\", \"summary\": \"\"}]))\n\n        articles = []\n        for item in items:\n            try:\n                title = self.clean_html(item.title.text if item.title else \"\")\n                link = item.link.text if item.link else \"\"\n                published = item.pubDate.text if item.pubDate else \"\"\n                summary = self.clean_html(item.description.text if item.description else \"\")\n                articles.append({\"title\": title, \"link\": link, \"published\": published, \"summary\": summary})\n            except (AttributeError, ValueError, TypeError) as e:\n                self.log(f\"Error parsing article: {e!s}\")\n                continue\n\n        df_articles = pd.DataFrame(articles)\n        self.log(f\"Found {len(df_articles)} articles.\")\n        return DataFrame(df_articles)\n\n    def clean_html(self, html_string: str) -> str:\n        return BeautifulSoup(html_string, \"html.parser\").get_text(separator=\" \", strip=True)\n"},"gl":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Country (gl)","dynamic":false,"info":"Country code, e.g. US, FR, DE. Default: US.","input_types":[],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"gl","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"hl":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Language (hl)","dynamic":false,"info":"Language code, e.g. en-US, fr, de. Default: en-US.","input_types":[],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"hl","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"location":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Location (Geo)","dynamic":false,"info":"City, state, or country for location-based news. Leave blank for keyword search.","input_types":[],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"location","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"query":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Search keywords for news articles.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"query","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"timeout":{"_input_type":"IntInput","advanced":true,"display_name":"Timeout","dynamic":false,"info":"Timeout for the request in seconds.","list":false,"list_add_label":"Add More","name":"timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5},"topic":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Topic","dynamic":false,"info":"One of: WORLD, NATION, BUSINESS, TECHNOLOGY, ENTERTAINMENT, SCIENCE, SPORTS, HEALTH.","input_types":[],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"topic","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"RSSReaderSimple":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Fetches and parses an RSS feed.","display_name":"RSS Reader","documentation":"https://docs.langflow.org/components-data#rss-reader","edited":false,"field_order":["rss_url","timeout"],"frozen":false,"icon":"rss","legacy":true,"metadata":{"code_hash":"27df3344d19b","dependencies":{"dependencies":[{"name":"pandas","version":"2.2.3"},{"name":"requests","version":"2.32.5"},{"name":"bs4","version":"4.12.3"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.data.rss.RSSReaderComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Articles","group_outputs":false,"method":"read_rss","name":"articles","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":[],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\n\nfrom lfx.custom import Component\nfrom lfx.io import IntInput, MessageTextInput, Output\nfrom lfx.log.logger import logger\nfrom lfx.schema import DataFrame\n\n\nclass RSSReaderComponent(Component):\n    display_name = \"RSS Reader\"\n    description = \"Fetches and parses an RSS feed.\"\n    documentation: str = \"https://docs.langflow.org/components-data#rss-reader\"\n    icon = \"rss\"\n    name = \"RSSReaderSimple\"\n    legacy = True\n    replacement = \"data.WebSearch\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"rss_url\",\n            display_name=\"RSS Feed URL\",\n            info=\"URL of the RSS feed to parse.\",\n            tool_mode=True,\n            required=True,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"Timeout for the RSS feed request.\",\n            value=5,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [Output(name=\"articles\", display_name=\"Articles\", method=\"read_rss\")]\n\n    def read_rss(self) -> DataFrame:\n        try:\n            response = requests.get(self.rss_url, timeout=self.timeout)\n            response.raise_for_status()\n            if not response.content.strip():\n                msg = \"Empty response received\"\n                raise ValueError(msg)\n            # Check if the response is valid XML\n            try:\n                BeautifulSoup(response.content, \"xml\")\n            except Exception as e:\n                msg = f\"Invalid XML response: {e}\"\n                raise ValueError(msg) from e\n            soup = BeautifulSoup(response.content, \"xml\")\n            items = soup.find_all(\"item\")\n        except (requests.RequestException, ValueError) as e:\n            self.status = f\"Failed to fetch RSS: {e}\"\n            return DataFrame(pd.DataFrame([{\"title\": \"Error\", \"link\": \"\", \"published\": \"\", \"summary\": str(e)}]))\n\n        articles = [\n            {\n                \"title\": item.title.text if item.title else \"\",\n                \"link\": item.link.text if item.link else \"\",\n                \"published\": item.pubDate.text if item.pubDate else \"\",\n                \"summary\": item.description.text if item.description else \"\",\n            }\n            for item in items\n        ]\n\n        # Ensure the DataFrame has the correct columns even if empty\n        df_articles = pd.DataFrame(articles, columns=[\"title\", \"link\", \"published\", \"summary\"])\n        logger.info(f\"Fetched {len(df_articles)} articles.\")\n        return DataFrame(df_articles)\n"},"rss_url":{"_input_type":"MessageTextInput","advanced":false,"display_name":"RSS Feed URL","dynamic":false,"info":"URL of the RSS feed to parse.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"rss_url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"timeout":{"_input_type":"IntInput","advanced":true,"display_name":"Timeout","dynamic":false,"info":"Timeout for the RSS feed request.","list":false,"list_add_label":"Add More","name":"timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5}},"tool_mode":false},"SQLComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Executes SQL queries on SQLAlchemy-compatible databases.","display_name":"SQL Database","documentation":"https://docs.langflow.org/components-data#sql-database","edited":false,"field_order":["database_url","query","include_columns","add_error"],"frozen":false,"icon":"database","legacy":false,"metadata":{"code_hash":"b0dd6558ceb9","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"sqlalchemy","version":"2.0.44"},{"name":"lfx","version":null}],"total_dependencies":3},"keywords":["sql","database","query","db","fetch"],"module":"lfx.components.data.sql_executor.SQLComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Result Table","group_outputs":false,"method":"run_sql_query","name":"run_sql_query","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","add_error":{"_input_type":"BoolInput","advanced":true,"display_name":"Add Error","dynamic":false,"info":"If True, the error will be added to the result","list":false,"list_add_label":"Add More","name":"add_error","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_metadata":true,"type":"bool","value":false},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import TYPE_CHECKING, Any\n\nfrom langchain_community.utilities import SQLDatabase\nfrom sqlalchemy.exc import SQLAlchemyError\n\nfrom lfx.custom.custom_component.component_with_cache import ComponentWithCache\nfrom lfx.io import BoolInput, MessageTextInput, MultilineInput, Output\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.message import Message\nfrom lfx.services.cache.utils import CacheMiss\n\nif TYPE_CHECKING:\n    from sqlalchemy.engine import Result\n\n\nclass SQLComponent(ComponentWithCache):\n    \"\"\"A sql component.\"\"\"\n\n    display_name = \"SQL Database\"\n    description = \"Executes SQL queries on SQLAlchemy-compatible databases.\"\n    documentation: str = \"https://docs.langflow.org/components-data#sql-database\"\n    icon = \"database\"\n    name = \"SQLComponent\"\n    metadata = {\"keywords\": [\"sql\", \"database\", \"query\", \"db\", \"fetch\"]}\n\n    def __init__(self, **kwargs) -> None:\n        super().__init__(**kwargs)\n        self.db: SQLDatabase = None\n\n    def maybe_create_db(self):\n        if self.database_url != \"\":\n            if self._shared_component_cache:\n                cached_db = self._shared_component_cache.get(self.database_url)\n                if not isinstance(cached_db, CacheMiss):\n                    self.db = cached_db\n                    return\n                self.log(\"Connecting to database\")\n            try:\n                self.db = SQLDatabase.from_uri(self.database_url)\n            except Exception as e:\n                msg = f\"An error occurred while connecting to the database: {e}\"\n                raise ValueError(msg) from e\n            if self._shared_component_cache:\n                self._shared_component_cache.set(self.database_url, self.db)\n\n    inputs = [\n        MessageTextInput(name=\"database_url\", display_name=\"Database URL\", required=True),\n        MultilineInput(name=\"query\", display_name=\"SQL Query\", tool_mode=True, required=True),\n        BoolInput(name=\"include_columns\", display_name=\"Include Columns\", value=True, tool_mode=True, advanced=True),\n        BoolInput(\n            name=\"add_error\",\n            display_name=\"Add Error\",\n            value=False,\n            tool_mode=True,\n            info=\"If True, the error will be added to the result\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Result Table\", name=\"run_sql_query\", method=\"run_sql_query\"),\n    ]\n\n    def build_component(\n        self,\n    ) -> Message:\n        error = None\n        self.maybe_create_db()\n        try:\n            result = self.db.run(self.query, include_columns=self.include_columns)\n            self.status = result\n        except SQLAlchemyError as e:\n            msg = f\"An error occurred while running the SQL Query: {e}\"\n            self.log(msg)\n            result = str(e)\n            self.status = result\n            error = repr(e)\n\n        if self.add_error and error is not None:\n            result = f\"{result}\\n\\nError: {error}\\n\\nQuery: {self.query}\"\n        elif error is not None:\n            # Then we won't add the error to the result\n            result = self.query\n\n        return Message(text=result)\n\n    def __execute_query(self) -> list[dict[str, Any]]:\n        self.maybe_create_db()\n        try:\n            cursor: Result[Any] = self.db.run(self.query, fetch=\"cursor\")\n            return [x._asdict() for x in cursor.fetchall()]\n        except SQLAlchemyError as e:\n            msg = f\"An error occurred while running the SQL Query: {e}\"\n            self.log(msg)\n            raise ValueError(msg) from e\n\n    def run_sql_query(self) -> DataFrame:\n        result = self.__execute_query()\n        df_result = DataFrame(result)\n        self.status = df_result\n        return df_result\n"},"database_url":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Database URL","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"database_url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"include_columns":{"_input_type":"BoolInput","advanced":true,"display_name":"Include Columns","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"include_columns","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_metadata":true,"type":"bool","value":true},"query":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"SQL Query","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"query","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"SaveToFile":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Save data to local file, AWS S3, or Google Drive in the selected format.","display_name":"Write File","documentation":"https://docs.langflow.org/components-processing#save-file","edited":false,"field_order":["storage_location","input","file_name","local_format","aws_format","gdrive_format","aws_access_key_id","aws_secret_access_key","bucket_name","aws_region","s3_prefix","service_account_key","folder_id"],"frozen":false,"icon":"file-text","legacy":false,"metadata":{"code_hash":"df2a0603fe8f","dependencies":{"dependencies":[{"name":"orjson","version":"3.10.15"},{"name":"pandas","version":"2.2.3"},{"name":"fastapi","version":"0.119.0"},{"name":"lfx","version":null},{"name":"langflow","version":null},{"name":"boto3","version":"1.40.52"},{"name":"google","version":"0.8.5"},{"name":"googleapiclient","version":"2.154.0"}],"total_dependencies":8},"module":"lfx.components.data.save_file.SaveToFileComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"File Path","group_outputs":false,"method":"save_to_file","name":"message","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","aws_access_key_id":{"_input_type":"SecretStrInput","advanced":true,"display_name":"AWS Access Key ID","dynamic":false,"info":"AWS Access key ID.","input_types":[],"load_from_db":true,"name":"aws_access_key_id","password":true,"placeholder":"","required":false,"show":false,"title_case":false,"type":"str","value":""},"aws_format":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"File Format","dynamic":false,"external_options":{},"info":"Select the file format for AWS S3 storage.","name":"aws_format","options":["txt","json","csv","xml","html","md","yaml","log","tsv","jsonl","parquet","xlsx","zip"],"options_metadata":[],"placeholder":"","required":false,"show":false,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"txt"},"aws_region":{"_input_type":"StrInput","advanced":true,"display_name":"AWS Region","dynamic":false,"info":"AWS region (e.g., us-east-1, eu-west-1).","list":false,"list_add_label":"Add More","load_from_db":false,"name":"aws_region","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"aws_secret_access_key":{"_input_type":"SecretStrInput","advanced":true,"display_name":"AWS Secret Key","dynamic":false,"info":"AWS Secret Key.","input_types":[],"load_from_db":true,"name":"aws_secret_access_key","password":true,"placeholder":"","required":false,"show":false,"title_case":false,"type":"str","value":""},"bucket_name":{"_input_type":"StrInput","advanced":true,"display_name":"S3 Bucket Name","dynamic":false,"info":"Enter the name of the S3 bucket.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"bucket_name","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nfrom collections.abc import AsyncIterator, Iterator\nfrom pathlib import Path\n\nimport orjson\nimport pandas as pd\nfrom fastapi import UploadFile\nfrom fastapi.encoders import jsonable_encoder\n\nfrom lfx.custom import Component\nfrom lfx.inputs import SortableListInput\nfrom lfx.io import DropdownInput, HandleInput, SecretStrInput, StrInput\nfrom lfx.schema import Data, DataFrame, Message\nfrom lfx.services.deps import get_settings_service, get_storage_service, session_scope\nfrom lfx.template.field.base import Output\n\n\nclass SaveToFileComponent(Component):\n    display_name = \"Write File\"\n    description = \"Save data to local file, AWS S3, or Google Drive in the selected format.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#save-file\"\n    icon = \"file-text\"\n    name = \"SaveToFile\"\n\n    # File format options for different storage types\n    LOCAL_DATA_FORMAT_CHOICES = [\"csv\", \"excel\", \"json\", \"markdown\"]\n    LOCAL_MESSAGE_FORMAT_CHOICES = [\"txt\", \"json\", \"markdown\"]\n    AWS_FORMAT_CHOICES = [\n        \"txt\",\n        \"json\",\n        \"csv\",\n        \"xml\",\n        \"html\",\n        \"md\",\n        \"yaml\",\n        \"log\",\n        \"tsv\",\n        \"jsonl\",\n        \"parquet\",\n        \"xlsx\",\n        \"zip\",\n    ]\n    GDRIVE_FORMAT_CHOICES = [\"txt\", \"json\", \"csv\", \"xlsx\", \"slides\", \"docs\", \"jpg\", \"mp3\"]\n\n    inputs = [\n        # Storage location selection\n        SortableListInput(\n            name=\"storage_location\",\n            display_name=\"Storage Location\",\n            placeholder=\"Select Location\",\n            info=\"Choose where to save the file.\",\n            options=[\n                {\"name\": \"Local\", \"icon\": \"hard-drive\"},\n                {\"name\": \"AWS\", \"icon\": \"Amazon\"},\n                {\"name\": \"Google Drive\", \"icon\": \"google\"},\n            ],\n            real_time_refresh=True,\n            limit=1,\n        ),\n        # Common inputs\n        HandleInput(\n            name=\"input\",\n            display_name=\"File Content\",\n            info=\"The input to save.\",\n            dynamic=True,\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        StrInput(\n            name=\"file_name\",\n            display_name=\"File Name\",\n            info=\"Name file will be saved as (without extension).\",\n            required=True,\n            show=False,\n            tool_mode=True,\n        ),\n        # Format inputs (dynamic based on storage location)\n        DropdownInput(\n            name=\"local_format\",\n            display_name=\"File Format\",\n            options=list(dict.fromkeys(LOCAL_DATA_FORMAT_CHOICES + LOCAL_MESSAGE_FORMAT_CHOICES)),\n            info=\"Select the file format for local storage.\",\n            value=\"json\",\n            show=False,\n        ),\n        DropdownInput(\n            name=\"aws_format\",\n            display_name=\"File Format\",\n            options=AWS_FORMAT_CHOICES,\n            info=\"Select the file format for AWS S3 storage.\",\n            value=\"txt\",\n            show=False,\n        ),\n        DropdownInput(\n            name=\"gdrive_format\",\n            display_name=\"File Format\",\n            options=GDRIVE_FORMAT_CHOICES,\n            info=\"Select the file format for Google Drive storage.\",\n            value=\"txt\",\n            show=False,\n        ),\n        # AWS S3 specific inputs\n        SecretStrInput(\n            name=\"aws_access_key_id\",\n            display_name=\"AWS Access Key ID\",\n            info=\"AWS Access key ID.\",\n            show=False,\n            advanced=True,\n        ),\n        SecretStrInput(\n            name=\"aws_secret_access_key\",\n            display_name=\"AWS Secret Key\",\n            info=\"AWS Secret Key.\",\n            show=False,\n            advanced=True,\n        ),\n        StrInput(\n            name=\"bucket_name\",\n            display_name=\"S3 Bucket Name\",\n            info=\"Enter the name of the S3 bucket.\",\n            show=False,\n            advanced=True,\n        ),\n        StrInput(\n            name=\"aws_region\",\n            display_name=\"AWS Region\",\n            info=\"AWS region (e.g., us-east-1, eu-west-1).\",\n            show=False,\n            advanced=True,\n        ),\n        StrInput(\n            name=\"s3_prefix\",\n            display_name=\"S3 Prefix\",\n            info=\"Prefix for all files in S3.\",\n            show=False,\n            advanced=True,\n        ),\n        # Google Drive specific inputs\n        SecretStrInput(\n            name=\"service_account_key\",\n            display_name=\"GCP Credentials Secret Key\",\n            info=\"Your Google Cloud Platform service account JSON key as a secret string (complete JSON content).\",\n            show=False,\n            advanced=True,\n        ),\n        StrInput(\n            name=\"folder_id\",\n            display_name=\"Google Drive Folder ID\",\n            info=(\n                \"The Google Drive folder ID where the file will be uploaded. \"\n                \"The folder must be shared with the service account email.\"\n            ),\n            show=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [Output(display_name=\"File Path\", name=\"message\", method=\"save_to_file\")]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Update build configuration to show/hide fields based on storage location selection.\"\"\"\n        if field_name != \"storage_location\":\n            return build_config\n\n        # Extract selected storage location\n        selected = [location[\"name\"] for location in field_value] if isinstance(field_value, list) else []\n\n        # Hide all dynamic fields first\n        dynamic_fields = [\n            \"file_name\",  # Common fields (input is always visible)\n            \"local_format\",\n            \"aws_format\",\n            \"gdrive_format\",\n            \"aws_access_key_id\",\n            \"aws_secret_access_key\",\n            \"bucket_name\",\n            \"aws_region\",\n            \"s3_prefix\",\n            \"service_account_key\",\n            \"folder_id\",\n        ]\n\n        for f_name in dynamic_fields:\n            if f_name in build_config:\n                build_config[f_name][\"show\"] = False\n\n        # Show fields based on selected storage location\n        if len(selected) == 1:\n            location = selected[0]\n\n            # Show file_name when any storage location is selected (input is always visible)\n            if \"file_name\" in build_config:\n                build_config[\"file_name\"][\"show\"] = True\n\n            if location == \"Local\":\n                if \"local_format\" in build_config:\n                    build_config[\"local_format\"][\"show\"] = True\n\n            elif location == \"AWS\":\n                aws_fields = [\n                    \"aws_format\",\n                    \"aws_access_key_id\",\n                    \"aws_secret_access_key\",\n                    \"bucket_name\",\n                    \"aws_region\",\n                    \"s3_prefix\",\n                ]\n                for f_name in aws_fields:\n                    if f_name in build_config:\n                        build_config[f_name][\"show\"] = True\n\n            elif location == \"Google Drive\":\n                gdrive_fields = [\"gdrive_format\", \"service_account_key\", \"folder_id\"]\n                for f_name in gdrive_fields:\n                    if f_name in build_config:\n                        build_config[f_name][\"show\"] = True\n\n        return build_config\n\n    async def save_to_file(self) -> Message:\n        \"\"\"Save the input to a file and upload it, returning a confirmation message.\"\"\"\n        # Validate inputs\n        if not self.file_name:\n            msg = \"File name must be provided.\"\n            raise ValueError(msg)\n        if not self._get_input_type():\n            msg = \"Input type is not set.\"\n            raise ValueError(msg)\n\n        # Get selected storage location\n        storage_location = self._get_selected_storage_location()\n        if not storage_location:\n            msg = \"Storage location must be selected.\"\n            raise ValueError(msg)\n\n        # Route to appropriate save method based on storage location\n        if storage_location == \"Local\":\n            return await self._save_to_local()\n        if storage_location == \"AWS\":\n            return await self._save_to_aws()\n        if storage_location == \"Google Drive\":\n            return await self._save_to_google_drive()\n        msg = f\"Unsupported storage location: {storage_location}\"\n        raise ValueError(msg)\n\n    def _get_input_type(self) -> str:\n        \"\"\"Determine the input type based on the provided input.\"\"\"\n        # Use exact type checking (type() is) instead of isinstance() to avoid inheritance issues.\n        # Since Message inherits from Data, isinstance(message, Data) would return True for Message objects,\n        # causing Message inputs to be incorrectly identified as Data type.\n        if type(self.input) is DataFrame:\n            return \"DataFrame\"\n        if type(self.input) is Message:\n            return \"Message\"\n        if type(self.input) is Data:\n            return \"Data\"\n        msg = f\"Unsupported input type: {type(self.input)}\"\n        raise ValueError(msg)\n\n    def _get_default_format(self) -> str:\n        \"\"\"Return the default file format based on input type.\"\"\"\n        if self._get_input_type() == \"DataFrame\":\n            return \"csv\"\n        if self._get_input_type() == \"Data\":\n            return \"json\"\n        if self._get_input_type() == \"Message\":\n            return \"json\"\n        return \"json\"  # Fallback\n\n    def _adjust_file_path_with_format(self, path: Path, fmt: str) -> Path:\n        \"\"\"Adjust the file path to include the correct extension.\"\"\"\n        file_extension = path.suffix.lower().lstrip(\".\")\n        if fmt == \"excel\":\n            return Path(f\"{path}.xlsx\").expanduser() if file_extension not in [\"xlsx\", \"xls\"] else path\n        return Path(f\"{path}.{fmt}\").expanduser() if file_extension != fmt else path\n\n    async def _upload_file(self, file_path: Path) -> None:\n        \"\"\"Upload the saved file using the upload_user_file service.\"\"\"\n        from langflow.api.v2.files import upload_user_file\n        from langflow.services.database.models.user.crud import get_user_by_id\n\n        # Ensure the file exists\n        if not file_path.exists():\n            msg = f\"File not found: {file_path}\"\n            raise FileNotFoundError(msg)\n\n        # Upload the file\n        with file_path.open(\"rb\") as f:\n            async with session_scope() as db:\n                if not self.user_id:\n                    msg = \"User ID is required for file saving.\"\n                    raise ValueError(msg)\n                current_user = await get_user_by_id(db, self.user_id)\n\n                await upload_user_file(\n                    file=UploadFile(filename=file_path.name, file=f, size=file_path.stat().st_size),\n                    session=db,\n                    current_user=current_user,\n                    storage_service=get_storage_service(),\n                    settings_service=get_settings_service(),\n                )\n\n    def _save_dataframe(self, dataframe: DataFrame, path: Path, fmt: str) -> str:\n        \"\"\"Save a DataFrame to the specified file format.\"\"\"\n        if fmt == \"csv\":\n            dataframe.to_csv(path, index=False)\n        elif fmt == \"excel\":\n            dataframe.to_excel(path, index=False, engine=\"openpyxl\")\n        elif fmt == \"json\":\n            dataframe.to_json(path, orient=\"records\", indent=2)\n        elif fmt == \"markdown\":\n            path.write_text(dataframe.to_markdown(index=False), encoding=\"utf-8\")\n        else:\n            msg = f\"Unsupported DataFrame format: {fmt}\"\n            raise ValueError(msg)\n        return f\"DataFrame saved successfully as '{path}'\"\n\n    def _save_data(self, data: Data, path: Path, fmt: str) -> str:\n        \"\"\"Save a Data object to the specified file format.\"\"\"\n        if fmt == \"csv\":\n            pd.DataFrame(data.data).to_csv(path, index=False)\n        elif fmt == \"excel\":\n            pd.DataFrame(data.data).to_excel(path, index=False, engine=\"openpyxl\")\n        elif fmt == \"json\":\n            path.write_text(\n                orjson.dumps(jsonable_encoder(data.data), option=orjson.OPT_INDENT_2).decode(\"utf-8\"), encoding=\"utf-8\"\n            )\n        elif fmt == \"markdown\":\n            path.write_text(pd.DataFrame(data.data).to_markdown(index=False), encoding=\"utf-8\")\n        else:\n            msg = f\"Unsupported Data format: {fmt}\"\n            raise ValueError(msg)\n        return f\"Data saved successfully as '{path}'\"\n\n    async def _save_message(self, message: Message, path: Path, fmt: str) -> str:\n        \"\"\"Save a Message to the specified file format, handling async iterators.\"\"\"\n        content = \"\"\n        if message.text is None:\n            content = \"\"\n        elif isinstance(message.text, AsyncIterator):\n            async for item in message.text:\n                content += str(item) + \" \"\n            content = content.strip()\n        elif isinstance(message.text, Iterator):\n            content = \" \".join(str(item) for item in message.text)\n        else:\n            content = str(message.text)\n\n        if fmt == \"txt\":\n            path.write_text(content, encoding=\"utf-8\")\n        elif fmt == \"json\":\n            path.write_text(json.dumps({\"message\": content}, indent=2), encoding=\"utf-8\")\n        elif fmt == \"markdown\":\n            path.write_text(f\"**Message:**\\n\\n{content}\", encoding=\"utf-8\")\n        else:\n            msg = f\"Unsupported Message format: {fmt}\"\n            raise ValueError(msg)\n        return f\"Message saved successfully as '{path}'\"\n\n    def _get_selected_storage_location(self) -> str:\n        \"\"\"Get the selected storage location from the SortableListInput.\"\"\"\n        if hasattr(self, \"storage_location\") and self.storage_location:\n            if isinstance(self.storage_location, list) and len(self.storage_location) > 0:\n                return self.storage_location[0].get(\"name\", \"\")\n            if isinstance(self.storage_location, dict):\n                return self.storage_location.get(\"name\", \"\")\n        return \"\"\n\n    def _get_file_format_for_location(self, location: str) -> str:\n        \"\"\"Get the appropriate file format based on storage location.\"\"\"\n        if location == \"Local\":\n            return getattr(self, \"local_format\", None) or self._get_default_format()\n        if location == \"AWS\":\n            return getattr(self, \"aws_format\", \"txt\")\n        if location == \"Google Drive\":\n            return getattr(self, \"gdrive_format\", \"txt\")\n        return self._get_default_format()\n\n    async def _save_to_local(self) -> Message:\n        \"\"\"Save file to local storage (original functionality).\"\"\"\n        file_format = self._get_file_format_for_location(\"Local\")\n\n        # Validate file format based on input type\n        allowed_formats = (\n            self.LOCAL_MESSAGE_FORMAT_CHOICES if self._get_input_type() == \"Message\" else self.LOCAL_DATA_FORMAT_CHOICES\n        )\n        if file_format not in allowed_formats:\n            msg = f\"Invalid file format '{file_format}' for {self._get_input_type()}. Allowed: {allowed_formats}\"\n            raise ValueError(msg)\n\n        # Prepare file path\n        file_path = Path(self.file_name).expanduser()\n        if not file_path.parent.exists():\n            file_path.parent.mkdir(parents=True, exist_ok=True)\n        file_path = self._adjust_file_path_with_format(file_path, file_format)\n\n        # Save the input to file based on type\n        if self._get_input_type() == \"DataFrame\":\n            confirmation = self._save_dataframe(self.input, file_path, file_format)\n        elif self._get_input_type() == \"Data\":\n            confirmation = self._save_data(self.input, file_path, file_format)\n        elif self._get_input_type() == \"Message\":\n            confirmation = await self._save_message(self.input, file_path, file_format)\n        else:\n            msg = f\"Unsupported input type: {self._get_input_type()}\"\n            raise ValueError(msg)\n\n        # Upload the saved file\n        await self._upload_file(file_path)\n\n        # Return the final file path and confirmation message\n        final_path = Path.cwd() / file_path if not file_path.is_absolute() else file_path\n        return Message(text=f\"{confirmation} at {final_path}\")\n\n    async def _save_to_aws(self) -> Message:\n        \"\"\"Save file to AWS S3 using S3 functionality.\"\"\"\n        # Validate AWS credentials\n        if not getattr(self, \"aws_access_key_id\", None):\n            msg = \"AWS Access Key ID is required for S3 storage\"\n            raise ValueError(msg)\n        if not getattr(self, \"aws_secret_access_key\", None):\n            msg = \"AWS Secret Key is required for S3 storage\"\n            raise ValueError(msg)\n        if not getattr(self, \"bucket_name\", None):\n            msg = \"S3 Bucket Name is required for S3 storage\"\n            raise ValueError(msg)\n\n        # Use S3 upload functionality\n        try:\n            import boto3\n        except ImportError as e:\n            msg = \"boto3 is not installed. Please install it using `uv pip install boto3`.\"\n            raise ImportError(msg) from e\n\n        # Create S3 client\n        client_config = {\n            \"aws_access_key_id\": self.aws_access_key_id,\n            \"aws_secret_access_key\": self.aws_secret_access_key,\n        }\n\n        if hasattr(self, \"aws_region\") and self.aws_region:\n            client_config[\"region_name\"] = self.aws_region\n\n        s3_client = boto3.client(\"s3\", **client_config)\n\n        # Extract content\n        content = self._extract_content_for_upload()\n        file_format = self._get_file_format_for_location(\"AWS\")\n\n        # Generate file path\n        file_path = f\"{self.file_name}.{file_format}\"\n        if hasattr(self, \"s3_prefix\") and self.s3_prefix:\n            file_path = f\"{self.s3_prefix.rstrip('/')}/{file_path}\"\n\n        # Create temporary file\n        import tempfile\n\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=f\".{file_format}\", delete=False) as temp_file:\n            temp_file.write(content)\n            temp_file_path = temp_file.name\n\n        try:\n            # Upload to S3\n            s3_client.upload_file(temp_file_path, self.bucket_name, file_path)\n            s3_url = f\"s3://{self.bucket_name}/{file_path}\"\n            return Message(text=f\"File successfully uploaded to {s3_url}\")\n        finally:\n            # Clean up temp file\n            if Path(temp_file_path).exists():\n                Path(temp_file_path).unlink()\n\n    async def _save_to_google_drive(self) -> Message:\n        \"\"\"Save file to Google Drive using Google Drive functionality.\"\"\"\n        # Validate Google Drive credentials\n        if not getattr(self, \"service_account_key\", None):\n            msg = \"GCP Credentials Secret Key is required for Google Drive storage\"\n            raise ValueError(msg)\n        if not getattr(self, \"folder_id\", None):\n            msg = \"Google Drive Folder ID is required for Google Drive storage\"\n            raise ValueError(msg)\n\n        # Use Google Drive upload functionality\n        try:\n            import json\n            import tempfile\n\n            from google.oauth2 import service_account\n            from googleapiclient.discovery import build\n            from googleapiclient.http import MediaFileUpload\n        except ImportError as e:\n            msg = \"Google API client libraries are not installed. Please install them.\"\n            raise ImportError(msg) from e\n\n        # Parse credentials\n        try:\n            credentials_dict = json.loads(self.service_account_key)\n        except json.JSONDecodeError as e:\n            msg = f\"Invalid JSON in service account key: {e!s}\"\n            raise ValueError(msg) from e\n\n        # Create Google Drive service\n        credentials = service_account.Credentials.from_service_account_info(\n            credentials_dict, scopes=[\"https://www.googleapis.com/auth/drive.file\"]\n        )\n        drive_service = build(\"drive\", \"v3\", credentials=credentials)\n\n        # Extract content and format\n        content = self._extract_content_for_upload()\n        file_format = self._get_file_format_for_location(\"Google Drive\")\n\n        # Handle special Google Drive formats\n        if file_format in [\"slides\", \"docs\"]:\n            return await self._save_to_google_apps(drive_service, content, file_format)\n\n        # Create temporary file\n        file_path = f\"{self.file_name}.{file_format}\"\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=f\".{file_format}\", delete=False) as temp_file:\n            temp_file.write(content)\n            temp_file_path = temp_file.name\n\n        try:\n            # Upload to Google Drive\n            file_metadata = {\"name\": file_path, \"parents\": [self.folder_id]}\n            media = MediaFileUpload(temp_file_path, resumable=True)\n\n            uploaded_file = drive_service.files().create(body=file_metadata, media_body=media, fields=\"id\").execute()\n\n            file_id = uploaded_file.get(\"id\")\n            file_url = f\"https://drive.google.com/file/d/{file_id}/view\"\n            return Message(text=f\"File successfully uploaded to Google Drive: {file_url}\")\n        finally:\n            # Clean up temp file\n            if Path(temp_file_path).exists():\n                Path(temp_file_path).unlink()\n\n    async def _save_to_google_apps(self, drive_service, content: str, app_type: str) -> Message:\n        \"\"\"Save content to Google Apps (Slides or Docs).\"\"\"\n        import time\n\n        if app_type == \"slides\":\n            from googleapiclient.discovery import build\n\n            slides_service = build(\"slides\", \"v1\", credentials=drive_service._http.credentials)\n\n            file_metadata = {\n                \"name\": self.file_name,\n                \"mimeType\": \"application/vnd.google-apps.presentation\",\n                \"parents\": [self.folder_id],\n            }\n\n            created_file = drive_service.files().create(body=file_metadata, fields=\"id\").execute()\n            presentation_id = created_file[\"id\"]\n\n            time.sleep(2)  # Wait for file to be available  # noqa: ASYNC251\n\n            presentation = slides_service.presentations().get(presentationId=presentation_id).execute()\n            slide_id = presentation[\"slides\"][0][\"objectId\"]\n\n            # Add content to slide\n            requests = [\n                {\n                    \"createShape\": {\n                        \"objectId\": \"TextBox_01\",\n                        \"shapeType\": \"TEXT_BOX\",\n                        \"elementProperties\": {\n                            \"pageObjectId\": slide_id,\n                            \"size\": {\n                                \"height\": {\"magnitude\": 3000000, \"unit\": \"EMU\"},\n                                \"width\": {\"magnitude\": 6000000, \"unit\": \"EMU\"},\n                            },\n                            \"transform\": {\n                                \"scaleX\": 1,\n                                \"scaleY\": 1,\n                                \"translateX\": 1000000,\n                                \"translateY\": 1000000,\n                                \"unit\": \"EMU\",\n                            },\n                        },\n                    }\n                },\n                {\"insertText\": {\"objectId\": \"TextBox_01\", \"insertionIndex\": 0, \"text\": content}},\n            ]\n\n            slides_service.presentations().batchUpdate(\n                presentationId=presentation_id, body={\"requests\": requests}\n            ).execute()\n            file_url = f\"https://docs.google.com/presentation/d/{presentation_id}/edit\"\n\n        elif app_type == \"docs\":\n            from googleapiclient.discovery import build\n\n            docs_service = build(\"docs\", \"v1\", credentials=drive_service._http.credentials)\n\n            file_metadata = {\n                \"name\": self.file_name,\n                \"mimeType\": \"application/vnd.google-apps.document\",\n                \"parents\": [self.folder_id],\n            }\n\n            created_file = drive_service.files().create(body=file_metadata, fields=\"id\").execute()\n            document_id = created_file[\"id\"]\n\n            time.sleep(2)  # Wait for file to be available  # noqa: ASYNC251\n\n            # Add content to document\n            requests = [{\"insertText\": {\"location\": {\"index\": 1}, \"text\": content}}]\n            docs_service.documents().batchUpdate(documentId=document_id, body={\"requests\": requests}).execute()\n            file_url = f\"https://docs.google.com/document/d/{document_id}/edit\"\n\n        return Message(text=f\"File successfully created in Google {app_type.title()}: {file_url}\")\n\n    def _extract_content_for_upload(self) -> str:\n        \"\"\"Extract content from input for upload to cloud services.\"\"\"\n        if self._get_input_type() == \"DataFrame\":\n            return self.input.to_csv(index=False)\n        if self._get_input_type() == \"Data\":\n            if hasattr(self.input, \"data\") and self.input.data:\n                if isinstance(self.input.data, dict):\n                    import json\n\n                    return json.dumps(self.input.data, indent=2, ensure_ascii=False)\n                return str(self.input.data)\n            return str(self.input)\n        if self._get_input_type() == \"Message\":\n            return str(self.input.text) if self.input.text else str(self.input)\n        return str(self.input)\n"},"file_name":{"_input_type":"StrInput","advanced":false,"display_name":"File Name","dynamic":false,"info":"Name file will be saved as (without extension).","list":false,"list_add_label":"Add More","load_from_db":false,"name":"file_name","placeholder":"","required":true,"show":false,"title_case":false,"tool_mode":true,"trace_as_metadata":true,"type":"str","value":""},"folder_id":{"_input_type":"StrInput","advanced":true,"display_name":"Google Drive Folder ID","dynamic":false,"info":"The Google Drive folder ID where the file will be uploaded. The folder must be shared with the service account email.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"folder_id","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"gdrive_format":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"File Format","dynamic":false,"external_options":{},"info":"Select the file format for Google Drive storage.","name":"gdrive_format","options":["txt","json","csv","xlsx","slides","docs","jpg","mp3"],"options_metadata":[],"placeholder":"","required":false,"show":false,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"txt"},"input":{"_input_type":"HandleInput","advanced":false,"display_name":"File Content","dynamic":true,"info":"The input to save.","input_types":["Data","DataFrame","Message"],"list":false,"list_add_label":"Add More","name":"input","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"local_format":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"File Format","dynamic":false,"external_options":{},"info":"Select the file format for local storage.","name":"local_format","options":["csv","excel","json","markdown","txt"],"options_metadata":[],"placeholder":"","required":false,"show":false,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"json"},"s3_prefix":{"_input_type":"StrInput","advanced":true,"display_name":"S3 Prefix","dynamic":false,"info":"Prefix for all files in S3.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"s3_prefix","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"service_account_key":{"_input_type":"SecretStrInput","advanced":true,"display_name":"GCP Credentials Secret Key","dynamic":false,"info":"Your Google Cloud Platform service account JSON key as a secret string (complete JSON content).","input_types":[],"load_from_db":true,"name":"service_account_key","password":true,"placeholder":"","required":false,"show":false,"title_case":false,"type":"str","value":""},"storage_location":{"_input_type":"SortableListInput","advanced":false,"display_name":"Storage Location","dynamic":false,"info":"Choose where to save the file.","limit":1,"name":"storage_location","options":[{"icon":"hard-drive","name":"Local"},{"icon":"Amazon","name":"AWS"},{"icon":"google","name":"Google Drive"}],"placeholder":"Select Location","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":""}},"tool_mode":false},"URLComponent":{"base_classes":["DataFrame","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Fetch content from one or more web pages, following links recursively.","display_name":"URL","documentation":"https://docs.langflow.org/components-data#url","edited":false,"field_order":["urls","max_depth","prevent_outside","use_async","format","timeout","headers","filter_text_html","continue_on_failure","check_response_status","autoset_encoding"],"frozen":false,"icon":"layout-template","legacy":false,"metadata":{"code_hash":"cdb7d379306e","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"bs4","version":"4.12.3"},{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.data.url.URLComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Extracted Pages","group_outputs":false,"method":"fetch_content","name":"page_results","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Raw Content","group_outputs":false,"method":"fetch_content_as_message","name":"raw_results","selected":"Message","tool_mode":false,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","autoset_encoding":{"_input_type":"BoolInput","advanced":true,"display_name":"Autoset Encoding","dynamic":false,"info":"If enabled, automatically sets the encoding of the request.","list":false,"list_add_label":"Add More","name":"autoset_encoding","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"check_response_status":{"_input_type":"BoolInput","advanced":true,"display_name":"Check Response Status","dynamic":false,"info":"If enabled, checks the response status of the request.","list":false,"list_add_label":"Add More","name":"check_response_status","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import importlib\nimport re\n\nimport requests\nfrom bs4 import BeautifulSoup\nfrom langchain_community.document_loaders import RecursiveUrlLoader\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.helpers.data import safe_convert\nfrom lfx.io import BoolInput, DropdownInput, IntInput, MessageTextInput, Output, SliderInput, TableInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.message import Message\nfrom lfx.utils.request_utils import get_user_agent\n\n# Constants\nDEFAULT_TIMEOUT = 30\nDEFAULT_MAX_DEPTH = 1\nDEFAULT_FORMAT = \"Text\"\n\n\nURL_REGEX = re.compile(\n    r\"^(https?:\\/\\/)?\" r\"(www\\.)?\" r\"([a-zA-Z0-9.-]+)\" r\"(\\.[a-zA-Z]{2,})?\" r\"(:\\d+)?\" r\"(\\/[^\\s]*)?$\",\n    re.IGNORECASE,\n)\n\nUSER_AGENT = None\n# Check if langflow is installed using importlib.util.find_spec(name))\nif importlib.util.find_spec(\"langflow\"):\n    langflow_installed = True\n    USER_AGENT = get_user_agent()\nelse:\n    langflow_installed = False\n    USER_AGENT = \"lfx\"\n\n\nclass URLComponent(Component):\n    \"\"\"A component that loads and parses content from web pages recursively.\n\n    This component allows fetching content from one or more URLs, with options to:\n    - Control crawl depth\n    - Prevent crawling outside the root domain\n    - Use async loading for better performance\n    - Extract either raw HTML or clean text\n    - Configure request headers and timeouts\n    \"\"\"\n\n    display_name = \"URL\"\n    description = \"Fetch content from one or more web pages, following links recursively.\"\n    documentation: str = \"https://docs.langflow.org/components-data#url\"\n    icon = \"layout-template\"\n    name = \"URLComponent\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"urls\",\n            display_name=\"URLs\",\n            info=\"Enter one or more URLs to crawl recursively, by clicking the '+' button.\",\n            is_list=True,\n            tool_mode=True,\n            placeholder=\"Enter a URL...\",\n            list_add_label=\"Add URL\",\n            input_types=[],\n        ),\n        SliderInput(\n            name=\"max_depth\",\n            display_name=\"Depth\",\n            info=(\n                \"Controls how many 'clicks' away from the initial page the crawler will go:\\n\"\n                \"- depth 1: only the initial page\\n\"\n                \"- depth 2: initial page + all pages linked directly from it\\n\"\n                \"- depth 3: initial page + direct links + links found on those direct link pages\\n\"\n                \"Note: This is about link traversal, not URL path depth.\"\n            ),\n            value=DEFAULT_MAX_DEPTH,\n            range_spec=RangeSpec(min=1, max=5, step=1),\n            required=False,\n            min_label=\" \",\n            max_label=\" \",\n            min_label_icon=\"None\",\n            max_label_icon=\"None\",\n            # slider_input=True\n        ),\n        BoolInput(\n            name=\"prevent_outside\",\n            display_name=\"Prevent Outside\",\n            info=(\n                \"If enabled, only crawls URLs within the same domain as the root URL. \"\n                \"This helps prevent the crawler from going to external websites.\"\n            ),\n            value=True,\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"use_async\",\n            display_name=\"Use Async\",\n            info=(\n                \"If enabled, uses asynchronous loading which can be significantly faster \"\n                \"but might use more system resources.\"\n            ),\n            value=True,\n            required=False,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"format\",\n            display_name=\"Output Format\",\n            info=\"Output Format. Use 'Text' to extract the text from the HTML or 'HTML' for the raw HTML content.\",\n            options=[\"Text\", \"HTML\"],\n            value=DEFAULT_FORMAT,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"Timeout for the request in seconds.\",\n            value=DEFAULT_TIMEOUT,\n            required=False,\n            advanced=True,\n        ),\n        TableInput(\n            name=\"headers\",\n            display_name=\"Headers\",\n            info=\"The headers to send with the request\",\n            table_schema=[\n                {\n                    \"name\": \"key\",\n                    \"display_name\": \"Header\",\n                    \"type\": \"str\",\n                    \"description\": \"Header name\",\n                },\n                {\n                    \"name\": \"value\",\n                    \"display_name\": \"Value\",\n                    \"type\": \"str\",\n                    \"description\": \"Header value\",\n                },\n            ],\n            value=[{\"key\": \"User-Agent\", \"value\": USER_AGENT}],\n            advanced=True,\n            input_types=[\"DataFrame\"],\n        ),\n        BoolInput(\n            name=\"filter_text_html\",\n            display_name=\"Filter Text/HTML\",\n            info=\"If enabled, filters out text/css content type from the results.\",\n            value=True,\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"continue_on_failure\",\n            display_name=\"Continue on Failure\",\n            info=\"If enabled, continues crawling even if some requests fail.\",\n            value=True,\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"check_response_status\",\n            display_name=\"Check Response Status\",\n            info=\"If enabled, checks the response status of the request.\",\n            value=False,\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"autoset_encoding\",\n            display_name=\"Autoset Encoding\",\n            info=\"If enabled, automatically sets the encoding of the request.\",\n            value=True,\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Extracted Pages\", name=\"page_results\", method=\"fetch_content\"),\n        Output(display_name=\"Raw Content\", name=\"raw_results\", method=\"fetch_content_as_message\", tool_mode=False),\n    ]\n\n    @staticmethod\n    def validate_url(url: str) -> bool:\n        \"\"\"Validates if the given string matches URL pattern.\n\n        Args:\n            url: The URL string to validate\n\n        Returns:\n            bool: True if the URL is valid, False otherwise\n        \"\"\"\n        return bool(URL_REGEX.match(url))\n\n    def ensure_url(self, url: str) -> str:\n        \"\"\"Ensures the given string is a valid URL.\n\n        Args:\n            url: The URL string to validate and normalize\n\n        Returns:\n            str: The normalized URL\n\n        Raises:\n            ValueError: If the URL is invalid\n        \"\"\"\n        url = url.strip()\n        if not url.startswith((\"http://\", \"https://\")):\n            url = \"https://\" + url\n\n        if not self.validate_url(url):\n            msg = f\"Invalid URL: {url}\"\n            raise ValueError(msg)\n\n        return url\n\n    def _create_loader(self, url: str) -> RecursiveUrlLoader:\n        \"\"\"Creates a RecursiveUrlLoader instance with the configured settings.\n\n        Args:\n            url: The URL to load\n\n        Returns:\n            RecursiveUrlLoader: Configured loader instance\n        \"\"\"\n        headers_dict = {header[\"key\"]: header[\"value\"] for header in self.headers if header[\"value\"] is not None}\n        extractor = (lambda x: x) if self.format == \"HTML\" else (lambda x: BeautifulSoup(x, \"lxml\").get_text())\n\n        return RecursiveUrlLoader(\n            url=url,\n            max_depth=self.max_depth,\n            prevent_outside=self.prevent_outside,\n            use_async=self.use_async,\n            extractor=extractor,\n            timeout=self.timeout,\n            headers=headers_dict,\n            check_response_status=self.check_response_status,\n            continue_on_failure=self.continue_on_failure,\n            base_url=url,  # Add base_url to ensure consistent domain crawling\n            autoset_encoding=self.autoset_encoding,  # Enable automatic encoding detection\n            exclude_dirs=[],  # Allow customization of excluded directories\n            link_regex=None,  # Allow customization of link filtering\n        )\n\n    def fetch_url_contents(self) -> list[dict]:\n        \"\"\"Load documents from the configured URLs.\n\n        Returns:\n            List[Data]: List of Data objects containing the fetched content\n\n        Raises:\n            ValueError: If no valid URLs are provided or if there's an error loading documents\n        \"\"\"\n        try:\n            urls = list({self.ensure_url(url) for url in self.urls if url.strip()})\n            logger.debug(f\"URLs: {urls}\")\n            if not urls:\n                msg = \"No valid URLs provided.\"\n                raise ValueError(msg)\n\n            all_docs = []\n            for url in urls:\n                logger.debug(f\"Loading documents from {url}\")\n\n                try:\n                    loader = self._create_loader(url)\n                    docs = loader.load()\n\n                    if not docs:\n                        logger.warning(f\"No documents found for {url}\")\n                        continue\n\n                    logger.debug(f\"Found {len(docs)} documents from {url}\")\n                    all_docs.extend(docs)\n\n                except requests.exceptions.RequestException as e:\n                    logger.exception(f\"Error loading documents from {url}: {e}\")\n                    continue\n\n            if not all_docs:\n                msg = \"No documents were successfully loaded from any URL\"\n                raise ValueError(msg)\n\n            # data = [Data(text=doc.page_content, **doc.metadata) for doc in all_docs]\n            data = [\n                {\n                    \"text\": safe_convert(doc.page_content, clean_data=True),\n                    \"url\": doc.metadata.get(\"source\", \"\"),\n                    \"title\": doc.metadata.get(\"title\", \"\"),\n                    \"description\": doc.metadata.get(\"description\", \"\"),\n                    \"content_type\": doc.metadata.get(\"content_type\", \"\"),\n                    \"language\": doc.metadata.get(\"language\", \"\"),\n                }\n                for doc in all_docs\n            ]\n        except Exception as e:\n            error_msg = e.message if hasattr(e, \"message\") else e\n            msg = f\"Error loading documents: {error_msg!s}\"\n            logger.exception(msg)\n            raise ValueError(msg) from e\n        return data\n\n    def fetch_content(self) -> DataFrame:\n        \"\"\"Convert the documents to a DataFrame.\"\"\"\n        return DataFrame(data=self.fetch_url_contents())\n\n    def fetch_content_as_message(self) -> Message:\n        \"\"\"Convert the documents to a Message.\"\"\"\n        url_contents = self.fetch_url_contents()\n        return Message(text=\"\\n\\n\".join([x[\"text\"] for x in url_contents]), data={\"data\": url_contents})\n"},"continue_on_failure":{"_input_type":"BoolInput","advanced":true,"display_name":"Continue on Failure","dynamic":false,"info":"If enabled, continues crawling even if some requests fail.","list":false,"list_add_label":"Add More","name":"continue_on_failure","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"filter_text_html":{"_input_type":"BoolInput","advanced":true,"display_name":"Filter Text/HTML","dynamic":false,"info":"If enabled, filters out text/css content type from the results.","list":false,"list_add_label":"Add More","name":"filter_text_html","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"format":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Output Format","dynamic":false,"external_options":{},"info":"Output Format. Use 'Text' to extract the text from the HTML or 'HTML' for the raw HTML content.","name":"format","options":["Text","HTML"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Text"},"headers":{"_input_type":"TableInput","advanced":true,"display_name":"Headers","dynamic":false,"info":"The headers to send with the request","input_types":["DataFrame"],"is_list":true,"list_add_label":"Add More","name":"headers","placeholder":"","required":false,"show":true,"table_icon":"Table","table_schema":[{"description":"Header name","display_name":"Header","name":"key","type":"str"},{"description":"Header value","display_name":"Value","name":"value","type":"str"}],"title_case":false,"tool_mode":false,"trace_as_metadata":true,"trigger_icon":"Table","trigger_text":"Open table","type":"table","value":[{"key":"User-Agent","value":null}]},"max_depth":{"_input_type":"SliderInput","advanced":false,"display_name":"Depth","dynamic":false,"info":"Controls how many 'clicks' away from the initial page the crawler will go:\n- depth 1: only the initial page\n- depth 2: initial page + all pages linked directly from it\n- depth 3: initial page + direct links + links found on those direct link pages\nNote: This is about link traversal, not URL path depth.","max_label":" ","max_label_icon":"None","min_label":" ","min_label_icon":"None","name":"max_depth","placeholder":"","range_spec":{"max":5.0,"min":1.0,"step":1.0,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":1},"prevent_outside":{"_input_type":"BoolInput","advanced":true,"display_name":"Prevent Outside","dynamic":false,"info":"If enabled, only crawls URLs within the same domain as the root URL. This helps prevent the crawler from going to external websites.","list":false,"list_add_label":"Add More","name":"prevent_outside","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"timeout":{"_input_type":"IntInput","advanced":true,"display_name":"Timeout","dynamic":false,"info":"Timeout for the request in seconds.","list":false,"list_add_label":"Add More","name":"timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":30},"urls":{"_input_type":"MessageTextInput","advanced":false,"display_name":"URLs","dynamic":false,"info":"Enter one or more URLs to crawl recursively, by clicking the '+' button.","input_types":[],"list":true,"list_add_label":"Add URL","load_from_db":false,"name":"urls","placeholder":"Enter a URL...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"use_async":{"_input_type":"BoolInput","advanced":true,"display_name":"Use Async","dynamic":false,"info":"If enabled, uses asynchronous loading which can be significantly faster but might use more system resources.","list":false,"list_add_label":"Add More","name":"use_async","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false},"UnifiedWebSearch":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Search the web, news, or RSS feeds.","display_name":"Web Search","documentation":"https://docs.langflow.org/components-data#web-search","edited":false,"field_order":["search_mode","query","hl","gl","ceid","topic","location","timeout"],"frozen":false,"icon":"search","legacy":false,"metadata":{"code_hash":"e3c482a7ed88","dependencies":{"dependencies":[{"name":"pandas","version":"2.2.3"},{"name":"requests","version":"2.32.5"},{"name":"bs4","version":"4.12.3"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.data.web_search.WebSearchComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Results","group_outputs":false,"method":"perform_search","name":"results","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","ceid":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Country:Language (ceid)","dynamic":false,"info":"e.g. US:en, FR:fr. Default: US:en.","input_types":[],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"ceid","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"US:en"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"\"\"\"Unified Web Search Component.\n\nThis component consolidates Web Search, News Search, and RSS Reader into a single\ncomponent with tabs for different search modes.\n\"\"\"\n\nimport re\nfrom typing import Any\nfrom urllib.parse import parse_qs, quote_plus, unquote, urlparse\n\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\n\nfrom lfx.custom import Component\nfrom lfx.io import IntInput, MessageTextInput, Output, TabInput\nfrom lfx.schema import DataFrame\nfrom lfx.utils.request_utils import get_user_agent\n\n\nclass WebSearchComponent(Component):\n    display_name = \"Web Search\"\n    description = \"Search the web, news, or RSS feeds.\"\n    documentation: str = \"https://docs.langflow.org/components-data#web-search\"\n    icon = \"search\"\n    name = \"UnifiedWebSearch\"\n\n    inputs = [\n        TabInput(\n            name=\"search_mode\",\n            display_name=\"Search Mode\",\n            options=[\"Web\", \"News\", \"RSS\"],\n            info=\"Choose search mode: Web (DuckDuckGo), News (Google News), or RSS (Feed Reader)\",\n            value=\"Web\",\n            real_time_refresh=True,\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"Search Query\",\n            info=\"Search keywords for news articles.\",\n            tool_mode=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"hl\",\n            display_name=\"Language (hl)\",\n            info=\"Language code, e.g. en-US, fr, de. Default: en-US.\",\n            tool_mode=False,\n            input_types=[],\n            required=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"gl\",\n            display_name=\"Country (gl)\",\n            info=\"Country code, e.g. US, FR, DE. Default: US.\",\n            tool_mode=False,\n            input_types=[],\n            required=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"ceid\",\n            display_name=\"Country:Language (ceid)\",\n            info=\"e.g. US:en, FR:fr. Default: US:en.\",\n            tool_mode=False,\n            value=\"US:en\",\n            input_types=[],\n            required=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"topic\",\n            display_name=\"Topic\",\n            info=\"One of: WORLD, NATION, BUSINESS, TECHNOLOGY, ENTERTAINMENT, SCIENCE, SPORTS, HEALTH.\",\n            tool_mode=False,\n            input_types=[],\n            required=False,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"location\",\n            display_name=\"Location (Geo)\",\n            info=\"City, state, or country for location-based news. Leave blank for keyword search.\",\n            tool_mode=False,\n            input_types=[],\n            required=False,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"Timeout for the request in seconds.\",\n            value=5,\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [Output(name=\"results\", display_name=\"Results\", method=\"perform_search\")]\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        \"\"\"Update input visibility based on search mode.\"\"\"\n        if field_name == \"search_mode\":\n            # Show/hide inputs based on search mode\n            is_news = field_value == \"News\"\n            is_rss = field_value == \"RSS\"\n\n            # Update query field info based on mode\n            if is_rss:\n                build_config[\"query\"][\"info\"] = \"RSS feed URL to parse\"\n                build_config[\"query\"][\"display_name\"] = \"RSS Feed URL\"\n            elif is_news:\n                build_config[\"query\"][\"info\"] = \"Search keywords for news articles.\"\n                build_config[\"query\"][\"display_name\"] = \"Search Query\"\n            else:  # Web\n                build_config[\"query\"][\"info\"] = \"Keywords to search for\"\n                build_config[\"query\"][\"display_name\"] = \"Search Query\"\n\n            # Keep news-specific fields as advanced (matching original News Search component)\n            # They remain advanced=True in all modes, just like in the original component\n\n        return build_config\n\n    def validate_url(self, string: str) -> bool:\n        \"\"\"Validate URL format.\"\"\"\n        url_regex = re.compile(\n            r\"^(https?:\\/\\/)?\" r\"(www\\.)?\" r\"([a-zA-Z0-9.-]+)\" r\"(\\.[a-zA-Z]{2,})?\" r\"(:\\d+)?\" r\"(\\/[^\\s]*)?$\",\n            re.IGNORECASE,\n        )\n        return bool(url_regex.match(string))\n\n    def ensure_url(self, url: str) -> str:\n        \"\"\"Ensure URL has proper protocol.\"\"\"\n        if not url.startswith((\"http://\", \"https://\")):\n            url = \"https://\" + url\n        if not self.validate_url(url):\n            msg = f\"Invalid URL: {url}\"\n            raise ValueError(msg)\n        return url\n\n    def _sanitize_query(self, query: str) -> str:\n        \"\"\"Sanitize search query.\"\"\"\n        return re.sub(r'[<>\"\\']', \"\", query.strip())\n\n    def clean_html(self, html_string: str) -> str:\n        \"\"\"Remove HTML tags from text.\"\"\"\n        return BeautifulSoup(html_string, \"html.parser\").get_text(separator=\" \", strip=True)\n\n    def perform_web_search(self) -> DataFrame:\n        \"\"\"Perform DuckDuckGo web search.\"\"\"\n        query = self._sanitize_query(self.query)\n        if not query:\n            msg = \"Empty search query\"\n            raise ValueError(msg)\n\n        headers = {\"User-Agent\": get_user_agent()}\n        params = {\"q\": query, \"kl\": \"us-en\"}\n        url = \"https://html.duckduckgo.com/html/\"\n\n        try:\n            response = requests.get(url, params=params, headers=headers, timeout=self.timeout)\n            response.raise_for_status()\n        except requests.RequestException as e:\n            self.status = f\"Failed request: {e!s}\"\n            return DataFrame(pd.DataFrame([{\"title\": \"Error\", \"link\": \"\", \"snippet\": str(e), \"content\": \"\"}]))\n\n        if not response.text or \"text/html\" not in response.headers.get(\"content-type\", \"\").lower():\n            self.status = \"No results found\"\n            return DataFrame(\n                pd.DataFrame([{\"title\": \"Error\", \"link\": \"\", \"snippet\": \"No results found\", \"content\": \"\"}])\n            )\n\n        soup = BeautifulSoup(response.text, \"html.parser\")\n        results = []\n\n        for result in soup.select(\"div.result\"):\n            title_tag = result.select_one(\"a.result__a\")\n            snippet_tag = result.select_one(\"a.result__snippet\")\n            if title_tag:\n                raw_link = title_tag.get(\"href\", \"\")\n                parsed = urlparse(raw_link)\n                uddg = parse_qs(parsed.query).get(\"uddg\", [\"\"])[0]\n                decoded_link = unquote(uddg) if uddg else raw_link\n\n                try:\n                    final_url = self.ensure_url(decoded_link)\n                    page = requests.get(final_url, headers=headers, timeout=self.timeout)\n                    page.raise_for_status()\n                    content = BeautifulSoup(page.text, \"lxml\").get_text(separator=\" \", strip=True)\n                except requests.RequestException as e:\n                    final_url = decoded_link\n                    content = f\"(Failed to fetch: {e!s}\"\n\n                results.append(\n                    {\n                        \"title\": title_tag.get_text(strip=True),\n                        \"link\": final_url,\n                        \"snippet\": snippet_tag.get_text(strip=True) if snippet_tag else \"\",\n                        \"content\": content,\n                    }\n                )\n\n        return DataFrame(pd.DataFrame(results))\n\n    def perform_news_search(self) -> DataFrame:\n        \"\"\"Perform Google News search.\"\"\"\n        query = getattr(self, \"query\", \"\")\n        hl = getattr(self, \"hl\", \"en-US\") or \"en-US\"\n        gl = getattr(self, \"gl\", \"US\") or \"US\"\n        topic = getattr(self, \"topic\", None)\n        location = getattr(self, \"location\", None)\n\n        ceid = f\"{gl}:{hl.split('-')[0]}\"\n\n        # Build RSS URL based on parameters\n        if topic:\n            # Topic-based feed\n            base_url = f\"https://news.google.com/rss/headlines/section/topic/{quote_plus(topic.upper())}\"\n            params = f\"?hl={hl}&gl={gl}&ceid={ceid}\"\n            rss_url = base_url + params\n        elif location:\n            # Location-based feed\n            base_url = f\"https://news.google.com/rss/headlines/section/geo/{quote_plus(location)}\"\n            params = f\"?hl={hl}&gl={gl}&ceid={ceid}\"\n            rss_url = base_url + params\n        elif query:\n            # Keyword search feed\n            base_url = \"https://news.google.com/rss/search?q=\"\n            query_encoded = quote_plus(query)\n            params = f\"&hl={hl}&gl={gl}&ceid={ceid}\"\n            rss_url = f\"{base_url}{query_encoded}{params}\"\n        else:\n            self.status = \"No search query, topic, or location provided.\"\n            return DataFrame(\n                pd.DataFrame(\n                    [{\"title\": \"Error\", \"link\": \"\", \"published\": \"\", \"summary\": \"No search parameters provided\"}]\n                )\n            )\n\n        try:\n            response = requests.get(rss_url, timeout=self.timeout)\n            response.raise_for_status()\n            soup = BeautifulSoup(response.content, \"xml\")\n            items = soup.find_all(\"item\")\n        except requests.RequestException as e:\n            self.status = f\"Failed to fetch news: {e}\"\n            return DataFrame(pd.DataFrame([{\"title\": \"Error\", \"link\": \"\", \"published\": \"\", \"summary\": str(e)}]))\n\n        if not items:\n            self.status = \"No news articles found.\"\n            return DataFrame(pd.DataFrame([{\"title\": \"No articles found\", \"link\": \"\", \"published\": \"\", \"summary\": \"\"}]))\n\n        articles = []\n        for item in items:\n            try:\n                title = self.clean_html(item.title.text if item.title else \"\")\n                link = item.link.text if item.link else \"\"\n                published = item.pubDate.text if item.pubDate else \"\"\n                summary = self.clean_html(item.description.text if item.description else \"\")\n                articles.append({\"title\": title, \"link\": link, \"published\": published, \"summary\": summary})\n            except (AttributeError, ValueError, TypeError) as e:\n                self.log(f\"Error parsing article: {e!s}\")\n                continue\n\n        return DataFrame(pd.DataFrame(articles))\n\n    def perform_rss_read(self) -> DataFrame:\n        \"\"\"Read RSS feed.\"\"\"\n        rss_url = getattr(self, \"query\", \"\")\n        if not rss_url:\n            return DataFrame(\n                pd.DataFrame([{\"title\": \"Error\", \"link\": \"\", \"published\": \"\", \"summary\": \"No RSS URL provided\"}])\n            )\n\n        try:\n            response = requests.get(rss_url, timeout=self.timeout)\n            response.raise_for_status()\n            if not response.content.strip():\n                msg = \"Empty response received\"\n                raise ValueError(msg)\n\n            # Validate XML\n            try:\n                BeautifulSoup(response.content, \"xml\")\n            except Exception as e:\n                msg = f\"Invalid XML response: {e}\"\n                raise ValueError(msg) from e\n\n            soup = BeautifulSoup(response.content, \"xml\")\n            items = soup.find_all(\"item\")\n        except (requests.RequestException, ValueError) as e:\n            self.status = f\"Failed to fetch RSS: {e}\"\n            return DataFrame(pd.DataFrame([{\"title\": \"Error\", \"link\": \"\", \"published\": \"\", \"summary\": str(e)}]))\n\n        articles = [\n            {\n                \"title\": item.title.text if item.title else \"\",\n                \"link\": item.link.text if item.link else \"\",\n                \"published\": item.pubDate.text if item.pubDate else \"\",\n                \"summary\": item.description.text if item.description else \"\",\n            }\n            for item in items\n        ]\n\n        # Ensure DataFrame has correct columns even if empty\n        df_articles = pd.DataFrame(articles, columns=[\"title\", \"link\", \"published\", \"summary\"])\n        self.log(f\"Fetched {len(df_articles)} articles.\")\n        return DataFrame(df_articles)\n\n    def perform_search(self) -> DataFrame:\n        \"\"\"Main search method that routes to appropriate search function based on mode.\"\"\"\n        search_mode = getattr(self, \"search_mode\", \"Web\")\n\n        if search_mode == \"Web\":\n            return self.perform_web_search()\n        if search_mode == \"News\":\n            return self.perform_news_search()\n        if search_mode == \"RSS\":\n            return self.perform_rss_read()\n        # Fallback to web search\n        return self.perform_web_search()\n"},"gl":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Country (gl)","dynamic":false,"info":"Country code, e.g. US, FR, DE. Default: US.","input_types":[],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"gl","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"hl":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Language (hl)","dynamic":false,"info":"Language code, e.g. en-US, fr, de. Default: en-US.","input_types":[],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"hl","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"location":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Location (Geo)","dynamic":false,"info":"City, state, or country for location-based news. Leave blank for keyword search.","input_types":[],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"location","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"query":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Search keywords for news articles.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"query","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"search_mode":{"_input_type":"TabInput","advanced":false,"display_name":"Search Mode","dynamic":false,"info":"Choose search mode: Web (DuckDuckGo), News (Google News), or RSS (Feed Reader)","name":"search_mode","options":["Web","News","RSS"],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_metadata":true,"type":"tab","value":"Web"},"timeout":{"_input_type":"IntInput","advanced":true,"display_name":"Timeout","dynamic":false,"info":"Timeout for the request in seconds.","list":false,"list_add_label":"Add More","name":"timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5},"topic":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Topic","dynamic":false,"info":"One of: WORLD, NATION, BUSINESS, TECHNOLOGY, ENTERTAINMENT, SCIENCE, SPORTS, HEALTH.","input_types":[],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"topic","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"Webhook":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"display_name":"Webhook","documentation":"https://docs.langflow.org/components-data#webhook","edited":false,"field_order":["data","curl","endpoint"],"frozen":false,"icon":"webhook","legacy":false,"metadata":{"code_hash":"8b68dd5d22d4","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.data.webhook.WebhookComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"build_data","name":"output_data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import MultilineInput, Output\nfrom lfx.schema.data import Data\n\n\nclass WebhookComponent(Component):\n    display_name = \"Webhook\"\n    documentation: str = \"https://docs.langflow.org/components-data#webhook\"\n    name = \"Webhook\"\n    icon = \"webhook\"\n\n    inputs = [\n        MultilineInput(\n            name=\"data\",\n            display_name=\"Payload\",\n            info=\"Receives a payload from external systems via HTTP POST.\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"curl\",\n            display_name=\"cURL\",\n            value=\"CURL_WEBHOOK\",\n            advanced=True,\n            input_types=[],\n        ),\n        MultilineInput(\n            name=\"endpoint\",\n            display_name=\"Endpoint\",\n            value=\"BACKEND_URL\",\n            advanced=False,\n            copy_field=True,\n            input_types=[],\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Data\", name=\"output_data\", method=\"build_data\"),\n    ]\n\n    def build_data(self) -> Data:\n        message: str | Data = \"\"\n        if not self.data:\n            self.status = \"No data provided.\"\n            return Data(data={})\n        try:\n            my_data = self.data.replace('\"\\n\"', '\"\\\\n\"')\n            body = json.loads(my_data or \"{}\")\n        except json.JSONDecodeError:\n            body = {\"payload\": self.data}\n            message = f\"Invalid JSON payload. Please check the format.\\n\\n{self.data}\"\n        data = Data(data=body)\n        if not message:\n            message = data\n        self.status = message\n        return data\n"},"curl":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"cURL","dynamic":false,"info":"","input_types":[],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"curl","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"CURL_WEBHOOK"},"data":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"Payload","dynamic":false,"info":"Receives a payload from external systems via HTTP POST.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"data","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"endpoint":{"_input_type":"MultilineInput","advanced":false,"copy_field":true,"display_name":"Endpoint","dynamic":false,"info":"","input_types":[],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"endpoint","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"BACKEND_URL"}},"tool_mode":false}}],["datastax",{"AssistantsCreateAssistant":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Creates an Assistant and returns it's id","display_name":"Create Assistant","documentation":"","edited":false,"field_order":["assistant_name","instructions","model","env_set"],"frozen":false,"icon":"AstraDB","legacy":false,"metadata":{"code_hash":"549d3e5cc2ea","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.datastax.create_assistant.AssistantsCreateAssistant"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Assistant ID","group_outputs":false,"method":"process_inputs","name":"assistant_id","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","assistant_name":{"_input_type":"StrInput","advanced":false,"display_name":"Assistant Name","dynamic":false,"info":"Name for the assistant being created","list":false,"list_add_label":"Add More","load_from_db":false,"name":"assistant_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.astra_assistants.util import get_patched_openai_client\nfrom lfx.custom.custom_component.component_with_cache import ComponentWithCache\nfrom lfx.inputs.inputs import MultilineInput, StrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.message import Message\nfrom lfx.template.field.base import Output\n\n\nclass AssistantsCreateAssistant(ComponentWithCache):\n    icon = \"AstraDB\"\n    display_name = \"Create Assistant\"\n    description = \"Creates an Assistant and returns it's id\"\n\n    inputs = [\n        StrInput(\n            name=\"assistant_name\",\n            display_name=\"Assistant Name\",\n            info=\"Name for the assistant being created\",\n        ),\n        StrInput(\n            name=\"instructions\",\n            display_name=\"Instructions\",\n            info=\"Instructions for the assistant, think of these as the system prompt.\",\n        ),\n        StrInput(\n            name=\"model\",\n            display_name=\"Model name\",\n            info=(\n                \"Model for the assistant.\\n\\n\"\n                \"Environment variables for provider credentials can be set with the Dotenv Component.\\n\\n\"\n                \"Models are supported via LiteLLM, \"\n                \"see (https://docs.litellm.ai/docs/providers) for supported model names and env vars.\"\n            ),\n            # refresh_model=True\n        ),\n        MultilineInput(\n            name=\"env_set\",\n            display_name=\"Environment Set\",\n            info=\"Dummy input to allow chaining with Dotenv Component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Assistant ID\", name=\"assistant_id\", method=\"process_inputs\"),\n    ]\n\n    def __init__(self, **kwargs) -> None:\n        super().__init__(**kwargs)\n        self.client = get_patched_openai_client(self._shared_component_cache)\n\n    def process_inputs(self) -> Message:\n        logger.info(f\"env_set is {self.env_set}\")\n        assistant = self.client.beta.assistants.create(\n            name=self.assistant_name,\n            instructions=self.instructions,\n            model=self.model,\n        )\n        return Message(text=assistant.id)\n"},"env_set":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Environment Set","dynamic":false,"info":"Dummy input to allow chaining with Dotenv Component.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"env_set","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"instructions":{"_input_type":"StrInput","advanced":false,"display_name":"Instructions","dynamic":false,"info":"Instructions for the assistant, think of these as the system prompt.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"instructions","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"model":{"_input_type":"StrInput","advanced":false,"display_name":"Model name","dynamic":false,"info":"Model for the assistant.\n\nEnvironment variables for provider credentials can be set with the Dotenv Component.\n\nModels are supported via LiteLLM, see (https://docs.litellm.ai/docs/providers) for supported model names and env vars.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"model","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"AssistantsCreateThread":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Creates a thread and returns the thread id","display_name":"Create Assistant Thread","documentation":"","edited":false,"field_order":["env_set"],"frozen":false,"icon":"AstraDB","legacy":false,"metadata":{"code_hash":"ce914ea547f3","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.datastax.create_thread.AssistantsCreateThread"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Thread ID","group_outputs":false,"method":"process_inputs","name":"thread_id","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.astra_assistants.util import get_patched_openai_client\nfrom lfx.custom.custom_component.component_with_cache import ComponentWithCache\nfrom lfx.inputs.inputs import MultilineInput\nfrom lfx.schema.message import Message\nfrom lfx.template.field.base import Output\n\n\nclass AssistantsCreateThread(ComponentWithCache):\n    display_name = \"Create Assistant Thread\"\n    description = \"Creates a thread and returns the thread id\"\n    icon = \"AstraDB\"\n    inputs = [\n        MultilineInput(\n            name=\"env_set\",\n            display_name=\"Environment Set\",\n            info=\"Dummy input to allow chaining with Dotenv Component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Thread ID\", name=\"thread_id\", method=\"process_inputs\"),\n    ]\n\n    def __init__(self, **kwargs) -> None:\n        super().__init__(**kwargs)\n        self.client = get_patched_openai_client(self._shared_component_cache)\n\n    def process_inputs(self) -> Message:\n        thread = self.client.beta.threads.create()\n        thread_id = thread.id\n\n        return Message(text=thread_id)\n"},"env_set":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Environment Set","dynamic":false,"info":"Dummy input to allow chaining with Dotenv Component.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"env_set","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"AssistantsGetAssistantName":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Assistant by id","display_name":"Get Assistant name","documentation":"","edited":false,"field_order":["assistant_id","env_set"],"frozen":false,"icon":"AstraDB","legacy":false,"metadata":{"code_hash":"a00e47712af7","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.datastax.get_assistant.AssistantsGetAssistantName"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Assistant Name","group_outputs":false,"method":"process_inputs","name":"assistant_name","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","assistant_id":{"_input_type":"StrInput","advanced":false,"display_name":"Assistant ID","dynamic":false,"info":"ID of the assistant","list":false,"list_add_label":"Add More","load_from_db":false,"name":"assistant_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.astra_assistants.util import get_patched_openai_client\nfrom lfx.custom.custom_component.component_with_cache import ComponentWithCache\nfrom lfx.inputs.inputs import MultilineInput, StrInput\nfrom lfx.schema.message import Message\nfrom lfx.template.field.base import Output\n\n\nclass AssistantsGetAssistantName(ComponentWithCache):\n    display_name = \"Get Assistant name\"\n    description = \"Assistant by id\"\n    icon = \"AstraDB\"\n    inputs = [\n        StrInput(\n            name=\"assistant_id\",\n            display_name=\"Assistant ID\",\n            info=\"ID of the assistant\",\n        ),\n        MultilineInput(\n            name=\"env_set\",\n            display_name=\"Environment Set\",\n            info=\"Dummy input to allow chaining with Dotenv Component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Assistant Name\", name=\"assistant_name\", method=\"process_inputs\"),\n    ]\n\n    def __init__(self, **kwargs) -> None:\n        super().__init__(**kwargs)\n        self.client = get_patched_openai_client(self._shared_component_cache)\n\n    def process_inputs(self) -> Message:\n        assistant = self.client.beta.assistants.retrieve(\n            assistant_id=self.assistant_id,\n        )\n        return Message(text=assistant.name)\n"},"env_set":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Environment Set","dynamic":false,"info":"Dummy input to allow chaining with Dotenv Component.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"env_set","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"AssistantsListAssistants":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Returns a list of assistant id's","display_name":"List Assistants","documentation":"","edited":false,"field_order":[],"frozen":false,"icon":"AstraDB","legacy":false,"metadata":{"code_hash":"5b944e312068","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.datastax.list_assistants.AssistantsListAssistants"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Assistants","group_outputs":false,"method":"process_inputs","name":"assistants","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.astra_assistants.util import get_patched_openai_client\nfrom lfx.custom.custom_component.component_with_cache import ComponentWithCache\nfrom lfx.schema.message import Message\nfrom lfx.template.field.base import Output\n\n\nclass AssistantsListAssistants(ComponentWithCache):\n    display_name = \"List Assistants\"\n    description = \"Returns a list of assistant id's\"\n    icon = \"AstraDB\"\n    outputs = [\n        Output(display_name=\"Assistants\", name=\"assistants\", method=\"process_inputs\"),\n    ]\n\n    def __init__(self, **kwargs) -> None:\n        super().__init__(**kwargs)\n        self.client = get_patched_openai_client(self._shared_component_cache)\n\n    def process_inputs(self) -> Message:\n        assistants = self.client.beta.assistants.list().data\n        id_list = [assistant.id for assistant in assistants]\n        return Message(\n            # get text from list\n            text=\"\\n\".join(id_list)\n        )\n"}},"tool_mode":false},"AssistantsRun":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Executes an Assistant Run against a thread","display_name":"Run Assistant","documentation":"","edited":false,"field_order":["assistant_id","user_message","thread_id","env_set"],"frozen":false,"icon":"AstraDB","legacy":false,"metadata":{"code_hash":"c8f3fcff9c01","dependencies":{"dependencies":[{"name":"openai","version":"1.82.1"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.datastax.run.AssistantsRun"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Assistant Response","group_outputs":false,"method":"process_inputs","name":"assistant_response","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","assistant_id":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Assistant ID","dynamic":false,"info":"The ID of the assistant to run. \n\nCan be retrieved using the List Assistants component or created with the Create Assistant component.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"assistant_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom openai.lib.streaming import AssistantEventHandler\n\nfrom lfx.base.astra_assistants.util import get_patched_openai_client\nfrom lfx.custom.custom_component.component_with_cache import ComponentWithCache\nfrom lfx.inputs.inputs import MultilineInput\nfrom lfx.schema.dotdict import dotdict\nfrom lfx.schema.message import Message\nfrom lfx.template.field.base import Output\n\n\nclass AssistantsRun(ComponentWithCache):\n    display_name = \"Run Assistant\"\n    description = \"Executes an Assistant Run against a thread\"\n    icon = \"AstraDB\"\n\n    def __init__(self, **kwargs) -> None:\n        super().__init__(**kwargs)\n        self.client = get_patched_openai_client(self._shared_component_cache)\n        self.thread_id = None\n\n    def update_build_config(\n        self,\n        build_config: dotdict,\n        field_value: Any,\n        field_name: str | None = None,\n    ) -> None:\n        if field_name == \"thread_id\":\n            if field_value is None:\n                thread = self.client.beta.threads.create()\n                self.thread_id = thread.id\n            build_config[\"thread_id\"] = field_value\n\n    inputs = [\n        MultilineInput(\n            name=\"assistant_id\",\n            display_name=\"Assistant ID\",\n            info=(\n                \"The ID of the assistant to run. \\n\\n\"\n                \"Can be retrieved using the List Assistants component or created with the Create Assistant component.\"\n            ),\n        ),\n        MultilineInput(\n            name=\"user_message\",\n            display_name=\"User Message\",\n            info=\"User message to pass to the run.\",\n        ),\n        MultilineInput(\n            name=\"thread_id\",\n            display_name=\"Thread ID\",\n            required=False,\n            info=\"Thread ID to use with the run. If not provided, a new thread will be created.\",\n        ),\n        MultilineInput(\n            name=\"env_set\",\n            display_name=\"Environment Set\",\n            info=\"Dummy input to allow chaining with Dotenv Component.\",\n        ),\n    ]\n\n    outputs = [Output(display_name=\"Assistant Response\", name=\"assistant_response\", method=\"process_inputs\")]\n\n    def process_inputs(self) -> Message:\n        text = \"\"\n\n        if self.thread_id is None:\n            thread = self.client.beta.threads.create()\n            self.thread_id = thread.id\n\n        # add the user message\n        self.client.beta.threads.messages.create(thread_id=self.thread_id, role=\"user\", content=self.user_message)\n\n        class EventHandler(AssistantEventHandler):\n            def __init__(self) -> None:\n                super().__init__()\n\n            def on_exception(self, exception: Exception) -> None:\n                raise exception\n\n        event_handler = EventHandler()\n        with self.client.beta.threads.runs.create_and_stream(\n            thread_id=self.thread_id,\n            assistant_id=self.assistant_id,\n            event_handler=event_handler,\n        ) as stream:\n            for part in stream.text_deltas:\n                text += part\n        return Message(text=text)\n"},"env_set":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Environment Set","dynamic":false,"info":"Dummy input to allow chaining with Dotenv Component.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"env_set","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"thread_id":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Thread ID","dynamic":false,"info":"Thread ID to use with the run. If not provided, a new thread will be created.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"thread_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"user_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"User Message","dynamic":false,"info":"User message to pass to the run.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"user_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"Astra Assistant Agent":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Manages Assistant Interactions","display_name":"Astra Assistant Agent","documentation":"","edited":false,"field_order":["model_name","instructions","input_tools","user_message","file","input_thread_id","input_assistant_id","env_set"],"frozen":false,"icon":"AstraDB","legacy":false,"metadata":{"code_hash":"e6f2dbb82c52","dependencies":{"dependencies":[{"name":"astra_assistants","version":"2.2.13"},{"name":"langchain_core","version":"0.3.79"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.datastax.astra_assistant_manager.AstraAssistantManager"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Assistant Response","group_outputs":false,"method":"get_assistant_response","name":"assistant_response","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool output","group_outputs":false,"hidden":true,"method":"get_tool_output","name":"tool_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Thread Id","group_outputs":false,"hidden":true,"method":"get_thread_id","name":"output_thread_id","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Assistant Id","group_outputs":false,"hidden":true,"method":"get_assistant_id","name":"output_assistant_id","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Vector Store Id","group_outputs":false,"hidden":true,"method":"get_vs_id","name":"output_vs_id","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import asyncio\nfrom asyncio import to_thread\nfrom typing import TYPE_CHECKING, Any, cast\n\nfrom astra_assistants.astra_assistants_manager import AssistantManager\nfrom langchain_core.agents import AgentFinish\n\nfrom lfx.base.agents.events import ExceptionWithMessageError, process_agent_events\nfrom lfx.base.astra_assistants.util import (\n    get_patched_openai_client,\n    litellm_model_names,\n    sync_upload,\n    wrap_base_tool_as_tool_interface,\n)\nfrom lfx.custom.custom_component.component_with_cache import ComponentWithCache\nfrom lfx.inputs.inputs import DropdownInput, FileInput, HandleInput, MultilineInput\nfrom lfx.log.logger import logger\nfrom lfx.memory import delete_message\nfrom lfx.schema.content_block import ContentBlock\nfrom lfx.schema.message import Message\nfrom lfx.template.field.base import Output\nfrom lfx.utils.constants import MESSAGE_SENDER_AI\n\nif TYPE_CHECKING:\n    from lfx.schema.log import SendMessageFunctionType\n\n\nclass AstraAssistantManager(ComponentWithCache):\n    display_name = \"Astra Assistant Agent\"\n    name = \"Astra Assistant Agent\"\n    description = \"Manages Assistant Interactions\"\n    icon = \"AstraDB\"\n\n    inputs = [\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model\",\n            advanced=False,\n            options=litellm_model_names,\n            value=\"gpt-4o-mini\",\n        ),\n        MultilineInput(\n            name=\"instructions\",\n            display_name=\"Agent Instructions\",\n            info=\"Instructions for the assistant, think of these as the system prompt.\",\n        ),\n        HandleInput(\n            name=\"input_tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            required=False,\n            info=\"These are the tools that the agent can use to help with tasks.\",\n        ),\n        # DropdownInput(\n        #    display_name=\"Tools\",\n        #    name=\"tool\",\n        #    options=tool_names,\n        # ),\n        MultilineInput(\n            name=\"user_message\", display_name=\"User Message\", info=\"User message to pass to the run.\", tool_mode=True\n        ),\n        FileInput(\n            name=\"file\",\n            display_name=\"File(s) for retrieval\",\n            list=True,\n            info=\"Files to be sent with the message.\",\n            required=False,\n            show=True,\n            file_types=[\n                \"txt\",\n                \"md\",\n                \"mdx\",\n                \"csv\",\n                \"json\",\n                \"yaml\",\n                \"yml\",\n                \"xml\",\n                \"html\",\n                \"htm\",\n                \"pdf\",\n                \"docx\",\n                \"py\",\n                \"sh\",\n                \"sql\",\n                \"js\",\n                \"ts\",\n                \"tsx\",\n                \"jpg\",\n                \"jpeg\",\n                \"png\",\n                \"bmp\",\n                \"image\",\n                \"zip\",\n                \"tar\",\n                \"tgz\",\n                \"bz2\",\n                \"gz\",\n                \"c\",\n                \"cpp\",\n                \"cs\",\n                \"css\",\n                \"go\",\n                \"java\",\n                \"php\",\n                \"rb\",\n                \"tex\",\n                \"doc\",\n                \"docx\",\n                \"ppt\",\n                \"pptx\",\n                \"xls\",\n                \"xlsx\",\n                \"jsonl\",\n            ],\n        ),\n        MultilineInput(\n            name=\"input_thread_id\",\n            display_name=\"Thread ID (optional)\",\n            info=\"ID of the thread\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"input_assistant_id\",\n            display_name=\"Assistant ID (optional)\",\n            info=\"ID of the assistant\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"env_set\",\n            display_name=\"Environment Set\",\n            info=\"Dummy input to allow chaining with Dotenv Component.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Assistant Response\", name=\"assistant_response\", method=\"get_assistant_response\"),\n        Output(display_name=\"Tool output\", name=\"tool_output\", method=\"get_tool_output\", hidden=True),\n        Output(display_name=\"Thread Id\", name=\"output_thread_id\", method=\"get_thread_id\", hidden=True),\n        Output(display_name=\"Assistant Id\", name=\"output_assistant_id\", method=\"get_assistant_id\", hidden=True),\n        Output(display_name=\"Vector Store Id\", name=\"output_vs_id\", method=\"get_vs_id\", hidden=True),\n    ]\n\n    def __init__(self, **kwargs) -> None:\n        super().__init__(**kwargs)\n        self.lock = asyncio.Lock()\n        self.initialized: bool = False\n        self._assistant_response: Message = None  # type: ignore[assignment]\n        self._tool_output: Message = None  # type: ignore[assignment]\n        self._thread_id: Message = None  # type: ignore[assignment]\n        self._assistant_id: Message = None  # type: ignore[assignment]\n        self._vs_id: Message = None  # type: ignore[assignment]\n        self.client = get_patched_openai_client(self._shared_component_cache)\n        self.input_tools: list[Any]\n\n    async def get_assistant_response(self) -> Message:\n        await self.initialize()\n        self.status = self._assistant_response\n        return self._assistant_response\n\n    async def get_vs_id(self) -> Message:\n        await self.initialize()\n        self.status = self._vs_id\n        return self._vs_id\n\n    async def get_tool_output(self) -> Message:\n        await self.initialize()\n        self.status = self._tool_output\n        return self._tool_output\n\n    async def get_thread_id(self) -> Message:\n        await self.initialize()\n        self.status = self._thread_id\n        return self._thread_id\n\n    async def get_assistant_id(self) -> Message:\n        await self.initialize()\n        self.status = self._assistant_id\n        return self._assistant_id\n\n    async def initialize(self) -> None:\n        async with self.lock:\n            if not self.initialized:\n                await self.process_inputs()\n                self.initialized = True\n\n    async def process_inputs(self) -> None:\n        await logger.ainfo(f\"env_set is {self.env_set}\")\n        await logger.ainfo(self.input_tools)\n        tools = []\n        tool_obj = None\n        if self.input_tools is None:\n            self.input_tools = []\n        for tool in self.input_tools:\n            tool_obj = wrap_base_tool_as_tool_interface(tool)\n            tools.append(tool_obj)\n\n        assistant_id = None\n        thread_id = None\n        if self.input_assistant_id:\n            assistant_id = self.input_assistant_id\n        if self.input_thread_id:\n            thread_id = self.input_thread_id\n\n        if hasattr(self, \"graph\"):\n            session_id = self.graph.session_id\n        elif hasattr(self, \"_session_id\"):\n            session_id = self._session_id\n        else:\n            session_id = None\n\n        agent_message = Message(\n            sender=MESSAGE_SENDER_AI,\n            sender_name=self.display_name or \"Astra Assistant\",\n            properties={\"icon\": \"Bot\", \"state\": \"partial\"},\n            content_blocks=[ContentBlock(title=\"Assistant Steps\", contents=[])],\n            session_id=session_id,\n        )\n\n        assistant_manager = AssistantManager(\n            instructions=self.instructions,\n            model=self.model_name,\n            name=\"managed_assistant\",\n            tools=tools,\n            client=self.client,\n            thread_id=thread_id,\n            assistant_id=assistant_id,\n        )\n\n        if self.file:\n            file = await to_thread(sync_upload, self.file, assistant_manager.client)\n            vector_store = assistant_manager.client.beta.vector_stores.create(name=\"my_vs\", file_ids=[file.id])\n            assistant_tools = assistant_manager.assistant.tools\n            assistant_tools += [{\"type\": \"file_search\"}]\n            assistant = assistant_manager.client.beta.assistants.update(\n                assistant_manager.assistant.id,\n                tools=assistant_tools,\n                tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n            )\n            assistant_manager.assistant = assistant\n\n        async def step_iterator():\n            # Initial event\n            yield {\"event\": \"on_chain_start\", \"name\": \"AstraAssistant\", \"data\": {\"input\": {\"text\": self.user_message}}}\n\n            content = self.user_message\n            result = await assistant_manager.run_thread(content=content, tool=tool_obj)\n\n            # Tool usage if present\n            if \"output\" in result and \"arguments\" in result:\n                yield {\"event\": \"on_tool_start\", \"name\": \"tool\", \"data\": {\"input\": {\"text\": str(result[\"arguments\"])}}}\n                yield {\"event\": \"on_tool_end\", \"name\": \"tool\", \"data\": {\"output\": result[\"output\"]}}\n\n            if \"file_search\" in result and result[\"file_search\"] is not None:\n                yield {\"event\": \"on_tool_start\", \"name\": \"tool\", \"data\": {\"input\": {\"text\": self.user_message}}}\n                file_search_str = \"\"\n                for chunk in result[\"file_search\"].to_dict().get(\"chunks\", []):\n                    file_search_str += f\"## Chunk ID: `{chunk['chunk_id']}`\\n\"\n                    file_search_str += f\"**Content:**\\n\\n```\\n{chunk['content']}\\n```\\n\\n\"\n                    if \"score\" in chunk:\n                        file_search_str += f\"**Score:** {chunk['score']}\\n\\n\"\n                    if \"file_id\" in chunk:\n                        file_search_str += f\"**File ID:** `{chunk['file_id']}`\\n\\n\"\n                    if \"file_name\" in chunk:\n                        file_search_str += f\"**File Name:** `{chunk['file_name']}`\\n\\n\"\n                    if \"bytes\" in chunk:\n                        file_search_str += f\"**Bytes:** {chunk['bytes']}\\n\\n\"\n                    if \"search_string\" in chunk:\n                        file_search_str += f\"**Search String:** {chunk['search_string']}\\n\\n\"\n                yield {\"event\": \"on_tool_end\", \"name\": \"tool\", \"data\": {\"output\": file_search_str}}\n\n            if \"text\" not in result:\n                msg = f\"No text in result, {result}\"\n                raise ValueError(msg)\n\n            self._assistant_response = Message(text=result[\"text\"])\n            if \"decision\" in result:\n                self._tool_output = Message(text=str(result[\"decision\"].is_complete))\n            else:\n                self._tool_output = Message(text=result[\"text\"])\n            self._thread_id = Message(text=assistant_manager.thread.id)\n            self._assistant_id = Message(text=assistant_manager.assistant.id)\n\n            # Final event - format it like AgentFinish to match the expected format\n            yield {\n                \"event\": \"on_chain_end\",\n                \"name\": \"AstraAssistant\",\n                \"data\": {\"output\": AgentFinish(return_values={\"output\": result[\"text\"]}, log=\"\")},\n            }\n\n        try:\n            if hasattr(self, \"send_message\"):\n                processed_result = await process_agent_events(\n                    step_iterator(),\n                    agent_message,\n                    cast(\"SendMessageFunctionType\", self.send_message),\n                )\n                self.status = processed_result\n        except ExceptionWithMessageError as e:\n            msg_id = e.agent_message.id\n            await delete_message(id_=msg_id)\n            await self._send_message_event(e.agent_message, category=\"remove_message\")\n            raise\n        except Exception:\n            raise\n"},"env_set":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"Environment Set","dynamic":false,"info":"Dummy input to allow chaining with Dotenv Component.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"env_set","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"file":{"_input_type":"FileInput","advanced":false,"display_name":"File(s) for retrieval","dynamic":false,"fileTypes":["txt","md","mdx","csv","json","yaml","yml","xml","html","htm","pdf","docx","py","sh","sql","js","ts","tsx","jpg","jpeg","png","bmp","image","zip","tar","tgz","bz2","gz","c","cpp","cs","css","go","java","php","rb","tex","doc","docx","ppt","pptx","xls","xlsx","jsonl"],"file_path":"","info":"Files to be sent with the message.","list":true,"list_add_label":"Add More","name":"file","placeholder":"","required":false,"show":true,"temp_file":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"file","value":""},"input_assistant_id":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"Assistant ID (optional)","dynamic":false,"info":"ID of the assistant","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"input_assistant_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"input_thread_id":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"Thread ID (optional)","dynamic":false,"info":"ID of the thread","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"input_thread_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"input_tools":{"_input_type":"HandleInput","advanced":false,"display_name":"Tools","dynamic":false,"info":"These are the tools that the agent can use to help with tasks.","input_types":["Tool"],"list":true,"list_add_label":"Add More","name":"input_tools","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"instructions":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Agent Instructions","dynamic":false,"info":"Instructions for the assistant, think of these as the system prompt.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"instructions","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model","dynamic":false,"external_options":{},"info":"","name":"model_name","options":["1024-x-1024/50-steps/bedrock/amazon.nova-canvas-v1:0","1024-x-1024/50-steps/stability.stable-diffusion-xl-v1","1024-x-1024/dall-e-2","1024-x-1024/max-steps/stability.stable-diffusion-xl-v1","256-x-256/dall-e-2","512-x-512/50-steps/stability.stable-diffusion-xl-v0","512-x-512/dall-e-2","512-x-512/max-steps/stability.stable-diffusion-xl-v0","ai21.j2-mid-v1","ai21.j2-ultra-v1","ai21.jamba-1-5-large-v1:0","ai21.jamba-1-5-mini-v1:0","ai21.jamba-instruct-v1:0","aiml/dall-e-2","aiml/dall-e-3","aiml/flux-pro","aiml/flux-pro/v1.1","aiml/flux-pro/v1.1-ultra","aiml/flux-realism","aiml/flux/dev","aiml/flux/kontext-max/text-to-image","aiml/flux/kontext-pro/text-to-image","aiml/flux/schnell","amazon.nova-lite-v1:0","amazon.nova-micro-v1:0","amazon.nova-pro-v1:0","amazon.rerank-v1:0","amazon.titan-embed-image-v1","amazon.titan-embed-text-v1","amazon.titan-embed-text-v2:0","twelvelabs.marengo-embed-2-7-v1:0","us.twelvelabs.marengo-embed-2-7-v1:0","eu.twelvelabs.marengo-embed-2-7-v1:0","twelvelabs.pegasus-1-2-v1:0","us.twelvelabs.pegasus-1-2-v1:0","eu.twelvelabs.pegasus-1-2-v1:0","amazon.titan-text-express-v1","amazon.titan-text-lite-v1","amazon.titan-text-premier-v1:0","anthropic.claude-3-5-haiku-20241022-v1:0","anthropic.claude-haiku-4-5-20251001-v1:0","anthropic.claude-haiku-4-5@20251001","anthropic.claude-3-5-sonnet-20240620-v1:0","anthropic.claude-3-5-sonnet-20241022-v2:0","anthropic.claude-3-7-sonnet-20250219-v1:0","anthropic.claude-3-haiku-20240307-v1:0","anthropic.claude-3-opus-20240229-v1:0","anthropic.claude-3-sonnet-20240229-v1:0","anthropic.claude-instant-v1","anthropic.claude-opus-4-1-20250805-v1:0","anthropic.claude-opus-4-20250514-v1:0","anthropic.claude-sonnet-4-20250514-v1:0","anthropic.claude-v1","anthropic.claude-v2:1","anyscale/HuggingFaceH4/zephyr-7b-beta","anyscale/codellama/CodeLlama-34b-Instruct-hf","anyscale/codellama/CodeLlama-70b-Instruct-hf","anyscale/google/gemma-7b-it","anyscale/meta-llama/Llama-2-13b-chat-hf","anyscale/meta-llama/Llama-2-70b-chat-hf","anyscale/meta-llama/Llama-2-7b-chat-hf","anyscale/meta-llama/Meta-Llama-3-70B-Instruct","anyscale/meta-llama/Meta-Llama-3-8B-Instruct","anyscale/mistralai/Mistral-7B-Instruct-v0.1","anyscale/mistralai/Mixtral-8x22B-Instruct-v0.1","anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1","apac.amazon.nova-lite-v1:0","apac.amazon.nova-micro-v1:0","apac.amazon.nova-pro-v1:0","apac.anthropic.claude-3-5-sonnet-20240620-v1:0","apac.anthropic.claude-3-5-sonnet-20241022-v2:0","apac.anthropic.claude-3-haiku-20240307-v1:0","apac.anthropic.claude-haiku-4-5-20251001-v1:0","apac.anthropic.claude-3-sonnet-20240229-v1:0","apac.anthropic.claude-sonnet-4-20250514-v1:0","assemblyai/best","assemblyai/nano","au.anthropic.claude-sonnet-4-5-20250929-v1:0","azure/ada","azure/codex-mini","azure/command-r-plus","azure/computer-use-preview","azure/eu/gpt-4o-2024-08-06","azure/eu/gpt-4o-2024-11-20","azure/eu/gpt-4o-mini-2024-07-18","azure/eu/gpt-4o-mini-realtime-preview-2024-12-17","azure/eu/gpt-4o-realtime-preview-2024-10-01","azure/eu/gpt-4o-realtime-preview-2024-12-17","azure/eu/o1-2024-12-17","azure/eu/o1-mini-2024-09-12","azure/eu/o1-preview-2024-09-12","azure/eu/o3-mini-2025-01-31","azure/global-standard/gpt-4o-2024-08-06","azure/global-standard/gpt-4o-2024-11-20","azure/global-standard/gpt-4o-mini","azure/global/gpt-4o-2024-08-06","azure/global/gpt-4o-2024-11-20","azure/gpt-3.5-turbo","azure/gpt-3.5-turbo-0125","azure/gpt-3.5-turbo-instruct-0914","azure/gpt-35-turbo","azure/gpt-35-turbo-0125","azure/gpt-35-turbo-0301","azure/gpt-35-turbo-0613","azure/gpt-35-turbo-1106","azure/gpt-35-turbo-16k","azure/gpt-35-turbo-16k-0613","azure/gpt-35-turbo-instruct","azure/gpt-35-turbo-instruct-0914","azure/gpt-4","azure/gpt-4-0125-preview","azure/gpt-4-0613","azure/gpt-4-1106-preview","azure/gpt-4-32k","azure/gpt-4-32k-0613","azure/gpt-4-turbo","azure/gpt-4-turbo-2024-04-09","azure/gpt-4-turbo-vision-preview","azure/gpt-4.1","azure/gpt-4.1-2025-04-14","azure/gpt-4.1-mini","azure/gpt-4.1-mini-2025-04-14","azure/gpt-4.1-nano","azure/gpt-4.1-nano-2025-04-14","azure/gpt-4.5-preview","azure/gpt-4o","azure/gpt-4o-2024-05-13","azure/gpt-4o-2024-08-06","azure/gpt-4o-2024-11-20","azure/gpt-4o-audio-preview-2024-12-17","azure/gpt-4o-mini","azure/gpt-4o-mini-2024-07-18","azure/gpt-4o-mini-audio-preview-2024-12-17","azure/gpt-4o-mini-realtime-preview-2024-12-17","azure/gpt-4o-mini-transcribe","azure/gpt-4o-mini-tts","azure/gpt-4o-realtime-preview-2024-10-01","azure/gpt-4o-realtime-preview-2024-12-17","azure/gpt-4o-transcribe","azure/gpt-5","azure/gpt-5-2025-08-07","azure/gpt-5-chat","azure/gpt-5-chat-latest","azure/gpt-5-codex","azure/gpt-5-mini","azure/gpt-5-mini-2025-08-07","azure/gpt-5-nano","azure/gpt-5-nano-2025-08-07","azure/gpt-image-1","azure/hd/1024-x-1024/dall-e-3","azure/hd/1024-x-1792/dall-e-3","azure/hd/1792-x-1024/dall-e-3","azure/high/1024-x-1024/gpt-image-1","azure/high/1024-x-1536/gpt-image-1","azure/high/1536-x-1024/gpt-image-1","azure/low/1024-x-1024/gpt-image-1","azure/low/1024-x-1536/gpt-image-1","azure/low/1536-x-1024/gpt-image-1","azure/medium/1024-x-1024/gpt-image-1","azure/medium/1024-x-1536/gpt-image-1","azure/medium/1536-x-1024/gpt-image-1","azure/mistral-large-2402","azure/mistral-large-latest","azure/o1","azure/o1-2024-12-17","azure/o1-mini","azure/o1-mini-2024-09-12","azure/o1-preview","azure/o1-preview-2024-09-12","azure/o3","azure/o3-2025-04-16","azure/o3-deep-research","azure/o3-mini","azure/o3-mini-2025-01-31","azure/o3-pro","azure/o3-pro-2025-06-10","azure/o4-mini","azure/o4-mini-2025-04-16","azure/standard/1024-x-1024/dall-e-2","azure/standard/1024-x-1024/dall-e-3","azure/standard/1024-x-1792/dall-e-3","azure/standard/1792-x-1024/dall-e-3","azure/text-embedding-3-large","azure/text-embedding-3-small","azure/text-embedding-ada-002","azure/speech/azure-tts","azure/speech/azure-tts-hd","azure/tts-1","azure/tts-1-hd","azure/us/gpt-4o-2024-08-06","azure/us/gpt-4o-2024-11-20","azure/us/gpt-4o-mini-2024-07-18","azure/us/gpt-4o-mini-realtime-preview-2024-12-17","azure/us/gpt-4o-realtime-preview-2024-10-01","azure/us/gpt-4o-realtime-preview-2024-12-17","azure/us/o1-2024-12-17","azure/us/o1-mini-2024-09-12","azure/us/o1-preview-2024-09-12","azure/us/o3-mini-2025-01-31","azure/whisper-1","azure_ai/Cohere-embed-v3-english","azure_ai/Cohere-embed-v3-multilingual","azure_ai/FLUX-1.1-pro","azure_ai/FLUX.1-Kontext-pro","azure_ai/Llama-3.2-11B-Vision-Instruct","azure_ai/Llama-3.2-90B-Vision-Instruct","azure_ai/Llama-3.3-70B-Instruct","azure_ai/Llama-4-Maverick-17B-128E-Instruct-FP8","azure_ai/Llama-4-Scout-17B-16E-Instruct","azure_ai/Meta-Llama-3-70B-Instruct","azure_ai/Meta-Llama-3.1-405B-Instruct","azure_ai/Meta-Llama-3.1-70B-Instruct","azure_ai/Meta-Llama-3.1-8B-Instruct","azure_ai/Phi-3-medium-128k-instruct","azure_ai/Phi-3-medium-4k-instruct","azure_ai/Phi-3-mini-128k-instruct","azure_ai/Phi-3-mini-4k-instruct","azure_ai/Phi-3-small-128k-instruct","azure_ai/Phi-3-small-8k-instruct","azure_ai/Phi-3.5-MoE-instruct","azure_ai/Phi-3.5-mini-instruct","azure_ai/Phi-3.5-vision-instruct","azure_ai/Phi-4","azure_ai/Phi-4-mini-instruct","azure_ai/Phi-4-multimodal-instruct","azure_ai/Phi-4-mini-reasoning","azure_ai/Phi-4-reasoning","azure_ai/mistral-document-ai-2505","azure_ai/MAI-DS-R1","azure_ai/cohere-rerank-v3-english","azure_ai/cohere-rerank-v3-multilingual","azure_ai/cohere-rerank-v3.5","azure_ai/deepseek-r1","azure_ai/deepseek-v3","azure_ai/deepseek-v3-0324","azure_ai/embed-v-4-0","azure_ai/global/grok-3","azure_ai/global/grok-3-mini","azure_ai/grok-3","azure_ai/grok-3-mini","azure_ai/grok-4","azure_ai/grok-4-fast-non-reasoning","azure_ai/grok-4-fast-reasoning","azure_ai/grok-code-fast-1","azure_ai/jais-30b-chat","azure_ai/jamba-instruct","azure_ai/ministral-3b","azure_ai/mistral-large","azure_ai/mistral-large-2407","azure_ai/mistral-large-latest","azure_ai/mistral-medium-2505","azure_ai/mistral-nemo","azure_ai/mistral-small","azure_ai/mistral-small-2503","babbage-002","bedrock/*/1-month-commitment/cohere.command-light-text-v14","bedrock/*/1-month-commitment/cohere.command-text-v14","bedrock/*/6-month-commitment/cohere.command-light-text-v14","bedrock/*/6-month-commitment/cohere.command-text-v14","bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1","bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v1","bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2:1","bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1","bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v1","bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2:1","bedrock/ap-northeast-1/anthropic.claude-instant-v1","bedrock/ap-northeast-1/anthropic.claude-v1","bedrock/ap-northeast-1/anthropic.claude-v2:1","bedrock/ap-south-1/meta.llama3-70b-instruct-v1:0","bedrock/ap-south-1/meta.llama3-8b-instruct-v1:0","bedrock/ca-central-1/meta.llama3-70b-instruct-v1:0","bedrock/ca-central-1/meta.llama3-8b-instruct-v1:0","bedrock/eu-central-1/1-month-commitment/anthropic.claude-instant-v1","bedrock/eu-central-1/1-month-commitment/anthropic.claude-v1","bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2:1","bedrock/eu-central-1/6-month-commitment/anthropic.claude-instant-v1","bedrock/eu-central-1/6-month-commitment/anthropic.claude-v1","bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2:1","bedrock/eu-central-1/anthropic.claude-instant-v1","bedrock/eu-central-1/anthropic.claude-v1","bedrock/eu-central-1/anthropic.claude-v2:1","bedrock/eu-west-1/meta.llama3-70b-instruct-v1:0","bedrock/eu-west-1/meta.llama3-8b-instruct-v1:0","bedrock/eu-west-2/meta.llama3-70b-instruct-v1:0","bedrock/eu-west-2/meta.llama3-8b-instruct-v1:0","bedrock/eu-west-3/mistral.mistral-7b-instruct-v0:2","bedrock/eu-west-3/mistral.mistral-large-2402-v1:0","bedrock/eu-west-3/mistral.mixtral-8x7b-instruct-v0:1","bedrock/invoke/anthropic.claude-3-5-sonnet-20240620-v1:0","bedrock/sa-east-1/meta.llama3-70b-instruct-v1:0","bedrock/sa-east-1/meta.llama3-8b-instruct-v1:0","bedrock/us-east-1/1-month-commitment/anthropic.claude-instant-v1","bedrock/us-east-1/1-month-commitment/anthropic.claude-v1","bedrock/us-east-1/1-month-commitment/anthropic.claude-v2:1","bedrock/us-east-1/6-month-commitment/anthropic.claude-instant-v1","bedrock/us-east-1/6-month-commitment/anthropic.claude-v1","bedrock/us-east-1/6-month-commitment/anthropic.claude-v2:1","bedrock/us-east-1/anthropic.claude-instant-v1","bedrock/us-east-1/anthropic.claude-v1","bedrock/us-east-1/anthropic.claude-v2:1","bedrock/us-east-1/meta.llama3-70b-instruct-v1:0","bedrock/us-east-1/meta.llama3-8b-instruct-v1:0","bedrock/us-east-1/mistral.mistral-7b-instruct-v0:2","bedrock/us-east-1/mistral.mistral-large-2402-v1:0","bedrock/us-east-1/mistral.mixtral-8x7b-instruct-v0:1","bedrock/us-gov-east-1/amazon.nova-pro-v1:0","bedrock/us-gov-east-1/amazon.titan-embed-text-v1","bedrock/us-gov-east-1/amazon.titan-embed-text-v2:0","bedrock/us-gov-east-1/amazon.titan-text-express-v1","bedrock/us-gov-east-1/amazon.titan-text-lite-v1","bedrock/us-gov-east-1/amazon.titan-text-premier-v1:0","bedrock/us-gov-east-1/anthropic.claude-3-5-sonnet-20240620-v1:0","bedrock/us-gov-east-1/anthropic.claude-3-haiku-20240307-v1:0","bedrock/us-gov-east-1/meta.llama3-70b-instruct-v1:0","bedrock/us-gov-east-1/meta.llama3-8b-instruct-v1:0","bedrock/us-gov-west-1/amazon.nova-pro-v1:0","bedrock/us-gov-west-1/amazon.titan-embed-text-v1","bedrock/us-gov-west-1/amazon.titan-embed-text-v2:0","bedrock/us-gov-west-1/amazon.titan-text-express-v1","bedrock/us-gov-west-1/amazon.titan-text-lite-v1","bedrock/us-gov-west-1/amazon.titan-text-premier-v1:0","bedrock/us-gov-west-1/anthropic.claude-3-5-sonnet-20240620-v1:0","bedrock/us-gov-west-1/anthropic.claude-3-haiku-20240307-v1:0","bedrock/us-gov-west-1/meta.llama3-70b-instruct-v1:0","bedrock/us-gov-west-1/meta.llama3-8b-instruct-v1:0","bedrock/us-west-1/meta.llama3-70b-instruct-v1:0","bedrock/us-west-1/meta.llama3-8b-instruct-v1:0","bedrock/us-west-2/1-month-commitment/anthropic.claude-instant-v1","bedrock/us-west-2/1-month-commitment/anthropic.claude-v1","bedrock/us-west-2/1-month-commitment/anthropic.claude-v2:1","bedrock/us-west-2/6-month-commitment/anthropic.claude-instant-v1","bedrock/us-west-2/6-month-commitment/anthropic.claude-v1","bedrock/us-west-2/6-month-commitment/anthropic.claude-v2:1","bedrock/us-west-2/anthropic.claude-instant-v1","bedrock/us-west-2/anthropic.claude-v1","bedrock/us-west-2/anthropic.claude-v2:1","bedrock/us-west-2/mistral.mistral-7b-instruct-v0:2","bedrock/us-west-2/mistral.mistral-large-2402-v1:0","bedrock/us-west-2/mistral.mixtral-8x7b-instruct-v0:1","bedrock/us.anthropic.claude-3-5-haiku-20241022-v1:0","cerebras/llama-3.3-70b","cerebras/llama3.1-70b","cerebras/llama3.1-8b","cerebras/openai/gpt-oss-120b","cerebras/qwen-3-32b","chat-bison","chat-bison-32k","chat-bison-32k@002","chat-bison@001","chat-bison@002","chatdolphin","chatgpt-4o-latest","claude-3-5-haiku-20241022","claude-3-5-haiku-latest","claude-haiku-4-5-20251001","claude-haiku-4-5","claude-3-5-sonnet-20240620","claude-3-5-sonnet-20241022","claude-3-5-sonnet-latest","claude-3-7-sonnet-20250219","claude-3-7-sonnet-latest","claude-3-haiku-20240307","claude-3-opus-20240229","claude-3-opus-latest","claude-4-opus-20250514","claude-4-sonnet-20250514","claude-sonnet-4-5","claude-sonnet-4-5-20250929","claude-opus-4-1","claude-opus-4-1-20250805","claude-opus-4-20250514","claude-sonnet-4-20250514","cloudflare/@cf/meta/llama-2-7b-chat-fp16","cloudflare/@cf/meta/llama-2-7b-chat-int8","cloudflare/@cf/mistral/mistral-7b-instruct-v0.1","cloudflare/@hf/thebloke/codellama-7b-instruct-awq","code-bison","code-bison-32k@002","code-bison32k","code-bison@001","code-bison@002","code-gecko","code-gecko-latest","code-gecko@001","code-gecko@002","codechat-bison","codechat-bison-32k","codechat-bison-32k@002","codechat-bison@001","codechat-bison@002","codechat-bison@latest","codestral/codestral-2405","codestral/codestral-latest","codex-mini-latest","cohere.command-light-text-v14","cohere.command-r-plus-v1:0","cohere.command-r-v1:0","cohere.command-text-v14","cohere.embed-english-v3","cohere.embed-multilingual-v3","cohere.embed-v4:0","cohere.rerank-v3-5:0","command","command-a-03-2025","command-light","command-nightly","command-r","command-r-08-2024","command-r-plus","command-r-plus-08-2024","command-r7b-12-2024","computer-use-preview","deepseek-chat","deepseek-reasoner","dashscope/qwen-coder","dashscope/qwen-flash","dashscope/qwen-flash-2025-07-28","dashscope/qwen-max","dashscope/qwen-plus","dashscope/qwen-plus-2025-01-25","dashscope/qwen-plus-2025-04-28","dashscope/qwen-plus-2025-07-14","dashscope/qwen-plus-2025-07-28","dashscope/qwen-plus-2025-09-11","dashscope/qwen-plus-latest","dashscope/qwen-turbo","dashscope/qwen-turbo-2024-11-01","dashscope/qwen-turbo-2025-04-28","dashscope/qwen-turbo-latest","dashscope/qwen3-30b-a3b","dashscope/qwen3-coder-flash","dashscope/qwen3-coder-flash-2025-07-28","dashscope/qwen3-coder-plus","dashscope/qwen3-coder-plus-2025-07-22","dashscope/qwen3-max-preview","dashscope/qwq-plus","databricks/databricks-bge-large-en","databricks/databricks-claude-3-7-sonnet","databricks/databricks-gte-large-en","databricks/databricks-llama-2-70b-chat","databricks/databricks-llama-4-maverick","databricks/databricks-meta-llama-3-1-405b-instruct","databricks/databricks-meta-llama-3-3-70b-instruct","databricks/databricks-meta-llama-3-70b-instruct","databricks/databricks-mixtral-8x7b-instruct","databricks/databricks-mpt-30b-instruct","databricks/databricks-mpt-7b-instruct","davinci-002","deepgram/base","deepgram/base-conversationalai","deepgram/base-finance","deepgram/base-general","deepgram/base-meeting","deepgram/base-phonecall","deepgram/base-video","deepgram/base-voicemail","deepgram/enhanced","deepgram/enhanced-finance","deepgram/enhanced-general","deepgram/enhanced-meeting","deepgram/enhanced-phonecall","deepgram/nova","deepgram/nova-2","deepgram/nova-2-atc","deepgram/nova-2-automotive","deepgram/nova-2-conversationalai","deepgram/nova-2-drivethru","deepgram/nova-2-finance","deepgram/nova-2-general","deepgram/nova-2-meeting","deepgram/nova-2-phonecall","deepgram/nova-2-video","deepgram/nova-2-voicemail","deepgram/nova-3","deepgram/nova-3-general","deepgram/nova-3-medical","deepgram/nova-general","deepgram/nova-phonecall","deepgram/whisper","deepgram/whisper-base","deepgram/whisper-large","deepgram/whisper-medium","deepgram/whisper-small","deepgram/whisper-tiny","deepinfra/Gryphe/MythoMax-L2-13b","deepinfra/NousResearch/Hermes-3-Llama-3.1-405B","deepinfra/NousResearch/Hermes-3-Llama-3.1-70B","deepinfra/Qwen/QwQ-32B","deepinfra/Qwen/Qwen2.5-72B-Instruct","deepinfra/Qwen/Qwen2.5-7B-Instruct","deepinfra/Qwen/Qwen2.5-VL-32B-Instruct","deepinfra/Qwen/Qwen3-14B","deepinfra/Qwen/Qwen3-235B-A22B","deepinfra/Qwen/Qwen3-235B-A22B-Instruct-2507","deepinfra/Qwen/Qwen3-235B-A22B-Thinking-2507","deepinfra/Qwen/Qwen3-30B-A3B","deepinfra/Qwen/Qwen3-32B","deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct","deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo","deepinfra/Qwen/Qwen3-Next-80B-A3B-Instruct","deepinfra/Qwen/Qwen3-Next-80B-A3B-Thinking","deepinfra/Sao10K/L3-8B-Lunaris-v1-Turbo","deepinfra/Sao10K/L3.1-70B-Euryale-v2.2","deepinfra/Sao10K/L3.3-70B-Euryale-v2.3","deepinfra/allenai/olmOCR-7B-0725-FP8","deepinfra/anthropic/claude-3-7-sonnet-latest","deepinfra/anthropic/claude-4-opus","deepinfra/anthropic/claude-4-sonnet","deepinfra/deepseek-ai/DeepSeek-R1","deepinfra/deepseek-ai/DeepSeek-R1-0528","deepinfra/deepseek-ai/DeepSeek-R1-0528-Turbo","deepinfra/deepseek-ai/DeepSeek-R1-Distill-Llama-70B","deepinfra/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B","deepinfra/deepseek-ai/DeepSeek-R1-Turbo","deepinfra/deepseek-ai/DeepSeek-V3","deepinfra/deepseek-ai/DeepSeek-V3-0324","deepinfra/deepseek-ai/DeepSeek-V3.1","deepinfra/deepseek-ai/DeepSeek-V3.1-Terminus","deepinfra/google/gemini-2.0-flash-001","deepinfra/google/gemini-2.5-flash","deepinfra/google/gemini-2.5-pro","deepinfra/google/gemma-3-12b-it","deepinfra/google/gemma-3-27b-it","deepinfra/google/gemma-3-4b-it","deepinfra/meta-llama/Llama-3.2-11B-Vision-Instruct","deepinfra/meta-llama/Llama-3.2-3B-Instruct","deepinfra/meta-llama/Llama-3.3-70B-Instruct","deepinfra/meta-llama/Llama-3.3-70B-Instruct-Turbo","deepinfra/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8","deepinfra/meta-llama/Llama-4-Scout-17B-16E-Instruct","deepinfra/meta-llama/Llama-Guard-3-8B","deepinfra/meta-llama/Llama-Guard-4-12B","deepinfra/meta-llama/Meta-Llama-3-8B-Instruct","deepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct","deepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo","deepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct","deepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo","deepinfra/microsoft/WizardLM-2-8x22B","deepinfra/microsoft/phi-4","deepinfra/mistralai/Mistral-Nemo-Instruct-2407","deepinfra/mistralai/Mistral-Small-24B-Instruct-2501","deepinfra/mistralai/Mistral-Small-3.2-24B-Instruct-2506","deepinfra/mistralai/Mixtral-8x7B-Instruct-v0.1","deepinfra/moonshotai/Kimi-K2-Instruct","deepinfra/moonshotai/Kimi-K2-Instruct-0905","deepinfra/nvidia/Llama-3.1-Nemotron-70B-Instruct","deepinfra/nvidia/Llama-3.3-Nemotron-Super-49B-v1.5","deepinfra/nvidia/NVIDIA-Nemotron-Nano-9B-v2","deepinfra/openai/gpt-oss-120b","deepinfra/openai/gpt-oss-20b","deepinfra/zai-org/GLM-4.5","deepseek/deepseek-chat","deepseek/deepseek-coder","deepseek/deepseek-r1","deepseek/deepseek-reasoner","deepseek/deepseek-v3","deepseek.v3-v1:0","dolphin","doubao-embedding","doubao-embedding-large","doubao-embedding-large-text-240915","doubao-embedding-large-text-250515","doubao-embedding-text-240715","elevenlabs/scribe_v1","elevenlabs/scribe_v1_experimental","embed-english-light-v2.0","embed-english-light-v3.0","embed-english-v2.0","embed-english-v3.0","embed-multilingual-v2.0","embed-multilingual-v3.0","eu.amazon.nova-lite-v1:0","eu.amazon.nova-micro-v1:0","eu.amazon.nova-pro-v1:0","eu.anthropic.claude-3-5-haiku-20241022-v1:0","eu.anthropic.claude-haiku-4-5-20251001-v1:0","eu.anthropic.claude-3-5-sonnet-20240620-v1:0","eu.anthropic.claude-3-5-sonnet-20241022-v2:0","eu.anthropic.claude-3-7-sonnet-20250219-v1:0","eu.anthropic.claude-3-haiku-20240307-v1:0","eu.anthropic.claude-3-opus-20240229-v1:0","eu.anthropic.claude-3-sonnet-20240229-v1:0","eu.anthropic.claude-opus-4-1-20250805-v1:0","eu.anthropic.claude-opus-4-20250514-v1:0","eu.anthropic.claude-sonnet-4-20250514-v1:0","eu.anthropic.claude-sonnet-4-5-20250929-v1:0","eu.meta.llama3-2-1b-instruct-v1:0","eu.meta.llama3-2-3b-instruct-v1:0","eu.mistral.pixtral-large-2502-v1:0","featherless_ai/featherless-ai/Qwerky-72B","featherless_ai/featherless-ai/Qwerky-QwQ-32B","fireworks-ai-4.1b-to-16b","fireworks-ai-56b-to-176b","fireworks-ai-above-16b","fireworks-ai-default","fireworks-ai-embedding-150m-to-350m","fireworks-ai-embedding-up-to-150m","fireworks-ai-moe-up-to-56b","fireworks-ai-up-to-4b","fireworks_ai/WhereIsAI/UAE-Large-V1","fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct","fireworks_ai/accounts/fireworks/models/deepseek-r1","fireworks_ai/accounts/fireworks/models/deepseek-r1-0528","fireworks_ai/accounts/fireworks/models/deepseek-r1-basic","fireworks_ai/accounts/fireworks/models/deepseek-v3","fireworks_ai/accounts/fireworks/models/deepseek-v3-0324","fireworks_ai/accounts/fireworks/models/deepseek-v3p1","fireworks_ai/accounts/fireworks/models/firefunction-v2","fireworks_ai/accounts/fireworks/models/glm-4p5","fireworks_ai/accounts/fireworks/models/glm-4p5-air","fireworks_ai/accounts/fireworks/models/gpt-oss-120b","fireworks_ai/accounts/fireworks/models/gpt-oss-20b","fireworks_ai/accounts/fireworks/models/kimi-k2-instruct","fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct","fireworks_ai/accounts/fireworks/models/llama-v3p1-8b-instruct","fireworks_ai/accounts/fireworks/models/llama-v3p2-11b-vision-instruct","fireworks_ai/accounts/fireworks/models/llama-v3p2-1b-instruct","fireworks_ai/accounts/fireworks/models/llama-v3p2-3b-instruct","fireworks_ai/accounts/fireworks/models/llama-v3p2-90b-vision-instruct","fireworks_ai/accounts/fireworks/models/llama4-maverick-instruct-basic","fireworks_ai/accounts/fireworks/models/llama4-scout-instruct-basic","fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct-hf","fireworks_ai/accounts/fireworks/models/qwen2-72b-instruct","fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct","fireworks_ai/accounts/fireworks/models/yi-large","fireworks_ai/nomic-ai/nomic-embed-text-v1","fireworks_ai/nomic-ai/nomic-embed-text-v1.5","fireworks_ai/thenlper/gte-base","fireworks_ai/thenlper/gte-large","friendliai/meta-llama-3.1-70b-instruct","friendliai/meta-llama-3.1-8b-instruct","ft:babbage-002","ft:davinci-002","ft:gpt-3.5-turbo","ft:gpt-3.5-turbo-0125","ft:gpt-3.5-turbo-0613","ft:gpt-3.5-turbo-1106","ft:gpt-4-0613","ft:gpt-4o-2024-08-06","ft:gpt-4o-2024-11-20","ft:gpt-4o-mini-2024-07-18","gemini-1.0-pro","gemini-1.0-pro-001","gemini-1.0-pro-002","gemini-1.0-pro-vision","gemini-1.0-pro-vision-001","gemini-1.0-ultra","gemini-1.0-ultra-001","gemini-1.5-flash","gemini-1.5-flash-001","gemini-1.5-flash-002","gemini-1.5-flash-exp-0827","gemini-1.5-flash-preview-0514","gemini-1.5-pro","gemini-1.5-pro-001","gemini-1.5-pro-002","gemini-1.5-pro-preview-0215","gemini-1.5-pro-preview-0409","gemini-1.5-pro-preview-0514","gemini-2.0-flash","gemini-2.0-flash-001","gemini-2.0-flash-exp","gemini-2.0-flash-lite","gemini-2.0-flash-lite-001","gemini-2.0-flash-live-preview-04-09","gemini-2.0-flash-preview-image-generation","gemini-2.0-flash-thinking-exp","gemini-2.0-flash-thinking-exp-01-21","gemini-2.0-pro-exp-02-05","gemini-2.5-flash","gemini-2.5-flash-image","gemini-2.5-flash-image-preview","gemini-2.5-flash-lite","gemini-2.5-flash-lite-preview-09-2025","gemini-2.5-flash-preview-09-2025","gemini-2.5-flash-lite-preview-06-17","gemini-2.5-flash-preview-04-17","gemini-2.5-flash-preview-05-20","gemini-2.5-pro","gemini-2.5-pro-exp-03-25","gemini-2.5-pro-preview-03-25","gemini-2.5-pro-preview-05-06","gemini-2.5-pro-preview-06-05","gemini-2.5-pro-preview-tts","gemini-embedding-001","gemini-flash-experimental","gemini-pro","gemini-pro-experimental","gemini-pro-vision","gemini/gemini-1.5-flash","gemini/gemini-1.5-flash-001","gemini/gemini-1.5-flash-002","gemini/gemini-1.5-flash-8b","gemini/gemini-1.5-flash-8b-exp-0827","gemini/gemini-1.5-flash-8b-exp-0924","gemini/gemini-1.5-flash-exp-0827","gemini/gemini-1.5-flash-latest","gemini/gemini-1.5-pro","gemini/gemini-1.5-pro-001","gemini/gemini-1.5-pro-002","gemini/gemini-1.5-pro-exp-0801","gemini/gemini-1.5-pro-exp-0827","gemini/gemini-1.5-pro-latest","gemini/gemini-2.0-flash","gemini/gemini-2.0-flash-001","gemini/gemini-2.0-flash-exp","gemini/gemini-2.0-flash-lite","gemini/gemini-2.0-flash-lite-preview-02-05","gemini/gemini-2.0-flash-live-001","gemini/gemini-2.0-flash-preview-image-generation","gemini/gemini-2.0-flash-thinking-exp","gemini/gemini-2.0-flash-thinking-exp-01-21","gemini/gemini-2.0-pro-exp-02-05","gemini/gemini-2.5-flash","gemini/gemini-2.5-flash-image","gemini/gemini-2.5-flash-image-preview","gemini/gemini-2.5-flash-lite","gemini/gemini-2.5-flash-lite-preview-09-2025","gemini/gemini-2.5-flash-preview-09-2025","gemini/gemini-flash-latest","gemini/gemini-flash-lite-latest","gemini/gemini-2.5-flash-lite-preview-06-17","gemini/gemini-2.5-flash-preview-04-17","gemini/gemini-2.5-flash-preview-05-20","gemini/gemini-2.5-flash-preview-tts","gemini/gemini-2.5-pro","gemini/gemini-2.5-pro-exp-03-25","gemini/gemini-2.5-pro-preview-03-25","gemini/gemini-2.5-pro-preview-05-06","gemini/gemini-2.5-pro-preview-06-05","gemini/gemini-2.5-pro-preview-tts","gemini/gemini-exp-1114","gemini/gemini-exp-1206","gemini/gemini-gemma-2-27b-it","gemini/gemini-gemma-2-9b-it","gemini/gemini-pro","gemini/gemini-pro-vision","gemini/gemma-3-27b-it","gemini/imagen-3.0-fast-generate-001","gemini/imagen-3.0-generate-001","gemini/imagen-3.0-generate-002","gemini/imagen-4.0-fast-generate-001","gemini/imagen-4.0-generate-001","gemini/imagen-4.0-ultra-generate-001","gemini/learnlm-1.5-pro-experimental","gemini/veo-2.0-generate-001","gemini/veo-3.0-fast-generate-preview","gemini/veo-3.0-generate-preview","global.anthropic.claude-sonnet-4-5-20250929-v1:0","global.anthropic.claude-sonnet-4-20250514-v1:0","global.anthropic.claude-haiku-4-5-20251001-v1:0","gpt-3.5-turbo","gpt-3.5-turbo-0125","gpt-3.5-turbo-0301","gpt-3.5-turbo-0613","gpt-3.5-turbo-1106","gpt-3.5-turbo-16k","gpt-3.5-turbo-16k-0613","gpt-3.5-turbo-instruct","gpt-3.5-turbo-instruct-0914","gpt-4","gpt-4-0125-preview","gpt-4-0314","gpt-4-0613","gpt-4-1106-preview","gpt-4-1106-vision-preview","gpt-4-32k","gpt-4-32k-0314","gpt-4-32k-0613","gpt-4-turbo","gpt-4-turbo-2024-04-09","gpt-4-turbo-preview","gpt-4-vision-preview","gpt-4.1","gpt-4.1-2025-04-14","gpt-4.1-mini","gpt-4.1-mini-2025-04-14","gpt-4.1-nano","gpt-4.1-nano-2025-04-14","gpt-4.5-preview","gpt-4.5-preview-2025-02-27","gpt-4o","gpt-4o-2024-05-13","gpt-4o-2024-08-06","gpt-4o-2024-11-20","gpt-4o-audio-preview","gpt-4o-audio-preview-2024-10-01","gpt-4o-audio-preview-2024-12-17","gpt-4o-audio-preview-2025-06-03","gpt-4o-mini","gpt-4o-mini-2024-07-18","gpt-4o-mini-audio-preview","gpt-4o-mini-audio-preview-2024-12-17","gpt-4o-mini-realtime-preview","gpt-4o-mini-realtime-preview-2024-12-17","gpt-4o-mini-search-preview","gpt-4o-mini-search-preview-2025-03-11","gpt-4o-mini-transcribe","gpt-4o-mini-tts","gpt-4o-realtime-preview","gpt-4o-realtime-preview-2024-10-01","gpt-4o-realtime-preview-2024-12-17","gpt-4o-realtime-preview-2025-06-03","gpt-4o-search-preview","gpt-4o-search-preview-2025-03-11","gpt-4o-transcribe","gpt-5","gpt-5-pro","gpt-5-pro-2025-10-06","gpt-5-2025-08-07","gpt-5-chat","gpt-5-chat-latest","gpt-5-codex","gpt-5-mini","gpt-5-mini-2025-08-07","gpt-5-nano","gpt-5-nano-2025-08-07","gpt-image-1","gpt-image-1-mini","gpt-realtime","gpt-realtime-mini","gpt-realtime-2025-08-28","gradient_ai/alibaba-qwen3-32b","gradient_ai/anthropic-claude-3-opus","gradient_ai/anthropic-claude-3.5-haiku","gradient_ai/anthropic-claude-3.5-sonnet","gradient_ai/anthropic-claude-3.7-sonnet","gradient_ai/deepseek-r1-distill-llama-70b","gradient_ai/llama3-8b-instruct","gradient_ai/llama3.3-70b-instruct","gradient_ai/mistral-nemo-instruct-2407","gradient_ai/openai-gpt-4o","gradient_ai/openai-gpt-4o-mini","gradient_ai/openai-o3","gradient_ai/openai-o3-mini","lemonade/Qwen3-Coder-30B-A3B-Instruct-GGUF","lemonade/gpt-oss-20b-mxfp4-GGUF","lemonade/gpt-oss-120b-mxfp-GGUF","lemonade/Gemma-3-4b-it-GGUF","lemonade/Qwen3-4B-Instruct-2507-GGUF","groq/deepseek-r1-distill-llama-70b","groq/distil-whisper-large-v3-en","groq/gemma-7b-it","groq/gemma2-9b-it","groq/llama-3.1-405b-reasoning","groq/llama-3.1-70b-versatile","groq/llama-3.1-8b-instant","groq/llama-3.2-11b-text-preview","groq/llama-3.2-11b-vision-preview","groq/llama-3.2-1b-preview","groq/llama-3.2-3b-preview","groq/llama-3.2-90b-text-preview","groq/llama-3.2-90b-vision-preview","groq/llama-3.3-70b-specdec","groq/llama-3.3-70b-versatile","groq/llama-guard-3-8b","groq/llama2-70b-4096","groq/llama3-groq-70b-8192-tool-use-preview","groq/llama3-groq-8b-8192-tool-use-preview","groq/meta-llama/llama-4-maverick-17b-128e-instruct","groq/meta-llama/llama-4-scout-17b-16e-instruct","groq/mistral-saba-24b","groq/mixtral-8x7b-32768","groq/moonshotai/kimi-k2-instruct","groq/moonshotai/kimi-k2-instruct-0905","groq/openai/gpt-oss-120b","groq/openai/gpt-oss-20b","groq/playai-tts","groq/qwen/qwen3-32b","groq/whisper-large-v3","groq/whisper-large-v3-turbo","hd/1024-x-1024/dall-e-3","hd/1024-x-1792/dall-e-3","hd/1792-x-1024/dall-e-3","heroku/claude-3-5-haiku","heroku/claude-3-5-sonnet-latest","heroku/claude-3-7-sonnet","heroku/claude-4-sonnet","high/1024-x-1024/gpt-image-1","high/1024-x-1536/gpt-image-1","high/1536-x-1024/gpt-image-1","hyperbolic/NousResearch/Hermes-3-Llama-3.1-70B","hyperbolic/Qwen/QwQ-32B","hyperbolic/Qwen/Qwen2.5-72B-Instruct","hyperbolic/Qwen/Qwen2.5-Coder-32B-Instruct","hyperbolic/Qwen/Qwen3-235B-A22B","hyperbolic/deepseek-ai/DeepSeek-R1","hyperbolic/deepseek-ai/DeepSeek-R1-0528","hyperbolic/deepseek-ai/DeepSeek-V3","hyperbolic/deepseek-ai/DeepSeek-V3-0324","hyperbolic/meta-llama/Llama-3.2-3B-Instruct","hyperbolic/meta-llama/Llama-3.3-70B-Instruct","hyperbolic/meta-llama/Meta-Llama-3-70B-Instruct","hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct","hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct","hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct","hyperbolic/moonshotai/Kimi-K2-Instruct","j2-light","j2-mid","j2-ultra","jamba-1.5","jamba-1.5-large","jamba-1.5-large@001","jamba-1.5-mini","jamba-1.5-mini@001","jamba-large-1.6","jamba-large-1.7","jamba-mini-1.6","jamba-mini-1.7","jina-reranker-v2-base-multilingual","jp.anthropic.claude-sonnet-4-5-20250929-v1:0","jp.anthropic.claude-haiku-4-5-20251001-v1:0","lambda_ai/deepseek-llama3.3-70b","lambda_ai/deepseek-r1-0528","lambda_ai/deepseek-r1-671b","lambda_ai/deepseek-v3-0324","lambda_ai/hermes3-405b","lambda_ai/hermes3-70b","lambda_ai/hermes3-8b","lambda_ai/lfm-40b","lambda_ai/lfm-7b","lambda_ai/llama-4-maverick-17b-128e-instruct-fp8","lambda_ai/llama-4-scout-17b-16e-instruct","lambda_ai/llama3.1-405b-instruct-fp8","lambda_ai/llama3.1-70b-instruct-fp8","lambda_ai/llama3.1-8b-instruct","lambda_ai/llama3.1-nemotron-70b-instruct-fp8","lambda_ai/llama3.2-11b-vision-instruct","lambda_ai/llama3.2-3b-instruct","lambda_ai/llama3.3-70b-instruct-fp8","lambda_ai/qwen25-coder-32b-instruct","lambda_ai/qwen3-32b-fp8","low/1024-x-1024/gpt-image-1","low/1024-x-1536/gpt-image-1","low/1536-x-1024/gpt-image-1","luminous-base","luminous-base-control","luminous-extended","luminous-extended-control","luminous-supreme","luminous-supreme-control","max-x-max/50-steps/stability.stable-diffusion-xl-v0","max-x-max/max-steps/stability.stable-diffusion-xl-v0","medium/1024-x-1024/gpt-image-1","medium/1024-x-1536/gpt-image-1","medium/1536-x-1024/gpt-image-1","low/1024-x-1024/gpt-image-1-mini","low/1024-x-1536/gpt-image-1-mini","low/1536-x-1024/gpt-image-1-mini","medium/1024-x-1024/gpt-image-1-mini","medium/1024-x-1536/gpt-image-1-mini","medium/1536-x-1024/gpt-image-1-mini","medlm-large","medlm-medium","meta.llama2-13b-chat-v1","meta.llama2-70b-chat-v1","meta.llama3-1-405b-instruct-v1:0","meta.llama3-1-70b-instruct-v1:0","meta.llama3-1-8b-instruct-v1:0","meta.llama3-2-11b-instruct-v1:0","meta.llama3-2-1b-instruct-v1:0","meta.llama3-2-3b-instruct-v1:0","meta.llama3-2-90b-instruct-v1:0","meta.llama3-3-70b-instruct-v1:0","meta.llama3-70b-instruct-v1:0","meta.llama3-8b-instruct-v1:0","meta.llama4-maverick-17b-instruct-v1:0","meta.llama4-scout-17b-instruct-v1:0","meta_llama/Llama-3.3-70B-Instruct","meta_llama/Llama-3.3-8B-Instruct","meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8","meta_llama/Llama-4-Scout-17B-16E-Instruct-FP8","mistral.mistral-7b-instruct-v0:2","mistral.mistral-large-2402-v1:0","mistral.mistral-large-2407-v1:0","mistral.mistral-small-2402-v1:0","mistral.mixtral-8x7b-instruct-v0:1","mistral/codestral-2405","mistral/codestral-latest","mistral/codestral-mamba-latest","mistral/devstral-medium-2507","mistral/devstral-small-2505","mistral/devstral-small-2507","mistral/magistral-medium-2506","mistral/mistral-ocr-latest","mistral/mistral-ocr-2505-completion","mistral/magistral-medium-latest","mistral/magistral-small-2506","mistral/magistral-small-latest","mistral/mistral-embed","mistral/mistral-large-2402","mistral/mistral-large-2407","mistral/mistral-large-2411","mistral/mistral-large-latest","mistral/mistral-medium","mistral/mistral-medium-2312","mistral/mistral-medium-2505","mistral/mistral-medium-latest","mistral/mistral-small","mistral/mistral-small-latest","mistral/mistral-tiny","mistral/open-codestral-mamba","mistral/open-mistral-7b","mistral/open-mistral-nemo","mistral/open-mistral-nemo-2407","mistral/open-mixtral-8x22b","mistral/open-mixtral-8x7b","mistral/pixtral-12b-2409","mistral/pixtral-large-2411","mistral/pixtral-large-latest","moonshot/kimi-k2-0711-preview","moonshot/kimi-latest","moonshot/kimi-latest-128k","moonshot/kimi-latest-32k","moonshot/kimi-latest-8k","moonshot/kimi-thinking-preview","moonshot/moonshot-v1-128k","moonshot/moonshot-v1-128k-0430","moonshot/moonshot-v1-128k-vision-preview","moonshot/moonshot-v1-32k","moonshot/moonshot-v1-32k-0430","moonshot/moonshot-v1-32k-vision-preview","moonshot/moonshot-v1-8k","moonshot/moonshot-v1-8k-0430","moonshot/moonshot-v1-8k-vision-preview","moonshot/moonshot-v1-auto","morph/morph-v3-fast","morph/morph-v3-large","multimodalembedding","multimodalembedding@001","nscale/Qwen/QwQ-32B","nscale/Qwen/Qwen2.5-Coder-32B-Instruct","nscale/Qwen/Qwen2.5-Coder-3B-Instruct","nscale/Qwen/Qwen2.5-Coder-7B-Instruct","nscale/black-forest-labs/FLUX.1-schnell","nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-70B","nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-8B","nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B","nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B","nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B","nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B","nscale/meta-llama/Llama-3.1-8B-Instruct","nscale/meta-llama/Llama-3.3-70B-Instruct","nscale/meta-llama/Llama-4-Scout-17B-16E-Instruct","nscale/mistralai/mixtral-8x22b-instruct-v0.1","nscale/stabilityai/stable-diffusion-xl-base-1.0","o1","o1-2024-12-17","o1-mini","o1-mini-2024-09-12","o1-preview","o1-preview-2024-09-12","o1-pro","o1-pro-2025-03-19","o3","o3-2025-04-16","o3-deep-research","o3-deep-research-2025-06-26","o3-mini","o3-mini-2025-01-31","o3-pro","o3-pro-2025-06-10","o4-mini","o4-mini-2025-04-16","o4-mini-deep-research","o4-mini-deep-research-2025-06-26","oci/meta.llama-3.1-405b-instruct","oci/meta.llama-3.2-90b-vision-instruct","oci/meta.llama-3.3-70b-instruct","oci/meta.llama-4-maverick-17b-128e-instruct-fp8","oci/meta.llama-4-scout-17b-16e-instruct","oci/xai.grok-3","oci/xai.grok-3-fast","oci/xai.grok-3-mini","oci/xai.grok-3-mini-fast","oci/xai.grok-4","oci/cohere.command-latest","oci/cohere.command-a-03-2025","oci/cohere.command-plus-latest","ollama/codegeex4","ollama/codegemma","ollama/codellama","ollama/deepseek-coder-v2-base","ollama/deepseek-coder-v2-instruct","ollama/deepseek-coder-v2-lite-base","ollama/deepseek-coder-v2-lite-instruct","ollama/deepseek-v3.1:671b-cloud","ollama/gpt-oss:120b-cloud","ollama/gpt-oss:20b-cloud","ollama/internlm2_5-20b-chat","ollama/llama2","ollama/llama2-uncensored","ollama/llama2:13b","ollama/llama2:70b","ollama/llama2:7b","ollama/llama3","ollama/llama3.1","ollama/llama3:70b","ollama/llama3:8b","ollama/mistral","ollama/mistral-7B-Instruct-v0.1","ollama/mistral-7B-Instruct-v0.2","ollama/mistral-large-instruct-2407","ollama/mixtral-8x22B-Instruct-v0.1","ollama/mixtral-8x7B-Instruct-v0.1","ollama/orca-mini","ollama/qwen3-coder:480b-cloud","ollama/vicuna","omni-moderation-2024-09-26","omni-moderation-latest","omni-moderation-latest-intents","openai.gpt-oss-120b-1:0","openai.gpt-oss-20b-1:0","openrouter/anthropic/claude-2","openrouter/anthropic/claude-3-5-haiku","openrouter/anthropic/claude-3-5-haiku-20241022","openrouter/anthropic/claude-3-haiku","openrouter/anthropic/claude-3-haiku-20240307","openrouter/anthropic/claude-3-opus","openrouter/anthropic/claude-3-sonnet","openrouter/anthropic/claude-3.5-sonnet","openrouter/anthropic/claude-3.5-sonnet:beta","openrouter/anthropic/claude-3.7-sonnet","openrouter/anthropic/claude-3.7-sonnet:beta","openrouter/anthropic/claude-instant-v1","openrouter/anthropic/claude-opus-4","openrouter/anthropic/claude-opus-4.1","openrouter/anthropic/claude-sonnet-4","openrouter/anthropic/claude-sonnet-4.5","openrouter/bytedance/ui-tars-1.5-7b","openrouter/cognitivecomputations/dolphin-mixtral-8x7b","openrouter/cohere/command-r-plus","openrouter/databricks/dbrx-instruct","openrouter/deepseek/deepseek-chat","openrouter/deepseek/deepseek-chat-v3-0324","openrouter/deepseek/deepseek-chat-v3.1","openrouter/deepseek/deepseek-coder","openrouter/deepseek/deepseek-r1","openrouter/deepseek/deepseek-r1-0528","openrouter/fireworks/firellava-13b","openrouter/google/gemini-2.0-flash-001","openrouter/google/gemini-2.5-flash","openrouter/google/gemini-2.5-pro","openrouter/google/gemini-pro-1.5","openrouter/google/gemini-pro-vision","openrouter/google/palm-2-chat-bison","openrouter/google/palm-2-codechat-bison","openrouter/gryphe/mythomax-l2-13b","openrouter/jondurbin/airoboros-l2-70b-2.1","openrouter/mancer/weaver","openrouter/meta-llama/codellama-34b-instruct","openrouter/meta-llama/llama-2-13b-chat","openrouter/meta-llama/llama-2-70b-chat","openrouter/meta-llama/llama-3-70b-instruct","openrouter/meta-llama/llama-3-70b-instruct:nitro","openrouter/meta-llama/llama-3-8b-instruct:extended","openrouter/meta-llama/llama-3-8b-instruct:free","openrouter/microsoft/wizardlm-2-8x22b:nitro","openrouter/mistralai/mistral-7b-instruct","openrouter/mistralai/mistral-7b-instruct:free","openrouter/mistralai/mistral-large","openrouter/mistralai/mistral-small-3.1-24b-instruct","openrouter/mistralai/mistral-small-3.2-24b-instruct","openrouter/mistralai/mixtral-8x22b-instruct","openrouter/nousresearch/nous-hermes-llama2-13b","openrouter/openai/gpt-3.5-turbo","openrouter/openai/gpt-3.5-turbo-16k","openrouter/openai/gpt-4","openrouter/openai/gpt-4-vision-preview","openrouter/openai/gpt-4.1","openrouter/openai/gpt-4.1-2025-04-14","openrouter/openai/gpt-4.1-mini","openrouter/openai/gpt-4.1-mini-2025-04-14","openrouter/openai/gpt-4.1-nano","openrouter/openai/gpt-4.1-nano-2025-04-14","openrouter/openai/gpt-4o","openrouter/openai/gpt-4o-2024-05-13","openrouter/openai/gpt-5-chat","openrouter/openai/gpt-5-codex","openrouter/openai/gpt-5","openrouter/openai/gpt-5-mini","openrouter/openai/gpt-5-nano","openrouter/openai/gpt-oss-120b","openrouter/openai/gpt-oss-20b","openrouter/openai/o1","openrouter/openai/o1-mini","openrouter/openai/o1-mini-2024-09-12","openrouter/openai/o1-preview","openrouter/openai/o1-preview-2024-09-12","openrouter/openai/o3-mini","openrouter/openai/o3-mini-high","openrouter/pygmalionai/mythalion-13b","openrouter/qwen/qwen-2.5-coder-32b-instruct","openrouter/qwen/qwen-vl-plus","openrouter/qwen/qwen3-coder","openrouter/switchpoint/router","openrouter/undi95/remm-slerp-l2-13b","openrouter/x-ai/grok-4","openrouter/x-ai/grok-4-fast:free","ovhcloud/DeepSeek-R1-Distill-Llama-70B","ovhcloud/Llama-3.1-8B-Instruct","ovhcloud/Meta-Llama-3_1-70B-Instruct","ovhcloud/Meta-Llama-3_3-70B-Instruct","ovhcloud/Mistral-7B-Instruct-v0.3","ovhcloud/Mistral-Nemo-Instruct-2407","ovhcloud/Mistral-Small-3.2-24B-Instruct-2506","ovhcloud/Mixtral-8x7B-Instruct-v0.1","ovhcloud/Qwen2.5-Coder-32B-Instruct","ovhcloud/Qwen2.5-VL-72B-Instruct","ovhcloud/Qwen3-32B","ovhcloud/gpt-oss-120b","ovhcloud/gpt-oss-20b","ovhcloud/llava-v1.6-mistral-7b-hf","ovhcloud/mamba-codestral-7B-v0.1","palm/chat-bison","palm/chat-bison-001","palm/text-bison","palm/text-bison-001","palm/text-bison-safety-off","palm/text-bison-safety-recitation-off","perplexity/codellama-34b-instruct","perplexity/codellama-70b-instruct","perplexity/llama-2-70b-chat","perplexity/llama-3.1-70b-instruct","perplexity/llama-3.1-8b-instruct","perplexity/llama-3.1-sonar-huge-128k-online","perplexity/llama-3.1-sonar-large-128k-chat","perplexity/llama-3.1-sonar-large-128k-online","perplexity/llama-3.1-sonar-small-128k-chat","perplexity/llama-3.1-sonar-small-128k-online","perplexity/mistral-7b-instruct","perplexity/mixtral-8x7b-instruct","perplexity/pplx-70b-chat","perplexity/pplx-70b-online","perplexity/pplx-7b-chat","perplexity/pplx-7b-online","perplexity/sonar","perplexity/sonar-deep-research","perplexity/sonar-medium-chat","perplexity/sonar-medium-online","perplexity/sonar-pro","perplexity/sonar-reasoning","perplexity/sonar-reasoning-pro","perplexity/sonar-small-chat","perplexity/sonar-small-online","qwen.qwen3-coder-480b-a35b-v1:0","qwen.qwen3-235b-a22b-2507-v1:0","qwen.qwen3-coder-30b-a3b-v1:0","qwen.qwen3-32b-v1:0","recraft/recraftv2","recraft/recraftv3","replicate/meta/llama-2-13b","replicate/meta/llama-2-13b-chat","replicate/meta/llama-2-70b","replicate/meta/llama-2-70b-chat","replicate/meta/llama-2-7b","replicate/meta/llama-2-7b-chat","replicate/meta/llama-3-70b","replicate/meta/llama-3-70b-instruct","replicate/meta/llama-3-8b","replicate/meta/llama-3-8b-instruct","replicate/mistralai/mistral-7b-instruct-v0.2","replicate/mistralai/mistral-7b-v0.1","replicate/mistralai/mixtral-8x7b-instruct-v0.1","rerank-english-v2.0","rerank-english-v3.0","rerank-multilingual-v2.0","rerank-multilingual-v3.0","rerank-v3.5","nvidia_nim/nvidia/nv-rerankqa-mistral-4b-v3","nvidia_nim/nvidia/llama-3_2-nv-rerankqa-1b-v2","sagemaker/meta-textgeneration-llama-2-13b","sagemaker/meta-textgeneration-llama-2-13b-f","sagemaker/meta-textgeneration-llama-2-70b","sagemaker/meta-textgeneration-llama-2-70b-b-f","sagemaker/meta-textgeneration-llama-2-7b","sagemaker/meta-textgeneration-llama-2-7b-f","sambanova/DeepSeek-R1","sambanova/DeepSeek-R1-Distill-Llama-70B","sambanova/DeepSeek-V3-0324","sambanova/Llama-4-Maverick-17B-128E-Instruct","sambanova/Llama-4-Scout-17B-16E-Instruct","sambanova/Meta-Llama-3.1-405B-Instruct","sambanova/Meta-Llama-3.1-8B-Instruct","sambanova/Meta-Llama-3.2-1B-Instruct","sambanova/Meta-Llama-3.2-3B-Instruct","sambanova/Meta-Llama-3.3-70B-Instruct","sambanova/Meta-Llama-Guard-3-8B","sambanova/QwQ-32B","sambanova/Qwen2-Audio-7B-Instruct","sambanova/Qwen3-32B","sambanova/DeepSeek-V3.1","sambanova/gpt-oss-120b","snowflake/claude-3-5-sonnet","snowflake/deepseek-r1","snowflake/gemma-7b","snowflake/jamba-1.5-large","snowflake/jamba-1.5-mini","snowflake/jamba-instruct","snowflake/llama2-70b-chat","snowflake/llama3-70b","snowflake/llama3-8b","snowflake/llama3.1-405b","snowflake/llama3.1-70b","snowflake/llama3.1-8b","snowflake/llama3.2-1b","snowflake/llama3.2-3b","snowflake/llama3.3-70b","snowflake/mistral-7b","snowflake/mistral-large","snowflake/mistral-large2","snowflake/mixtral-8x7b","snowflake/reka-core","snowflake/reka-flash","snowflake/snowflake-arctic","snowflake/snowflake-llama-3.1-405b","snowflake/snowflake-llama-3.3-70b","stability.sd3-5-large-v1:0","stability.sd3-large-v1:0","stability.stable-image-core-v1:0","stability.stable-image-core-v1:1","stability.stable-image-ultra-v1:0","stability.stable-image-ultra-v1:1","standard/1024-x-1024/dall-e-3","standard/1024-x-1792/dall-e-3","standard/1792-x-1024/dall-e-3","text-bison","text-bison32k","text-bison32k@002","text-bison@001","text-bison@002","text-completion-codestral/codestral-2405","text-completion-codestral/codestral-latest","text-embedding-004","text-embedding-005","text-embedding-3-large","text-embedding-3-small","text-embedding-ada-002","text-embedding-ada-002-v2","text-embedding-large-exp-03-07","text-embedding-preview-0409","text-moderation-007","text-moderation-latest","text-moderation-stable","text-multilingual-embedding-002","text-multilingual-embedding-preview-0409","text-unicorn","text-unicorn@001","textembedding-gecko","textembedding-gecko-multilingual","textembedding-gecko-multilingual@001","textembedding-gecko@001","textembedding-gecko@003","together-ai-21.1b-41b","together-ai-4.1b-8b","together-ai-41.1b-80b","together-ai-8.1b-21b","together-ai-81.1b-110b","together-ai-embedding-151m-to-350m","together-ai-embedding-up-to-150m","together_ai/baai/bge-base-en-v1.5","together_ai/BAAI/bge-base-en-v1.5","together-ai-up-to-4b","together_ai/Qwen/Qwen2.5-72B-Instruct-Turbo","together_ai/Qwen/Qwen2.5-7B-Instruct-Turbo","together_ai/Qwen/Qwen3-235B-A22B-Instruct-2507-tput","together_ai/Qwen/Qwen3-235B-A22B-Thinking-2507","together_ai/Qwen/Qwen3-235B-A22B-fp8-tput","together_ai/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8","together_ai/deepseek-ai/DeepSeek-R1","together_ai/deepseek-ai/DeepSeek-R1-0528-tput","together_ai/deepseek-ai/DeepSeek-V3","together_ai/deepseek-ai/DeepSeek-V3.1","together_ai/meta-llama/Llama-3.2-3B-Instruct-Turbo","together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo","together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo-Free","together_ai/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8","together_ai/meta-llama/Llama-4-Scout-17B-16E-Instruct","together_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo","together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo","together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo","together_ai/mistralai/Mistral-7B-Instruct-v0.1","together_ai/mistralai/Mistral-Small-24B-Instruct-2501","together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1","together_ai/moonshotai/Kimi-K2-Instruct","together_ai/openai/gpt-oss-120b","together_ai/openai/gpt-oss-20b","together_ai/togethercomputer/CodeLlama-34b-Instruct","together_ai/zai-org/GLM-4.5-Air-FP8","together_ai/moonshotai/Kimi-K2-Instruct-0905","together_ai/Qwen/Qwen3-Next-80B-A3B-Instruct","together_ai/Qwen/Qwen3-Next-80B-A3B-Thinking","tts-1","tts-1-hd","us.amazon.nova-lite-v1:0","us.amazon.nova-micro-v1:0","us.amazon.nova-premier-v1:0","us.amazon.nova-pro-v1:0","us.anthropic.claude-3-5-haiku-20241022-v1:0","us.anthropic.claude-haiku-4-5-20251001-v1:0","us.anthropic.claude-3-5-sonnet-20240620-v1:0","us.anthropic.claude-3-5-sonnet-20241022-v2:0","us.anthropic.claude-3-7-sonnet-20250219-v1:0","us.anthropic.claude-3-haiku-20240307-v1:0","us.anthropic.claude-3-opus-20240229-v1:0","us.anthropic.claude-3-sonnet-20240229-v1:0","us.anthropic.claude-opus-4-1-20250805-v1:0","us.anthropic.claude-sonnet-4-5-20250929-v1:0","au.anthropic.claude-haiku-4-5-20251001-v1:0","us.anthropic.claude-opus-4-20250514-v1:0","us.anthropic.claude-sonnet-4-20250514-v1:0","us.deepseek.r1-v1:0","us.meta.llama3-1-405b-instruct-v1:0","us.meta.llama3-1-70b-instruct-v1:0","us.meta.llama3-1-8b-instruct-v1:0","us.meta.llama3-2-11b-instruct-v1:0","us.meta.llama3-2-1b-instruct-v1:0","us.meta.llama3-2-3b-instruct-v1:0","us.meta.llama3-2-90b-instruct-v1:0","us.meta.llama3-3-70b-instruct-v1:0","us.meta.llama4-maverick-17b-instruct-v1:0","us.meta.llama4-scout-17b-instruct-v1:0","us.mistral.pixtral-large-2502-v1:0","v0/v0-1.0-md","v0/v0-1.5-lg","v0/v0-1.5-md","vercel_ai_gateway/alibaba/qwen-3-14b","vercel_ai_gateway/glm-4.6","vercel_ai_gateway/alibaba/qwen-3-235b","vercel_ai_gateway/alibaba/qwen-3-30b","vercel_ai_gateway/alibaba/qwen-3-32b","vercel_ai_gateway/alibaba/qwen3-coder","vercel_ai_gateway/amazon/nova-lite","vercel_ai_gateway/amazon/nova-micro","vercel_ai_gateway/amazon/nova-pro","vercel_ai_gateway/amazon/titan-embed-text-v2","vercel_ai_gateway/anthropic/claude-3-haiku","vercel_ai_gateway/anthropic/claude-3-opus","vercel_ai_gateway/anthropic/claude-3.5-haiku","vercel_ai_gateway/anthropic/claude-3.5-sonnet","vercel_ai_gateway/anthropic/claude-3.7-sonnet","vercel_ai_gateway/anthropic/claude-4-opus","vercel_ai_gateway/anthropic/claude-4-sonnet","vercel_ai_gateway/cohere/command-a","vercel_ai_gateway/cohere/command-r","vercel_ai_gateway/cohere/command-r-plus","vercel_ai_gateway/cohere/embed-v4.0","vercel_ai_gateway/deepseek/deepseek-r1","vercel_ai_gateway/deepseek/deepseek-r1-distill-llama-70b","vercel_ai_gateway/deepseek/deepseek-v3","vercel_ai_gateway/google/gemini-2.0-flash","vercel_ai_gateway/google/gemini-2.0-flash-lite","vercel_ai_gateway/google/gemini-2.5-flash","vercel_ai_gateway/google/gemini-2.5-pro","vercel_ai_gateway/google/gemini-embedding-001","vercel_ai_gateway/google/gemma-2-9b","vercel_ai_gateway/google/text-embedding-005","vercel_ai_gateway/google/text-multilingual-embedding-002","vercel_ai_gateway/inception/mercury-coder-small","vercel_ai_gateway/meta/llama-3-70b","vercel_ai_gateway/meta/llama-3-8b","vercel_ai_gateway/meta/llama-3.1-70b","vercel_ai_gateway/meta/llama-3.1-8b","vercel_ai_gateway/meta/llama-3.2-11b","vercel_ai_gateway/meta/llama-3.2-1b","vercel_ai_gateway/meta/llama-3.2-3b","vercel_ai_gateway/meta/llama-3.2-90b","vercel_ai_gateway/meta/llama-3.3-70b","vercel_ai_gateway/meta/llama-4-maverick","vercel_ai_gateway/meta/llama-4-scout","vercel_ai_gateway/mistral/codestral","vercel_ai_gateway/mistral/codestral-embed","vercel_ai_gateway/mistral/devstral-small","vercel_ai_gateway/mistral/magistral-medium","vercel_ai_gateway/mistral/magistral-small","vercel_ai_gateway/mistral/ministral-3b","vercel_ai_gateway/mistral/ministral-8b","vercel_ai_gateway/mistral/mistral-embed","vercel_ai_gateway/mistral/mistral-large","vercel_ai_gateway/mistral/mistral-saba-24b","vercel_ai_gateway/mistral/mistral-small","vercel_ai_gateway/mistral/mixtral-8x22b-instruct","vercel_ai_gateway/mistral/pixtral-12b","vercel_ai_gateway/mistral/pixtral-large","vercel_ai_gateway/moonshotai/kimi-k2","vercel_ai_gateway/morph/morph-v3-fast","vercel_ai_gateway/morph/morph-v3-large","vercel_ai_gateway/openai/gpt-3.5-turbo","vercel_ai_gateway/openai/gpt-3.5-turbo-instruct","vercel_ai_gateway/openai/gpt-4-turbo","vercel_ai_gateway/openai/gpt-4.1","vercel_ai_gateway/openai/gpt-4.1-mini","vercel_ai_gateway/openai/gpt-4.1-nano","vercel_ai_gateway/openai/gpt-4o","vercel_ai_gateway/openai/gpt-4o-mini","vercel_ai_gateway/openai/o1","vercel_ai_gateway/openai/o3","vercel_ai_gateway/openai/o3-mini","vercel_ai_gateway/openai/o4-mini","vercel_ai_gateway/openai/text-embedding-3-large","vercel_ai_gateway/openai/text-embedding-3-small","vercel_ai_gateway/openai/text-embedding-ada-002","vercel_ai_gateway/perplexity/sonar","vercel_ai_gateway/perplexity/sonar-pro","vercel_ai_gateway/perplexity/sonar-reasoning","vercel_ai_gateway/perplexity/sonar-reasoning-pro","vercel_ai_gateway/vercel/v0-1.0-md","vercel_ai_gateway/vercel/v0-1.5-md","vercel_ai_gateway/xai/grok-2","vercel_ai_gateway/xai/grok-2-vision","vercel_ai_gateway/xai/grok-3","vercel_ai_gateway/xai/grok-3-fast","vercel_ai_gateway/xai/grok-3-mini","vercel_ai_gateway/xai/grok-3-mini-fast","vercel_ai_gateway/xai/grok-4","vercel_ai_gateway/zai/glm-4.5","vercel_ai_gateway/zai/glm-4.5-air","vertex_ai/claude-3-5-haiku","vertex_ai/claude-3-5-haiku@20241022","vertex_ai/claude-haiku-4-5@20251001","vertex_ai/claude-3-5-sonnet","vertex_ai/claude-3-5-sonnet-v2","vertex_ai/claude-3-5-sonnet-v2@20241022","vertex_ai/claude-3-5-sonnet@20240620","vertex_ai/claude-3-7-sonnet@20250219","vertex_ai/claude-3-haiku","vertex_ai/claude-3-haiku@20240307","vertex_ai/claude-3-opus","vertex_ai/claude-3-opus@20240229","vertex_ai/claude-3-sonnet","vertex_ai/claude-3-sonnet@20240229","vertex_ai/claude-opus-4","vertex_ai/claude-opus-4-1","vertex_ai/claude-opus-4-1@20250805","vertex_ai/claude-sonnet-4-5","vertex_ai/claude-sonnet-4-5@20250929","vertex_ai/claude-opus-4@20250514","vertex_ai/claude-sonnet-4","vertex_ai/claude-sonnet-4@20250514","vertex_ai/codestral-2501","vertex_ai/codestral@2405","vertex_ai/codestral@latest","vertex_ai/deepseek-ai/deepseek-v3.1-maas","vertex_ai/deepseek-ai/deepseek-r1-0528-maas","vertex_ai/imagegeneration@006","vertex_ai/imagen-3.0-fast-generate-001","vertex_ai/imagen-3.0-generate-001","vertex_ai/imagen-3.0-generate-002","vertex_ai/imagen-4.0-fast-generate-001","vertex_ai/imagen-4.0-generate-001","vertex_ai/imagen-4.0-ultra-generate-001","vertex_ai/jamba-1.5","vertex_ai/jamba-1.5-large","vertex_ai/jamba-1.5-large@001","vertex_ai/jamba-1.5-mini","vertex_ai/jamba-1.5-mini@001","vertex_ai/meta/llama-3.1-405b-instruct-maas","vertex_ai/meta/llama-3.1-70b-instruct-maas","vertex_ai/meta/llama-3.1-8b-instruct-maas","vertex_ai/meta/llama-3.2-90b-vision-instruct-maas","vertex_ai/meta/llama-4-maverick-17b-128e-instruct-maas","vertex_ai/meta/llama-4-maverick-17b-16e-instruct-maas","vertex_ai/meta/llama-4-scout-17b-128e-instruct-maas","vertex_ai/meta/llama-4-scout-17b-16e-instruct-maas","vertex_ai/meta/llama3-405b-instruct-maas","vertex_ai/meta/llama3-70b-instruct-maas","vertex_ai/meta/llama3-8b-instruct-maas","vertex_ai/mistral-large-2411","vertex_ai/mistral-large@2407","vertex_ai/mistral-large@2411-001","vertex_ai/mistral-large@latest","vertex_ai/mistral-nemo@2407","vertex_ai/mistral-nemo@latest","vertex_ai/mistral-small-2503","vertex_ai/mistral-small-2503@001","vertex_ai/openai/gpt-oss-120b-maas","vertex_ai/openai/gpt-oss-20b-maas","vertex_ai/qwen/qwen3-235b-a22b-instruct-2507-maas","vertex_ai/qwen/qwen3-coder-480b-a35b-instruct-maas","vertex_ai/qwen/qwen3-next-80b-a3b-instruct-maas","vertex_ai/qwen/qwen3-next-80b-a3b-thinking-maas","vertex_ai/veo-2.0-generate-001","vertex_ai/veo-3.0-fast-generate-preview","vertex_ai/veo-3.0-generate-preview","voyage/rerank-2","voyage/rerank-2-lite","voyage/voyage-2","voyage/voyage-3","voyage/voyage-3-large","voyage/voyage-3-lite","voyage/voyage-code-2","voyage/voyage-code-3","voyage/voyage-context-3","voyage/voyage-finance-2","voyage/voyage-large-2","voyage/voyage-law-2","voyage/voyage-lite-01","voyage/voyage-lite-02-instruct","voyage/voyage-multimodal-3","wandb/openai/gpt-oss-120b","wandb/openai/gpt-oss-20b","wandb/zai-org/GLM-4.5","wandb/Qwen/Qwen3-235B-A22B-Instruct-2507","wandb/Qwen/Qwen3-Coder-480B-A35B-Instruct","wandb/Qwen/Qwen3-235B-A22B-Thinking-2507","wandb/moonshotai/Kimi-K2-Instruct","wandb/meta-llama/Llama-3.1-8B-Instruct","wandb/deepseek-ai/DeepSeek-V3.1","wandb/deepseek-ai/DeepSeek-R1-0528","wandb/deepseek-ai/DeepSeek-V3-0324","wandb/meta-llama/Llama-3.3-70B-Instruct","wandb/meta-llama/Llama-4-Scout-17B-16E-Instruct","wandb/microsoft/Phi-4-mini-instruct","watsonx/ibm/granite-3-8b-instruct","watsonx/mistralai/mistral-large","watsonx/bigscience/mt0-xxl-13b","watsonx/core42/jais-13b-chat","watsonx/google/flan-t5-xl-3b","watsonx/ibm/granite-13b-chat-v2","watsonx/ibm/granite-13b-instruct-v2","watsonx/ibm/granite-3-3-8b-instruct","watsonx/ibm/granite-4-h-small","watsonx/ibm/granite-guardian-3-2-2b","watsonx/ibm/granite-guardian-3-3-8b","watsonx/ibm/granite-ttm-1024-96-r2","watsonx/ibm/granite-ttm-1536-96-r2","watsonx/ibm/granite-ttm-512-96-r2","watsonx/ibm/granite-vision-3-2-2b","watsonx/meta-llama/llama-3-2-11b-vision-instruct","watsonx/meta-llama/llama-3-2-1b-instruct","watsonx/meta-llama/llama-3-2-3b-instruct","watsonx/meta-llama/llama-3-2-90b-vision-instruct","watsonx/meta-llama/llama-3-3-70b-instruct","watsonx/meta-llama/llama-4-maverick-17b","watsonx/meta-llama/llama-guard-3-11b-vision","watsonx/mistralai/mistral-medium-2505","watsonx/mistralai/mistral-small-2503","watsonx/mistralai/mistral-small-3-1-24b-instruct-2503","watsonx/mistralai/pixtral-12b-2409","watsonx/openai/gpt-oss-120b","watsonx/sdaia/allam-1-13b-instruct","whisper-1","xai/grok-2","xai/grok-2-1212","xai/grok-2-latest","xai/grok-2-vision","xai/grok-2-vision-1212","xai/grok-2-vision-latest","xai/grok-3","xai/grok-3-beta","xai/grok-3-fast-beta","xai/grok-3-fast-latest","xai/grok-3-latest","xai/grok-3-mini","xai/grok-3-mini-beta","xai/grok-3-mini-fast","xai/grok-3-mini-fast-beta","xai/grok-3-mini-fast-latest","xai/grok-3-mini-latest","xai/grok-4","xai/grok-4-fast-reasoning","xai/grok-4-fast-non-reasoning","xai/grok-4-0709","xai/grok-4-latest","xai/grok-beta","xai/grok-code-fast","xai/grok-code-fast-1","xai/grok-code-fast-1-0825","xai/grok-vision-beta"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"gpt-4o-mini"},"user_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"User Message","dynamic":false,"info":"User message to pass to the run.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"user_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"AstraDB":{"base_classes":["Data","DataFrame","VectorStore"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Ingest and search documents in Astra DB","display_name":"Astra DB","documentation":"https://docs.langflow.org/bundles-datastax#astra-db","edited":false,"field_order":["token","environment","database_name","api_endpoint","keyspace","collection_name","embedding_model","ingest_data","search_query","should_cache_vector_store","search_method","reranker","lexical_terms","number_of_results","search_type","search_score_threshold","advanced_search_filter","autodetect_collection","content_field","deletion_field","ignore_invalid_documents","astradb_vectorstore_kwargs"],"frozen":false,"icon":"AstraDB","legacy":false,"metadata":{"code_hash":"2b63a735fb89","dependencies":{"dependencies":[{"name":"astrapy","version":"2.1.0"},{"name":"langchain_astradb","version":"0.6.1"},{"name":"langchain_core","version":"0.3.79"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.datastax.astradb_vectorstore.AstraDBVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Vector Store Connection","group_outputs":false,"hidden":false,"method":"as_vector_store","name":"vectorstoreconnection","selected":"VectorStore","tool_mode":true,"types":["VectorStore"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","advanced_search_filter":{"_input_type":"NestedDictInput","advanced":true,"display_name":"Search Metadata Filter","dynamic":false,"info":"Optional dictionary of filters to apply to the search query.","list":false,"list_add_label":"Add More","name":"advanced_search_filter","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"NestedDict","value":{}},"api_endpoint":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Astra DB API Endpoint","dynamic":false,"external_options":{},"info":"The API Endpoint for the Astra DB instance. Supercedes database selection.","name":"api_endpoint","options":[],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"astradb_vectorstore_kwargs":{"_input_type":"NestedDictInput","advanced":true,"display_name":"AstraDBVectorStore Parameters","dynamic":false,"info":"Optional dictionary of additional parameters for the AstraDBVectorStore.","list":false,"list_add_label":"Add More","name":"astradb_vectorstore_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"NestedDict","value":{}},"autodetect_collection":{"_input_type":"BoolInput","advanced":true,"display_name":"Autodetect Collection","dynamic":false,"info":"Boolean flag to determine whether to autodetect the collection.","list":false,"list_add_label":"Add More","name":"autodetect_collection","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import re\nfrom collections import defaultdict\nfrom dataclasses import asdict, dataclass, field\n\nfrom astrapy import DataAPIClient, Database\nfrom astrapy.data.info.reranking import RerankServiceOptions\nfrom astrapy.info import CollectionDescriptor, CollectionLexicalOptions, CollectionRerankOptions\nfrom langchain_astradb import AstraDBVectorStore, VectorServiceOptions\nfrom langchain_astradb.utils.astradb import HybridSearchMode, _AstraDBCollectionEnvironment\nfrom langchain_core.documents import Document\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.base.vectorstores.vector_store_connection_decorator import vector_store_connection\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.inputs.inputs import FloatInput, NestedDictInput\nfrom lfx.io import (\n    BoolInput,\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    QueryInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom lfx.schema.data import Data\nfrom lfx.serialization import serialize\nfrom lfx.utils.version import get_version_info\n\n\n@vector_store_connection\nclass AstraDBVectorStoreComponent(LCVectorStoreComponent):\n    display_name: str = \"Astra DB\"\n    description: str = \"Ingest and search documents in Astra DB\"\n    documentation: str = \"https://docs.langflow.org/bundles-datastax#astra-db\"\n    name = \"AstraDB\"\n    icon: str = \"AstraDB\"\n\n    _cached_vector_store: AstraDBVectorStore | None = None\n\n    @dataclass\n    class NewDatabaseInput:\n        functionality: str = \"create\"\n        fields: dict[str, dict] = field(\n            default_factory=lambda: {\n                \"data\": {\n                    \"node\": {\n                        \"name\": \"create_database\",\n                        \"description\": \"Please allow several minutes for creation to complete.\",\n                        \"display_name\": \"Create new database\",\n                        \"field_order\": [\"01_new_database_name\", \"02_cloud_provider\", \"03_region\"],\n                        \"template\": {\n                            \"01_new_database_name\": StrInput(\n                                name=\"new_database_name\",\n                                display_name=\"Name\",\n                                info=\"Name of the new database to create in Astra DB.\",\n                                required=True,\n                            ),\n                            \"02_cloud_provider\": DropdownInput(\n                                name=\"cloud_provider\",\n                                display_name=\"Cloud provider\",\n                                info=\"Cloud provider for the new database.\",\n                                options=[],\n                                required=True,\n                                real_time_refresh=True,\n                            ),\n                            \"03_region\": DropdownInput(\n                                name=\"region\",\n                                display_name=\"Region\",\n                                info=\"Region for the new database.\",\n                                options=[],\n                                required=True,\n                            ),\n                        },\n                    },\n                }\n            }\n        )\n\n    @dataclass\n    class NewCollectionInput:\n        functionality: str = \"create\"\n        fields: dict[str, dict] = field(\n            default_factory=lambda: {\n                \"data\": {\n                    \"node\": {\n                        \"name\": \"create_collection\",\n                        \"description\": \"Please allow several seconds for creation to complete.\",\n                        \"display_name\": \"Create new collection\",\n                        \"field_order\": [\n                            \"01_new_collection_name\",\n                            \"02_embedding_generation_provider\",\n                            \"03_embedding_generation_model\",\n                            \"04_dimension\",\n                        ],\n                        \"template\": {\n                            \"01_new_collection_name\": StrInput(\n                                name=\"new_collection_name\",\n                                display_name=\"Name\",\n                                info=\"Name of the new collection to create in Astra DB.\",\n                                required=True,\n                            ),\n                            \"02_embedding_generation_provider\": DropdownInput(\n                                name=\"embedding_generation_provider\",\n                                display_name=\"Embedding generation method\",\n                                info=\"Provider to use for generating embeddings.\",\n                                helper_text=(\n                                    \"To create collections with more embedding provider options, go to \"\n                                    '<a class=\"underline\" href=\"https://astra.datastax.com/\" target=\" _blank\" '\n                                    'rel=\"noopener noreferrer\">your database in Astra DB</a>'\n                                ),\n                                real_time_refresh=True,\n                                required=True,\n                                options=[],\n                            ),\n                            \"03_embedding_generation_model\": DropdownInput(\n                                name=\"embedding_generation_model\",\n                                display_name=\"Embedding model\",\n                                info=\"Model to use for generating embeddings.\",\n                                real_time_refresh=True,\n                                options=[],\n                            ),\n                            \"04_dimension\": IntInput(\n                                name=\"dimension\",\n                                display_name=\"Dimensions\",\n                                info=\"Dimensions of the embeddings to generate.\",\n                                value=None,\n                            ),\n                        },\n                    },\n                }\n            }\n        )\n\n    inputs = [\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n            required=True,\n            real_time_refresh=True,\n            input_types=[],\n        ),\n        DropdownInput(\n            name=\"environment\",\n            display_name=\"Environment\",\n            info=\"The environment for the Astra DB API Endpoint.\",\n            options=[\"prod\", \"test\", \"dev\"],\n            value=\"prod\",\n            advanced=True,\n            real_time_refresh=True,\n            combobox=True,\n        ),\n        DropdownInput(\n            name=\"database_name\",\n            display_name=\"Database\",\n            info=\"The Database name for the Astra DB instance.\",\n            required=True,\n            refresh_button=True,\n            real_time_refresh=True,\n            dialog_inputs=asdict(NewDatabaseInput()),\n            combobox=True,\n        ),\n        DropdownInput(\n            name=\"api_endpoint\",\n            display_name=\"Astra DB API Endpoint\",\n            info=\"The API Endpoint for the Astra DB instance. Supercedes database selection.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"keyspace\",\n            display_name=\"Keyspace\",\n            info=\"Optional keyspace within Astra DB to use for the collection.\",\n            advanced=True,\n            options=[],\n            real_time_refresh=True,\n        ),\n        DropdownInput(\n            name=\"collection_name\",\n            display_name=\"Collection\",\n            info=\"The name of the collection within Astra DB where the vectors will be stored.\",\n            required=True,\n            refresh_button=True,\n            real_time_refresh=True,\n            dialog_inputs=asdict(NewCollectionInput()),\n            combobox=True,\n            show=False,\n        ),\n        HandleInput(\n            name=\"embedding_model\",\n            display_name=\"Embedding Model\",\n            input_types=[\"Embeddings\"],\n            info=\"Specify the Embedding Model. Not required for Astra Vectorize collections.\",\n            required=False,\n            show=True,\n        ),\n        *LCVectorStoreComponent.inputs,\n        DropdownInput(\n            name=\"search_method\",\n            display_name=\"Search Method\",\n            info=(\n                \"Determine how your content is matched: Vector finds semantic similarity, \"\n                \"and Hybrid Search (suggested) combines both approaches \"\n                \"with a reranker.\"\n            ),\n            options=[\"Hybrid Search\", \"Vector Search\"],  # TODO: Restore Lexical Search?\n            options_metadata=[{\"icon\": \"SearchHybrid\"}, {\"icon\": \"SearchVector\"}],\n            value=\"Vector Search\",\n            advanced=True,\n            real_time_refresh=True,\n        ),\n        DropdownInput(\n            name=\"reranker\",\n            display_name=\"Reranker\",\n            info=\"Post-retrieval model that re-scores results for optimal relevance ranking.\",\n            show=False,\n            toggle=True,\n        ),\n        QueryInput(\n            name=\"lexical_terms\",\n            display_name=\"Lexical Terms\",\n            info=\"Add additional terms/keywords to augment search precision.\",\n            placeholder=\"Enter terms to search...\",\n            separator=\" \",\n            show=False,\n            value=\"\",\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Search Results\",\n            info=\"Number of search results to return.\",\n            advanced=True,\n            value=4,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            info=\"Search type to use\",\n            options=[\"Similarity\", \"Similarity with score threshold\", \"MMR (Max Marginal Relevance)\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results. \"\n            \"(when using 'Similarity with score threshold')\",\n            value=0,\n            advanced=True,\n        ),\n        NestedDictInput(\n            name=\"advanced_search_filter\",\n            display_name=\"Search Metadata Filter\",\n            info=\"Optional dictionary of filters to apply to the search query.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"autodetect_collection\",\n            display_name=\"Autodetect Collection\",\n            info=\"Boolean flag to determine whether to autodetect the collection.\",\n            advanced=True,\n            value=True,\n        ),\n        StrInput(\n            name=\"content_field\",\n            display_name=\"Content Field\",\n            info=\"Field to use as the text content field for the vector store.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"deletion_field\",\n            display_name=\"Deletion Based On Field\",\n            info=\"When this parameter is provided, documents in the target collection with \"\n            \"metadata field values matching the input metadata field value will be deleted \"\n            \"before new data is loaded.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"ignore_invalid_documents\",\n            display_name=\"Ignore Invalid Documents\",\n            info=\"Boolean flag to determine whether to ignore invalid documents at runtime.\",\n            advanced=True,\n        ),\n        NestedDictInput(\n            name=\"astradb_vectorstore_kwargs\",\n            display_name=\"AstraDBVectorStore Parameters\",\n            info=\"Optional dictionary of additional parameters for the AstraDBVectorStore.\",\n            advanced=True,\n        ),\n    ]\n\n    @classmethod\n    def map_cloud_providers(cls):\n        # TODO: Programmatically fetch the regions for each cloud provider\n        return {\n            \"dev\": {\n                \"Amazon Web Services\": {\n                    \"id\": \"aws\",\n                    \"regions\": [\"us-west-2\"],\n                },\n                \"Google Cloud Platform\": {\n                    \"id\": \"gcp\",\n                    \"regions\": [\"us-central1\", \"europe-west4\"],\n                },\n            },\n            \"test\": {\n                \"Google Cloud Platform\": {\n                    \"id\": \"gcp\",\n                    \"regions\": [\"us-central1\"],\n                },\n            },\n            \"prod\": {\n                \"Amazon Web Services\": {\n                    \"id\": \"aws\",\n                    \"regions\": [\"us-east-2\", \"ap-south-1\", \"eu-west-1\"],\n                },\n                \"Google Cloud Platform\": {\n                    \"id\": \"gcp\",\n                    \"regions\": [\"us-east1\"],\n                },\n                \"Microsoft Azure\": {\n                    \"id\": \"azure\",\n                    \"regions\": [\"westus3\"],\n                },\n            },\n        }\n\n    @classmethod\n    def get_vectorize_providers(cls, token: str, environment: str | None = None, api_endpoint: str | None = None):\n        try:\n            # Get the admin object\n            client = DataAPIClient(environment=environment)\n            admin_client = client.get_admin()\n            db_admin = admin_client.get_database_admin(api_endpoint, token=token)\n\n            # Get the list of embedding providers\n            embedding_providers = db_admin.find_embedding_providers()\n\n            vectorize_providers_mapping = {}\n            # Map the provider display name to the provider key and models\n            for provider_key, provider_data in embedding_providers.embedding_providers.items():\n                # Get the provider display name and models\n                display_name = provider_data.display_name\n                models = [model.name for model in provider_data.models]\n\n                # Build our mapping\n                vectorize_providers_mapping[display_name] = [provider_key, models]\n\n            # Sort the resulting dictionary\n            return defaultdict(list, dict(sorted(vectorize_providers_mapping.items())))\n        except Exception as _:  # noqa: BLE001\n            return {}\n\n    @classmethod\n    async def create_database_api(\n        cls,\n        new_database_name: str,\n        cloud_provider: str,\n        region: str,\n        token: str,\n        environment: str | None = None,\n        keyspace: str | None = None,\n    ):\n        client = DataAPIClient(environment=environment)\n\n        # Get the admin object\n        admin_client = client.get_admin(token=token)\n\n        # Get the environment, set to prod if null like\n        my_env = environment or \"prod\"\n\n        # Raise a value error if name isn't provided\n        if not new_database_name:\n            msg = \"Database name is required to create a new database.\"\n            raise ValueError(msg)\n\n        # Call the create database function\n        return await admin_client.async_create_database(\n            name=new_database_name,\n            cloud_provider=cls.map_cloud_providers()[my_env][cloud_provider][\"id\"],\n            region=region,\n            keyspace=keyspace,\n            wait_until_active=False,\n        )\n\n    @classmethod\n    async def create_collection_api(\n        cls,\n        new_collection_name: str,\n        token: str,\n        api_endpoint: str,\n        environment: str | None = None,\n        keyspace: str | None = None,\n        dimension: int | None = None,\n        embedding_generation_provider: str | None = None,\n        embedding_generation_model: str | None = None,\n        reranker: str | None = None,\n    ):\n        # Build vectorize options, if needed\n        vectorize_options = None\n        if not dimension:\n            providers = cls.get_vectorize_providers(token=token, environment=environment, api_endpoint=api_endpoint)\n            vectorize_options = VectorServiceOptions(\n                provider=providers.get(embedding_generation_provider, [None, []])[0],\n                model_name=embedding_generation_model,\n            )\n\n        # Raise a value error if name isn't provided\n        if not new_collection_name:\n            msg = \"Collection name is required to create a new collection.\"\n            raise ValueError(msg)\n\n        # Define the base arguments being passed to the create collection function\n        base_args = {\n            \"collection_name\": new_collection_name,\n            \"token\": token,\n            \"api_endpoint\": api_endpoint,\n            \"keyspace\": keyspace,\n            \"environment\": environment,\n            \"embedding_dimension\": dimension,\n            \"collection_vector_service_options\": vectorize_options,\n        }\n\n        # Add optional arguments if the reranker is set\n        if reranker:\n            # Split the reranker field into a provider a model name\n            provider, _ = reranker.split(\"/\")\n            base_args[\"collection_rerank\"] = CollectionRerankOptions(\n                service=RerankServiceOptions(provider=provider, model_name=reranker),\n            )\n            base_args[\"collection_lexical\"] = CollectionLexicalOptions(analyzer=\"STANDARD\")\n\n        _AstraDBCollectionEnvironment(**base_args)\n\n    @classmethod\n    def get_database_list_static(cls, token: str, environment: str | None = None):\n        client = DataAPIClient(environment=environment)\n\n        # Get the admin object\n        admin_client = client.get_admin(token=token)\n\n        # Get the list of databases\n        db_list = admin_client.list_databases()\n\n        # Generate the api endpoint for each database\n        db_info_dict = {}\n        for db in db_list:\n            try:\n                # Get the API endpoint for the database\n                api_endpoints = [db_reg.api_endpoint for db_reg in db.regions]\n\n                # Get the number of collections\n                try:\n                    # Get the number of collections in the database\n                    num_collections = len(\n                        client.get_database(\n                            api_endpoints[0],\n                            token=token,\n                        ).list_collection_names()\n                    )\n                except Exception:  # noqa: BLE001\n                    if db.status != \"PENDING\":\n                        continue\n                    num_collections = 0\n\n                # Add the database to the dictionary\n                db_info_dict[db.name] = {\n                    \"api_endpoints\": api_endpoints,\n                    \"keyspaces\": db.keyspaces,\n                    \"collections\": num_collections,\n                    \"status\": db.status if db.status != \"ACTIVE\" else None,\n                    \"org_id\": db.org_id if db.org_id else None,\n                }\n            except Exception:  # noqa: BLE001\n                pass\n\n        return db_info_dict\n\n    def get_database_list(self):\n        return self.get_database_list_static(\n            token=self.token,\n            environment=self.environment,\n        )\n\n    @classmethod\n    def get_api_endpoint_static(\n        cls,\n        token: str,\n        environment: str | None = None,\n        api_endpoint: str | None = None,\n        database_name: str | None = None,\n    ):\n        # If the api_endpoint is set, return it\n        if api_endpoint:\n            return api_endpoint\n\n        # Check if the database_name is like a url\n        if database_name and database_name.startswith(\"https://\"):\n            return database_name\n\n        # If the database is not set, nothing we can do.\n        if not database_name:\n            return None\n\n        # Grab the database object\n        db = cls.get_database_list_static(token=token, environment=environment).get(database_name)\n        if not db:\n            return None\n\n        # Otherwise, get the URL from the database list\n        endpoints = db.get(\"api_endpoints\") or []\n        return endpoints[0] if endpoints else None\n\n    def get_api_endpoint(self):\n        return self.get_api_endpoint_static(\n            token=self.token,\n            environment=self.environment,\n            api_endpoint=self.api_endpoint,\n            database_name=self.database_name,\n        )\n\n    @classmethod\n    def get_database_id_static(cls, api_endpoint: str) -> str | None:\n        # Pattern matches standard UUID format: 8-4-4-4-12 hexadecimal characters\n        uuid_pattern = r\"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n        match = re.search(uuid_pattern, api_endpoint)\n\n        return match.group(0) if match else None\n\n    def get_database_id(self):\n        return self.get_database_id_static(api_endpoint=self.get_api_endpoint())\n\n    def get_keyspace(self):\n        keyspace = self.keyspace\n\n        if keyspace:\n            return keyspace.strip()\n\n        return \"default_keyspace\"\n\n    def get_database_object(self, api_endpoint: str | None = None):\n        try:\n            client = DataAPIClient(environment=self.environment)\n\n            return client.get_database(\n                api_endpoint or self.get_api_endpoint(),\n                token=self.token,\n                keyspace=self.get_keyspace(),\n            )\n        except Exception as e:\n            msg = f\"Error fetching database object: {e}\"\n            raise ValueError(msg) from e\n\n    def collection_data(self, collection_name: str, database: Database | None = None):\n        try:\n            if not database:\n                client = DataAPIClient(environment=self.environment)\n\n                database = client.get_database(\n                    self.get_api_endpoint(),\n                    token=self.token,\n                    keyspace=self.get_keyspace(),\n                )\n\n            collection = database.get_collection(collection_name)\n\n            return collection.estimated_document_count()\n        except Exception as e:  # noqa: BLE001\n            self.log(f\"Error checking collection data: {e}\")\n\n            return None\n\n    def _initialize_database_options(self):\n        try:\n            return [\n                {\n                    \"name\": name,\n                    \"status\": info[\"status\"],\n                    \"collections\": info[\"collections\"],\n                    \"api_endpoints\": info[\"api_endpoints\"],\n                    \"keyspaces\": info[\"keyspaces\"],\n                    \"org_id\": info[\"org_id\"],\n                }\n                for name, info in self.get_database_list().items()\n            ]\n        except Exception as e:\n            msg = f\"Error fetching database options: {e}\"\n            raise ValueError(msg) from e\n\n    @classmethod\n    def get_provider_icon(cls, collection: CollectionDescriptor | None = None, provider_name: str | None = None) -> str:\n        # Get the provider name from the collection\n        provider_name = provider_name or (\n            collection.definition.vector.service.provider\n            if (\n                collection\n                and collection.definition\n                and collection.definition.vector\n                and collection.definition.vector.service\n            )\n            else None\n        )\n\n        # If there is no provider, use the vector store icon\n        if not provider_name or provider_name.lower() == \"bring your own\":\n            return \"vectorstores\"\n\n        # Map provider casings\n        case_map = {\n            \"nvidia\": \"NVIDIA\",\n            \"openai\": \"OpenAI\",\n            \"amazon bedrock\": \"AmazonBedrockEmbeddings\",\n            \"azure openai\": \"AzureOpenAiEmbeddings\",\n            \"cohere\": \"Cohere\",\n            \"jina ai\": \"JinaAI\",\n            \"mistral ai\": \"MistralAI\",\n            \"upstage\": \"Upstage\",\n            \"voyage ai\": \"VoyageAI\",\n        }\n\n        # Adjust the casing on some like nvidia\n        return case_map[provider_name.lower()] if provider_name.lower() in case_map else provider_name.title()\n\n    def _initialize_collection_options(self, api_endpoint: str | None = None):\n        # Nothing to generate if we don't have an API endpoint yet\n        api_endpoint = api_endpoint or self.get_api_endpoint()\n        if not api_endpoint:\n            return []\n\n        # Retrieve the database object\n        database = self.get_database_object(api_endpoint=api_endpoint)\n\n        # Get the list of collections\n        collection_list = database.list_collections(keyspace=self.get_keyspace())\n\n        # Return the list of collections and metadata associated\n        return [\n            {\n                \"name\": col.name,\n                \"records\": self.collection_data(collection_name=col.name, database=database),\n                \"provider\": (\n                    col.definition.vector.service.provider\n                    if col.definition.vector and col.definition.vector.service\n                    else None\n                ),\n                \"icon\": self.get_provider_icon(collection=col),\n                \"model\": (\n                    col.definition.vector.service.model_name\n                    if col.definition.vector and col.definition.vector.service\n                    else None\n                ),\n            }\n            for col in collection_list\n        ]\n\n    def reset_provider_options(self, build_config: dict) -> dict:\n        \"\"\"Reset provider options and related configurations in the build_config dictionary.\"\"\"\n        # Extract template path for cleaner access\n        template = build_config[\"collection_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"]\n\n        # Get vectorize providers\n        vectorize_providers_api = self.get_vectorize_providers(\n            token=self.token,\n            environment=self.environment,\n            api_endpoint=build_config[\"api_endpoint\"][\"value\"],\n        )\n\n        # Create a new dictionary with \"Bring your own\" first\n        vectorize_providers: dict[str, list[list[str]]] = {\"Bring your own\": [[], []]}\n\n        # Add the remaining items (only Nvidia) from the original dictionary\n        vectorize_providers.update(\n            {\n                k: v\n                for k, v in vectorize_providers_api.items()\n                if k.lower() in [\"nvidia\"]  # TODO: Eventually support more\n            }\n        )\n\n        # Set provider options\n        provider_field = \"02_embedding_generation_provider\"\n        template[provider_field][\"options\"] = list(vectorize_providers.keys())\n\n        # Add metadata for each provider option\n        template[provider_field][\"options_metadata\"] = [\n            {\"icon\": self.get_provider_icon(provider_name=provider)} for provider in template[provider_field][\"options\"]\n        ]\n\n        # Get selected embedding provider\n        embedding_provider = template[provider_field][\"value\"]\n        is_bring_your_own = embedding_provider and embedding_provider == \"Bring your own\"\n\n        # Configure embedding model field\n        model_field = \"03_embedding_generation_model\"\n        template[model_field].update(\n            {\n                \"options\": vectorize_providers.get(embedding_provider, [[], []])[1],\n                \"placeholder\": \"Bring your own\" if is_bring_your_own else None,\n                \"readonly\": is_bring_your_own,\n                \"required\": not is_bring_your_own,\n                \"value\": None,\n            }\n        )\n\n        # If this is a bring your own, set dimensions to 0\n        return self.reset_dimension_field(build_config)\n\n    def reset_dimension_field(self, build_config: dict) -> dict:\n        \"\"\"Reset dimension field options based on provided configuration.\"\"\"\n        # Extract template path for cleaner access\n        template = build_config[\"collection_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"]\n\n        # Get selected embedding model\n        provider_field = \"02_embedding_generation_provider\"\n        embedding_provider = template[provider_field][\"value\"]\n        is_bring_your_own = embedding_provider and embedding_provider == \"Bring your own\"\n\n        # Configure dimension field\n        dimension_field = \"04_dimension\"\n        dimension_value = 1024 if not is_bring_your_own else None  # TODO: Dynamically figure this out\n        template[dimension_field].update(\n            {\n                \"placeholder\": dimension_value,\n                \"value\": dimension_value,\n                \"readonly\": not is_bring_your_own,\n                \"required\": is_bring_your_own,\n            }\n        )\n\n        return build_config\n\n    def reset_collection_list(self, build_config: dict) -> dict:\n        \"\"\"Reset collection list options based on provided configuration.\"\"\"\n        # Get collection options\n        collection_options = self._initialize_collection_options(api_endpoint=build_config[\"api_endpoint\"][\"value\"])\n        # Update collection configuration\n        collection_config = build_config[\"collection_name\"]\n        collection_config.update(\n            {\n                \"options\": [col[\"name\"] for col in collection_options],\n                \"options_metadata\": [{k: v for k, v in col.items() if k != \"name\"} for col in collection_options],\n            }\n        )\n\n        # Reset selected collection if not in options\n        if collection_config[\"value\"] not in collection_config[\"options\"]:\n            collection_config[\"value\"] = \"\"\n\n        # Set advanced status based on database selection\n        collection_config[\"show\"] = bool(build_config[\"database_name\"][\"value\"])\n\n        return build_config\n\n    def reset_database_list(self, build_config: dict) -> dict:\n        \"\"\"Reset database list options and related configurations.\"\"\"\n        # Get database options\n        database_options = self._initialize_database_options()\n\n        # Update cloud provider options\n        env = self.environment\n        template = build_config[\"database_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"]\n        template[\"02_cloud_provider\"][\"options\"] = list(self.map_cloud_providers()[env].keys())\n\n        # Update database configuration\n        database_config = build_config[\"database_name\"]\n        database_config.update(\n            {\n                \"options\": [db[\"name\"] for db in database_options],\n                \"options_metadata\": [{k: v for k, v in db.items() if k != \"name\"} for db in database_options],\n            }\n        )\n\n        # Reset selections if value not in options\n        if database_config[\"value\"] not in database_config[\"options\"]:\n            database_config[\"value\"] = \"\"\n            build_config[\"api_endpoint\"][\"options\"] = []\n            build_config[\"api_endpoint\"][\"value\"] = \"\"\n            build_config[\"collection_name\"][\"show\"] = False\n\n        # Set advanced status based on token presence\n        database_config[\"show\"] = bool(build_config[\"token\"][\"value\"])\n\n        return build_config\n\n    def reset_build_config(self, build_config: dict) -> dict:\n        \"\"\"Reset all build configuration options to default empty state.\"\"\"\n        # Reset database configuration\n        database_config = build_config[\"database_name\"]\n        database_config.update({\"options\": [], \"options_metadata\": [], \"value\": \"\", \"show\": False})\n        build_config[\"api_endpoint\"][\"options\"] = []\n        build_config[\"api_endpoint\"][\"value\"] = \"\"\n\n        # Reset hybrid search options\n        build_config[\"reranker\"][\"options\"] = []\n        build_config[\"reranker\"][\"value\"] = \"\"\n        build_config[\"reranker\"][\"show\"] = False\n        build_config[\"lexical_terms\"][\"value\"] = \"\"\n        build_config[\"lexical_terms\"][\"show\"] = False\n\n        # Reset collection configuration\n        collection_config = build_config[\"collection_name\"]\n        collection_config.update({\"options\": [], \"options_metadata\": [], \"value\": \"\", \"show\": False})\n\n        return build_config\n\n    def _handle_hybrid_search_options(self, build_config: dict) -> dict:\n        \"\"\"Set hybrid search options in the build configuration.\"\"\"\n        # Detect what hybrid options are available\n        # Get the admin object\n        client = DataAPIClient(environment=self.environment)\n        admin_client = client.get_admin()\n        db_admin = admin_client.get_database_admin(self.get_api_endpoint(), token=self.token)\n\n        # We will try to get the reranking providers to see if its hybrid emabled\n        try:\n            providers = db_admin.find_reranking_providers()\n            build_config[\"reranker\"][\"options\"] = [\n                model.name for provider_data in providers.reranking_providers.values() for model in provider_data.models\n            ]\n            build_config[\"reranker\"][\"options_metadata\"] = [\n                {\"icon\": self.get_provider_icon(provider_name=model.name.split(\"/\")[0])}\n                for provider in providers.reranking_providers.values()\n                for model in provider.models\n            ]\n            build_config[\"reranker\"][\"value\"] = build_config[\"reranker\"][\"options\"][0]\n\n            # Set the default search field to hybrid search\n            build_config[\"search_method\"][\"show\"] = True\n            build_config[\"search_method\"][\"options\"] = [\"Hybrid Search\", \"Vector Search\"]\n            build_config[\"search_method\"][\"value\"] = \"Hybrid Search\"\n        except Exception as _:  # noqa: BLE001\n            build_config[\"reranker\"][\"options\"] = []\n            build_config[\"reranker\"][\"options_metadata\"] = []\n\n            # Set the default search field to vector search\n            build_config[\"search_method\"][\"show\"] = False\n            build_config[\"search_method\"][\"options\"] = [\"Vector Search\"]\n            build_config[\"search_method\"][\"value\"] = \"Vector Search\"\n\n        return build_config\n\n    async def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        \"\"\"Update build configuration based on field name and value.\"\"\"\n        # Early return if no token provided\n        if not self.token:\n            return self.reset_build_config(build_config)\n\n        # Database creation callback\n        if field_name == \"database_name\" and isinstance(field_value, dict):\n            if \"01_new_database_name\" in field_value:\n                await self._create_new_database(build_config, field_value)\n                return self.reset_collection_list(build_config)\n            return self._update_cloud_regions(build_config, field_value)\n\n        # Collection creation callback\n        if field_name == \"collection_name\" and isinstance(field_value, dict):\n            # Case 1: New collection creation\n            if \"01_new_collection_name\" in field_value:\n                await self._create_new_collection(build_config, field_value)\n                return build_config\n\n            # Case 2: Update embedding provider options\n            if \"02_embedding_generation_provider\" in field_value:\n                return self.reset_provider_options(build_config)\n\n            # Case 3: Update dimension field\n            if \"03_embedding_generation_model\" in field_value:\n                return self.reset_dimension_field(build_config)\n\n        # Initial execution or token/environment change\n        first_run = field_name == \"collection_name\" and not field_value and not build_config[\"database_name\"][\"options\"]\n        if first_run or field_name in {\"token\", \"environment\"}:\n            return self.reset_database_list(build_config)\n\n        # Database selection change\n        if field_name == \"database_name\" and not isinstance(field_value, dict):\n            return self._handle_database_selection(build_config, field_value)\n\n        # Keyspace selection change\n        if field_name == \"keyspace\":\n            return self.reset_collection_list(build_config)\n\n        # Collection selection change\n        if field_name == \"collection_name\" and not isinstance(field_value, dict):\n            return self._handle_collection_selection(build_config, field_value)\n\n        # Search method selection change\n        if field_name == \"search_method\":\n            is_vector_search = field_value == \"Vector Search\"\n            is_autodetect = build_config[\"autodetect_collection\"][\"value\"]\n\n            # Configure lexical terms (same for both cases)\n            build_config[\"lexical_terms\"][\"show\"] = not is_vector_search\n            build_config[\"lexical_terms\"][\"value\"] = \"\" if is_vector_search else build_config[\"lexical_terms\"][\"value\"]\n\n            # Disable reranker disabling if hybrid search is selected\n            build_config[\"reranker\"][\"show\"] = not is_vector_search\n            build_config[\"reranker\"][\"toggle_disable\"] = not is_vector_search\n            build_config[\"reranker\"][\"toggle_value\"] = True\n            build_config[\"reranker\"][\"value\"] = build_config[\"reranker\"][\"options\"][0]\n\n            # Toggle search type and score threshold based on search method\n            build_config[\"search_type\"][\"show\"] = is_vector_search\n            build_config[\"search_score_threshold\"][\"show\"] = is_vector_search\n\n            # Make sure the search_type is set to \"Similarity\"\n            if not is_vector_search or is_autodetect:\n                build_config[\"search_type\"][\"value\"] = \"Similarity\"\n\n        return build_config\n\n    async def _create_new_database(self, build_config: dict, field_value: dict) -> None:\n        \"\"\"Create a new database and update build config options.\"\"\"\n        try:\n            await self.create_database_api(\n                new_database_name=field_value[\"01_new_database_name\"],\n                token=self.token,\n                keyspace=self.get_keyspace(),\n                environment=self.environment,\n                cloud_provider=field_value[\"02_cloud_provider\"],\n                region=field_value[\"03_region\"],\n            )\n        except Exception as e:\n            msg = f\"Error creating database: {e}\"\n            raise ValueError(msg) from e\n\n        build_config[\"database_name\"][\"options\"].append(field_value[\"01_new_database_name\"])\n        build_config[\"database_name\"][\"options_metadata\"].append(\n            {\n                \"status\": \"PENDING\",\n                \"collections\": 0,\n                \"api_endpoints\": [],\n                \"keyspaces\": [self.get_keyspace()],\n                \"org_id\": None,\n            }\n        )\n\n    def _update_cloud_regions(self, build_config: dict, field_value: dict) -> dict:\n        \"\"\"Update cloud provider regions in build config.\"\"\"\n        env = self.environment\n        cloud_provider = field_value[\"02_cloud_provider\"]\n\n        # Update the region options based on the selected cloud provider\n        template = build_config[\"database_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"]\n        template[\"03_region\"][\"options\"] = self.map_cloud_providers()[env][cloud_provider][\"regions\"]\n\n        # Reset the the 03_region value if it's not in the new options\n        if template[\"03_region\"][\"value\"] not in template[\"03_region\"][\"options\"]:\n            template[\"03_region\"][\"value\"] = None\n\n        return build_config\n\n    async def _create_new_collection(self, build_config: dict, field_value: dict) -> None:\n        \"\"\"Create a new collection and update build config options.\"\"\"\n        embedding_provider = field_value.get(\"02_embedding_generation_provider\")\n        try:\n            await self.create_collection_api(\n                new_collection_name=field_value[\"01_new_collection_name\"],\n                token=self.token,\n                api_endpoint=build_config[\"api_endpoint\"][\"value\"],\n                environment=self.environment,\n                keyspace=self.get_keyspace(),\n                dimension=field_value.get(\"04_dimension\") if embedding_provider == \"Bring your own\" else None,\n                embedding_generation_provider=embedding_provider,\n                embedding_generation_model=field_value.get(\"03_embedding_generation_model\"),\n                reranker=self.reranker,\n            )\n        except Exception as e:\n            msg = f\"Error creating collection: {e}\"\n            raise ValueError(msg) from e\n\n        provider = embedding_provider.lower() if embedding_provider and embedding_provider != \"Bring your own\" else None\n        build_config[\"collection_name\"].update(\n            {\n                \"value\": field_value[\"01_new_collection_name\"],\n                \"options\": build_config[\"collection_name\"][\"options\"] + [field_value[\"01_new_collection_name\"]],\n            }\n        )\n        build_config[\"embedding_model\"][\"show\"] = not bool(provider)\n        build_config[\"embedding_model\"][\"required\"] = not bool(provider)\n        build_config[\"collection_name\"][\"options_metadata\"].append(\n            {\n                \"records\": 0,\n                \"provider\": provider,\n                \"icon\": self.get_provider_icon(provider_name=provider),\n                \"model\": field_value.get(\"03_embedding_generation_model\"),\n            }\n        )\n\n        # Make sure we always show the reranker options if the collection is hybrid enabled\n        # And right now they always are\n        build_config[\"lexical_terms\"][\"show\"] = True\n\n    def _handle_database_selection(self, build_config: dict, field_value: str) -> dict:\n        \"\"\"Handle database selection and update related configurations.\"\"\"\n        build_config = self.reset_database_list(build_config)\n\n        # Reset collection list if database selection changes\n        if field_value not in build_config[\"database_name\"][\"options\"]:\n            build_config[\"database_name\"][\"value\"] = \"\"\n            return build_config\n\n        # Get the api endpoint for the selected database\n        index = build_config[\"database_name\"][\"options\"].index(field_value)\n        build_config[\"api_endpoint\"][\"options\"] = build_config[\"database_name\"][\"options_metadata\"][index][\n            \"api_endpoints\"\n        ]\n        build_config[\"api_endpoint\"][\"value\"] = build_config[\"database_name\"][\"options_metadata\"][index][\n            \"api_endpoints\"\n        ][0]\n\n        # Get the org_id for the selected database\n        org_id = build_config[\"database_name\"][\"options_metadata\"][index][\"org_id\"]\n        if not org_id:\n            return build_config\n\n        # Update the list of keyspaces based on the db info\n        build_config[\"keyspace\"][\"options\"] = build_config[\"database_name\"][\"options_metadata\"][index][\"keyspaces\"]\n        build_config[\"keyspace\"][\"value\"] = (\n            build_config[\"keyspace\"][\"options\"] and build_config[\"keyspace\"][\"options\"][0]\n            if build_config[\"keyspace\"][\"value\"] not in build_config[\"keyspace\"][\"options\"]\n            else build_config[\"keyspace\"][\"value\"]\n        )\n\n        # Get the database id for the selected database\n        db_id = self.get_database_id_static(api_endpoint=build_config[\"api_endpoint\"][\"value\"])\n        keyspace = self.get_keyspace()\n\n        # Update the helper text for the embedding provider field\n        template = build_config[\"collection_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"]\n        template[\"02_embedding_generation_provider\"][\"helper_text\"] = (\n            \"To create collections with more embedding provider options, go to \"\n            f'<a class=\"underline\" target=\"_blank\" rel=\"noopener noreferrer\" '\n            f'href=\"https://astra.datastax.com/org/{org_id}/database/{db_id}/data-explorer?createCollection=1&namespace={keyspace}\">'\n            \"your database in Astra DB</a>.\"\n        )\n\n        # Reset provider options\n        build_config = self.reset_provider_options(build_config)\n\n        # Handle hybrid search options\n        build_config = self._handle_hybrid_search_options(build_config)\n\n        return self.reset_collection_list(build_config)\n\n    def _handle_collection_selection(self, build_config: dict, field_value: str) -> dict:\n        \"\"\"Handle collection selection and update embedding options.\"\"\"\n        build_config[\"autodetect_collection\"][\"value\"] = True\n        build_config = self.reset_collection_list(build_config)\n\n        # Reset embedding model if collection selection changes\n        if field_value and field_value not in build_config[\"collection_name\"][\"options\"]:\n            build_config[\"collection_name\"][\"options\"].append(field_value)\n            build_config[\"collection_name\"][\"options_metadata\"].append(\n                {\n                    \"records\": 0,\n                    \"provider\": None,\n                    \"icon\": \"vectorstores\",\n                    \"model\": None,\n                }\n            )\n            build_config[\"autodetect_collection\"][\"value\"] = False\n\n        if not field_value:\n            return build_config\n\n        # Get the selected collection index\n        index = build_config[\"collection_name\"][\"options\"].index(field_value)\n\n        # Set the provider of the selected collection\n        provider = build_config[\"collection_name\"][\"options_metadata\"][index][\"provider\"]\n        build_config[\"embedding_model\"][\"show\"] = not bool(provider)\n        build_config[\"embedding_model\"][\"required\"] = not bool(provider)\n\n        # Grab the collection object\n        database = self.get_database_object(api_endpoint=build_config[\"api_endpoint\"][\"value\"])\n        collection = database.get_collection(\n            name=field_value,\n            keyspace=build_config[\"keyspace\"][\"value\"],\n        )\n\n        # Check if hybrid and lexical are enabled\n        col_options = collection.options()\n        hyb_enabled = col_options.rerank and col_options.rerank.enabled\n        lex_enabled = col_options.lexical and col_options.lexical.enabled\n        user_hyb_enabled = build_config[\"search_method\"][\"value\"] == \"Hybrid Search\"\n\n        # Reranker visible when both the collection supports it and the user selected Hybrid\n        hybrid_active = bool(hyb_enabled and user_hyb_enabled)\n        build_config[\"reranker\"][\"show\"] = hybrid_active\n        build_config[\"reranker\"][\"toggle_value\"] = hybrid_active\n        build_config[\"reranker\"][\"toggle_disable\"] = False  # allow user to toggle if visible\n\n        # If hybrid is active, lock search_type to \"Similarity\"\n        if hybrid_active:\n            build_config[\"search_type\"][\"value\"] = \"Similarity\"\n\n        # Show the lexical terms option only if the collection enables lexical search\n        build_config[\"lexical_terms\"][\"show\"] = bool(lex_enabled)\n\n        return build_config\n\n    @check_cached_vector_store\n    def build_vector_store(self):\n        try:\n            from langchain_astradb import AstraDBVectorStore\n        except ImportError as e:\n            msg = (\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n            raise ImportError(msg) from e\n\n        # Get the embedding model and additional params\n        embedding_params = {\"embedding\": self.embedding_model} if self.embedding_model else {}\n\n        # Get the additional parameters\n        additional_params = self.astradb_vectorstore_kwargs or {}\n\n        # Get Langflow version and platform information\n        __version__ = get_version_info()[\"version\"]\n        langflow_prefix = \"\"\n        # if os.getenv(\"AWS_EXECUTION_ENV\") == \"AWS_ECS_FARGATE\":  # TODO: More precise way of detecting\n        #     langflow_prefix = \"ds-\"\n\n        # Get the database object\n        database = self.get_database_object()\n        autodetect = self.collection_name in database.list_collection_names() and self.autodetect_collection\n\n        # Bundle up the auto-detect parameters\n        autodetect_params = {\n            \"autodetect_collection\": autodetect,\n            \"content_field\": (\n                self.content_field\n                if self.content_field and embedding_params\n                else (\n                    \"page_content\"\n                    if embedding_params\n                    and self.collection_data(collection_name=self.collection_name, database=database) == 0\n                    else None\n                )\n            ),\n            \"ignore_invalid_documents\": self.ignore_invalid_documents,\n        }\n\n        # Choose HybridSearchMode based on the selected param\n        hybrid_search_mode = HybridSearchMode.DEFAULT if self.search_method == \"Hybrid Search\" else HybridSearchMode.OFF\n\n        # Attempt to build the Vector Store object\n        try:\n            vector_store = AstraDBVectorStore(\n                # Astra DB Authentication Parameters\n                token=self.token,\n                api_endpoint=database.api_endpoint,\n                namespace=database.keyspace,\n                collection_name=self.collection_name,\n                environment=self.environment,\n                # Hybrid Search Parameters\n                hybrid_search=hybrid_search_mode,\n                # Astra DB Usage Tracking Parameters\n                ext_callers=[(f\"{langflow_prefix}langflow\", __version__)],\n                # Astra DB Vector Store Parameters\n                **autodetect_params,\n                **embedding_params,\n                **additional_params,\n            )\n        except Exception as e:\n            msg = f\"Error initializing AstraDBVectorStore: {e}\"\n            raise ValueError(msg) from e\n\n        # Add documents to the vector store\n        self._add_documents_to_vector_store(vector_store)\n\n        return vector_store\n\n    def _add_documents_to_vector_store(self, vector_store) -> None:\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                msg = \"Vector Store Inputs must be Data objects.\"\n                raise TypeError(msg)\n\n        documents = [\n            Document(page_content=doc.page_content, metadata=serialize(doc.metadata, to_str=True)) for doc in documents\n        ]\n\n        if documents and self.deletion_field:\n            self.log(f\"Deleting documents where {self.deletion_field}\")\n            try:\n                database = self.get_database_object()\n                collection = database.get_collection(self.collection_name, keyspace=database.keyspace)\n                delete_values = list({doc.metadata[self.deletion_field] for doc in documents})\n                self.log(f\"Deleting documents where {self.deletion_field} matches {delete_values}.\")\n                collection.delete_many({f\"metadata.{self.deletion_field}\": {\"$in\": delete_values}})\n            except Exception as e:\n                msg = f\"Error deleting documents from AstraDBVectorStore based on '{self.deletion_field}': {e}\"\n                raise ValueError(msg) from e\n\n        if documents:\n            self.log(f\"Adding {len(documents)} documents to the Vector Store.\")\n            try:\n                vector_store.add_documents(documents)\n            except Exception as e:\n                msg = f\"Error adding documents to AstraDBVectorStore: {e}\"\n                raise ValueError(msg) from e\n        else:\n            self.log(\"No documents to add to the Vector Store.\")\n\n    def _map_search_type(self) -> str:\n        search_type_mapping = {\n            \"Similarity with score threshold\": \"similarity_score_threshold\",\n            \"MMR (Max Marginal Relevance)\": \"mmr\",\n        }\n\n        return search_type_mapping.get(self.search_type, \"similarity\")\n\n    def _build_search_args(self):\n        # Clean up the search query\n        query = self.search_query if isinstance(self.search_query, str) and self.search_query.strip() else None\n        lexical_terms = self.lexical_terms or None\n\n        # Check if we have a search query, and if so set the args\n        if query:\n            args = {\n                \"query\": query,\n                \"search_type\": self._map_search_type(),\n                \"k\": self.number_of_results,\n                \"score_threshold\": self.search_score_threshold,\n                \"lexical_query\": lexical_terms,\n            }\n        elif self.advanced_search_filter:\n            args = {\n                \"n\": self.number_of_results,\n            }\n        else:\n            return {}\n\n        filter_arg = self.advanced_search_filter or {}\n        if filter_arg:\n            args[\"filter\"] = filter_arg\n\n        return args\n\n    def search_documents(self, vector_store=None) -> list[Data]:\n        vector_store = vector_store or self.build_vector_store()\n\n        self.log(f\"Search input: {self.search_query}\")\n        self.log(f\"Search type: {self.search_type}\")\n        self.log(f\"Number of results: {self.number_of_results}\")\n        self.log(f\"store.hybrid_search: {vector_store.hybrid_search}\")\n        self.log(f\"Lexical terms: {self.lexical_terms}\")\n        self.log(f\"Reranker: {self.reranker}\")\n\n        try:\n            search_args = self._build_search_args()\n        except Exception as e:\n            msg = f\"Error in AstraDBVectorStore._build_search_args: {e}\"\n            raise ValueError(msg) from e\n\n        if not search_args:\n            self.log(\"No search input or filters provided. Skipping search.\")\n            return []\n\n        docs = []\n        search_method = \"search\" if \"query\" in search_args else \"metadata_search\"\n\n        try:\n            self.log(f\"Calling vector_store.{search_method} with args: {search_args}\")\n            docs = getattr(vector_store, search_method)(**search_args)\n        except Exception as e:\n            msg = f\"Error performing {search_method} in AstraDBVectorStore: {e}\"\n            raise ValueError(msg) from e\n\n        self.log(f\"Retrieved documents: {len(docs)}\")\n\n        data = docs_to_data(docs)\n        self.log(f\"Converted documents to data: {len(data)}\")\n        self.status = data\n\n        return data\n\n    def get_retriever_kwargs(self):\n        search_args = self._build_search_args()\n\n        return {\n            \"search_type\": self._map_search_type(),\n            \"search_kwargs\": search_args,\n        }\n"},"collection_name":{"_input_type":"DropdownInput","advanced":false,"combobox":true,"dialog_inputs":{"fields":{"data":{"node":{"description":"Please allow several seconds for creation to complete.","display_name":"Create new collection","field_order":["01_new_collection_name","02_embedding_generation_provider","03_embedding_generation_model","04_dimension"],"name":"create_collection","template":{"01_new_collection_name":{"_input_type":"StrInput","advanced":false,"display_name":"Name","dynamic":false,"info":"Name of the new collection to create in Astra DB.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"new_collection_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"02_embedding_generation_provider":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Embedding generation method","dynamic":false,"external_options":{},"helper_text":"To create collections with more embedding provider options, go to <a class=\"underline\" href=\"https://astra.datastax.com/\" target=\" _blank\" rel=\"noopener noreferrer\">your database in Astra DB</a>","info":"Provider to use for generating embeddings.","name":"embedding_generation_provider","options":[],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"03_embedding_generation_model":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Embedding model","dynamic":false,"external_options":{},"info":"Model to use for generating embeddings.","name":"embedding_generation_model","options":[],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"04_dimension":{"_input_type":"IntInput","advanced":false,"display_name":"Dimensions","dynamic":false,"info":"Dimensions of the embeddings to generate.","list":false,"list_add_label":"Add More","name":"dimension","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int"}}}}},"functionality":"create"},"display_name":"Collection","dynamic":false,"external_options":{},"info":"The name of the collection within Astra DB where the vectors will be stored.","name":"collection_name","options":[],"options_metadata":[],"placeholder":"","real_time_refresh":true,"refresh_button":true,"required":true,"show":false,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"content_field":{"_input_type":"StrInput","advanced":true,"display_name":"Content Field","dynamic":false,"info":"Field to use as the text content field for the vector store.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"content_field","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"database_name":{"_input_type":"DropdownInput","advanced":false,"combobox":true,"dialog_inputs":{"fields":{"data":{"node":{"description":"Please allow several minutes for creation to complete.","display_name":"Create new database","field_order":["01_new_database_name","02_cloud_provider","03_region"],"name":"create_database","template":{"01_new_database_name":{"_input_type":"StrInput","advanced":false,"display_name":"Name","dynamic":false,"info":"Name of the new database to create in Astra DB.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"new_database_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"02_cloud_provider":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Cloud provider","dynamic":false,"external_options":{},"info":"Cloud provider for the new database.","name":"cloud_provider","options":[],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"03_region":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Region","dynamic":false,"external_options":{},"info":"Region for the new database.","name":"region","options":[],"options_metadata":[],"placeholder":"","required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}}}}},"functionality":"create"},"display_name":"Database","dynamic":false,"external_options":{},"info":"The Database name for the Astra DB instance.","name":"database_name","options":[],"options_metadata":[],"placeholder":"","real_time_refresh":true,"refresh_button":true,"required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"deletion_field":{"_input_type":"StrInput","advanced":true,"display_name":"Deletion Based On Field","dynamic":false,"info":"When this parameter is provided, documents in the target collection with metadata field values matching the input metadata field value will be deleted before new data is loaded.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"deletion_field","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"embedding_model":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding Model","dynamic":false,"info":"Specify the Embedding Model. Not required for Astra Vectorize collections.","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding_model","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"environment":{"_input_type":"DropdownInput","advanced":true,"combobox":true,"dialog_inputs":{},"display_name":"Environment","dynamic":false,"external_options":{},"info":"The environment for the Astra DB API Endpoint.","name":"environment","options":["prod","test","dev"],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"prod"},"ignore_invalid_documents":{"_input_type":"BoolInput","advanced":true,"display_name":"Ignore Invalid Documents","dynamic":false,"info":"Boolean flag to determine whether to ignore invalid documents at runtime.","list":false,"list_add_label":"Add More","name":"ignore_invalid_documents","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"keyspace":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Keyspace","dynamic":false,"external_options":{},"info":"Optional keyspace within Astra DB to use for the collection.","name":"keyspace","options":[],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"lexical_terms":{"_input_type":"QueryInput","advanced":false,"display_name":"Lexical Terms","dynamic":false,"info":"Add additional terms/keywords to augment search precision.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"lexical_terms","placeholder":"Enter terms to search...","required":false,"separator":" ","show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Search Results","dynamic":false,"info":"Number of search results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"reranker":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Reranker","dynamic":false,"external_options":{},"info":"Post-retrieval model that re-scores results for optimal relevance ranking.","name":"reranker","options":[],"options_metadata":[],"placeholder":"","required":false,"show":false,"title_case":false,"toggle":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"search_method":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Search Method","dynamic":false,"external_options":{},"info":"Determine how your content is matched: Vector finds semantic similarity, and Hybrid Search (suggested) combines both approaches with a reranker.","name":"search_method","options":["Hybrid Search","Vector Search"],"options_metadata":[{"icon":"SearchHybrid"},{"icon":"SearchVector"}],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Vector Search"},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"search_score_threshold":{"_input_type":"FloatInput","advanced":true,"display_name":"Search Score Threshold","dynamic":false,"info":"Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')","list":false,"list_add_label":"Add More","name":"search_score_threshold","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.0},"search_type":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Search Type","dynamic":false,"external_options":{},"info":"Search type to use","name":"search_type","options":["Similarity","Similarity with score threshold","MMR (Max Marginal Relevance)"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Similarity"},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Astra DB Application Token","dynamic":false,"info":"Authentication token for accessing Astra DB.","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"ASTRA_DB_APPLICATION_TOKEN"}},"tool_mode":false},"AstraDBCQLToolComponent":{"base_classes":["Data","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Create a tool to get transactional data from DataStax Astra DB CQL Table","display_name":"Astra DB CQL","documentation":"https://docs.langflow.org/bundles-datastax#astra-db-cql","edited":false,"field_order":["tool_name","tool_description","keyspace","table_name","token","api_endpoint","projection_fields","tools_params","partition_keys","clustering_keys","static_filters","number_of_results"],"frozen":false,"icon":"AstraDB","legacy":false,"metadata":{"code_hash":"a479ace75bc2","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"langchain_core","version":"0.3.79"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.datastax.astradb_cql.AstraDBCQLToolComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"run_model","name":"api_run_model","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"api_build_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_endpoint":{"_input_type":"StrInput","advanced":false,"display_name":"API Endpoint","dynamic":false,"info":"API endpoint URL for the Astra DB service.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"api_endpoint","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"ASTRA_DB_API_ENDPOINT"},"clustering_keys":{"_input_type":"DictInput","advanced":true,"display_name":"DEPRECATED: Clustering Keys","dynamic":false,"info":"Field name and description to the model","list":true,"list_add_label":"Add More","name":"clustering_keys","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nimport urllib\nfrom datetime import datetime, timezone\nfrom http import HTTPStatus\nfrom typing import Any\n\nimport requests\nfrom langchain_core.tools import StructuredTool, Tool\nfrom pydantic import BaseModel, Field, create_model\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.io import DictInput, IntInput, SecretStrInput, StrInput, TableInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.table import EditMode\n\n\nclass AstraDBCQLToolComponent(LCToolComponent):\n    display_name: str = \"Astra DB CQL\"\n    description: str = \"Create a tool to get transactional data from DataStax Astra DB CQL Table\"\n    documentation: str = \"https://docs.langflow.org/bundles-datastax#astra-db-cql\"\n    icon: str = \"AstraDB\"\n\n    inputs = [\n        StrInput(name=\"tool_name\", display_name=\"Tool Name\", info=\"The name of the tool.\", required=True),\n        StrInput(\n            name=\"tool_description\",\n            display_name=\"Tool Description\",\n            info=\"The tool description to be passed to the model.\",\n            required=True,\n        ),\n        StrInput(\n            name=\"keyspace\",\n            display_name=\"Keyspace\",\n            value=\"default_keyspace\",\n            info=\"The keyspace name within Astra DB where the data is stored.\",\n            required=True,\n            advanced=True,\n        ),\n        StrInput(\n            name=\"table_name\",\n            display_name=\"Table Name\",\n            info=\"The name of the table within Astra DB where the data is stored.\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n            required=True,\n        ),\n        StrInput(\n            name=\"api_endpoint\",\n            display_name=\"API Endpoint\",\n            info=\"API endpoint URL for the Astra DB service.\",\n            value=\"ASTRA_DB_API_ENDPOINT\",\n            required=True,\n        ),\n        StrInput(\n            name=\"projection_fields\",\n            display_name=\"Projection fields\",\n            info=\"Attributes to return separated by comma.\",\n            required=True,\n            value=\"*\",\n            advanced=True,\n        ),\n        TableInput(\n            name=\"tools_params\",\n            display_name=\"Tools Parameters\",\n            info=\"Define the structure for the tool parameters. Describe the parameters \"\n            \"in a way the LLM can understand how to use them. Add the parameters \"\n            \"respecting the table schema (Partition Keys, Clustering Keys and Indexed Fields).\",\n            required=False,\n            table_schema=[\n                {\n                    \"name\": \"name\",\n                    \"display_name\": \"Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Name of the field/parameter to be used by the model.\",\n                    \"default\": \"field\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"field_name\",\n                    \"display_name\": \"Field Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Specify the column name to be filtered on the table. \"\n                    \"Leave empty if the attribute name is the same as the name of the field.\",\n                    \"default\": \"\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"description\",\n                    \"display_name\": \"Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Describe the purpose of the parameter.\",\n                    \"default\": \"description of tool parameter\",\n                    \"edit_mode\": EditMode.POPOVER,\n                },\n                {\n                    \"name\": \"mandatory\",\n                    \"display_name\": \"Is Mandatory\",\n                    \"type\": \"boolean\",\n                    \"edit_mode\": EditMode.INLINE,\n                    \"description\": (\"Indicate if the field is mandatory.\"),\n                    \"options\": [\"True\", \"False\"],\n                    \"default\": \"False\",\n                },\n                {\n                    \"name\": \"is_timestamp\",\n                    \"display_name\": \"Is Timestamp\",\n                    \"type\": \"boolean\",\n                    \"edit_mode\": EditMode.INLINE,\n                    \"description\": (\"Indicate if the field is a timestamp.\"),\n                    \"options\": [\"True\", \"False\"],\n                    \"default\": \"False\",\n                },\n                {\n                    \"name\": \"operator\",\n                    \"display_name\": \"Operator\",\n                    \"type\": \"str\",\n                    \"description\": \"Set the operator for the field. \"\n                    \"https://docs.datastax.com/en/astra-db-serverless/api-reference/documents.html#operators\",\n                    \"default\": \"$eq\",\n                    \"options\": [\"$gt\", \"$gte\", \"$lt\", \"$lte\", \"$eq\", \"$ne\", \"$in\", \"$nin\", \"$exists\", \"$all\", \"$size\"],\n                    \"edit_mode\": EditMode.INLINE,\n                },\n            ],\n            value=[],\n        ),\n        DictInput(\n            name=\"partition_keys\",\n            display_name=\"DEPRECATED: Partition Keys\",\n            is_list=True,\n            info=\"Field name and description to the model\",\n            required=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"clustering_keys\",\n            display_name=\"DEPRECATED: Clustering Keys\",\n            is_list=True,\n            info=\"Field name and description to the model\",\n            required=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"static_filters\",\n            display_name=\"Static Filters\",\n            is_list=True,\n            advanced=True,\n            info=\"Field name and value. When filled, it will not be generated by the LLM.\",\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=5,\n        ),\n    ]\n\n    def parse_timestamp(self, timestamp_str: str) -> str:\n        \"\"\"Parse a timestamp string into Astra DB REST API format.\n\n        Args:\n            timestamp_str (str): Input timestamp string\n\n        Returns:\n            str: Formatted timestamp string in YYYY-MM-DDTHH:MI:SS.000Z format\n\n        Raises:\n            ValueError: If the timestamp cannot be parsed\n        \"\"\"\n        # Common datetime formats to try\n        formats = [\n            \"%Y-%m-%d\",  # 2024-03-21\n            \"%Y-%m-%dT%H:%M:%S\",  # 2024-03-21T15:30:00\n            \"%Y-%m-%dT%H:%M:%S%z\",  # 2024-03-21T15:30:00+0000\n            \"%Y-%m-%d %H:%M:%S\",  # 2024-03-21 15:30:00\n            \"%d/%m/%Y\",  # 21/03/2024\n            \"%Y/%m/%d\",  # 2024/03/21\n        ]\n\n        for fmt in formats:\n            try:\n                # Parse the date string\n                date_obj = datetime.strptime(timestamp_str, fmt).astimezone()\n\n                # If the parsed date has no timezone info, assume UTC\n                if date_obj.tzinfo is None:\n                    date_obj = date_obj.replace(tzinfo=timezone.utc)\n\n                # Convert to UTC and format\n                utc_date = date_obj.astimezone(timezone.utc)\n                return utc_date.strftime(\"%Y-%m-%dT%H:%M:%S.000Z\")\n            except ValueError:\n                continue\n\n        msg = f\"Could not parse date: {timestamp_str}\"\n        logger.error(msg)\n        raise ValueError(msg)\n\n    def astra_rest(self, args):\n        headers = {\"Accept\": \"application/json\", \"X-Cassandra-Token\": f\"{self.token}\"}\n        astra_url = f\"{self.api_endpoint}/api/rest/v2/keyspaces/{self.keyspace}/{self.table_name}/\"\n        where = {}\n\n        for param in self.tools_params:\n            field_name = param[\"field_name\"] if param[\"field_name\"] else param[\"name\"]\n            field_value = None\n\n            if field_name in self.static_filters:\n                field_value = self.static_filters[field_name]\n            elif param[\"name\"] in args:\n                field_value = args[param[\"name\"]]\n\n            if field_value is None:\n                continue\n\n            if param[\"is_timestamp\"] == True:  # noqa: E712\n                try:\n                    field_value = self.parse_timestamp(field_value)\n                except ValueError as e:\n                    msg = f\"Error parsing timestamp: {e} - Use the prompt to specify the date in the correct format\"\n                    logger.error(msg)\n                    raise ValueError(msg) from e\n\n            if param[\"operator\"] == \"$exists\":\n                where[field_name] = {**where.get(field_name, {}), param[\"operator\"]: True}\n            elif param[\"operator\"] in [\"$in\", \"$nin\", \"$all\"]:\n                where[field_name] = {\n                    **where.get(field_name, {}),\n                    param[\"operator\"]: field_value.split(\",\") if isinstance(field_value, str) else field_value,\n                }\n            else:\n                where[field_name] = {**where.get(field_name, {}), param[\"operator\"]: field_value}\n\n        url = f\"{astra_url}?page-size={self.number_of_results}\"\n        url += f\"&where={json.dumps(where)}\"\n\n        if self.projection_fields != \"*\":\n            url += f\"&fields={urllib.parse.quote(self.projection_fields.replace(' ', ''))}\"\n\n        res = requests.request(\"GET\", url=url, headers=headers, timeout=10)\n\n        if int(res.status_code) >= HTTPStatus.BAD_REQUEST:\n            msg = f\"Error on Astra DB CQL Tool {self.tool_name} request: {res.text}\"\n            logger.error(msg)\n            raise ValueError(msg)\n\n        try:\n            res_data = res.json()\n            return res_data[\"data\"]\n        except ValueError:\n            return res.status_code\n\n    def create_args_schema(self) -> dict[str, BaseModel]:\n        args: dict[str, tuple[Any, Field]] = {}\n\n        for param in self.tools_params:\n            field_name = param[\"field_name\"] if param[\"field_name\"] else param[\"name\"]\n            if field_name not in self.static_filters:\n                if param[\"mandatory\"]:\n                    args[param[\"name\"]] = (str, Field(description=param[\"description\"]))\n                else:\n                    args[param[\"name\"]] = (str | None, Field(description=param[\"description\"], default=None))\n\n        model = create_model(\"ToolInput\", **args, __base__=BaseModel)\n        return {\"ToolInput\": model}\n\n    def build_tool(self) -> Tool:\n        \"\"\"Builds a Astra DB CQL Table tool.\n\n        Args:\n            name (str, optional): The name of the tool.\n\n        Returns:\n            Tool: The built Astra DB tool.\n        \"\"\"\n        schema_dict = self.create_args_schema()\n        return StructuredTool.from_function(\n            name=self.tool_name,\n            args_schema=schema_dict[\"ToolInput\"],\n            description=self.tool_description,\n            func=self.run_model,\n            return_direct=False,\n        )\n\n    def projection_args(self, input_str: str) -> dict:\n        elements = input_str.split(\",\")\n        result = {}\n\n        for element in elements:\n            if element.startswith(\"!\"):\n                result[element[1:]] = False\n            else:\n                result[element] = True\n\n        return result\n\n    def run_model(self, **args) -> Data | list[Data]:\n        results = self.astra_rest(args)\n        data: list[Data] = []\n\n        if isinstance(results, list):\n            data = [Data(data=doc) for doc in results]\n        else:\n            self.status = results\n            return []\n\n        self.status = data\n        return data\n"},"keyspace":{"_input_type":"StrInput","advanced":true,"display_name":"Keyspace","dynamic":false,"info":"The keyspace name within Astra DB where the data is stored.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"keyspace","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"default_keyspace"},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5},"partition_keys":{"_input_type":"DictInput","advanced":true,"display_name":"DEPRECATED: Partition Keys","dynamic":false,"info":"Field name and description to the model","list":true,"list_add_label":"Add More","name":"partition_keys","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"projection_fields":{"_input_type":"StrInput","advanced":true,"display_name":"Projection fields","dynamic":false,"info":"Attributes to return separated by comma.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"projection_fields","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"*"},"static_filters":{"_input_type":"DictInput","advanced":true,"display_name":"Static Filters","dynamic":false,"info":"Field name and value. When filled, it will not be generated by the LLM.","list":true,"list_add_label":"Add More","name":"static_filters","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"table_name":{"_input_type":"StrInput","advanced":false,"display_name":"Table Name","dynamic":false,"info":"The name of the table within Astra DB where the data is stored.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"table_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Astra DB Application Token","dynamic":false,"info":"Authentication token for accessing Astra DB.","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"ASTRA_DB_APPLICATION_TOKEN"},"tool_description":{"_input_type":"StrInput","advanced":false,"display_name":"Tool Description","dynamic":false,"info":"The tool description to be passed to the model.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tool_description","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tool_name":{"_input_type":"StrInput","advanced":false,"display_name":"Tool Name","dynamic":false,"info":"The name of the tool.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tool_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tools_params":{"_input_type":"TableInput","advanced":false,"display_name":"Tools Parameters","dynamic":false,"info":"Define the structure for the tool parameters. Describe the parameters in a way the LLM can understand how to use them. Add the parameters respecting the table schema (Partition Keys, Clustering Keys and Indexed Fields).","is_list":true,"list_add_label":"Add More","name":"tools_params","placeholder":"","required":false,"show":true,"table_icon":"Table","table_schema":[{"default":"field","description":"Name of the field/parameter to be used by the model.","display_name":"Name","edit_mode":"inline","name":"name","type":"str"},{"default":"","description":"Specify the column name to be filtered on the table. Leave empty if the attribute name is the same as the name of the field.","display_name":"Field Name","edit_mode":"inline","name":"field_name","type":"str"},{"default":"description of tool parameter","description":"Describe the purpose of the parameter.","display_name":"Description","edit_mode":"popover","name":"description","type":"str"},{"default":"False","description":"Indicate if the field is mandatory.","display_name":"Is Mandatory","edit_mode":"inline","name":"mandatory","options":["True","False"],"type":"boolean"},{"default":"False","description":"Indicate if the field is a timestamp.","display_name":"Is Timestamp","edit_mode":"inline","name":"is_timestamp","options":["True","False"],"type":"boolean"},{"default":"$eq","description":"Set the operator for the field. https://docs.datastax.com/en/astra-db-serverless/api-reference/documents.html#operators","display_name":"Operator","edit_mode":"inline","name":"operator","options":["$gt","$gte","$lt","$lte","$eq","$ne","$in","$nin","$exists","$all","$size"],"type":"str"}],"title_case":false,"tool_mode":false,"trace_as_metadata":true,"trigger_icon":"Table","trigger_text":"Open table","type":"table","value":[]}},"tool_mode":false},"AstraDBChatMemory":{"base_classes":["Memory"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Retrieves and store chat messages from Astra DB.","display_name":"Astra DB Chat Memory","documentation":"https://docs.langflow.org/bundles-datastax#astra-db-chat-memory","edited":false,"field_order":["token","api_endpoint","collection_name","namespace","session_id"],"frozen":false,"icon":"AstraDB","legacy":false,"metadata":{"code_hash":"8b92cbf3bb22","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"astrapy","version":"2.1.0"},{"name":"langchain_astradb","version":"0.6.1"}],"total_dependencies":3},"module":"lfx.components.datastax.astra_db.AstraDBChatMemory"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Memory","group_outputs":false,"method":"build_message_history","name":"memory","selected":"Memory","tool_mode":true,"types":["Memory"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_endpoint":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Astra DB API Endpoint","dynamic":false,"info":"API endpoint URL for the Astra DB service.","input_types":[],"load_from_db":true,"name":"api_endpoint","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"ASTRA_DB_API_ENDPOINT"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import os\n\nfrom lfx.base.memory.model import LCChatMemoryComponent\nfrom lfx.field_typing.constants import Memory\nfrom lfx.inputs.inputs import MessageTextInput, SecretStrInput, StrInput\n\n\nclass AstraDBChatMemory(LCChatMemoryComponent):\n    display_name = \"Astra DB Chat Memory\"\n    description = \"Retrieves and store chat messages from Astra DB.\"\n    name = \"AstraDBChatMemory\"\n    documentation: str = \"https://docs.langflow.org/bundles-datastax#astra-db-chat-memory\"\n    icon: str = \"AstraDB\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n            required=True,\n            advanced=os.getenv(\"ASTRA_ENHANCED\", \"false\").lower() == \"true\",\n        ),\n        SecretStrInput(\n            name=\"api_endpoint\",\n            display_name=\"Astra DB API Endpoint\",\n            info=\"API endpoint URL for the Astra DB service.\",\n            value=\"ASTRA_DB_API_ENDPOINT\",\n            required=True,\n        ),\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            info=\"The name of the collection within Astra DB where the vectors will be stored.\",\n            required=True,\n        ),\n        StrInput(\n            name=\"namespace\",\n            display_name=\"Namespace\",\n            info=\"Optional namespace within Astra DB to use for the collection.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_message_history(self) -> Memory:\n        try:\n            from astrapy.admin import parse_api_endpoint\n            from langchain_astradb.chat_message_histories import AstraDBChatMessageHistory\n\n        except ImportError as e:\n            msg = (\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n            raise ImportError(msg) from e\n\n        try:\n            from astrapy.admin import parse_api_endpoint\n\n        except ImportError as e:\n            msg = \"Could not import astrapy package. \"\n            raise ImportError(msg) from e\n\n        return AstraDBChatMessageHistory(\n            session_id=self.session_id,\n            collection_name=self.collection_name,\n            token=self.token,\n            api_endpoint=self.api_endpoint,\n            namespace=self.namespace or None,\n            environment=parse_api_endpoint(self.api_endpoint).environment,\n        )\n"},"collection_name":{"_input_type":"StrInput","advanced":false,"display_name":"Collection Name","dynamic":false,"info":"The name of the collection within Astra DB where the vectors will be stored.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"namespace":{"_input_type":"StrInput","advanced":true,"display_name":"Namespace","dynamic":false,"info":"Optional namespace within Astra DB to use for the collection.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"namespace","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"session_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Session ID","dynamic":false,"info":"The session ID of the chat. If empty, the current session ID parameter will be used.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"session_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Astra DB Application Token","dynamic":false,"info":"Authentication token for accessing Astra DB.","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"ASTRA_DB_APPLICATION_TOKEN"}},"tool_mode":false},"AstraDBGraph":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Implementation of Graph Vector Store using Astra DB","display_name":"Astra DB Graph","documentation":"https://docs.langflow.org/bundles-datastax#astra-db-graph","edited":false,"field_order":["token","api_endpoint","collection_name","metadata_incoming_links_key","ingest_data","search_query","should_cache_vector_store","keyspace","embedding_model","metric","batch_size","bulk_insert_batch_concurrency","bulk_insert_overwrite_concurrency","bulk_delete_concurrency","setup_mode","pre_delete_collection","metadata_indexing_include","metadata_indexing_exclude","collection_indexing_policy","number_of_results","search_type","search_score_threshold","search_filter"],"frozen":false,"icon":"AstraDB","legacy":false,"metadata":{"code_hash":"3a0fbd50cc56","dependencies":{"dependencies":[{"name":"orjson","version":"3.10.15"},{"name":"lfx","version":null},{"name":"astrapy","version":"2.1.0"},{"name":"langchain_astradb","version":"0.6.1"}],"total_dependencies":4},"module":"lfx.components.datastax.astradb_graph.AstraDBGraphVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_endpoint":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Endpoint","dynamic":false,"info":"API endpoint URL for the Astra DB service.","input_types":[],"load_from_db":true,"name":"api_endpoint","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"ASTRA_DB_API_ENDPOINT"},"batch_size":{"_input_type":"IntInput","advanced":true,"display_name":"Batch Size","dynamic":false,"info":"Optional number of data to process in a single batch.","list":false,"list_add_label":"Add More","name":"batch_size","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"bulk_delete_concurrency":{"_input_type":"IntInput","advanced":true,"display_name":"Bulk Delete Concurrency","dynamic":false,"info":"Optional concurrency level for bulk delete operations.","list":false,"list_add_label":"Add More","name":"bulk_delete_concurrency","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"bulk_insert_batch_concurrency":{"_input_type":"IntInput","advanced":true,"display_name":"Bulk Insert Batch Concurrency","dynamic":false,"info":"Optional concurrency level for bulk insert operations.","list":false,"list_add_label":"Add More","name":"bulk_insert_batch_concurrency","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"bulk_insert_overwrite_concurrency":{"_input_type":"IntInput","advanced":true,"display_name":"Bulk Insert Overwrite Concurrency","dynamic":false,"info":"Optional concurrency level for bulk insert operations that overwrite existing data.","list":false,"list_add_label":"Add More","name":"bulk_insert_overwrite_concurrency","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import os\n\nimport orjson\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.inputs.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    HandleInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass AstraDBGraphVectorStoreComponent(LCVectorStoreComponent):\n    display_name: str = \"Astra DB Graph\"\n    description: str = \"Implementation of Graph Vector Store using Astra DB\"\n    name = \"AstraDBGraph\"\n    documentation: str = \"https://docs.langflow.org/bundles-datastax#astra-db-graph\"\n    icon: str = \"AstraDB\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n            required=True,\n            advanced=os.getenv(\"ASTRA_ENHANCED\", \"false\").lower() == \"true\",\n        ),\n        SecretStrInput(\n            name=\"api_endpoint\",\n            display_name=\"Database\" if os.getenv(\"ASTRA_ENHANCED\", \"false\").lower() == \"true\" else \"API Endpoint\",\n            info=\"API endpoint URL for the Astra DB service.\",\n            value=\"ASTRA_DB_API_ENDPOINT\",\n            required=True,\n        ),\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            info=\"The name of the collection within Astra DB where the vectors will be stored.\",\n            required=True,\n        ),\n        StrInput(\n            name=\"metadata_incoming_links_key\",\n            display_name=\"Metadata incoming links key\",\n            info=\"Metadata key used for incoming links.\",\n            advanced=True,\n        ),\n        *LCVectorStoreComponent.inputs,\n        StrInput(\n            name=\"keyspace\",\n            display_name=\"Keyspace\",\n            info=\"Optional keyspace within Astra DB to use for the collection.\",\n            advanced=True,\n        ),\n        HandleInput(\n            name=\"embedding_model\",\n            display_name=\"Embedding Model\",\n            input_types=[\"Embeddings\"],\n            info=\"Allows an embedding model configuration.\",\n        ),\n        DropdownInput(\n            name=\"metric\",\n            display_name=\"Metric\",\n            info=\"Optional distance metric for vector comparisons in the vector store.\",\n            options=[\"cosine\", \"dot_product\", \"euclidean\"],\n            value=\"cosine\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"batch_size\",\n            display_name=\"Batch Size\",\n            info=\"Optional number of data to process in a single batch.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_batch_concurrency\",\n            display_name=\"Bulk Insert Batch Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_overwrite_concurrency\",\n            display_name=\"Bulk Insert Overwrite Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations that overwrite existing data.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_delete_concurrency\",\n            display_name=\"Bulk Delete Concurrency\",\n            info=\"Optional concurrency level for bulk delete operations.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"setup_mode\",\n            display_name=\"Setup Mode\",\n            info=\"Configuration mode for setting up the vector store, with options like 'Sync', or 'Off'.\",\n            options=[\"Sync\", \"Off\"],\n            advanced=True,\n            value=\"Sync\",\n        ),\n        BoolInput(\n            name=\"pre_delete_collection\",\n            display_name=\"Pre Delete Collection\",\n            info=\"Boolean flag to determine whether to delete the collection before creating a new one.\",\n            advanced=True,\n            value=False,\n        ),\n        StrInput(\n            name=\"metadata_indexing_include\",\n            display_name=\"Metadata Indexing Include\",\n            info=\"Optional list of metadata fields to include in the indexing.\",\n            advanced=True,\n            list=True,\n        ),\n        StrInput(\n            name=\"metadata_indexing_exclude\",\n            display_name=\"Metadata Indexing Exclude\",\n            info=\"Optional list of metadata fields to exclude from the indexing.\",\n            advanced=True,\n            list=True,\n        ),\n        StrInput(\n            name=\"collection_indexing_policy\",\n            display_name=\"Collection Indexing Policy\",\n            info='Optional JSON string for the \"indexing\" field of the collection. '\n            \"See https://docs.datastax.com/en/astra-db-serverless/api-reference/collections.html#the-indexing-option\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            info=\"Search type to use\",\n            options=[\n                \"Similarity\",\n                \"Similarity with score threshold\",\n                \"MMR (Max Marginal Relevance)\",\n                \"Graph Traversal\",\n                \"MMR (Max Marginal Relevance) Graph Traversal\",\n            ],\n            value=\"MMR (Max Marginal Relevance) Graph Traversal\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results. \"\n            \"(when using 'Similarity with score threshold')\",\n            value=0,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"search_filter\",\n            display_name=\"Search Metadata Filter\",\n            info=\"Optional dictionary of filters to apply to the search query.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self):\n        try:\n            from astrapy.admin import parse_api_endpoint\n            from langchain_astradb import AstraDBGraphVectorStore\n            from langchain_astradb.utils.astradb import SetupMode\n        except ImportError as e:\n            msg = (\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n            raise ImportError(msg) from e\n\n        try:\n            if not self.setup_mode:\n                self.setup_mode = self._inputs[\"setup_mode\"].options[0]\n\n            setup_mode_value = SetupMode[self.setup_mode.upper()]\n        except KeyError as e:\n            msg = f\"Invalid setup mode: {self.setup_mode}\"\n            raise ValueError(msg) from e\n\n        try:\n            self.log(f\"Initializing Graph Vector Store {self.collection_name}\")\n\n            # Handle environment parsing with try-except to avoid circular import\n            environment = None\n            if self.api_endpoint:\n                try:\n                    from astrapy.admin import parse_api_endpoint\n\n                    environment = parse_api_endpoint(self.api_endpoint).environment\n                except ImportError:\n                    self.log(\"Warning: Could not import parse_api_endpoint, using None for environment\")\n                    environment = None\n\n            vector_store = AstraDBGraphVectorStore(\n                embedding=self.embedding_model,\n                collection_name=self.collection_name,\n                metadata_incoming_links_key=self.metadata_incoming_links_key or \"incoming_links\",\n                token=self.token,\n                api_endpoint=self.api_endpoint,\n                namespace=self.keyspace or None,\n                environment=environment,\n                metric=self.metric or None,\n                batch_size=self.batch_size or None,\n                bulk_insert_batch_concurrency=self.bulk_insert_batch_concurrency or None,\n                bulk_insert_overwrite_concurrency=self.bulk_insert_overwrite_concurrency or None,\n                bulk_delete_concurrency=self.bulk_delete_concurrency or None,\n                setup_mode=setup_mode_value,\n                pre_delete_collection=self.pre_delete_collection,\n                metadata_indexing_include=[s for s in self.metadata_indexing_include if s] or None,\n                metadata_indexing_exclude=[s for s in self.metadata_indexing_exclude if s] or None,\n                collection_indexing_policy=orjson.loads(self.collection_indexing_policy.encode(\"utf-8\"))\n                if self.collection_indexing_policy\n                else None,\n            )\n        except Exception as e:\n            msg = f\"Error initializing AstraDBGraphVectorStore: {e}\"\n            raise ValueError(msg) from e\n\n        self.log(f\"Vector Store initialized: {vector_store.astra_env.collection_name}\")\n        self._add_documents_to_vector_store(vector_store)\n\n        return vector_store\n\n    def _add_documents_to_vector_store(self, vector_store) -> None:\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                msg = \"Vector Store Inputs must be Data objects.\"\n                raise TypeError(msg)\n\n        if documents:\n            self.log(f\"Adding {len(documents)} documents to the Vector Store.\")\n            try:\n                vector_store.add_documents(documents)\n            except Exception as e:\n                msg = f\"Error adding documents to AstraDBGraphVectorStore: {e}\"\n                raise ValueError(msg) from e\n        else:\n            self.log(\"No documents to add to the Vector Store.\")\n\n    def _map_search_type(self) -> str:\n        match self.search_type:\n            case \"Similarity\":\n                return \"similarity\"\n            case \"Similarity with score threshold\":\n                return \"similarity_score_threshold\"\n            case \"MMR (Max Marginal Relevance)\":\n                return \"mmr\"\n            case \"Graph Traversal\":\n                return \"traversal\"\n            case \"MMR (Max Marginal Relevance) Graph Traversal\":\n                return \"mmr_traversal\"\n            case _:\n                return \"similarity\"\n\n    def _build_search_args(self):\n        args = {\n            \"k\": self.number_of_results,\n            \"score_threshold\": self.search_score_threshold,\n        }\n\n        if self.search_filter:\n            clean_filter = {k: v for k, v in self.search_filter.items() if k and v}\n            if len(clean_filter) > 0:\n                args[\"filter\"] = clean_filter\n        return args\n\n    def search_documents(self, vector_store=None) -> list[Data]:\n        if not vector_store:\n            vector_store = self.build_vector_store()\n\n        self.log(\"Searching for documents in AstraDBGraphVectorStore.\")\n        self.log(f\"Search query: {self.search_query}\")\n        self.log(f\"Search type: {self.search_type}\")\n        self.log(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            try:\n                search_type = self._map_search_type()\n                search_args = self._build_search_args()\n\n                docs = vector_store.search(query=self.search_query, search_type=search_type, **search_args)\n\n                # Drop links from the metadata. At this point the links don't add any value for building the\n                # context and haven't been restored to json which causes the conversion to fail.\n                self.log(\"Removing links from metadata.\")\n                for doc in docs:\n                    if \"links\" in doc.metadata:\n                        doc.metadata.pop(\"links\")\n\n            except Exception as e:\n                msg = f\"Error performing search in AstraDBGraphVectorStore: {e}\"\n                raise ValueError(msg) from e\n\n            self.log(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n\n            self.log(f\"Converted documents to data: {len(data)}\")\n\n            self.status = data\n            return data\n        self.log(\"No search input provided. Skipping search.\")\n        return []\n\n    def get_retriever_kwargs(self):\n        search_args = self._build_search_args()\n        return {\n            \"search_type\": self._map_search_type(),\n            \"search_kwargs\": search_args,\n        }\n"},"collection_indexing_policy":{"_input_type":"StrInput","advanced":true,"display_name":"Collection Indexing Policy","dynamic":false,"info":"Optional JSON string for the \"indexing\" field of the collection. See https://docs.datastax.com/en/astra-db-serverless/api-reference/collections.html#the-indexing-option","list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_indexing_policy","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"collection_name":{"_input_type":"StrInput","advanced":false,"display_name":"Collection Name","dynamic":false,"info":"The name of the collection within Astra DB where the vectors will be stored.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"embedding_model":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding Model","dynamic":false,"info":"Allows an embedding model configuration.","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding_model","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"keyspace":{"_input_type":"StrInput","advanced":true,"display_name":"Keyspace","dynamic":false,"info":"Optional keyspace within Astra DB to use for the collection.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"keyspace","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"metadata_incoming_links_key":{"_input_type":"StrInput","advanced":true,"display_name":"Metadata incoming links key","dynamic":false,"info":"Metadata key used for incoming links.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"metadata_incoming_links_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"metadata_indexing_exclude":{"_input_type":"StrInput","advanced":true,"display_name":"Metadata Indexing Exclude","dynamic":false,"info":"Optional list of metadata fields to exclude from the indexing.","list":true,"list_add_label":"Add More","load_from_db":false,"name":"metadata_indexing_exclude","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"metadata_indexing_include":{"_input_type":"StrInput","advanced":true,"display_name":"Metadata Indexing Include","dynamic":false,"info":"Optional list of metadata fields to include in the indexing.","list":true,"list_add_label":"Add More","load_from_db":false,"name":"metadata_indexing_include","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"metric":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Metric","dynamic":false,"external_options":{},"info":"Optional distance metric for vector comparisons in the vector store.","name":"metric","options":["cosine","dot_product","euclidean"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"cosine"},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"pre_delete_collection":{"_input_type":"BoolInput","advanced":true,"display_name":"Pre Delete Collection","dynamic":false,"info":"Boolean flag to determine whether to delete the collection before creating a new one.","list":false,"list_add_label":"Add More","name":"pre_delete_collection","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"search_filter":{"_input_type":"DictInput","advanced":true,"display_name":"Search Metadata Filter","dynamic":false,"info":"Optional dictionary of filters to apply to the search query.","list":true,"list_add_label":"Add More","name":"search_filter","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"search_score_threshold":{"_input_type":"FloatInput","advanced":true,"display_name":"Search Score Threshold","dynamic":false,"info":"Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')","list":false,"list_add_label":"Add More","name":"search_score_threshold","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.0},"search_type":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Search Type","dynamic":false,"external_options":{},"info":"Search type to use","name":"search_type","options":["Similarity","Similarity with score threshold","MMR (Max Marginal Relevance)","Graph Traversal","MMR (Max Marginal Relevance) Graph Traversal"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"MMR (Max Marginal Relevance) Graph Traversal"},"setup_mode":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Setup Mode","dynamic":false,"external_options":{},"info":"Configuration mode for setting up the vector store, with options like 'Sync', or 'Off'.","name":"setup_mode","options":["Sync","Off"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Sync"},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Astra DB Application Token","dynamic":false,"info":"Authentication token for accessing Astra DB.","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"ASTRA_DB_APPLICATION_TOKEN"}},"tool_mode":false},"AstraDBToolComponent":{"base_classes":["Data","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Tool to run hybrid vector and metadata search on DataStax Astra DB Collection","display_name":"Astra DB Tool","documentation":"https://docs.langflow.org/bundles-datastax#astra-db-tool","edited":false,"field_order":["tool_name","tool_description","keyspace","collection_name","token","api_endpoint","projection_attributes","tools_params_v2","tool_params","static_filters","number_of_results","use_search_query","use_vectorize","embedding","semantic_search_instruction"],"frozen":false,"icon":"AstraDB","legacy":false,"metadata":{"code_hash":"e6d22b76cc5b","dependencies":{"dependencies":[{"name":"astrapy","version":"2.1.0"},{"name":"langchain_core","version":"0.3.79"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.datastax.astradb_tool.AstraDBToolComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"run_model","name":"api_run_model","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"api_build_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_endpoint":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Endpoint","dynamic":false,"info":"API endpoint URL for the Astra DB service.","input_types":[],"load_from_db":true,"name":"api_endpoint","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"ASTRA_DB_API_ENDPOINT"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import os\nfrom datetime import datetime, timezone\nfrom typing import Any\n\nfrom astrapy import Collection, DataAPIClient, Database\nfrom langchain_core.tools import StructuredTool, Tool\nfrom pydantic import BaseModel, Field, create_model\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.io import BoolInput, DictInput, HandleInput, IntInput, SecretStrInput, StrInput, TableInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.table import EditMode\n\n\nclass AstraDBToolComponent(LCToolComponent):\n    display_name: str = \"Astra DB Tool\"\n    description: str = \"Tool to run hybrid vector and metadata search on DataStax Astra DB Collection\"\n    documentation: str = \"https://docs.langflow.org/bundles-datastax#astra-db-tool\"\n    icon: str = \"AstraDB\"\n\n    inputs = [\n        StrInput(\n            name=\"tool_name\",\n            display_name=\"Tool Name\",\n            info=\"The name of the tool to be passed to the LLM.\",\n            required=True,\n        ),\n        StrInput(\n            name=\"tool_description\",\n            display_name=\"Tool Description\",\n            info=\"Describe the tool to LLM. Add any information that can help the LLM to use the tool.\",\n            required=True,\n        ),\n        StrInput(\n            name=\"keyspace\",\n            display_name=\"Keyspace Name\",\n            info=\"The name of the keyspace within Astra where the collection is stored.\",\n            value=\"default_keyspace\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            info=\"The name of the collection within Astra DB where the vectors will be stored.\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_endpoint\",\n            display_name=\"Database\" if os.getenv(\"ASTRA_ENHANCED\", \"false\").lower() == \"true\" else \"API Endpoint\",\n            info=\"API endpoint URL for the Astra DB service.\",\n            value=\"ASTRA_DB_API_ENDPOINT\",\n            required=True,\n        ),\n        StrInput(\n            name=\"projection_attributes\",\n            display_name=\"Projection Attributes\",\n            info=\"Attributes to be returned by the tool separated by comma.\",\n            required=True,\n            value=\"*\",\n            advanced=True,\n        ),\n        TableInput(\n            name=\"tools_params_v2\",\n            display_name=\"Tools Parameters\",\n            info=\"Define the structure for the tool parameters. Describe the parameters \"\n            \"in a way the LLM can understand how to use them.\",\n            required=False,\n            table_schema=[\n                {\n                    \"name\": \"name\",\n                    \"display_name\": \"Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Specify the name of the output field/parameter for the model.\",\n                    \"default\": \"field\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"attribute_name\",\n                    \"display_name\": \"Attribute Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Specify the attribute name to be filtered on the collection. \"\n                    \"Leave empty if the attribute name is the same as the name of the field.\",\n                    \"default\": \"\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"description\",\n                    \"display_name\": \"Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Describe the purpose of the output field.\",\n                    \"default\": \"description of field\",\n                    \"edit_mode\": EditMode.POPOVER,\n                },\n                {\n                    \"name\": \"metadata\",\n                    \"display_name\": \"Is Metadata\",\n                    \"type\": \"boolean\",\n                    \"edit_mode\": EditMode.INLINE,\n                    \"description\": (\"Indicate if the field is included in the metadata field.\"),\n                    \"options\": [\"True\", \"False\"],\n                    \"default\": \"False\",\n                },\n                {\n                    \"name\": \"mandatory\",\n                    \"display_name\": \"Is Mandatory\",\n                    \"type\": \"boolean\",\n                    \"edit_mode\": EditMode.INLINE,\n                    \"description\": (\"Indicate if the field is mandatory.\"),\n                    \"options\": [\"True\", \"False\"],\n                    \"default\": \"False\",\n                },\n                {\n                    \"name\": \"is_timestamp\",\n                    \"display_name\": \"Is Timestamp\",\n                    \"type\": \"boolean\",\n                    \"edit_mode\": EditMode.INLINE,\n                    \"description\": (\"Indicate if the field is a timestamp.\"),\n                    \"options\": [\"True\", \"False\"],\n                    \"default\": \"False\",\n                },\n                {\n                    \"name\": \"operator\",\n                    \"display_name\": \"Operator\",\n                    \"type\": \"str\",\n                    \"description\": \"Set the operator for the field. \"\n                    \"https://docs.datastax.com/en/astra-db-serverless/api-reference/documents.html#operators\",\n                    \"default\": \"$eq\",\n                    \"options\": [\"$gt\", \"$gte\", \"$lt\", \"$lte\", \"$eq\", \"$ne\", \"$in\", \"$nin\", \"$exists\", \"$all\", \"$size\"],\n                    \"edit_mode\": EditMode.INLINE,\n                },\n            ],\n            value=[],\n        ),\n        DictInput(\n            name=\"tool_params\",\n            info=\"DEPRECATED: Attributes to filter and description to the model. \"\n            \"Add ! for mandatory (e.g: !customerId)\",\n            display_name=\"Tool params\",\n            is_list=True,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"static_filters\",\n            info=\"Attributes to filter and correspoding value\",\n            display_name=\"Static filters\",\n            advanced=True,\n            is_list=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=5,\n        ),\n        BoolInput(\n            name=\"use_search_query\",\n            display_name=\"Semantic Search\",\n            info=\"When this parameter is activated, the search query parameter will be used to search the collection.\",\n            advanced=False,\n            value=False,\n        ),\n        BoolInput(\n            name=\"use_vectorize\",\n            display_name=\"Use Astra DB Vectorize\",\n            info=\"When this parameter is activated, Astra DB Vectorize method will be used to generate the embeddings.\",\n            advanced=False,\n            value=False,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding Model\", input_types=[\"Embeddings\"]),\n        StrInput(\n            name=\"semantic_search_instruction\",\n            display_name=\"Semantic Search Instruction\",\n            info=\"The instruction to use for the semantic search.\",\n            required=True,\n            value=\"Search query to find relevant documents.\",\n            advanced=True,\n        ),\n    ]\n\n    _cached_client: DataAPIClient | None = None\n    _cached_db: Database | None = None\n    _cached_collection: Collection | None = None\n\n    def _build_collection(self):\n        try:\n            from astrapy.admin import parse_api_endpoint\n        except ImportError as e:\n            msg = \"Could not import Astra DB integration package. Please install it with `uv pip install astrapy`.\"\n            raise ImportError(msg) from e\n        if self._cached_collection:\n            return self._cached_collection\n\n        try:\n            environment = parse_api_endpoint(self.api_endpoint).environment\n            cached_client = DataAPIClient(self.token, environment=environment)\n            cached_db = cached_client.get_database(self.api_endpoint, keyspace=self.keyspace)\n            self._cached_collection = cached_db.get_collection(self.collection_name)\n        except Exception as e:\n            msg = f\"Error building collection: {e}\"\n            raise ValueError(msg) from e\n        else:\n            return self._cached_collection\n\n    def create_args_schema(self) -> dict[str, BaseModel]:\n        \"\"\"DEPRECATED: This method is deprecated. Please use create_args_schema_v2 instead.\n\n        It is keep only for backward compatibility.\n        \"\"\"\n        logger.warning(\"This is the old way to define the tool parameters. Please use the new way.\")\n        args: dict[str, tuple[Any, Field] | list[str]] = {}\n\n        for key in self.tool_params:\n            if key.startswith(\"!\"):  # Mandatory\n                args[key[1:]] = (str, Field(description=self.tool_params[key]))\n            else:  # Optional\n                args[key] = (str | None, Field(description=self.tool_params[key], default=None))\n\n        if self.use_search_query:\n            args[\"search_query\"] = (\n                str | None,\n                Field(description=\"Search query to find relevant documents.\", default=None),\n            )\n\n        model = create_model(\"ToolInput\", **args, __base__=BaseModel)\n        return {\"ToolInput\": model}\n\n    def create_args_schema_v2(self) -> dict[str, BaseModel]:\n        \"\"\"Create the tool input schema using the new tool parameters configuration.\"\"\"\n        args: dict[str, tuple[Any, Field] | list[str]] = {}\n\n        for tool_param in self.tools_params_v2:\n            if tool_param[\"mandatory\"]:\n                args[tool_param[\"name\"]] = (str, Field(description=tool_param[\"description\"]))\n            else:\n                args[tool_param[\"name\"]] = (str | None, Field(description=tool_param[\"description\"], default=None))\n\n        if self.use_search_query:\n            args[\"search_query\"] = (\n                str,\n                Field(description=self.semantic_search_instruction),\n            )\n\n        model = create_model(\"ToolInput\", **args, __base__=BaseModel)\n        return {\"ToolInput\": model}\n\n    def build_tool(self) -> Tool:\n        \"\"\"Builds an Astra DB Collection tool.\n\n        Returns:\n            Tool: The built Astra DB tool.\n        \"\"\"\n        schema_dict = self.create_args_schema() if len(self.tool_params.keys()) > 0 else self.create_args_schema_v2()\n\n        tool = StructuredTool.from_function(\n            name=self.tool_name,\n            args_schema=schema_dict[\"ToolInput\"],\n            description=self.tool_description,\n            func=self.run_model,\n            return_direct=False,\n        )\n        self.status = \"Astra DB Tool created\"\n\n        return tool\n\n    def projection_args(self, input_str: str) -> dict | None:\n        \"\"\"Build the projection arguments for the Astra DB query.\"\"\"\n        elements = input_str.split(\",\")\n        result = {}\n\n        if elements == [\"*\"]:\n            return None\n\n        # Force the projection to exclude the $vector field as it is not required by the tool\n        result[\"$vector\"] = False\n\n        # Fields with ! as prefix should be removed from the projection\n        for element in elements:\n            if element.startswith(\"!\"):\n                result[element[1:]] = False\n            else:\n                result[element] = True\n\n        return result\n\n    def parse_timestamp(self, timestamp_str: str) -> datetime:\n        \"\"\"Parse a timestamp string into Astra DB REST API format.\n\n        Args:\n            timestamp_str (str): Input timestamp string\n\n        Returns:\n            datetime: Datetime object\n\n        Raises:\n            ValueError: If the timestamp cannot be parsed\n        \"\"\"\n        # Common datetime formats to try\n        formats = [\n            \"%Y-%m-%d\",  # 2024-03-21\n            \"%Y-%m-%dT%H:%M:%S\",  # 2024-03-21T15:30:00\n            \"%Y-%m-%dT%H:%M:%S%z\",  # 2024-03-21T15:30:00+0000\n            \"%Y-%m-%d %H:%M:%S\",  # 2024-03-21 15:30:00\n            \"%d/%m/%Y\",  # 21/03/2024\n            \"%Y/%m/%d\",  # 2024/03/21\n        ]\n\n        for fmt in formats:\n            try:\n                # Parse the date string\n                date_obj = datetime.strptime(timestamp_str, fmt).astimezone()\n\n                # If the parsed date has no timezone info, assume UTC\n                if date_obj.tzinfo is None:\n                    date_obj = date_obj.replace(tzinfo=timezone.utc)\n\n                # Convert to UTC and format\n                return date_obj.astimezone(timezone.utc)\n\n            except ValueError:\n                continue\n\n        msg = f\"Could not parse date: {timestamp_str}\"\n        logger.error(msg)\n        raise ValueError(msg)\n\n    def build_filter(self, args: dict, filter_settings: list) -> dict:\n        \"\"\"Build filter dictionary for Astra DB query.\n\n        Args:\n            args: Dictionary of arguments from the tool\n            filter_settings: List of filter settings from tools_params_v2\n        Returns:\n            Dictionary containing the filter conditions\n        \"\"\"\n        filters = {**self.static_filters}\n\n        for key, value in args.items():\n            # Skip search_query as it's handled separately\n            if key == \"search_query\":\n                continue\n\n            filter_setting = next((x for x in filter_settings if x[\"name\"] == key), None)\n            if filter_setting and value is not None:\n                field_name = filter_setting[\"attribute_name\"] if filter_setting[\"attribute_name\"] else key\n                filter_key = field_name if not filter_setting[\"metadata\"] else f\"metadata.{field_name}\"\n                if filter_setting[\"operator\"] == \"$exists\":\n                    filters[filter_key] = {**filters.get(filter_key, {}), filter_setting[\"operator\"]: True}\n                elif filter_setting[\"operator\"] in [\"$in\", \"$nin\", \"$all\"]:\n                    filters[filter_key] = {\n                        **filters.get(filter_key, {}),\n                        filter_setting[\"operator\"]: value.split(\",\") if isinstance(value, str) else value,\n                    }\n                elif filter_setting[\"is_timestamp\"] == True:  # noqa: E712\n                    try:\n                        filters[filter_key] = {\n                            **filters.get(filter_key, {}),\n                            filter_setting[\"operator\"]: self.parse_timestamp(value),\n                        }\n                    except ValueError as e:\n                        msg = f\"Error parsing timestamp: {e} - Use the prompt to specify the date in the correct format\"\n                        logger.error(msg)\n                        raise ValueError(msg) from e\n                else:\n                    filters[filter_key] = {**filters.get(filter_key, {}), filter_setting[\"operator\"]: value}\n        return filters\n\n    def run_model(self, **args) -> Data | list[Data]:\n        \"\"\"Run the query to get the data from the Astra DB collection.\"\"\"\n        collection = self._build_collection()\n        sort = {}\n\n        # Build filters using the new method\n        filters = self.build_filter(args, self.tools_params_v2)\n\n        # Build the vector search on\n        if self.use_search_query and args[\"search_query\"] is not None and args[\"search_query\"] != \"\":\n            if self.use_vectorize:\n                sort[\"$vectorize\"] = args[\"search_query\"]\n            else:\n                if self.embedding is None:\n                    msg = \"Embedding model is not set. Please set the embedding model or use Astra DB Vectorize.\"\n                    logger.error(msg)\n                    raise ValueError(msg)\n                embedding_query = self.embedding.embed_query(args[\"search_query\"])\n                sort[\"$vector\"] = embedding_query\n            del args[\"search_query\"]\n\n        find_options = {\n            \"filter\": filters,\n            \"limit\": self.number_of_results,\n            \"sort\": sort,\n        }\n\n        projection = self.projection_args(self.projection_attributes)\n        if projection and len(projection) > 0:\n            find_options[\"projection\"] = projection\n\n        try:\n            results = collection.find(**find_options)\n        except Exception as e:\n            msg = f\"Error on Astra DB Tool {self.tool_name} request: {e}\"\n            logger.error(msg)\n            raise ValueError(msg) from e\n\n        logger.info(f\"Tool {self.tool_name} executed`\")\n\n        data: list[Data] = [Data(data=doc) for doc in results]\n        self.status = data\n        return data\n"},"collection_name":{"_input_type":"StrInput","advanced":false,"display_name":"Collection Name","dynamic":false,"info":"The name of the collection within Astra DB where the vectors will be stored.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding Model","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"keyspace":{"_input_type":"StrInput","advanced":true,"display_name":"Keyspace Name","dynamic":false,"info":"The name of the keyspace within Astra where the collection is stored.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"keyspace","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"default_keyspace"},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5},"projection_attributes":{"_input_type":"StrInput","advanced":true,"display_name":"Projection Attributes","dynamic":false,"info":"Attributes to be returned by the tool separated by comma.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"projection_attributes","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"*"},"semantic_search_instruction":{"_input_type":"StrInput","advanced":true,"display_name":"Semantic Search Instruction","dynamic":false,"info":"The instruction to use for the semantic search.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"semantic_search_instruction","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Search query to find relevant documents."},"static_filters":{"_input_type":"DictInput","advanced":true,"display_name":"Static filters","dynamic":false,"info":"Attributes to filter and correspoding value","list":true,"list_add_label":"Add More","name":"static_filters","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Astra DB Application Token","dynamic":false,"info":"Authentication token for accessing Astra DB.","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"ASTRA_DB_APPLICATION_TOKEN"},"tool_description":{"_input_type":"StrInput","advanced":false,"display_name":"Tool Description","dynamic":false,"info":"Describe the tool to LLM. Add any information that can help the LLM to use the tool.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tool_description","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tool_name":{"_input_type":"StrInput","advanced":false,"display_name":"Tool Name","dynamic":false,"info":"The name of the tool to be passed to the LLM.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tool_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tool_params":{"_input_type":"DictInput","advanced":true,"display_name":"Tool params","dynamic":false,"info":"DEPRECATED: Attributes to filter and description to the model. Add ! for mandatory (e.g: !customerId)","list":true,"list_add_label":"Add More","name":"tool_params","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"tools_params_v2":{"_input_type":"TableInput","advanced":false,"display_name":"Tools Parameters","dynamic":false,"info":"Define the structure for the tool parameters. Describe the parameters in a way the LLM can understand how to use them.","is_list":true,"list_add_label":"Add More","name":"tools_params_v2","placeholder":"","required":false,"show":true,"table_icon":"Table","table_schema":[{"default":"field","description":"Specify the name of the output field/parameter for the model.","display_name":"Name","edit_mode":"inline","name":"name","type":"str"},{"default":"","description":"Specify the attribute name to be filtered on the collection. Leave empty if the attribute name is the same as the name of the field.","display_name":"Attribute Name","edit_mode":"inline","name":"attribute_name","type":"str"},{"default":"description of field","description":"Describe the purpose of the output field.","display_name":"Description","edit_mode":"popover","name":"description","type":"str"},{"default":"False","description":"Indicate if the field is included in the metadata field.","display_name":"Is Metadata","edit_mode":"inline","name":"metadata","options":["True","False"],"type":"boolean"},{"default":"False","description":"Indicate if the field is mandatory.","display_name":"Is Mandatory","edit_mode":"inline","name":"mandatory","options":["True","False"],"type":"boolean"},{"default":"False","description":"Indicate if the field is a timestamp.","display_name":"Is Timestamp","edit_mode":"inline","name":"is_timestamp","options":["True","False"],"type":"boolean"},{"default":"$eq","description":"Set the operator for the field. https://docs.datastax.com/en/astra-db-serverless/api-reference/documents.html#operators","display_name":"Operator","edit_mode":"inline","name":"operator","options":["$gt","$gte","$lt","$lte","$eq","$ne","$in","$nin","$exists","$all","$size"],"type":"str"}],"title_case":false,"tool_mode":false,"trace_as_metadata":true,"trigger_icon":"Table","trigger_text":"Open table","type":"table","value":[]},"use_search_query":{"_input_type":"BoolInput","advanced":false,"display_name":"Semantic Search","dynamic":false,"info":"When this parameter is activated, the search query parameter will be used to search the collection.","list":false,"list_add_label":"Add More","name":"use_search_query","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"use_vectorize":{"_input_type":"BoolInput","advanced":false,"display_name":"Use Astra DB Vectorize","dynamic":false,"info":"When this parameter is activated, Astra DB Vectorize method will be used to generate the embeddings.","list":false,"list_add_label":"Add More","name":"use_vectorize","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false},"AstraVectorize":{"base_classes":["dict"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Configuration options for Astra Vectorize server-side embeddings. ","display_name":"Astra Vectorize","documentation":"https://docs.datastax.com/en/astra-db-serverless/databases/embedding-generation.html","edited":false,"field_order":["provider","model_name","api_key_name","authentication","provider_api_key","authentication","model_parameters"],"frozen":false,"icon":"AstraDB","legacy":true,"metadata":{"code_hash":"3d976690c262","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.datastax.astra_vectorize.AstraVectorizeComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Vectorize","group_outputs":false,"method":"build_options","name":"config","selected":"dict","tool_mode":true,"types":["dict"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["datastax.AstraDB"],"template":{"_type":"Component","api_key_name":{"_input_type":"MessageTextInput","advanced":false,"display_name":"API Key name","dynamic":false,"info":"The name of the embeddings provider API key stored on Astra. If set, it will override the 'ProviderKey' in the authentication parameters.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"api_key_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"authentication":{"_input_type":"DictInput","advanced":true,"display_name":"Authentication Parameters","dynamic":false,"info":"","list":true,"list_add_label":"Add More","name":"authentication","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import DictInput, DropdownInput, MessageTextInput, SecretStrInput\nfrom lfx.template.field.base import Output\n\n\nclass AstraVectorizeComponent(Component):\n    display_name: str = \"Astra Vectorize\"\n    description: str = \"Configuration options for Astra Vectorize server-side embeddings. \"\n    documentation: str = \"https://docs.datastax.com/en/astra-db-serverless/databases/embedding-generation.html\"\n    legacy = True\n    icon = \"AstraDB\"\n    name = \"AstraVectorize\"\n    replacement = [\"datastax.AstraDB\"]\n\n    VECTORIZE_PROVIDERS_MAPPING = {\n        \"Azure OpenAI\": [\"azureOpenAI\", [\"text-embedding-3-small\", \"text-embedding-3-large\", \"text-embedding-ada-002\"]],\n        \"Hugging Face - Dedicated\": [\"huggingfaceDedicated\", [\"endpoint-defined-model\"]],\n        \"Hugging Face - Serverless\": [\n            \"huggingface\",\n            [\n                \"sentence-transformers/all-MiniLM-L6-v2\",\n                \"intfloat/multilingual-e5-large\",\n                \"intfloat/multilingual-e5-large-instruct\",\n                \"BAAI/bge-small-en-v1.5\",\n                \"BAAI/bge-base-en-v1.5\",\n                \"BAAI/bge-large-en-v1.5\",\n            ],\n        ],\n        \"Jina AI\": [\n            \"jinaAI\",\n            [\n                \"jina-embeddings-v2-base-en\",\n                \"jina-embeddings-v2-base-de\",\n                \"jina-embeddings-v2-base-es\",\n                \"jina-embeddings-v2-base-code\",\n                \"jina-embeddings-v2-base-zh\",\n            ],\n        ],\n        \"Mistral AI\": [\"mistral\", [\"mistral-embed\"]],\n        \"NVIDIA\": [\"nvidia\", [\"NV-Embed-QA\"]],\n        \"OpenAI\": [\"openai\", [\"text-embedding-3-small\", \"text-embedding-3-large\", \"text-embedding-ada-002\"]],\n        \"Upstage\": [\"upstageAI\", [\"solar-embedding-1-large\"]],\n        \"Voyage AI\": [\n            \"voyageAI\",\n            [\"voyage-large-2-instruct\", \"voyage-law-2\", \"voyage-code-2\", \"voyage-large-2\", \"voyage-2\"],\n        ],\n    }\n    VECTORIZE_MODELS_STR = \"\\n\\n\".join(\n        [provider + \": \" + (\", \".join(models[1])) for provider, models in VECTORIZE_PROVIDERS_MAPPING.items()]\n    )\n\n    inputs = [\n        DropdownInput(\n            name=\"provider\",\n            display_name=\"Provider\",\n            options=VECTORIZE_PROVIDERS_MAPPING.keys(),\n            value=\"\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            info=\"The embedding model to use for the selected provider. Each provider has a different set of models \"\n            f\"available (full list at https://docs.datastax.com/en/astra-db-serverless/databases/embedding-generation.html):\\n\\n{VECTORIZE_MODELS_STR}\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"api_key_name\",\n            display_name=\"API Key name\",\n            info=\"The name of the embeddings provider API key stored on Astra. \"\n            \"If set, it will override the 'ProviderKey' in the authentication parameters.\",\n        ),\n        DictInput(\n            name=\"authentication\",\n            display_name=\"Authentication parameters\",\n            is_list=True,\n            advanced=True,\n        ),\n        SecretStrInput(\n            name=\"provider_api_key\",\n            display_name=\"Provider API Key\",\n            info=\"An alternative to the Astra Authentication that passes an API key for the provider with each request \"\n            \"to Astra DB. \"\n            \"This may be used when Vectorize is configured for the collection, \"\n            \"but no corresponding provider secret is stored within Astra's key management system.\",\n            advanced=True,\n        ),\n        DictInput(\n            name=\"authentication\",\n            display_name=\"Authentication Parameters\",\n            is_list=True,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"model_parameters\",\n            display_name=\"Model Parameters\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Vectorize\", name=\"config\", method=\"build_options\", types=[\"dict\"]),\n    ]\n\n    def build_options(self) -> dict[str, Any]:\n        provider_value = self.VECTORIZE_PROVIDERS_MAPPING[self.provider][0]\n        authentication = {**(self.authentication or {})}\n        api_key_name = self.api_key_name\n        if api_key_name:\n            authentication[\"providerKey\"] = api_key_name\n        return {\n            # must match astrapy.info.VectorServiceOptions\n            \"collection_vector_service_options\": {\n                \"provider\": provider_value,\n                \"modelName\": self.model_name,\n                \"authentication\": authentication,\n                \"parameters\": self.model_parameters or {},\n            },\n            \"collection_embedding_api_key\": self.provider_api_key,\n        }\n"},"model_name":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Model Name","dynamic":false,"info":"The embedding model to use for the selected provider. Each provider has a different set of models available (full list at https://docs.datastax.com/en/astra-db-serverless/databases/embedding-generation.html):\n\nAzure OpenAI: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002\n\nHugging Face - Dedicated: endpoint-defined-model\n\nHugging Face - Serverless: sentence-transformers/all-MiniLM-L6-v2, intfloat/multilingual-e5-large, intfloat/multilingual-e5-large-instruct, BAAI/bge-small-en-v1.5, BAAI/bge-base-en-v1.5, BAAI/bge-large-en-v1.5\n\nJina AI: jina-embeddings-v2-base-en, jina-embeddings-v2-base-de, jina-embeddings-v2-base-es, jina-embeddings-v2-base-code, jina-embeddings-v2-base-zh\n\nMistral AI: mistral-embed\n\nNVIDIA: NV-Embed-QA\n\nOpenAI: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002\n\nUpstage: solar-embedding-1-large\n\nVoyage AI: voyage-large-2-instruct, voyage-law-2, voyage-code-2, voyage-large-2, voyage-2","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"model_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"model_parameters":{"_input_type":"DictInput","advanced":true,"display_name":"Model Parameters","dynamic":false,"info":"","list":true,"list_add_label":"Add More","name":"model_parameters","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"provider":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Provider","dynamic":false,"external_options":{},"info":"","name":"provider","options":["Azure OpenAI","Hugging Face - Dedicated","Hugging Face - Serverless","Jina AI","Mistral AI","NVIDIA","OpenAI","Upstage","Voyage AI"],"options_metadata":[],"placeholder":"","required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"provider_api_key":{"_input_type":"SecretStrInput","advanced":true,"display_name":"Provider API Key","dynamic":false,"info":"An alternative to the Astra Authentication that passes an API key for the provider with each request to Astra DB. This may be used when Vectorize is configured for the collection, but no corresponding provider secret is stored within Astra's key management system.","input_types":[],"load_from_db":true,"name":"provider_api_key","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""}},"tool_mode":false},"CassandraChatMemory":{"base_classes":["Memory"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Retrieves and store chat messages from Apache Cassandra.","display_name":"Cassandra Chat Memory","documentation":"","edited":false,"field_order":["database_ref","username","token","keyspace","table_name","session_id","cluster_kwargs"],"frozen":false,"icon":"Cassandra","legacy":false,"metadata":{"code_hash":"f6497182984e","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"langchain_community","version":"0.3.21"},{"name":"cassio","version":null}],"total_dependencies":3},"module":"lfx.components.datastax.cassandra.CassandraChatMemory"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Memory","group_outputs":false,"method":"build_message_history","name":"memory","selected":"Memory","tool_mode":true,"types":["Memory"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","cluster_kwargs":{"_input_type":"DictInput","advanced":true,"display_name":"Cluster arguments","dynamic":false,"info":"Optional dictionary of additional keyword arguments for the Cassandra cluster.","list":true,"list_add_label":"Add More","name":"cluster_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.memory.model import LCChatMemoryComponent\nfrom lfx.field_typing.constants import Memory\nfrom lfx.inputs.inputs import DictInput, MessageTextInput, SecretStrInput\n\n\nclass CassandraChatMemory(LCChatMemoryComponent):\n    display_name = \"Cassandra Chat Memory\"\n    description = \"Retrieves and store chat messages from Apache Cassandra.\"\n    name = \"CassandraChatMemory\"\n    icon = \"Cassandra\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"database_ref\",\n            display_name=\"Contact Points / Astra Database ID\",\n            info=\"Contact points for the database (or Astra DB database ID)\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"username\", display_name=\"Username\", info=\"Username for the database (leave empty for Astra DB).\"\n        ),\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Password / Astra DB Token\",\n            info=\"User password for the database (or Astra DB token).\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"keyspace\",\n            display_name=\"Keyspace\",\n            info=\"Table Keyspace (or Astra DB namespace).\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"table_name\",\n            display_name=\"Table Name\",\n            info=\"The name of the table (or Astra DB collection) where vectors will be stored.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        DictInput(\n            name=\"cluster_kwargs\",\n            display_name=\"Cluster arguments\",\n            info=\"Optional dictionary of additional keyword arguments for the Cassandra cluster.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n\n    def build_message_history(self) -> Memory:\n        from langchain_community.chat_message_histories import CassandraChatMessageHistory\n\n        try:\n            import cassio\n        except ImportError as e:\n            msg = \"Could not import cassio integration package. Please install it with `pip install cassio`.\"\n            raise ImportError(msg) from e\n\n        from uuid import UUID\n\n        database_ref = self.database_ref\n\n        try:\n            UUID(self.database_ref)\n            is_astra = True\n        except ValueError:\n            is_astra = False\n            if \",\" in self.database_ref:\n                # use a copy because we can't change the type of the parameter\n                database_ref = self.database_ref.split(\",\")\n\n        if is_astra:\n            cassio.init(\n                database_id=database_ref,\n                token=self.token,\n                cluster_kwargs=self.cluster_kwargs,\n            )\n        else:\n            cassio.init(\n                contact_points=database_ref,\n                username=self.username,\n                password=self.token,\n                cluster_kwargs=self.cluster_kwargs,\n            )\n\n        return CassandraChatMessageHistory(\n            session_id=self.session_id,\n            table_name=self.table_name,\n            keyspace=self.keyspace,\n        )\n"},"database_ref":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Contact Points / Astra Database ID","dynamic":false,"info":"Contact points for the database (or Astra DB database ID)","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"database_ref","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"keyspace":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Keyspace","dynamic":false,"info":"Table Keyspace (or Astra DB namespace).","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"keyspace","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"session_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Session ID","dynamic":false,"info":"Session ID for the message.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"session_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"table_name":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Table Name","dynamic":false,"info":"The name of the table (or Astra DB collection) where vectors will be stored.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"table_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password / Astra DB Token","dynamic":false,"info":"User password for the database (or Astra DB token).","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"username":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Username","dynamic":false,"info":"Username for the database (leave empty for Astra DB).","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"Dotenv":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Load .env file into env vars","display_name":"Dotenv","documentation":"","edited":false,"field_order":["dotenv_file_content"],"frozen":false,"icon":"AstraDB","legacy":false,"metadata":{"code_hash":"4bb9b56b951c","dependencies":{"dependencies":[{"name":"dotenv","version":"1.1.1"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.datastax.dotenv.Dotenv"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"env_set","group_outputs":false,"method":"process_inputs","name":"env_set","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import io\n\nfrom dotenv import load_dotenv\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import MultilineSecretInput\nfrom lfx.schema.message import Message\nfrom lfx.template.field.base import Output\n\n\nclass Dotenv(Component):\n    display_name = \"Dotenv\"\n    description = \"Load .env file into env vars\"\n    icon = \"AstraDB\"\n    inputs = [\n        MultilineSecretInput(\n            name=\"dotenv_file_content\",\n            display_name=\"Dotenv file content\",\n            info=\"Paste the content of your .env file directly, since contents are sensitive, \"\n            \"using a Global variable set as 'password' is recommended\",\n        )\n    ]\n\n    outputs = [\n        Output(display_name=\"env_set\", name=\"env_set\", method=\"process_inputs\"),\n    ]\n\n    def process_inputs(self) -> Message:\n        fake_file = io.StringIO(self.dotenv_file_content)\n        result = load_dotenv(stream=fake_file, override=True)\n\n        message = Message(text=\"No variables found in .env\")\n        if result:\n            message = Message(text=\"Loaded .env\")\n        return message\n"},"dotenv_file_content":{"_input_type":"MultilineSecretInput","advanced":false,"display_name":"Dotenv file content","dynamic":false,"info":"Paste the content of your .env file directly, since contents are sensitive, using a Global variable set as 'password' is recommended","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"dotenv_file_content","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"GetEnvVar":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Gets the value of an environment variable from the system.","display_name":"Get Environment Variable","documentation":"","edited":false,"field_order":["env_var_name"],"frozen":false,"icon":"AstraDB","legacy":false,"metadata":{"code_hash":"adb837972e39","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.datastax.getenvvar.GetEnvVar"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Environment Variable Value","group_outputs":false,"method":"process_inputs","name":"env_var_value","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import os\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import StrInput\nfrom lfx.schema.message import Message\nfrom lfx.template.field.base import Output\n\n\nclass GetEnvVar(Component):\n    display_name = \"Get Environment Variable\"\n    description = \"Gets the value of an environment variable from the system.\"\n    icon = \"AstraDB\"\n\n    inputs = [\n        StrInput(\n            name=\"env_var_name\",\n            display_name=\"Environment Variable Name\",\n            info=\"Name of the environment variable to get\",\n        )\n    ]\n\n    outputs = [\n        Output(display_name=\"Environment Variable Value\", name=\"env_var_value\", method=\"process_inputs\"),\n    ]\n\n    def process_inputs(self) -> Message:\n        if self.env_var_name not in os.environ:\n            msg = f\"Environment variable {self.env_var_name} not set\"\n            raise ValueError(msg)\n        return Message(text=os.environ[self.env_var_name])\n"},"env_var_name":{"_input_type":"StrInput","advanced":false,"display_name":"Environment Variable Name","dynamic":false,"info":"Name of the environment variable to get","list":false,"list_add_label":"Add More","load_from_db":false,"name":"env_var_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"Graph RAG":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Graph RAG traversal for vector store.","display_name":"Graph RAG","documentation":"","edited":false,"field_order":["embedding_model","vector_store","edge_definition","strategy","search_query","graphrag_strategy_kwargs"],"frozen":false,"icon":"AstraDB","legacy":false,"metadata":{"code_hash":"e0d9984248d2","dependencies":{"dependencies":[{"name":"graph_retriever","version":"0.8.0"},{"name":"langchain_graph_retriever","version":"0.8.0"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.datastax.graph_rag.GraphRAGComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import inspect\nfrom abc import ABC\n\nimport graph_retriever.strategies as strategies_module\nfrom langchain_graph_retriever import GraphRetriever\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.inputs.inputs import DropdownInput, HandleInput, MultilineInput, NestedDictInput, StrInput\nfrom lfx.schema.data import Data\n\n\ndef traversal_strategies() -> list[str]:\n    \"\"\"Retrieves a list of class names from the strategies_module.\n\n    This function uses the `inspect` module to get all the class members\n    from the `strategies_module` and returns their names as a list of strings.\n\n    Returns:\n        list[str]: A list of strategy class names.\n    \"\"\"\n    classes = inspect.getmembers(strategies_module, inspect.isclass)\n    return [name for name, cls in classes if ABC not in cls.__bases__]\n\n\nclass GraphRAGComponent(LCVectorStoreComponent):\n    \"\"\"GraphRAGComponent is a component for performing Graph RAG traversal in a vector store.\n\n    Attributes:\n        display_name (str): The display name of the component.\n        description (str): A brief description of the component.\n        name (str): The name of the component.\n        icon (str): The icon representing the component.\n        inputs (list): A list of input configurations for the component.\n\n    Methods:\n        _build_search_args():\n            Builds the arguments required for the search operation.\n        search_documents() -> list[Data]:\n            Searches for documents using the specified strategy, edge definition, and query.\n        _edge_definition_from_input() -> tuple:\n            Processes the edge definition input and returns it as a tuple.\n    \"\"\"\n\n    display_name: str = \"Graph RAG\"\n    description: str = \"Graph RAG traversal for vector store.\"\n    name = \"Graph RAG\"\n    icon: str = \"AstraDB\"\n\n    inputs = [\n        HandleInput(\n            name=\"embedding_model\",\n            display_name=\"Embedding Model\",\n            input_types=[\"Embeddings\"],\n            info=\"Specify the Embedding Model. Not required for Astra Vectorize collections.\",\n            required=False,\n        ),\n        HandleInput(\n            name=\"vector_store\",\n            display_name=\"Vector Store Connection\",\n            input_types=[\"VectorStore\"],\n            info=\"Connection to Vector Store.\",\n        ),\n        StrInput(\n            name=\"edge_definition\",\n            display_name=\"Edge Definition\",\n            info=\"Edge definition for the graph traversal.\",\n        ),\n        DropdownInput(\n            name=\"strategy\",\n            display_name=\"Traversal Strategies\",\n            options=traversal_strategies(),\n        ),\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n            tool_mode=True,\n        ),\n        NestedDictInput(\n            name=\"graphrag_strategy_kwargs\",\n            display_name=\"Strategy Parameters\",\n            info=(\n                \"Optional dictionary of additional parameters for the retrieval strategy. \"\n                \"Please see https://datastax.github.io/graph-rag/reference/graph_retriever/strategies/ for details.\"\n            ),\n            advanced=True,\n        ),\n    ]\n\n    def search_documents(self) -> list[Data]:\n        \"\"\"Searches for documents using the graph retriever based on the selected strategy, edge definition, and query.\n\n        Returns:\n            list[Data]: A list of retrieved documents.\n\n        Raises:\n            AttributeError: If there is an issue with attribute access.\n            TypeError: If there is a type mismatch.\n            ValueError: If there is a value error.\n        \"\"\"\n        additional_params = self.graphrag_strategy_kwargs or {}\n\n        # Invoke the graph retriever based on the selected strategy, edge definition, and query\n        strategy_class = getattr(strategies_module, self.strategy)\n        retriever = GraphRetriever(\n            store=self.vector_store,\n            edges=[self._evaluate_edge_definition_input()],\n            strategy=strategy_class(**additional_params),\n        )\n\n        return docs_to_data(retriever.invoke(self.search_query))\n\n    def _edge_definition_from_input(self) -> tuple:\n        \"\"\"Generates the edge definition from the input data.\n\n        Returns:\n            tuple: A tuple representing the edge definition.\n        \"\"\"\n        values = self.edge_definition.split(\",\")\n        values = [value.strip() for value in values]\n\n        return tuple(values)\n\n    def _evaluate_edge_definition_input(self) -> tuple:\n        from graph_retriever.edges.metadata import Id\n\n        \"\"\"Evaluates the edge definition, converting any function calls from strings.\n\n        Args:\n            edge_definition (tuple): The edge definition to evaluate.\n\n        Returns:\n            tuple: The evaluated edge definition.\n        \"\"\"\n        evaluated_values = []\n        for value in self._edge_definition_from_input():\n            if value == \"Id()\":\n                evaluated_values.append(Id())  # Evaluate Id() as a function call\n            else:\n                evaluated_values.append(value)\n        return tuple(evaluated_values)\n"},"edge_definition":{"_input_type":"StrInput","advanced":false,"display_name":"Edge Definition","dynamic":false,"info":"Edge definition for the graph traversal.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"edge_definition","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"embedding_model":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding Model","dynamic":false,"info":"Specify the Embedding Model. Not required for Astra Vectorize collections.","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding_model","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"graphrag_strategy_kwargs":{"_input_type":"NestedDictInput","advanced":true,"display_name":"Strategy Parameters","dynamic":false,"info":"Optional dictionary of additional parameters for the retrieval strategy. Please see https://datastax.github.io/graph-rag/reference/graph_retriever/strategies/ for details.","list":false,"list_add_label":"Add More","name":"graphrag_strategy_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"NestedDict","value":{}},"search_query":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Search Query","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"search_query","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"strategy":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Traversal Strategies","dynamic":false,"external_options":{},"info":"","name":"strategy","options":["Eager","Mmr","NodeTracker","Scored"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"vector_store":{"_input_type":"HandleInput","advanced":false,"display_name":"Vector Store Connection","dynamic":false,"info":"Connection to Vector Store.","input_types":["VectorStore"],"list":false,"list_add_label":"Add More","name":"vector_store","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""}},"tool_mode":false},"HCD":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Implementation of Vector Store using Hyper-Converged Database (HCD) with search capabilities","display_name":"Hyper-Converged Database","documentation":"https://docs.langflow.org/bundles-datastax#hyper-converged-database-hcd","edited":false,"field_order":["collection_name","username","password","api_endpoint","ingest_data","search_query","should_cache_vector_store","namespace","ca_certificate","metric","batch_size","bulk_insert_batch_concurrency","bulk_insert_overwrite_concurrency","bulk_delete_concurrency","setup_mode","pre_delete_collection","metadata_indexing_include","embedding","metadata_indexing_exclude","collection_indexing_policy","number_of_results","search_type","search_score_threshold","search_filter"],"frozen":false,"icon":"HCD","legacy":false,"metadata":{"code_hash":"7e7469e03bc5","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"langchain_astradb","version":"0.6.1"},{"name":"astrapy","version":"2.1.0"}],"total_dependencies":3},"module":"lfx.components.datastax.hcd.HCDVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_endpoint":{"_input_type":"SecretStrInput","advanced":false,"display_name":"HCD API Endpoint","dynamic":false,"info":"API endpoint URL for the HCD service.","input_types":[],"load_from_db":true,"name":"api_endpoint","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"HCD_API_ENDPOINT"},"batch_size":{"_input_type":"IntInput","advanced":true,"display_name":"Batch Size","dynamic":false,"info":"Optional number of data to process in a single batch.","list":false,"list_add_label":"Add More","name":"batch_size","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"bulk_delete_concurrency":{"_input_type":"IntInput","advanced":true,"display_name":"Bulk Delete Concurrency","dynamic":false,"info":"Optional concurrency level for bulk delete operations.","list":false,"list_add_label":"Add More","name":"bulk_delete_concurrency","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"bulk_insert_batch_concurrency":{"_input_type":"IntInput","advanced":true,"display_name":"Bulk Insert Batch Concurrency","dynamic":false,"info":"Optional concurrency level for bulk insert operations.","list":false,"list_add_label":"Add More","name":"bulk_insert_batch_concurrency","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"bulk_insert_overwrite_concurrency":{"_input_type":"IntInput","advanced":true,"display_name":"Bulk Insert Overwrite Concurrency","dynamic":false,"info":"Optional concurrency level for bulk insert operations that overwrite existing data.","list":false,"list_add_label":"Add More","name":"bulk_insert_overwrite_concurrency","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"ca_certificate":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"CA Certificate","dynamic":false,"info":"Optional CA certificate for TLS connections to HCD.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"ca_certificate","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.inputs.inputs import DictInput, FloatInput\nfrom lfx.io import (\n    BoolInput,\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    MultilineInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass HCDVectorStoreComponent(LCVectorStoreComponent):\n    display_name: str = \"Hyper-Converged Database\"\n    description: str = \"Implementation of Vector Store using Hyper-Converged Database (HCD) with search capabilities\"\n    name = \"HCD\"\n    documentation: str = \"https://docs.langflow.org/bundles-datastax#hyper-converged-database-hcd\"\n    icon: str = \"HCD\"\n\n    inputs = [\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            info=\"The name of the collection within HCD where the vectors will be stored.\",\n            required=True,\n        ),\n        StrInput(\n            name=\"username\",\n            display_name=\"HCD Username\",\n            info=\"Authentication username for accessing HCD.\",\n            value=\"hcd-superuser\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"password\",\n            display_name=\"HCD Password\",\n            info=\"Authentication password for accessing HCD.\",\n            value=\"HCD_PASSWORD\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_endpoint\",\n            display_name=\"HCD API Endpoint\",\n            info=\"API endpoint URL for the HCD service.\",\n            value=\"HCD_API_ENDPOINT\",\n            required=True,\n        ),\n        *LCVectorStoreComponent.inputs,\n        StrInput(\n            name=\"namespace\",\n            display_name=\"Namespace\",\n            info=\"Optional namespace within HCD to use for the collection.\",\n            value=\"default_namespace\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"ca_certificate\",\n            display_name=\"CA Certificate\",\n            info=\"Optional CA certificate for TLS connections to HCD.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"metric\",\n            display_name=\"Metric\",\n            info=\"Optional distance metric for vector comparisons in the vector store.\",\n            options=[\"cosine\", \"dot_product\", \"euclidean\"],\n            advanced=True,\n        ),\n        IntInput(\n            name=\"batch_size\",\n            display_name=\"Batch Size\",\n            info=\"Optional number of data to process in a single batch.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_batch_concurrency\",\n            display_name=\"Bulk Insert Batch Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_overwrite_concurrency\",\n            display_name=\"Bulk Insert Overwrite Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations that overwrite existing data.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_delete_concurrency\",\n            display_name=\"Bulk Delete Concurrency\",\n            info=\"Optional concurrency level for bulk delete operations.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"setup_mode\",\n            display_name=\"Setup Mode\",\n            info=\"Configuration mode for setting up the vector store, with options like 'Sync', 'Async', or 'Off'.\",\n            options=[\"Sync\", \"Async\", \"Off\"],\n            advanced=True,\n            value=\"Sync\",\n        ),\n        BoolInput(\n            name=\"pre_delete_collection\",\n            display_name=\"Pre Delete Collection\",\n            info=\"Boolean flag to determine whether to delete the collection before creating a new one.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"metadata_indexing_include\",\n            display_name=\"Metadata Indexing Include\",\n            info=\"Optional list of metadata fields to include in the indexing.\",\n            advanced=True,\n        ),\n        HandleInput(\n            name=\"embedding\",\n            display_name=\"Embedding or Astra Vectorize\",\n            input_types=[\"Embeddings\", \"dict\"],\n            # TODO: This should be optional, but need to refactor langchain-astradb first.\n            info=\"Allows either an embedding model or an Astra Vectorize configuration.\",\n        ),\n        StrInput(\n            name=\"metadata_indexing_exclude\",\n            display_name=\"Metadata Indexing Exclude\",\n            info=\"Optional list of metadata fields to exclude from the indexing.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"collection_indexing_policy\",\n            display_name=\"Collection Indexing Policy\",\n            info=\"Optional dictionary defining the indexing policy for the collection.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            info=\"Search type to use\",\n            options=[\"Similarity\", \"Similarity with score threshold\", \"MMR (Max Marginal Relevance)\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results. \"\n            \"(when using 'Similarity with score threshold')\",\n            value=0,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"search_filter\",\n            display_name=\"Search Metadata Filter\",\n            info=\"Optional dictionary of filters to apply to the search query.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self):\n        try:\n            from langchain_astradb import AstraDBVectorStore\n            from langchain_astradb.utils.astradb import SetupMode\n        except ImportError as e:\n            msg = (\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n            raise ImportError(msg) from e\n\n        try:\n            from astrapy.authentication import UsernamePasswordTokenProvider\n            from astrapy.constants import Environment\n        except ImportError as e:\n            msg = \"Could not import astrapy integration package. Please install it with `pip install astrapy`.\"\n            raise ImportError(msg) from e\n\n        try:\n            if not self.setup_mode:\n                self.setup_mode = self._inputs[\"setup_mode\"].options[0]\n\n            setup_mode_value = SetupMode[self.setup_mode.upper()]\n        except KeyError as e:\n            msg = f\"Invalid setup mode: {self.setup_mode}\"\n            raise ValueError(msg) from e\n\n        if not isinstance(self.embedding, dict):\n            embedding_dict = {\"embedding\": self.embedding}\n        else:\n            from astrapy.info import VectorServiceOptions\n\n            dict_options = self.embedding.get(\"collection_vector_service_options\", {})\n            dict_options[\"authentication\"] = {\n                k: v for k, v in dict_options.get(\"authentication\", {}).items() if k and v\n            }\n            dict_options[\"parameters\"] = {k: v for k, v in dict_options.get(\"parameters\", {}).items() if k and v}\n            embedding_dict = {\"collection_vector_service_options\": VectorServiceOptions.from_dict(dict_options)}\n            collection_embedding_api_key = self.embedding.get(\"collection_embedding_api_key\")\n            if collection_embedding_api_key:\n                embedding_dict[\"collection_embedding_api_key\"] = collection_embedding_api_key\n\n        token_provider = UsernamePasswordTokenProvider(self.username, self.password)\n        vector_store_kwargs = {\n            **embedding_dict,\n            \"collection_name\": self.collection_name,\n            \"token\": token_provider,\n            \"api_endpoint\": self.api_endpoint,\n            \"namespace\": self.namespace,\n            \"metric\": self.metric or None,\n            \"batch_size\": self.batch_size or None,\n            \"bulk_insert_batch_concurrency\": self.bulk_insert_batch_concurrency or None,\n            \"bulk_insert_overwrite_concurrency\": self.bulk_insert_overwrite_concurrency or None,\n            \"bulk_delete_concurrency\": self.bulk_delete_concurrency or None,\n            \"setup_mode\": setup_mode_value,\n            \"pre_delete_collection\": self.pre_delete_collection or False,\n            \"environment\": Environment.HCD,\n        }\n\n        if self.metadata_indexing_include:\n            vector_store_kwargs[\"metadata_indexing_include\"] = self.metadata_indexing_include\n        elif self.metadata_indexing_exclude:\n            vector_store_kwargs[\"metadata_indexing_exclude\"] = self.metadata_indexing_exclude\n        elif self.collection_indexing_policy:\n            vector_store_kwargs[\"collection_indexing_policy\"] = self.collection_indexing_policy\n\n        try:\n            vector_store = AstraDBVectorStore(**vector_store_kwargs)\n        except Exception as e:\n            msg = f\"Error initializing AstraDBVectorStore: {e}\"\n            raise ValueError(msg) from e\n\n        self._add_documents_to_vector_store(vector_store)\n        return vector_store\n\n    def _add_documents_to_vector_store(self, vector_store) -> None:\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                msg = \"Vector Store Inputs must be Data objects.\"\n                raise TypeError(msg)\n\n        if documents:\n            self.log(f\"Adding {len(documents)} documents to the Vector Store.\")\n            try:\n                vector_store.add_documents(documents)\n            except Exception as e:\n                msg = f\"Error adding documents to AstraDBVectorStore: {e}\"\n                raise ValueError(msg) from e\n        else:\n            self.log(\"No documents to add to the Vector Store.\")\n\n    def _map_search_type(self) -> str:\n        if self.search_type == \"Similarity with score threshold\":\n            return \"similarity_score_threshold\"\n        if self.search_type == \"MMR (Max Marginal Relevance)\":\n            return \"mmr\"\n        return \"similarity\"\n\n    def _build_search_args(self):\n        args = {\n            \"k\": self.number_of_results,\n            \"score_threshold\": self.search_score_threshold,\n        }\n\n        if self.search_filter:\n            clean_filter = {k: v for k, v in self.search_filter.items() if k and v}\n            if len(clean_filter) > 0:\n                args[\"filter\"] = clean_filter\n        return args\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        self.log(f\"Search query: {self.search_query}\")\n        self.log(f\"Search type: {self.search_type}\")\n        self.log(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            try:\n                search_type = self._map_search_type()\n                search_args = self._build_search_args()\n\n                docs = vector_store.search(query=self.search_query, search_type=search_type, **search_args)\n            except Exception as e:\n                msg = f\"Error performing search in AstraDBVectorStore: {e}\"\n                raise ValueError(msg) from e\n\n            self.log(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n            self.log(f\"Converted documents to data: {len(data)}\")\n            self.status = data\n            return data\n        self.log(\"No search input provided. Skipping search.\")\n        return []\n\n    def get_retriever_kwargs(self):\n        search_args = self._build_search_args()\n        return {\n            \"search_type\": self._map_search_type(),\n            \"search_kwargs\": search_args,\n        }\n"},"collection_indexing_policy":{"_input_type":"StrInput","advanced":true,"display_name":"Collection Indexing Policy","dynamic":false,"info":"Optional dictionary defining the indexing policy for the collection.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_indexing_policy","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"collection_name":{"_input_type":"StrInput","advanced":false,"display_name":"Collection Name","dynamic":false,"info":"The name of the collection within HCD where the vectors will be stored.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding or Astra Vectorize","dynamic":false,"info":"Allows either an embedding model or an Astra Vectorize configuration.","input_types":["Embeddings","dict"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"metadata_indexing_exclude":{"_input_type":"StrInput","advanced":true,"display_name":"Metadata Indexing Exclude","dynamic":false,"info":"Optional list of metadata fields to exclude from the indexing.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"metadata_indexing_exclude","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"metadata_indexing_include":{"_input_type":"StrInput","advanced":true,"display_name":"Metadata Indexing Include","dynamic":false,"info":"Optional list of metadata fields to include in the indexing.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"metadata_indexing_include","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"metric":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Metric","dynamic":false,"external_options":{},"info":"Optional distance metric for vector comparisons in the vector store.","name":"metric","options":["cosine","dot_product","euclidean"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"namespace":{"_input_type":"StrInput","advanced":true,"display_name":"Namespace","dynamic":false,"info":"Optional namespace within HCD to use for the collection.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"namespace","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"default_namespace"},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"HCD Password","dynamic":false,"info":"Authentication password for accessing HCD.","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"HCD_PASSWORD"},"pre_delete_collection":{"_input_type":"BoolInput","advanced":true,"display_name":"Pre Delete Collection","dynamic":false,"info":"Boolean flag to determine whether to delete the collection before creating a new one.","list":false,"list_add_label":"Add More","name":"pre_delete_collection","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"search_filter":{"_input_type":"DictInput","advanced":true,"display_name":"Search Metadata Filter","dynamic":false,"info":"Optional dictionary of filters to apply to the search query.","list":true,"list_add_label":"Add More","name":"search_filter","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"search_score_threshold":{"_input_type":"FloatInput","advanced":true,"display_name":"Search Score Threshold","dynamic":false,"info":"Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')","list":false,"list_add_label":"Add More","name":"search_score_threshold","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.0},"search_type":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Search Type","dynamic":false,"external_options":{},"info":"Search type to use","name":"search_type","options":["Similarity","Similarity with score threshold","MMR (Max Marginal Relevance)"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Similarity"},"setup_mode":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Setup Mode","dynamic":false,"external_options":{},"info":"Configuration mode for setting up the vector store, with options like 'Sync', 'Async', or 'Off'.","name":"setup_mode","options":["Sync","Async","Off"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Sync"},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"username":{"_input_type":"StrInput","advanced":false,"display_name":"HCD Username","dynamic":false,"info":"Authentication username for accessing HCD.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"hcd-superuser"}},"tool_mode":false}}],["deepseek",{"DeepSeekModelComponent":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate text using DeepSeek LLMs.","display_name":"DeepSeek","documentation":"","edited":false,"field_order":["input_value","system_message","stream","max_tokens","model_kwargs","json_mode","model_name","api_base","api_key","temperature","seed"],"frozen":false,"icon":"DeepSeek","legacy":false,"metadata":{"code_hash":"c8dac7a258d7","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"pydantic","version":"2.10.6"},{"name":"typing_extensions","version":"4.15.0"},{"name":"lfx","version":null},{"name":"langchain_openai","version":"0.3.23"},{"name":"openai","version":"1.82.1"}],"total_dependencies":6},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.deepseek.deepseek.DeepSeekModelComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_base":{"_input_type":"StrInput","advanced":true,"display_name":"DeepSeek API Base","dynamic":false,"info":"Base URL for API requests. Defaults to https://api.deepseek.com","list":false,"list_add_label":"Add More","load_from_db":false,"name":"api_base","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"https://api.deepseek.com"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"DeepSeek API Key","dynamic":false,"info":"The DeepSeek API Key","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import requests\nfrom pydantic.v1 import SecretStr\nfrom typing_extensions import override\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.inputs.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\n\nDEEPSEEK_MODELS = [\"deepseek-chat\"]\n\n\nclass DeepSeekModelComponent(LCModelComponent):\n    display_name = \"DeepSeek\"\n    description = \"Generate text using DeepSeek LLMs.\"\n    icon = \"DeepSeek\"\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"Maximum number of tokens to generate. Set to 0 for unlimited.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            info=\"DeepSeek model to use\",\n            options=DEEPSEEK_MODELS,\n            value=\"deepseek-chat\",\n            refresh_button=True,\n        ),\n        StrInput(\n            name=\"api_base\",\n            display_name=\"DeepSeek API Base\",\n            advanced=True,\n            info=\"Base URL for API requests. Defaults to https://api.deepseek.com\",\n            value=\"https://api.deepseek.com\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"DeepSeek API Key\",\n            info=\"The DeepSeek API Key\",\n            advanced=False,\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            info=\"Controls randomness in responses\",\n            value=1.0,\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def get_models(self) -> list[str]:\n        if not self.api_key:\n            return DEEPSEEK_MODELS\n\n        url = f\"{self.api_base}/models\"\n        headers = {\"Authorization\": f\"Bearer {self.api_key}\", \"Accept\": \"application/json\"}\n\n        try:\n            response = requests.get(url, headers=headers, timeout=10)\n            response.raise_for_status()\n            model_list = response.json()\n            return [model[\"id\"] for model in model_list.get(\"data\", [])]\n        except requests.RequestException as e:\n            self.status = f\"Error fetching models: {e}\"\n            return DEEPSEEK_MODELS\n\n    @override\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\n        if field_name in {\"api_key\", \"api_base\", \"model_name\"}:\n            models = self.get_models()\n            build_config[\"model_name\"][\"options\"] = models\n        return build_config\n\n    def build_model(self) -> LanguageModel:\n        try:\n            from langchain_openai import ChatOpenAI\n        except ImportError as e:\n            msg = \"langchain-openai not installed. Please install with `pip install langchain-openai`\"\n            raise ImportError(msg) from e\n\n        api_key = SecretStr(self.api_key).get_secret_value() if self.api_key else None\n        output = ChatOpenAI(\n            model=self.model_name,\n            temperature=self.temperature if self.temperature is not None else 0.1,\n            max_tokens=self.max_tokens or None,\n            model_kwargs=self.model_kwargs or {},\n            base_url=self.api_base,\n            api_key=api_key,\n            streaming=self.stream if hasattr(self, \"stream\") else False,\n            seed=self.seed,\n        )\n\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get message from DeepSeek API exception.\"\"\"\n        try:\n            from openai import BadRequestError\n\n            if isinstance(e, BadRequestError):\n                message = e.body.get(\"message\")\n                if message:\n                    return message\n        except ImportError:\n            pass\n        return None\n"},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"json_mode":{"_input_type":"BoolInput","advanced":true,"display_name":"JSON Mode","dynamic":false,"info":"If True, it will output JSON regardless of passing a schema.","list":false,"list_add_label":"Add More","name":"json_mode","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"max_tokens":{"_input_type":"IntInput","advanced":true,"display_name":"Max Tokens","dynamic":false,"info":"Maximum number of tokens to generate. Set to 0 for unlimited.","list":false,"list_add_label":"Add More","name":"max_tokens","placeholder":"","range_spec":{"max":128000.0,"min":0.0,"step":0.1,"step_type":"float"},"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"model_kwargs":{"_input_type":"DictInput","advanced":true,"display_name":"Model Kwargs","dynamic":false,"info":"Additional keyword arguments to pass to the model.","list":false,"list_add_label":"Add More","name":"model_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model Name","dynamic":false,"external_options":{},"info":"DeepSeek model to use","name":"model_name","options":["deepseek-chat"],"options_metadata":[],"placeholder":"","refresh_button":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"deepseek-chat"},"seed":{"_input_type":"IntInput","advanced":true,"display_name":"Seed","dynamic":false,"info":"The seed controls the reproducibility of the job.","list":false,"list_add_label":"Add More","name":"seed","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"SliderInput","advanced":true,"display_name":"Temperature","dynamic":false,"info":"Controls randomness in responses","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"temperature","placeholder":"","range_spec":{"max":2.0,"min":0.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":1.0}},"tool_mode":false}}],["docling",{"ChunkDoclingDocument":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Use the DocumentDocument chunkers to split the document into chunks.","display_name":"Chunk DoclingDocument","documentation":"https://docling-project.github.io/docling/concepts/chunking/","edited":false,"field_order":["data_inputs","chunker","provider","hf_model_name","openai_model_name","max_tokens","doc_key"],"frozen":false,"icon":"Docling","legacy":false,"metadata":{"code_hash":"397fa38f89d7","dependencies":{"dependencies":[{"name":"tiktoken","version":"0.12.0"},{"name":"docling_core","version":"2.48.4"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.docling.chunk_docling_document.ChunkDoclingDocumentComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"chunk_documents","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","chunker":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Chunker","dynamic":false,"external_options":{},"info":"Which chunker to use.","name":"chunker","options":["HybridChunker","HierarchicalChunker"],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"HybridChunker"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\n\nimport tiktoken\nfrom docling_core.transforms.chunker import BaseChunker, DocMeta\nfrom docling_core.transforms.chunker.hierarchical_chunker import HierarchicalChunker\n\nfrom lfx.base.data.docling_utils import extract_docling_documents\nfrom lfx.custom import Component\nfrom lfx.io import DropdownInput, HandleInput, IntInput, MessageTextInput, Output, StrInput\nfrom lfx.schema import Data, DataFrame\n\n\nclass ChunkDoclingDocumentComponent(Component):\n    display_name: str = \"Chunk DoclingDocument\"\n    description: str = \"Use the DocumentDocument chunkers to split the document into chunks.\"\n    documentation = \"https://docling-project.github.io/docling/concepts/chunking/\"\n    icon = \"Docling\"\n    name = \"ChunkDoclingDocument\"\n\n    inputs = [\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Data or DataFrame\",\n            info=\"The data with documents to split in chunks.\",\n            input_types=[\"Data\", \"DataFrame\"],\n            required=True,\n        ),\n        DropdownInput(\n            name=\"chunker\",\n            display_name=\"Chunker\",\n            options=[\"HybridChunker\", \"HierarchicalChunker\"],\n            info=(\"Which chunker to use.\"),\n            value=\"HybridChunker\",\n            real_time_refresh=True,\n        ),\n        DropdownInput(\n            name=\"provider\",\n            display_name=\"Provider\",\n            options=[\"Hugging Face\", \"OpenAI\"],\n            info=(\"Which tokenizer provider.\"),\n            value=\"Hugging Face\",\n            show=True,\n            real_time_refresh=True,\n            advanced=True,\n            dynamic=True,\n        ),\n        StrInput(\n            name=\"hf_model_name\",\n            display_name=\"HF model name\",\n            info=(\n                \"Model name of the tokenizer to use with the HybridChunker when Hugging Face is chosen as a tokenizer.\"\n            ),\n            value=\"sentence-transformers/all-MiniLM-L6-v2\",\n            show=True,\n            advanced=True,\n            dynamic=True,\n        ),\n        StrInput(\n            name=\"openai_model_name\",\n            display_name=\"OpenAI model name\",\n            info=(\"Model name of the tokenizer to use with the HybridChunker when OpenAI is chosen as a tokenizer.\"),\n            value=\"gpt-4o\",\n            show=False,\n            advanced=True,\n            dynamic=True,\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Maximum tokens\",\n            info=(\"Maximum number of tokens for the HybridChunker.\"),\n            show=True,\n            required=False,\n            advanced=True,\n            dynamic=True,\n        ),\n        MessageTextInput(\n            name=\"doc_key\",\n            display_name=\"Doc Key\",\n            info=\"The key to use for the DoclingDocument column.\",\n            value=\"doc\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"chunk_documents\"),\n    ]\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        if field_name == \"chunker\":\n            provider_type = build_config[\"provider\"][\"value\"]\n            is_hf = provider_type == \"Hugging Face\"\n            is_openai = provider_type == \"OpenAI\"\n            if field_value == \"HybridChunker\":\n                build_config[\"provider\"][\"show\"] = True\n                build_config[\"hf_model_name\"][\"show\"] = is_hf\n                build_config[\"openai_model_name\"][\"show\"] = is_openai\n                build_config[\"max_tokens\"][\"show\"] = True\n            else:\n                build_config[\"provider\"][\"show\"] = False\n                build_config[\"hf_model_name\"][\"show\"] = False\n                build_config[\"openai_model_name\"][\"show\"] = False\n                build_config[\"max_tokens\"][\"show\"] = False\n        elif field_name == \"provider\" and build_config[\"chunker\"][\"value\"] == \"HybridChunker\":\n            if field_value == \"Hugging Face\":\n                build_config[\"hf_model_name\"][\"show\"] = True\n                build_config[\"openai_model_name\"][\"show\"] = False\n            elif field_value == \"OpenAI\":\n                build_config[\"hf_model_name\"][\"show\"] = False\n                build_config[\"openai_model_name\"][\"show\"] = True\n\n        return build_config\n\n    def _docs_to_data(self, docs) -> list[Data]:\n        return [Data(text=doc.page_content, data=doc.metadata) for doc in docs]\n\n    def chunk_documents(self) -> DataFrame:\n        documents = extract_docling_documents(self.data_inputs, self.doc_key)\n\n        chunker: BaseChunker\n        if self.chunker == \"HybridChunker\":\n            try:\n                from docling_core.transforms.chunker.hybrid_chunker import HybridChunker\n            except ImportError as e:\n                msg = (\n                    \"HybridChunker is not installed. Please install it with `uv pip install docling-core[chunking] \"\n                    \"or `uv pip install transformers`\"\n                )\n                raise ImportError(msg) from e\n            max_tokens: int | None = self.max_tokens if self.max_tokens else None\n            if self.provider == \"Hugging Face\":\n                try:\n                    from docling_core.transforms.chunker.tokenizer.huggingface import HuggingFaceTokenizer\n                except ImportError as e:\n                    msg = (\n                        \"HuggingFaceTokenizer is not installed.\"\n                        \" Please install it with `uv pip install docling-core[chunking]`\"\n                    )\n                    raise ImportError(msg) from e\n                tokenizer = HuggingFaceTokenizer.from_pretrained(\n                    model_name=self.hf_model_name,\n                    max_tokens=max_tokens,\n                )\n            elif self.provider == \"OpenAI\":\n                try:\n                    from docling_core.transforms.chunker.tokenizer.openai import OpenAITokenizer\n                except ImportError as e:\n                    msg = (\n                        \"OpenAITokenizer is not installed.\"\n                        \" Please install it with `uv pip install docling-core[chunking]`\"\n                        \" or `uv pip install transformers`\"\n                    )\n                    raise ImportError(msg) from e\n                if max_tokens is None:\n                    max_tokens = 128 * 1024  # context window length required for OpenAI tokenizers\n                tokenizer = OpenAITokenizer(\n                    tokenizer=tiktoken.encoding_for_model(self.openai_model_name), max_tokens=max_tokens\n                )\n            chunker = HybridChunker(\n                tokenizer=tokenizer,\n            )\n        elif self.chunker == \"HierarchicalChunker\":\n            chunker = HierarchicalChunker()\n\n        results: list[Data] = []\n        try:\n            for doc in documents:\n                for chunk in chunker.chunk(dl_doc=doc):\n                    enriched_text = chunker.contextualize(chunk=chunk)\n                    meta = DocMeta.model_validate(chunk.meta)\n\n                    results.append(\n                        Data(\n                            data={\n                                \"text\": enriched_text,\n                                \"document_id\": f\"{doc.origin.binary_hash}\",\n                                \"doc_items\": json.dumps([item.self_ref for item in meta.doc_items]),\n                            }\n                        )\n                    )\n\n        except Exception as e:\n            msg = f\"Error splitting text: {e}\"\n            raise TypeError(msg) from e\n\n        return DataFrame(results)\n"},"data_inputs":{"_input_type":"HandleInput","advanced":false,"display_name":"Data or DataFrame","dynamic":false,"info":"The data with documents to split in chunks.","input_types":["Data","DataFrame"],"list":false,"list_add_label":"Add More","name":"data_inputs","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"doc_key":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Doc Key","dynamic":false,"info":"The key to use for the DoclingDocument column.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"doc_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"doc"},"hf_model_name":{"_input_type":"StrInput","advanced":true,"display_name":"HF model name","dynamic":true,"info":"Model name of the tokenizer to use with the HybridChunker when Hugging Face is chosen as a tokenizer.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"hf_model_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"sentence-transformers/all-MiniLM-L6-v2"},"max_tokens":{"_input_type":"IntInput","advanced":true,"display_name":"Maximum tokens","dynamic":true,"info":"Maximum number of tokens for the HybridChunker.","list":false,"list_add_label":"Add More","name":"max_tokens","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"openai_model_name":{"_input_type":"StrInput","advanced":true,"display_name":"OpenAI model name","dynamic":true,"info":"Model name of the tokenizer to use with the HybridChunker when OpenAI is chosen as a tokenizer.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"openai_model_name","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"gpt-4o"},"provider":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Provider","dynamic":true,"external_options":{},"info":"Which tokenizer provider.","name":"provider","options":["Hugging Face","OpenAI"],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Hugging Face"}},"tool_mode":false},"DoclingInline":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Uses Docling to process input documents running the Docling models locally.","display_name":"Docling","documentation":"https://docling-project.github.io/docling/","edited":false,"field_order":["path","file_path","separator","silent_errors","delete_server_file_after_processing","ignore_unsupported_extensions","ignore_unspecified_files","pipeline","ocr_engine","do_picture_classification","pic_desc_llm","pic_desc_prompt"],"frozen":false,"icon":"Docling","legacy":false,"metadata":{"code_hash":"d76b3853ceb4","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"docling","version":"2.57.0"}],"total_dependencies":2},"module":"lfx.components.docling.docling_inline.DoclingInlineComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Files","group_outputs":false,"method":"load_files","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import time\nfrom multiprocessing import Queue, get_context\nfrom queue import Empty\n\nfrom lfx.base.data import BaseFileComponent\nfrom lfx.base.data.docling_utils import _serialize_pydantic_model, docling_worker\nfrom lfx.inputs import BoolInput, DropdownInput, HandleInput, StrInput\nfrom lfx.schema import Data\n\n\nclass DoclingInlineComponent(BaseFileComponent):\n    display_name = \"Docling\"\n    description = \"Uses Docling to process input documents running the Docling models locally.\"\n    documentation = \"https://docling-project.github.io/docling/\"\n    trace_type = \"tool\"\n    icon = \"Docling\"\n    name = \"DoclingInline\"\n\n    # https://docling-project.github.io/docling/usage/supported_formats/\n    VALID_EXTENSIONS = [\n        \"adoc\",\n        \"asciidoc\",\n        \"asc\",\n        \"bmp\",\n        \"csv\",\n        \"dotx\",\n        \"dotm\",\n        \"docm\",\n        \"docx\",\n        \"htm\",\n        \"html\",\n        \"jpeg\",\n        \"json\",\n        \"md\",\n        \"pdf\",\n        \"png\",\n        \"potx\",\n        \"ppsx\",\n        \"pptm\",\n        \"potm\",\n        \"ppsm\",\n        \"pptx\",\n        \"tiff\",\n        \"txt\",\n        \"xls\",\n        \"xlsx\",\n        \"xhtml\",\n        \"xml\",\n        \"webp\",\n    ]\n\n    inputs = [\n        *BaseFileComponent.get_base_inputs(),\n        DropdownInput(\n            name=\"pipeline\",\n            display_name=\"Pipeline\",\n            info=\"Docling pipeline to use\",\n            options=[\"standard\", \"vlm\"],\n            value=\"standard\",\n        ),\n        DropdownInput(\n            name=\"ocr_engine\",\n            display_name=\"OCR Engine\",\n            info=\"OCR engine to use. None will disable OCR.\",\n            options=[\"None\", \"easyocr\", \"tesserocr\", \"rapidocr\", \"ocrmac\"],\n            value=\"None\",\n        ),\n        BoolInput(\n            name=\"do_picture_classification\",\n            display_name=\"Picture classification\",\n            info=\"If enabled, the Docling pipeline will classify the pictures type.\",\n            value=False,\n        ),\n        HandleInput(\n            name=\"pic_desc_llm\",\n            display_name=\"Picture description LLM\",\n            info=\"If connected, the model to use for running the picture description task.\",\n            input_types=[\"LanguageModel\"],\n            required=False,\n        ),\n        StrInput(\n            name=\"pic_desc_prompt\",\n            display_name=\"Picture description prompt\",\n            value=\"Describe the image in three sentences. Be concise and accurate.\",\n            info=\"The user prompt to use when invoking the model.\",\n            advanced=True,\n        ),\n        # TODO: expose more Docling options\n    ]\n\n    outputs = [\n        *BaseFileComponent.get_base_outputs(),\n    ]\n\n    def _wait_for_result_with_process_monitoring(self, queue: Queue, proc, timeout: int = 300):\n        \"\"\"Wait for result from queue while monitoring process health.\n\n        Handles cases where process crashes without sending result.\n        \"\"\"\n        start_time = time.time()\n\n        while time.time() - start_time < timeout:\n            # Check if process is still alive\n            if not proc.is_alive():\n                # Process died, try to get any result it might have sent\n                try:\n                    result = queue.get_nowait()\n                except Empty:\n                    # Process died without sending result\n                    msg = f\"Worker process crashed unexpectedly without producing result. Exit code: {proc.exitcode}\"\n                    raise RuntimeError(msg) from None\n                else:\n                    self.log(\"Process completed and result retrieved\")\n                    return result\n\n            # Poll the queue instead of blocking\n            try:\n                result = queue.get(timeout=1)\n            except Empty:\n                # No result yet, continue monitoring\n                continue\n            else:\n                self.log(\"Result received from worker process\")\n                return result\n\n        # Overall timeout reached\n        msg = f\"Process timed out after {timeout} seconds\"\n        raise TimeoutError(msg)\n\n    def _terminate_process_gracefully(self, proc, timeout_terminate: int = 10, timeout_kill: int = 5):\n        \"\"\"Terminate process gracefully with escalating signals.\n\n        First tries SIGTERM, then SIGKILL if needed.\n        \"\"\"\n        if not proc.is_alive():\n            return\n\n        self.log(\"Attempting graceful process termination with SIGTERM\")\n        proc.terminate()  # Send SIGTERM\n        proc.join(timeout=timeout_terminate)\n\n        if proc.is_alive():\n            self.log(\"Process didn't respond to SIGTERM, using SIGKILL\")\n            proc.kill()  # Send SIGKILL\n            proc.join(timeout=timeout_kill)\n\n            if proc.is_alive():\n                self.log(\"Warning: Process still alive after SIGKILL\")\n\n    def process_files(self, file_list: list[BaseFileComponent.BaseFile]) -> list[BaseFileComponent.BaseFile]:\n        try:\n            from docling.document_converter import DocumentConverter  # noqa: F401\n        except ImportError as e:\n            msg = (\n                \"Docling is an optional dependency. Install with `uv pip install 'langflow[docling]'` or refer to the \"\n                \"documentation on how to install optional dependencies.\"\n            )\n            raise ImportError(msg) from e\n\n        file_paths = [file.path for file in file_list if file.path]\n\n        if not file_paths:\n            self.log(\"No files to process.\")\n            return file_list\n\n        pic_desc_config: dict | None = None\n        if self.pic_desc_llm is not None:\n            pic_desc_config = _serialize_pydantic_model(self.pic_desc_llm)\n\n        ctx = get_context(\"spawn\")\n        queue: Queue = ctx.Queue()\n        proc = ctx.Process(\n            target=docling_worker,\n            kwargs={\n                \"file_paths\": file_paths,\n                \"queue\": queue,\n                \"pipeline\": self.pipeline,\n                \"ocr_engine\": self.ocr_engine,\n                \"do_picture_classification\": self.do_picture_classification,\n                \"pic_desc_config\": pic_desc_config,\n                \"pic_desc_prompt\": self.pic_desc_prompt,\n            },\n        )\n\n        result = None\n        proc.start()\n\n        try:\n            result = self._wait_for_result_with_process_monitoring(queue, proc, timeout=300)\n        except KeyboardInterrupt:\n            self.log(\"Docling process cancelled by user\")\n            result = []\n        except Exception as e:\n            self.log(f\"Error during processing: {e}\")\n            raise\n        finally:\n            # Improved cleanup with graceful termination\n            try:\n                self._terminate_process_gracefully(proc)\n            finally:\n                # Always close and cleanup queue resources\n                try:\n                    queue.close()\n                    queue.join_thread()\n                except Exception as e:  # noqa: BLE001\n                    # Ignore cleanup errors, but log them\n                    self.log(f\"Warning: Error during queue cleanup - {e}\")\n\n        # Enhanced error checking with dependency-specific handling\n        if isinstance(result, dict) and \"error\" in result:\n            error_msg = result[\"error\"]\n\n            # Handle dependency errors specifically\n            if result.get(\"error_type\") == \"dependency_error\":\n                dependency_name = result.get(\"dependency_name\", \"Unknown dependency\")\n                install_command = result.get(\"install_command\", \"Please check documentation\")\n\n                # Create a user-friendly error message\n                user_message = (\n                    f\"Missing OCR dependency: {dependency_name}. \"\n                    f\"{install_command} \"\n                    f\"Alternatively, you can set OCR Engine to 'None' to disable OCR processing.\"\n                )\n                raise ImportError(user_message)\n\n            # Handle other specific errors\n            if error_msg.startswith(\"Docling is not installed\"):\n                raise ImportError(error_msg)\n\n            # Handle graceful shutdown\n            if \"Worker interrupted by SIGINT\" in error_msg or \"shutdown\" in result:\n                self.log(\"Docling process cancelled by user\")\n                result = []\n            else:\n                raise RuntimeError(error_msg)\n\n        processed_data = [Data(data={\"doc\": r[\"document\"], \"file_path\": r[\"file_path\"]}) if r else None for r in result]\n        return self.rollup_data(file_list, processed_data)\n"},"delete_server_file_after_processing":{"_input_type":"BoolInput","advanced":true,"display_name":"Delete Server File After Processing","dynamic":false,"info":"If true, the Server File Path will be deleted after processing.","list":false,"list_add_label":"Add More","name":"delete_server_file_after_processing","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"do_picture_classification":{"_input_type":"BoolInput","advanced":false,"display_name":"Picture classification","dynamic":false,"info":"If enabled, the Docling pipeline will classify the pictures type.","list":false,"list_add_label":"Add More","name":"do_picture_classification","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"file_path":{"_input_type":"HandleInput","advanced":true,"display_name":"Server File Path","dynamic":false,"info":"Data object with a 'file_path' property pointing to server file or a Message object with a path to the file. Supercedes 'Path' but supports same file types.","input_types":["Data","Message"],"list":true,"list_add_label":"Add More","name":"file_path","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"ignore_unspecified_files":{"_input_type":"BoolInput","advanced":true,"display_name":"Ignore Unspecified Files","dynamic":false,"info":"If true, Data with no 'file_path' property will be ignored.","list":false,"list_add_label":"Add More","name":"ignore_unspecified_files","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"ignore_unsupported_extensions":{"_input_type":"BoolInput","advanced":true,"display_name":"Ignore Unsupported Extensions","dynamic":false,"info":"If true, files with unsupported extensions will not be processed.","list":false,"list_add_label":"Add More","name":"ignore_unsupported_extensions","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"ocr_engine":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"OCR Engine","dynamic":false,"external_options":{},"info":"OCR engine to use. None will disable OCR.","name":"ocr_engine","options":["None","easyocr","tesserocr","rapidocr","ocrmac"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"None"},"path":{"_input_type":"FileInput","advanced":false,"display_name":"Files","dynamic":false,"fileTypes":["adoc","asciidoc","asc","bmp","csv","dotx","dotm","docm","docx","htm","html","jpeg","json","md","pdf","png","potx","ppsx","pptm","potm","ppsm","pptx","tiff","txt","xls","xlsx","xhtml","xml","webp","zip","tar","tgz","bz2","gz"],"file_path":"","info":"Supported file extensions: adoc, asciidoc, asc, bmp, csv, dotx, dotm, docm, docx, htm, html, jpeg, json, md, pdf, png, potx, ppsx, pptm, potm, ppsm, pptx, tiff, txt, xls, xlsx, xhtml, xml, webp; optionally bundled in file extensions: zip, tar, tgz, bz2, gz","list":true,"list_add_label":"Add More","name":"path","placeholder":"","required":false,"show":true,"temp_file":false,"title_case":false,"tool_mode":true,"trace_as_metadata":true,"type":"file","value":[]},"pic_desc_llm":{"_input_type":"HandleInput","advanced":false,"display_name":"Picture description LLM","dynamic":false,"info":"If connected, the model to use for running the picture description task.","input_types":["LanguageModel"],"list":false,"list_add_label":"Add More","name":"pic_desc_llm","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"pic_desc_prompt":{"_input_type":"StrInput","advanced":true,"display_name":"Picture description prompt","dynamic":false,"info":"The user prompt to use when invoking the model.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"pic_desc_prompt","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Describe the image in three sentences. Be concise and accurate."},"pipeline":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Pipeline","dynamic":false,"external_options":{},"info":"Docling pipeline to use","name":"pipeline","options":["standard","vlm"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"standard"},"separator":{"_input_type":"StrInput","advanced":true,"display_name":"Separator","dynamic":false,"info":"Specify the separator to use between multiple outputs in Message format.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"separator","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"\n\n"},"silent_errors":{"_input_type":"BoolInput","advanced":true,"display_name":"Silent Errors","dynamic":false,"info":"If true, errors will not raise an exception.","list":false,"list_add_label":"Add More","name":"silent_errors","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false},"DoclingRemote":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Uses Docling to process input documents connecting to your instance of Docling Serve.","display_name":"Docling Serve","documentation":"https://docling-project.github.io/docling/","edited":false,"field_order":["path","file_path","separator","silent_errors","delete_server_file_after_processing","ignore_unsupported_extensions","ignore_unspecified_files","api_url","max_concurrency","max_poll_timeout","api_headers","docling_serve_opts"],"frozen":false,"icon":"Docling","legacy":false,"metadata":{"code_hash":"26eeb513dded","dependencies":{"dependencies":[{"name":"httpx","version":"0.28.1"},{"name":"docling_core","version":"2.48.4"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.docling.docling_remote.DoclingRemoteComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Files","group_outputs":false,"method":"load_files","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_headers":{"_input_type":"NestedDictInput","advanced":true,"display_name":"HTTP headers","dynamic":false,"info":"Optional dictionary of additional headers required for connecting to Docling Serve.","list":false,"list_add_label":"Add More","name":"api_headers","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"NestedDict","value":{}},"api_url":{"_input_type":"StrInput","advanced":false,"display_name":"Server address","dynamic":false,"info":"URL of the Docling Serve instance.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"api_url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import base64\nimport time\nfrom concurrent.futures import Future, ThreadPoolExecutor\nfrom pathlib import Path\nfrom typing import Any\n\nimport httpx\nfrom docling_core.types.doc import DoclingDocument\nfrom pydantic import ValidationError\n\nfrom lfx.base.data import BaseFileComponent\nfrom lfx.inputs import IntInput, NestedDictInput, StrInput\nfrom lfx.inputs.inputs import FloatInput\nfrom lfx.schema import Data\nfrom lfx.utils.util import transform_localhost_url\n\n\nclass DoclingRemoteComponent(BaseFileComponent):\n    display_name = \"Docling Serve\"\n    description = \"Uses Docling to process input documents connecting to your instance of Docling Serve.\"\n    documentation = \"https://docling-project.github.io/docling/\"\n    trace_type = \"tool\"\n    icon = \"Docling\"\n    name = \"DoclingRemote\"\n\n    MAX_500_RETRIES = 5\n\n    # https://docling-project.github.io/docling/usage/supported_formats/\n    VALID_EXTENSIONS = [\n        \"adoc\",\n        \"asciidoc\",\n        \"asc\",\n        \"bmp\",\n        \"csv\",\n        \"dotx\",\n        \"dotm\",\n        \"docm\",\n        \"docx\",\n        \"htm\",\n        \"html\",\n        \"jpeg\",\n        \"json\",\n        \"md\",\n        \"pdf\",\n        \"png\",\n        \"potx\",\n        \"ppsx\",\n        \"pptm\",\n        \"potm\",\n        \"ppsm\",\n        \"pptx\",\n        \"tiff\",\n        \"txt\",\n        \"xls\",\n        \"xlsx\",\n        \"xhtml\",\n        \"xml\",\n        \"webp\",\n    ]\n\n    inputs = [\n        *BaseFileComponent.get_base_inputs(),\n        StrInput(\n            name=\"api_url\",\n            display_name=\"Server address\",\n            info=\"URL of the Docling Serve instance.\",\n            required=True,\n        ),\n        IntInput(\n            name=\"max_concurrency\",\n            display_name=\"Concurrency\",\n            info=\"Maximum number of concurrent requests for the server.\",\n            advanced=True,\n            value=2,\n        ),\n        FloatInput(\n            name=\"max_poll_timeout\",\n            display_name=\"Maximum poll time\",\n            info=\"Maximum waiting time for the document conversion to complete.\",\n            advanced=True,\n            value=3600,\n        ),\n        NestedDictInput(\n            name=\"api_headers\",\n            display_name=\"HTTP headers\",\n            advanced=True,\n            required=False,\n            info=(\"Optional dictionary of additional headers required for connecting to Docling Serve.\"),\n        ),\n        NestedDictInput(\n            name=\"docling_serve_opts\",\n            display_name=\"Docling options\",\n            advanced=True,\n            required=False,\n            info=(\n                \"Optional dictionary of additional options. \"\n                \"See https://github.com/docling-project/docling-serve/blob/main/docs/usage.md for more information.\"\n            ),\n        ),\n    ]\n\n    outputs = [\n        *BaseFileComponent.get_base_outputs(),\n    ]\n\n    def process_files(self, file_list: list[BaseFileComponent.BaseFile]) -> list[BaseFileComponent.BaseFile]:\n        # Transform localhost URLs to container-accessible hosts when running in a container\n        transformed_url = transform_localhost_url(self.api_url)\n        base_url = f\"{transformed_url}/v1\"\n\n        def _convert_document(client: httpx.Client, file_path: Path, options: dict[str, Any]) -> Data | None:\n            encoded_doc = base64.b64encode(file_path.read_bytes()).decode()\n            payload = {\n                \"options\": options,\n                \"sources\": [{\"kind\": \"file\", \"base64_string\": encoded_doc, \"filename\": file_path.name}],\n            }\n\n            response = client.post(f\"{base_url}/convert/source/async\", json=payload)\n            response.raise_for_status()\n            task = response.json()\n\n            http_failures = 0\n            retry_status_start = 500\n            retry_status_end = 600\n            start_wait_time = time.monotonic()\n            while task[\"task_status\"] not in (\"success\", \"failure\"):\n                # Check if processing exceeds the maximum poll timeout\n                processing_time = time.monotonic() - start_wait_time\n                if processing_time >= self.max_poll_timeout:\n                    msg = (\n                        f\"Processing time {processing_time=} exceeds the maximum poll timeout {self.max_poll_timeout=}.\"\n                        \"Please increase the max_poll_timeout parameter or review why the processing \"\n                        \"takes long on the server.\"\n                    )\n                    self.log(msg)\n                    raise RuntimeError(msg)\n\n                # Call for a new status update\n                time.sleep(2)\n                response = client.get(f\"{base_url}/status/poll/{task['task_id']}\")\n\n                # Check if the status call gets into 5xx errors and retry\n                if retry_status_start <= response.status_code < retry_status_end:\n                    http_failures += 1\n                    if http_failures > self.MAX_500_RETRIES:\n                        self.log(f\"The status requests got a http response {response.status_code} too many times.\")\n                        return None\n                    continue\n\n                # Update task status\n                task = response.json()\n\n            result_resp = client.get(f\"{base_url}/result/{task['task_id']}\")\n            result_resp.raise_for_status()\n            result = result_resp.json()\n\n            if \"json_content\" not in result[\"document\"] or result[\"document\"][\"json_content\"] is None:\n                self.log(\"No JSON DoclingDocument found in the result.\")\n                return None\n\n            try:\n                doc = DoclingDocument.model_validate(result[\"document\"][\"json_content\"])\n                return Data(data={\"doc\": doc, \"file_path\": str(file_path)})\n            except ValidationError as e:\n                self.log(f\"Error validating the document. {e}\")\n                return None\n\n        docling_options = {\n            \"to_formats\": [\"json\"],\n            \"image_export_mode\": \"placeholder\",\n            **(self.docling_serve_opts or {}),\n        }\n\n        processed_data: list[Data | None] = []\n        with (\n            httpx.Client(headers=self.api_headers) as client,\n            ThreadPoolExecutor(max_workers=self.max_concurrency) as executor,\n        ):\n            futures: list[tuple[int, Future]] = []\n            for i, file in enumerate(file_list):\n                if file.path is None:\n                    processed_data.append(None)\n                    continue\n\n                futures.append((i, executor.submit(_convert_document, client, file.path, docling_options)))\n\n            for _index, future in futures:\n                try:\n                    result_data = future.result()\n                    processed_data.append(result_data)\n                except (httpx.HTTPStatusError, httpx.RequestError, KeyError, ValueError) as exc:\n                    self.log(f\"Docling remote processing failed: {exc}\")\n                    raise\n\n        return self.rollup_data(file_list, processed_data)\n"},"delete_server_file_after_processing":{"_input_type":"BoolInput","advanced":true,"display_name":"Delete Server File After Processing","dynamic":false,"info":"If true, the Server File Path will be deleted after processing.","list":false,"list_add_label":"Add More","name":"delete_server_file_after_processing","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"docling_serve_opts":{"_input_type":"NestedDictInput","advanced":true,"display_name":"Docling options","dynamic":false,"info":"Optional dictionary of additional options. See https://github.com/docling-project/docling-serve/blob/main/docs/usage.md for more information.","list":false,"list_add_label":"Add More","name":"docling_serve_opts","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"NestedDict","value":{}},"file_path":{"_input_type":"HandleInput","advanced":true,"display_name":"Server File Path","dynamic":false,"info":"Data object with a 'file_path' property pointing to server file or a Message object with a path to the file. Supercedes 'Path' but supports same file types.","input_types":["Data","Message"],"list":true,"list_add_label":"Add More","name":"file_path","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"ignore_unspecified_files":{"_input_type":"BoolInput","advanced":true,"display_name":"Ignore Unspecified Files","dynamic":false,"info":"If true, Data with no 'file_path' property will be ignored.","list":false,"list_add_label":"Add More","name":"ignore_unspecified_files","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"ignore_unsupported_extensions":{"_input_type":"BoolInput","advanced":true,"display_name":"Ignore Unsupported Extensions","dynamic":false,"info":"If true, files with unsupported extensions will not be processed.","list":false,"list_add_label":"Add More","name":"ignore_unsupported_extensions","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"max_concurrency":{"_input_type":"IntInput","advanced":true,"display_name":"Concurrency","dynamic":false,"info":"Maximum number of concurrent requests for the server.","list":false,"list_add_label":"Add More","name":"max_concurrency","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":2},"max_poll_timeout":{"_input_type":"FloatInput","advanced":true,"display_name":"Maximum poll time","dynamic":false,"info":"Maximum waiting time for the document conversion to complete.","list":false,"list_add_label":"Add More","name":"max_poll_timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":3600.0},"path":{"_input_type":"FileInput","advanced":false,"display_name":"Files","dynamic":false,"fileTypes":["adoc","asciidoc","asc","bmp","csv","dotx","dotm","docm","docx","htm","html","jpeg","json","md","pdf","png","potx","ppsx","pptm","potm","ppsm","pptx","tiff","txt","xls","xlsx","xhtml","xml","webp","zip","tar","tgz","bz2","gz"],"file_path":"","info":"Supported file extensions: adoc, asciidoc, asc, bmp, csv, dotx, dotm, docm, docx, htm, html, jpeg, json, md, pdf, png, potx, ppsx, pptm, potm, ppsm, pptx, tiff, txt, xls, xlsx, xhtml, xml, webp; optionally bundled in file extensions: zip, tar, tgz, bz2, gz","list":true,"list_add_label":"Add More","name":"path","placeholder":"","required":false,"show":true,"temp_file":false,"title_case":false,"tool_mode":true,"trace_as_metadata":true,"type":"file","value":[]},"separator":{"_input_type":"StrInput","advanced":true,"display_name":"Separator","dynamic":false,"info":"Specify the separator to use between multiple outputs in Message format.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"separator","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"\n\n"},"silent_errors":{"_input_type":"BoolInput","advanced":true,"display_name":"Silent Errors","dynamic":false,"info":"If true, errors will not raise an exception.","list":false,"list_add_label":"Add More","name":"silent_errors","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false},"ExportDoclingDocument":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Export DoclingDocument to markdown, html or other formats.","display_name":"Export DoclingDocument","documentation":"https://docling-project.github.io/docling/","edited":false,"field_order":["data_inputs","export_format","image_mode","md_image_placeholder","md_page_break_placeholder","doc_key"],"frozen":false,"icon":"Docling","legacy":false,"metadata":{"code_hash":"4de16ddd37ac","dependencies":{"dependencies":[{"name":"docling_core","version":"2.48.4"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.docling.export_docling_document.ExportDoclingDocumentComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Exported data","group_outputs":false,"method":"export_document","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom docling_core.types.doc import ImageRefMode\n\nfrom lfx.base.data.docling_utils import extract_docling_documents\nfrom lfx.custom import Component\nfrom lfx.io import DropdownInput, HandleInput, MessageTextInput, Output, StrInput\nfrom lfx.schema import Data, DataFrame\n\n\nclass ExportDoclingDocumentComponent(Component):\n    display_name: str = \"Export DoclingDocument\"\n    description: str = \"Export DoclingDocument to markdown, html or other formats.\"\n    documentation = \"https://docling-project.github.io/docling/\"\n    icon = \"Docling\"\n    name = \"ExportDoclingDocument\"\n\n    inputs = [\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Data or DataFrame\",\n            info=\"The data with documents to export.\",\n            input_types=[\"Data\", \"DataFrame\"],\n            required=True,\n        ),\n        DropdownInput(\n            name=\"export_format\",\n            display_name=\"Export format\",\n            options=[\"Markdown\", \"HTML\", \"Plaintext\", \"DocTags\"],\n            info=\"Select the export format to convert the input.\",\n            value=\"Markdown\",\n            real_time_refresh=True,\n        ),\n        DropdownInput(\n            name=\"image_mode\",\n            display_name=\"Image export mode\",\n            options=[\"placeholder\", \"embedded\"],\n            info=(\n                \"Specify how images are exported in the output. Placeholder will replace the images with a string, \"\n                \"whereas Embedded will include them as base64 encoded images.\"\n            ),\n            value=\"placeholder\",\n        ),\n        StrInput(\n            name=\"md_image_placeholder\",\n            display_name=\"Image placeholder\",\n            info=\"Specify the image placeholder for markdown exports.\",\n            value=\"<!-- image -->\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"md_page_break_placeholder\",\n            display_name=\"Page break placeholder\",\n            info=\"Add this placeholder betweek pages in the markdown output.\",\n            value=\"\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"doc_key\",\n            display_name=\"Doc Key\",\n            info=\"The key to use for the DoclingDocument column.\",\n            value=\"doc\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Exported data\", name=\"data\", method=\"export_document\"),\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"as_dataframe\"),\n    ]\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name == \"export_format\" and field_value == \"Markdown\":\n            build_config[\"md_image_placeholder\"][\"show\"] = True\n            build_config[\"md_page_break_placeholder\"][\"show\"] = True\n            build_config[\"image_mode\"][\"show\"] = True\n        elif field_name == \"export_format\" and field_value == \"HTML\":\n            build_config[\"md_image_placeholder\"][\"show\"] = False\n            build_config[\"md_page_break_placeholder\"][\"show\"] = False\n            build_config[\"image_mode\"][\"show\"] = True\n        elif field_name == \"export_format\" and field_value in {\"Plaintext\", \"DocTags\"}:\n            build_config[\"md_image_placeholder\"][\"show\"] = False\n            build_config[\"md_page_break_placeholder\"][\"show\"] = False\n            build_config[\"image_mode\"][\"show\"] = False\n\n        return build_config\n\n    def export_document(self) -> list[Data]:\n        documents = extract_docling_documents(self.data_inputs, self.doc_key)\n\n        results: list[Data] = []\n        try:\n            image_mode = ImageRefMode(self.image_mode)\n            for doc in documents:\n                content = \"\"\n                if self.export_format == \"Markdown\":\n                    content = doc.export_to_markdown(\n                        image_mode=image_mode,\n                        image_placeholder=self.md_image_placeholder,\n                        page_break_placeholder=self.md_page_break_placeholder,\n                    )\n                elif self.export_format == \"HTML\":\n                    content = doc.export_to_html(image_mode=image_mode)\n                elif self.export_format == \"Plaintext\":\n                    content = doc.export_to_text()\n                elif self.export_format == \"DocTags\":\n                    content = doc.export_to_doctags()\n\n                results.append(Data(text=content))\n        except Exception as e:\n            msg = f\"Error splitting text: {e}\"\n            raise TypeError(msg) from e\n\n        return results\n\n    def as_dataframe(self) -> DataFrame:\n        return DataFrame(self.export_document())\n"},"data_inputs":{"_input_type":"HandleInput","advanced":false,"display_name":"Data or DataFrame","dynamic":false,"info":"The data with documents to export.","input_types":["Data","DataFrame"],"list":false,"list_add_label":"Add More","name":"data_inputs","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"doc_key":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Doc Key","dynamic":false,"info":"The key to use for the DoclingDocument column.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"doc_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"doc"},"export_format":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Export format","dynamic":false,"external_options":{},"info":"Select the export format to convert the input.","name":"export_format","options":["Markdown","HTML","Plaintext","DocTags"],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Markdown"},"image_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Image export mode","dynamic":false,"external_options":{},"info":"Specify how images are exported in the output. Placeholder will replace the images with a string, whereas Embedded will include them as base64 encoded images.","name":"image_mode","options":["placeholder","embedded"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"placeholder"},"md_image_placeholder":{"_input_type":"StrInput","advanced":true,"display_name":"Image placeholder","dynamic":false,"info":"Specify the image placeholder for markdown exports.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"md_image_placeholder","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"<!-- image -->"},"md_page_break_placeholder":{"_input_type":"StrInput","advanced":true,"display_name":"Page break placeholder","dynamic":false,"info":"Add this placeholder betweek pages in the markdown output.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"md_page_break_placeholder","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["duckduckgo",{"DuckDuckGoSearchComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Search the web using DuckDuckGo with customizable result limits","display_name":"DuckDuckGo Search","documentation":"https://python.langchain.com/docs/integrations/tools/ddg","edited":false,"field_order":["input_value","max_results","max_snippet_length"],"frozen":false,"icon":"DuckDuckGo","legacy":false,"metadata":{"code_hash":"2e522a5a4389","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.duckduckgo.duck_duck_go_search_run.DuckDuckGoSearchComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"fetch_content_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_community.tools import DuckDuckGoSearchRun\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import IntInput, MessageTextInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.template.field.base import Output\n\n\nclass DuckDuckGoSearchComponent(Component):\n    \"\"\"Component for performing web searches using DuckDuckGo.\"\"\"\n\n    display_name = \"DuckDuckGo Search\"\n    description = \"Search the web using DuckDuckGo with customizable result limits\"\n    documentation = \"https://python.langchain.com/docs/integrations/tools/ddg\"\n    icon = \"DuckDuckGo\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Search Query\",\n            required=True,\n            info=\"The search query to execute with DuckDuckGo\",\n            tool_mode=True,\n        ),\n        IntInput(\n            name=\"max_results\",\n            display_name=\"Max Results\",\n            value=5,\n            required=False,\n            advanced=True,\n            info=\"Maximum number of search results to return\",\n        ),\n        IntInput(\n            name=\"max_snippet_length\",\n            display_name=\"Max Snippet Length\",\n            value=100,\n            required=False,\n            advanced=True,\n            info=\"Maximum length of each result snippet\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"fetch_content_dataframe\"),\n    ]\n\n    def _build_wrapper(self) -> DuckDuckGoSearchRun:\n        \"\"\"Build the DuckDuckGo search wrapper.\"\"\"\n        return DuckDuckGoSearchRun()\n\n    def run_model(self) -> DataFrame:\n        return self.fetch_content_dataframe()\n\n    def fetch_content(self) -> list[Data]:\n        \"\"\"Execute the search and return results as Data objects.\"\"\"\n        try:\n            wrapper = self._build_wrapper()\n\n            full_results = wrapper.run(f\"{self.input_value} (site:*)\")\n\n            result_list = full_results.split(\"\\n\")[: self.max_results]\n\n            data_results = []\n            for result in result_list:\n                if result.strip():\n                    snippet = result[: self.max_snippet_length]\n                    data_results.append(\n                        Data(\n                            text=snippet,\n                            data={\n                                \"content\": result,\n                                \"snippet\": snippet,\n                            },\n                        )\n                    )\n        except (ValueError, AttributeError) as e:\n            error_data = [Data(text=str(e), data={\"error\": str(e)})]\n            self.status = error_data\n            return error_data\n        else:\n            self.status = data_results\n            return data_results\n\n    def fetch_content_dataframe(self) -> DataFrame:\n        \"\"\"Convert the search results to a DataFrame.\n\n        Returns:\n            DataFrame: A DataFrame containing the search results.\n        \"\"\"\n        data = self.fetch_content()\n        return DataFrame(data)\n"},"input_value":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"The search query to execute with DuckDuckGo","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"max_results":{"_input_type":"IntInput","advanced":true,"display_name":"Max Results","dynamic":false,"info":"Maximum number of search results to return","list":false,"list_add_label":"Add More","name":"max_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5},"max_snippet_length":{"_input_type":"IntInput","advanced":true,"display_name":"Max Snippet Length","dynamic":false,"info":"Maximum length of each result snippet","list":false,"list_add_label":"Add More","name":"max_snippet_length","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":100}},"tool_mode":false}}],["elastic",{"Elasticsearch":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Elasticsearch Vector Store with with advanced, customizable search capabilities.","display_name":"Elasticsearch","documentation":"","edited":false,"field_order":["elasticsearch_url","cloud_id","index_name","ingest_data","search_query","should_cache_vector_store","username","password","embedding","search_type","number_of_results","search_score_threshold","api_key","verify_certs"],"frozen":false,"icon":"ElasticsearchStore","legacy":false,"metadata":{"code_hash":"b66e56d813fa","dependencies":{"dependencies":[{"name":"elasticsearch","version":"8.16.0"},{"name":"langchain","version":"0.3.23"},{"name":"langchain_elasticsearch","version":"0.3.0"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.elastic.elasticsearch.ElasticsearchVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":true,"display_name":"Elastic API Key","dynamic":false,"info":"API Key for Elastic Cloud authentication. If used, 'username' and 'password' are not required.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"cloud_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Elastic Cloud ID","dynamic":false,"info":"Use this for Elastic Cloud deployments. Do not use together with 'Elasticsearch URL'.","input_types":[],"load_from_db":true,"name":"cloud_id","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom elasticsearch import Elasticsearch\nfrom langchain.schema import Document\nfrom langchain_elasticsearch import ElasticsearchStore\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.io import (\n    BoolInput,\n    DropdownInput,\n    FloatInput,\n    HandleInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass ElasticsearchVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"Elasticsearch Vector Store with with advanced, customizable search capabilities.\"\"\"\n\n    display_name: str = \"Elasticsearch\"\n    description: str = \"Elasticsearch Vector Store with with advanced, customizable search capabilities.\"\n    name = \"Elasticsearch\"\n    icon = \"ElasticsearchStore\"\n\n    inputs = [\n        StrInput(\n            name=\"elasticsearch_url\",\n            display_name=\"Elasticsearch URL\",\n            value=\"http://localhost:9200\",\n            info=\"URL for self-managed Elasticsearch deployments (e.g., http://localhost:9200). \"\n            \"Do not use with Elastic Cloud deployments, use Elastic Cloud ID instead.\",\n        ),\n        SecretStrInput(\n            name=\"cloud_id\",\n            display_name=\"Elastic Cloud ID\",\n            value=\"\",\n            info=\"Use this for Elastic Cloud deployments. Do not use together with 'Elasticsearch URL'.\",\n        ),\n        StrInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            value=\"langflow\",\n            info=\"The index name where the vectors will be stored in Elasticsearch cluster.\",\n        ),\n        *LCVectorStoreComponent.inputs,\n        StrInput(\n            name=\"username\",\n            display_name=\"Username\",\n            value=\"\",\n            advanced=False,\n            info=(\n                \"Elasticsearch username (e.g., 'elastic'). \"\n                \"Required for both local and Elastic Cloud setups unless API keys are used.\"\n            ),\n        ),\n        SecretStrInput(\n            name=\"password\",\n            display_name=\"Elasticsearch Password\",\n            value=\"\",\n            advanced=False,\n            info=(\n                \"Elasticsearch password for the specified user. \"\n                \"Required for both local and Elastic Cloud setups unless API keys are used.\"\n            ),\n        ),\n        HandleInput(\n            name=\"embedding\",\n            display_name=\"Embedding\",\n            input_types=[\"Embeddings\"],\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            options=[\"similarity\", \"mmr\"],\n            value=\"similarity\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results.\",\n            value=0.0,\n            advanced=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Elastic API Key\",\n            value=\"\",\n            advanced=True,\n            info=\"API Key for Elastic Cloud authentication. If used, 'username' and 'password' are not required.\",\n        ),\n        BoolInput(\n            name=\"verify_certs\",\n            display_name=\"Verify SSL Certificates\",\n            value=True,\n            advanced=True,\n            info=\"Whether to verify SSL certificates when connecting to Elasticsearch.\",\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> ElasticsearchStore:\n        \"\"\"Builds the Elasticsearch Vector Store object.\"\"\"\n        if self.cloud_id and self.elasticsearch_url:\n            msg = (\n                \"Both 'cloud_id' and 'elasticsearch_url' provided. \"\n                \"Please use only one based on your deployment (Cloud or Local).\"\n            )\n            raise ValueError(msg)\n\n        es_params = {\n            \"index_name\": self.index_name,\n            \"embedding\": self.embedding,\n            \"es_user\": self.username or None,\n            \"es_password\": self.password or None,\n        }\n\n        if self.cloud_id:\n            es_params[\"es_cloud_id\"] = self.cloud_id\n        else:\n            es_params[\"es_url\"] = self.elasticsearch_url\n\n        if self.api_key:\n            es_params[\"api_key\"] = self.api_key\n\n        # Check if we need to verify SSL certificates\n        if self.verify_certs is False:\n            # Build client parameters for Elasticsearch constructor\n            client_params: dict[str, Any] = {}\n            client_params[\"verify_certs\"] = False\n\n            if self.cloud_id:\n                client_params[\"cloud_id\"] = self.cloud_id\n            else:\n                client_params[\"hosts\"] = [self.elasticsearch_url]\n\n            if self.api_key:\n                client_params[\"api_key\"] = self.api_key\n            elif self.username and self.password:\n                client_params[\"basic_auth\"] = (self.username, self.password)\n\n            es_client = Elasticsearch(**client_params)\n            es_params[\"es_connection\"] = es_client\n\n        elasticsearch = ElasticsearchStore(**es_params)\n\n        # If documents are provided, add them to the store\n        if self.ingest_data:\n            documents = self._prepare_documents()\n            if documents:\n                elasticsearch.add_documents(documents)\n\n        return elasticsearch\n\n    def _prepare_documents(self) -> list[Document]:\n        \"\"\"Prepares documents from the input data to add to the vector store.\"\"\"\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for data in self.ingest_data:\n            if isinstance(data, Data):\n                documents.append(data.to_lc_document())\n            else:\n                error_message = \"Vector Store Inputs must be Data objects.\"\n                self.log(error_message)\n                raise TypeError(error_message)\n        return documents\n\n    def _add_documents_to_vector_store(self, vector_store: \"ElasticsearchStore\") -> None:\n        \"\"\"Adds documents to the Vector Store.\"\"\"\n        documents = self._prepare_documents()\n        if documents and self.embedding:\n            self.log(f\"Adding {len(documents)} documents to the Vector Store.\")\n            vector_store.add_documents(documents)\n        else:\n            self.log(\"No documents to add to the Vector Store.\")\n\n    def search(self, query: str | None = None) -> list[dict[str, Any]]:\n        \"\"\"Search for similar documents in the vector store or retrieve all documents if no query is provided.\"\"\"\n        vector_store = self.build_vector_store()\n        search_kwargs = {\n            \"k\": self.number_of_results,\n            \"score_threshold\": self.search_score_threshold,\n        }\n\n        if query:\n            search_type = self.search_type.lower()\n            if search_type not in {\"similarity\", \"mmr\"}:\n                msg = f\"Invalid search type: {self.search_type}\"\n                self.log(msg)\n                raise ValueError(msg)\n            try:\n                if search_type == \"similarity\":\n                    results = vector_store.similarity_search_with_score(query, **search_kwargs)\n                elif search_type == \"mmr\":\n                    results = vector_store.max_marginal_relevance_search(query, **search_kwargs)\n            except Exception as e:\n                msg = (\n                    \"Error occurred while querying the Elasticsearch VectorStore,\"\n                    \" there is no Data into the VectorStore.\"\n                )\n                self.log(msg)\n                raise ValueError(msg) from e\n            return [\n                {\"page_content\": doc.page_content, \"metadata\": doc.metadata, \"score\": score} for doc, score in results\n            ]\n        results = self.get_all_documents(vector_store, **search_kwargs)\n        return [{\"page_content\": doc.page_content, \"metadata\": doc.metadata, \"score\": score} for doc, score in results]\n\n    def get_all_documents(self, vector_store: ElasticsearchStore, **kwargs) -> list[tuple[Document, float]]:\n        \"\"\"Retrieve all documents from the vector store.\"\"\"\n        client = vector_store.client\n        index_name = self.index_name\n\n        query = {\n            \"query\": {\"match_all\": {}},\n            \"size\": kwargs.get(\"k\", self.number_of_results),\n        }\n\n        response = client.search(index=index_name, body=query)\n\n        results = []\n        for hit in response[\"hits\"][\"hits\"]:\n            doc = Document(\n                page_content=hit[\"_source\"].get(\"text\", \"\"),\n                metadata=hit[\"_source\"].get(\"metadata\", {}),\n            )\n            score = hit[\"_score\"]\n            results.append((doc, score))\n\n        return results\n\n    def search_documents(self) -> list[Data]:\n        \"\"\"Search for documents in the vector store based on the search input.\n\n        If no search input is provided, retrieve all documents.\n        \"\"\"\n        results = self.search(self.search_query)\n        retrieved_data = [\n            Data(\n                text=result[\"page_content\"],\n                file_path=result[\"metadata\"].get(\"file_path\", \"\"),\n            )\n            for result in results\n        ]\n        self.status = retrieved_data\n        return retrieved_data\n\n    def get_retriever_kwargs(self):\n        \"\"\"Get the keyword arguments for the retriever.\"\"\"\n        return {\n            \"search_type\": self.search_type.lower(),\n            \"search_kwargs\": {\n                \"k\": self.number_of_results,\n                \"score_threshold\": self.search_score_threshold,\n            },\n        }\n"},"elasticsearch_url":{"_input_type":"StrInput","advanced":false,"display_name":"Elasticsearch URL","dynamic":false,"info":"URL for self-managed Elasticsearch deployments (e.g., http://localhost:9200). Do not use with Elastic Cloud deployments, use Elastic Cloud ID instead.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"elasticsearch_url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"http://localhost:9200"},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"index_name":{"_input_type":"StrInput","advanced":false,"display_name":"Index Name","dynamic":false,"info":"The index name where the vectors will be stored in Elasticsearch cluster.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"index_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"langflow"},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Elasticsearch Password","dynamic":false,"info":"Elasticsearch password for the specified user. Required for both local and Elastic Cloud setups unless API keys are used.","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"search_score_threshold":{"_input_type":"FloatInput","advanced":true,"display_name":"Search Score Threshold","dynamic":false,"info":"Minimum similarity score threshold for search results.","list":false,"list_add_label":"Add More","name":"search_score_threshold","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.0},"search_type":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Search Type","dynamic":false,"external_options":{},"info":"","name":"search_type","options":["similarity","mmr"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"similarity"},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"Elasticsearch username (e.g., 'elastic'). Required for both local and Elastic Cloud setups unless API keys are used.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verify_certs":{"_input_type":"BoolInput","advanced":true,"display_name":"Verify SSL Certificates","dynamic":false,"info":"Whether to verify SSL certificates when connecting to Elasticsearch.","list":false,"list_add_label":"Add More","name":"verify_certs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false},"OpenSearchVectorStoreComponent":{"base_classes":["Data","DataFrame","VectorStore"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Store and search documents using OpenSearch with hybrid semantic and keyword search capabilities.","display_name":"OpenSearch","documentation":"","edited":false,"field_order":["docs_metadata","opensearch_url","index_name","engine","space_type","ef_construction","m","ingest_data","search_query","should_cache_vector_store","embedding","vector_field","number_of_results","filter_expression","auth_mode","username","password","jwt_token","jwt_header","bearer_prefix","use_ssl","verify_certs"],"frozen":false,"icon":"OpenSearch","legacy":false,"metadata":{"code_hash":"77834dd0fa75","dependencies":{"dependencies":[{"name":"opensearchpy","version":"2.8.0"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.elastic.opensearch.OpenSearchVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Vector Store Connection","group_outputs":false,"hidden":false,"method":"as_vector_store","name":"vectorstoreconnection","selected":"VectorStore","tool_mode":true,"types":["VectorStore"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","auth_mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Authentication Mode","dynamic":false,"external_options":{},"info":"Authentication method: 'basic' for username/password authentication, or 'jwt' for JSON Web Token (Bearer) authentication.","name":"auth_mode","options":["basic","jwt"],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"basic"},"bearer_prefix":{"_input_type":"BoolInput","advanced":true,"display_name":"Prefix 'Bearer '","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"bearer_prefix","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from __future__ import annotations\n\nimport json\nimport uuid\nfrom typing import Any\n\nfrom opensearchpy import OpenSearch, helpers\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.base.vectorstores.vector_store_connection_decorator import vector_store_connection\nfrom lfx.io import BoolInput, DropdownInput, HandleInput, IntInput, MultilineInput, SecretStrInput, StrInput, TableInput\nfrom lfx.log import logger\nfrom lfx.schema.data import Data\n\n\n@vector_store_connection\nclass OpenSearchVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"OpenSearch Vector Store Component with Hybrid Search Capabilities.\n\n    This component provides vector storage and retrieval using OpenSearch, combining semantic\n    similarity search (KNN) with keyword-based search for optimal results. It supports document\n    ingestion, vector embeddings, and advanced filtering with authentication options.\n\n    Features:\n    - Vector storage with configurable engines (jvector, nmslib, faiss, lucene)\n    - Hybrid search combining KNN vector similarity and keyword matching\n    - Flexible authentication (Basic auth, JWT tokens)\n    - Advanced filtering and aggregations\n    - Metadata injection during document ingestion\n    \"\"\"\n\n    display_name: str = \"OpenSearch\"\n    icon: str = \"OpenSearch\"\n    description: str = (\n        \"Store and search documents using OpenSearch with hybrid semantic and keyword search capabilities.\"\n    )\n\n    # Keys we consider baseline\n    default_keys: list[str] = [\n        \"opensearch_url\",\n        \"index_name\",\n        *[i.name for i in LCVectorStoreComponent.inputs],  # search_query, add_documents, etc.\n        \"embedding\",\n        \"vector_field\",\n        \"number_of_results\",\n        \"auth_mode\",\n        \"username\",\n        \"password\",\n        \"jwt_token\",\n        \"jwt_header\",\n        \"bearer_prefix\",\n        \"use_ssl\",\n        \"verify_certs\",\n        \"filter_expression\",\n        \"engine\",\n        \"space_type\",\n        \"ef_construction\",\n        \"m\",\n        \"docs_metadata\",\n    ]\n\n    inputs = [\n        TableInput(\n            name=\"docs_metadata\",\n            display_name=\"Document Metadata\",\n            info=(\n                \"Additional metadata key-value pairs to be added to all ingested documents. \"\n                \"Useful for tagging documents with source information, categories, or other custom attributes.\"\n            ),\n            table_schema=[\n                {\n                    \"name\": \"key\",\n                    \"display_name\": \"Key\",\n                    \"type\": \"str\",\n                    \"description\": \"Key name\",\n                },\n                {\n                    \"name\": \"value\",\n                    \"display_name\": \"Value\",\n                    \"type\": \"str\",\n                    \"description\": \"Value of the metadata\",\n                },\n            ],\n            value=[],\n            input_types=[\"Data\"],\n        ),\n        StrInput(\n            name=\"opensearch_url\",\n            display_name=\"OpenSearch URL\",\n            value=\"http://localhost:9200\",\n            info=(\n                \"The connection URL for your OpenSearch cluster \"\n                \"(e.g., http://localhost:9200 for local development or your cloud endpoint).\"\n            ),\n        ),\n        StrInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            value=\"langflow\",\n            info=(\n                \"The OpenSearch index name where documents will be stored and searched. \"\n                \"Will be created automatically if it doesn't exist.\"\n            ),\n        ),\n        DropdownInput(\n            name=\"engine\",\n            display_name=\"Vector Engine\",\n            options=[\"jvector\", \"nmslib\", \"faiss\", \"lucene\"],\n            value=\"jvector\",\n            info=(\n                \"Vector search engine for similarity calculations. 'jvector' is recommended for most use cases. \"\n                \"Note: Amazon OpenSearch Serverless only supports 'nmslib' or 'faiss'.\"\n            ),\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"space_type\",\n            display_name=\"Distance Metric\",\n            options=[\"l2\", \"l1\", \"cosinesimil\", \"linf\", \"innerproduct\"],\n            value=\"l2\",\n            info=(\n                \"Distance metric for calculating vector similarity. 'l2' (Euclidean) is most common, \"\n                \"'cosinesimil' for cosine similarity, 'innerproduct' for dot product.\"\n            ),\n            advanced=True,\n        ),\n        IntInput(\n            name=\"ef_construction\",\n            display_name=\"EF Construction\",\n            value=512,\n            info=(\n                \"Size of the dynamic candidate list during index construction. \"\n                \"Higher values improve recall but increase indexing time and memory usage.\"\n            ),\n            advanced=True,\n        ),\n        IntInput(\n            name=\"m\",\n            display_name=\"M Parameter\",\n            value=16,\n            info=(\n                \"Number of bidirectional connections for each vector in the HNSW graph. \"\n                \"Higher values improve search quality but increase memory usage and indexing time.\"\n            ),\n            advanced=True,\n        ),\n        *LCVectorStoreComponent.inputs,  # includes search_query, add_documents, etc.\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        StrInput(\n            name=\"vector_field\",\n            display_name=\"Vector Field Name\",\n            value=\"chunk_embedding\",\n            advanced=True,\n            info=\"Name of the field in OpenSearch documents that stores the vector embeddings for similarity search.\",\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Default Result Limit\",\n            value=10,\n            advanced=True,\n            info=(\n                \"Default maximum number of search results to return when no limit is \"\n                \"specified in the filter expression.\"\n            ),\n        ),\n        MultilineInput(\n            name=\"filter_expression\",\n            display_name=\"Search Filters (JSON)\",\n            value=\"\",\n            info=(\n                \"Optional JSON configuration for search filtering, result limits, and score thresholds.\\n\\n\"\n                \"Format 1 - Explicit filters:\\n\"\n                '{\"filter\": [{\"term\": {\"filename\":\"doc.pdf\"}}, '\n                '{\"terms\":{\"owner\":[\"user1\",\"user2\"]}}], \"limit\": 10, \"score_threshold\": 1.6}\\n\\n'\n                \"Format 2 - Context-style mapping:\\n\"\n                '{\"data_sources\":[\"file.pdf\"], \"document_types\":[\"application/pdf\"], \"owners\":[\"user123\"]}\\n\\n'\n                \"Use __IMPOSSIBLE_VALUE__ as placeholder to ignore specific filters.\"\n            ),\n        ),\n        # ----- Auth controls (dynamic) -----\n        DropdownInput(\n            name=\"auth_mode\",\n            display_name=\"Authentication Mode\",\n            value=\"basic\",\n            options=[\"basic\", \"jwt\"],\n            info=(\n                \"Authentication method: 'basic' for username/password authentication, \"\n                \"or 'jwt' for JSON Web Token (Bearer) authentication.\"\n            ),\n            real_time_refresh=True,\n            advanced=False,\n        ),\n        StrInput(\n            name=\"username\",\n            display_name=\"Username\",\n            value=\"admin\",\n            show=False,\n        ),\n        SecretStrInput(\n            name=\"password\",\n            display_name=\"OpenSearch Password\",\n            value=\"admin\",\n            show=False,\n        ),\n        SecretStrInput(\n            name=\"jwt_token\",\n            display_name=\"JWT Token\",\n            value=\"JWT\",\n            load_from_db=False,\n            show=True,\n            info=(\n                \"Valid JSON Web Token for authentication. \"\n                \"Will be sent in the Authorization header (with optional 'Bearer ' prefix).\"\n            ),\n        ),\n        StrInput(\n            name=\"jwt_header\",\n            display_name=\"JWT Header Name\",\n            value=\"Authorization\",\n            show=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"bearer_prefix\",\n            display_name=\"Prefix 'Bearer '\",\n            value=True,\n            show=False,\n            advanced=True,\n        ),\n        # ----- TLS -----\n        BoolInput(\n            name=\"use_ssl\",\n            display_name=\"Use SSL/TLS\",\n            value=True,\n            advanced=True,\n            info=\"Enable SSL/TLS encryption for secure connections to OpenSearch.\",\n        ),\n        BoolInput(\n            name=\"verify_certs\",\n            display_name=\"Verify SSL Certificates\",\n            value=False,\n            advanced=True,\n            info=(\n                \"Verify SSL certificates when connecting. \"\n                \"Disable for self-signed certificates in development environments.\"\n            ),\n        ),\n    ]\n\n    # ---------- helper functions for index management ----------\n    def _default_text_mapping(\n        self,\n        dim: int,\n        engine: str = \"jvector\",\n        space_type: str = \"l2\",\n        ef_search: int = 512,\n        ef_construction: int = 100,\n        m: int = 16,\n        vector_field: str = \"vector_field\",\n    ) -> dict[str, Any]:\n        \"\"\"Create the default OpenSearch index mapping for vector search.\n\n        This method generates the index configuration with k-NN settings optimized\n        for approximate nearest neighbor search using the specified vector engine.\n\n        Args:\n            dim: Dimensionality of the vector embeddings\n            engine: Vector search engine (jvector, nmslib, faiss, lucene)\n            space_type: Distance metric for similarity calculation\n            ef_search: Size of dynamic list used during search\n            ef_construction: Size of dynamic list used during index construction\n            m: Number of bidirectional links for each vector\n            vector_field: Name of the field storing vector embeddings\n\n        Returns:\n            Dictionary containing OpenSearch index mapping configuration\n        \"\"\"\n        return {\n            \"settings\": {\"index\": {\"knn\": True, \"knn.algo_param.ef_search\": ef_search}},\n            \"mappings\": {\n                \"properties\": {\n                    vector_field: {\n                        \"type\": \"knn_vector\",\n                        \"dimension\": dim,\n                        \"method\": {\n                            \"name\": \"disk_ann\",\n                            \"space_type\": space_type,\n                            \"engine\": engine,\n                            \"parameters\": {\"ef_construction\": ef_construction, \"m\": m},\n                        },\n                    }\n                }\n            },\n        }\n\n    def _validate_aoss_with_engines(self, *, is_aoss: bool, engine: str) -> None:\n        \"\"\"Validate engine compatibility with Amazon OpenSearch Serverless (AOSS).\n\n        Amazon OpenSearch Serverless has restrictions on which vector engines\n        can be used. This method ensures the selected engine is compatible.\n\n        Args:\n            is_aoss: Whether the connection is to Amazon OpenSearch Serverless\n            engine: The selected vector search engine\n\n        Raises:\n            ValueError: If AOSS is used with an incompatible engine\n        \"\"\"\n        if is_aoss and engine not in {\"nmslib\", \"faiss\"}:\n            msg = \"Amazon OpenSearch Service Serverless only supports `nmslib` or `faiss` engines\"\n            raise ValueError(msg)\n\n    def _is_aoss_enabled(self, http_auth: Any) -> bool:\n        \"\"\"Determine if Amazon OpenSearch Serverless (AOSS) is being used.\n\n        Args:\n            http_auth: The HTTP authentication object\n\n        Returns:\n            True if AOSS is enabled, False otherwise\n        \"\"\"\n        return http_auth is not None and hasattr(http_auth, \"service\") and http_auth.service == \"aoss\"\n\n    def _bulk_ingest_embeddings(\n        self,\n        client: OpenSearch,\n        index_name: str,\n        embeddings: list[list[float]],\n        texts: list[str],\n        metadatas: list[dict] | None = None,\n        ids: list[str] | None = None,\n        vector_field: str = \"vector_field\",\n        text_field: str = \"text\",\n        mapping: dict | None = None,\n        max_chunk_bytes: int | None = 1 * 1024 * 1024,\n        *,\n        is_aoss: bool = False,\n    ) -> list[str]:\n        \"\"\"Efficiently ingest multiple documents with embeddings into OpenSearch.\n\n        This method uses bulk operations to insert documents with their vector\n        embeddings and metadata into the specified OpenSearch index.\n\n        Args:\n            client: OpenSearch client instance\n            index_name: Target index for document storage\n            embeddings: List of vector embeddings for each document\n            texts: List of document texts\n            metadatas: Optional metadata dictionaries for each document\n            ids: Optional document IDs (UUIDs generated if not provided)\n            vector_field: Field name for storing vector embeddings\n            text_field: Field name for storing document text\n            mapping: Optional index mapping configuration\n            max_chunk_bytes: Maximum size per bulk request chunk\n            is_aoss: Whether using Amazon OpenSearch Serverless\n\n        Returns:\n            List of document IDs that were successfully ingested\n        \"\"\"\n        if not mapping:\n            mapping = {}\n\n        requests = []\n        return_ids = []\n\n        for i, text in enumerate(texts):\n            metadata = metadatas[i] if metadatas else {}\n            _id = ids[i] if ids else str(uuid.uuid4())\n            request = {\n                \"_op_type\": \"index\",\n                \"_index\": index_name,\n                vector_field: embeddings[i],\n                text_field: text,\n                **metadata,\n            }\n            if is_aoss:\n                request[\"id\"] = _id\n            else:\n                request[\"_id\"] = _id\n            requests.append(request)\n            return_ids.append(_id)\n        if metadatas:\n            self.log(f\"Sample metadata: {metadatas[0] if metadatas else {}}\")\n        helpers.bulk(client, requests, max_chunk_bytes=max_chunk_bytes)\n        return return_ids\n\n    # ---------- auth / client ----------\n    def _build_auth_kwargs(self) -> dict[str, Any]:\n        \"\"\"Build authentication configuration for OpenSearch client.\n\n        Constructs the appropriate authentication parameters based on the\n        selected auth mode (basic username/password or JWT token).\n\n        Returns:\n            Dictionary containing authentication configuration\n\n        Raises:\n            ValueError: If required authentication parameters are missing\n        \"\"\"\n        mode = (self.auth_mode or \"basic\").strip().lower()\n        if mode == \"jwt\":\n            token = (self.jwt_token or \"\").strip()\n            if not token:\n                msg = \"Auth Mode is 'jwt' but no jwt_token was provided.\"\n                raise ValueError(msg)\n            header_name = (self.jwt_header or \"Authorization\").strip()\n            header_value = f\"Bearer {token}\" if self.bearer_prefix else token\n            return {\"headers\": {header_name: header_value}}\n        user = (self.username or \"\").strip()\n        pwd = (self.password or \"\").strip()\n        if not user or not pwd:\n            msg = \"Auth Mode is 'basic' but username/password are missing.\"\n            raise ValueError(msg)\n        return {\"http_auth\": (user, pwd)}\n\n    def build_client(self) -> OpenSearch:\n        \"\"\"Create and configure an OpenSearch client instance.\n\n        Returns:\n            Configured OpenSearch client ready for operations\n        \"\"\"\n        auth_kwargs = self._build_auth_kwargs()\n        return OpenSearch(\n            hosts=[self.opensearch_url],\n            use_ssl=self.use_ssl,\n            verify_certs=self.verify_certs,\n            ssl_assert_hostname=False,\n            ssl_show_warn=False,\n            **auth_kwargs,\n        )\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> OpenSearch:\n        # Return raw OpenSearch client as our “vector store.”\n        self.log(self.ingest_data)\n        client = self.build_client()\n        self._add_documents_to_vector_store(client=client)\n        return client\n\n    # ---------- ingest ----------\n    def _add_documents_to_vector_store(self, client: OpenSearch) -> None:\n        \"\"\"Process and ingest documents into the OpenSearch vector store.\n\n        This method handles the complete document ingestion pipeline:\n        - Prepares document data and metadata\n        - Generates vector embeddings\n        - Creates appropriate index mappings\n        - Bulk inserts documents with vectors\n\n        Args:\n            client: OpenSearch client for performing operations\n        \"\"\"\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        docs = self.ingest_data or []\n        if not docs:\n            self.log(\"No documents to ingest.\")\n            return\n\n        # Extract texts and metadata from documents\n        texts = []\n        metadatas = []\n        # Process docs_metadata table input into a dict\n        additional_metadata = {}\n        if hasattr(self, \"docs_metadata\") and self.docs_metadata:\n            logger.debug(f\"[LF] Docs metadata {self.docs_metadata}\")\n            if isinstance(self.docs_metadata[-1], Data):\n                logger.debug(f\"[LF] Docs metadata is a Data object {self.docs_metadata}\")\n                self.docs_metadata = self.docs_metadata[-1].data\n                logger.debug(f\"[LF] Docs metadata is a Data object {self.docs_metadata}\")\n                additional_metadata.update(self.docs_metadata)\n            else:\n                for item in self.docs_metadata:\n                    if isinstance(item, dict) and \"key\" in item and \"value\" in item:\n                        additional_metadata[item[\"key\"]] = item[\"value\"]\n        # Replace string \"None\" values with actual None\n        for key, value in additional_metadata.items():\n            if value == \"None\":\n                additional_metadata[key] = None\n        logger.debug(f\"[LF] Additional metadata {additional_metadata}\")\n        for doc_obj in docs:\n            data_copy = json.loads(doc_obj.model_dump_json())\n            text = data_copy.pop(doc_obj.text_key, doc_obj.default_value)\n            texts.append(text)\n\n            # Merge additional metadata from table input\n            data_copy.update(additional_metadata)\n\n            metadatas.append(data_copy)\n        self.log(metadatas)\n        if not self.embedding:\n            msg = \"Embedding handle is required to embed documents.\"\n            raise ValueError(msg)\n\n        # Generate embeddings\n        vectors = self.embedding.embed_documents(texts)\n\n        if not vectors:\n            self.log(\"No vectors generated from documents.\")\n            return\n\n        # Get vector dimension for mapping\n        dim = len(vectors[0]) if vectors else 768  # default fallback\n\n        # Check for AOSS\n        auth_kwargs = self._build_auth_kwargs()\n        is_aoss = self._is_aoss_enabled(auth_kwargs.get(\"http_auth\"))\n\n        # Validate engine with AOSS\n        engine = getattr(self, \"engine\", \"jvector\")\n        self._validate_aoss_with_engines(is_aoss=is_aoss, engine=engine)\n\n        # Create mapping with proper KNN settings\n        space_type = getattr(self, \"space_type\", \"l2\")\n        ef_construction = getattr(self, \"ef_construction\", 512)\n        m = getattr(self, \"m\", 16)\n\n        mapping = self._default_text_mapping(\n            dim=dim,\n            engine=engine,\n            space_type=space_type,\n            ef_construction=ef_construction,\n            m=m,\n            vector_field=self.vector_field,\n        )\n\n        self.log(f\"Indexing {len(texts)} documents into '{self.index_name}' with proper KNN mapping...\")\n\n        # Use the LangChain-style bulk ingestion\n        return_ids = self._bulk_ingest_embeddings(\n            client=client,\n            index_name=self.index_name,\n            embeddings=vectors,\n            texts=texts,\n            metadatas=metadatas,\n            vector_field=self.vector_field,\n            text_field=\"text\",\n            mapping=mapping,\n            is_aoss=is_aoss,\n        )\n        self.log(metadatas)\n\n        self.log(f\"Successfully indexed {len(return_ids)} documents.\")\n\n    # ---------- helpers for filters ----------\n    def _is_placeholder_term(self, term_obj: dict) -> bool:\n        # term_obj like {\"filename\": \"__IMPOSSIBLE_VALUE__\"}\n        return any(v == \"__IMPOSSIBLE_VALUE__\" for v in term_obj.values())\n\n    def _coerce_filter_clauses(self, filter_obj: dict | None) -> list[dict]:\n        \"\"\"Convert filter expressions into OpenSearch-compatible filter clauses.\n\n        This method accepts two filter formats and converts them to standardized\n        OpenSearch query clauses:\n\n        Format A - Explicit filters:\n        {\"filter\": [{\"term\": {\"field\": \"value\"}}, {\"terms\": {\"field\": [\"val1\", \"val2\"]}}],\n         \"limit\": 10, \"score_threshold\": 1.5}\n\n        Format B - Context-style mapping:\n        {\"data_sources\": [\"file1.pdf\"], \"document_types\": [\"pdf\"], \"owners\": [\"user1\"]}\n\n        Args:\n            filter_obj: Filter configuration dictionary or None\n\n        Returns:\n            List of OpenSearch filter clauses (term/terms objects)\n            Placeholder values with \"__IMPOSSIBLE_VALUE__\" are ignored\n        \"\"\"\n        if not filter_obj:\n            return []\n\n        # If it is a string, try to parse it once\n        if isinstance(filter_obj, str):\n            try:\n                filter_obj = json.loads(filter_obj)\n            except json.JSONDecodeError:\n                # Not valid JSON - treat as no filters\n                return []\n\n        # Case A: already an explicit list/dict under \"filter\"\n        if \"filter\" in filter_obj:\n            raw = filter_obj[\"filter\"]\n            if isinstance(raw, dict):\n                raw = [raw]\n            explicit_clauses: list[dict] = []\n            for f in raw or []:\n                if \"term\" in f and isinstance(f[\"term\"], dict) and not self._is_placeholder_term(f[\"term\"]):\n                    explicit_clauses.append(f)\n                elif \"terms\" in f and isinstance(f[\"terms\"], dict):\n                    field, vals = next(iter(f[\"terms\"].items()))\n                    if isinstance(vals, list) and len(vals) > 0:\n                        explicit_clauses.append(f)\n            return explicit_clauses\n\n        # Case B: convert context-style maps into clauses\n        field_mapping = {\n            \"data_sources\": \"filename\",\n            \"document_types\": \"mimetype\",\n            \"owners\": \"owner\",\n        }\n        context_clauses: list[dict] = []\n        for k, values in filter_obj.items():\n            if not isinstance(values, list):\n                continue\n            field = field_mapping.get(k, k)\n            if len(values) == 0:\n                # Match-nothing placeholder (kept to mirror your tool semantics)\n                context_clauses.append({\"term\": {field: \"__IMPOSSIBLE_VALUE__\"}})\n            elif len(values) == 1:\n                if values[0] != \"__IMPOSSIBLE_VALUE__\":\n                    context_clauses.append({\"term\": {field: values[0]}})\n            else:\n                context_clauses.append({\"terms\": {field: values}})\n        return context_clauses\n\n    # ---------- search (single hybrid path matching your tool) ----------\n    def search(self, query: str | None = None) -> list[dict[str, Any]]:\n        \"\"\"Perform hybrid search combining vector similarity and keyword matching.\n\n        This method executes a sophisticated search that combines:\n        - K-nearest neighbor (KNN) vector similarity search (70% weight)\n        - Multi-field keyword search with fuzzy matching (30% weight)\n        - Optional filtering and score thresholds\n        - Aggregations for faceted search results\n\n        Args:\n            query: Search query string (used for both vector embedding and keyword search)\n\n        Returns:\n            List of search results with page_content, metadata, and relevance scores\n\n        Raises:\n            ValueError: If embedding component is not provided or filter JSON is invalid\n        \"\"\"\n        logger.info(self.ingest_data)\n        client = self.build_client()\n        q = (query or \"\").strip()\n\n        # Parse optional filter expression (can be either A or B shape; see _coerce_filter_clauses)\n        filter_obj = None\n        if getattr(self, \"filter_expression\", \"\") and self.filter_expression.strip():\n            try:\n                filter_obj = json.loads(self.filter_expression)\n            except json.JSONDecodeError as e:\n                msg = f\"Invalid filter_expression JSON: {e}\"\n                raise ValueError(msg) from e\n\n        if not self.embedding:\n            msg = \"Embedding is required to run hybrid search (KNN + keyword).\"\n            raise ValueError(msg)\n\n        # Embed the query\n        vec = self.embedding.embed_query(q)\n\n        # Build filter clauses (accept both shapes)\n        filter_clauses = self._coerce_filter_clauses(filter_obj)\n\n        # Respect the tool's limit/threshold defaults\n        limit = (filter_obj or {}).get(\"limit\", self.number_of_results)\n        score_threshold = (filter_obj or {}).get(\"score_threshold\", 0)\n\n        # Build the same hybrid body as your SearchService\n        body = {\n            \"query\": {\n                \"bool\": {\n                    \"should\": [\n                        {\n                            \"knn\": {\n                                self.vector_field: {\n                                    \"vector\": vec,\n                                    \"k\": 10,  # fixed to match the tool\n                                    \"boost\": 0.7,\n                                }\n                            }\n                        },\n                        {\n                            \"multi_match\": {\n                                \"query\": q,\n                                \"fields\": [\"text^2\", \"filename^1.5\"],\n                                \"type\": \"best_fields\",\n                                \"fuzziness\": \"AUTO\",\n                                \"boost\": 0.3,\n                            }\n                        },\n                    ],\n                    \"minimum_should_match\": 1,\n                }\n            },\n            \"aggs\": {\n                \"data_sources\": {\"terms\": {\"field\": \"filename\", \"size\": 20}},\n                \"document_types\": {\"terms\": {\"field\": \"mimetype\", \"size\": 10}},\n                \"owners\": {\"terms\": {\"field\": \"owner\", \"size\": 10}},\n            },\n            \"_source\": [\n                \"filename\",\n                \"mimetype\",\n                \"page\",\n                \"text\",\n                \"source_url\",\n                \"owner\",\n                \"allowed_users\",\n                \"allowed_groups\",\n            ],\n            \"size\": limit,\n        }\n        if filter_clauses:\n            body[\"query\"][\"bool\"][\"filter\"] = filter_clauses\n\n        if isinstance(score_threshold, (int, float)) and score_threshold > 0:\n            # top-level min_score (matches your tool)\n            body[\"min_score\"] = score_threshold\n\n        resp = client.search(index=self.index_name, body=body)\n        hits = resp.get(\"hits\", {}).get(\"hits\", [])\n        return [\n            {\n                \"page_content\": hit[\"_source\"].get(\"text\", \"\"),\n                \"metadata\": {k: v for k, v in hit[\"_source\"].items() if k != \"text\"},\n                \"score\": hit.get(\"_score\"),\n            }\n            for hit in hits\n        ]\n\n    def search_documents(self) -> list[Data]:\n        \"\"\"Search documents and return results as Data objects.\n\n        This is the main interface method that performs the search using the\n        configured search_query and returns results in Langflow's Data format.\n\n        Returns:\n            List of Data objects containing search results with text and metadata\n\n        Raises:\n            Exception: If search operation fails\n        \"\"\"\n        try:\n            raw = self.search(self.search_query or \"\")\n            return [Data(text=hit[\"page_content\"], **hit[\"metadata\"]) for hit in raw]\n            self.log(self.ingest_data)\n        except Exception as e:\n            self.log(f\"search_documents error: {e}\")\n            raise\n\n    # -------- dynamic UI handling (auth switch) --------\n    async def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        \"\"\"Dynamically update component configuration based on field changes.\n\n        This method handles real-time UI updates, particularly for authentication\n        mode changes that show/hide relevant input fields.\n\n        Args:\n            build_config: Current component configuration\n            field_value: New value for the changed field\n            field_name: Name of the field that changed\n\n        Returns:\n            Updated build configuration with appropriate field visibility\n        \"\"\"\n        try:\n            if field_name == \"auth_mode\":\n                mode = (field_value or \"basic\").strip().lower()\n                is_basic = mode == \"basic\"\n                is_jwt = mode == \"jwt\"\n\n                build_config[\"username\"][\"show\"] = is_basic\n                build_config[\"password\"][\"show\"] = is_basic\n\n                build_config[\"jwt_token\"][\"show\"] = is_jwt\n                build_config[\"jwt_header\"][\"show\"] = is_jwt\n                build_config[\"bearer_prefix\"][\"show\"] = is_jwt\n\n                build_config[\"username\"][\"required\"] = is_basic\n                build_config[\"password\"][\"required\"] = is_basic\n\n                build_config[\"jwt_token\"][\"required\"] = is_jwt\n                build_config[\"jwt_header\"][\"required\"] = is_jwt\n                build_config[\"bearer_prefix\"][\"required\"] = False\n\n                if is_basic:\n                    build_config[\"jwt_token\"][\"value\"] = \"\"\n\n                return build_config\n\n        except (KeyError, ValueError) as e:\n            self.log(f\"update_build_config error: {e}\")\n\n        return build_config\n"},"docs_metadata":{"_input_type":"TableInput","advanced":false,"display_name":"Document Metadata","dynamic":false,"info":"Additional metadata key-value pairs to be added to all ingested documents. Useful for tagging documents with source information, categories, or other custom attributes.","input_types":["Data"],"is_list":true,"list_add_label":"Add More","name":"docs_metadata","placeholder":"","required":false,"show":true,"table_icon":"Table","table_schema":[{"description":"Key name","display_name":"Key","name":"key","type":"str"},{"description":"Value of the metadata","display_name":"Value","name":"value","type":"str"}],"title_case":false,"tool_mode":false,"trace_as_metadata":true,"trigger_icon":"Table","trigger_text":"Open table","type":"table","value":[]},"ef_construction":{"_input_type":"IntInput","advanced":true,"display_name":"EF Construction","dynamic":false,"info":"Size of the dynamic candidate list during index construction. Higher values improve recall but increase indexing time and memory usage.","list":false,"list_add_label":"Add More","name":"ef_construction","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":512},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"engine":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Vector Engine","dynamic":false,"external_options":{},"info":"Vector search engine for similarity calculations. 'jvector' is recommended for most use cases. Note: Amazon OpenSearch Serverless only supports 'nmslib' or 'faiss'.","name":"engine","options":["jvector","nmslib","faiss","lucene"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"jvector"},"filter_expression":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Search Filters (JSON)","dynamic":false,"info":"Optional JSON configuration for search filtering, result limits, and score thresholds.\n\nFormat 1 - Explicit filters:\n{\"filter\": [{\"term\": {\"filename\":\"doc.pdf\"}}, {\"terms\":{\"owner\":[\"user1\",\"user2\"]}}], \"limit\": 10, \"score_threshold\": 1.6}\n\nFormat 2 - Context-style mapping:\n{\"data_sources\":[\"file.pdf\"], \"document_types\":[\"application/pdf\"], \"owners\":[\"user123\"]}\n\nUse __IMPOSSIBLE_VALUE__ as placeholder to ignore specific filters.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"filter_expression","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"index_name":{"_input_type":"StrInput","advanced":false,"display_name":"Index Name","dynamic":false,"info":"The OpenSearch index name where documents will be stored and searched. Will be created automatically if it doesn't exist.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"index_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"langflow"},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"jwt_header":{"_input_type":"StrInput","advanced":true,"display_name":"JWT Header Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"jwt_header","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Authorization"},"jwt_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"JWT Token","dynamic":false,"info":"Valid JSON Web Token for authentication. Will be sent in the Authorization header (with optional 'Bearer ' prefix).","input_types":[],"load_from_db":false,"name":"jwt_token","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":"JWT"},"m":{"_input_type":"IntInput","advanced":true,"display_name":"M Parameter","dynamic":false,"info":"Number of bidirectional connections for each vector in the HNSW graph. Higher values improve search quality but increase memory usage and indexing time.","list":false,"list_add_label":"Add More","name":"m","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":16},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Default Result Limit","dynamic":false,"info":"Default maximum number of search results to return when no limit is specified in the filter expression.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":10},"opensearch_url":{"_input_type":"StrInput","advanced":false,"display_name":"OpenSearch URL","dynamic":false,"info":"The connection URL for your OpenSearch cluster (e.g., http://localhost:9200 for local development or your cloud endpoint).","list":false,"list_add_label":"Add More","load_from_db":false,"name":"opensearch_url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"http://localhost:9200"},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"OpenSearch Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","required":false,"show":false,"title_case":false,"type":"str","value":"admin"},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"space_type":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Distance Metric","dynamic":false,"external_options":{},"info":"Distance metric for calculating vector similarity. 'l2' (Euclidean) is most common, 'cosinesimil' for cosine similarity, 'innerproduct' for dot product.","name":"space_type","options":["l2","l1","cosinesimil","linf","innerproduct"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"l2"},"use_ssl":{"_input_type":"BoolInput","advanced":true,"display_name":"Use SSL/TLS","dynamic":false,"info":"Enable SSL/TLS encryption for secure connections to OpenSearch.","list":false,"list_add_label":"Add More","name":"use_ssl","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"admin"},"vector_field":{"_input_type":"StrInput","advanced":true,"display_name":"Vector Field Name","dynamic":false,"info":"Name of the field in OpenSearch documents that stores the vector embeddings for similarity search.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"vector_field","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"chunk_embedding"},"verify_certs":{"_input_type":"BoolInput","advanced":true,"display_name":"Verify SSL Certificates","dynamic":false,"info":"Verify SSL certificates when connecting. Disable for self-signed certificates in development environments.","list":false,"list_add_label":"Add More","name":"verify_certs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false}}],["embeddings",{"EmbeddingSimilarityComponent":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Compute selected form of similarity between two embedding vectors.","display_name":"Embedding Similarity","documentation":"","edited":false,"field_order":["embedding_vectors","similarity_metric"],"frozen":false,"icon":"equal","legacy":true,"metadata":{"code_hash":"d94c7d791f69","dependencies":{"dependencies":[{"name":"numpy","version":"2.2.6"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.embeddings.similarity.EmbeddingSimilarityComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Similarity Data","group_outputs":false,"method":"compute_similarity","name":"similarity_data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["datastax.AstraDB"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nimport numpy as np\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import DataInput, DropdownInput, Output\nfrom lfx.schema.data import Data\n\n\nclass EmbeddingSimilarityComponent(Component):\n    display_name: str = \"Embedding Similarity\"\n    description: str = \"Compute selected form of similarity between two embedding vectors.\"\n    icon = \"equal\"\n    legacy: bool = True\n    replacement = [\"datastax.AstraDB\"]\n\n    inputs = [\n        DataInput(\n            name=\"embedding_vectors\",\n            display_name=\"Embedding Vectors\",\n            info=\"A list containing exactly two data objects with embedding vectors to compare.\",\n            is_list=True,\n            required=True,\n        ),\n        DropdownInput(\n            name=\"similarity_metric\",\n            display_name=\"Similarity Metric\",\n            info=\"Select the similarity metric to use.\",\n            options=[\"Cosine Similarity\", \"Euclidean Distance\", \"Manhattan Distance\"],\n            value=\"Cosine Similarity\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Similarity Data\", name=\"similarity_data\", method=\"compute_similarity\"),\n    ]\n\n    def compute_similarity(self) -> Data:\n        embedding_vectors: list[Data] = self.embedding_vectors\n\n        # Assert that the list contains exactly two Data objects\n        if len(embedding_vectors) != 2:  # noqa: PLR2004\n            msg = \"Exactly two embedding vectors are required.\"\n            raise ValueError(msg)\n\n        embedding_1 = np.array(embedding_vectors[0].data[\"embeddings\"])\n        embedding_2 = np.array(embedding_vectors[1].data[\"embeddings\"])\n\n        if embedding_1.shape != embedding_2.shape:\n            similarity_score: dict[str, Any] = {\"error\": \"Embeddings must have the same dimensions.\"}\n        else:\n            similarity_metric = self.similarity_metric\n\n            if similarity_metric == \"Cosine Similarity\":\n                score = np.dot(embedding_1, embedding_2) / (np.linalg.norm(embedding_1) * np.linalg.norm(embedding_2))\n                similarity_score = {\"cosine_similarity\": score}\n\n            elif similarity_metric == \"Euclidean Distance\":\n                score = np.linalg.norm(embedding_1 - embedding_2)\n                similarity_score = {\"euclidean_distance\": score}\n\n            elif similarity_metric == \"Manhattan Distance\":\n                score = np.sum(np.abs(embedding_1 - embedding_2))\n                similarity_score = {\"manhattan_distance\": score}\n\n        # Create a Data object to encapsulate the similarity score and additional information\n        similarity_data = Data(\n            data={\n                \"embedding_1\": embedding_vectors[0].data[\"embeddings\"],\n                \"embedding_2\": embedding_vectors[1].data[\"embeddings\"],\n                \"similarity_score\": similarity_score,\n            },\n            text_key=\"similarity_score\",\n        )\n\n        self.status = similarity_data\n        return similarity_data\n"},"embedding_vectors":{"_input_type":"DataInput","advanced":false,"display_name":"Embedding Vectors","dynamic":false,"info":"A list containing exactly two data objects with embedding vectors to compare.","input_types":["Data"],"list":true,"list_add_label":"Add More","name":"embedding_vectors","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"similarity_metric":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Similarity Metric","dynamic":false,"external_options":{},"info":"Select the similarity metric to use.","name":"similarity_metric","options":["Cosine Similarity","Euclidean Distance","Manhattan Distance"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Cosine Similarity"}},"tool_mode":false},"TextEmbedderComponent":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate embeddings for a given message using the specified embedding model.","display_name":"Text Embedder","documentation":"","edited":false,"field_order":["embedding_model","message"],"frozen":false,"icon":"binary","legacy":true,"metadata":{"code_hash":"541a2fb78066","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.embeddings.text_embedder.TextEmbedderComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Embedding Data","group_outputs":false,"method":"generate_embeddings","name":"embeddings","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["models.EmbeddingModel"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import TYPE_CHECKING\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import HandleInput, MessageInput, Output\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\n\nif TYPE_CHECKING:\n    from lfx.field_typing import Embeddings\n    from lfx.schema.message import Message\n\n\nclass TextEmbedderComponent(Component):\n    display_name: str = \"Text Embedder\"\n    description: str = \"Generate embeddings for a given message using the specified embedding model.\"\n    icon = \"binary\"\n    legacy: bool = True\n    replacement = [\"models.EmbeddingModel\"]\n    inputs = [\n        HandleInput(\n            name=\"embedding_model\",\n            display_name=\"Embedding Model\",\n            info=\"The embedding model to use for generating embeddings.\",\n            input_types=[\"Embeddings\"],\n            required=True,\n        ),\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The message to generate embeddings for.\",\n            required=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Embedding Data\", name=\"embeddings\", method=\"generate_embeddings\"),\n    ]\n\n    def generate_embeddings(self) -> Data:\n        try:\n            embedding_model: Embeddings = self.embedding_model\n            message: Message = self.message\n\n            # Combine validation checks to reduce nesting\n            if not embedding_model or not hasattr(embedding_model, \"embed_documents\"):\n                msg = \"Invalid or incompatible embedding model\"\n                raise ValueError(msg)\n\n            text_content = message.text if message and message.text else \"\"\n            if not text_content:\n                msg = \"No text content found in message\"\n                raise ValueError(msg)\n\n            embeddings = embedding_model.embed_documents([text_content])\n            if not embeddings or not isinstance(embeddings, list):\n                msg = \"Invalid embeddings generated\"\n                raise ValueError(msg)\n\n            embedding_vector = embeddings[0]\n            self.status = {\"text\": text_content, \"embeddings\": embedding_vector}\n            return Data(data={\"text\": text_content, \"embeddings\": embedding_vector})\n        except Exception as e:  # noqa: BLE001\n            logger.exception(\"Error generating embeddings\")\n            error_data = Data(data={\"text\": \"\", \"embeddings\": [], \"error\": str(e)})\n            self.status = {\"error\": str(e)}\n            return error_data\n"},"embedding_model":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding Model","dynamic":false,"info":"The embedding model to use for generating embeddings.","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding_model","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"message":{"_input_type":"MessageInput","advanced":false,"display_name":"Message","dynamic":false,"info":"The message to generate embeddings for.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"message","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["exa",{"ExaSearch":{"base_classes":["Tool"],"beta":true,"conditional_paths":[],"custom_fields":{},"description":"Exa Search toolkit for search and content retrieval","display_name":"Exa Search","documentation":"https://python.langchain.com/docs/integrations/tools/metaphor_search","edited":false,"field_order":["metaphor_api_key","use_autoprompt","search_num_results","similar_num_results"],"frozen":false,"icon":"ExaSearch","legacy":false,"metadata":{"code_hash":"26039e2a8b78","dependencies":{"dependencies":[{"name":"langchain_core","version":"0.3.79"},{"name":"metaphor_python","version":"0.1.23"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.exa.exa_search.ExaSearchToolkit"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Tools","group_outputs":false,"method":"build_toolkit","name":"tools","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_core.tools import tool\nfrom metaphor_python import Metaphor\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.field_typing import Tool\nfrom lfx.io import BoolInput, IntInput, Output, SecretStrInput\n\n\nclass ExaSearchToolkit(Component):\n    display_name = \"Exa Search\"\n    description = \"Exa Search toolkit for search and content retrieval\"\n    documentation = \"https://python.langchain.com/docs/integrations/tools/metaphor_search\"\n    beta = True\n    name = \"ExaSearch\"\n    icon = \"ExaSearch\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"metaphor_api_key\",\n            display_name=\"Exa Search API Key\",\n            password=True,\n        ),\n        BoolInput(\n            name=\"use_autoprompt\",\n            display_name=\"Use Autoprompt\",\n            value=True,\n        ),\n        IntInput(\n            name=\"search_num_results\",\n            display_name=\"Search Number of Results\",\n            value=5,\n        ),\n        IntInput(\n            name=\"similar_num_results\",\n            display_name=\"Similar Number of Results\",\n            value=5,\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"tools\", display_name=\"Tools\", method=\"build_toolkit\"),\n    ]\n\n    def build_toolkit(self) -> Tool:\n        client = Metaphor(api_key=self.metaphor_api_key)\n\n        @tool\n        def search(query: str):\n            \"\"\"Call search engine with a query.\"\"\"\n            return client.search(query, use_autoprompt=self.use_autoprompt, num_results=self.search_num_results)\n\n        @tool\n        def get_contents(ids: list[str]):\n            \"\"\"Get contents of a webpage.\n\n            The ids passed in should be a list of ids as fetched from `search`.\n            \"\"\"\n            return client.get_contents(ids)\n\n        @tool\n        def find_similar(url: str):\n            \"\"\"Get search results similar to a given URL.\n\n            The url passed in should be a URL returned from `search`\n            \"\"\"\n            return client.find_similar(url, num_results=self.similar_num_results)\n\n        return [search, get_contents, find_similar]\n"},"metaphor_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Exa Search API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"metaphor_api_key","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"search_num_results":{"_input_type":"IntInput","advanced":false,"display_name":"Search Number of Results","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"search_num_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5},"similar_num_results":{"_input_type":"IntInput","advanced":false,"display_name":"Similar Number of Results","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"similar_num_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5},"use_autoprompt":{"_input_type":"BoolInput","advanced":false,"display_name":"Use Autoprompt","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"use_autoprompt","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false}}],["firecrawl",{"FirecrawlCrawlApi":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Crawls a URL and returns the results.","display_name":"Firecrawl Crawl API","documentation":"https://docs.firecrawl.dev/v1/api-reference/endpoint/crawl-post","edited":false,"field_order":["api_key","url","timeout","idempotency_key","crawlerOptions","scrapeOptions"],"frozen":false,"legacy":false,"metadata":{"code_hash":"22fd75efce27","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"firecrawl","version":"1.17.0"}],"total_dependencies":2},"module":"lfx.components.firecrawl.firecrawl_crawl_api.FirecrawlCrawlApi"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"crawl","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Firecrawl API Key","dynamic":false,"info":"The API key to use Firecrawl API.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import uuid\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import DataInput, IntInput, MultilineInput, Output, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass FirecrawlCrawlApi(Component):\n    display_name: str = \"Firecrawl Crawl API\"\n    description: str = \"Crawls a URL and returns the results.\"\n    name = \"FirecrawlCrawlApi\"\n\n    documentation: str = \"https://docs.firecrawl.dev/v1/api-reference/endpoint/crawl-post\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Firecrawl API Key\",\n            required=True,\n            password=True,\n            info=\"The API key to use Firecrawl API.\",\n        ),\n        MultilineInput(\n            name=\"url\",\n            display_name=\"URL\",\n            required=True,\n            info=\"The URL to scrape.\",\n            tool_mode=True,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"Timeout in milliseconds for the request.\",\n        ),\n        StrInput(\n            name=\"idempotency_key\",\n            display_name=\"Idempotency Key\",\n            info=\"Optional idempotency key to ensure unique requests.\",\n        ),\n        DataInput(\n            name=\"crawlerOptions\",\n            display_name=\"Crawler Options\",\n            info=\"The crawler options to send with the request.\",\n        ),\n        DataInput(\n            name=\"scrapeOptions\",\n            display_name=\"Scrape Options\",\n            info=\"The page options to send with the request.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"crawl\"),\n    ]\n    idempotency_key: str | None = None\n\n    def crawl(self) -> Data:\n        try:\n            from firecrawl import FirecrawlApp\n        except ImportError as e:\n            msg = \"Could not import firecrawl integration package. Please install it with `pip install firecrawl-py`.\"\n            raise ImportError(msg) from e\n\n        params = self.crawlerOptions.__dict__[\"data\"] if self.crawlerOptions else {}\n        scrape_options_dict = self.scrapeOptions.__dict__[\"data\"] if self.scrapeOptions else {}\n        if scrape_options_dict:\n            params[\"scrapeOptions\"] = scrape_options_dict\n\n        # Set default values for new parameters in v1\n        params.setdefault(\"maxDepth\", 2)\n        params.setdefault(\"limit\", 10000)\n        params.setdefault(\"allowExternalLinks\", False)\n        params.setdefault(\"allowBackwardLinks\", False)\n        params.setdefault(\"ignoreSitemap\", False)\n        params.setdefault(\"ignoreQueryParameters\", False)\n\n        # Ensure onlyMainContent is explicitly set if not provided\n        if \"scrapeOptions\" in params:\n            params[\"scrapeOptions\"].setdefault(\"onlyMainContent\", True)\n        else:\n            params[\"scrapeOptions\"] = {\"onlyMainContent\": True}\n\n        if not self.idempotency_key:\n            self.idempotency_key = str(uuid.uuid4())\n\n        app = FirecrawlApp(api_key=self.api_key)\n        crawl_result = app.crawl_url(self.url, params=params, idempotency_key=self.idempotency_key)\n        return Data(data={\"results\": crawl_result})\n"},"crawlerOptions":{"_input_type":"DataInput","advanced":false,"display_name":"Crawler Options","dynamic":false,"info":"The crawler options to send with the request.","input_types":["Data"],"list":false,"list_add_label":"Add More","name":"crawlerOptions","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"idempotency_key":{"_input_type":"StrInput","advanced":false,"display_name":"Idempotency Key","dynamic":false,"info":"Optional idempotency key to ensure unique requests.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"idempotency_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"scrapeOptions":{"_input_type":"DataInput","advanced":false,"display_name":"Scrape Options","dynamic":false,"info":"The page options to send with the request.","input_types":["Data"],"list":false,"list_add_label":"Add More","name":"scrapeOptions","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"timeout":{"_input_type":"IntInput","advanced":false,"display_name":"Timeout","dynamic":false,"info":"Timeout in milliseconds for the request.","list":false,"list_add_label":"Add More","name":"timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"url":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"URL","dynamic":false,"info":"The URL to scrape.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"FirecrawlExtractApi":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Extracts data from a URL.","display_name":"Firecrawl Extract API","documentation":"https://docs.firecrawl.dev/api-reference/endpoint/extract","edited":false,"field_order":["api_key","urls","prompt","schema","enable_web_search"],"frozen":false,"legacy":false,"metadata":{"code_hash":"8083782c2c28","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"firecrawl","version":"1.17.0"}],"total_dependencies":2},"module":"lfx.components.firecrawl.firecrawl_extract_api.FirecrawlExtractApi"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"extract","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Firecrawl API Key","dynamic":false,"info":"The API key to use Firecrawl API.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.io import BoolInput, DataInput, MultilineInput, Output, SecretStrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\n\n\nclass FirecrawlExtractApi(Component):\n    display_name: str = \"Firecrawl Extract API\"\n    description: str = \"Extracts data from a URL.\"\n    name = \"FirecrawlExtractApi\"\n\n    documentation: str = \"https://docs.firecrawl.dev/api-reference/endpoint/extract\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Firecrawl API Key\",\n            required=True,\n            password=True,\n            info=\"The API key to use Firecrawl API.\",\n        ),\n        MultilineInput(\n            name=\"urls\",\n            display_name=\"URLs\",\n            required=True,\n            info=\"List of URLs to extract data from (separated by commas or new lines).\",\n            tool_mode=True,\n        ),\n        MultilineInput(\n            name=\"prompt\",\n            display_name=\"Prompt\",\n            required=True,\n            info=\"Prompt to guide the extraction process.\",\n            tool_mode=True,\n        ),\n        DataInput(\n            name=\"schema\",\n            display_name=\"Schema\",\n            required=False,\n            info=\"Schema to define the structure of the extracted data.\",\n        ),\n        BoolInput(\n            name=\"enable_web_search\",\n            display_name=\"Enable Web Search\",\n            info=\"When true, the extraction will use web search to find additional data.\",\n        ),\n        # # Optional: Not essential for basic extraction\n        # BoolInput(\n        #     name=\"ignore_sitemap\",\n        #     display_name=\"Ignore Sitemap\",\n        #     info=\"When true, sitemap.xml files will be ignored during website scanning.\",\n        # ),\n        # # Optional: Not essential for basic extraction\n        # BoolInput(\n        #     name=\"include_subdomains\",\n        #     display_name=\"Include Subdomains\",\n        #     info=\"When true, subdomains of the provided URLs will also be scanned.\",\n        # ),\n        # # Optional: Not essential for basic extraction\n        # BoolInput(\n        #     name=\"show_sources\",\n        #     display_name=\"Show Sources\",\n        #     info=\"When true, the sources used to extract the data will be included in the response.\",\n        # ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"extract\"),\n    ]\n\n    def extract(self) -> Data:\n        try:\n            from firecrawl import FirecrawlApp\n        except ImportError as e:\n            msg = \"Could not import firecrawl integration package. Please install it with `pip install firecrawl-py`.\"\n            raise ImportError(msg) from e\n\n        # Validate API key\n        if not self.api_key:\n            msg = \"API key is required\"\n            raise ValueError(msg)\n\n        # Validate URLs\n        if not self.urls:\n            msg = \"URLs are required\"\n            raise ValueError(msg)\n\n        # Split and validate URLs (handle both commas and newlines)\n        urls = [url.strip() for url in self.urls.replace(\"\\n\", \",\").split(\",\") if url.strip()]\n        if not urls:\n            msg = \"No valid URLs provided\"\n            raise ValueError(msg)\n\n        # Validate and process prompt\n        if not self.prompt:\n            msg = \"Prompt is required\"\n            raise ValueError(msg)\n\n        # Get the prompt text (handling both string and multiline input)\n        prompt_text = self.prompt.strip()\n\n        # Enhance the prompt to encourage comprehensive extraction\n        enhanced_prompt = prompt_text\n        if \"schema\" not in prompt_text.lower():\n            enhanced_prompt = f\"{prompt_text}. Please extract all instances in a comprehensive, structured format.\"\n\n        params = {\n            \"prompt\": enhanced_prompt,\n            \"enableWebSearch\": self.enable_web_search,\n            # Optional parameters - not essential for basic extraction\n            \"ignoreSitemap\": self.ignore_sitemap,\n            \"includeSubdomains\": self.include_subdomains,\n            \"showSources\": self.show_sources,\n            \"timeout\": 300,\n        }\n\n        # Only add schema to params if it's provided and is a valid schema structure\n        if self.schema:\n            try:\n                if isinstance(self.schema, dict) and \"type\" in self.schema:\n                    params[\"schema\"] = self.schema\n                elif hasattr(self.schema, \"dict\") and \"type\" in self.schema.dict():\n                    params[\"schema\"] = self.schema.dict()\n                else:\n                    # Skip invalid schema without raising an error\n                    pass\n            except Exception as e:  # noqa: BLE001\n                logger.error(f\"Invalid schema: {e!s}\")\n\n        try:\n            app = FirecrawlApp(api_key=self.api_key)\n            extract_result = app.extract(urls, params=params)\n            return Data(data=extract_result)\n        except Exception as e:\n            msg = f\"Error during extraction: {e!s}\"\n            raise ValueError(msg) from e\n"},"enable_web_search":{"_input_type":"BoolInput","advanced":false,"display_name":"Enable Web Search","dynamic":false,"info":"When true, the extraction will use web search to find additional data.","list":false,"list_add_label":"Add More","name":"enable_web_search","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"prompt":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Prompt","dynamic":false,"info":"Prompt to guide the extraction process.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"prompt","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"schema":{"_input_type":"DataInput","advanced":false,"display_name":"Schema","dynamic":false,"info":"Schema to define the structure of the extracted data.","input_types":["Data"],"list":false,"list_add_label":"Add More","name":"schema","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"urls":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"URLs","dynamic":false,"info":"List of URLs to extract data from (separated by commas or new lines).","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"urls","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"FirecrawlMapApi":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Maps a URL and returns the results.","display_name":"Firecrawl Map API","documentation":"https://docs.firecrawl.dev/api-reference/endpoint/map","edited":false,"field_order":["api_key","urls","ignore_sitemap","sitemap_only","include_subdomains"],"frozen":false,"legacy":false,"metadata":{"code_hash":"e326e840049b","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"firecrawl","version":"1.17.0"}],"total_dependencies":2},"module":"lfx.components.firecrawl.firecrawl_map_api.FirecrawlMapApi"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"map","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Firecrawl API Key","dynamic":false,"info":"The API key to use Firecrawl API.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.io import (\n    BoolInput,\n    MultilineInput,\n    Output,\n    SecretStrInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass FirecrawlMapApi(Component):\n    display_name: str = \"Firecrawl Map API\"\n    description: str = \"Maps a URL and returns the results.\"\n    name = \"FirecrawlMapApi\"\n\n    documentation: str = \"https://docs.firecrawl.dev/api-reference/endpoint/map\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Firecrawl API Key\",\n            required=True,\n            password=True,\n            info=\"The API key to use Firecrawl API.\",\n        ),\n        MultilineInput(\n            name=\"urls\",\n            display_name=\"URLs\",\n            required=True,\n            info=\"List of URLs to create maps from (separated by commas or new lines).\",\n            tool_mode=True,\n        ),\n        BoolInput(\n            name=\"ignore_sitemap\",\n            display_name=\"Ignore Sitemap\",\n            info=\"When true, the sitemap.xml file will be ignored during crawling.\",\n        ),\n        BoolInput(\n            name=\"sitemap_only\",\n            display_name=\"Sitemap Only\",\n            info=\"When true, only links found in the sitemap will be returned.\",\n        ),\n        BoolInput(\n            name=\"include_subdomains\",\n            display_name=\"Include Subdomains\",\n            info=\"When true, subdomains of the provided URL will also be scanned.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"map\"),\n    ]\n\n    def map(self) -> Data:\n        try:\n            from firecrawl import FirecrawlApp\n        except ImportError as e:\n            msg = \"Could not import firecrawl integration package. Please install it with `pip install firecrawl-py`.\"\n            raise ImportError(msg) from e\n\n        # Validate URLs\n        if not self.urls:\n            msg = \"URLs are required\"\n            raise ValueError(msg)\n\n        # Split and validate URLs (handle both commas and newlines)\n        urls = [url.strip() for url in self.urls.replace(\"\\n\", \",\").split(\",\") if url.strip()]\n        if not urls:\n            msg = \"No valid URLs provided\"\n            raise ValueError(msg)\n\n        params = {\n            \"ignoreSitemap\": self.ignore_sitemap,\n            \"sitemapOnly\": self.sitemap_only,\n            \"includeSubdomains\": self.include_subdomains,\n        }\n\n        app = FirecrawlApp(api_key=self.api_key)\n\n        # Map all provided URLs and combine results\n        combined_links = []\n        for url in urls:\n            result = app.map_url(url, params=params)\n            if isinstance(result, dict) and \"links\" in result:\n                combined_links.extend(result[\"links\"])\n\n        map_result = {\"success\": True, \"links\": combined_links}\n\n        return Data(data=map_result)\n"},"ignore_sitemap":{"_input_type":"BoolInput","advanced":false,"display_name":"Ignore Sitemap","dynamic":false,"info":"When true, the sitemap.xml file will be ignored during crawling.","list":false,"list_add_label":"Add More","name":"ignore_sitemap","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"include_subdomains":{"_input_type":"BoolInput","advanced":false,"display_name":"Include Subdomains","dynamic":false,"info":"When true, subdomains of the provided URL will also be scanned.","list":false,"list_add_label":"Add More","name":"include_subdomains","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"sitemap_only":{"_input_type":"BoolInput","advanced":false,"display_name":"Sitemap Only","dynamic":false,"info":"When true, only links found in the sitemap will be returned.","list":false,"list_add_label":"Add More","name":"sitemap_only","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"urls":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"URLs","dynamic":false,"info":"List of URLs to create maps from (separated by commas or new lines).","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"urls","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"FirecrawlScrapeApi":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Scrapes a URL and returns the results.","display_name":"Firecrawl Scrape API","documentation":"https://docs.firecrawl.dev/api-reference/endpoint/scrape","edited":false,"field_order":["api_key","url","timeout","scrapeOptions","extractorOptions"],"frozen":false,"legacy":false,"metadata":{"code_hash":"857b7da04207","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"firecrawl","version":"1.17.0"}],"total_dependencies":2},"module":"lfx.components.firecrawl.firecrawl_scrape_api.FirecrawlScrapeApi"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"scrape","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Firecrawl API Key","dynamic":false,"info":"The API key to use Firecrawl API.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.io import (\n    DataInput,\n    IntInput,\n    MultilineInput,\n    Output,\n    SecretStrInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass FirecrawlScrapeApi(Component):\n    display_name: str = \"Firecrawl Scrape API\"\n    description: str = \"Scrapes a URL and returns the results.\"\n    name = \"FirecrawlScrapeApi\"\n\n    documentation: str = \"https://docs.firecrawl.dev/api-reference/endpoint/scrape\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Firecrawl API Key\",\n            required=True,\n            password=True,\n            info=\"The API key to use Firecrawl API.\",\n        ),\n        MultilineInput(\n            name=\"url\",\n            display_name=\"URL\",\n            required=True,\n            info=\"The URL to scrape.\",\n            tool_mode=True,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"Timeout in milliseconds for the request.\",\n        ),\n        DataInput(\n            name=\"scrapeOptions\",\n            display_name=\"Scrape Options\",\n            info=\"The page options to send with the request.\",\n        ),\n        DataInput(\n            name=\"extractorOptions\",\n            display_name=\"Extractor Options\",\n            info=\"The extractor options to send with the request.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"scrape\"),\n    ]\n\n    def scrape(self) -> Data:\n        try:\n            from firecrawl import FirecrawlApp\n        except ImportError as e:\n            msg = \"Could not import firecrawl integration package. Please install it with `pip install firecrawl-py`.\"\n            raise ImportError(msg) from e\n\n        params = self.scrapeOptions.__dict__.get(\"data\", {}) if self.scrapeOptions else {}\n        extractor_options_dict = self.extractorOptions.__dict__.get(\"data\", {}) if self.extractorOptions else {}\n        if extractor_options_dict:\n            params[\"extract\"] = extractor_options_dict\n\n        # Set default values for parameters\n        params.setdefault(\"formats\", [\"markdown\"])  # Default output format\n        params.setdefault(\"onlyMainContent\", True)  # Default to only main content\n\n        app = FirecrawlApp(api_key=self.api_key)\n        results = app.scrape_url(self.url, params=params)\n        return Data(data=results)\n"},"extractorOptions":{"_input_type":"DataInput","advanced":false,"display_name":"Extractor Options","dynamic":false,"info":"The extractor options to send with the request.","input_types":["Data"],"list":false,"list_add_label":"Add More","name":"extractorOptions","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"scrapeOptions":{"_input_type":"DataInput","advanced":false,"display_name":"Scrape Options","dynamic":false,"info":"The page options to send with the request.","input_types":["Data"],"list":false,"list_add_label":"Add More","name":"scrapeOptions","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"timeout":{"_input_type":"IntInput","advanced":false,"display_name":"Timeout","dynamic":false,"info":"Timeout in milliseconds for the request.","list":false,"list_add_label":"Add More","name":"timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"url":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"URL","dynamic":false,"info":"The URL to scrape.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["git",{"GitExtractorComponent":{"base_classes":["Data","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Analyzes a Git repository and returns file contents and complete repository information","display_name":"GitExtractor","documentation":"","edited":false,"field_order":["repository_url"],"frozen":false,"icon":"GitLoader","legacy":false,"metadata":{"code_hash":"79f338765b69","dependencies":{"dependencies":[{"name":"aiofiles","version":"24.1.0"},{"name":"git","version":"3.1.43"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.git.gitextractor.GitExtractorComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Text-Based File Contents","group_outputs":false,"method":"get_text_based_file_contents","name":"text_based_file_contents","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Directory Structure","group_outputs":false,"method":"get_directory_structure","name":"directory_structure","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Repository Info","group_outputs":false,"method":"get_repository_info","name":"repository_info","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Statistics","group_outputs":false,"method":"get_statistics","name":"statistics","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Files Content","group_outputs":false,"method":"get_files_content","name":"files_content","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import os\nimport shutil\nimport tempfile\nfrom contextlib import asynccontextmanager\nfrom pathlib import Path\n\nimport aiofiles\nimport git\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import MessageTextInput, Output\nfrom lfx.schema.data import Data\nfrom lfx.schema.message import Message\n\n\nclass GitExtractorComponent(Component):\n    display_name = \"GitExtractor\"\n    description = \"Analyzes a Git repository and returns file contents and complete repository information\"\n    icon = \"GitLoader\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"repository_url\",\n            display_name=\"Repository URL\",\n            info=\"URL of the Git repository (e.g., https://github.com/username/repo)\",\n            value=\"\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Text-Based File Contents\",\n            name=\"text_based_file_contents\",\n            method=\"get_text_based_file_contents\",\n        ),\n        Output(display_name=\"Directory Structure\", name=\"directory_structure\", method=\"get_directory_structure\"),\n        Output(display_name=\"Repository Info\", name=\"repository_info\", method=\"get_repository_info\"),\n        Output(display_name=\"Statistics\", name=\"statistics\", method=\"get_statistics\"),\n        Output(display_name=\"Files Content\", name=\"files_content\", method=\"get_files_content\"),\n    ]\n\n    @asynccontextmanager\n    async def temp_git_repo(self):\n        \"\"\"Async context manager for temporary git repository cloning.\"\"\"\n        temp_dir = tempfile.mkdtemp()\n        try:\n            # Clone is still sync but wrapped in try/finally\n            git.Repo.clone_from(self.repository_url, temp_dir)\n            yield temp_dir\n        finally:\n            shutil.rmtree(temp_dir, ignore_errors=True)\n\n    async def get_repository_info(self) -> list[Data]:\n        try:\n            async with self.temp_git_repo() as temp_dir:\n                repo = git.Repo(temp_dir)\n                repo_info = {\n                    \"name\": self.repository_url.split(\"/\")[-1],\n                    \"url\": self.repository_url,\n                    \"default_branch\": repo.active_branch.name,\n                    \"remote_urls\": [remote.url for remote in repo.remotes],\n                    \"last_commit\": {\n                        \"hash\": repo.head.commit.hexsha,\n                        \"author\": str(repo.head.commit.author),\n                        \"message\": repo.head.commit.message.strip(),\n                        \"date\": str(repo.head.commit.committed_datetime),\n                    },\n                    \"branches\": [str(branch) for branch in repo.branches],\n                }\n                result = [Data(data=repo_info)]\n                self.status = result\n                return result\n        except git.GitError as e:\n            error_result = [Data(data={\"error\": f\"Error getting repository info: {e!s}\"})]\n            self.status = error_result\n            return error_result\n\n    async def get_statistics(self) -> list[Data]:\n        try:\n            async with self.temp_git_repo() as temp_dir:\n                total_files = 0\n                total_size = 0\n                total_lines = 0\n                binary_files = 0\n                directories = 0\n\n                for root, dirs, files in os.walk(temp_dir):\n                    total_files += len(files)\n                    directories += len(dirs)\n                    for file in files:\n                        file_path = Path(root) / file\n                        total_size += file_path.stat().st_size\n                        try:\n                            async with aiofiles.open(file_path, encoding=\"utf-8\") as f:\n                                total_lines += sum(1 for _ in await f.readlines())\n                        except UnicodeDecodeError:\n                            binary_files += 1\n\n                statistics = {\n                    \"total_files\": total_files,\n                    \"total_size_bytes\": total_size,\n                    \"total_size_kb\": round(total_size / 1024, 2),\n                    \"total_size_mb\": round(total_size / (1024 * 1024), 2),\n                    \"total_lines\": total_lines,\n                    \"binary_files\": binary_files,\n                    \"directories\": directories,\n                }\n                result = [Data(data=statistics)]\n                self.status = result\n                return result\n        except git.GitError as e:\n            error_result = [Data(data={\"error\": f\"Error calculating statistics: {e!s}\"})]\n            self.status = error_result\n            return error_result\n\n    async def get_directory_structure(self) -> Message:\n        try:\n            async with self.temp_git_repo() as temp_dir:\n                tree = [\"Directory structure:\"]\n                for root, _dirs, files in os.walk(temp_dir):\n                    level = root.replace(temp_dir, \"\").count(os.sep)\n                    indent = \"    \" * level\n                    if level == 0:\n                        tree.append(f\"└── {Path(root).name}\")\n                    else:\n                        tree.append(f\"{indent}├── {Path(root).name}\")\n                    subindent = \"    \" * (level + 1)\n                    tree.extend(f\"{subindent}├── {f}\" for f in files)\n                directory_structure = \"\\n\".join(tree)\n                self.status = directory_structure\n                return Message(text=directory_structure)\n        except git.GitError as e:\n            error_message = f\"Error getting directory structure: {e!s}\"\n            self.status = error_message\n            return Message(text=error_message)\n\n    async def get_files_content(self) -> list[Data]:\n        try:\n            async with self.temp_git_repo() as temp_dir:\n                content_list = []\n                for root, _, files in os.walk(temp_dir):\n                    for file in files:\n                        file_path = Path(root) / file\n                        relative_path = file_path.relative_to(temp_dir)\n                        file_size = file_path.stat().st_size\n                        try:\n                            async with aiofiles.open(file_path, encoding=\"utf-8\") as f:\n                                file_content = await f.read()\n                        except UnicodeDecodeError:\n                            file_content = \"[BINARY FILE]\"\n                        content_list.append(\n                            Data(data={\"path\": str(relative_path), \"size\": file_size, \"content\": file_content})\n                        )\n                self.status = content_list\n                return content_list\n        except git.GitError as e:\n            error_result = [Data(data={\"error\": f\"Error getting files content: {e!s}\"})]\n            self.status = error_result\n            return error_result\n\n    async def get_text_based_file_contents(self) -> Message:\n        try:\n            async with self.temp_git_repo() as temp_dir:\n                content_list = [\"(Files content cropped to 300k characters, download full ingest to see more)\"]\n                total_chars = 0\n                char_limit = 300000\n\n                for root, _, files in os.walk(temp_dir):\n                    for file in files:\n                        file_path = Path(root) / file\n                        relative_path = file_path.relative_to(temp_dir)\n                        content_list.extend([\"=\" * 50, f\"File: /{relative_path}\", \"=\" * 50])\n\n                        try:\n                            async with aiofiles.open(file_path, encoding=\"utf-8\") as f:\n                                file_content = await f.read()\n                                if total_chars + len(file_content) > char_limit:\n                                    remaining_chars = char_limit - total_chars\n                                    file_content = file_content[:remaining_chars] + \"\\n... (content truncated)\"\n                                content_list.append(file_content)\n                                total_chars += len(file_content)\n                        except UnicodeDecodeError:\n                            content_list.append(\"[BINARY FILE]\")\n\n                        content_list.append(\"\")\n\n                        if total_chars >= char_limit:\n                            break\n\n                text_content = \"\\n\".join(content_list)\n                self.status = text_content\n                return Message(text=text_content)\n        except git.GitError as e:\n            error_message = f\"Error getting text-based file contents: {e!s}\"\n            self.status = error_message\n            return Message(text=error_message)\n"},"repository_url":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Repository URL","dynamic":false,"info":"URL of the Git repository (e.g., https://github.com/username/repo)","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"repository_url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"GitLoaderComponent":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Load and filter documents from a local or remote Git repository. Use a local repo path or clone from a remote URL.","display_name":"Git","documentation":"","edited":false,"field_order":["repo_source","repo_path","clone_url","branch","file_filter","content_filter"],"frozen":false,"icon":"GitLoader","legacy":false,"metadata":{"code_hash":"ac5de0564a4f","dependencies":{"dependencies":[{"name":"anyio","version":"4.11.0"},{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.git.git.GitLoaderComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"load_documents","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","branch":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Branch","dynamic":false,"info":"The branch to load files from. Defaults to 'main'.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"branch","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"main"},"clone_url":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Clone URL","dynamic":true,"info":"The URL of the Git repository to clone (used if 'Clone' is selected).","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"clone_url","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import re\nimport tempfile\nfrom contextlib import asynccontextmanager\nfrom fnmatch import fnmatch\nfrom pathlib import Path\n\nimport anyio\nfrom langchain_community.document_loaders.git import GitLoader\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import DropdownInput, MessageTextInput, Output\nfrom lfx.schema.data import Data\n\n\nclass GitLoaderComponent(Component):\n    display_name = \"Git\"\n    description = (\n        \"Load and filter documents from a local or remote Git repository. \"\n        \"Use a local repo path or clone from a remote URL.\"\n    )\n    trace_type = \"tool\"\n    icon = \"GitLoader\"\n\n    inputs = [\n        DropdownInput(\n            name=\"repo_source\",\n            display_name=\"Repository Source\",\n            options=[\"Local\", \"Remote\"],\n            required=True,\n            info=\"Select whether to use a local repo path or clone from a remote URL.\",\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"repo_path\",\n            display_name=\"Local Repository Path\",\n            required=False,\n            info=\"The local path to the existing Git repository (used if 'Local' is selected).\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"clone_url\",\n            display_name=\"Clone URL\",\n            required=False,\n            info=\"The URL of the Git repository to clone (used if 'Clone' is selected).\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"branch\",\n            display_name=\"Branch\",\n            required=False,\n            value=\"main\",\n            info=\"The branch to load files from. Defaults to 'main'.\",\n        ),\n        MessageTextInput(\n            name=\"file_filter\",\n            display_name=\"File Filter\",\n            required=False,\n            advanced=True,\n            info=(\n                \"Patterns to filter files. For example:\\n\"\n                \"Include only .py files: '*.py'\\n\"\n                \"Exclude .py files: '!*.py'\\n\"\n                \"Multiple patterns can be separated by commas.\"\n            ),\n        ),\n        MessageTextInput(\n            name=\"content_filter\",\n            display_name=\"Content Filter\",\n            required=False,\n            advanced=True,\n            info=\"A regex pattern to filter files based on their content.\",\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"data\", display_name=\"Data\", method=\"load_documents\"),\n    ]\n\n    @staticmethod\n    def is_binary(file_path: str | Path) -> bool:\n        \"\"\"Check if a file is binary by looking for null bytes.\"\"\"\n        try:\n            with Path(file_path).open(\"rb\") as file:\n                content = file.read(1024)\n                return b\"\\x00\" in content\n        except Exception:  # noqa: BLE001\n            return True\n\n    @staticmethod\n    def check_file_patterns(file_path: str | Path, patterns: str) -> bool:\n        \"\"\"Check if a file matches the given patterns.\n\n        Args:\n            file_path: Path to the file to check\n            patterns: Comma-separated list of glob patterns\n\n        Returns:\n            bool: True if file should be included, False if excluded\n        \"\"\"\n        # Handle empty or whitespace-only patterns\n        if not patterns or patterns.isspace():\n            return True\n\n        path_str = str(file_path)\n        file_name = Path(path_str).name\n        pattern_list: list[str] = [pattern.strip() for pattern in patterns.split(\",\") if pattern.strip()]\n\n        # If no valid patterns after stripping, treat as include all\n        if not pattern_list:\n            return True\n\n        # Process exclusion patterns first\n        for pattern in pattern_list:\n            if pattern.startswith(\"!\"):\n                # For exclusions, match against both full path and filename\n                exclude_pattern = pattern[1:]\n                if fnmatch(path_str, exclude_pattern) or fnmatch(file_name, exclude_pattern):\n                    return False\n\n        # Then check inclusion patterns\n        include_patterns = [p for p in pattern_list if not p.startswith(\"!\")]\n        # If no include patterns, treat as include all\n        if not include_patterns:\n            return True\n\n        # For inclusions, match against both full path and filename\n        return any(fnmatch(path_str, pattern) or fnmatch(file_name, pattern) for pattern in include_patterns)\n\n    @staticmethod\n    def check_content_pattern(file_path: str | Path, pattern: str) -> bool:\n        \"\"\"Check if file content matches the given regex pattern.\n\n        Args:\n            file_path: Path to the file to check\n            pattern: Regex pattern to match against content\n\n        Returns:\n            bool: True if content matches, False otherwise\n        \"\"\"\n        try:\n            # Check if file is binary\n            with Path(file_path).open(\"rb\") as file:\n                content = file.read(1024)\n                if b\"\\x00\" in content:\n                    return False\n\n            # Try to compile the regex pattern first\n            try:\n                # Use the MULTILINE flag to better handle text content\n                content_regex = re.compile(pattern, re.MULTILINE)\n                # Test the pattern with a simple string to catch syntax errors\n                test_str = \"test\\nstring\"\n                if not content_regex.search(test_str):\n                    # Pattern is valid but doesn't match test string\n                    pass\n            except (re.error, TypeError, ValueError):\n                return False\n\n            # If not binary and regex is valid, check content\n            with Path(file_path).open(encoding=\"utf-8\") as file:\n                file_content = file.read()\n            return bool(content_regex.search(file_content))\n        except (OSError, UnicodeDecodeError):\n            return False\n\n    def build_combined_filter(self, file_filter_patterns: str | None = None, content_filter_pattern: str | None = None):\n        \"\"\"Build a combined filter function from file and content patterns.\n\n        Args:\n            file_filter_patterns: Comma-separated glob patterns\n            content_filter_pattern: Regex pattern for content\n\n        Returns:\n            callable: Filter function that takes a file path and returns bool\n        \"\"\"\n\n        def combined_filter(file_path: str) -> bool:\n            try:\n                path = Path(file_path)\n\n                # Check if file exists and is readable\n                if not path.exists():\n                    return False\n\n                # Check if file is binary\n                if self.is_binary(path):\n                    return False\n\n                # Apply file pattern filters\n                if file_filter_patterns and not self.check_file_patterns(path, file_filter_patterns):\n                    return False\n\n                # Apply content filter\n                return not (content_filter_pattern and not self.check_content_pattern(path, content_filter_pattern))\n            except Exception:  # noqa: BLE001\n                return False\n\n        return combined_filter\n\n    @asynccontextmanager\n    async def temp_clone_dir(self):\n        \"\"\"Context manager for handling temporary clone directory.\"\"\"\n        temp_dir = None\n        try:\n            temp_dir = tempfile.mkdtemp(prefix=\"langflow_clone_\")\n            yield temp_dir\n        finally:\n            if temp_dir:\n                await anyio.Path(temp_dir).rmdir()\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        # Hide fields by default\n        build_config[\"repo_path\"][\"show\"] = False\n        build_config[\"clone_url\"][\"show\"] = False\n\n        if field_name == \"repo_source\":\n            if field_value == \"Local\":\n                build_config[\"repo_path\"][\"show\"] = True\n                build_config[\"repo_path\"][\"required\"] = True\n                build_config[\"clone_url\"][\"required\"] = False\n            elif field_value == \"Remote\":\n                build_config[\"clone_url\"][\"show\"] = True\n                build_config[\"clone_url\"][\"required\"] = True\n                build_config[\"repo_path\"][\"required\"] = False\n\n        return build_config\n\n    async def build_gitloader(self) -> GitLoader:\n        file_filter_patterns = getattr(self, \"file_filter\", None)\n        content_filter_pattern = getattr(self, \"content_filter\", None)\n\n        combined_filter = self.build_combined_filter(file_filter_patterns, content_filter_pattern)\n\n        repo_source = getattr(self, \"repo_source\", None)\n        if repo_source == \"Local\":\n            repo_path = self.repo_path\n            clone_url = None\n        else:\n            # Clone source\n            clone_url = self.clone_url\n            async with self.temp_clone_dir() as temp_dir:\n                repo_path = temp_dir\n\n        # Only pass branch if it's explicitly set\n        branch = getattr(self, \"branch\", None)\n        if not branch:\n            branch = None\n\n        return GitLoader(\n            repo_path=repo_path,\n            clone_url=clone_url if repo_source == \"Remote\" else None,\n            branch=branch,\n            file_filter=combined_filter,\n        )\n\n    async def load_documents(self) -> list[Data]:\n        gitloader = await self.build_gitloader()\n        data = [Data.from_document(doc) async for doc in gitloader.alazy_load()]\n        self.status = data\n        return data\n"},"content_filter":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Content Filter","dynamic":false,"info":"A regex pattern to filter files based on their content.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"content_filter","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"file_filter":{"_input_type":"MessageTextInput","advanced":true,"display_name":"File Filter","dynamic":false,"info":"Patterns to filter files. For example:\nInclude only .py files: '*.py'\nExclude .py files: '!*.py'\nMultiple patterns can be separated by commas.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"file_filter","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"repo_path":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Local Repository Path","dynamic":true,"info":"The local path to the existing Git repository (used if 'Local' is selected).","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"repo_path","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"repo_source":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Repository Source","dynamic":false,"external_options":{},"info":"Select whether to use a local repo path or clone from a remote URL.","name":"repo_source","options":["Local","Remote"],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["glean",{"GleanSearchAPIComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Search using Glean's API.","display_name":"Glean Search API","documentation":"https://docs.langflow.org/Components/components-tools#glean-search-api","edited":false,"field_order":["glean_api_url","glean_access_token","query","page_size","request_options"],"frozen":false,"icon":"Glean","legacy":false,"metadata":{"code_hash":"25613a76fe6f","dependencies":{"dependencies":[{"name":"httpx","version":"0.28.1"},{"name":"langchain_core","version":"0.3.79"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.glean.glean_search_api.GleanSearchAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"fetch_content_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nfrom typing import Any\nfrom urllib.parse import urljoin\n\nimport httpx\nfrom langchain_core.tools import StructuredTool, ToolException\nfrom pydantic import BaseModel\nfrom pydantic.v1 import Field\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.field_typing import Tool\nfrom lfx.inputs.inputs import IntInput, MultilineInput, NestedDictInput, SecretStrInput, StrInput\nfrom lfx.io import Output\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\n\n\nclass GleanSearchAPISchema(BaseModel):\n    query: str = Field(..., description=\"The search query\")\n    page_size: int = Field(10, description=\"Maximum number of results to return\")\n    request_options: dict[str, Any] | None = Field(default_factory=dict, description=\"Request Options\")\n\n\nclass GleanAPIWrapper(BaseModel):\n    \"\"\"Wrapper around Glean API.\"\"\"\n\n    glean_api_url: str\n    glean_access_token: str\n    act_as: str = \"langflow-component@datastax.com\"  # TODO: Detect this\n\n    def _prepare_request(\n        self,\n        query: str,\n        page_size: int = 10,\n        request_options: dict[str, Any] | None = None,\n    ) -> dict:\n        # Ensure there's a trailing slash\n        url = self.glean_api_url\n        if not url.endswith(\"/\"):\n            url += \"/\"\n\n        return {\n            \"url\": urljoin(url, \"search\"),\n            \"headers\": {\n                \"Authorization\": f\"Bearer {self.glean_access_token}\",\n                \"X-Scio-ActAs\": self.act_as,\n            },\n            \"payload\": {\n                \"query\": query,\n                \"pageSize\": page_size,\n                \"requestOptions\": request_options,\n            },\n        }\n\n    def results(self, query: str, **kwargs: Any) -> list[dict[str, Any]]:\n        results = self._search_api_results(query, **kwargs)\n\n        if len(results) == 0:\n            msg = \"No good Glean Search Result was found\"\n            raise AssertionError(msg)\n\n        return results\n\n    def run(self, query: str, **kwargs: Any) -> list[dict[str, Any]]:\n        try:\n            results = self.results(query, **kwargs)\n\n            processed_results = []\n            for result in results:\n                if \"title\" in result:\n                    result[\"snippets\"] = result.get(\"snippets\", [{\"snippet\": {\"text\": result[\"title\"]}}])\n                    if \"text\" not in result[\"snippets\"][0]:\n                        result[\"snippets\"][0][\"text\"] = result[\"title\"]\n\n                processed_results.append(result)\n        except Exception as e:\n            error_message = f\"Error in Glean Search API: {e!s}\"\n            raise ToolException(error_message) from e\n\n        return processed_results\n\n    def _search_api_results(self, query: str, **kwargs: Any) -> list[dict[str, Any]]:\n        request_details = self._prepare_request(query, **kwargs)\n\n        response = httpx.post(\n            request_details[\"url\"],\n            json=request_details[\"payload\"],\n            headers=request_details[\"headers\"],\n        )\n\n        response.raise_for_status()\n        response_json = response.json()\n\n        return response_json.get(\"results\", [])\n\n    @staticmethod\n    def _result_as_string(result: dict) -> str:\n        return json.dumps(result, indent=4)\n\n\nclass GleanSearchAPIComponent(LCToolComponent):\n    display_name: str = \"Glean Search API\"\n    description: str = \"Search using Glean's API.\"\n    documentation: str = \"https://docs.langflow.org/Components/components-tools#glean-search-api\"\n    icon: str = \"Glean\"\n\n    outputs = [\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"fetch_content_dataframe\"),\n    ]\n\n    inputs = [\n        StrInput(name=\"glean_api_url\", display_name=\"Glean API URL\", required=True),\n        SecretStrInput(name=\"glean_access_token\", display_name=\"Glean Access Token\", required=True),\n        MultilineInput(name=\"query\", display_name=\"Query\", required=True, tool_mode=True),\n        IntInput(name=\"page_size\", display_name=\"Page Size\", value=10),\n        NestedDictInput(name=\"request_options\", display_name=\"Request Options\", required=False),\n    ]\n\n    def build_tool(self) -> Tool:\n        wrapper = self._build_wrapper(\n            glean_api_url=self.glean_api_url,\n            glean_access_token=self.glean_access_token,\n        )\n\n        tool = StructuredTool.from_function(\n            name=\"glean_search_api\",\n            description=\"Search Glean for relevant results.\",\n            func=wrapper.run,\n            args_schema=GleanSearchAPISchema,\n        )\n\n        self.status = \"Glean Search API Tool for Langchain\"\n\n        return tool\n\n    def run_model(self) -> DataFrame:\n        return self.fetch_content_dataframe()\n\n    def fetch_content(self) -> list[Data]:\n        tool = self.build_tool()\n\n        results = tool.run(\n            {\n                \"query\": self.query,\n                \"page_size\": self.page_size,\n                \"request_options\": self.request_options,\n            }\n        )\n\n        # Build the data\n        data = [Data(data=result, text=result[\"snippets\"][0][\"text\"]) for result in results]\n        self.status = data  # type: ignore[assignment]\n\n        return data\n\n    def _build_wrapper(\n        self,\n        glean_api_url: str,\n        glean_access_token: str,\n    ):\n        return GleanAPIWrapper(\n            glean_api_url=glean_api_url,\n            glean_access_token=glean_access_token,\n        )\n\n    def fetch_content_dataframe(self) -> DataFrame:\n        \"\"\"Convert the Glean search results to a DataFrame.\n\n        Returns:\n            DataFrame: A DataFrame containing the search results.\n        \"\"\"\n        data = self.fetch_content()\n        return DataFrame(data)\n"},"glean_access_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Glean Access Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"glean_access_token","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"glean_api_url":{"_input_type":"StrInput","advanced":false,"display_name":"Glean API URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"glean_api_url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"page_size":{"_input_type":"IntInput","advanced":false,"display_name":"Page Size","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"page_size","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":10},"query":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Query","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"query","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"request_options":{"_input_type":"NestedDictInput","advanced":false,"display_name":"Request Options","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"request_options","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"NestedDict","value":{}}},"tool_mode":false}}],["google",{"BigQueryExecutor":{"base_classes":["DataFrame"],"beta":true,"conditional_paths":[],"custom_fields":{},"description":"Execute SQL queries on Google BigQuery.","display_name":"BigQuery","documentation":"","edited":false,"field_order":["service_account_json_file","query","clean_query"],"frozen":false,"icon":"Google","legacy":false,"metadata":{"code_hash":"7f61159743ec","dependencies":{"dependencies":[{"name":"google","version":"0.8.5"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.google.google_bq_sql_executor.BigQueryExecutorComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Query Results","group_outputs":false,"method":"execute_sql","name":"query_results","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","clean_query":{"_input_type":"BoolInput","advanced":true,"display_name":"Clean Query","dynamic":false,"info":"When enabled, this will automatically clean up your SQL query.","list":false,"list_add_label":"Add More","name":"clean_query","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nimport re\nfrom pathlib import Path\n\nfrom google.auth.exceptions import RefreshError\nfrom google.cloud import bigquery\nfrom google.oauth2.service_account import Credentials\n\nfrom lfx.custom import Component\nfrom lfx.io import BoolInput, FileInput, MessageTextInput, Output\nfrom lfx.schema.dataframe import DataFrame\n\n\nclass BigQueryExecutorComponent(Component):\n    display_name = \"BigQuery\"\n    description = \"Execute SQL queries on Google BigQuery.\"\n    name = \"BigQueryExecutor\"\n    icon = \"Google\"\n    beta: bool = True\n\n    inputs = [\n        FileInput(\n            name=\"service_account_json_file\",\n            display_name=\"Upload Service Account JSON\",\n            info=\"Upload the JSON file containing Google Cloud service account credentials.\",\n            file_types=[\"json\"],\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"SQL Query\",\n            info=\"The SQL query to execute on BigQuery.\",\n            required=True,\n            tool_mode=True,\n        ),\n        BoolInput(\n            name=\"clean_query\",\n            display_name=\"Clean Query\",\n            info=\"When enabled, this will automatically clean up your SQL query.\",\n            value=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Query Results\", name=\"query_results\", method=\"execute_sql\"),\n    ]\n\n    def _clean_sql_query(self, query: str) -> str:\n        \"\"\"Clean SQL query by removing surrounding quotes and whitespace.\n\n        Also extracts SQL statements from text that might contain other content.\n\n        Args:\n            query: The SQL query to clean\n\n        Returns:\n            The cleaned SQL query\n        \"\"\"\n        # First, try to extract SQL from code blocks\n        sql_pattern = r\"```(?:sql)?\\s*([\\s\\S]*?)\\s*```\"\n        sql_matches = re.findall(sql_pattern, query, re.IGNORECASE)\n\n        if sql_matches:\n            # If we found SQL in code blocks, use the first match\n            query = sql_matches[0]\n        else:\n            # If no code block, try to find SQL statements\n            # Look for common SQL keywords at the start of lines\n            sql_keywords = r\"(?i)(SELECT|INSERT|UPDATE|DELETE|CREATE|ALTER|DROP|WITH|MERGE)\"\n            lines = query.split(\"\\n\")\n            sql_lines = []\n            in_sql = False\n\n            for _line in lines:\n                line = _line.strip()\n                if re.match(sql_keywords, line):\n                    in_sql = True\n                if in_sql:\n                    sql_lines.append(line)\n                if line.endswith(\";\"):\n                    in_sql = False\n\n            if sql_lines:\n                query = \"\\n\".join(sql_lines)\n\n        # Remove any backticks that might be at the start or end\n        query = query.strip(\"`\")\n\n        # Then remove surrounding quotes (single or double) if they exist\n        query = query.strip()\n        if (query.startswith('\"') and query.endswith('\"')) or (query.startswith(\"'\") and query.endswith(\"'\")):\n            query = query[1:-1]\n\n        # Finally, clean up any remaining whitespace and ensure no backticks remain\n        query = query.strip()\n        # Remove any remaining backticks, but preserve them if they're part of a table/column name\n        # This regex will remove backticks that are not part of a valid identifier\n        return re.sub(r\"`(?![a-zA-Z0-9_])|(?<![a-zA-Z0-9_])`\", \"\", query)\n\n    def execute_sql(self) -> DataFrame:\n        try:\n            # First try to read the file\n            try:\n                service_account_path = Path(self.service_account_json_file)\n                with service_account_path.open() as f:\n                    credentials_json = json.load(f)\n                    project_id = credentials_json.get(\"project_id\")\n                    if not project_id:\n                        msg = \"No project_id found in service account credentials file.\"\n                        raise ValueError(msg)\n            except FileNotFoundError as e:\n                msg = f\"Service account file not found: {e}\"\n                raise ValueError(msg) from e\n            except json.JSONDecodeError as e:\n                msg = \"Invalid JSON string for service account credentials\"\n                raise ValueError(msg) from e\n\n            # Then try to load credentials\n            try:\n                credentials = Credentials.from_service_account_file(self.service_account_json_file)\n            except Exception as e:\n                msg = f\"Error loading service account credentials: {e}\"\n                raise ValueError(msg) from e\n\n        except ValueError:\n            raise\n        except Exception as e:\n            msg = f\"Error executing BigQuery SQL query: {e}\"\n            raise ValueError(msg) from e\n\n        try:\n            client = bigquery.Client(credentials=credentials, project=project_id)\n\n            # Check for empty or whitespace-only query before cleaning\n            if not str(self.query).strip():\n                msg = \"No valid SQL query found in input text.\"\n                raise ValueError(msg)\n\n            # Always clean the query if it contains code block markers, quotes, or if clean_query is enabled\n            if \"```\" in str(self.query) or '\"' in str(self.query) or \"'\" in str(self.query) or self.clean_query:\n                sql_query = self._clean_sql_query(str(self.query))\n            else:\n                sql_query = str(self.query).strip()  # At minimum, strip whitespace\n\n            query_job = client.query(sql_query)\n            results = query_job.result()\n            output_dict = [dict(row) for row in results]\n\n        except RefreshError as e:\n            msg = \"Authentication error: Unable to refresh authentication token. Please try to reauthenticate.\"\n            raise ValueError(msg) from e\n        except Exception as e:\n            msg = f\"Error executing BigQuery SQL query: {e}\"\n            raise ValueError(msg) from e\n\n        return DataFrame(output_dict)\n"},"query":{"_input_type":"MessageTextInput","advanced":false,"display_name":"SQL Query","dynamic":false,"info":"The SQL query to execute on BigQuery.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"query","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"service_account_json_file":{"_input_type":"FileInput","advanced":false,"display_name":"Upload Service Account JSON","dynamic":false,"fileTypes":["json"],"file_path":"","info":"Upload the JSON file containing Google Cloud service account credentials.","list":false,"list_add_label":"Add More","name":"service_account_json_file","placeholder":"","required":true,"show":true,"temp_file":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"file","value":""}},"tool_mode":false},"GmailLoaderComponent":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Loads emails from Gmail using provided credentials.","display_name":"Gmail Loader","documentation":"","edited":false,"field_order":["json_string","label_ids","max_results"],"frozen":false,"icon":"Google","legacy":true,"metadata":{"code_hash":"b973c5a1987b","dependencies":{"dependencies":[{"name":"google","version":"0.8.5"},{"name":"googleapiclient","version":"2.154.0"},{"name":"langchain_core","version":"0.3.79"},{"name":"langchain_google_community","version":"2.0.3"},{"name":"lfx","version":null}],"total_dependencies":5},"module":"lfx.components.google.gmail.GmailLoaderComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"load_emails","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["composio.ComposioGmailAPIComponent"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import base64\nimport json\nimport re\nfrom collections.abc import Iterator\nfrom json.decoder import JSONDecodeError\nfrom typing import Any\n\nfrom google.auth.exceptions import RefreshError\nfrom google.oauth2.credentials import Credentials\nfrom googleapiclient.discovery import build\nfrom langchain_core.chat_sessions import ChatSession\nfrom langchain_core.messages import HumanMessage\nfrom langchain_google_community.gmail.loader import GMailLoader\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import MessageTextInput\nfrom lfx.io import SecretStrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.template.field.base import Output\n\n\nclass GmailLoaderComponent(Component):\n    display_name = \"Gmail Loader\"\n    description = \"Loads emails from Gmail using provided credentials.\"\n    icon = \"Google\"\n    legacy: bool = True\n    replacement = [\"composio.ComposioGmailAPIComponent\"]\n\n    inputs = [\n        SecretStrInput(\n            name=\"json_string\",\n            display_name=\"JSON String of the Service Account Token\",\n            info=\"JSON string containing OAuth 2.0 access token information for service account access\",\n            required=True,\n            value=\"\"\"{\n                \"account\": \"\",\n                \"client_id\": \"\",\n                \"client_secret\": \"\",\n                \"expiry\": \"\",\n                \"refresh_token\": \"\",\n                \"scopes\": [\n                    \"https://www.googleapis.com/auth/gmail.readonly\",\n                ],\n                \"token\": \"\",\n                \"token_uri\": \"https://oauth2.googleapis.com/token\",\n                \"universe_domain\": \"googleapis.com\"\n            }\"\"\",\n        ),\n        MessageTextInput(\n            name=\"label_ids\",\n            display_name=\"Label IDs\",\n            info=\"Comma-separated list of label IDs to filter emails.\",\n            required=True,\n            value=\"INBOX,SENT,UNREAD,IMPORTANT\",\n        ),\n        MessageTextInput(\n            name=\"max_results\",\n            display_name=\"Max Results\",\n            info=\"Maximum number of emails to load.\",\n            required=True,\n            value=\"10\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"load_emails\"),\n    ]\n\n    def load_emails(self) -> Data:\n        class CustomGMailLoader(GMailLoader):\n            def __init__(\n                self, creds: Any, *, n: int = 100, label_ids: list[str] | None = None, raise_error: bool = False\n            ) -> None:\n                super().__init__(creds, n, raise_error)\n                self.label_ids = label_ids if label_ids is not None else [\"SENT\"]\n\n            def clean_message_content(self, message):\n                # Remove URLs\n                message = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", message, flags=re.MULTILINE)\n\n                # Remove email addresses\n                message = re.sub(r\"\\S+@\\S+\", \"\", message)\n\n                # Remove special characters and excessive whitespace\n                message = re.sub(r\"[^A-Za-z0-9\\s]+\", \" \", message)\n                message = re.sub(r\"\\s{2,}\", \" \", message)\n\n                # Trim leading and trailing whitespace\n                return message.strip()\n\n            def _extract_email_content(self, msg: Any) -> HumanMessage:\n                from_email = None\n                for values in msg[\"payload\"][\"headers\"]:\n                    name = values[\"name\"]\n                    if name == \"From\":\n                        from_email = values[\"value\"]\n                if from_email is None:\n                    msg = \"From email not found.\"\n                    raise ValueError(msg)\n\n                parts = msg[\"payload\"][\"parts\"] if \"parts\" in msg[\"payload\"] else [msg[\"payload\"]]\n\n                for part in parts:\n                    if part[\"mimeType\"] == \"text/plain\":\n                        data = part[\"body\"][\"data\"]\n                        data = base64.urlsafe_b64decode(data).decode(\"utf-8\")\n                        pattern = re.compile(r\"\\r\\nOn .+(\\r\\n)*wrote:\\r\\n\")\n                        newest_response = re.split(pattern, data)[0]\n                        return HumanMessage(\n                            content=self.clean_message_content(newest_response),\n                            additional_kwargs={\"sender\": from_email},\n                        )\n                msg = \"No plain text part found in the email.\"\n                raise ValueError(msg)\n\n            def _get_message_data(self, service: Any, message: Any) -> ChatSession:\n                msg = service.users().messages().get(userId=\"me\", id=message[\"id\"]).execute()\n                message_content = self._extract_email_content(msg)\n\n                in_reply_to = None\n                email_data = msg[\"payload\"][\"headers\"]\n                for values in email_data:\n                    name = values[\"name\"]\n                    if name == \"In-Reply-To\":\n                        in_reply_to = values[\"value\"]\n\n                thread_id = msg[\"threadId\"]\n\n                if in_reply_to:\n                    thread = service.users().threads().get(userId=\"me\", id=thread_id).execute()\n                    messages = thread[\"messages\"]\n\n                    response_email = None\n                    for _message in messages:\n                        email_data = _message[\"payload\"][\"headers\"]\n                        for values in email_data:\n                            if values[\"name\"] == \"Message-ID\":\n                                message_id = values[\"value\"]\n                                if message_id == in_reply_to:\n                                    response_email = _message\n                    if response_email is None:\n                        msg = \"Response email not found in the thread.\"\n                        raise ValueError(msg)\n                    starter_content = self._extract_email_content(response_email)\n                    return ChatSession(messages=[starter_content, message_content])\n                return ChatSession(messages=[message_content])\n\n            def lazy_load(self) -> Iterator[ChatSession]:\n                service = build(\"gmail\", \"v1\", credentials=self.creds)\n                results = (\n                    service.users().messages().list(userId=\"me\", labelIds=self.label_ids, maxResults=self.n).execute()\n                )\n                messages = results.get(\"messages\", [])\n                if not messages:\n                    logger.warning(\"No messages found with the specified labels.\")\n                for message in messages:\n                    try:\n                        yield self._get_message_data(service, message)\n                    except Exception:\n                        if self.raise_error:\n                            raise\n                        else:\n                            logger.exception(f\"Error processing message {message['id']}\")\n\n        json_string = self.json_string\n        label_ids = self.label_ids.split(\",\") if self.label_ids else [\"INBOX\"]\n        max_results = int(self.max_results) if self.max_results else 100\n\n        # Load the token information from the JSON string\n        try:\n            token_info = json.loads(json_string)\n        except JSONDecodeError as e:\n            msg = \"Invalid JSON string\"\n            raise ValueError(msg) from e\n\n        creds = Credentials.from_authorized_user_info(token_info)\n\n        # Initialize the custom loader with the provided credentials\n        loader = CustomGMailLoader(creds=creds, n=max_results, label_ids=label_ids)\n\n        try:\n            docs = loader.load()\n        except RefreshError as e:\n            msg = \"Authentication error: Unable to refresh authentication token. Please try to reauthenticate.\"\n            raise ValueError(msg) from e\n        except Exception as e:\n            msg = f\"Error loading documents: {e}\"\n            raise ValueError(msg) from e\n\n        # Return the loaded documents\n        self.status = docs\n        return Data(data={\"text\": docs})\n"},"json_string":{"_input_type":"SecretStrInput","advanced":false,"display_name":"JSON String of the Service Account Token","dynamic":false,"info":"JSON string containing OAuth 2.0 access token information for service account access","input_types":[],"load_from_db":true,"name":"json_string","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"{\n                \"account\": \"\",\n                \"client_id\": \"\",\n                \"client_secret\": \"\",\n                \"expiry\": \"\",\n                \"refresh_token\": \"\",\n                \"scopes\": [\n                    \"https://www.googleapis.com/auth/gmail.readonly\",\n                ],\n                \"token\": \"\",\n                \"token_uri\": \"https://oauth2.googleapis.com/token\",\n                \"universe_domain\": \"googleapis.com\"\n            }"},"label_ids":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Label IDs","dynamic":false,"info":"Comma-separated list of label IDs to filter emails.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"label_ids","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"INBOX,SENT,UNREAD,IMPORTANT"},"max_results":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Max Results","dynamic":false,"info":"Maximum number of emails to load.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"max_results","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"10"}},"tool_mode":false},"Google Generative AI Embeddings":{"base_classes":["Embeddings"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Connect to Google's generative AI embeddings service using the GoogleGenerativeAIEmbeddings class, found in the langchain-google-genai package.","display_name":"Google Generative AI Embeddings","documentation":"https://python.langchain.com/v0.2/docs/integrations/text_embedding/google_generative_ai/","edited":false,"field_order":["api_key","model_name"],"frozen":false,"icon":"GoogleGenerativeAI","legacy":false,"metadata":{"code_hash":"7756ad70a221","dependencies":{"dependencies":[{"name":"google","version":"0.8.5"},{"name":"langchain_core","version":"0.3.79"},{"name":"langchain_google_genai","version":"2.0.6"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.google.google_generative_ai_embeddings.GoogleGenerativeAIEmbeddingsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Embeddings","group_outputs":false,"method":"build_embeddings","name":"embeddings","selected":"Embeddings","tool_mode":true,"types":["Embeddings"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Google Generative AI API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"# from lfx.field_typing import Data\n\n# TODO: remove ignore once the google package is published with types\nfrom google.ai.generativelanguage_v1beta.types import BatchEmbedContentsRequest\nfrom langchain_core.embeddings import Embeddings\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\nfrom langchain_google_genai._common import GoogleGenerativeAIError\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import MessageTextInput, Output, SecretStrInput\n\nMIN_DIMENSION_ERROR = \"Output dimensionality must be at least 1\"\nMAX_DIMENSION_ERROR = (\n    \"Output dimensionality cannot exceed 768. Google's embedding models only support dimensions up to 768.\"\n)\nMAX_DIMENSION = 768\nMIN_DIMENSION = 1\n\n\nclass GoogleGenerativeAIEmbeddingsComponent(Component):\n    display_name = \"Google Generative AI Embeddings\"\n    description = (\n        \"Connect to Google's generative AI embeddings service using the GoogleGenerativeAIEmbeddings class, \"\n        \"found in the langchain-google-genai package.\"\n    )\n    documentation: str = \"https://python.langchain.com/v0.2/docs/integrations/text_embedding/google_generative_ai/\"\n    icon = \"GoogleGenerativeAI\"\n    name = \"Google Generative AI Embeddings\"\n\n    inputs = [\n        SecretStrInput(name=\"api_key\", display_name=\"Google Generative AI API Key\", required=True),\n        MessageTextInput(name=\"model_name\", display_name=\"Model Name\", value=\"models/text-embedding-004\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        if not self.api_key:\n            msg = \"API Key is required\"\n            raise ValueError(msg)\n\n        class HotaGoogleGenerativeAIEmbeddings(GoogleGenerativeAIEmbeddings):\n            def __init__(self, *args, **kwargs) -> None:\n                super(GoogleGenerativeAIEmbeddings, self).__init__(*args, **kwargs)\n\n            def embed_documents(\n                self,\n                texts: list[str],\n                *,\n                batch_size: int = 100,\n                task_type: str | None = None,\n                titles: list[str] | None = None,\n                output_dimensionality: int | None = 768,\n            ) -> list[list[float]]:\n                \"\"\"Embed a list of strings.\n\n                Google Generative AI currently sets a max batch size of 100 strings.\n\n                Args:\n                    texts: List[str] The list of strings to embed.\n                    batch_size: [int] The batch size of embeddings to send to the model\n                    task_type: task_type (https://ai.google.dev/api/rest/v1/TaskType)\n                    titles: An optional list of titles for texts provided.\n                    Only applicable when TaskType is RETRIEVAL_DOCUMENT.\n                    output_dimensionality: Optional reduced dimension for the output embedding.\n                    https://ai.google.dev/api/rest/v1/models/batchEmbedContents#EmbedContentRequest\n                Returns:\n                    List of embeddings, one for each text.\n                \"\"\"\n                if output_dimensionality is not None and output_dimensionality < MIN_DIMENSION:\n                    raise ValueError(MIN_DIMENSION_ERROR)\n                if output_dimensionality is not None and output_dimensionality > MAX_DIMENSION:\n                    error_msg = MAX_DIMENSION_ERROR.format(output_dimensionality)\n                    raise ValueError(error_msg)\n\n                embeddings: list[list[float]] = []\n                batch_start_index = 0\n                for batch in GoogleGenerativeAIEmbeddings._prepare_batches(texts, batch_size):\n                    if titles:\n                        titles_batch = titles[batch_start_index : batch_start_index + len(batch)]\n                        batch_start_index += len(batch)\n                    else:\n                        titles_batch = [None] * len(batch)  # type: ignore[list-item]\n\n                    requests = [\n                        self._prepare_request(\n                            text=text,\n                            task_type=task_type,\n                            title=title,\n                            output_dimensionality=output_dimensionality,\n                        )\n                        for text, title in zip(batch, titles_batch, strict=True)\n                    ]\n\n                    try:\n                        result = self.client.batch_embed_contents(\n                            BatchEmbedContentsRequest(requests=requests, model=self.model)\n                        )\n                    except Exception as e:\n                        msg = f\"Error embedding content: {e}\"\n                        raise GoogleGenerativeAIError(msg) from e\n                    embeddings.extend([list(e.values) for e in result.embeddings])\n                return embeddings\n\n            def embed_query(\n                self,\n                text: str,\n                task_type: str | None = None,\n                title: str | None = None,\n                output_dimensionality: int | None = 768,\n            ) -> list[float]:\n                \"\"\"Embed a text.\n\n                Args:\n                    text: The text to embed.\n                    task_type: task_type (https://ai.google.dev/api/rest/v1/TaskType)\n                    title: An optional title for the text.\n                    Only applicable when TaskType is RETRIEVAL_DOCUMENT.\n                    output_dimensionality: Optional reduced dimension for the output embedding.\n                    https://ai.google.dev/api/rest/v1/models/batchEmbedContents#EmbedContentRequest\n\n                Returns:\n                    Embedding for the text.\n                \"\"\"\n                if output_dimensionality is not None and output_dimensionality < MIN_DIMENSION:\n                    raise ValueError(MIN_DIMENSION_ERROR)\n                if output_dimensionality is not None and output_dimensionality > MAX_DIMENSION:\n                    error_msg = MAX_DIMENSION_ERROR.format(output_dimensionality)\n                    raise ValueError(error_msg)\n\n                task_type = task_type or \"RETRIEVAL_QUERY\"\n                return self.embed_documents(\n                    [text],\n                    task_type=task_type,\n                    titles=[title] if title else None,\n                    output_dimensionality=output_dimensionality,\n                )[0]\n\n        return HotaGoogleGenerativeAIEmbeddings(model=self.model_name, google_api_key=self.api_key)\n"},"model_name":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Model Name","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"model_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"models/text-embedding-004"}},"tool_mode":false},"GoogleDriveComponent":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Loads documents from Google Drive using provided credentials.","display_name":"Google Drive Loader","documentation":"","edited":false,"field_order":["json_string","document_id"],"frozen":false,"icon":"Google","legacy":true,"metadata":{"code_hash":"1727f517e814","dependencies":{"dependencies":[{"name":"google","version":"0.8.5"},{"name":"langchain_google_community","version":"2.0.3"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.google.google_drive.GoogleDriveComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Loaded Documents","group_outputs":false,"method":"load_documents","name":"docs","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nfrom json.decoder import JSONDecodeError\n\nfrom google.auth.exceptions import RefreshError\nfrom google.oauth2.credentials import Credentials\nfrom langchain_google_community import GoogleDriveLoader\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.inputs.inputs import MessageTextInput\nfrom lfx.io import SecretStrInput\nfrom lfx.schema.data import Data\nfrom lfx.template.field.base import Output\n\n\nclass GoogleDriveComponent(Component):\n    display_name = \"Google Drive Loader\"\n    description = \"Loads documents from Google Drive using provided credentials.\"\n    icon = \"Google\"\n    legacy: bool = True\n\n    inputs = [\n        SecretStrInput(\n            name=\"json_string\",\n            display_name=\"JSON String of the Service Account Token\",\n            info=\"JSON string containing OAuth 2.0 access token information for service account access\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"document_id\", display_name=\"Document ID\", info=\"Single Google Drive document ID\", required=True\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Loaded Documents\", name=\"docs\", method=\"load_documents\"),\n    ]\n\n    def load_documents(self) -> Data:\n        class CustomGoogleDriveLoader(GoogleDriveLoader):\n            creds: Credentials | None = None\n            \"\"\"Credentials object to be passed directly.\"\"\"\n\n            def _load_credentials(self):\n                \"\"\"Load credentials from the provided creds attribute or fallback to the original method.\"\"\"\n                if self.creds:\n                    return self.creds\n                msg = \"No credentials provided.\"\n                raise ValueError(msg)\n\n            class Config:\n                arbitrary_types_allowed = True\n\n        json_string = self.json_string\n\n        document_ids = [self.document_id]\n        if len(document_ids) != 1:\n            msg = \"Expected a single document ID\"\n            raise ValueError(msg)\n\n        # TODO: Add validation to check if the document ID is valid\n\n        # Load the token information from the JSON string\n        try:\n            token_info = json.loads(json_string)\n        except JSONDecodeError as e:\n            msg = \"Invalid JSON string\"\n            raise ValueError(msg) from e\n\n        # Initialize the custom loader with the provided credentials and document IDs\n        loader = CustomGoogleDriveLoader(\n            creds=Credentials.from_authorized_user_info(token_info), document_ids=document_ids\n        )\n\n        # Load the documents\n        try:\n            docs = loader.load()\n        # catch google.auth.exceptions.RefreshError\n        except RefreshError as e:\n            msg = \"Authentication error: Unable to refresh authentication token. Please try to reauthenticate.\"\n            raise ValueError(msg) from e\n        except Exception as e:\n            msg = f\"Error loading documents: {e}\"\n            raise ValueError(msg) from e\n\n        if len(docs) != 1:\n            msg = \"Expected a single document to be loaded.\"\n            raise ValueError(msg)\n\n        data = docs_to_data(docs)\n        # Return the loaded documents\n        self.status = data\n        return Data(data={\"text\": data})\n"},"document_id":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Document ID","dynamic":false,"info":"Single Google Drive document ID","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"document_id","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"json_string":{"_input_type":"SecretStrInput","advanced":false,"display_name":"JSON String of the Service Account Token","dynamic":false,"info":"JSON string containing OAuth 2.0 access token information for service account access","input_types":[],"load_from_db":true,"name":"json_string","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""}},"tool_mode":false},"GoogleDriveSearchComponent":{"base_classes":["Data","Text"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Searches Google Drive files using provided credentials and query parameters.","display_name":"Google Drive Search","documentation":"","edited":false,"field_order":["token_string","query_item","valid_operator","search_term","query_string"],"frozen":false,"icon":"Google","legacy":true,"metadata":{"code_hash":"8f8dbdf04aaf","dependencies":{"dependencies":[{"name":"google","version":"0.8.5"},{"name":"googleapiclient","version":"2.154.0"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.google.google_drive_search.GoogleDriveSearchComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Document URLs","group_outputs":false,"method":"search_doc_urls","name":"doc_urls","selected":"Text","tool_mode":true,"types":["Text"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Document IDs","group_outputs":false,"method":"search_doc_ids","name":"doc_ids","selected":"Text","tool_mode":true,"types":["Text"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Document Titles","group_outputs":false,"method":"search_doc_titles","name":"doc_titles","selected":"Text","tool_mode":true,"types":["Text"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"search_data","name":"Data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\n\nfrom google.oauth2.credentials import Credentials\nfrom googleapiclient.discovery import build\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import DropdownInput, MessageTextInput\nfrom lfx.io import SecretStrInput\nfrom lfx.schema.data import Data\nfrom lfx.template.field.base import Output\n\n\nclass GoogleDriveSearchComponent(Component):\n    display_name = \"Google Drive Search\"\n    description = \"Searches Google Drive files using provided credentials and query parameters.\"\n    icon = \"Google\"\n    legacy: bool = True\n\n    inputs = [\n        SecretStrInput(\n            name=\"token_string\",\n            display_name=\"Token String\",\n            info=\"JSON string containing OAuth 2.0 access token information for service account access\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"query_item\",\n            display_name=\"Query Item\",\n            options=[\n                \"name\",\n                \"fullText\",\n                \"mimeType\",\n                \"modifiedTime\",\n                \"viewedByMeTime\",\n                \"trashed\",\n                \"starred\",\n                \"parents\",\n                \"owners\",\n                \"writers\",\n                \"readers\",\n                \"sharedWithMe\",\n                \"createdTime\",\n                \"properties\",\n                \"appProperties\",\n                \"visibility\",\n                \"shortcutDetails.targetId\",\n            ],\n            info=\"The field to query.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"valid_operator\",\n            display_name=\"Valid Operator\",\n            options=[\"contains\", \"=\", \"!=\", \"<=\", \"<\", \">\", \">=\", \"in\", \"has\"],\n            info=\"Operator to use in the query.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"search_term\",\n            display_name=\"Search Term\",\n            info=\"The value to search for in the specified query item.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"query_string\",\n            display_name=\"Query String\",\n            info=\"The query string used for searching. You can edit this manually.\",\n            value=\"\",  # This will be updated with the generated query string\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Document URLs\", name=\"doc_urls\", method=\"search_doc_urls\"),\n        Output(display_name=\"Document IDs\", name=\"doc_ids\", method=\"search_doc_ids\"),\n        Output(display_name=\"Document Titles\", name=\"doc_titles\", method=\"search_doc_titles\"),\n        Output(display_name=\"Data\", name=\"Data\", method=\"search_data\"),\n    ]\n\n    def generate_query_string(self) -> str:\n        query_item = self.query_item\n        valid_operator = self.valid_operator\n        search_term = self.search_term\n\n        # Construct the query string\n        query = f\"{query_item} {valid_operator} '{search_term}'\"\n\n        # Update the editable query string input with the generated query\n        self.query_string = query\n\n        return query\n\n    def on_inputs_changed(self) -> None:\n        # Automatically regenerate the query string when inputs change\n        self.generate_query_string()\n\n    def generate_file_url(self, file_id: str, mime_type: str) -> str:\n        \"\"\"Generates the appropriate Google Drive URL for a file based on its MIME type.\"\"\"\n        return {\n            \"application/vnd.google-apps.document\": f\"https://docs.google.com/document/d/{file_id}/edit\",\n            \"application/vnd.google-apps.spreadsheet\": f\"https://docs.google.com/spreadsheets/d/{file_id}/edit\",\n            \"application/vnd.google-apps.presentation\": f\"https://docs.google.com/presentation/d/{file_id}/edit\",\n            \"application/vnd.google-apps.drawing\": f\"https://docs.google.com/drawings/d/{file_id}/edit\",\n            \"application/pdf\": f\"https://drive.google.com/file/d/{file_id}/view?usp=drivesdk\",\n        }.get(mime_type, f\"https://drive.google.com/file/d/{file_id}/view?usp=drivesdk\")\n\n    def search_files(self) -> dict:\n        # Load the token information from the JSON string\n        token_info = json.loads(self.token_string)\n        creds = Credentials.from_authorized_user_info(token_info)\n\n        # Use the query string from the input (which might have been edited by the user)\n        query = self.query_string or self.generate_query_string()\n\n        # Initialize the Google Drive API service\n        service = build(\"drive\", \"v3\", credentials=creds)\n\n        # Perform the search\n        results = service.files().list(q=query, pageSize=5, fields=\"nextPageToken, files(id, name, mimeType)\").execute()\n        items = results.get(\"files\", [])\n\n        doc_urls = []\n        doc_ids = []\n        doc_titles_urls = []\n        doc_titles = []\n\n        if items:\n            for item in items:\n                # Directly use the file ID, title, and MIME type to generate the URL\n                file_id = item[\"id\"]\n                file_title = item[\"name\"]\n                mime_type = item[\"mimeType\"]\n                file_url = self.generate_file_url(file_id, mime_type)\n\n                # Store the URL, ID, and title+URL in their respective lists\n                doc_urls.append(file_url)\n                doc_ids.append(file_id)\n                doc_titles.append(file_title)\n                doc_titles_urls.append({\"title\": file_title, \"url\": file_url})\n\n        return {\"doc_urls\": doc_urls, \"doc_ids\": doc_ids, \"doc_titles_urls\": doc_titles_urls, \"doc_titles\": doc_titles}\n\n    def search_doc_ids(self) -> list[str]:\n        return self.search_files()[\"doc_ids\"]\n\n    def search_doc_urls(self) -> list[str]:\n        return self.search_files()[\"doc_urls\"]\n\n    def search_doc_titles(self) -> list[str]:\n        return self.search_files()[\"doc_titles\"]\n\n    def search_data(self) -> Data:\n        return Data(data={\"text\": self.search_files()[\"doc_titles_urls\"]})\n"},"query_item":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Query Item","dynamic":false,"external_options":{},"info":"The field to query.","name":"query_item","options":["name","fullText","mimeType","modifiedTime","viewedByMeTime","trashed","starred","parents","owners","writers","readers","sharedWithMe","createdTime","properties","appProperties","visibility","shortcutDetails.targetId"],"options_metadata":[],"placeholder":"","required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"query_string":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Query String","dynamic":false,"info":"The query string used for searching. You can edit this manually.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"query_string","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"search_term":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Search Term","dynamic":false,"info":"The value to search for in the specified query item.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_term","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"token_string":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token String","dynamic":false,"info":"JSON string containing OAuth 2.0 access token information for service account access","input_types":[],"load_from_db":true,"name":"token_string","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"valid_operator":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Valid Operator","dynamic":false,"external_options":{},"info":"Operator to use in the query.","name":"valid_operator","options":["contains","=","!=","<=","<",">",">=","in","has"],"options_metadata":[],"placeholder":"","required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"GoogleGenerativeAIModel":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate text using Google Generative AI.","display_name":"Google Generative AI","documentation":"","edited":false,"field_order":["input_value","system_message","stream","max_output_tokens","model_name","api_key","top_p","temperature","n","top_k","tool_model_enabled"],"frozen":false,"icon":"GoogleGenerativeAI","legacy":false,"metadata":{"code_hash":"ffb6e75b6684","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null},{"name":"google","version":"0.8.5"},{"name":"langchain_google_genai","version":"2.0.6"}],"total_dependencies":5},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.google.google_generative_ai.GoogleGenerativeAIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Google API Key","dynamic":false,"info":"The Google API Key to use for the Google Generative AI.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nimport requests\nfrom pydantic.v1 import SecretStr\n\nfrom lfx.base.models.google_generative_ai_constants import GOOGLE_GENERATIVE_AI_MODELS\nfrom lfx.base.models.google_generative_ai_model import ChatGoogleGenerativeAIFixed\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.inputs.inputs import BoolInput, DropdownInput, FloatInput, IntInput, SecretStrInput, SliderInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.dotdict import dotdict\n\n\nclass GoogleGenerativeAIComponent(LCModelComponent):\n    display_name = \"Google Generative AI\"\n    description = \"Generate text using Google Generative AI.\"\n    icon = \"GoogleGenerativeAI\"\n    name = \"GoogleGenerativeAIModel\"\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        IntInput(\n            name=\"max_output_tokens\", display_name=\"Max Output Tokens\", info=\"The maximum number of tokens to generate.\"\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model\",\n            info=\"The name of the model to use.\",\n            options=GOOGLE_GENERATIVE_AI_MODELS,\n            value=\"gemini-1.5-pro\",\n            refresh_button=True,\n            combobox=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Google API Key\",\n            info=\"The Google API Key to use for the Google Generative AI.\",\n            required=True,\n            real_time_refresh=True,\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"The maximum cumulative probability of tokens to consider when sampling.\",\n            advanced=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            info=\"Controls randomness. Lower values are more deterministic, higher values are more creative.\",\n        ),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. \"\n            \"Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            info=\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tool_model_enabled\",\n            display_name=\"Tool Model Enabled\",\n            info=\"Whether to use the tool model.\",\n            value=False,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        google_api_key = self.api_key\n        model = self.model_name\n        max_output_tokens = self.max_output_tokens\n        temperature = self.temperature\n        top_k = self.top_k\n        top_p = self.top_p\n        n = self.n\n\n        # Use modified ChatGoogleGenerativeAIFixed class for multiple function support\n        # TODO: Potentially remove when fixed upstream\n        return ChatGoogleGenerativeAIFixed(\n            model=model,\n            max_output_tokens=max_output_tokens or None,\n            temperature=temperature,\n            top_k=top_k or None,\n            top_p=top_p or None,\n            n=n or 1,\n            google_api_key=SecretStr(google_api_key).get_secret_value(),\n        )\n\n    def get_models(self, *, tool_model_enabled: bool | None = None) -> list[str]:\n        try:\n            import google.generativeai as genai\n\n            genai.configure(api_key=self.api_key)\n            model_ids = [\n                model.name.replace(\"models/\", \"\")\n                for model in genai.list_models()\n                if \"generateContent\" in model.supported_generation_methods\n            ]\n            model_ids.sort(reverse=True)\n        except (ImportError, ValueError) as e:\n            logger.exception(f\"Error getting model names: {e}\")\n            model_ids = GOOGLE_GENERATIVE_AI_MODELS\n        if tool_model_enabled:\n            try:\n                from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n            except ImportError as e:\n                msg = \"langchain_google_genai is not installed.\"\n                raise ImportError(msg) from e\n            for model in model_ids:\n                model_with_tool = ChatGoogleGenerativeAI(\n                    model=self.model_name,\n                    google_api_key=self.api_key,\n                )\n                if not self.supports_tool_calling(model_with_tool):\n                    model_ids.remove(model)\n        return model_ids\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name in {\"base_url\", \"model_name\", \"tool_model_enabled\", \"api_key\"} and field_value:\n            try:\n                if len(self.api_key) == 0:\n                    ids = GOOGLE_GENERATIVE_AI_MODELS\n                else:\n                    try:\n                        ids = self.get_models(tool_model_enabled=self.tool_model_enabled)\n                    except (ImportError, ValueError, requests.exceptions.RequestException) as e:\n                        logger.exception(f\"Error getting model names: {e}\")\n                        ids = GOOGLE_GENERATIVE_AI_MODELS\n                build_config.setdefault(\"model_name\", {})\n                build_config[\"model_name\"][\"options\"] = ids\n                build_config[\"model_name\"].setdefault(\"value\", ids[0])\n            except Exception as e:\n                msg = f\"Error getting model names: {e}\"\n                raise ValueError(msg) from e\n        return build_config\n"},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"max_output_tokens":{"_input_type":"IntInput","advanced":false,"display_name":"Max Output Tokens","dynamic":false,"info":"The maximum number of tokens to generate.","list":false,"list_add_label":"Add More","name":"max_output_tokens","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":true,"dialog_inputs":{},"display_name":"Model","dynamic":false,"external_options":{},"info":"The name of the model to use.","name":"model_name","options":["gemini-1.5-pro","gemini-1.5-flash","gemini-1.5-flash-8b","gemini-2.5-pro","gemini-2.5-flash","gemini-2.5-flash-lite","gemini-2.0-flash-lite","gemini-2.0-flash","gemini-exp-1206","gemini-2.0-flash-thinking-exp-01-21","learnlm-1.5-pro-experimental","gemma-2-2b","gemma-2-9b","gemma-2-27b"],"options_metadata":[],"placeholder":"","refresh_button":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"gemini-1.5-pro"},"n":{"_input_type":"IntInput","advanced":true,"display_name":"N","dynamic":false,"info":"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.","list":false,"list_add_label":"Add More","name":"n","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"SliderInput","advanced":false,"display_name":"Temperature","dynamic":false,"info":"Controls randomness. Lower values are more deterministic, higher values are more creative.","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"temperature","placeholder":"","range_spec":{"max":1.0,"min":0.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":0.1},"tool_model_enabled":{"_input_type":"BoolInput","advanced":false,"display_name":"Tool Model Enabled","dynamic":false,"info":"Whether to use the tool model.","list":false,"list_add_label":"Add More","name":"tool_model_enabled","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"top_k":{"_input_type":"IntInput","advanced":true,"display_name":"Top K","dynamic":false,"info":"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.","list":false,"list_add_label":"Add More","name":"top_k","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"top_p":{"_input_type":"FloatInput","advanced":true,"display_name":"Top P","dynamic":false,"info":"The maximum cumulative probability of tokens to consider when sampling.","list":false,"list_add_label":"Add More","name":"top_p","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":""}},"tool_mode":false},"GoogleOAuthToken":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generates a JSON string with your Google OAuth token.","display_name":"Google OAuth Token","documentation":"https://developers.google.com/identity/protocols/oauth2/web-server?hl=pt-br#python_1","edited":false,"field_order":["scopes","oauth_credentials"],"frozen":false,"icon":"Google","legacy":true,"metadata":{"code_hash":"151778572099","dependencies":{"dependencies":[{"name":"google","version":"0.8.5"},{"name":"google_auth_oauthlib","version":"1.2.2"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.google.google_oauth_token.GoogleOAuthToken"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Output","group_outputs":false,"method":"build_output","name":"output","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nimport re\nfrom pathlib import Path\n\nfrom google.auth.transport.requests import Request\nfrom google.oauth2.credentials import Credentials\nfrom google_auth_oauthlib.flow import InstalledAppFlow\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import FileInput, MultilineInput, Output\nfrom lfx.schema.data import Data\n\n\nclass GoogleOAuthToken(Component):\n    display_name = \"Google OAuth Token\"\n    description = \"Generates a JSON string with your Google OAuth token.\"\n    documentation: str = \"https://developers.google.com/identity/protocols/oauth2/web-server?hl=pt-br#python_1\"\n    icon = \"Google\"\n    name = \"GoogleOAuthToken\"\n    legacy: bool = True\n    inputs = [\n        MultilineInput(\n            name=\"scopes\",\n            display_name=\"Scopes\",\n            info=\"Input scopes for your application.\",\n            required=True,\n        ),\n        FileInput(\n            name=\"oauth_credentials\",\n            display_name=\"Credentials File\",\n            info=\"Input OAuth Credentials file (e.g. credentials.json).\",\n            file_types=[\"json\"],\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def validate_scopes(self, scopes):\n        pattern = (\n            r\"^(https://www\\.googleapis\\.com/auth/[\\w\\.\\-]+\"\n            r\"|mail\\.google\\.com/\"\n            r\"|www\\.google\\.com/calendar/feeds\"\n            r\"|www\\.google\\.com/m8/feeds)\"\n            r\"(,\\s*https://www\\.googleapis\\.com/auth/[\\w\\.\\-]+\"\n            r\"|mail\\.google\\.com/\"\n            r\"|www\\.google\\.com/calendar/feeds\"\n            r\"|www\\.google\\.com/m8/feeds)*$\"\n        )\n        if not re.match(pattern, scopes):\n            error_message = \"Invalid scope format.\"\n            raise ValueError(error_message)\n\n    def build_output(self) -> Data:\n        self.validate_scopes(self.scopes)\n\n        user_scopes = [scope.strip() for scope in self.scopes.split(\",\")]\n        if self.scopes:\n            scopes = user_scopes\n        else:\n            error_message = \"Incorrect scope, check the scopes field.\"\n            raise ValueError(error_message)\n\n        creds = None\n        token_path = Path(\"token.json\")\n\n        if token_path.exists():\n            creds = Credentials.from_authorized_user_file(str(token_path), scopes)\n\n        if not creds or not creds.valid:\n            if creds and creds.expired and creds.refresh_token:\n                creds.refresh(Request())\n            else:\n                if self.oauth_credentials:\n                    client_secret_file = self.oauth_credentials\n                else:\n                    error_message = \"OAuth 2.0 Credentials file not provided.\"\n                    raise ValueError(error_message)\n\n                flow = InstalledAppFlow.from_client_secrets_file(client_secret_file, scopes)\n                creds = flow.run_local_server(port=0)\n\n                token_path.write_text(creds.to_json(), encoding=\"utf-8\")\n\n        creds_json = json.loads(creds.to_json())\n\n        return Data(data=creds_json)\n"},"oauth_credentials":{"_input_type":"FileInput","advanced":false,"display_name":"Credentials File","dynamic":false,"fileTypes":["json"],"file_path":"","info":"Input OAuth Credentials file (e.g. credentials.json).","list":false,"list_add_label":"Add More","name":"oauth_credentials","placeholder":"","required":true,"show":true,"temp_file":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"file","value":""},"scopes":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Scopes","dynamic":false,"info":"Input scopes for your application.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"scopes","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"GoogleSearchAPICore":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Call Google Search API and return results as a DataFrame.","display_name":"Google Search API","documentation":"","edited":false,"field_order":["google_api_key","google_cse_id","input_value","k"],"frozen":false,"icon":"Google","legacy":false,"metadata":{"code_hash":"853c193aa41c","dependencies":{"dependencies":[{"name":"langchain_google_community","version":"2.0.3"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.google.google_search_api_core.GoogleSearchAPICore"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Results","group_outputs":false,"method":"search_google","name":"results","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_google_community import GoogleSearchAPIWrapper\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import IntInput, MultilineInput, Output, SecretStrInput\nfrom lfx.schema.dataframe import DataFrame\n\n\nclass GoogleSearchAPICore(Component):\n    display_name = \"Google Search API\"\n    description = \"Call Google Search API and return results as a DataFrame.\"\n    icon = \"Google\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"google_api_key\",\n            display_name=\"Google API Key\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"google_cse_id\",\n            display_name=\"Google CSE ID\",\n            required=True,\n        ),\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            tool_mode=True,\n        ),\n        IntInput(\n            name=\"k\",\n            display_name=\"Number of results\",\n            value=4,\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Results\",\n            name=\"results\",\n            type_=DataFrame,\n            method=\"search_google\",\n        ),\n    ]\n\n    def search_google(self) -> DataFrame:\n        \"\"\"Search Google using the provided query.\"\"\"\n        if not self.google_api_key:\n            return DataFrame([{\"error\": \"Invalid Google API Key\"}])\n\n        if not self.google_cse_id:\n            return DataFrame([{\"error\": \"Invalid Google CSE ID\"}])\n\n        try:\n            wrapper = GoogleSearchAPIWrapper(\n                google_api_key=self.google_api_key, google_cse_id=self.google_cse_id, k=self.k\n            )\n            results = wrapper.results(query=self.input_value, num_results=self.k)\n            return DataFrame(results)\n        except (ValueError, KeyError) as e:\n            return DataFrame([{\"error\": f\"Invalid configuration: {e!s}\"}])\n        except ConnectionError as e:\n            return DataFrame([{\"error\": f\"Connection error: {e!s}\"}])\n        except RuntimeError as e:\n            return DataFrame([{\"error\": f\"Error occurred while searching: {e!s}\"}])\n\n    def build(self):\n        return self.search_google\n"},"google_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Google API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"google_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"google_cse_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Google CSE ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"google_cse_id","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"input_value":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"k":{"_input_type":"IntInput","advanced":false,"display_name":"Number of results","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"k","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4}},"tool_mode":false},"GoogleSerperAPICore":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Call the Serper.dev Google Search API.","display_name":"Google Serper API","documentation":"","edited":false,"field_order":["serper_api_key","input_value","k"],"frozen":false,"icon":"Serper","legacy":false,"metadata":{"code_hash":"527183dcb201","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.google.google_serper_api_core.GoogleSerperAPICore"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Results","group_outputs":false,"method":"search_serper","name":"results","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_community.utilities.google_serper import GoogleSerperAPIWrapper\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import IntInput, MultilineInput, Output, SecretStrInput\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.message import Message\n\n\nclass GoogleSerperAPICore(Component):\n    display_name = \"Google Serper API\"\n    description = \"Call the Serper.dev Google Search API.\"\n    icon = \"Serper\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"serper_api_key\",\n            display_name=\"Serper API Key\",\n            required=True,\n        ),\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            tool_mode=True,\n        ),\n        IntInput(\n            name=\"k\",\n            display_name=\"Number of results\",\n            value=4,\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Results\",\n            name=\"results\",\n            type_=DataFrame,\n            method=\"search_serper\",\n        ),\n    ]\n\n    def search_serper(self) -> DataFrame:\n        try:\n            wrapper = self._build_wrapper()\n            results = wrapper.results(query=self.input_value)\n            list_results = results.get(\"organic\", [])\n\n            # Convert results to DataFrame using list comprehension\n            df_data = [\n                {\n                    \"title\": result.get(\"title\", \"\"),\n                    \"link\": result.get(\"link\", \"\"),\n                    \"snippet\": result.get(\"snippet\", \"\"),\n                }\n                for result in list_results\n            ]\n\n            return DataFrame(df_data)\n        except (ValueError, KeyError, ConnectionError) as e:\n            error_message = f\"Error occurred while searching: {e!s}\"\n            self.status = error_message\n            # Return DataFrame with error as a list of dictionaries\n            return DataFrame([{\"error\": error_message}])\n\n    def text_search_serper(self) -> Message:\n        search_results = self.search_serper()\n        text_result = search_results.to_string(index=False) if not search_results.empty else \"No results found.\"\n        return Message(text=text_result)\n\n    def _build_wrapper(self):\n        return GoogleSerperAPIWrapper(serper_api_key=self.serper_api_key, k=self.k)\n\n    def build(self):\n        return self.search_serper\n"},"input_value":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"k":{"_input_type":"IntInput","advanced":false,"display_name":"Number of results","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"k","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"serper_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Serper API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"serper_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""}},"tool_mode":false}}],["groq",{"GroqModel":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate text using Groq.","display_name":"Groq","documentation":"","edited":false,"field_order":["input_value","system_message","stream","api_key","base_url","max_tokens","temperature","n","model_name","tool_model_enabled"],"frozen":false,"icon":"Groq","legacy":false,"metadata":{"code_hash":"eeb2336a8717","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null},{"name":"langchain_groq","version":"0.2.1"}],"total_dependencies":4},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.groq.groq.GroqModel"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Groq API Key","dynamic":false,"info":"API key for the Groq API.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"type":"str","value":""},"base_url":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Groq API Base","dynamic":false,"info":"Base URL path for API requests, leave blank if not using a proxy or service emulator.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"https://api.groq.com"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import requests\nfrom pydantic.v1 import SecretStr\n\nfrom lfx.base.models.groq_constants import GROQ_MODELS, TOOL_CALLING_UNSUPPORTED_GROQ_MODELS, UNSUPPORTED_GROQ_MODELS\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.io import BoolInput, DropdownInput, IntInput, MessageTextInput, SecretStrInput, SliderInput\nfrom lfx.log.logger import logger\n\n\nclass GroqModel(LCModelComponent):\n    display_name: str = \"Groq\"\n    description: str = \"Generate text using Groq.\"\n    icon = \"Groq\"\n    name = \"GroqModel\"\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        SecretStrInput(\n            name=\"api_key\", display_name=\"Groq API Key\", info=\"API key for the Groq API.\", real_time_refresh=True\n        ),\n        MessageTextInput(\n            name=\"base_url\",\n            display_name=\"Groq API Base\",\n            info=\"Base URL path for API requests, leave blank if not using a proxy or service emulator.\",\n            advanced=True,\n            value=\"https://api.groq.com\",\n            real_time_refresh=True,\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Output Tokens\",\n            info=\"The maximum number of tokens to generate.\",\n            advanced=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            info=\"Run inference with this temperature. Must by in the closed interval [0.0, 1.0].\",\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. \"\n            \"Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model\",\n            info=\"The name of the model to use.\",\n            options=GROQ_MODELS,\n            value=GROQ_MODELS[0],\n            refresh_button=True,\n            combobox=True,\n        ),\n        BoolInput(\n            name=\"tool_model_enabled\",\n            display_name=\"Enable Tool Models\",\n            info=(\n                \"Select if you want to use models that can work with tools. If yes, only those models will be shown.\"\n            ),\n            advanced=False,\n            value=False,\n            real_time_refresh=True,\n        ),\n    ]\n\n    def get_models(self, *, tool_model_enabled: bool | None = None) -> list[str]:\n        try:\n            url = f\"{self.base_url}/openai/v1/models\"\n            headers = {\"Authorization\": f\"Bearer {self.api_key}\", \"Content-Type\": \"application/json\"}\n\n            response = requests.get(url, headers=headers, timeout=10)\n            response.raise_for_status()\n            model_list = response.json()\n            model_ids = [\n                model[\"id\"] for model in model_list.get(\"data\", []) if model[\"id\"] not in UNSUPPORTED_GROQ_MODELS\n            ]\n        except (ImportError, ValueError, requests.exceptions.RequestException) as e:\n            logger.exception(f\"Error getting model names: {e}\")\n            model_ids = GROQ_MODELS\n        if tool_model_enabled:\n            try:\n                from langchain_groq import ChatGroq\n            except ImportError as e:\n                msg = \"langchain_groq is not installed. Please install it with `pip install langchain_groq`.\"\n                raise ImportError(msg) from e\n            for model in model_ids:\n                model_with_tool = ChatGroq(\n                    model=model,\n                    api_key=self.api_key,\n                    base_url=self.base_url,\n                )\n                if not self.supports_tool_calling(model_with_tool) or model in TOOL_CALLING_UNSUPPORTED_GROQ_MODELS:\n                    model_ids.remove(model)\n            return model_ids\n        return model_ids\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\n        if field_name in {\"base_url\", \"model_name\", \"tool_model_enabled\", \"api_key\"} and field_value:\n            try:\n                if len(self.api_key) != 0:\n                    try:\n                        ids = self.get_models(tool_model_enabled=self.tool_model_enabled)\n                    except (ImportError, ValueError, requests.exceptions.RequestException) as e:\n                        logger.exception(f\"Error getting model names: {e}\")\n                        ids = GROQ_MODELS\n                    build_config.setdefault(\"model_name\", {})\n                    build_config[\"model_name\"][\"options\"] = ids\n                    build_config[\"model_name\"].setdefault(\"value\", ids[0])\n            except Exception as e:\n                msg = f\"Error getting model names: {e}\"\n                raise ValueError(msg) from e\n        return build_config\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_groq import ChatGroq\n        except ImportError as e:\n            msg = \"langchain-groq is not installed. Please install it with `pip install langchain-groq`.\"\n            raise ImportError(msg) from e\n\n        return ChatGroq(\n            model=self.model_name,\n            max_tokens=self.max_tokens or None,\n            temperature=self.temperature,\n            base_url=self.base_url,\n            n=self.n or 1,\n            api_key=SecretStr(self.api_key).get_secret_value(),\n            streaming=self.stream,\n        )\n"},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"max_tokens":{"_input_type":"IntInput","advanced":true,"display_name":"Max Output Tokens","dynamic":false,"info":"The maximum number of tokens to generate.","list":false,"list_add_label":"Add More","name":"max_tokens","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":true,"dialog_inputs":{},"display_name":"Model","dynamic":false,"external_options":{},"info":"The name of the model to use.","name":"model_name","options":["gemma2-9b-it","llama-3.3-70b-versatile","llama-3.1-8b-instant","llama-guard-3-8b","llama3-70b-8192","llama3-8b-8192","meta-llama/llama-4-scout-17b-16e-instruct","meta-llama/llama-4-maverick-17b-128e-instruct","qwen-qwq-32b","qwen-2.5-coder-32b","qwen-2.5-32b","deepseek-r1-distill-qwen-32b","deepseek-r1-distill-llama-70b","llama-3.3-70b-specdec","llama-3.2-1b-preview","llama-3.2-3b-preview","llama-3.2-11b-vision-preview","llama-3.2-90b-vision-preview","allam-2-7b"],"options_metadata":[],"placeholder":"","refresh_button":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"gemma2-9b-it"},"n":{"_input_type":"IntInput","advanced":true,"display_name":"N","dynamic":false,"info":"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.","list":false,"list_add_label":"Add More","name":"n","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"SliderInput","advanced":true,"display_name":"Temperature","dynamic":false,"info":"Run inference with this temperature. Must by in the closed interval [0.0, 1.0].","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"temperature","placeholder":"","range_spec":{"max":1.0,"min":0.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":0.1},"tool_model_enabled":{"_input_type":"BoolInput","advanced":false,"display_name":"Enable Tool Models","dynamic":false,"info":"Select if you want to use models that can work with tools. If yes, only those models will be shown.","list":false,"list_add_label":"Add More","name":"tool_model_enabled","placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false}}],["helpers",{"CalculatorComponent":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Perform basic arithmetic operations on a given expression.","display_name":"Calculator","documentation":"https://docs.langflow.org/components-helpers#calculator","edited":false,"field_order":["expression"],"frozen":false,"icon":"calculator","legacy":false,"metadata":{"code_hash":"5fcfa26be77d","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.helpers.calculator_core.CalculatorComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"evaluate_expression","name":"result","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import ast\nimport operator\nfrom collections.abc import Callable\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import MessageTextInput\nfrom lfx.io import Output\nfrom lfx.schema.data import Data\n\n\nclass CalculatorComponent(Component):\n    display_name = \"Calculator\"\n    description = \"Perform basic arithmetic operations on a given expression.\"\n    documentation: str = \"https://docs.langflow.org/components-helpers#calculator\"\n    icon = \"calculator\"\n\n    # Cache operators dictionary as a class variable\n    OPERATORS: dict[type[ast.operator], Callable] = {\n        ast.Add: operator.add,\n        ast.Sub: operator.sub,\n        ast.Mult: operator.mul,\n        ast.Div: operator.truediv,\n        ast.Pow: operator.pow,\n    }\n\n    inputs = [\n        MessageTextInput(\n            name=\"expression\",\n            display_name=\"Expression\",\n            info=\"The arithmetic expression to evaluate (e.g., '4*4*(33/22)+12-20').\",\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"result\", type_=Data, method=\"evaluate_expression\"),\n    ]\n\n    def _eval_expr(self, node: ast.AST) -> float:\n        \"\"\"Evaluate an AST node recursively.\"\"\"\n        if isinstance(node, ast.Constant):\n            if isinstance(node.value, int | float):\n                return float(node.value)\n            error_msg = f\"Unsupported constant type: {type(node.value).__name__}\"\n            raise TypeError(error_msg)\n        if isinstance(node, ast.Num):  # For backwards compatibility\n            if isinstance(node.n, int | float):\n                return float(node.n)\n            error_msg = f\"Unsupported number type: {type(node.n).__name__}\"\n            raise TypeError(error_msg)\n\n        if isinstance(node, ast.BinOp):\n            op_type = type(node.op)\n            if op_type not in self.OPERATORS:\n                error_msg = f\"Unsupported binary operator: {op_type.__name__}\"\n                raise TypeError(error_msg)\n\n            left = self._eval_expr(node.left)\n            right = self._eval_expr(node.right)\n            return self.OPERATORS[op_type](left, right)\n\n        error_msg = f\"Unsupported operation or expression type: {type(node).__name__}\"\n        raise TypeError(error_msg)\n\n    def evaluate_expression(self) -> Data:\n        \"\"\"Evaluate the mathematical expression and return the result.\"\"\"\n        try:\n            tree = ast.parse(self.expression, mode=\"eval\")\n            result = self._eval_expr(tree.body)\n\n            formatted_result = f\"{float(result):.6f}\".rstrip(\"0\").rstrip(\".\")\n            self.log(f\"Calculation result: {formatted_result}\")\n\n            self.status = formatted_result\n            return Data(data={\"result\": formatted_result})\n\n        except ZeroDivisionError:\n            error_message = \"Error: Division by zero\"\n            self.status = error_message\n            return Data(data={\"error\": error_message, \"input\": self.expression})\n\n        except (SyntaxError, TypeError, KeyError, ValueError, AttributeError, OverflowError) as e:\n            error_message = f\"Invalid expression: {e!s}\"\n            self.status = error_message\n            return Data(data={\"error\": error_message, \"input\": self.expression})\n\n    def build(self):\n        \"\"\"Return the main evaluation function.\"\"\"\n        return self.evaluate_expression\n"},"expression":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Expression","dynamic":false,"info":"The arithmetic expression to evaluate (e.g., '4*4*(33/22)+12-20').","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"expression","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"CreateList":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Creates a list of texts.","display_name":"Create List","documentation":"","edited":false,"field_order":["texts"],"frozen":false,"icon":"list","legacy":true,"metadata":{"code_hash":"9ec770d03310","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.helpers.create_list.CreateListComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data List","group_outputs":false,"method":"create_list","name":"list","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import StrInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.template.field.base import Output\n\n\nclass CreateListComponent(Component):\n    display_name = \"Create List\"\n    description = \"Creates a list of texts.\"\n    icon = \"list\"\n    name = \"CreateList\"\n    legacy = True\n\n    inputs = [\n        StrInput(\n            name=\"texts\",\n            display_name=\"Texts\",\n            info=\"Enter one or more texts.\",\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data List\", name=\"list\", method=\"create_list\"),\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"as_dataframe\"),\n    ]\n\n    def create_list(self) -> list[Data]:\n        data = [Data(text=text) for text in self.texts]\n        self.status = data\n        return data\n\n    def as_dataframe(self) -> DataFrame:\n        \"\"\"Convert the list of Data objects into a DataFrame.\n\n        Returns:\n            DataFrame: A DataFrame containing the list data.\n        \"\"\"\n        return DataFrame(self.create_list())\n"},"texts":{"_input_type":"StrInput","advanced":false,"display_name":"Texts","dynamic":false,"info":"Enter one or more texts.","list":true,"list_add_label":"Add More","load_from_db":false,"name":"texts","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"CurrentDate":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Returns the current date and time in the selected timezone.","display_name":"Current Date","documentation":"https://docs.langflow.org/components-helpers#current-date","edited":false,"field_order":["timezone"],"frozen":false,"icon":"clock","legacy":false,"metadata":{"code_hash":"8739f0b64a05","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.helpers.current_date.CurrentDateComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Current Date","group_outputs":false,"method":"get_current_date","name":"current_date","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from datetime import datetime\nfrom zoneinfo import ZoneInfo, available_timezones\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import DropdownInput, Output\nfrom lfx.log.logger import logger\nfrom lfx.schema.message import Message\n\n\nclass CurrentDateComponent(Component):\n    display_name = \"Current Date\"\n    description = \"Returns the current date and time in the selected timezone.\"\n    documentation: str = \"https://docs.langflow.org/components-helpers#current-date\"\n    icon = \"clock\"\n    name = \"CurrentDate\"\n\n    inputs = [\n        DropdownInput(\n            name=\"timezone\",\n            display_name=\"Timezone\",\n            options=sorted(tz for tz in available_timezones() if tz != \"localtime\"),\n            value=\"UTC\",\n            info=\"Select the timezone for the current date and time.\",\n            tool_mode=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Current Date\", name=\"current_date\", method=\"get_current_date\"),\n    ]\n\n    def get_current_date(self) -> Message:\n        try:\n            tz = ZoneInfo(self.timezone)\n            current_date = datetime.now(tz).strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n            result = f\"Current date and time in {self.timezone}: {current_date}\"\n            self.status = result\n            return Message(text=result)\n        except Exception as e:  # noqa: BLE001\n            logger.debug(\"Error getting current date\", exc_info=True)\n            error_message = f\"Error: {e}\"\n            self.status = error_message\n            return Message(text=error_message)\n"},"timezone":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Timezone","dynamic":false,"external_options":{},"info":"Select the timezone for the current date and time.","name":"timezone","options":["Africa/Abidjan","Africa/Accra","Africa/Addis_Ababa","Africa/Algiers","Africa/Asmara","Africa/Asmera","Africa/Bamako","Africa/Bangui","Africa/Banjul","Africa/Bissau","Africa/Blantyre","Africa/Brazzaville","Africa/Bujumbura","Africa/Cairo","Africa/Casablanca","Africa/Ceuta","Africa/Conakry","Africa/Dakar","Africa/Dar_es_Salaam","Africa/Djibouti","Africa/Douala","Africa/El_Aaiun","Africa/Freetown","Africa/Gaborone","Africa/Harare","Africa/Johannesburg","Africa/Juba","Africa/Kampala","Africa/Khartoum","Africa/Kigali","Africa/Kinshasa","Africa/Lagos","Africa/Libreville","Africa/Lome","Africa/Luanda","Africa/Lubumbashi","Africa/Lusaka","Africa/Malabo","Africa/Maputo","Africa/Maseru","Africa/Mbabane","Africa/Mogadishu","Africa/Monrovia","Africa/Nairobi","Africa/Ndjamena","Africa/Niamey","Africa/Nouakchott","Africa/Ouagadougou","Africa/Porto-Novo","Africa/Sao_Tome","Africa/Timbuktu","Africa/Tripoli","Africa/Tunis","Africa/Windhoek","America/Adak","America/Anchorage","America/Anguilla","America/Antigua","America/Araguaina","America/Argentina/Buenos_Aires","America/Argentina/Catamarca","America/Argentina/ComodRivadavia","America/Argentina/Cordoba","America/Argentina/Jujuy","America/Argentina/La_Rioja","America/Argentina/Mendoza","America/Argentina/Rio_Gallegos","America/Argentina/Salta","America/Argentina/San_Juan","America/Argentina/San_Luis","America/Argentina/Tucuman","America/Argentina/Ushuaia","America/Aruba","America/Asuncion","America/Atikokan","America/Atka","America/Bahia","America/Bahia_Banderas","America/Barbados","America/Belem","America/Belize","America/Blanc-Sablon","America/Boa_Vista","America/Bogota","America/Boise","America/Buenos_Aires","America/Cambridge_Bay","America/Campo_Grande","America/Cancun","America/Caracas","America/Catamarca","America/Cayenne","America/Cayman","America/Chicago","America/Chihuahua","America/Ciudad_Juarez","America/Coral_Harbour","America/Cordoba","America/Costa_Rica","America/Coyhaique","America/Creston","America/Cuiaba","America/Curacao","America/Danmarkshavn","America/Dawson","America/Dawson_Creek","America/Denver","America/Detroit","America/Dominica","America/Edmonton","America/Eirunepe","America/El_Salvador","America/Ensenada","America/Fort_Nelson","America/Fort_Wayne","America/Fortaleza","America/Glace_Bay","America/Godthab","America/Goose_Bay","America/Grand_Turk","America/Grenada","America/Guadeloupe","America/Guatemala","America/Guayaquil","America/Guyana","America/Halifax","America/Havana","America/Hermosillo","America/Indiana/Indianapolis","America/Indiana/Knox","America/Indiana/Marengo","America/Indiana/Petersburg","America/Indiana/Tell_City","America/Indiana/Vevay","America/Indiana/Vincennes","America/Indiana/Winamac","America/Indianapolis","America/Inuvik","America/Iqaluit","America/Jamaica","America/Jujuy","America/Juneau","America/Kentucky/Louisville","America/Kentucky/Monticello","America/Knox_IN","America/Kralendijk","America/La_Paz","America/Lima","America/Los_Angeles","America/Louisville","America/Lower_Princes","America/Maceio","America/Managua","America/Manaus","America/Marigot","America/Martinique","America/Matamoros","America/Mazatlan","America/Mendoza","America/Menominee","America/Merida","America/Metlakatla","America/Mexico_City","America/Miquelon","America/Moncton","America/Monterrey","America/Montevideo","America/Montreal","America/Montserrat","America/Nassau","America/New_York","America/Nipigon","America/Nome","America/Noronha","America/North_Dakota/Beulah","America/North_Dakota/Center","America/North_Dakota/New_Salem","America/Nuuk","America/Ojinaga","America/Panama","America/Pangnirtung","America/Paramaribo","America/Phoenix","America/Port-au-Prince","America/Port_of_Spain","America/Porto_Acre","America/Porto_Velho","America/Puerto_Rico","America/Punta_Arenas","America/Rainy_River","America/Rankin_Inlet","America/Recife","America/Regina","America/Resolute","America/Rio_Branco","America/Rosario","America/Santa_Isabel","America/Santarem","America/Santiago","America/Santo_Domingo","America/Sao_Paulo","America/Scoresbysund","America/Shiprock","America/Sitka","America/St_Barthelemy","America/St_Johns","America/St_Kitts","America/St_Lucia","America/St_Thomas","America/St_Vincent","America/Swift_Current","America/Tegucigalpa","America/Thule","America/Thunder_Bay","America/Tijuana","America/Toronto","America/Tortola","America/Vancouver","America/Virgin","America/Whitehorse","America/Winnipeg","America/Yakutat","America/Yellowknife","Antarctica/Casey","Antarctica/Davis","Antarctica/DumontDUrville","Antarctica/Macquarie","Antarctica/Mawson","Antarctica/McMurdo","Antarctica/Palmer","Antarctica/Rothera","Antarctica/South_Pole","Antarctica/Syowa","Antarctica/Troll","Antarctica/Vostok","Arctic/Longyearbyen","Asia/Aden","Asia/Almaty","Asia/Amman","Asia/Anadyr","Asia/Aqtau","Asia/Aqtobe","Asia/Ashgabat","Asia/Ashkhabad","Asia/Atyrau","Asia/Baghdad","Asia/Bahrain","Asia/Baku","Asia/Bangkok","Asia/Barnaul","Asia/Beirut","Asia/Bishkek","Asia/Brunei","Asia/Calcutta","Asia/Chita","Asia/Choibalsan","Asia/Chongqing","Asia/Chungking","Asia/Colombo","Asia/Dacca","Asia/Damascus","Asia/Dhaka","Asia/Dili","Asia/Dubai","Asia/Dushanbe","Asia/Famagusta","Asia/Gaza","Asia/Harbin","Asia/Hebron","Asia/Ho_Chi_Minh","Asia/Hong_Kong","Asia/Hovd","Asia/Irkutsk","Asia/Istanbul","Asia/Jakarta","Asia/Jayapura","Asia/Jerusalem","Asia/Kabul","Asia/Kamchatka","Asia/Karachi","Asia/Kashgar","Asia/Kathmandu","Asia/Katmandu","Asia/Khandyga","Asia/Kolkata","Asia/Krasnoyarsk","Asia/Kuala_Lumpur","Asia/Kuching","Asia/Kuwait","Asia/Macao","Asia/Macau","Asia/Magadan","Asia/Makassar","Asia/Manila","Asia/Muscat","Asia/Nicosia","Asia/Novokuznetsk","Asia/Novosibirsk","Asia/Omsk","Asia/Oral","Asia/Phnom_Penh","Asia/Pontianak","Asia/Pyongyang","Asia/Qatar","Asia/Qostanay","Asia/Qyzylorda","Asia/Rangoon","Asia/Riyadh","Asia/Saigon","Asia/Sakhalin","Asia/Samarkand","Asia/Seoul","Asia/Shanghai","Asia/Singapore","Asia/Srednekolymsk","Asia/Taipei","Asia/Tashkent","Asia/Tbilisi","Asia/Tehran","Asia/Tel_Aviv","Asia/Thimbu","Asia/Thimphu","Asia/Tokyo","Asia/Tomsk","Asia/Ujung_Pandang","Asia/Ulaanbaatar","Asia/Ulan_Bator","Asia/Urumqi","Asia/Ust-Nera","Asia/Vientiane","Asia/Vladivostok","Asia/Yakutsk","Asia/Yangon","Asia/Yekaterinburg","Asia/Yerevan","Atlantic/Azores","Atlantic/Bermuda","Atlantic/Canary","Atlantic/Cape_Verde","Atlantic/Faeroe","Atlantic/Faroe","Atlantic/Jan_Mayen","Atlantic/Madeira","Atlantic/Reykjavik","Atlantic/South_Georgia","Atlantic/St_Helena","Atlantic/Stanley","Australia/ACT","Australia/Adelaide","Australia/Brisbane","Australia/Broken_Hill","Australia/Canberra","Australia/Currie","Australia/Darwin","Australia/Eucla","Australia/Hobart","Australia/LHI","Australia/Lindeman","Australia/Lord_Howe","Australia/Melbourne","Australia/NSW","Australia/North","Australia/Perth","Australia/Queensland","Australia/South","Australia/Sydney","Australia/Tasmania","Australia/Victoria","Australia/West","Australia/Yancowinna","Brazil/Acre","Brazil/DeNoronha","Brazil/East","Brazil/West","CET","CST6CDT","Canada/Atlantic","Canada/Central","Canada/Eastern","Canada/Mountain","Canada/Newfoundland","Canada/Pacific","Canada/Saskatchewan","Canada/Yukon","Chile/Continental","Chile/EasterIsland","Cuba","EET","EST","EST5EDT","Egypt","Eire","Etc/GMT","Etc/GMT+0","Etc/GMT+1","Etc/GMT+10","Etc/GMT+11","Etc/GMT+12","Etc/GMT+2","Etc/GMT+3","Etc/GMT+4","Etc/GMT+5","Etc/GMT+6","Etc/GMT+7","Etc/GMT+8","Etc/GMT+9","Etc/GMT-0","Etc/GMT-1","Etc/GMT-10","Etc/GMT-11","Etc/GMT-12","Etc/GMT-13","Etc/GMT-14","Etc/GMT-2","Etc/GMT-3","Etc/GMT-4","Etc/GMT-5","Etc/GMT-6","Etc/GMT-7","Etc/GMT-8","Etc/GMT-9","Etc/GMT0","Etc/Greenwich","Etc/UCT","Etc/UTC","Etc/Universal","Etc/Zulu","Europe/Amsterdam","Europe/Andorra","Europe/Astrakhan","Europe/Athens","Europe/Belfast","Europe/Belgrade","Europe/Berlin","Europe/Bratislava","Europe/Brussels","Europe/Bucharest","Europe/Budapest","Europe/Busingen","Europe/Chisinau","Europe/Copenhagen","Europe/Dublin","Europe/Gibraltar","Europe/Guernsey","Europe/Helsinki","Europe/Isle_of_Man","Europe/Istanbul","Europe/Jersey","Europe/Kaliningrad","Europe/Kiev","Europe/Kirov","Europe/Kyiv","Europe/Lisbon","Europe/Ljubljana","Europe/London","Europe/Luxembourg","Europe/Madrid","Europe/Malta","Europe/Mariehamn","Europe/Minsk","Europe/Monaco","Europe/Moscow","Europe/Nicosia","Europe/Oslo","Europe/Paris","Europe/Podgorica","Europe/Prague","Europe/Riga","Europe/Rome","Europe/Samara","Europe/San_Marino","Europe/Sarajevo","Europe/Saratov","Europe/Simferopol","Europe/Skopje","Europe/Sofia","Europe/Stockholm","Europe/Tallinn","Europe/Tirane","Europe/Tiraspol","Europe/Ulyanovsk","Europe/Uzhgorod","Europe/Vaduz","Europe/Vatican","Europe/Vienna","Europe/Vilnius","Europe/Volgograd","Europe/Warsaw","Europe/Zagreb","Europe/Zaporozhye","Europe/Zurich","Factory","GB","GB-Eire","GMT","GMT+0","GMT-0","GMT0","Greenwich","HST","Hongkong","Iceland","Indian/Antananarivo","Indian/Chagos","Indian/Christmas","Indian/Cocos","Indian/Comoro","Indian/Kerguelen","Indian/Mahe","Indian/Maldives","Indian/Mauritius","Indian/Mayotte","Indian/Reunion","Iran","Israel","Jamaica","Japan","Kwajalein","Libya","MET","MST","MST7MDT","Mexico/BajaNorte","Mexico/BajaSur","Mexico/General","NZ","NZ-CHAT","Navajo","PRC","PST8PDT","Pacific/Apia","Pacific/Auckland","Pacific/Bougainville","Pacific/Chatham","Pacific/Chuuk","Pacific/Easter","Pacific/Efate","Pacific/Enderbury","Pacific/Fakaofo","Pacific/Fiji","Pacific/Funafuti","Pacific/Galapagos","Pacific/Gambier","Pacific/Guadalcanal","Pacific/Guam","Pacific/Honolulu","Pacific/Johnston","Pacific/Kanton","Pacific/Kiritimati","Pacific/Kosrae","Pacific/Kwajalein","Pacific/Majuro","Pacific/Marquesas","Pacific/Midway","Pacific/Nauru","Pacific/Niue","Pacific/Norfolk","Pacific/Noumea","Pacific/Pago_Pago","Pacific/Palau","Pacific/Pitcairn","Pacific/Pohnpei","Pacific/Ponape","Pacific/Port_Moresby","Pacific/Rarotonga","Pacific/Saipan","Pacific/Samoa","Pacific/Tahiti","Pacific/Tarawa","Pacific/Tongatapu","Pacific/Truk","Pacific/Wake","Pacific/Wallis","Pacific/Yap","Poland","Portugal","ROC","ROK","Singapore","Turkey","UCT","US/Alaska","US/Aleutian","US/Arizona","US/Central","US/East-Indiana","US/Eastern","US/Hawaii","US/Indiana-Starke","US/Michigan","US/Mountain","US/Pacific","US/Samoa","UTC","Universal","W-SU","WET","Zulu"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":true,"trace_as_metadata":true,"type":"str","value":"UTC"}},"tool_mode":false},"IDGenerator":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generates a unique ID.","display_name":"ID Generator","documentation":"","edited":false,"field_order":["unique_id"],"frozen":false,"icon":"fingerprint","legacy":true,"metadata":{"code_hash":"cddb8b4edbc3","dependencies":{"dependencies":[{"name":"typing_extensions","version":"4.15.0"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.helpers.id_generator.IDGeneratorComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"ID","group_outputs":false,"method":"generate_id","name":"id","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import uuid\nfrom typing import Any\n\nfrom typing_extensions import override\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import MessageTextInput, Output\nfrom lfx.schema.dotdict import dotdict\nfrom lfx.schema.message import Message\n\n\nclass IDGeneratorComponent(Component):\n    display_name = \"ID Generator\"\n    description = \"Generates a unique ID.\"\n    icon = \"fingerprint\"\n    name = \"IDGenerator\"\n    legacy = True\n\n    inputs = [\n        MessageTextInput(\n            name=\"unique_id\",\n            display_name=\"Value\",\n            info=\"The generated unique ID.\",\n            refresh_button=True,\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"ID\", name=\"id\", method=\"generate_id\"),\n    ]\n\n    @override\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"unique_id\":\n            build_config[field_name][\"value\"] = str(uuid.uuid4())\n        return build_config\n\n    def generate_id(self) -> Message:\n        unique_id = self.unique_id or str(uuid.uuid4())\n        self.status = f\"Generated ID: {unique_id}\"\n        return Message(text=unique_id)\n"},"unique_id":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Value","dynamic":false,"info":"The generated unique ID.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"unique_id","placeholder":"","refresh_button":true,"required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"Memory":{"base_classes":["DataFrame","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Stores or retrieves stored chat messages from Langflow tables or an external memory.","display_name":"Message History","documentation":"https://docs.langflow.org/components-helpers#message-history","edited":false,"field_order":["mode","message","memory","sender_type","sender","sender_name","n_messages","session_id","context_id","order","template"],"frozen":false,"icon":"message-square-more","legacy":false,"metadata":{"code_hash":"227e053b4704","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.helpers.memory.MemoryComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Message","group_outputs":false,"method":"retrieve_messages_as_text","name":"messages_text","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Dataframe","group_outputs":false,"method":"retrieve_messages_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any, cast\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.helpers.data import data_to_text\nfrom lfx.inputs.inputs import DropdownInput, HandleInput, IntInput, MessageTextInput, MultilineInput, TabInput\nfrom lfx.memory import aget_messages, astore_message\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.dotdict import dotdict\nfrom lfx.schema.message import Message\nfrom lfx.template.field.base import Output\nfrom lfx.utils.component_utils import set_current_fields, set_field_display\nfrom lfx.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Message History\"\n    description = \"Stores or retrieves stored chat messages from Langflow tables or an external memory.\"\n    documentation: str = \"https://docs.langflow.org/components-helpers#message-history\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n    default_keys = [\"mode\", \"memory\", \"session_id\", \"context_id\"]\n    mode_config = {\n        \"Store\": [\"message\", \"memory\", \"sender\", \"sender_name\", \"session_id\", \"context_id\"],\n        \"Retrieve\": [\"n_messages\", \"order\", \"template\", \"memory\", \"session_id\", \"context_id\"],\n    }\n\n    inputs = [\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Retrieve\", \"Store\"],\n            value=\"Retrieve\",\n            info=\"Operation mode: Store messages or Retrieve messages.\",\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The chat message to be stored.\",\n            tool_mode=True,\n            dynamic=True,\n            show=False,\n        ),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"Memory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender_type\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender\",\n            display_name=\"Sender\",\n            info=\"The sender of the message. Might be Machine or User. \"\n            \"If empty, the current sender parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n            show=False,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n            show=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            value=\"\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"context_id\",\n            display_name=\"Context ID\",\n            info=\"The context ID of the chat. Adds an extra layer to the local memory.\",\n            value=\"\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n            tool_mode=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n            show=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Message\", name=\"messages_text\", method=\"retrieve_messages_as_text\", dynamic=True),\n        Output(display_name=\"Dataframe\", name=\"dataframe\", method=\"retrieve_messages_dataframe\", dynamic=True),\n    ]\n\n    def update_outputs(self, frontend_node: dict, field_name: str, field_value: Any) -> dict:\n        \"\"\"Dynamically show only the relevant output based on the selected output type.\"\"\"\n        if field_name == \"mode\":\n            # Start with empty outputs\n            frontend_node[\"outputs\"] = []\n            if field_value == \"Store\":\n                frontend_node[\"outputs\"] = [\n                    Output(\n                        display_name=\"Stored Messages\",\n                        name=\"stored_messages\",\n                        method=\"store_message\",\n                        hidden=True,\n                        dynamic=True,\n                    )\n                ]\n            if field_value == \"Retrieve\":\n                frontend_node[\"outputs\"] = [\n                    Output(\n                        display_name=\"Messages\", name=\"messages_text\", method=\"retrieve_messages_as_text\", dynamic=True\n                    ),\n                    Output(\n                        display_name=\"Dataframe\", name=\"dataframe\", method=\"retrieve_messages_dataframe\", dynamic=True\n                    ),\n                ]\n        return frontend_node\n\n    async def store_message(self) -> Message:\n        message = Message(text=self.message) if isinstance(self.message, str) else self.message\n\n        message.context_id = self.context_id or message.context_id\n        message.session_id = self.session_id or message.session_id\n        message.sender = self.sender or message.sender or MESSAGE_SENDER_AI\n        message.sender_name = self.sender_name or message.sender_name or MESSAGE_SENDER_NAME_AI\n\n        stored_messages: list[Message] = []\n\n        if self.memory:\n            self.memory.context_id = message.context_id\n            self.memory.session_id = message.session_id\n            lc_message = message.to_lc_message()\n            await self.memory.aadd_messages([lc_message])\n\n            stored_messages = await self.memory.aget_messages() or []\n\n            stored_messages = [Message.from_lc_message(m) for m in stored_messages] if stored_messages else []\n\n            if message.sender:\n                stored_messages = [m for m in stored_messages if m.sender == message.sender]\n        else:\n            await astore_message(message, flow_id=self.graph.flow_id)\n            stored_messages = (\n                await aget_messages(\n                    session_id=message.session_id,\n                    context_id=message.context_id,\n                    sender_name=message.sender_name,\n                    sender=message.sender,\n                )\n                or []\n            )\n\n        if not stored_messages:\n            msg = \"No messages were stored. Please ensure that the session ID and sender are properly set.\"\n            raise ValueError(msg)\n\n        stored_message = stored_messages[0]\n        self.status = stored_message\n        return stored_message\n\n    async def retrieve_messages(self) -> Data:\n        sender_type = self.sender_type\n        sender_name = self.sender_name\n        session_id = self.session_id\n        context_id = self.context_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender_type == \"Machine and User\":\n            sender_type = None\n\n        if self.memory and not hasattr(self.memory, \"aget_messages\"):\n            memory_name = type(self.memory).__name__\n            err_msg = f\"External Memory object ({memory_name}) must have 'aget_messages' method.\"\n            raise AttributeError(err_msg)\n        # Check if n_messages is None or 0\n        if n_messages == 0:\n            stored = []\n        elif self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n            self.memory.context_id = context_id\n\n            stored = await self.memory.aget_messages()\n            # langchain memories are supposed to return messages in ascending order\n\n            if n_messages:\n                stored = stored[-n_messages:]  # Get last N messages first\n\n            if order == \"DESC\":\n                stored = stored[::-1]  # Then reverse if needed\n\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender_type:\n                expected_type = MESSAGE_SENDER_AI if sender_type == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            # For internal memory, we always fetch the last N messages by ordering by DESC\n            stored = await aget_messages(\n                sender=sender_type,\n                sender_name=sender_name,\n                session_id=session_id,\n                context_id=context_id,\n                limit=10000,\n                order=order,\n            )\n            if n_messages:\n                stored = stored[-n_messages:]  # Get last N messages\n\n        # self.status = stored\n        return cast(\"Data\", stored)\n\n    async def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, await self.retrieve_messages())\n        # self.status = stored_text\n        return Message(text=stored_text)\n\n    async def retrieve_messages_dataframe(self) -> DataFrame:\n        \"\"\"Convert the retrieved messages into a DataFrame.\n\n        Returns:\n            DataFrame: A DataFrame containing the message data.\n        \"\"\"\n        messages = await self.retrieve_messages()\n        return DataFrame(messages)\n\n    def update_build_config(\n        self,\n        build_config: dotdict,\n        field_value: Any,  # noqa: ARG002\n        field_name: str | None = None,  # noqa: ARG002\n    ) -> dotdict:\n        return set_current_fields(\n            build_config=build_config,\n            action_fields=self.mode_config,\n            selected_action=build_config[\"mode\"][\"value\"],\n            default_fields=self.default_keys,\n            func=set_field_display,\n        )\n"},"context_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Context ID","dynamic":false,"info":"The context ID of the chat. Adds an extra layer to the local memory.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"context_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"memory":{"_input_type":"HandleInput","advanced":true,"display_name":"External Memory","dynamic":false,"info":"Retrieve messages from an external memory. If empty, it will use the Langflow tables.","input_types":["Memory"],"list":false,"list_add_label":"Add More","name":"memory","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"message":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Message","dynamic":true,"info":"The chat message to be stored.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"message","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"mode":{"_input_type":"TabInput","advanced":false,"display_name":"Mode","dynamic":false,"info":"Operation mode: Store messages or Retrieve messages.","name":"mode","options":["Retrieve","Store"],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"tab","value":"Retrieve"},"n_messages":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Messages","dynamic":false,"info":"Number of messages to retrieve.","list":false,"list_add_label":"Add More","name":"n_messages","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":100},"order":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Order","dynamic":false,"external_options":{},"info":"Order of the messages.","name":"order","options":["Ascending","Descending"],"options_metadata":[],"placeholder":"","required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":true,"trace_as_metadata":true,"type":"str","value":"Ascending"},"sender":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Sender","dynamic":false,"info":"The sender of the message. Might be Machine or User. If empty, the current sender parameter will be used.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"sender","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"sender_name":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Sender Name","dynamic":false,"info":"Filter by sender name.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"sender_name","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"sender_type":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Sender Type","dynamic":false,"external_options":{},"info":"Filter by sender type.","name":"sender_type","options":["Machine","User","Machine and User"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Machine and User"},"session_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Session ID","dynamic":false,"info":"The session ID of the chat. If empty, the current session ID parameter will be used.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"session_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"template":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"Template","dynamic":false,"info":"The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"template","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"{sender_name}: {text}"}},"tool_mode":false},"OutputParser":{"base_classes":["Message","OutputParser"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Transforms the output of an LLM into a specified format.","display_name":"Output Parser","documentation":"","edited":false,"field_order":["parser_type"],"frozen":false,"icon":"type","legacy":true,"metadata":{"code_hash":"9beb62a3e8fb","dependencies":{"dependencies":[{"name":"langchain_core","version":"0.3.79"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.helpers.output_parser.OutputParserComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Format Instructions","group_outputs":false,"method":"format_instructions","name":"format_instructions","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Output Parser","group_outputs":false,"method":"build_parser","name":"output_parser","selected":"OutputParser","tool_mode":true,"types":["OutputParser"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["processing.StructuredOutput","processing.ParserComponent"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_core.output_parsers import CommaSeparatedListOutputParser\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.field_typing.constants import OutputParser\nfrom lfx.io import DropdownInput, Output\nfrom lfx.schema.message import Message\n\n\nclass OutputParserComponent(Component):\n    display_name = \"Output Parser\"\n    description = \"Transforms the output of an LLM into a specified format.\"\n    icon = \"type\"\n    name = \"OutputParser\"\n    legacy = True\n    replacement = [\"processing.StructuredOutput\", \"processing.ParserComponent\"]\n\n    inputs = [\n        DropdownInput(\n            name=\"parser_type\",\n            display_name=\"Parser\",\n            options=[\"CSV\"],\n            value=\"CSV\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Format Instructions\",\n            name=\"format_instructions\",\n            info=\"Pass to a prompt template to include formatting instructions for LLM responses.\",\n            method=\"format_instructions\",\n        ),\n        Output(display_name=\"Output Parser\", name=\"output_parser\", method=\"build_parser\"),\n    ]\n\n    def build_parser(self) -> OutputParser:\n        if self.parser_type == \"CSV\":\n            return CommaSeparatedListOutputParser()\n        msg = \"Unsupported or missing parser\"\n        raise ValueError(msg)\n\n    def format_instructions(self) -> Message:\n        if self.parser_type == \"CSV\":\n            return Message(text=CommaSeparatedListOutputParser().get_format_instructions())\n        msg = \"Unsupported or missing parser\"\n        raise ValueError(msg)\n"},"parser_type":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Parser","dynamic":false,"external_options":{},"info":"","name":"parser_type","options":["CSV"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"CSV"}},"tool_mode":false},"StoreMessage":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Stores a chat message or text into Langflow tables or an external memory.","display_name":"Message Store","documentation":"","edited":false,"field_order":["message","memory","sender","sender_name","session_id"],"frozen":false,"icon":"message-square-text","legacy":true,"metadata":{"code_hash":"9ad1aa08b597","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.helpers.store_message.MessageStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Stored Messages","group_outputs":false,"hidden":true,"method":"store_message","name":"stored_messages","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["helpers.Memory"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import (\n    HandleInput,\n    MessageTextInput,\n)\nfrom lfx.memory import aget_messages, astore_message\nfrom lfx.schema.message import Message\nfrom lfx.template.field.base import Output\nfrom lfx.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI\n\n\nclass MessageStoreComponent(Component):\n    display_name = \"Message Store\"\n    description = \"Stores a chat message or text into Langflow tables or an external memory.\"\n    icon = \"message-square-text\"\n    name = \"StoreMessage\"\n    legacy = True\n    replacement = [\"helpers.Memory\"]\n\n    inputs = [\n        MessageTextInput(\n            name=\"message\", display_name=\"Message\", info=\"The chat message to be stored.\", required=True, tool_mode=True\n        ),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"Memory\"],\n            info=\"The external memory to store the message. If empty, it will use the Langflow tables.\",\n        ),\n        MessageTextInput(\n            name=\"sender\",\n            display_name=\"Sender\",\n            info=\"The sender of the message. Might be Machine or User. \"\n            \"If empty, the current sender parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"The name of the sender. Might be AI or User. If empty, the current sender parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            value=\"\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Stored Messages\", name=\"stored_messages\", method=\"store_message\", hidden=True),\n    ]\n\n    async def store_message(self) -> Message:\n        message = Message(text=self.message) if isinstance(self.message, str) else self.message\n\n        message.session_id = self.session_id or message.session_id\n        message.sender = self.sender or message.sender or MESSAGE_SENDER_AI\n        message.sender_name = self.sender_name or message.sender_name or MESSAGE_SENDER_NAME_AI\n\n        stored_messages: list[Message] = []\n\n        if self.memory:\n            self.memory.session_id = message.session_id\n            lc_message = message.to_lc_message()\n            await self.memory.aadd_messages([lc_message])\n\n            stored_messages = await self.memory.aget_messages() or []\n\n            stored_messages = [Message.from_lc_message(m) for m in stored_messages] if stored_messages else []\n\n            if message.sender:\n                stored_messages = [m for m in stored_messages if m.sender == message.sender]\n        else:\n            await astore_message(message, flow_id=self.graph.flow_id)\n            stored_messages = (\n                await aget_messages(\n                    session_id=message.session_id, sender_name=message.sender_name, sender=message.sender\n                )\n                or []\n            )\n\n        if not stored_messages:\n            msg = \"No messages were stored. Please ensure that the session ID and sender are properly set.\"\n            raise ValueError(msg)\n\n        stored_message = stored_messages[0]\n        self.status = stored_message\n        return stored_message\n"},"memory":{"_input_type":"HandleInput","advanced":false,"display_name":"External Memory","dynamic":false,"info":"The external memory to store the message. If empty, it will use the Langflow tables.","input_types":["Memory"],"list":false,"list_add_label":"Add More","name":"memory","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"message":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Message","dynamic":false,"info":"The chat message to be stored.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"message","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"sender":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Sender","dynamic":false,"info":"The sender of the message. Might be Machine or User. If empty, the current sender parameter will be used.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"sender","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"sender_name":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Sender Name","dynamic":false,"info":"The name of the sender. Might be AI or User. If empty, the current sender parameter will be used.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"sender_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"session_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Session ID","dynamic":false,"info":"The session ID of the chat. If empty, the current session ID parameter will be used.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"session_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["homeassistant",{"HomeAssistantControl":{"base_classes":["Data","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"A very simple tool to control Home Assistant devices. Only action (turn_on, turn_off, toggle) and entity_id need to be provided.","display_name":"Home Assistant Control","documentation":"https://developers.home-assistant.io/docs/api/rest/","edited":false,"field_order":["ha_token","base_url","default_action","default_entity_id"],"frozen":false,"icon":"HomeAssistant","legacy":false,"metadata":{"code_hash":"32b34baf3c7d","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"langchain","version":"0.3.23"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.homeassistant.home_assistant_control.HomeAssistantControl"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"run_model","name":"api_run_model","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"api_build_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Home Assistant URL","dynamic":false,"info":"e.g., http://192.168.0.10:8123","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nfrom typing import Any\n\nimport requests\nfrom langchain.tools import StructuredTool\nfrom pydantic import BaseModel, Field\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.field_typing import Tool\nfrom lfx.inputs.inputs import SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass HomeAssistantControl(LCToolComponent):\n    \"\"\"This tool is used to control Home Assistant devices.\n\n    A very simple tool to control Home Assistant devices.\n    - The agent only needs to provide action (turn_on, turn_off, toggle) + entity_id (e.g., switch.xxx, light.xxx).\n    - The domain (e.g., 'switch', 'light') is automatically extracted from entity_id.\n    \"\"\"\n\n    display_name: str = \"Home Assistant Control\"\n    description: str = (\n        \"A very simple tool to control Home Assistant devices. \"\n        \"Only action (turn_on, turn_off, toggle) and entity_id need to be provided.\"\n    )\n    documentation: str = \"https://developers.home-assistant.io/docs/api/rest/\"\n    icon: str = \"HomeAssistant\"\n\n    # --- Input fields for LangFlow UI (token, URL) ---\n    inputs = [\n        SecretStrInput(\n            name=\"ha_token\",\n            display_name=\"Home Assistant Token\",\n            info=\"Home Assistant Long-Lived Access Token\",\n            required=True,\n        ),\n        StrInput(\n            name=\"base_url\",\n            display_name=\"Home Assistant URL\",\n            info=\"e.g., http://192.168.0.10:8123\",\n            required=True,\n        ),\n        StrInput(\n            name=\"default_action\",\n            display_name=\"Default Action (Optional)\",\n            info=\"One of turn_on, turn_off, toggle\",\n            required=False,\n        ),\n        StrInput(\n            name=\"default_entity_id\",\n            display_name=\"Default Entity ID (Optional)\",\n            info=\"Default entity ID to control (e.g., switch.unknown_switch_3)\",\n            required=False,\n        ),\n    ]\n\n    # --- Parameters exposed to the agent (Pydantic schema) ---\n    class ToolSchema(BaseModel):\n        \"\"\"Parameters to be passed by the agent: action, entity_id only.\"\"\"\n\n        action: str = Field(..., description=\"Home Assistant service name. (One of turn_on, turn_off, toggle)\")\n        entity_id: str = Field(\n            ...,\n            description=\"Entity ID to control (e.g., switch.xxx, light.xxx, cover.xxx, etc.).\"\n            \"Do not infer; use the list_homeassistant_states tool to retrieve it.\",\n        )\n\n    def run_model(self) -> Data:\n        \"\"\"Used when the 'Run' button is clicked in LangFlow.\n\n        - Uses default_action and default_entity_id entered in the UI.\n        \"\"\"\n        action = self.default_action or \"turn_off\"\n        entity_id = self.default_entity_id or \"switch.unknown_switch_3\"\n\n        result = self._control_device(\n            ha_token=self.ha_token,\n            base_url=self.base_url,\n            action=action,\n            entity_id=entity_id,\n        )\n        return self._make_data_response(result)\n\n    def build_tool(self) -> Tool:\n        \"\"\"Returns a tool to be used by the agent (LLM).\n\n        - The agent can only pass action and entity_id as arguments.\n        \"\"\"\n        return StructuredTool.from_function(\n            name=\"home_assistant_control\",\n            description=(\n                \"A tool to control Home Assistant devices easily. \"\n                \"Parameters: action ('turn_on'/'turn_off'/'toggle'), entity_id ('switch.xxx', etc.).\"\n                \"Entity ID must be obtained using the list_homeassistant_states tool and not guessed.\"\n            ),\n            func=self._control_device_for_tool,  # Wrapper function below\n            args_schema=self.ToolSchema,\n        )\n\n    def _control_device_for_tool(self, action: str, entity_id: str) -> dict[str, Any] | str:\n        \"\"\"Function called by the agent.\n\n        -> Internally calls _control_device.\n        \"\"\"\n        return self._control_device(\n            ha_token=self.ha_token,\n            base_url=self.base_url,\n            action=action,\n            entity_id=entity_id,\n        )\n\n    def _control_device(\n        self,\n        ha_token: str,\n        base_url: str,\n        action: str,\n        entity_id: str,\n    ) -> dict[str, Any] | str:\n        \"\"\"Actual logic to call the Home Assistant service.\n\n        The domain is extracted from the beginning of the entity_id.\n        Example: entity_id=\"switch.unknown_switch_3\" -> domain=\"switch\".\n        \"\"\"\n        try:\n            domain = entity_id.split(\".\")[0]  # switch, light, cover, etc.\n            url = f\"{base_url}/api/services/{domain}/{action}\"\n\n            headers = {\n                \"Authorization\": f\"Bearer {ha_token}\",\n                \"Content-Type\": \"application/json\",\n            }\n            payload = {\"entity_id\": entity_id}\n\n            response = requests.post(url, headers=headers, json=payload, timeout=10)\n            response.raise_for_status()\n\n            return response.json()  # HA response JSON on success\n        except requests.exceptions.RequestException as e:\n            return f\"Error: Failed to call service. {e}\"\n        except Exception as e:  # noqa: BLE001\n            return f\"An unexpected error occurred: {e}\"\n\n    def _make_data_response(self, result: dict[str, Any] | str) -> Data:\n        \"\"\"Returns a response in the LangFlow Data format.\"\"\"\n        if isinstance(result, str):\n            # Handle error messages\n            return Data(text=result)\n\n        # Convert dict to JSON string\n        formatted_json = json.dumps(result, indent=2, ensure_ascii=False)\n        return Data(data=result, text=formatted_json)\n"},"default_action":{"_input_type":"StrInput","advanced":false,"display_name":"Default Action (Optional)","dynamic":false,"info":"One of turn_on, turn_off, toggle","list":false,"list_add_label":"Add More","load_from_db":false,"name":"default_action","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"default_entity_id":{"_input_type":"StrInput","advanced":false,"display_name":"Default Entity ID (Optional)","dynamic":false,"info":"Default entity ID to control (e.g., switch.unknown_switch_3)","list":false,"list_add_label":"Add More","load_from_db":false,"name":"default_entity_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"ha_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Home Assistant Token","dynamic":false,"info":"Home Assistant Long-Lived Access Token","input_types":[],"load_from_db":true,"name":"ha_token","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""}},"tool_mode":false},"ListHomeAssistantStates":{"base_classes":["Data","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Retrieve states from Home Assistant. The agent only needs to specify 'filter_domain' (optional). Token and base_url are not exposed to the agent.","display_name":"List Home Assistant States","documentation":"https://developers.home-assistant.io/docs/api/rest/","edited":false,"field_order":["ha_token","base_url","filter_domain"],"frozen":false,"icon":"HomeAssistant","legacy":false,"metadata":{"code_hash":"c7bb91632474","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"langchain","version":"0.3.23"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.homeassistant.list_home_assistant_states.ListHomeAssistantStates"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"run_model","name":"api_run_model","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"api_build_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Home Assistant URL","dynamic":false,"info":"e.g., http://192.168.0.10:8123","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nfrom typing import Any\n\nimport requests\nfrom langchain.tools import StructuredTool\nfrom pydantic import BaseModel, Field\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.field_typing import Tool\nfrom lfx.inputs.inputs import SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass ListHomeAssistantStates(LCToolComponent):\n    display_name: str = \"List Home Assistant States\"\n    description: str = (\n        \"Retrieve states from Home Assistant. \"\n        \"The agent only needs to specify 'filter_domain' (optional). \"\n        \"Token and base_url are not exposed to the agent.\"\n    )\n    documentation: str = \"https://developers.home-assistant.io/docs/api/rest/\"\n    icon = \"HomeAssistant\"\n\n    # 1) Define fields to be received in LangFlow UI\n    inputs = [\n        SecretStrInput(\n            name=\"ha_token\",\n            display_name=\"Home Assistant Token\",\n            info=\"Home Assistant Long-Lived Access Token\",\n            required=True,\n        ),\n        StrInput(\n            name=\"base_url\",\n            display_name=\"Home Assistant URL\",\n            info=\"e.g., http://192.168.0.10:8123\",\n            required=True,\n        ),\n        StrInput(\n            name=\"filter_domain\",\n            display_name=\"Default Filter Domain (Optional)\",\n            info=\"light, switch, sensor, etc. (Leave empty to fetch all)\",\n            required=False,\n        ),\n    ]\n\n    # 2) Pydantic schema containing only parameters exposed to the agent\n    class ToolSchema(BaseModel):\n        \"\"\"Parameters to be passed by the agent: filter_domain only.\"\"\"\n\n        filter_domain: str = Field(\"\", description=\"Filter domain (e.g., 'light'). If empty, returns all.\")\n\n    def run_model(self) -> Data:\n        \"\"\"Execute the LangFlow component.\n\n        Uses self.ha_token, self.base_url, self.filter_domain as entered in the UI.\n        Triggered when 'Run' is clicked directly without an agent.\n        \"\"\"\n        filter_domain = self.filter_domain or \"\"  # Use \"\" for fetching all states\n        result = self._list_states(\n            ha_token=self.ha_token,\n            base_url=self.base_url,\n            filter_domain=filter_domain,\n        )\n        return self._make_data_response(result)\n\n    def build_tool(self) -> Tool:\n        \"\"\"Build a tool object to be used by the agent.\n\n        The agent can only pass 'filter_domain' as a parameter.\n        'ha_token' and 'base_url' are not exposed (stored as self attributes).\n        \"\"\"\n        return StructuredTool.from_function(\n            name=\"list_homeassistant_states\",\n            description=(\n                \"Retrieve states from Home Assistant. \"\n                \"You can provide filter_domain='light', 'switch', etc. to narrow results.\"\n            ),\n            func=self._list_states_for_tool,  # Wrapper function below\n            args_schema=self.ToolSchema,  # Requires only filter_domain\n        )\n\n    def _list_states_for_tool(self, filter_domain: str = \"\") -> list[Any] | str:\n        \"\"\"Execute the tool when called by the agent.\n\n        'ha_token' and 'base_url' are stored in self (not exposed).\n        \"\"\"\n        return self._list_states(\n            ha_token=self.ha_token,\n            base_url=self.base_url,\n            filter_domain=filter_domain,\n        )\n\n    def _list_states(\n        self,\n        ha_token: str,\n        base_url: str,\n        filter_domain: str = \"\",\n    ) -> list[Any] | str:\n        \"\"\"Call the Home Assistant /api/states endpoint.\"\"\"\n        try:\n            headers = {\n                \"Authorization\": f\"Bearer {ha_token}\",\n                \"Content-Type\": \"application/json\",\n            }\n            url = f\"{base_url}/api/states\"\n            response = requests.get(url, headers=headers, timeout=10)\n            response.raise_for_status()\n\n            all_states = response.json()\n            if filter_domain:\n                return [st for st in all_states if st.get(\"entity_id\", \"\").startswith(f\"{filter_domain}.\")]\n\n        except requests.exceptions.RequestException as e:\n            return f\"Error: Failed to fetch states. {e}\"\n        except (ValueError, TypeError) as e:\n            return f\"Error processing response: {e}\"\n        return all_states\n\n    def _make_data_response(self, result: list[Any] | str | dict) -> Data:\n        \"\"\"Format the response into a Data object.\"\"\"\n        try:\n            if isinstance(result, list):\n                # Wrap list data into a dictionary and convert to text\n                wrapped_result = {\"result\": result}\n                return Data(data=wrapped_result, text=json.dumps(wrapped_result, indent=2, ensure_ascii=False))\n            if isinstance(result, dict):\n                # Return dictionary as-is\n                return Data(data=result, text=json.dumps(result, indent=2, ensure_ascii=False))\n            if isinstance(result, str):\n                # Return error messages or strings\n                return Data(data={}, text=result)\n\n            # Handle unexpected data types\n            return Data(data={}, text=\"Error: Unexpected response format.\")\n        except (TypeError, ValueError) as e:\n            # Handle specific exceptions during formatting\n            return Data(data={}, text=f\"Error: Failed to process response. Details: {e!s}\")\n"},"filter_domain":{"_input_type":"StrInput","advanced":false,"display_name":"Default Filter Domain (Optional)","dynamic":false,"info":"light, switch, sensor, etc. (Leave empty to fetch all)","list":false,"list_add_label":"Add More","load_from_db":false,"name":"filter_domain","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"ha_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Home Assistant Token","dynamic":false,"info":"Home Assistant Long-Lived Access Token","input_types":[],"load_from_db":true,"name":"ha_token","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""}},"tool_mode":false}}],["huggingface",{"HuggingFaceInferenceAPIEmbeddings":{"base_classes":["Embeddings"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate embeddings using Hugging Face Text Embeddings Inference (TEI)","display_name":"Hugging Face Embeddings Inference","documentation":"https://huggingface.co/docs/text-embeddings-inference/index","edited":false,"field_order":["api_key","inference_endpoint","model_name"],"frozen":false,"icon":"HuggingFace","legacy":false,"metadata":{"code_hash":"af0546658974","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"langchain_community","version":"0.3.21"},{"name":"pydantic","version":"2.10.6"},{"name":"tenacity","version":"8.5.0"},{"name":"lfx","version":null}],"total_dependencies":5},"module":"lfx.components.huggingface.huggingface_inference_api.HuggingFaceInferenceAPIEmbeddingsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Embeddings","group_outputs":false,"method":"build_embeddings","name":"embeddings","selected":"Embeddings","tool_mode":true,"types":["Embeddings"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"HuggingFace API Key","dynamic":false,"info":"Required for non-local inference endpoints. Local inference does not require an API Key.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from urllib.parse import urlparse\n\nimport requests\nfrom langchain_community.embeddings.huggingface import HuggingFaceInferenceAPIEmbeddings\n\n# Next update: use langchain_huggingface\nfrom pydantic import SecretStr\nfrom tenacity import retry, stop_after_attempt, wait_fixed\n\nfrom lfx.base.embeddings.model import LCEmbeddingsModel\nfrom lfx.field_typing import Embeddings\nfrom lfx.io import MessageTextInput, Output, SecretStrInput\n\n\nclass HuggingFaceInferenceAPIEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"Hugging Face Embeddings Inference\"\n    description = \"Generate embeddings using Hugging Face Text Embeddings Inference (TEI)\"\n    documentation = \"https://huggingface.co/docs/text-embeddings-inference/index\"\n    icon = \"HuggingFace\"\n    name = \"HuggingFaceInferenceAPIEmbeddings\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"HuggingFace API Key\",\n            advanced=False,\n            info=\"Required for non-local inference endpoints. Local inference does not require an API Key.\",\n        ),\n        MessageTextInput(\n            name=\"inference_endpoint\",\n            display_name=\"Inference Endpoint\",\n            required=True,\n            value=\"https://api-inference.huggingface.co/models/\",\n            info=\"Custom inference endpoint URL.\",\n        ),\n        MessageTextInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            value=\"BAAI/bge-large-en-v1.5\",\n            info=\"The name of the model to use for text embeddings.\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def validate_inference_endpoint(self, inference_endpoint: str) -> bool:\n        parsed_url = urlparse(inference_endpoint)\n        if not all([parsed_url.scheme, parsed_url.netloc]):\n            msg = (\n                f\"Invalid inference endpoint format: '{self.inference_endpoint}'. \"\n                \"Please ensure the URL includes both a scheme (e.g., 'http://' or 'https://') and a domain name. \"\n                \"Example: 'http://localhost:8080' or 'https://api.example.com'\"\n            )\n            raise ValueError(msg)\n\n        try:\n            response = requests.get(f\"{inference_endpoint}/health\", timeout=5)\n        except requests.RequestException as e:\n            msg = (\n                f\"Inference endpoint '{inference_endpoint}' is not responding. \"\n                \"Please ensure the URL is correct and the service is running.\"\n            )\n            raise ValueError(msg) from e\n\n        if response.status_code != requests.codes.ok:\n            msg = f\"Hugging Face health check failed: {response.status_code}\"\n            raise ValueError(msg)\n        # returning True to solve linting error\n        return True\n\n    def get_api_url(self) -> str:\n        if \"huggingface\" in self.inference_endpoint.lower():\n            return f\"{self.inference_endpoint}\"\n        return self.inference_endpoint\n\n    @retry(stop=stop_after_attempt(3), wait=wait_fixed(2))\n    def create_huggingface_embeddings(\n        self, api_key: SecretStr, api_url: str, model_name: str\n    ) -> HuggingFaceInferenceAPIEmbeddings:\n        return HuggingFaceInferenceAPIEmbeddings(api_key=api_key, api_url=api_url, model_name=model_name)\n\n    def build_embeddings(self) -> Embeddings:\n        api_url = self.get_api_url()\n\n        is_local_url = (\n            api_url.startswith((\"http://localhost\", \"http://127.0.0.1\", \"http://0.0.0.0\", \"http://docker\"))\n            or \"huggingface.co\" not in api_url.lower()\n        )\n\n        if not self.api_key and is_local_url:\n            self.validate_inference_endpoint(api_url)\n            api_key = SecretStr(\"APIKeyForLocalDeployment\")\n        elif not self.api_key:\n            msg = \"API Key is required for non-local inference endpoints\"\n            raise ValueError(msg)\n        else:\n            api_key = SecretStr(self.api_key).get_secret_value()\n\n        try:\n            return self.create_huggingface_embeddings(api_key, api_url, self.model_name)\n        except Exception as e:\n            msg = \"Could not connect to Hugging Face Inference API.\"\n            raise ValueError(msg) from e\n"},"inference_endpoint":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Inference Endpoint","dynamic":false,"info":"Custom inference endpoint URL.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"inference_endpoint","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"https://api-inference.huggingface.co/models/"},"model_name":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Model Name","dynamic":false,"info":"The name of the model to use for text embeddings.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"model_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"BAAI/bge-large-en-v1.5"}},"tool_mode":false},"HuggingFaceModel":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate text using Hugging Face Inference APIs.","display_name":"Hugging Face","documentation":"","edited":false,"field_order":["input_value","system_message","stream","model_id","custom_model","max_new_tokens","top_k","top_p","typical_p","temperature","repetition_penalty","inference_endpoint","task","huggingfacehub_api_token","model_kwargs","retry_attempts"],"frozen":false,"icon":"HuggingFace","legacy":false,"metadata":{"code_hash":"ba9d7c28859d","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"tenacity","version":"8.5.0"},{"name":"lfx","version":null}],"total_dependencies":3},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.huggingface.huggingface.HuggingFaceEndpointsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom langchain_community.llms.huggingface_endpoint import HuggingFaceEndpoint\nfrom tenacity import retry, stop_after_attempt, wait_fixed\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.io import DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, SliderInput, StrInput\n\n# TODO: langchain_community.llms.huggingface_endpoint is depreciated.\n#  Need to update to langchain_huggingface, but have dependency with langchain_core 0.3.0\n\n# Constants\nDEFAULT_MODEL = \"meta-llama/Llama-3.3-70B-Instruct\"\n\n\nclass HuggingFaceEndpointsComponent(LCModelComponent):\n    display_name: str = \"Hugging Face\"\n    description: str = \"Generate text using Hugging Face Inference APIs.\"\n    icon = \"HuggingFace\"\n    name = \"HuggingFaceModel\"\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        DropdownInput(\n            name=\"model_id\",\n            display_name=\"Model ID\",\n            info=\"Select a model from Hugging Face Hub\",\n            options=[\n                DEFAULT_MODEL,\n                \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n                \"mistralai/Mistral-7B-Instruct-v0.3\",\n                \"meta-llama/Llama-3.1-8B-Instruct\",\n                \"Qwen/Qwen2.5-Coder-32B-Instruct\",\n                \"Qwen/QwQ-32B-Preview\",\n                \"openai-community/gpt2\",\n                \"custom\",\n            ],\n            value=DEFAULT_MODEL,\n            required=True,\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"custom_model\",\n            display_name=\"Custom Model ID\",\n            info=\"Enter a custom model ID from Hugging Face Hub\",\n            value=\"\",\n            show=False,\n            required=True,\n        ),\n        IntInput(\n            name=\"max_new_tokens\", display_name=\"Max New Tokens\", value=512, info=\"Maximum number of generated tokens\"\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            advanced=True,\n            info=\"The number of highest probability vocabulary tokens to keep for top-k-filtering\",\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            value=0.95,\n            advanced=True,\n            info=(\n                \"If set to < 1, only the smallest set of most probable tokens with \"\n                \"probabilities that add up to `top_p` or higher are kept for generation\"\n            ),\n        ),\n        FloatInput(\n            name=\"typical_p\",\n            display_name=\"Typical P\",\n            value=0.95,\n            advanced=True,\n            info=\"Typical Decoding mass.\",\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.8,\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\n            info=\"The value used to module the logits distribution\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"repetition_penalty\",\n            display_name=\"Repetition Penalty\",\n            info=\"The parameter for repetition penalty. 1.0 means no penalty.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"inference_endpoint\",\n            display_name=\"Inference Endpoint\",\n            value=\"https://api-inference.huggingface.co/models/\",\n            info=\"Custom inference endpoint URL.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"task\",\n            display_name=\"Task\",\n            options=[\"text2text-generation\", \"text-generation\", \"summarization\", \"translation\"],\n            value=\"text-generation\",\n            advanced=True,\n            info=\"The task to call the model with. Should be a task that returns `generated_text` or `summary_text`.\",\n        ),\n        SecretStrInput(\n            name=\"huggingfacehub_api_token\", display_name=\"HuggingFace HubAPI Token\", password=True, required=True\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Keyword Arguments\", advanced=True),\n        IntInput(name=\"retry_attempts\", display_name=\"Retry Attempts\", value=1, advanced=True),\n    ]\n\n    def get_api_url(self) -> str:\n        if \"huggingface\" in self.inference_endpoint.lower():\n            if self.model_id == \"custom\":\n                if not self.custom_model:\n                    error_msg = \"Custom model ID is required when 'custom' is selected\"\n                    raise ValueError(error_msg)\n                return f\"{self.inference_endpoint}{self.custom_model}\"\n            return f\"{self.inference_endpoint}{self.model_id}\"\n        return self.inference_endpoint\n\n    async def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        \"\"\"Update build configuration based on field updates.\"\"\"\n        try:\n            if field_name is None or field_name == \"model_id\":\n                # If model_id is custom, show custom model field\n                if field_value == \"custom\":\n                    build_config[\"custom_model\"][\"show\"] = True\n                    build_config[\"custom_model\"][\"required\"] = True\n                else:\n                    build_config[\"custom_model\"][\"show\"] = False\n                    build_config[\"custom_model\"][\"value\"] = \"\"\n\n        except (KeyError, AttributeError) as e:\n            self.log(f\"Error updating build config: {e!s}\")\n        return build_config\n\n    def create_huggingface_endpoint(\n        self,\n        task: str | None,\n        huggingfacehub_api_token: str | None,\n        model_kwargs: dict[str, Any],\n        max_new_tokens: int,\n        top_k: int | None,\n        top_p: float,\n        typical_p: float | None,\n        temperature: float | None,\n        repetition_penalty: float | None,\n    ) -> HuggingFaceEndpoint:\n        retry_attempts = self.retry_attempts\n        endpoint_url = self.get_api_url()\n\n        @retry(stop=stop_after_attempt(retry_attempts), wait=wait_fixed(2))\n        def _attempt_create():\n            return HuggingFaceEndpoint(\n                endpoint_url=endpoint_url,\n                task=task,\n                huggingfacehub_api_token=huggingfacehub_api_token,\n                model_kwargs=model_kwargs,\n                max_new_tokens=max_new_tokens,\n                top_k=top_k,\n                top_p=top_p,\n                typical_p=typical_p,\n                temperature=temperature,\n                repetition_penalty=repetition_penalty,\n            )\n\n        return _attempt_create()\n\n    def build_model(self) -> LanguageModel:\n        task = self.task or None\n        huggingfacehub_api_token = self.huggingfacehub_api_token\n        model_kwargs = self.model_kwargs or {}\n        max_new_tokens = self.max_new_tokens\n        top_k = self.top_k or None\n        top_p = self.top_p\n        typical_p = self.typical_p or None\n        temperature = self.temperature or 0.8\n        repetition_penalty = self.repetition_penalty or None\n\n        try:\n            llm = self.create_huggingface_endpoint(\n                task=task,\n                huggingfacehub_api_token=huggingfacehub_api_token,\n                model_kwargs=model_kwargs,\n                max_new_tokens=max_new_tokens,\n                top_k=top_k,\n                top_p=top_p,\n                typical_p=typical_p,\n                temperature=temperature,\n                repetition_penalty=repetition_penalty,\n            )\n        except Exception as e:\n            msg = \"Could not connect to Hugging Face Endpoints API.\"\n            raise ValueError(msg) from e\n\n        return llm\n"},"custom_model":{"_input_type":"StrInput","advanced":false,"display_name":"Custom Model ID","dynamic":false,"info":"Enter a custom model ID from Hugging Face Hub","list":false,"list_add_label":"Add More","load_from_db":false,"name":"custom_model","placeholder":"","required":true,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"huggingfacehub_api_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"HuggingFace HubAPI Token","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"huggingfacehub_api_token","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"inference_endpoint":{"_input_type":"StrInput","advanced":false,"display_name":"Inference Endpoint","dynamic":false,"info":"Custom inference endpoint URL.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"inference_endpoint","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"https://api-inference.huggingface.co/models/"},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"max_new_tokens":{"_input_type":"IntInput","advanced":false,"display_name":"Max New Tokens","dynamic":false,"info":"Maximum number of generated tokens","list":false,"list_add_label":"Add More","name":"max_new_tokens","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":512},"model_id":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model ID","dynamic":false,"external_options":{},"info":"Select a model from Hugging Face Hub","name":"model_id","options":["meta-llama/Llama-3.3-70B-Instruct","mistralai/Mixtral-8x7B-Instruct-v0.1","mistralai/Mistral-7B-Instruct-v0.3","meta-llama/Llama-3.1-8B-Instruct","Qwen/Qwen2.5-Coder-32B-Instruct","Qwen/QwQ-32B-Preview","openai-community/gpt2","custom"],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"meta-llama/Llama-3.3-70B-Instruct"},"model_kwargs":{"_input_type":"DictInput","advanced":true,"display_name":"Model Keyword Arguments","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"model_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"repetition_penalty":{"_input_type":"FloatInput","advanced":true,"display_name":"Repetition Penalty","dynamic":false,"info":"The parameter for repetition penalty. 1.0 means no penalty.","list":false,"list_add_label":"Add More","name":"repetition_penalty","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":""},"retry_attempts":{"_input_type":"IntInput","advanced":true,"display_name":"Retry Attempts","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"retry_attempts","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"task":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Task","dynamic":false,"external_options":{},"info":"The task to call the model with. Should be a task that returns `generated_text` or `summary_text`.","name":"task","options":["text2text-generation","text-generation","summarization","translation"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"text-generation"},"temperature":{"_input_type":"SliderInput","advanced":true,"display_name":"Temperature","dynamic":false,"info":"The value used to module the logits distribution","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"temperature","placeholder":"","range_spec":{"max":2.0,"min":0.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":0.8},"top_k":{"_input_type":"IntInput","advanced":true,"display_name":"Top K","dynamic":false,"info":"The number of highest probability vocabulary tokens to keep for top-k-filtering","list":false,"list_add_label":"Add More","name":"top_k","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"top_p":{"_input_type":"FloatInput","advanced":true,"display_name":"Top P","dynamic":false,"info":"If set to < 1, only the smallest set of most probable tokens with probabilities that add up to `top_p` or higher are kept for generation","list":false,"list_add_label":"Add More","name":"top_p","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.95},"typical_p":{"_input_type":"FloatInput","advanced":true,"display_name":"Typical P","dynamic":false,"info":"Typical Decoding mass.","list":false,"list_add_label":"Add More","name":"typical_p","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.95}},"tool_mode":false}}],["ibm",{"IBMwatsonxModel":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate text using IBM watsonx.ai foundation models.","display_name":"IBM watsonx.ai","documentation":"","edited":false,"field_order":["input_value","system_message","stream","url","project_id","api_key","model_name","max_tokens","stop_sequence","temperature","top_p","frequency_penalty","presence_penalty","seed","logprobs","top_logprobs","logit_bias"],"frozen":false,"icon":"WatsonxAI","legacy":false,"metadata":{"code_hash":"85c24939214c","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"langchain_ibm","version":"0.3.19"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":4},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.ibm.watsonx.WatsonxAIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Watsonx API Key","dynamic":false,"info":"The API Key to use for the model.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nfrom typing import Any\n\nimport requests\nfrom langchain_ibm import ChatWatsonx\nfrom pydantic.v1 import SecretStr\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.inputs.inputs import BoolInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.dotdict import dotdict\n\n\nclass WatsonxAIComponent(LCModelComponent):\n    display_name = \"IBM watsonx.ai\"\n    description = \"Generate text using IBM watsonx.ai foundation models.\"\n    icon = \"WatsonxAI\"\n    name = \"IBMwatsonxModel\"\n    beta = False\n\n    _default_models = [\"ibm/granite-3-2b-instruct\", \"ibm/granite-3-8b-instruct\", \"ibm/granite-13b-instruct-v2\"]\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        DropdownInput(\n            name=\"url\",\n            display_name=\"watsonx API Endpoint\",\n            info=\"The base URL of the API.\",\n            value=None,\n            options=[\n                \"https://us-south.ml.cloud.ibm.com\",\n                \"https://eu-de.ml.cloud.ibm.com\",\n                \"https://eu-gb.ml.cloud.ibm.com\",\n                \"https://au-syd.ml.cloud.ibm.com\",\n                \"https://jp-tok.ml.cloud.ibm.com\",\n                \"https://ca-tor.ml.cloud.ibm.com\",\n            ],\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"project_id\",\n            display_name=\"watsonx Project ID\",\n            required=True,\n            info=\"The project ID or deployment space ID that is associated with the foundation model.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Watsonx API Key\",\n            info=\"The API Key to use for the model.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            options=[],\n            value=None,\n            dynamic=True,\n            required=True,\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate.\",\n            range_spec=RangeSpec(min=1, max=4096),\n            value=1000,\n        ),\n        StrInput(\n            name=\"stop_sequence\",\n            display_name=\"Stop Sequence\",\n            advanced=True,\n            info=\"Sequence where generation should stop.\",\n            field_type=\"str\",\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            info=\"Controls randomness, higher values increase diversity.\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\n            advanced=True,\n        ),\n        SliderInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"The cumulative probability cutoff for token selection. \"\n            \"Lower values mean sampling from a smaller, more top-weighted nucleus.\",\n            value=0.9,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            advanced=True,\n        ),\n        SliderInput(\n            name=\"frequency_penalty\",\n            display_name=\"Frequency Penalty\",\n            info=\"Penalty for frequency of token usage.\",\n            value=0.5,\n            range_spec=RangeSpec(min=-2.0, max=2.0, step=0.01),\n            advanced=True,\n        ),\n        SliderInput(\n            name=\"presence_penalty\",\n            display_name=\"Presence Penalty\",\n            info=\"Penalty for token presence in prior text.\",\n            value=0.3,\n            range_spec=RangeSpec(min=-2.0, max=2.0, step=0.01),\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Random Seed\",\n            advanced=True,\n            info=\"The random seed for the model.\",\n            value=8,\n        ),\n        BoolInput(\n            name=\"logprobs\",\n            display_name=\"Log Probabilities\",\n            advanced=True,\n            info=\"Whether to return log probabilities of the output tokens.\",\n            value=True,\n        ),\n        IntInput(\n            name=\"top_logprobs\",\n            display_name=\"Top Log Probabilities\",\n            advanced=True,\n            info=\"Number of most likely tokens to return at each position.\",\n            value=3,\n            range_spec=RangeSpec(min=1, max=20),\n        ),\n        StrInput(\n            name=\"logit_bias\",\n            display_name=\"Logit Bias\",\n            advanced=True,\n            info='JSON string of token IDs to bias or suppress (e.g., {\"1003\": -100, \"1004\": 100}).',\n            field_type=\"str\",\n        ),\n    ]\n\n    @staticmethod\n    def fetch_models(base_url: str) -> list[str]:\n        \"\"\"Fetch available models from the watsonx.ai API.\"\"\"\n        try:\n            endpoint = f\"{base_url}/ml/v1/foundation_model_specs\"\n            params = {\"version\": \"2024-09-16\", \"filters\": \"function_text_chat,!lifecycle_withdrawn\"}\n            response = requests.get(endpoint, params=params, timeout=10)\n            response.raise_for_status()\n            data = response.json()\n            models = [model[\"model_id\"] for model in data.get(\"resources\", [])]\n            return sorted(models)\n        except Exception:  # noqa: BLE001\n            logger.exception(\"Error fetching models. Using default models.\")\n            return WatsonxAIComponent._default_models\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        \"\"\"Update model options when URL or API key changes.\"\"\"\n        logger.info(\"Updating build config. Field name: %s, Field value: %s\", field_name, field_value)\n\n        if field_name == \"url\" and field_value:\n            try:\n                models = self.fetch_models(base_url=build_config.url.value)\n                build_config.model_name.options = models\n                if build_config.model_name.value:\n                    build_config.model_name.value = models[0]\n                info_message = f\"Updated model options: {len(models)} models found in {build_config.url.value}\"\n                logger.info(info_message)\n            except Exception:  # noqa: BLE001\n                logger.exception(\"Error updating model options.\")\n\n    def build_model(self) -> LanguageModel:\n        # Parse logit_bias from JSON string if provided\n        logit_bias = None\n        if hasattr(self, \"logit_bias\") and self.logit_bias:\n            try:\n                logit_bias = json.loads(self.logit_bias)\n            except json.JSONDecodeError:\n                logger.warning(\"Invalid logit_bias JSON format. Using default instead.\")\n                logit_bias = {\"1003\": -100, \"1004\": -100}\n\n        chat_params = {\n            \"max_tokens\": getattr(self, \"max_tokens\", None),\n            \"temperature\": getattr(self, \"temperature\", None),\n            \"top_p\": getattr(self, \"top_p\", None),\n            \"frequency_penalty\": getattr(self, \"frequency_penalty\", None),\n            \"presence_penalty\": getattr(self, \"presence_penalty\", None),\n            \"seed\": getattr(self, \"seed\", None),\n            \"stop\": [self.stop_sequence] if self.stop_sequence else [],\n            \"n\": 1,\n            \"logprobs\": getattr(self, \"logprobs\", True),\n            \"top_logprobs\": getattr(self, \"top_logprobs\", None),\n            \"time_limit\": 600000,\n            \"logit_bias\": logit_bias,\n        }\n\n        return ChatWatsonx(\n            apikey=SecretStr(self.api_key).get_secret_value(),\n            url=self.url,\n            project_id=self.project_id,\n            model_id=self.model_name,\n            params=chat_params,\n            streaming=self.stream,\n        )\n"},"frequency_penalty":{"_input_type":"SliderInput","advanced":true,"display_name":"Frequency Penalty","dynamic":false,"info":"Penalty for frequency of token usage.","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"frequency_penalty","placeholder":"","range_spec":{"max":2.0,"min":-2.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":0.5},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"logit_bias":{"_input_type":"StrInput","advanced":true,"display_name":"Logit Bias","dynamic":false,"info":"JSON string of token IDs to bias or suppress (e.g., {\"1003\": -100, \"1004\": 100}).","list":false,"list_add_label":"Add More","load_from_db":false,"name":"logit_bias","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"logprobs":{"_input_type":"BoolInput","advanced":true,"display_name":"Log Probabilities","dynamic":false,"info":"Whether to return log probabilities of the output tokens.","list":false,"list_add_label":"Add More","name":"logprobs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"max_tokens":{"_input_type":"IntInput","advanced":true,"display_name":"Max Tokens","dynamic":false,"info":"The maximum number of tokens to generate.","list":false,"list_add_label":"Add More","name":"max_tokens","placeholder":"","range_spec":{"max":4096.0,"min":1.0,"step":0.1,"step_type":"float"},"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1000},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model Name","dynamic":true,"external_options":{},"info":"","name":"model_name","options":[],"options_metadata":[],"placeholder":"","required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str"},"presence_penalty":{"_input_type":"SliderInput","advanced":true,"display_name":"Presence Penalty","dynamic":false,"info":"Penalty for token presence in prior text.","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"presence_penalty","placeholder":"","range_spec":{"max":2.0,"min":-2.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":0.3},"project_id":{"_input_type":"StrInput","advanced":false,"display_name":"watsonx Project ID","dynamic":false,"info":"The project ID or deployment space ID that is associated with the foundation model.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"project_id","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"seed":{"_input_type":"IntInput","advanced":true,"display_name":"Random Seed","dynamic":false,"info":"The random seed for the model.","list":false,"list_add_label":"Add More","name":"seed","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":8},"stop_sequence":{"_input_type":"StrInput","advanced":true,"display_name":"Stop Sequence","dynamic":false,"info":"Sequence where generation should stop.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"stop_sequence","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"SliderInput","advanced":true,"display_name":"Temperature","dynamic":false,"info":"Controls randomness, higher values increase diversity.","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"temperature","placeholder":"","range_spec":{"max":2.0,"min":0.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":0.1},"top_logprobs":{"_input_type":"IntInput","advanced":true,"display_name":"Top Log Probabilities","dynamic":false,"info":"Number of most likely tokens to return at each position.","list":false,"list_add_label":"Add More","name":"top_logprobs","placeholder":"","range_spec":{"max":20.0,"min":1.0,"step":0.1,"step_type":"float"},"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":3},"top_p":{"_input_type":"SliderInput","advanced":true,"display_name":"Top P","dynamic":false,"info":"The cumulative probability cutoff for token selection. Lower values mean sampling from a smaller, more top-weighted nucleus.","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"top_p","placeholder":"","range_spec":{"max":1.0,"min":0.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":0.9},"url":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"watsonx API Endpoint","dynamic":false,"external_options":{},"info":"The base URL of the API.","name":"url","options":["https://us-south.ml.cloud.ibm.com","https://eu-de.ml.cloud.ibm.com","https://eu-gb.ml.cloud.ibm.com","https://au-syd.ml.cloud.ibm.com","https://jp-tok.ml.cloud.ibm.com","https://ca-tor.ml.cloud.ibm.com"],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str"}},"tool_mode":false},"WatsonxEmbeddingsComponent":{"base_classes":["Embeddings"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate embeddings using IBM watsonx.ai models.","display_name":"IBM watsonx.ai Embeddings","documentation":"","edited":false,"field_order":["url","project_id","api_key","model_name","truncate_input_tokens","input_text"],"frozen":false,"icon":"WatsonxAI","legacy":false,"metadata":{"code_hash":"ffded413ea90","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"ibm_watsonx_ai","version":"1.4.1"},{"name":"langchain_ibm","version":"0.3.19"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":5},"module":"lfx.components.ibm.watsonx_embeddings.WatsonxEmbeddingsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Embedding Model","group_outputs":false,"method":"build_embeddings","name":"embeddings","selected":"Embeddings","tool_mode":true,"types":["Embeddings"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Watsonx API Key","dynamic":false,"info":"The API Key to use for the model.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nimport requests\nfrom ibm_watsonx_ai import APIClient, Credentials\nfrom ibm_watsonx_ai.metanames import EmbedTextParamsMetaNames\nfrom langchain_ibm import WatsonxEmbeddings\nfrom pydantic.v1 import SecretStr\n\nfrom lfx.base.embeddings.model import LCEmbeddingsModel\nfrom lfx.field_typing import Embeddings\nfrom lfx.io import BoolInput, DropdownInput, IntInput, SecretStrInput, StrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.dotdict import dotdict\n\n\nclass WatsonxEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"IBM watsonx.ai Embeddings\"\n    description = \"Generate embeddings using IBM watsonx.ai models.\"\n    icon = \"WatsonxAI\"\n    name = \"WatsonxEmbeddingsComponent\"\n\n    # models present in all the regions\n    _default_models = [\n        \"sentence-transformers/all-minilm-l12-v2\",\n        \"ibm/slate-125m-english-rtrvr-v2\",\n        \"ibm/slate-30m-english-rtrvr-v2\",\n        \"intfloat/multilingual-e5-large\",\n    ]\n\n    inputs = [\n        DropdownInput(\n            name=\"url\",\n            display_name=\"watsonx API Endpoint\",\n            info=\"The base URL of the API.\",\n            value=None,\n            options=[\n                \"https://us-south.ml.cloud.ibm.com\",\n                \"https://eu-de.ml.cloud.ibm.com\",\n                \"https://eu-gb.ml.cloud.ibm.com\",\n                \"https://au-syd.ml.cloud.ibm.com\",\n                \"https://jp-tok.ml.cloud.ibm.com\",\n                \"https://ca-tor.ml.cloud.ibm.com\",\n            ],\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"project_id\",\n            display_name=\"watsonx project id\",\n            info=\"The project ID or deployment space ID that is associated with the foundation model.\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Watsonx API Key\",\n            info=\"The API Key to use for the model.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            options=[],\n            value=None,\n            dynamic=True,\n            required=True,\n        ),\n        IntInput(\n            name=\"truncate_input_tokens\",\n            display_name=\"Truncate Input Tokens\",\n            advanced=True,\n            value=200,\n        ),\n        BoolInput(\n            name=\"input_text\",\n            display_name=\"Include the original text in the output\",\n            value=True,\n            advanced=True,\n        ),\n    ]\n\n    @staticmethod\n    def fetch_models(base_url: str) -> list[str]:\n        \"\"\"Fetch available models from the watsonx.ai API.\"\"\"\n        try:\n            endpoint = f\"{base_url}/ml/v1/foundation_model_specs\"\n            params = {\n                \"version\": \"2024-09-16\",\n                \"filters\": \"function_embedding,!lifecycle_withdrawn:and\",\n            }\n            response = requests.get(endpoint, params=params, timeout=10)\n            response.raise_for_status()\n            data = response.json()\n            models = [model[\"model_id\"] for model in data.get(\"resources\", [])]\n            return sorted(models)\n        except Exception:  # noqa: BLE001\n            logger.exception(\"Error fetching models\")\n            return WatsonxEmbeddingsComponent._default_models\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        \"\"\"Update model options when URL or API key changes.\"\"\"\n        logger.debug(\n            \"Updating build config. Field name: %s, Field value: %s\",\n            field_name,\n            field_value,\n        )\n\n        if field_name == \"url\" and field_value:\n            try:\n                models = self.fetch_models(base_url=build_config.url.value)\n                build_config.model_name.options = models\n                if build_config.model_name.value:\n                    build_config.model_name.value = models[0]\n                info_message = f\"Updated model options: {len(models)} models found in {build_config.url.value}\"\n                logger.info(info_message)\n            except Exception:  # noqa: BLE001\n                logger.exception(\"Error updating model options.\")\n\n    def build_embeddings(self) -> Embeddings:\n        credentials = Credentials(\n            api_key=SecretStr(self.api_key).get_secret_value(),\n            url=self.url,\n        )\n\n        api_client = APIClient(credentials)\n\n        params = {\n            EmbedTextParamsMetaNames.TRUNCATE_INPUT_TOKENS: self.truncate_input_tokens,\n            EmbedTextParamsMetaNames.RETURN_OPTIONS: {\"input_text\": self.input_text},\n        }\n\n        return WatsonxEmbeddings(\n            model_id=self.model_name,\n            params=params,\n            watsonx_client=api_client,\n            project_id=self.project_id,\n        )\n"},"input_text":{"_input_type":"BoolInput","advanced":true,"display_name":"Include the original text in the output","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"input_text","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model Name","dynamic":true,"external_options":{},"info":"","name":"model_name","options":[],"options_metadata":[],"placeholder":"","required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str"},"project_id":{"_input_type":"StrInput","advanced":false,"display_name":"watsonx project id","dynamic":false,"info":"The project ID or deployment space ID that is associated with the foundation model.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"project_id","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"truncate_input_tokens":{"_input_type":"IntInput","advanced":true,"display_name":"Truncate Input Tokens","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"truncate_input_tokens","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":200},"url":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"watsonx API Endpoint","dynamic":false,"external_options":{},"info":"The base URL of the API.","name":"url","options":["https://us-south.ml.cloud.ibm.com","https://eu-de.ml.cloud.ibm.com","https://eu-gb.ml.cloud.ibm.com","https://au-syd.ml.cloud.ibm.com","https://jp-tok.ml.cloud.ibm.com","https://ca-tor.ml.cloud.ibm.com"],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str"}},"tool_mode":false}}],["icosacomputing",{"Combinatorial Reasoner":{"base_classes":["Data","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Uses Combinatorial Optimization to construct an optimal prompt with embedded reasons. Sign up here:\nhttps://forms.gle/oWNv2NKjBNaqqvCx6","display_name":"Combinatorial Reasoner","documentation":"","edited":false,"field_order":["prompt","openai_api_key","username","password","model_name"],"frozen":false,"icon":"Icosa","legacy":false,"metadata":{"code_hash":"48557047ff23","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.icosacomputing.combinatorial_reasoner.CombinatorialReasonerComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Optimized Prompt","group_outputs":false,"method":"build_prompt","name":"optimized_prompt","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Selected Reasons","group_outputs":false,"method":"build_reasons","name":"reasons","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import requests\nfrom requests.auth import HTTPBasicAuth\n\nfrom lfx.base.models.openai_constants import OPENAI_CHAT_MODEL_NAMES\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import DropdownInput, SecretStrInput, StrInput\nfrom lfx.io import MessageTextInput, Output\nfrom lfx.schema.data import Data\nfrom lfx.schema.message import Message\n\n\nclass CombinatorialReasonerComponent(Component):\n    display_name = \"Combinatorial Reasoner\"\n    description = \"Uses Combinatorial Optimization to construct an optimal prompt with embedded reasons. Sign up here:\\nhttps://forms.gle/oWNv2NKjBNaqqvCx6\"\n    icon = \"Icosa\"\n    name = \"Combinatorial Reasoner\"\n\n    inputs = [\n        MessageTextInput(name=\"prompt\", display_name=\"Prompt\", required=True),\n        SecretStrInput(\n            name=\"openai_api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        StrInput(\n            name=\"username\",\n            display_name=\"Username\",\n            info=\"Username to authenticate access to Icosa CR API\",\n            advanced=False,\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"password\",\n            display_name=\"Combinatorial Reasoner Password\",\n            info=\"Password to authenticate access to Icosa CR API.\",\n            advanced=False,\n            required=True,\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_CHAT_MODEL_NAMES,\n            value=OPENAI_CHAT_MODEL_NAMES[0],\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Optimized Prompt\",\n            name=\"optimized_prompt\",\n            method=\"build_prompt\",\n        ),\n        Output(display_name=\"Selected Reasons\", name=\"reasons\", method=\"build_reasons\"),\n    ]\n\n    def build_prompt(self) -> Message:\n        params = {\n            \"prompt\": self.prompt,\n            \"apiKey\": self.openai_api_key,\n            \"model\": self.model_name,\n        }\n\n        creds = HTTPBasicAuth(self.username, password=self.password)\n        response = requests.post(\n            \"https://cr-api.icosacomputing.com/cr/langflow\",\n            json=params,\n            auth=creds,\n            timeout=100,\n        )\n        response.raise_for_status()\n\n        prompt = response.json()[\"prompt\"]\n\n        self.reasons = response.json()[\"finalReasons\"]\n        return prompt\n\n    def build_reasons(self) -> Data:\n        # list of selected reasons\n        final_reasons = [reason[0] for reason in self.reasons]\n        return Data(value=final_reasons)\n"},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model Name","dynamic":false,"external_options":{},"info":"","name":"model_name","options":["gpt-4o-mini","gpt-4o","gpt-4.1","gpt-4.1-mini","gpt-4.1-nano","gpt-4-turbo","gpt-4-turbo-preview","gpt-4","gpt-3.5-turbo"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"gpt-4o-mini"},"openai_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"OpenAI API Key","dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","input_types":[],"load_from_db":true,"name":"openai_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"OPENAI_API_KEY"},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Combinatorial Reasoner Password","dynamic":false,"info":"Password to authenticate access to Icosa CR API.","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"prompt":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Prompt","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"prompt","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"Username to authenticate access to Icosa CR API","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["input_output",{"ChatInput":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Get chat inputs from the Playground.","display_name":"Chat Input","documentation":"https://docs.langflow.org/components-io#chat-input","edited":false,"field_order":["input_value","should_store_message","sender","sender_name","session_id","context_id","files"],"frozen":false,"icon":"MessagesSquare","legacy":false,"metadata":{"code_hash":"0014a5b41817","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.input_output.chat.ChatInput"},"minimized":true,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Chat Message","group_outputs":false,"method":"message_response","name":"message","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom lfx.base.io.chat import ChatComponent\nfrom lfx.inputs.inputs import BoolInput\nfrom lfx.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom lfx.schema.message import Message\nfrom lfx.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-input\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"context_id\",\n            display_name=\"Context ID\",\n            info=\"The context ID of the chat. Adds an extra layer to the local memory.\",\n            value=\"\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n            temp_file=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Chat Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        # Ensure files is a list and filter out empty/None values\n        files = self.files if self.files else []\n        if files and not isinstance(files, list):\n            files = [files]\n        # Filter out None/empty values\n        files = [f for f in files if f is not None and f != \"\"]\n\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            context_id=self.context_id,\n            files=files,\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"},"context_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Context ID","dynamic":false,"info":"The context ID of the chat. Adds an extra layer to the local memory.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"context_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"files":{"_input_type":"FileInput","advanced":true,"display_name":"Files","dynamic":false,"fileTypes":["csv","json","pdf","txt","md","mdx","yaml","yml","xml","html","htm","docx","py","sh","sql","js","ts","tsx","jpg","jpeg","png","bmp","image"],"file_path":"","info":"Files to be sent with the message.","list":true,"list_add_label":"Add More","name":"files","placeholder":"","required":false,"show":true,"temp_file":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"file","value":""},"input_value":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Input Text","dynamic":false,"info":"Message to be passed as input.","input_types":[],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"sender":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Sender Type","dynamic":false,"external_options":{},"info":"Type of sender.","name":"sender","options":["Machine","User"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"User"},"sender_name":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Sender Name","dynamic":false,"info":"Name of the sender.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"sender_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"User"},"session_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Session ID","dynamic":false,"info":"The session ID of the chat. If empty, the current session ID parameter will be used.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"session_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"should_store_message":{"_input_type":"BoolInput","advanced":true,"display_name":"Store Messages","dynamic":false,"info":"Store the message in the history.","list":false,"list_add_label":"Add More","name":"should_store_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false},"ChatOutput":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Display a chat message in the Playground.","display_name":"Chat Output","documentation":"https://docs.langflow.org/components-io#chat-output","edited":false,"field_order":["input_value","should_store_message","sender","sender_name","session_id","context_id","data_template","clean_data"],"frozen":false,"icon":"MessagesSquare","legacy":false,"metadata":{"code_hash":"4848ad3e35d5","dependencies":{"dependencies":[{"name":"orjson","version":"3.10.15"},{"name":"fastapi","version":"0.119.0"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.input_output.chat_output.ChatOutput"},"minimized":true,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Output Message","group_outputs":false,"method":"message_response","name":"message","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","clean_data":{"_input_type":"BoolInput","advanced":true,"display_name":"Basic Clean Data","dynamic":false,"info":"Whether to clean data before converting to string.","list":false,"list_add_label":"Add More","name":"clean_data","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom lfx.base.io.chat import ChatComponent\nfrom lfx.helpers.data import safe_convert\nfrom lfx.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.message import Message\nfrom lfx.schema.properties import Source\nfrom lfx.template.field.base import Output\nfrom lfx.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"context_id\",\n            display_name=\"Context ID\",\n            info=\"The context ID of the chat. Adds an extra layer to the local memory.\",\n            value=\"\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            advanced=True,\n            info=\"Whether to clean data before converting to string.\",\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, _, display_name, source_id = self.get_properties_from_source_component()\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.context_id = self.context_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            clean_data: bool = getattr(self, \"clean_data\", False)\n            return \"\\n\".join([safe_convert(item, clean_data=clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"},"context_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Context ID","dynamic":false,"info":"The context ID of the chat. Adds an extra layer to the local memory.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"context_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"data_template":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Data Template","dynamic":false,"info":"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"data_template","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"{text}"},"input_value":{"_input_type":"HandleInput","advanced":false,"display_name":"Inputs","dynamic":false,"info":"Message to be passed as output.","input_types":["Data","DataFrame","Message"],"list":false,"list_add_label":"Add More","name":"input_value","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"sender":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Sender Type","dynamic":false,"external_options":{},"info":"Type of sender.","name":"sender","options":["Machine","User"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Machine"},"sender_name":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Sender Name","dynamic":false,"info":"Name of the sender.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"sender_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"AI"},"session_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Session ID","dynamic":false,"info":"The session ID of the chat. If empty, the current session ID parameter will be used.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"session_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"should_store_message":{"_input_type":"BoolInput","advanced":true,"display_name":"Store Messages","dynamic":false,"info":"Store the message in the history.","list":false,"list_add_label":"Add More","name":"should_store_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false},"TextInput":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Get user text inputs.","display_name":"Text Input","documentation":"https://docs.langflow.org/components-io#text-input","edited":false,"field_order":["input_value"],"frozen":false,"icon":"type","legacy":false,"metadata":{"code_hash":"3dd28ea591b9","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.input_output.text.TextInputComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Output Text","group_outputs":false,"method":"text_response","name":"text","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.io.text import TextComponent\nfrom lfx.io import MultilineInput, Output\nfrom lfx.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get user text inputs.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-input\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"},"input_value":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Text","dynamic":false,"info":"Text to be passed as input.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"TextOutput":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Sends text output via API.","display_name":"Text Output","documentation":"https://docs.langflow.org/components-io#text-output","edited":false,"field_order":["input_value"],"frozen":false,"icon":"type","legacy":false,"metadata":{"code_hash":"223fd793686e","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.input_output.text_output.TextOutputComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Output Text","group_outputs":false,"method":"text_response","name":"text","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.io.text import TextComponent\nfrom lfx.io import MultilineInput, Output\nfrom lfx.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Sends text output via API.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-output\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n"},"input_value":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Inputs","dynamic":false,"info":"Text to be passed as output.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["jigsawstack",{"JigsawStackAIScraper":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Scrape any website instantly and get consistent structured data         in seconds without writing any css selector code","display_name":"AI Scraper","documentation":"https://jigsawstack.com/docs/api-reference/ai/scrape","edited":false,"field_order":["api_key","url","html","element_prompts","root_element_selector"],"frozen":false,"icon":"JigsawStack","legacy":false,"metadata":{"code_hash":"08a0063e2564","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"jigsawstack","version":"0.2.7"}],"total_dependencies":2},"module":"lfx.components.jigsawstack.ai_scrape.JigsawStackAIScraperComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"AI Scraper Results","group_outputs":false,"method":"scrape","name":"scrape_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"JigsawStack API Key","dynamic":false,"info":"Your JigsawStack API key for authentication","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.io import MessageTextInput, Output, SecretStrInput\nfrom lfx.schema.data import Data\n\nMAX_ELEMENT_PROMPTS = 5\n\n\nclass JigsawStackAIScraperComponent(Component):\n    display_name = \"AI Scraper\"\n    description = \"Scrape any website instantly and get consistent structured data \\\n        in seconds without writing any css selector code\"\n    documentation = \"https://jigsawstack.com/docs/api-reference/ai/scrape\"\n    icon = \"JigsawStack\"\n    name = \"JigsawStackAIScraper\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"JigsawStack API Key\",\n            info=\"Your JigsawStack API key for authentication\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"url\",\n            display_name=\"URL\",\n            info=\"URL of the page to scrape. Either url or html is required, but not both.\",\n            required=False,\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"html\",\n            display_name=\"HTML\",\n            info=\"HTML content to scrape. Either url or html is required, but not both.\",\n            required=False,\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"element_prompts\",\n            display_name=\"Element Prompts\",\n            info=\"Items on the page to be scraped (maximum 5). E.g. 'Plan price', 'Plan title'\",\n            required=True,\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"root_element_selector\",\n            display_name=\"Root Element Selector\",\n            info=\"CSS selector to limit the scope of scraping to a specific element and its children\",\n            required=False,\n            value=\"main\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"AI Scraper Results\", name=\"scrape_results\", method=\"scrape\"),\n    ]\n\n    def scrape(self) -> Data:\n        try:\n            from jigsawstack import JigsawStack, JigsawStackError\n        except ImportError as e:\n            jigsawstack_import_error = (\n                \"JigsawStack package not found. Please install it using: pip install jigsawstack>=0.2.7\"\n            )\n            raise ImportError(jigsawstack_import_error) from e\n\n        try:\n            client = JigsawStack(api_key=self.api_key)\n\n            # Build request object\n            scrape_params: dict = {}\n            if self.url:\n                scrape_params[\"url\"] = self.url\n            if self.html:\n                scrape_params[\"html\"] = self.html\n\n            url_value = scrape_params.get(\"url\", \"\")\n            html_value = scrape_params.get(\"html\", \"\")\n            if (not url_value or not url_value.strip()) and (not html_value or not html_value.strip()):\n                url_or_html_error = \"Either 'url' or 'html' must be provided for scraping\"\n                raise ValueError(url_or_html_error)\n\n            # Process element_prompts with proper type handling\n            element_prompts_list: list[str] = []\n            if self.element_prompts:\n                element_prompts_value: str | list[str] = self.element_prompts\n\n                if isinstance(element_prompts_value, str):\n                    if \",\" not in element_prompts_value:\n                        element_prompts_list = [element_prompts_value]\n                    else:\n                        element_prompts_list = element_prompts_value.split(\",\")\n                elif isinstance(element_prompts_value, list):\n                    element_prompts_list = element_prompts_value\n                else:\n                    # Fallback for other types\n                    element_prompts_list = str(element_prompts_value).split(\",\")\n\n                if len(element_prompts_list) > MAX_ELEMENT_PROMPTS:\n                    max_elements_error = \"Maximum of 5 element prompts allowed\"\n                    raise ValueError(max_elements_error)\n                if len(element_prompts_list) == 0:\n                    invalid_elements_error = \"Element prompts cannot be empty\"\n                    raise ValueError(invalid_elements_error)\n\n                scrape_params[\"element_prompts\"] = element_prompts_list\n\n            if self.root_element_selector:\n                scrape_params[\"root_element_selector\"] = self.root_element_selector\n\n            # Call web scraping\n            response = client.web.ai_scrape(scrape_params)\n\n            if not response.get(\"success\", False):\n                fail_error = \"JigsawStack API request failed.\"\n                raise ValueError(fail_error)\n\n            result_data = response\n\n            self.status = \"AI scrape process is now complete.\"\n\n            return Data(data=result_data)\n\n        except JigsawStackError as e:\n            error_data = {\"error\": str(e), \"success\": False}\n            self.status = f\"Error: {e!s}\"\n            return Data(data=error_data)\n"},"element_prompts":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Element Prompts","dynamic":false,"info":"Items on the page to be scraped (maximum 5). E.g. 'Plan price', 'Plan title'","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"element_prompts","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"html":{"_input_type":"MessageTextInput","advanced":false,"display_name":"HTML","dynamic":false,"info":"HTML content to scrape. Either url or html is required, but not both.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"html","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"root_element_selector":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Root Element Selector","dynamic":false,"info":"CSS selector to limit the scope of scraping to a specific element and its children","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"root_element_selector","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"main"},"url":{"_input_type":"MessageTextInput","advanced":false,"display_name":"URL","dynamic":false,"info":"URL of the page to scrape. Either url or html is required, but not both.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"JigsawStackAISearch":{"base_classes":["Data","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Effortlessly search the Web and get access to high-quality results powered with AI.","display_name":"AI Web Search","documentation":"https://jigsawstack.com/docs/api-reference/web/ai-search","edited":false,"field_order":["api_key","query","ai_overview","safe_search","spell_check"],"frozen":false,"icon":"JigsawStack","legacy":false,"metadata":{"code_hash":"5e821ee44040","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"jigsawstack","version":"0.2.7"}],"total_dependencies":2},"module":"lfx.components.jigsawstack.ai_web_search.JigsawStackAIWebSearchComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"AI Search Results","group_outputs":false,"method":"search","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Content Text","group_outputs":false,"method":"get_content_text","name":"content_text","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","ai_overview":{"_input_type":"BoolInput","advanced":false,"display_name":"AI Overview","dynamic":false,"info":"Include AI powered overview in the search results","list":false,"list_add_label":"Add More","name":"ai_overview","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"JigsawStack API Key","dynamic":false,"info":"Your JigsawStack API key for authentication","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.io import BoolInput, DropdownInput, Output, QueryInput, SecretStrInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.message import Message\n\n\nclass JigsawStackAIWebSearchComponent(Component):\n    display_name = \"AI Web Search\"\n    description = \"Effortlessly search the Web and get access to high-quality results powered with AI.\"\n    documentation = \"https://jigsawstack.com/docs/api-reference/web/ai-search\"\n    icon = \"JigsawStack\"\n    name = \"JigsawStackAISearch\"\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"JigsawStack API Key\",\n            info=\"Your JigsawStack API key for authentication\",\n            required=True,\n        ),\n        QueryInput(\n            name=\"query\",\n            display_name=\"Query\",\n            info=\"The search value. The maximum query character length is 400\",\n            required=True,\n            tool_mode=True,\n        ),\n        BoolInput(\n            name=\"ai_overview\",\n            display_name=\"AI Overview\",\n            info=\"Include AI powered overview in the search results\",\n            required=False,\n            value=True,\n        ),\n        DropdownInput(\n            name=\"safe_search\",\n            display_name=\"Safe Search\",\n            info=\"Enable safe search to filter out adult content\",\n            required=False,\n            options=[\"moderate\", \"strict\", \"off\"],\n            value=\"off\",\n        ),\n        BoolInput(\n            name=\"spell_check\",\n            display_name=\"Spell Check\",\n            info=\"Spell check the search query\",\n            required=False,\n            value=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"AI Search Results\", name=\"search_results\", method=\"search\"),\n        Output(display_name=\"Content Text\", name=\"content_text\", method=\"get_content_text\"),\n    ]\n\n    def search(self) -> Data:\n        try:\n            from jigsawstack import JigsawStack, JigsawStackError\n        except ImportError as e:\n            jigsawstack_import_error = (\n                \"JigsawStack package not found. Please install it using: pip install jigsawstack>=0.2.7\"\n            )\n            raise ImportError(jigsawstack_import_error) from e\n\n        try:\n            client = JigsawStack(api_key=self.api_key)\n\n            # build request object\n            search_params = {}\n            if self.query:\n                search_params[\"query\"] = self.query\n            if self.ai_overview is not None:\n                search_params[\"ai_overview\"] = self.ai_overview\n            if self.safe_search:\n                search_params[\"safe_search\"] = self.safe_search\n            if self.spell_check is not None:\n                search_params[\"spell_check\"] = self.spell_check\n\n            # Call web scraping\n            response = client.web.search(search_params)\n\n            api_error_msg = \"JigsawStack API returned unsuccessful response\"\n            if not response.get(\"success\", False):\n                raise ValueError(api_error_msg)\n\n            # Create comprehensive data object\n            result_data = {\n                \"query\": self.query,\n                \"ai_overview\": response.get(\"ai_overview\", \"\"),\n                \"spell_fixed\": response.get(\"spell_fixed\", False),\n                \"is_safe\": response.get(\"is_safe\", True),\n                \"results\": response.get(\"results\", []),\n                \"success\": True,\n            }\n\n            self.status = f\"Search complete for: {response.get('query', '')}\"\n\n            return Data(data=result_data)\n\n        except JigsawStackError as e:\n            error_data = {\"error\": str(e), \"success\": False}\n            self.status = f\"Error: {e!s}\"\n            return Data(data=error_data)\n\n    def get_content_text(self) -> Message:\n        try:\n            from jigsawstack import JigsawStack, JigsawStackError\n        except ImportError:\n            return Message(text=\"Error: JigsawStack package not found.\")\n\n        try:\n            # Initialize JigsawStack client\n            client = JigsawStack(api_key=self.api_key)\n            search_params = {}\n            if self.query:\n                search_params[\"query\"] = self.query\n            if self.ai_overview is not None:\n                search_params[\"ai_overview\"] = self.ai_overview\n            if self.safe_search:\n                search_params[\"safe_search\"] = self.safe_search\n            if self.spell_check is not None:\n                search_params[\"spell_check\"] = self.spell_check\n\n            # Call web scraping\n            response = client.web.search(search_params)\n\n            request_failed_msg = \"Request Failed\"\n            if not response.get(\"success\", False):\n                raise JigsawStackError(request_failed_msg)\n\n            # Return the content as text\n            content = response.get(\"ai_overview\", \"\")\n            return Message(text=content)\n\n        except JigsawStackError as e:\n            return Message(text=f\"Error while using AI Search: {e!s}\")\n"},"query":{"_input_type":"QueryInput","advanced":false,"display_name":"Query","dynamic":false,"info":"The search value. The maximum query character length is 400","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"query","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"safe_search":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Safe Search","dynamic":false,"external_options":{},"info":"Enable safe search to filter out adult content","name":"safe_search","options":["moderate","strict","off"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"off"},"spell_check":{"_input_type":"BoolInput","advanced":false,"display_name":"Spell Check","dynamic":false,"info":"Spell check the search query","list":false,"list_add_label":"Add More","name":"spell_check","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false},"JigsawStackFileRead":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Read any previously uploaded file seamlessly from         JigsawStack File Storage and use it in your AI applications.","display_name":"File Read","documentation":"https://jigsawstack.com/docs/api-reference/store/file/get","edited":false,"field_order":["api_key","key"],"frozen":false,"icon":"JigsawStack","legacy":false,"metadata":{"code_hash":"84d122f46fb1","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"jigsawstack","version":"0.2.7"}],"total_dependencies":2},"module":"lfx.components.jigsawstack.file_read.JigsawStackFileReadComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"File Path","group_outputs":false,"method":"read_and_save_file","name":"file_path","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"JigsawStack API Key","dynamic":false,"info":"Your JigsawStack API key for authentication","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import tempfile\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import Output, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass JigsawStackFileReadComponent(Component):\n    display_name = \"File Read\"\n    description = \"Read any previously uploaded file seamlessly from \\\n        JigsawStack File Storage and use it in your AI applications.\"\n    documentation = \"https://jigsawstack.com/docs/api-reference/store/file/get\"\n    icon = \"JigsawStack\"\n    name = \"JigsawStackFileRead\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"JigsawStack API Key\",\n            info=\"Your JigsawStack API key for authentication\",\n            required=True,\n        ),\n        StrInput(\n            name=\"key\",\n            display_name=\"Key\",\n            info=\"The key used to retrieve the file from JigsawStack File Storage.\",\n            required=True,\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"File Path\", name=\"file_path\", method=\"read_and_save_file\"),\n    ]\n\n    def read_and_save_file(self) -> Data:\n        \"\"\"Read file from JigsawStack and save to temp file, return file path.\"\"\"\n        try:\n            from jigsawstack import JigsawStack, JigsawStackError\n        except ImportError as e:\n            jigsawstack_import_error = (\n                \"JigsawStack package not found. Please install it using: pip install jigsawstack>=0.2.7\"\n            )\n            raise ImportError(jigsawstack_import_error) from e\n\n        try:\n            client = JigsawStack(api_key=self.api_key)\n            if not self.key or self.key.strip() == \"\":\n                invalid_key_error = \"Key is required to read a file from JigsawStack File Storage.\"\n                raise ValueError(invalid_key_error)\n\n            # Download file content\n            response = client.store.get(self.key)\n\n            # Determine file extension\n            file_extension = self._detect_file_extension(response)\n\n            # Create temporary file\n            with tempfile.NamedTemporaryFile(\n                delete=False, suffix=file_extension, prefix=f\"jigsawstack_{self.key}_\"\n            ) as temp_file:\n                if isinstance(response, bytes):\n                    temp_file.write(response)\n                else:\n                    # Handle string content\n                    temp_file.write(response.encode(\"utf-8\"))\n\n                temp_path = temp_file.name\n\n            return Data(\n                data={\n                    \"file_path\": temp_path,\n                    \"key\": self.key,\n                    \"file_extension\": file_extension,\n                    \"size\": len(response) if isinstance(response, bytes) else len(str(response)),\n                    \"success\": True,\n                }\n            )\n\n        except JigsawStackError as e:\n            error_data = {\"error\": str(e), \"success\": False}\n            self.status = f\"Error: {e!s}\"\n            return Data(data=error_data)\n\n    def _detect_file_extension(self, content) -> str:\n        \"\"\"Detect file extension based on content headers.\"\"\"\n        if isinstance(content, bytes):\n            # Check magic numbers for common file types\n            if content.startswith(b\"\\xff\\xd8\\xff\"):\n                return \".jpg\"\n            if content.startswith(b\"\\x89PNG\\r\\n\\x1a\\n\"):\n                return \".png\"\n            if content.startswith((b\"GIF87a\", b\"GIF89a\")):\n                return \".gif\"\n            if content.startswith(b\"%PDF\"):\n                return \".pdf\"\n            if content.startswith(b\"PK\\x03\\x04\"):  # ZIP/DOCX/XLSX\n                return \".zip\"\n            if content.startswith(b\"\\x00\\x00\\x01\\x00\"):  # ICO\n                return \".ico\"\n            if content.startswith(b\"RIFF\") and b\"WEBP\" in content[:12]:\n                return \".webp\"\n            if content.startswith((b\"\\xff\\xfb\", b\"\\xff\\xf3\", b\"\\xff\\xf2\")):\n                return \".mp3\"\n            if content.startswith((b\"ftypmp4\", b\"\\x00\\x00\\x00\\x20ftypmp4\")):\n                return \".mp4\"\n            # Try to decode as text\n            try:\n                content.decode(\"utf-8\")\n                return \".txt\"  # noqa: TRY300\n            except UnicodeDecodeError:\n                return \".bin\"  # Binary file\n        else:\n            # String content\n            return \".txt\"\n"},"key":{"_input_type":"StrInput","advanced":false,"display_name":"Key","dynamic":false,"info":"The key used to retrieve the file from JigsawStack File Storage.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"key","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"JigsawStackFileUpload":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Store any file seamlessly on JigsawStack File Storage and use it in your AI applications.         Supports various file types including images, documents, and more.","display_name":"File Upload","documentation":"https://jigsawstack.com/docs/api-reference/store/file/add","edited":false,"field_order":["api_key","file","key","overwrite","temp_public_url"],"frozen":false,"icon":"JigsawStack","legacy":false,"metadata":{"code_hash":"8261dc72a655","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"jigsawstack","version":"0.2.7"}],"total_dependencies":2},"module":"lfx.components.jigsawstack.file_upload.JigsawStackFileUploadComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"File Store Result","group_outputs":false,"method":"upload_file","name":"file_upload_result","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"JigsawStack API Key","dynamic":false,"info":"Your JigsawStack API key for authentication","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from pathlib import Path\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import BoolInput, FileInput, Output, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass JigsawStackFileUploadComponent(Component):\n    display_name = \"File Upload\"\n    description = \"Store any file seamlessly on JigsawStack File Storage and use it in your AI applications. \\\n        Supports various file types including images, documents, and more.\"\n    documentation = \"https://jigsawstack.com/docs/api-reference/store/file/add\"\n    icon = \"JigsawStack\"\n    name = \"JigsawStackFileUpload\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"JigsawStack API Key\",\n            info=\"Your JigsawStack API key for authentication\",\n            required=True,\n        ),\n        FileInput(\n            name=\"file\",\n            display_name=\"File\",\n            info=\"Upload file to be stored on JigsawStack File Storage.\",\n            required=True,\n            file_types=[\"pdf\", \"png\", \"jpg\", \"jpeg\", \"mp4\", \"mp3\", \"txt\", \"docx\", \"xlsx\"],\n        ),\n        StrInput(\n            name=\"key\",\n            display_name=\"Key\",\n            info=\"The key used to store the file on JigsawStack File Storage. \\\n                If not provided, a unique key will be generated.\",\n            required=False,\n            tool_mode=True,\n        ),\n        BoolInput(\n            name=\"overwrite\",\n            display_name=\"Overwrite Existing File\",\n            info=\"If true, will overwrite the existing file with the same key. \\\n                If false, will return an error if the file already exists.\",\n            required=False,\n            value=True,\n        ),\n        BoolInput(\n            name=\"temp_public_url\",\n            display_name=\"Return Temporary Public URL\",\n            info=\"If true, will return a temporary public URL which lasts for a limited time. \\\n                If false, will return the file store key which can only be accessed by the owner.\",\n            required=False,\n            value=False,\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"File Store Result\", name=\"file_upload_result\", method=\"upload_file\"),\n    ]\n\n    def upload_file(self) -> Data:\n        try:\n            from jigsawstack import JigsawStack, JigsawStackError\n        except ImportError as e:\n            jigsawstack_import_error = (\n                \"JigsawStack package not found. Please install it using: pip install jigsawstack>=0.2.7\"\n            )\n            raise ImportError(jigsawstack_import_error) from e\n\n        try:\n            client = JigsawStack(api_key=self.api_key)\n\n            file_path = Path(self.file)\n            with Path.open(file_path, \"rb\") as f:\n                file_content = f.read()\n            params = {}\n\n            if self.key:\n                # if key is provided, use it as the file store key\n                params[\"key\"] = self.key\n            if self.overwrite is not None:\n                # if overwrite is provided, use it to determine if the file should be overwritten\n                params[\"overwrite\"] = self.overwrite\n            if self.temp_public_url is not None:\n                # if temp_public_url is provided, use it to determine if a temporary public URL should\n                params[\"temp_public_url\"] = self.temp_public_url\n\n            response = client.store.upload(file_content, params)\n            return Data(data=response)\n\n        except JigsawStackError as e:\n            error_data = {\"error\": str(e), \"success\": False}\n            self.status = f\"Error: {e!s}\"\n            return Data(data=error_data)\n"},"file":{"_input_type":"FileInput","advanced":false,"display_name":"File","dynamic":false,"fileTypes":["pdf","png","jpg","jpeg","mp4","mp3","txt","docx","xlsx"],"file_path":"","info":"Upload file to be stored on JigsawStack File Storage.","list":false,"list_add_label":"Add More","name":"file","placeholder":"","required":true,"show":true,"temp_file":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"file","value":""},"key":{"_input_type":"StrInput","advanced":false,"display_name":"Key","dynamic":false,"info":"The key used to store the file on JigsawStack File Storage.                 If not provided, a unique key will be generated.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_metadata":true,"type":"str","value":""},"overwrite":{"_input_type":"BoolInput","advanced":false,"display_name":"Overwrite Existing File","dynamic":false,"info":"If true, will overwrite the existing file with the same key.                 If false, will return an error if the file already exists.","list":false,"list_add_label":"Add More","name":"overwrite","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"temp_public_url":{"_input_type":"BoolInput","advanced":false,"display_name":"Return Temporary Public URL","dynamic":false,"info":"If true, will return a temporary public URL which lasts for a limited time.                 If false, will return the file store key which can only be accessed by the owner.","list":false,"list_add_label":"Add More","name":"temp_public_url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false},"JigsawStackImageGeneration":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate an image based on the given text by employing AI models like Flux,         Stable Diffusion, and other top models.","display_name":"Image Generation","documentation":"https://jigsawstack.com/docs/api-reference/ai/image-generation","edited":false,"field_order":["api_key","prompt","aspect_ratio","url","file_store_key","width","height","steps","output_format","negative_prompt","seed","guidance"],"frozen":false,"icon":"JigsawStack","legacy":false,"metadata":{"code_hash":"463f8efbaa18","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"jigsawstack","version":"0.2.7"}],"total_dependencies":2},"module":"lfx.components.jigsawstack.image_generation.JigsawStackImageGenerationComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Image Generation Results","group_outputs":false,"method":"generate_image","name":"image_generation_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"JigsawStack API Key","dynamic":false,"info":"Your JigsawStack API key for authentication","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"aspect_ratio":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Aspect Ratio","dynamic":false,"info":"The aspect ratio of the generated image. Must be one of the following:                '1:1', '16:9', '21:9', '3:2', '2:3', '4:5', '5:4', '3:4', '4:3', '9:16', '9:21'                 Default is 1:1.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"aspect_ratio","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.io import DropdownInput, IntInput, MessageTextInput, Output, SecretStrInput\nfrom lfx.schema.data import Data\n\n\nclass JigsawStackImageGenerationComponent(Component):\n    display_name = \"Image Generation\"\n    description = \"Generate an image based on the given text by employing AI models like Flux, \\\n        Stable Diffusion, and other top models.\"\n    documentation = \"https://jigsawstack.com/docs/api-reference/ai/image-generation\"\n    icon = \"JigsawStack\"\n    name = \"JigsawStackImageGeneration\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"JigsawStack API Key\",\n            info=\"Your JigsawStack API key for authentication\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"prompt\",\n            display_name=\"Prompt\",\n            info=\"The text prompt to generate the image from. Must be between 1-5000 characters.\",\n            required=True,\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"aspect_ratio\",\n            display_name=\"Aspect Ratio\",\n            info=\"The aspect ratio of the generated image. Must be one of the following:\\\n                '1:1', '16:9', '21:9', '3:2', '2:3', '4:5', '5:4', '3:4', '4:3', '9:16', '9:21' \\\n                Default is 1:1.\",\n            required=False,\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"url\",\n            display_name=\"URL\",\n            info=\"A valid URL where the generated image will be sent.\",\n            required=False,\n        ),\n        MessageTextInput(\n            name=\"file_store_key\",\n            display_name=\"File Store Key\",\n            info=\"The key used to store the image on Jigsawstack File Storage. Not required if url is specified.\",\n            required=False,\n            tool_mode=True,\n        ),\n        IntInput(\n            name=\"width\",\n            display_name=\"Width\",\n            info=\"The width of the image. Must be between 256-1920 pixels.\",\n            required=False,\n        ),\n        IntInput(\n            name=\"height\",\n            display_name=\"Height\",\n            info=\"The height of the image. Must be between 256-1920 pixels.\",\n            required=False,\n        ),\n        IntInput(\n            name=\"steps\",\n            display_name=\"Steps\",\n            info=\"The number of denoising steps. Must be between 1-90. \\\n                Higher values produce better quality images but take more time to generate.\",\n            required=False,\n        ),\n        DropdownInput(\n            name=\"output_format\",\n            display_name=\"Output Format\",\n            info=\"The output format of the generated image. Must be one of the following values:\\\n                png or svg\",\n            required=False,\n            options=[\"png\", \"svg\"],\n            value=\"png\",\n        ),\n        MessageTextInput(\n            name=\"negative_prompt\",\n            display_name=\"Negative Prompt\",\n            info=\"The text prompt to avoid in the generated image. \\\n                Must be between 1-5000 characters.\",\n            required=False,\n            tool_mode=True,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"Makes generation deterministic.\\\n                Using the same seed and set of parameters will produce identical image each time.\",\n            required=False,\n            tool_mode=True,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"guidance\",\n            display_name=\"Guidance Scale\",\n            info=\"Higher guidance forces the model to better follow the prompt, \\\n                but may result in lower quality output. Must be between 1-28.\",\n            required=False,\n            tool_mode=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Image Generation Results\", name=\"image_generation_results\", method=\"generate_image\"),\n    ]\n\n    def generate_image(self) -> Data:\n        try:\n            from jigsawstack import JigsawStack, JigsawStackError\n        except ImportError as e:\n            jigsawstack_import_error = (\n                \"JigsawStack package not found. Please install it using: pip install jigsawstack>=0.2.7\"\n            )\n            raise ImportError(jigsawstack_import_error) from e\n\n        try:\n            min_character_length = 1\n            max_character_length = 5000\n            min_width = 256\n            max_width = 1920\n            min_height = 256\n            max_height = 1920\n            min_steps = 1\n            max_steps = 90\n            client = JigsawStack(api_key=self.api_key)\n\n            if not self.prompt or len(self.prompt) < min_character_length or len(self.prompt) > max_character_length:\n                invalid_prompt_error = f\"Prompts must be between \\\n                    {min_character_length}-{max_character_length} characters.\"\n                raise ValueError(invalid_prompt_error)\n\n            if self.aspect_ratio and self.aspect_ratio not in [\n                \"1:1\",\n                \"16:9\",\n                \"21:9\",\n                \"3:2\",\n                \"2:3\",\n                \"4:5\",\n                \"5:4\",\n                \"3:4\",\n                \"4:3\",\n                \"9:16\",\n                \"9:21\",\n            ]:\n                invalid_aspect_ratio_error = (\n                    \"Aspect ratio must be one of the following: '1:1', '16:9', '21:9', '3:2', '2:3', \"\n                    \"'4:5', '5:4', '3:4', '4:3', '9:16', '9:21'.\"\n                )\n                raise ValueError(invalid_aspect_ratio_error)\n            if self.width and (self.width < min_width or self.width > max_width):\n                invalid_width_error = f\"Width must be between {min_width}-{max_width} pixels.\"\n                raise ValueError(invalid_width_error)\n            if self.height and (self.height < min_height or self.height > max_height):\n                invalid_height_error = f\"Height must be between {min_height}-{max_height} pixels.\"\n                raise ValueError(invalid_height_error)\n            if self.steps and (self.steps < min_steps or self.steps > max_steps):\n                invalid_steps_error = f\"Steps must be between {min_steps}-{max_steps}.\"\n                raise ValueError(invalid_steps_error)\n\n            params = {}\n            if self.prompt:\n                params[\"prompt\"] = self.prompt.strip()\n            if self.aspect_ratio:\n                params[\"aspect_ratio\"] = self.aspect_ratio.strip()\n            if self.url:\n                params[\"url\"] = self.url.strip()\n            if self.file_store_key:\n                params[\"file_store_key\"] = self.file_store_key.strip()\n            if self.width:\n                params[\"width\"] = self.width\n            if self.height:\n                params[\"height\"] = self.height\n            params[\"return_type\"] = \"url\"\n            if self.output_format:\n                params[\"output_format\"] = self.output_format.strip()\n            if self.steps:\n                params[\"steps\"] = self.steps\n\n            # Initialize advance_config if any advanced parameters are provided\n            if self.negative_prompt or self.seed or self.guidance:\n                params[\"advance_config\"] = {}\n            if self.negative_prompt:\n                params[\"advance_config\"][\"negative_prompt\"] = self.negative_prompt\n            if self.seed:\n                params[\"advance_config\"][\"seed\"] = self.seed\n            if self.guidance:\n                params[\"advance_config\"][\"guidance\"] = self.guidance\n\n            # Call image generation\n            response = client.image_generation(params)\n\n            if response.get(\"url\", None) is None or response.get(\"url\", None).strip() == \"\":\n                failed_response_error = \"JigsawStack API returned unsuccessful response\"\n                raise ValueError(failed_response_error)\n\n            return Data(data=response)\n\n        except JigsawStackError as e:\n            error_data = {\"error\": str(e), \"success\": False}\n            self.status = f\"Error: {e!s}\"\n            return Data(data=error_data)\n"},"file_store_key":{"_input_type":"MessageTextInput","advanced":false,"display_name":"File Store Key","dynamic":false,"info":"The key used to store the image on Jigsawstack File Storage. Not required if url is specified.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"file_store_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"guidance":{"_input_type":"IntInput","advanced":true,"display_name":"Guidance Scale","dynamic":false,"info":"Higher guidance forces the model to better follow the prompt,                 but may result in lower quality output. Must be between 1-28.","list":false,"list_add_label":"Add More","name":"guidance","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_metadata":true,"type":"int","value":""},"height":{"_input_type":"IntInput","advanced":false,"display_name":"Height","dynamic":false,"info":"The height of the image. Must be between 256-1920 pixels.","list":false,"list_add_label":"Add More","name":"height","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"negative_prompt":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Negative Prompt","dynamic":false,"info":"The text prompt to avoid in the generated image.                 Must be between 1-5000 characters.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"negative_prompt","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"output_format":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Output Format","dynamic":false,"external_options":{},"info":"The output format of the generated image. Must be one of the following values:                png or svg","name":"output_format","options":["png","svg"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"png"},"prompt":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Prompt","dynamic":false,"info":"The text prompt to generate the image from. Must be between 1-5000 characters.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"prompt","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"seed":{"_input_type":"IntInput","advanced":true,"display_name":"Seed","dynamic":false,"info":"Makes generation deterministic.                Using the same seed and set of parameters will produce identical image each time.","list":false,"list_add_label":"Add More","name":"seed","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_metadata":true,"type":"int","value":""},"steps":{"_input_type":"IntInput","advanced":false,"display_name":"Steps","dynamic":false,"info":"The number of denoising steps. Must be between 1-90.                 Higher values produce better quality images but take more time to generate.","list":false,"list_add_label":"Add More","name":"steps","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"url":{"_input_type":"MessageTextInput","advanced":false,"display_name":"URL","dynamic":false,"info":"A valid URL where the generated image will be sent.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"width":{"_input_type":"IntInput","advanced":false,"display_name":"Width","dynamic":false,"info":"The width of the image. Must be between 256-1920 pixels.","list":false,"list_add_label":"Add More","name":"width","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""}},"tool_mode":false},"JigsawStackNSFW":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Detect if image/video contains NSFW content","display_name":"NSFW Detection","documentation":"https://jigsawstack.com/docs/api-reference/ai/nsfw","edited":false,"field_order":["api_key","url"],"frozen":false,"icon":"JigsawStack","legacy":false,"metadata":{"code_hash":"88b5eee38906","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"jigsawstack","version":"0.2.7"}],"total_dependencies":2},"module":"lfx.components.jigsawstack.nsfw.JigsawStackNSFWComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"NSFW Analysis","group_outputs":false,"method":"detect_nsfw","name":"nsfw_result","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"JigsawStack API Key","dynamic":false,"info":"Your JigsawStack API key for authentication","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.io import Output, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass JigsawStackNSFWComponent(Component):\n    display_name = \"NSFW Detection\"\n    description = \"Detect if image/video contains NSFW content\"\n    documentation = \"https://jigsawstack.com/docs/api-reference/ai/nsfw\"\n    icon = \"JigsawStack\"\n    name = \"JigsawStackNSFW\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"JigsawStack API Key\",\n            info=\"Your JigsawStack API key for authentication\",\n            required=True,\n        ),\n        StrInput(\n            name=\"url\",\n            display_name=\"URL\",\n            info=\"URL of the image or video to analyze\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"NSFW Analysis\", name=\"nsfw_result\", method=\"detect_nsfw\"),\n    ]\n\n    def detect_nsfw(self) -> Data:\n        try:\n            from jigsawstack import JigsawStack, JigsawStackError\n        except ImportError as e:\n            jigsawstack_import_error = (\n                \"JigsawStack package not found. Please install it using: pip install jigsawstack>=0.2.7\"\n            )\n            raise ImportError(jigsawstack_import_error) from e\n\n        try:\n            client = JigsawStack(api_key=self.api_key)\n\n            # Build request parameters\n            params = {\"url\": self.url}\n\n            response = client.validate.nsfw(params)\n\n            api_error_msg = \"JigsawStack API returned unsuccessful response\"\n            if not response.get(\"success\", False):\n                raise ValueError(api_error_msg)\n\n            return Data(data=response)\n\n        except ValueError:\n            raise\n        except JigsawStackError as e:\n            error_data = {\"error\": str(e), \"success\": False}\n            self.status = f\"Error: {e!s}\"\n            return Data(data=error_data)\n"},"url":{"_input_type":"StrInput","advanced":false,"display_name":"URL","dynamic":false,"info":"URL of the image or video to analyze","list":false,"list_add_label":"Add More","load_from_db":false,"name":"url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"JigsawStackObjectDetection":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Perform object detection on images using JigsawStack's Object Detection Model,         capable of image grounding, segmentation and computer use.","display_name":"Object Detection","documentation":"https://jigsawstack.com/docs/api-reference/ai/object-detection","edited":false,"field_order":["api_key","prompts","url","file_store_key","annotated_image","features","return_type"],"frozen":false,"icon":"JigsawStack","legacy":false,"metadata":{"code_hash":"fceaf0286f20","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"jigsawstack","version":"0.2.7"}],"total_dependencies":2},"module":"lfx.components.jigsawstack.object_detection.JigsawStackObjectDetectionComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Object Detection results","group_outputs":false,"method":"detect_objects","name":"object_detection_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","annotated_image":{"_input_type":"BoolInput","advanced":false,"display_name":"Return Annotated Image","dynamic":false,"info":"If true, will return an url for annotated image with detected objects.","list":false,"list_add_label":"Add More","name":"annotated_image","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"JigsawStack API Key","dynamic":false,"info":"Your JigsawStack API key for authentication","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.io import BoolInput, DropdownInput, MessageTextInput, Output, SecretStrInput\nfrom lfx.schema.data import Data\n\n\nclass JigsawStackObjectDetectionComponent(Component):\n    display_name = \"Object Detection\"\n    description = \"Perform object detection on images using JigsawStack's Object Detection Model, \\\n        capable of image grounding, segmentation and computer use.\"\n    documentation = \"https://jigsawstack.com/docs/api-reference/ai/object-detection\"\n    icon = \"JigsawStack\"\n    name = \"JigsawStackObjectDetection\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"JigsawStack API Key\",\n            info=\"Your JigsawStack API key for authentication\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"prompts\",\n            display_name=\"Prompts\",\n            info=\"The prompts to ground the object detection model. \\\n                You can pass a list of comma-separated prompts to extract different information from the image.\",\n            required=False,\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"url\",\n            display_name=\"URL\",\n            info=\"The image URL. Not required if file_store_key is specified.\",\n            required=False,\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"file_store_key\",\n            display_name=\"File Store Key\",\n            info=\"The key used to store the image on Jigsawstack File Storage. Not required if url is specified.\",\n            required=False,\n            tool_mode=True,\n        ),\n        BoolInput(\n            name=\"annotated_image\",\n            display_name=\"Return Annotated Image\",\n            info=\"If true, will return an url for annotated image with detected objects.\",\n            required=False,\n            value=True,\n        ),\n        DropdownInput(\n            name=\"features\",\n            display_name=\"Features\",\n            info=\"Select the features to enable for object detection\",\n            required=False,\n            options=[\"object_detection\", \"gui\"],\n            value=[\"object_detection\", \"gui\"],\n        ),\n        DropdownInput(\n            name=\"return_type\",\n            display_name=\"Return Type\",\n            info=\"Select the return type for the object detection results such as masks or annotations.\",\n            required=False,\n            options=[\"url\", \"base64\"],\n            value=\"url\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Object Detection results\", name=\"object_detection_results\", method=\"detect_objects\"),\n    ]\n\n    def detect_objects(self) -> Data:\n        try:\n            from jigsawstack import JigsawStack, JigsawStackError\n        except ImportError as e:\n            jigsawstack_import_error = (\n                \"JigsawStack package not found. Please install it using: pip install jigsawstack>=0.2.7\"\n            )\n            raise ImportError(jigsawstack_import_error) from e\n\n        try:\n            client = JigsawStack(api_key=self.api_key)\n\n            # build request object\n            params = {}\n            if self.prompts:\n                if isinstance(self.prompts, list):\n                    params[\"prompt\"] = self.prompts\n                elif isinstance(self.prompts, str):\n                    if \",\" in self.prompts:\n                        # Split by comma and strip whitespace\n                        params[\"prompt\"] = [p.strip() for p in self.prompts.split(\",\")]\n                    else:\n                        params[\"prompt\"] = [self.prompts.strip()]\n                else:\n                    invalid_prompt_error = \"Prompt must be a list of strings or a single string\"\n                    raise ValueError(invalid_prompt_error)\n            if self.url:\n                params[\"url\"] = self.url\n            if self.file_store_key:\n                params[\"file_store_key\"] = self.file_store_key\n\n            # if both url and file_store_key are not provided, raise an error\n            if not self.url and not self.file_store_key:\n                missing_url_error = \"Either URL or File Store Key must be provided to perform object detection\"\n                raise ValueError(missing_url_error)\n\n            params[\"annotated_image\"] = self.annotated_image\n            if self.features:\n                params[\"features\"] = self.features\n\n            # Call web scraping\n            response = client.vision.object_detection(params)\n\n            if not response.get(\"success\", False):\n                failed_response_error = \"JigsawStack API returned unsuccessful response\"\n                raise ValueError(failed_response_error)\n\n            return Data(data=response)\n\n        except JigsawStackError as e:\n            error_data = {\"error\": str(e), \"success\": False}\n            self.status = f\"Error: {e!s}\"\n            return Data(data=error_data)\n"},"features":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Features","dynamic":false,"external_options":{},"info":"Select the features to enable for object detection","name":"features","options":["object_detection","gui"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":["object_detection","gui"]},"file_store_key":{"_input_type":"MessageTextInput","advanced":false,"display_name":"File Store Key","dynamic":false,"info":"The key used to store the image on Jigsawstack File Storage. Not required if url is specified.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"file_store_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"prompts":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Prompts","dynamic":false,"info":"The prompts to ground the object detection model.                 You can pass a list of comma-separated prompts to extract different information from the image.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"prompts","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"return_type":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Return Type","dynamic":false,"external_options":{},"info":"Select the return type for the object detection results such as masks or annotations.","name":"return_type","options":["url","base64"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"url"},"url":{"_input_type":"MessageTextInput","advanced":false,"display_name":"URL","dynamic":false,"info":"The image URL. Not required if file_store_key is specified.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"JigsawStackSentiment":{"base_classes":["Data","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Analyze sentiment of text using JigsawStack AI","display_name":"Sentiment Analysis","documentation":"https://jigsawstack.com/docs/api-reference/ai/sentiment","edited":false,"field_order":["api_key","text"],"frozen":false,"icon":"JigsawStack","legacy":false,"metadata":{"code_hash":"00d0377e5c2e","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"jigsawstack","version":"0.2.7"}],"total_dependencies":2},"module":"lfx.components.jigsawstack.sentiment.JigsawStackSentimentComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Sentiment Data","group_outputs":false,"method":"analyze_sentiment","name":"sentiment_data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Sentiment Text","group_outputs":false,"method":"get_sentiment_text","name":"sentiment_text","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"JigsawStack API Key","dynamic":false,"info":"Your JigsawStack API key for authentication","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.io import MessageTextInput, Output, SecretStrInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.message import Message\n\n\nclass JigsawStackSentimentComponent(Component):\n    display_name = \"Sentiment Analysis\"\n    description = \"Analyze sentiment of text using JigsawStack AI\"\n    documentation = \"https://jigsawstack.com/docs/api-reference/ai/sentiment\"\n    icon = \"JigsawStack\"\n    name = \"JigsawStackSentiment\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"JigsawStack API Key\",\n            info=\"Your JigsawStack API key for authentication\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"text\",\n            display_name=\"Text\",\n            info=\"Text to analyze for sentiment\",\n            required=True,\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Sentiment Data\", name=\"sentiment_data\", method=\"analyze_sentiment\"),\n        Output(display_name=\"Sentiment Text\", name=\"sentiment_text\", method=\"get_sentiment_text\"),\n    ]\n\n    def analyze_sentiment(self) -> Data:\n        try:\n            from jigsawstack import JigsawStack, JigsawStackError\n        except ImportError as e:\n            jigsawstack_import_error = (\n                \"JigsawStack package not found. Please install it using: pip install jigsawstack>=0.2.7\"\n            )\n            raise ImportError(jigsawstack_import_error) from e\n\n        try:\n            client = JigsawStack(api_key=self.api_key)\n            response = client.sentiment({\"text\": self.text})\n\n            api_error_msg = \"JigsawStack API returned unsuccessful response\"\n            if not response.get(\"success\", False):\n                raise ValueError(api_error_msg)\n\n            sentiment_data = response.get(\"sentiment\", {})\n\n            result_data = {\n                \"text_analyzed\": self.text,\n                \"sentiment\": sentiment_data.get(\"sentiment\", \"Unknown\"),\n                \"emotion\": sentiment_data.get(\"emotion\", \"Unknown\"),\n                \"score\": sentiment_data.get(\"score\", 0.0),\n                \"sentences\": response.get(\"sentences\", []),\n                \"success\": True,\n            }\n\n            self.status = (\n                f\"Sentiment: {sentiment_data.get('sentiment', 'Unknown')} | \"\n                f\"Emotion: {sentiment_data.get('emotion', 'Unknown')} | \"\n                f\"Score: {sentiment_data.get('score', 0.0):.3f}\"\n            )\n\n            return Data(data=result_data)\n\n        except JigsawStackError as e:\n            error_data = {\"error\": str(e), \"text_analyzed\": self.text, \"success\": False}\n            self.status = f\"Error: {e!s}\"\n            return Data(data=error_data)\n\n    def get_sentiment_text(self) -> Message:\n        try:\n            from jigsawstack import JigsawStack, JigsawStackError\n        except ImportError:\n            return Message(text=\"Error: JigsawStack package not found. Please install it with: pip install jigsawstack\")\n\n        try:\n            client = JigsawStack(api_key=self.api_key)\n            response = client.sentiment({\"text\": self.text})\n\n            sentiment_data = response.get(\"sentiment\", {})\n            sentences = response.get(\"sentences\", [])\n\n            # Format the output\n            formatted_output = f\"\"\"Sentiment Analysis Results:\n\nText: {self.text}\n\nOverall Sentiment: {sentiment_data.get(\"sentiment\", \"Unknown\")}\nEmotion: {sentiment_data.get(\"emotion\", \"Unknown\")}\nScore: {sentiment_data.get(\"score\", 0.0):.3f}\n\nSentence-by-sentence Analysis:\n\"\"\"\n\n            for i, sentence in enumerate(sentences, 1):\n                formatted_output += (\n                    f\"{i}. {sentence.get('text', '')}\\n\"\n                    f\"   Sentiment: {sentence.get('sentiment', 'Unknown')} | \"\n                    f\"Emotion: {sentence.get('emotion', 'Unknown')} | \"\n                    f\"Score: {sentence.get('score', 0.0):.3f}\\n\"\n                )\n\n            return Message(text=formatted_output)\n\n        except JigsawStackError as e:\n            return Message(text=f\"Error analyzing sentiment: {e!s}\")\n"},"text":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Text","dynamic":false,"info":"Text to analyze for sentiment","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"text","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"JigsawStackTextToSQL":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Convert natural language to SQL queries using JigsawStack AI","display_name":"Text to SQL","documentation":"https://jigsawstack.com/docs/api-reference/ai/text-to-sql","edited":false,"field_order":["api_key","prompt","sql_schema","file_store_key"],"frozen":false,"icon":"JigsawStack","legacy":false,"metadata":{"code_hash":"30aa0cc15fb8","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"jigsawstack","version":"0.2.7"}],"total_dependencies":2},"module":"lfx.components.jigsawstack.text_to_sql.JigsawStackTextToSQLComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"SQL Query","group_outputs":false,"method":"generate_sql","name":"sql_query","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"JigsawStack API Key","dynamic":false,"info":"Your JigsawStack API key for authentication","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.io import MessageTextInput, Output, QueryInput, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass JigsawStackTextToSQLComponent(Component):\n    display_name = \"Text to SQL\"\n    description = \"Convert natural language to SQL queries using JigsawStack AI\"\n    documentation = \"https://jigsawstack.com/docs/api-reference/ai/text-to-sql\"\n    icon = \"JigsawStack\"\n    name = \"JigsawStackTextToSQL\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"JigsawStack API Key\",\n            info=\"Your JigsawStack API key for authentication\",\n            required=True,\n        ),\n        QueryInput(\n            name=\"prompt\",\n            display_name=\"Prompt\",\n            info=\"Natural language description of the SQL query you want to generate\",\n            required=True,\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"sql_schema\",\n            display_name=\"SQL Schema\",\n            info=(\n                \"The database schema information. Can be a CREATE TABLE statement or schema description. \"\n                \"Specifying this parameter improves SQL generation accuracy by applying \"\n                \"database-specific syntax and optimizations.\"\n            ),\n            required=False,\n            tool_mode=True,\n        ),\n        StrInput(\n            name=\"file_store_key\",\n            display_name=\"File Store Key\",\n            info=(\n                \"The key used to store the database schema on Jigsawstack file Storage. \"\n                \"Not required if sql_schema is specified.\"\n            ),\n            required=False,\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"SQL Query\", name=\"sql_query\", method=\"generate_sql\"),\n    ]\n\n    def generate_sql(self) -> Data:\n        try:\n            from jigsawstack import JigsawStack, JigsawStackError\n        except ImportError as e:\n            jigsawstack_import_error = (\n                \"JigsawStack package not found. Please install it using: pip install jigsawstack>=0.2.7\"\n            )\n            raise ImportError(jigsawstack_import_error) from e\n\n        try:\n            schema_error = \"Either 'sql_schema' or 'file_store_key' must be provided\"\n            if not self.sql_schema and not self.file_store_key:\n                raise ValueError(schema_error)\n\n            # build request object\n            params = {\"prompt\": self.prompt}\n\n            if self.sql_schema:\n                params[\"sql_schema\"] = self.sql_schema\n            if self.file_store_key:\n                params[\"file_store_key\"] = self.file_store_key\n\n            client = JigsawStack(api_key=self.api_key)\n            response = client.text_to_sql(params)\n\n            api_error_msg = \"JigsawStack API returned unsuccessful response\"\n            if not response.get(\"success\", False):\n                raise ValueError(api_error_msg)\n\n            return Data(data=response)\n\n        except ValueError:\n            raise\n        except JigsawStackError as e:\n            error_data = {\"error\": str(e), \"success\": False}\n            self.status = f\"Error: {e!s}\"\n            return Data(data=error_data)\n"},"file_store_key":{"_input_type":"StrInput","advanced":false,"display_name":"File Store Key","dynamic":false,"info":"The key used to store the database schema on Jigsawstack file Storage. Not required if sql_schema is specified.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"file_store_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_metadata":true,"type":"str","value":""},"prompt":{"_input_type":"QueryInput","advanced":false,"display_name":"Prompt","dynamic":false,"info":"Natural language description of the SQL query you want to generate","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"prompt","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"sql_schema":{"_input_type":"MessageTextInput","advanced":false,"display_name":"SQL Schema","dynamic":false,"info":"The database schema information. Can be a CREATE TABLE statement or schema description. Specifying this parameter improves SQL generation accuracy by applying database-specific syntax and optimizations.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"sql_schema","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"JigsawStackTextTranslate":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Translate text from one language to another with support for multiple text formats.","display_name":"Text Translate","documentation":"https://jigsawstack.com/docs/api-reference/ai/translate","edited":false,"field_order":["api_key","target_language","text"],"frozen":false,"icon":"JigsawStack","legacy":false,"metadata":{"code_hash":"46233e19961f","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"jigsawstack","version":"0.2.7"}],"total_dependencies":2},"module":"lfx.components.jigsawstack.text_translate.JigsawStackTextTranslateComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Translation Results","group_outputs":false,"method":"translation","name":"translation_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"JigsawStack API Key","dynamic":false,"info":"Your JigsawStack API key for authentication","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.io import MessageTextInput, Output, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass JigsawStackTextTranslateComponent(Component):\n    display_name = \"Text Translate\"\n    description = \"Translate text from one language to another with support for multiple text formats.\"\n    documentation = \"https://jigsawstack.com/docs/api-reference/ai/translate\"\n    icon = \"JigsawStack\"\n    name = \"JigsawStackTextTranslate\"\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"JigsawStack API Key\",\n            info=\"Your JigsawStack API key for authentication\",\n            required=True,\n        ),\n        StrInput(\n            name=\"target_language\",\n            display_name=\"Target Language\",\n            info=\"The language code of the target language to translate to. \\\n                Language code is identified by a unique ISO 639-1 two-letter code\",\n            required=True,\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"text\",\n            display_name=\"Text\",\n            info=\"The text to translate. This can be a single string or a list of strings. \\\n                If a list is provided, each string will be translated separately.\",\n            required=True,\n            is_list=True,\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Translation Results\", name=\"translation_results\", method=\"translation\"),\n    ]\n\n    def translation(self) -> Data:\n        try:\n            from jigsawstack import JigsawStack, JigsawStackError\n        except ImportError as e:\n            jigsawstack_import_error = (\n                \"JigsawStack package not found. Please install it using: pip install jigsawstack>=0.2.7\"\n            )\n            raise ImportError(jigsawstack_import_error) from e\n\n        try:\n            client = JigsawStack(api_key=self.api_key)\n\n            # build request object\n            params = {}\n            if self.target_language:\n                params[\"target_language\"] = self.target_language\n\n            if self.text:\n                if isinstance(self.text, list):\n                    params[\"text\"] = self.text\n                else:\n                    params[\"text\"] = [self.text]\n\n            # Call web scraping\n            response = client.translate.text(params)\n\n            if not response.get(\"success\", False):\n                failed_response_error = \"JigsawStack API returned unsuccessful response\"\n                raise ValueError(failed_response_error)\n\n            return Data(data=response)\n\n        except JigsawStackError as e:\n            error_data = {\"error\": str(e), \"success\": False}\n            self.status = f\"Error: {e!s}\"\n            return Data(data=error_data)\n"},"target_language":{"_input_type":"StrInput","advanced":false,"display_name":"Target Language","dynamic":false,"info":"The language code of the target language to translate to.                 Language code is identified by a unique ISO 639-1 two-letter code","list":false,"list_add_label":"Add More","load_from_db":false,"name":"target_language","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_metadata":true,"type":"str","value":""},"text":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Text","dynamic":false,"info":"The text to translate. This can be a single string or a list of strings.                 If a list is provided, each string will be translated separately.","input_types":["Message"],"list":true,"list_add_label":"Add More","load_from_db":false,"name":"text","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"JigsawStackVOCR":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Extract data from any document type in a consistent structure with fine-tuned         vLLMs for the highest accuracy","display_name":"VOCR","documentation":"https://jigsawstack.com/docs/api-reference/ai/vocr","edited":false,"field_order":["api_key","prompts","url","file_store_key","page_range_start","page_range_end"],"frozen":false,"icon":"JigsawStack","legacy":false,"metadata":{"code_hash":"a44491947ba7","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"jigsawstack","version":"0.2.7"}],"total_dependencies":2},"module":"lfx.components.jigsawstack.vocr.JigsawStackVOCRComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"VOCR results","group_outputs":false,"method":"vocr","name":"vocr_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"JigsawStack API Key","dynamic":false,"info":"Your JigsawStack API key for authentication","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.io import IntInput, MessageTextInput, Output, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass JigsawStackVOCRComponent(Component):\n    display_name = \"VOCR\"\n    description = \"Extract data from any document type in a consistent structure with fine-tuned \\\n        vLLMs for the highest accuracy\"\n    documentation = \"https://jigsawstack.com/docs/api-reference/ai/vocr\"\n    icon = \"JigsawStack\"\n    name = \"JigsawStackVOCR\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"JigsawStack API Key\",\n            info=\"Your JigsawStack API key for authentication\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"prompts\",\n            display_name=\"Prompts\",\n            info=\"The prompts used to describe the image. Default prompt is Describe the image in detail. \\\n                You can pass a list of comma-separated prompts to extract different information from the image.\",\n            required=False,\n            tool_mode=True,\n        ),\n        StrInput(\n            name=\"url\",\n            display_name=\"URL\",\n            info=\"The image or document url. Not required if file_store_key is specified.\",\n            required=False,\n            tool_mode=True,\n        ),\n        StrInput(\n            name=\"file_store_key\",\n            display_name=\"File Store Key\",\n            info=\"The key used to store the image on Jigsawstack File Storage. Not required if url is specified.\",\n            required=False,\n            tool_mode=True,\n        ),\n        IntInput(\n            name=\"page_range_start\",\n            display_name=\"Page Range\",\n            info=\"Page range start limit for the document. If not specified, all pages will be processed.\",\n            required=False,\n        ),\n        IntInput(\n            name=\"page_range_end\",\n            display_name=\"Page Range End\",\n            info=\"Page range end limit for the document. If not specified, all pages will be processed.\",\n            required=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"VOCR results\", name=\"vocr_results\", method=\"vocr\"),\n    ]\n\n    def vocr(self) -> Data:\n        try:\n            from jigsawstack import JigsawStack, JigsawStackError\n        except ImportError as e:\n            jigsawstack_import_error = (\n                \"JigsawStack package not found. Please install it using: pip install jigsawstack>=0.2.7\"\n            )\n            raise ImportError(jigsawstack_import_error) from e\n\n        try:\n            client = JigsawStack(api_key=self.api_key)\n\n            # build request object\n            params = {}\n            if self.prompts:\n                if isinstance(self.prompts, list):\n                    params[\"prompt\"] = self.prompts\n                elif isinstance(self.prompts, str):\n                    if \",\" in self.prompts:\n                        # Split by comma and strip whitespace\n                        params[\"prompt\"] = [p.strip() for p in self.prompts.split(\",\")]\n                    else:\n                        params[\"prompt\"] = [self.prompts.strip()]\n                else:\n                    invalid_prompt_error = \"Prompt must be a list of strings or a single string\"\n                    raise ValueError(invalid_prompt_error)\n            if self.url:\n                params[\"url\"] = self.url\n            if self.file_store_key:\n                params[\"file_store_key\"] = self.file_store_key\n\n            if self.page_range_start and self.page_range_end:\n                params[\"page_range\"] = [self.page_range_start, self.page_range_end]\n\n            # Call VOCR\n            response = client.vision.vocr(params)\n\n            if not response.get(\"success\", False):\n                failed_response_error = \"JigsawStack API returned unsuccessful response\"\n                raise ValueError(failed_response_error)\n\n            return Data(data=response)\n\n        except JigsawStackError as e:\n            error_data = {\"error\": str(e), \"success\": False}\n            self.status = f\"Error: {e!s}\"\n            return Data(data=error_data)\n"},"file_store_key":{"_input_type":"StrInput","advanced":false,"display_name":"File Store Key","dynamic":false,"info":"The key used to store the image on Jigsawstack File Storage. Not required if url is specified.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"file_store_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_metadata":true,"type":"str","value":""},"page_range_end":{"_input_type":"IntInput","advanced":false,"display_name":"Page Range End","dynamic":false,"info":"Page range end limit for the document. If not specified, all pages will be processed.","list":false,"list_add_label":"Add More","name":"page_range_end","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"page_range_start":{"_input_type":"IntInput","advanced":false,"display_name":"Page Range","dynamic":false,"info":"Page range start limit for the document. If not specified, all pages will be processed.","list":false,"list_add_label":"Add More","name":"page_range_start","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"prompts":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Prompts","dynamic":false,"info":"The prompts used to describe the image. Default prompt is Describe the image in detail.                 You can pass a list of comma-separated prompts to extract different information from the image.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"prompts","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"url":{"_input_type":"StrInput","advanced":false,"display_name":"URL","dynamic":false,"info":"The image or document url. Not required if file_store_key is specified.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["knowledge_bases",{"KnowledgeIngestion":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Create or update knowledge in Langflow.","display_name":"Knowledge Ingestion","documentation":"","edited":false,"field_order":["knowledge_base","input_df","column_config","chunk_size","api_key","allow_duplicates"],"frozen":false,"icon":"upload","legacy":false,"metadata":{"code_hash":"c753e92261ae","dependencies":{"dependencies":[{"name":"pandas","version":"2.2.3"},{"name":"cryptography","version":"43.0.3"},{"name":"langchain_chroma","version":"0.2.6"},{"name":"langflow","version":null},{"name":"lfx","version":null},{"name":"langchain_openai","version":"0.3.23"},{"name":"langchain_huggingface","version":"0.3.1"},{"name":"langchain_cohere","version":"0.3.3"}],"total_dependencies":8},"module":"lfx.components.knowledge_bases.ingestion.KnowledgeIngestionComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Results","group_outputs":false,"method":"build_kb_info","name":"dataframe_output","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","allow_duplicates":{"_input_type":"BoolInput","advanced":true,"display_name":"Allow Duplicates","dynamic":false,"info":"Allow duplicate rows in the knowledge base","list":false,"list_add_label":"Add More","name":"allow_duplicates","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"api_key":{"_input_type":"SecretStrInput","advanced":true,"display_name":"Embedding Provider API Key","dynamic":false,"info":"API key for the embedding provider to generate embeddings.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"chunk_size":{"_input_type":"IntInput","advanced":true,"display_name":"Chunk Size","dynamic":false,"info":"Batch size for processing embeddings","list":false,"list_add_label":"Add More","name":"chunk_size","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1000},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from __future__ import annotations\n\nimport asyncio\nimport contextlib\nimport hashlib\nimport json\nimport re\nimport uuid\nfrom dataclasses import asdict, dataclass, field\nfrom datetime import datetime, timezone\nfrom pathlib import Path\nfrom typing import TYPE_CHECKING, Any\n\nimport pandas as pd\nfrom cryptography.fernet import InvalidToken\nfrom langchain_chroma import Chroma\nfrom langflow.services.auth.utils import decrypt_api_key, encrypt_api_key\nfrom langflow.services.database.models.user.crud import get_user_by_id\n\nfrom lfx.base.knowledge_bases.knowledge_base_utils import get_knowledge_bases\nfrom lfx.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom lfx.components.processing.converter import convert_to_dataframe\nfrom lfx.custom import Component\nfrom lfx.io import (\n    BoolInput,\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    Output,\n    SecretStrInput,\n    StrInput,\n    TableInput,\n)\nfrom lfx.schema.data import Data\nfrom lfx.schema.table import EditMode\nfrom lfx.services.deps import (\n    get_settings_service,\n    get_variable_service,\n    session_scope,\n)\n\nif TYPE_CHECKING:\n    from lfx.schema.dataframe import DataFrame\n\nHUGGINGFACE_MODEL_NAMES = [\n    \"sentence-transformers/all-MiniLM-L6-v2\",\n    \"sentence-transformers/all-mpnet-base-v2\",\n]\nCOHERE_MODEL_NAMES = [\"embed-english-v3.0\", \"embed-multilingual-v3.0\"]\n\n_KNOWLEDGE_BASES_ROOT_PATH: Path | None = None\n\n\ndef _get_knowledge_bases_root_path() -> Path:\n    \"\"\"Lazy load the knowledge bases root path from settings.\"\"\"\n    global _KNOWLEDGE_BASES_ROOT_PATH  # noqa: PLW0603\n    if _KNOWLEDGE_BASES_ROOT_PATH is None:\n        settings = get_settings_service().settings\n        knowledge_directory = settings.knowledge_bases_dir\n        if not knowledge_directory:\n            msg = \"Knowledge bases directory is not set in the settings.\"\n            raise ValueError(msg)\n        _KNOWLEDGE_BASES_ROOT_PATH = Path(knowledge_directory).expanduser()\n    return _KNOWLEDGE_BASES_ROOT_PATH\n\n\nclass KnowledgeIngestionComponent(Component):\n    \"\"\"Create or append to Langflow Knowledge from a DataFrame.\"\"\"\n\n    # ------ UI metadata ---------------------------------------------------\n    display_name = \"Knowledge Ingestion\"\n    description = \"Create or update knowledge in Langflow.\"\n    icon = \"upload\"\n    name = \"KnowledgeIngestion\"\n\n    def __init__(self, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n        self._cached_kb_path: Path | None = None\n\n    @dataclass\n    class NewKnowledgeBaseInput:\n        functionality: str = \"create\"\n        fields: dict[str, dict] = field(\n            default_factory=lambda: {\n                \"data\": {\n                    \"node\": {\n                        \"name\": \"create_knowledge_base\",\n                        \"description\": \"Create new knowledge in Langflow.\",\n                        \"display_name\": \"Create new knowledge\",\n                        \"field_order\": [\n                            \"01_new_kb_name\",\n                            \"02_embedding_model\",\n                            \"03_api_key\",\n                        ],\n                        \"template\": {\n                            \"01_new_kb_name\": StrInput(\n                                name=\"new_kb_name\",\n                                display_name=\"Knowledge Name\",\n                                info=\"Name of the new knowledge to create.\",\n                                required=True,\n                            ),\n                            \"02_embedding_model\": DropdownInput(\n                                name=\"embedding_model\",\n                                display_name=\"Choose Embedding\",\n                                info=\"Select the embedding model to use for this knowledge base.\",\n                                required=True,\n                                options=OPENAI_EMBEDDING_MODEL_NAMES + HUGGINGFACE_MODEL_NAMES + COHERE_MODEL_NAMES,\n                                options_metadata=[{\"icon\": \"OpenAI\"} for _ in OPENAI_EMBEDDING_MODEL_NAMES]\n                                + [{\"icon\": \"HuggingFace\"} for _ in HUGGINGFACE_MODEL_NAMES]\n                                + [{\"icon\": \"Cohere\"} for _ in COHERE_MODEL_NAMES],\n                            ),\n                            \"03_api_key\": SecretStrInput(\n                                name=\"api_key\",\n                                display_name=\"API Key\",\n                                info=\"Provider API key for embedding model\",\n                                required=True,\n                                load_from_db=False,\n                            ),\n                        },\n                    },\n                }\n            }\n        )\n\n    # ------ Inputs --------------------------------------------------------\n    inputs = [\n        DropdownInput(\n            name=\"knowledge_base\",\n            display_name=\"Knowledge\",\n            info=\"Select the knowledge to load data from.\",\n            required=True,\n            options=[],\n            refresh_button=True,\n            real_time_refresh=True,\n            dialog_inputs=asdict(NewKnowledgeBaseInput()),\n        ),\n        HandleInput(\n            name=\"input_df\",\n            display_name=\"Input\",\n            info=(\n                \"Table with all original columns (already chunked / processed). \"\n                \"Accepts Data or DataFrame. If Data is provided, it is converted to a DataFrame automatically.\"\n            ),\n            input_types=[\"Data\", \"DataFrame\"],\n            required=True,\n        ),\n        TableInput(\n            name=\"column_config\",\n            display_name=\"Column Configuration\",\n            info=\"Configure column behavior for the knowledge base.\",\n            required=True,\n            table_schema=[\n                {\n                    \"name\": \"column_name\",\n                    \"display_name\": \"Column Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Name of the column in the source DataFrame\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"vectorize\",\n                    \"display_name\": \"Vectorize\",\n                    \"type\": \"boolean\",\n                    \"description\": \"Create embeddings for this column\",\n                    \"default\": False,\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"identifier\",\n                    \"display_name\": \"Identifier\",\n                    \"type\": \"boolean\",\n                    \"description\": \"Use this column as unique identifier\",\n                    \"default\": False,\n                    \"edit_mode\": EditMode.INLINE,\n                },\n            ],\n            value=[\n                {\n                    \"column_name\": \"text\",\n                    \"vectorize\": True,\n                    \"identifier\": True,\n                },\n            ],\n        ),\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"Batch size for processing embeddings\",\n            advanced=True,\n            value=1000,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Embedding Provider API Key\",\n            info=\"API key for the embedding provider to generate embeddings.\",\n            advanced=True,\n            required=False,\n        ),\n        BoolInput(\n            name=\"allow_duplicates\",\n            display_name=\"Allow Duplicates\",\n            info=\"Allow duplicate rows in the knowledge base\",\n            advanced=True,\n            value=False,\n        ),\n    ]\n\n    # ------ Outputs -------------------------------------------------------\n    outputs = [Output(display_name=\"Results\", name=\"dataframe_output\", method=\"build_kb_info\")]\n\n    # ------ Internal helpers ---------------------------------------------\n    def _get_kb_root(self) -> Path:\n        \"\"\"Return the root directory for knowledge bases.\"\"\"\n        return _get_knowledge_bases_root_path()\n\n    def _validate_column_config(self, df_source: pd.DataFrame) -> list[dict[str, Any]]:\n        \"\"\"Validate column configuration using Structured Output patterns.\"\"\"\n        if not self.column_config:\n            msg = \"Column configuration cannot be empty\"\n            raise ValueError(msg)\n\n        # Convert table input to list of dicts (similar to Structured Output)\n        config_list = self.column_config if isinstance(self.column_config, list) else []\n\n        # Validate column names exist in DataFrame\n        df_columns = set(df_source.columns)\n        for config in config_list:\n            col_name = config.get(\"column_name\")\n            if col_name not in df_columns:\n                msg = f\"Column '{col_name}' not found in DataFrame. Available columns: {sorted(df_columns)}\"\n                raise ValueError(msg)\n\n        return config_list\n\n    def _get_embedding_provider(self, embedding_model: str) -> str:\n        \"\"\"Get embedding provider by matching model name to lists.\"\"\"\n        if embedding_model in OPENAI_EMBEDDING_MODEL_NAMES:\n            return \"OpenAI\"\n        if embedding_model in HUGGINGFACE_MODEL_NAMES:\n            return \"HuggingFace\"\n        if embedding_model in COHERE_MODEL_NAMES:\n            return \"Cohere\"\n        return \"Custom\"\n\n    def _build_embeddings(self, embedding_model: str, api_key: str):\n        \"\"\"Build embedding model using provider patterns.\"\"\"\n        # Get provider by matching model name to lists\n        provider = self._get_embedding_provider(embedding_model)\n\n        # Validate provider and model\n        if provider == \"OpenAI\":\n            from langchain_openai import OpenAIEmbeddings\n\n            if not api_key:\n                msg = \"OpenAI API key is required when using OpenAI provider\"\n                raise ValueError(msg)\n            return OpenAIEmbeddings(\n                model=embedding_model,\n                api_key=api_key,\n                chunk_size=self.chunk_size,\n            )\n        if provider == \"HuggingFace\":\n            from langchain_huggingface import HuggingFaceEmbeddings\n\n            return HuggingFaceEmbeddings(\n                model=embedding_model,\n            )\n        if provider == \"Cohere\":\n            from langchain_cohere import CohereEmbeddings\n\n            if not api_key:\n                msg = \"Cohere API key is required when using Cohere provider\"\n                raise ValueError(msg)\n            return CohereEmbeddings(\n                model=embedding_model,\n                cohere_api_key=api_key,\n            )\n        if provider == \"Custom\":\n            # For custom embedding models, we would need additional configuration\n            msg = \"Custom embedding models not yet supported\"\n            raise NotImplementedError(msg)\n        msg = f\"Unknown provider: {provider}\"\n        raise ValueError(msg)\n\n    def _build_embedding_metadata(self, embedding_model, api_key) -> dict[str, Any]:\n        \"\"\"Build embedding model metadata.\"\"\"\n        # Get provider by matching model name to lists\n        embedding_provider = self._get_embedding_provider(embedding_model)\n\n        api_key_to_save = None\n        if api_key and hasattr(api_key, \"get_secret_value\"):\n            api_key_to_save = api_key.get_secret_value()\n        elif isinstance(api_key, str):\n            api_key_to_save = api_key\n\n        encrypted_api_key = None\n        if api_key_to_save:\n            settings_service = get_settings_service()\n            try:\n                encrypted_api_key = encrypt_api_key(api_key_to_save, settings_service=settings_service)\n            except (TypeError, ValueError) as e:\n                self.log(f\"Could not encrypt API key: {e}\")\n\n        return {\n            \"embedding_provider\": embedding_provider,\n            \"embedding_model\": embedding_model,\n            \"api_key\": encrypted_api_key,\n            \"api_key_used\": bool(api_key),\n            \"chunk_size\": self.chunk_size,\n            \"created_at\": datetime.now(timezone.utc).isoformat(),\n        }\n\n    def _save_embedding_metadata(self, kb_path: Path, embedding_model: str, api_key: str) -> None:\n        \"\"\"Save embedding model metadata.\"\"\"\n        embedding_metadata = self._build_embedding_metadata(embedding_model, api_key)\n        metadata_path = kb_path / \"embedding_metadata.json\"\n        metadata_path.write_text(json.dumps(embedding_metadata, indent=2))\n\n    def _save_kb_files(\n        self,\n        kb_path: Path,\n        config_list: list[dict[str, Any]],\n    ) -> None:\n        \"\"\"Save KB files using File Component storage patterns.\"\"\"\n        try:\n            # Create directory (following File Component patterns)\n            kb_path.mkdir(parents=True, exist_ok=True)\n\n            # Save column configuration\n            # Only do this if the file doesn't exist already\n            cfg_path = kb_path / \"schema.json\"\n            if not cfg_path.exists():\n                cfg_path.write_text(json.dumps(config_list, indent=2))\n\n        except (OSError, TypeError, ValueError) as e:\n            self.log(f\"Error saving KB files: {e}\")\n\n    def _build_column_metadata(self, config_list: list[dict[str, Any]], df_source: pd.DataFrame) -> dict[str, Any]:\n        \"\"\"Build detailed column metadata.\"\"\"\n        metadata: dict[str, Any] = {\n            \"total_columns\": len(df_source.columns),\n            \"mapped_columns\": len(config_list),\n            \"unmapped_columns\": len(df_source.columns) - len(config_list),\n            \"columns\": [],\n            \"summary\": {\"vectorized_columns\": [], \"identifier_columns\": []},\n        }\n\n        for config in config_list:\n            col_name = config.get(\"column_name\")\n            vectorize = config.get(\"vectorize\") == \"True\" or config.get(\"vectorize\") is True\n            identifier = config.get(\"identifier\") == \"True\" or config.get(\"identifier\") is True\n\n            # Add to columns list\n            metadata[\"columns\"].append(\n                {\n                    \"name\": col_name,\n                    \"vectorize\": vectorize,\n                    \"identifier\": identifier,\n                }\n            )\n\n            # Update summary\n            if vectorize:\n                metadata[\"summary\"][\"vectorized_columns\"].append(col_name)\n            if identifier:\n                metadata[\"summary\"][\"identifier_columns\"].append(col_name)\n\n        return metadata\n\n    async def _create_vector_store(\n        self,\n        df_source: pd.DataFrame,\n        config_list: list[dict[str, Any]],\n        embedding_model: str,\n        api_key: str,\n    ) -> None:\n        \"\"\"Create vector store following Local DB component pattern.\"\"\"\n        try:\n            # Set up vector store directory\n            vector_store_dir = await self._kb_path()\n            if not vector_store_dir:\n                msg = \"Knowledge base path is not set. Please create a new knowledge base first.\"\n                raise ValueError(msg)\n            vector_store_dir.mkdir(parents=True, exist_ok=True)\n\n            # Create embeddings model\n            embedding_function = self._build_embeddings(embedding_model, api_key)\n\n            # Convert DataFrame to Data objects (following Local DB pattern)\n            data_objects = await self._convert_df_to_data_objects(df_source, config_list)\n\n            # Create vector store\n            chroma = Chroma(\n                persist_directory=str(vector_store_dir),\n                embedding_function=embedding_function,\n                collection_name=self.knowledge_base,\n            )\n\n            # Convert Data objects to LangChain Documents\n            documents = []\n            for data_obj in data_objects:\n                doc = data_obj.to_lc_document()\n                documents.append(doc)\n\n            # Add documents to vector store\n            if documents:\n                chroma.add_documents(documents)\n                self.log(f\"Added {len(documents)} documents to vector store '{self.knowledge_base}'\")\n\n        except (OSError, ValueError, RuntimeError) as e:\n            self.log(f\"Error creating vector store: {e}\")\n\n    async def _convert_df_to_data_objects(\n        self, df_source: pd.DataFrame, config_list: list[dict[str, Any]]\n    ) -> list[Data]:\n        \"\"\"Convert DataFrame to Data objects for vector store.\"\"\"\n        data_objects: list[Data] = []\n\n        # Set up vector store directory\n        kb_path = await self._kb_path()\n\n        # If we don't allow duplicates, we need to get the existing hashes\n        chroma = Chroma(\n            persist_directory=str(kb_path),\n            collection_name=self.knowledge_base,\n        )\n\n        # Get all documents and their metadata\n        all_docs = chroma.get()\n\n        # Extract all _id values from metadata\n        id_list = [metadata.get(\"_id\") for metadata in all_docs[\"metadatas\"] if metadata.get(\"_id\")]\n\n        # Get column roles\n        content_cols = []\n        identifier_cols = []\n\n        for config in config_list:\n            col_name = config.get(\"column_name\")\n            vectorize = config.get(\"vectorize\") == \"True\" or config.get(\"vectorize\") is True\n            identifier = config.get(\"identifier\") == \"True\" or config.get(\"identifier\") is True\n\n            if vectorize:\n                content_cols.append(col_name)\n            elif identifier:\n                identifier_cols.append(col_name)\n\n        # Convert each row to a Data object\n        for _, row in df_source.iterrows():\n            # Build content text from identifier columns using list comprehension\n            identifier_parts = [str(row[col]) for col in content_cols if col in row and pd.notna(row[col])]\n\n            # Join all parts into a single string\n            page_content = \" \".join(identifier_parts)\n\n            # Build metadata from NON-vectorized columns only (simple key-value pairs)\n            data_dict = {\n                \"text\": page_content,  # Main content for vectorization\n            }\n\n            # Add identifier columns if they exist\n            if identifier_cols:\n                identifier_parts = [str(row[col]) for col in identifier_cols if col in row and pd.notna(row[col])]\n                page_content = \" \".join(identifier_parts)\n\n            # Add metadata columns as simple key-value pairs\n            for col in df_source.columns:\n                if col not in content_cols and col in row and pd.notna(row[col]):\n                    # Convert to simple types for Chroma metadata\n                    value = row[col]\n                    data_dict[col] = str(value)  # Convert complex types to string\n\n            # Hash the page_content for unique ID\n            page_content_hash = hashlib.sha256(page_content.encode()).hexdigest()\n            data_dict[\"_id\"] = page_content_hash\n\n            # If duplicates are disallowed, and hash exists, prevent adding this row\n            if not self.allow_duplicates and page_content_hash in id_list:\n                self.log(f\"Skipping duplicate row with hash {page_content_hash}\")\n                continue\n\n            # Create Data object - everything except \"text\" becomes metadata\n            data_obj = Data(data=data_dict)\n            data_objects.append(data_obj)\n\n        return data_objects\n\n    def is_valid_collection_name(self, name, min_length: int = 3, max_length: int = 63) -> bool:\n        \"\"\"Validates collection name against conditions 1-3.\n\n        1. Contains 3-63 characters\n        2. Starts and ends with alphanumeric character\n        3. Contains only alphanumeric characters, underscores, or hyphens.\n\n        Args:\n            name (str): Collection name to validate\n            min_length (int): Minimum length of the name\n            max_length (int): Maximum length of the name\n\n        Returns:\n            bool: True if valid, False otherwise\n        \"\"\"\n        # Check length (condition 1)\n        if not (min_length <= len(name) <= max_length):\n            return False\n\n        # Check start/end with alphanumeric (condition 2)\n        if not (name[0].isalnum() and name[-1].isalnum()):\n            return False\n\n        # Check allowed characters (condition 3)\n        return re.match(r\"^[a-zA-Z0-9_-]+$\", name) is not None\n\n    async def _kb_path(self) -> Path | None:\n        # Check if we already have the path cached\n        cached_path = getattr(self, \"_cached_kb_path\", None)\n        if cached_path is not None:\n            return cached_path\n\n        # If not cached, compute it\n        async with session_scope() as db:\n            if not self.user_id:\n                msg = \"User ID is required for fetching knowledge base path.\"\n                raise ValueError(msg)\n            current_user = await get_user_by_id(db, self.user_id)\n            if not current_user:\n                msg = f\"User with ID {self.user_id} not found.\"\n                raise ValueError(msg)\n            kb_user = current_user.username\n\n        kb_root = self._get_kb_root()\n\n        # Cache the result\n        self._cached_kb_path = kb_root / kb_user / self.knowledge_base\n\n        return self._cached_kb_path\n\n    # ---------------------------------------------------------------------\n    #                         OUTPUT METHODS\n    # ---------------------------------------------------------------------\n    async def build_kb_info(self) -> Data:\n        \"\"\"Main ingestion routine → returns a dict with KB metadata.\"\"\"\n        try:\n            input_value = self.input_df[0] if isinstance(self.input_df, list) else self.input_df\n            df_source: DataFrame = convert_to_dataframe(input_value, auto_parse=False)\n\n            # Validate column configuration (using Structured Output patterns)\n            config_list = self._validate_column_config(df_source)\n            column_metadata = self._build_column_metadata(config_list, df_source)\n\n            # Read the embedding info from the knowledge base folder\n            kb_path = await self._kb_path()\n            if not kb_path:\n                msg = \"Knowledge base path is not set. Please create a new knowledge base first.\"\n                raise ValueError(msg)\n            metadata_path = kb_path / \"embedding_metadata.json\"\n\n            # If the API key is not provided, try to read it from the metadata file\n            if metadata_path.exists():\n                settings_service = get_settings_service()\n                metadata = json.loads(metadata_path.read_text())\n                embedding_model = metadata.get(\"embedding_model\")\n                try:\n                    api_key = decrypt_api_key(metadata[\"api_key\"], settings_service)\n                except (InvalidToken, TypeError, ValueError) as e:\n                    self.log(f\"Could not decrypt API key. Please provide it manually. Error: {e}\")\n\n            # Check if a custom API key was provided, update metadata if so\n            if self.api_key:\n                api_key = self.api_key\n                self._save_embedding_metadata(\n                    kb_path=kb_path,\n                    embedding_model=embedding_model,\n                    api_key=api_key,\n                )\n\n            # Create vector store following Local DB component pattern\n            await self._create_vector_store(df_source, config_list, embedding_model=embedding_model, api_key=api_key)\n\n            # Save KB files (using File Component storage patterns)\n            self._save_kb_files(kb_path, config_list)\n\n            # Build metadata response\n            meta: dict[str, Any] = {\n                \"kb_id\": str(uuid.uuid4()),\n                \"kb_name\": self.knowledge_base,\n                \"rows\": len(df_source),\n                \"column_metadata\": column_metadata,\n                \"path\": str(kb_path),\n                \"config_columns\": len(config_list),\n                \"timestamp\": datetime.now(tz=timezone.utc).isoformat(),\n            }\n\n            # Set status message\n            self.status = f\"✅ KB **{self.knowledge_base}** saved · {len(df_source)} chunks.\"\n\n            return Data(data=meta)\n\n        except (OSError, ValueError, RuntimeError, KeyError) as e:\n            msg = f\"Error during KB ingestion: {e}\"\n            raise RuntimeError(msg) from e\n\n    async def _get_api_key_variable(self, field_value: dict[str, Any]):\n        async with session_scope() as db:\n            if not self.user_id:\n                msg = \"User ID is required for fetching global variables.\"\n                raise ValueError(msg)\n            current_user = await get_user_by_id(db, self.user_id)\n            if not current_user:\n                msg = f\"User with ID {self.user_id} not found.\"\n                raise ValueError(msg)\n            variable_service = get_variable_service()\n\n            # Process the api_key field variable\n            return await variable_service.get_variable(\n                user_id=current_user.id,\n                name=field_value[\"03_api_key\"],\n                field=\"\",\n                session=db,\n            )\n\n    async def update_build_config(\n        self,\n        build_config,\n        field_value: Any,\n        field_name: str | None = None,\n    ):\n        \"\"\"Update build configuration based on provider selection.\"\"\"\n        # Create a new knowledge base\n        if field_name == \"knowledge_base\":\n            async with session_scope() as db:\n                if not self.user_id:\n                    msg = \"User ID is required for fetching knowledge base list.\"\n                    raise ValueError(msg)\n                current_user = await get_user_by_id(db, self.user_id)\n                if not current_user:\n                    msg = f\"User with ID {self.user_id} not found.\"\n                    raise ValueError(msg)\n                kb_user = current_user.username\n            if isinstance(field_value, dict) and \"01_new_kb_name\" in field_value:\n                # Validate the knowledge base name - Make sure it follows these rules:\n                if not self.is_valid_collection_name(field_value[\"01_new_kb_name\"]):\n                    msg = f\"Invalid knowledge base name: {field_value['01_new_kb_name']}\"\n                    raise ValueError(msg)\n\n                api_key = field_value.get(\"03_api_key\", None)\n                with contextlib.suppress(Exception):\n                    # If the API key is a variable, resolve it\n                    api_key = await self._get_api_key_variable(field_value)\n\n                # Make sure api_key is a string\n                if not isinstance(api_key, str):\n                    msg = \"API key must be a string.\"\n                    raise ValueError(msg)\n\n                # We need to test the API Key one time against the embedding model\n                embed_model = self._build_embeddings(embedding_model=field_value[\"02_embedding_model\"], api_key=api_key)\n\n                # Try to generate a dummy embedding to validate the API key without blocking the event loop\n                try:\n                    await asyncio.wait_for(\n                        asyncio.to_thread(embed_model.embed_query, \"test\"),\n                        timeout=10,\n                    )\n                except TimeoutError as e:\n                    msg = \"Embedding validation timed out. Please verify network connectivity and key.\"\n                    raise ValueError(msg) from e\n                except Exception as e:\n                    msg = f\"Embedding validation failed: {e!s}\"\n                    raise ValueError(msg) from e\n\n                # Create the new knowledge base directory\n                kb_path = _get_knowledge_bases_root_path() / kb_user / field_value[\"01_new_kb_name\"]\n                kb_path.mkdir(parents=True, exist_ok=True)\n\n                # Save the embedding metadata\n                build_config[\"knowledge_base\"][\"value\"] = field_value[\"01_new_kb_name\"]\n                self._save_embedding_metadata(\n                    kb_path=kb_path,\n                    embedding_model=field_value[\"02_embedding_model\"],\n                    api_key=api_key,\n                )\n\n            # Update the knowledge base options dynamically\n            build_config[\"knowledge_base\"][\"options\"] = await get_knowledge_bases(\n                _get_knowledge_bases_root_path(),\n                user_id=self.user_id,\n            )\n\n            # If the selected knowledge base is not available, reset it\n            if build_config[\"knowledge_base\"][\"value\"] not in build_config[\"knowledge_base\"][\"options\"]:\n                build_config[\"knowledge_base\"][\"value\"] = None\n\n        return build_config\n"},"column_config":{"_input_type":"TableInput","advanced":false,"display_name":"Column Configuration","dynamic":false,"info":"Configure column behavior for the knowledge base.","is_list":true,"list_add_label":"Add More","name":"column_config","placeholder":"","required":true,"show":true,"table_icon":"Table","table_schema":[{"description":"Name of the column in the source DataFrame","display_name":"Column Name","edit_mode":"inline","name":"column_name","type":"str"},{"default":false,"description":"Create embeddings for this column","display_name":"Vectorize","edit_mode":"inline","name":"vectorize","type":"boolean"},{"default":false,"description":"Use this column as unique identifier","display_name":"Identifier","edit_mode":"inline","name":"identifier","type":"boolean"}],"title_case":false,"tool_mode":false,"trace_as_metadata":true,"trigger_icon":"Table","trigger_text":"Open table","type":"table","value":[{"column_name":"text","identifier":true,"vectorize":true}]},"input_df":{"_input_type":"HandleInput","advanced":false,"display_name":"Input","dynamic":false,"info":"Table with all original columns (already chunked / processed). Accepts Data or DataFrame. If Data is provided, it is converted to a DataFrame automatically.","input_types":["Data","DataFrame"],"list":false,"list_add_label":"Add More","name":"input_df","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"knowledge_base":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{"fields":{"data":{"node":{"description":"Create new knowledge in Langflow.","display_name":"Create new knowledge","field_order":["01_new_kb_name","02_embedding_model","03_api_key"],"name":"create_knowledge_base","template":{"01_new_kb_name":{"_input_type":"StrInput","advanced":false,"display_name":"Knowledge Name","dynamic":false,"info":"Name of the new knowledge to create.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"new_kb_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"02_embedding_model":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Choose Embedding","dynamic":false,"external_options":{},"info":"Select the embedding model to use for this knowledge base.","name":"embedding_model","options":["text-embedding-3-small","text-embedding-3-large","text-embedding-ada-002","sentence-transformers/all-MiniLM-L6-v2","sentence-transformers/all-mpnet-base-v2","embed-english-v3.0","embed-multilingual-v3.0"],"options_metadata":[{"icon":"OpenAI"},{"icon":"OpenAI"},{"icon":"OpenAI"},{"icon":"HuggingFace"},{"icon":"HuggingFace"},{"icon":"Cohere"},{"icon":"Cohere"}],"placeholder":"","required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"03_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"Provider API key for embedding model","input_types":[],"load_from_db":false,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""}}}}},"functionality":"create"},"display_name":"Knowledge","dynamic":false,"external_options":{},"info":"Select the knowledge to load data from.","name":"knowledge_base","options":[],"options_metadata":[],"placeholder":"","real_time_refresh":true,"refresh_button":true,"required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"KnowledgeRetrieval":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Search and retrieve data from knowledge.","display_name":"Knowledge Retrieval","documentation":"","edited":false,"field_order":["knowledge_base","api_key","search_query","top_k","include_metadata","include_embeddings"],"frozen":false,"icon":"download","legacy":false,"metadata":{"code_hash":"1898acd6df4b","dependencies":{"dependencies":[{"name":"cryptography","version":"43.0.3"},{"name":"langchain_chroma","version":"0.2.6"},{"name":"langflow","version":null},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null},{"name":"langchain_openai","version":"0.3.23"},{"name":"langchain_huggingface","version":"0.3.1"},{"name":"langchain_cohere","version":"0.3.3"}],"total_dependencies":8},"module":"lfx.components.knowledge_bases.retrieval.KnowledgeRetrievalComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Results","group_outputs":false,"method":"retrieve_data","name":"retrieve_data","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":true,"display_name":"Embedding Provider API Key","dynamic":false,"info":"API key for the embedding provider to generate embeddings.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nfrom pathlib import Path\nfrom typing import Any\n\nfrom cryptography.fernet import InvalidToken\nfrom langchain_chroma import Chroma\nfrom langflow.services.auth.utils import decrypt_api_key\nfrom langflow.services.database.models.user.crud import get_user_by_id\nfrom pydantic import SecretStr\n\nfrom lfx.base.knowledge_bases.knowledge_base_utils import get_knowledge_bases\nfrom lfx.custom import Component\nfrom lfx.io import BoolInput, DropdownInput, IntInput, MessageTextInput, Output, SecretStrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.services.deps import get_settings_service, session_scope\n\n_KNOWLEDGE_BASES_ROOT_PATH: Path | None = None\n\n\ndef _get_knowledge_bases_root_path() -> Path:\n    \"\"\"Lazy load the knowledge bases root path from settings.\"\"\"\n    global _KNOWLEDGE_BASES_ROOT_PATH  # noqa: PLW0603\n    if _KNOWLEDGE_BASES_ROOT_PATH is None:\n        settings = get_settings_service().settings\n        knowledge_directory = settings.knowledge_bases_dir\n        if not knowledge_directory:\n            msg = \"Knowledge bases directory is not set in the settings.\"\n            raise ValueError(msg)\n        _KNOWLEDGE_BASES_ROOT_PATH = Path(knowledge_directory).expanduser()\n    return _KNOWLEDGE_BASES_ROOT_PATH\n\n\nclass KnowledgeRetrievalComponent(Component):\n    display_name = \"Knowledge Retrieval\"\n    description = \"Search and retrieve data from knowledge.\"\n    icon = \"download\"\n    name = \"KnowledgeRetrieval\"\n\n    inputs = [\n        DropdownInput(\n            name=\"knowledge_base\",\n            display_name=\"Knowledge\",\n            info=\"Select the knowledge to load data from.\",\n            required=True,\n            options=[],\n            refresh_button=True,\n            real_time_refresh=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Embedding Provider API Key\",\n            info=\"API key for the embedding provider to generate embeddings.\",\n            advanced=True,\n            required=False,\n        ),\n        MessageTextInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n            info=\"Optional search query to filter knowledge base data.\",\n            tool_mode=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K Results\",\n            info=\"Number of top results to return from the knowledge base.\",\n            value=5,\n            advanced=True,\n            required=False,\n        ),\n        BoolInput(\n            name=\"include_metadata\",\n            display_name=\"Include Metadata\",\n            info=\"Whether to include all metadata in the output. If false, only content is returned.\",\n            value=True,\n            advanced=False,\n        ),\n        BoolInput(\n            name=\"include_embeddings\",\n            display_name=\"Include Embeddings\",\n            info=\"Whether to include embeddings in the output. Only applicable if 'Include Metadata' is enabled.\",\n            value=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            name=\"retrieve_data\",\n            display_name=\"Results\",\n            method=\"retrieve_data\",\n            info=\"Returns the data from the selected knowledge base.\",\n        ),\n    ]\n\n    async def update_build_config(self, build_config, field_value, field_name=None):  # noqa: ARG002\n        if field_name == \"knowledge_base\":\n            # Update the knowledge base options dynamically\n            build_config[\"knowledge_base\"][\"options\"] = await get_knowledge_bases(\n                _get_knowledge_bases_root_path(),\n                user_id=self.user_id,  # Use the user_id from the component context\n            )\n\n            # If the selected knowledge base is not available, reset it\n            if build_config[\"knowledge_base\"][\"value\"] not in build_config[\"knowledge_base\"][\"options\"]:\n                build_config[\"knowledge_base\"][\"value\"] = None\n\n        return build_config\n\n    def _get_kb_metadata(self, kb_path: Path) -> dict:\n        \"\"\"Load and process knowledge base metadata.\"\"\"\n        metadata: dict[str, Any] = {}\n        metadata_file = kb_path / \"embedding_metadata.json\"\n        if not metadata_file.exists():\n            logger.warning(f\"Embedding metadata file not found at {metadata_file}\")\n            return metadata\n\n        try:\n            with metadata_file.open(\"r\", encoding=\"utf-8\") as f:\n                metadata = json.load(f)\n        except json.JSONDecodeError:\n            logger.error(f\"Error decoding JSON from {metadata_file}\")\n            return {}\n\n        # Decrypt API key if it exists\n        if \"api_key\" in metadata and metadata.get(\"api_key\"):\n            settings_service = get_settings_service()\n            try:\n                decrypted_key = decrypt_api_key(metadata[\"api_key\"], settings_service)\n                metadata[\"api_key\"] = decrypted_key\n            except (InvalidToken, TypeError, ValueError) as e:\n                logger.error(f\"Could not decrypt API key. Please provide it manually. Error: {e}\")\n                metadata[\"api_key\"] = None\n        return metadata\n\n    def _build_embeddings(self, metadata: dict):\n        \"\"\"Build embedding model from metadata.\"\"\"\n        runtime_api_key = self.api_key.get_secret_value() if isinstance(self.api_key, SecretStr) else self.api_key\n        provider = metadata.get(\"embedding_provider\")\n        model = metadata.get(\"embedding_model\")\n        api_key = runtime_api_key or metadata.get(\"api_key\")\n        chunk_size = metadata.get(\"chunk_size\")\n\n        # Handle various providers\n        if provider == \"OpenAI\":\n            from langchain_openai import OpenAIEmbeddings\n\n            if not api_key:\n                msg = \"OpenAI API key is required. Provide it in the component's advanced settings.\"\n                raise ValueError(msg)\n            return OpenAIEmbeddings(\n                model=model,\n                api_key=api_key,\n                chunk_size=chunk_size,\n            )\n        if provider == \"HuggingFace\":\n            from langchain_huggingface import HuggingFaceEmbeddings\n\n            return HuggingFaceEmbeddings(\n                model=model,\n            )\n        if provider == \"Cohere\":\n            from langchain_cohere import CohereEmbeddings\n\n            if not api_key:\n                msg = \"Cohere API key is required when using Cohere provider\"\n                raise ValueError(msg)\n            return CohereEmbeddings(\n                model=model,\n                cohere_api_key=api_key,\n            )\n        if provider == \"Custom\":\n            # For custom embedding models, we would need additional configuration\n            msg = \"Custom embedding models not yet supported\"\n            raise NotImplementedError(msg)\n        # Add other providers here if they become supported in ingest\n        msg = f\"Embedding provider '{provider}' is not supported for retrieval.\"\n        raise NotImplementedError(msg)\n\n    async def retrieve_data(self) -> DataFrame:\n        \"\"\"Retrieve data from the selected knowledge base by reading the Chroma collection.\n\n        Returns:\n            A DataFrame containing the data rows from the knowledge base.\n        \"\"\"\n        # Get the current user\n        async with session_scope() as db:\n            if not self.user_id:\n                msg = \"User ID is required for fetching Knowledge Base data.\"\n                raise ValueError(msg)\n            current_user = await get_user_by_id(db, self.user_id)\n            if not current_user:\n                msg = f\"User with ID {self.user_id} not found.\"\n                raise ValueError(msg)\n            kb_user = current_user.username\n        kb_path = _get_knowledge_bases_root_path() / kb_user / self.knowledge_base\n\n        metadata = self._get_kb_metadata(kb_path)\n        if not metadata:\n            msg = f\"Metadata not found for knowledge base: {self.knowledge_base}. Ensure it has been indexed.\"\n            raise ValueError(msg)\n\n        # Build the embedder for the knowledge base\n        embedding_function = self._build_embeddings(metadata)\n\n        # Load vector store\n        chroma = Chroma(\n            persist_directory=str(kb_path),\n            embedding_function=embedding_function,\n            collection_name=self.knowledge_base,\n        )\n\n        # If a search query is provided, perform a similarity search\n        if self.search_query:\n            # Use the search query to perform a similarity search\n            logger.info(f\"Performing similarity search with query: {self.search_query}\")\n            results = chroma.similarity_search_with_score(\n                query=self.search_query or \"\",\n                k=self.top_k,\n            )\n        else:\n            results = chroma.similarity_search(\n                query=self.search_query or \"\",\n                k=self.top_k,\n            )\n\n            # For each result, make it a tuple to match the expected output format\n            results = [(doc, 0) for doc in results]  # Assign a dummy score of 0\n\n        # If include_embeddings is enabled, get embeddings for the results\n        id_to_embedding = {}\n        if self.include_embeddings and results:\n            doc_ids = [doc[0].metadata.get(\"_id\") for doc in results if doc[0].metadata.get(\"_id\")]\n\n            # Only proceed if we have valid document IDs\n            if doc_ids:\n                # Access underlying client to get embeddings\n                collection = chroma._client.get_collection(name=self.knowledge_base)\n                embeddings_result = collection.get(where={\"_id\": {\"$in\": doc_ids}}, include=[\"metadatas\", \"embeddings\"])\n\n                # Create a mapping from document ID to embedding\n                for i, metadata in enumerate(embeddings_result.get(\"metadatas\", [])):\n                    if metadata and \"_id\" in metadata:\n                        id_to_embedding[metadata[\"_id\"]] = embeddings_result[\"embeddings\"][i]\n\n        # Build output data based on include_metadata setting\n        data_list = []\n        for doc in results:\n            kwargs = {\n                \"content\": doc[0].page_content,\n            }\n            if self.search_query:\n                kwargs[\"_score\"] = -1 * doc[1]\n            if self.include_metadata:\n                # Include all metadata, embeddings, and content\n                kwargs.update(doc[0].metadata)\n            if self.include_embeddings:\n                kwargs[\"_embeddings\"] = id_to_embedding.get(doc[0].metadata.get(\"_id\"))\n\n            data_list.append(Data(**kwargs))\n\n        # Return the DataFrame containing the data\n        return DataFrame(data=data_list)\n"},"include_embeddings":{"_input_type":"BoolInput","advanced":true,"display_name":"Include Embeddings","dynamic":false,"info":"Whether to include embeddings in the output. Only applicable if 'Include Metadata' is enabled.","list":false,"list_add_label":"Add More","name":"include_embeddings","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"include_metadata":{"_input_type":"BoolInput","advanced":false,"display_name":"Include Metadata","dynamic":false,"info":"Whether to include all metadata in the output. If false, only content is returned.","list":false,"list_add_label":"Add More","name":"include_metadata","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"knowledge_base":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Knowledge","dynamic":false,"external_options":{},"info":"Select the knowledge to load data from.","name":"knowledge_base","options":[],"options_metadata":[],"placeholder":"","real_time_refresh":true,"refresh_button":true,"required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"search_query":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Optional search query to filter knowledge base data.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"top_k":{"_input_type":"IntInput","advanced":true,"display_name":"Top K Results","dynamic":false,"info":"Number of top results to return from the knowledge base.","list":false,"list_add_label":"Add More","name":"top_k","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5}},"tool_mode":false}}],["langchain_utilities",{"CSVAgent":{"base_classes":["AgentExecutor","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Construct a CSV agent from a CSV and tools.","display_name":"CSV Agent","documentation":"https://python.langchain.com/docs/modules/agents/toolkits/csv","edited":false,"field_order":["input_value","handle_parsing_errors","verbose","max_iterations","agent_description","llm","path","agent_type","input_value","pandas_kwargs"],"frozen":false,"icon":"LangChain","legacy":false,"metadata":{"code_hash":"fd8a98d0a625","dependencies":{"dependencies":[{"name":"langchain_experimental","version":"0.3.4"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.langchain_utilities.csv_agent.CSVAgentComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Response","group_outputs":false,"method":"build_agent_response","name":"response","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Agent","group_outputs":false,"hidden":true,"method":"build_agent","name":"agent","selected":"AgentExecutor","tool_mode":false,"types":["AgentExecutor"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","agent_description":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"Agent Description [Deprecated]","dynamic":false,"info":"The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"agent_description","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"A helpful assistant with access to the following tools:"},"agent_type":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Agent Type","dynamic":false,"external_options":{},"info":"","name":"agent_type","options":["zero-shot-react-description","openai-functions","openai-tools"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"openai-tools"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_experimental.agents.agent_toolkits.csv.base import create_csv_agent\n\nfrom lfx.base.agents.agent import LCAgentComponent\nfrom lfx.field_typing import AgentExecutor\nfrom lfx.inputs.inputs import (\n    DictInput,\n    DropdownInput,\n    FileInput,\n    HandleInput,\n    MessageTextInput,\n)\nfrom lfx.schema.message import Message\nfrom lfx.template.field.base import Output\n\n\nclass CSVAgentComponent(LCAgentComponent):\n    display_name = \"CSV Agent\"\n    description = \"Construct a CSV agent from a CSV and tools.\"\n    documentation = \"https://python.langchain.com/docs/modules/agents/toolkits/csv\"\n    name = \"CSVAgent\"\n    icon = \"LangChain\"\n\n    inputs = [\n        *LCAgentComponent.get_base_inputs(),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n            info=\"An LLM Model Object (It can be found in any LLM Component).\",\n        ),\n        FileInput(\n            name=\"path\",\n            display_name=\"File Path\",\n            file_types=[\"csv\"],\n            input_types=[\"str\", \"Message\"],\n            required=True,\n            info=\"A CSV File or File Path.\",\n        ),\n        DropdownInput(\n            name=\"agent_type\",\n            display_name=\"Agent Type\",\n            advanced=True,\n            options=[\"zero-shot-react-description\", \"openai-functions\", \"openai-tools\"],\n            value=\"openai-tools\",\n        ),\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input and extract info from the CSV File.\",\n            required=True,\n        ),\n        DictInput(\n            name=\"pandas_kwargs\",\n            display_name=\"Pandas Kwargs\",\n            info=\"Pandas Kwargs to be passed to the agent.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Response\", name=\"response\", method=\"build_agent_response\"),\n        Output(display_name=\"Agent\", name=\"agent\", method=\"build_agent\", hidden=True, tool_mode=False),\n    ]\n\n    def _path(self) -> str:\n        if isinstance(self.path, Message) and isinstance(self.path.text, str):\n            return self.path.text\n        return self.path\n\n    def build_agent_response(self) -> Message:\n        agent_kwargs = {\n            \"verbose\": self.verbose,\n            \"allow_dangerous_code\": True,\n        }\n\n        agent_csv = create_csv_agent(\n            llm=self.llm,\n            path=self._path(),\n            agent_type=self.agent_type,\n            handle_parsing_errors=self.handle_parsing_errors,\n            pandas_kwargs=self.pandas_kwargs,\n            **agent_kwargs,\n        )\n\n        result = agent_csv.invoke({\"input\": self.input_value})\n        return Message(text=str(result[\"output\"]))\n\n    def build_agent(self) -> AgentExecutor:\n        agent_kwargs = {\n            \"verbose\": self.verbose,\n            \"allow_dangerous_code\": True,\n        }\n\n        agent_csv = create_csv_agent(\n            llm=self.llm,\n            path=self._path(),\n            agent_type=self.agent_type,\n            handle_parsing_errors=self.handle_parsing_errors,\n            pandas_kwargs=self.pandas_kwargs,\n            **agent_kwargs,\n        )\n\n        self.status = Message(text=str(agent_csv))\n\n        return agent_csv\n"},"handle_parsing_errors":{"_input_type":"BoolInput","advanced":true,"display_name":"Handle Parse Errors","dynamic":false,"info":"Should the Agent fix errors when reading user input for better processing?","list":false,"list_add_label":"Add More","name":"handle_parsing_errors","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"input_value":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Text","dynamic":false,"info":"Text to be passed as input and extract info from the CSV File.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"llm":{"_input_type":"HandleInput","advanced":false,"display_name":"Language Model","dynamic":false,"info":"An LLM Model Object (It can be found in any LLM Component).","input_types":["LanguageModel"],"list":false,"list_add_label":"Add More","name":"llm","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"max_iterations":{"_input_type":"IntInput","advanced":true,"display_name":"Max Iterations","dynamic":false,"info":"The maximum number of attempts the agent can make to complete its task before it stops.","list":false,"list_add_label":"Add More","name":"max_iterations","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":15},"pandas_kwargs":{"_input_type":"DictInput","advanced":true,"display_name":"Pandas Kwargs","dynamic":false,"info":"Pandas Kwargs to be passed to the agent.","list":true,"list_add_label":"Add More","name":"pandas_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"path":{"_input_type":"FileInput","advanced":false,"display_name":"File Path","dynamic":false,"fileTypes":["csv"],"file_path":"","info":"A CSV File or File Path.","input_types":["str","Message"],"list":false,"list_add_label":"Add More","name":"path","placeholder":"","required":true,"show":true,"temp_file":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"file","value":""},"verbose":{"_input_type":"BoolInput","advanced":true,"display_name":"Verbose","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"verbose","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false},"CharacterTextSplitter":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Split text by number of characters.","display_name":"Character Text Splitter","documentation":"https://docs.langflow.org/components/text-splitters#charactertextsplitter","edited":false,"field_order":["chunk_size","chunk_overlap","data_input","separator"],"frozen":false,"icon":"LangChain","legacy":false,"metadata":{"code_hash":"da309893d64e","dependencies":{"dependencies":[{"name":"langchain_text_splitters","version":"0.3.11"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.langchain_utilities.character.CharacterTextSplitterComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"transform_data","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","chunk_overlap":{"_input_type":"IntInput","advanced":false,"display_name":"Chunk Overlap","dynamic":false,"info":"The amount of overlap between chunks.","list":false,"list_add_label":"Add More","name":"chunk_overlap","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":200},"chunk_size":{"_input_type":"IntInput","advanced":false,"display_name":"Chunk Size","dynamic":false,"info":"The maximum length of each chunk.","list":false,"list_add_label":"Add More","name":"chunk_size","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1000},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom langchain_text_splitters import CharacterTextSplitter, TextSplitter\n\nfrom lfx.base.textsplitters.model import LCTextSplitterComponent\nfrom lfx.inputs.inputs import DataInput, IntInput, MessageTextInput\nfrom lfx.utils.util import unescape_string\n\n\nclass CharacterTextSplitterComponent(LCTextSplitterComponent):\n    display_name = \"Character Text Splitter\"\n    description = \"Split text by number of characters.\"\n    documentation = \"https://docs.langflow.org/components/text-splitters#charactertextsplitter\"\n    name = \"CharacterTextSplitter\"\n    icon = \"LangChain\"\n\n    inputs = [\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum length of each chunk.\",\n            value=1000,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"The amount of overlap between chunks.\",\n            value=200,\n        ),\n        DataInput(\n            name=\"data_input\",\n            display_name=\"Input\",\n            info=\"The texts to split.\",\n            input_types=[\"Document\", \"Data\"],\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            info='The characters to split on.\\nIf left empty defaults to \"\\\\n\\\\n\".',\n        ),\n    ]\n\n    def get_data_input(self) -> Any:\n        return self.data_input\n\n    def build_text_splitter(self) -> TextSplitter:\n        separator = unescape_string(self.separator) if self.separator else \"\\n\\n\"\n        return CharacterTextSplitter(\n            chunk_overlap=self.chunk_overlap,\n            chunk_size=self.chunk_size,\n            separator=separator,\n        )\n"},"data_input":{"_input_type":"DataInput","advanced":false,"display_name":"Input","dynamic":false,"info":"The texts to split.","input_types":["Document","Data"],"list":false,"list_add_label":"Add More","name":"data_input","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"separator":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Separator","dynamic":false,"info":"The characters to split on.\nIf left empty defaults to \"\\n\\n\".","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"separator","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ConversationChain":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Chain to have a conversation and load context from memory.","display_name":"ConversationChain","documentation":"","edited":false,"field_order":["input_value","llm","memory"],"frozen":false,"icon":"LangChain","legacy":true,"metadata":{"code_hash":"b0e4044d3f08","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"langchain","version":"0.3.23"}],"total_dependencies":2},"module":"lfx.components.langchain_utilities.conversation.ConversationChainComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Text","group_outputs":false,"method":"invoke_chain","name":"text","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.chains.model import LCChainComponent\nfrom lfx.inputs.inputs import HandleInput, MultilineInput\nfrom lfx.schema.message import Message\n\n\nclass ConversationChainComponent(LCChainComponent):\n    display_name = \"ConversationChain\"\n    description = \"Chain to have a conversation and load context from memory.\"\n    name = \"ConversationChain\"\n    legacy: bool = True\n    icon = \"LangChain\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"The input value to pass to the chain.\",\n            required=True,\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            input_types=[\"BaseChatMemory\"],\n        ),\n    ]\n\n    def invoke_chain(self) -> Message:\n        try:\n            from langchain.chains import ConversationChain\n        except ImportError as e:\n            msg = (\n                \"ConversationChain requires langchain to be installed. Please install it with \"\n                \"`uv pip install langchain`.\"\n            )\n            raise ImportError(msg) from e\n\n        if not self.memory:\n            chain = ConversationChain(llm=self.llm)\n        else:\n            chain = ConversationChain(llm=self.llm, memory=self.memory)\n\n        result = chain.invoke(\n            {\"input\": self.input_value},\n            config={\"callbacks\": self.get_langchain_callbacks()},\n        )\n        if isinstance(result, dict):\n            result = result.get(chain.output_key, \"\")\n\n        elif not isinstance(result, str):\n            result = result.get(\"response\")\n        result = str(result)\n        self.status = result\n        return Message(text=result)\n"},"input_value":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Input","dynamic":false,"info":"The input value to pass to the chain.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"input_value","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"llm":{"_input_type":"HandleInput","advanced":false,"display_name":"Language Model","dynamic":false,"info":"","input_types":["LanguageModel"],"list":false,"list_add_label":"Add More","name":"llm","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"memory":{"_input_type":"HandleInput","advanced":false,"display_name":"Memory","dynamic":false,"info":"","input_types":["BaseChatMemory"],"list":false,"list_add_label":"Add More","name":"memory","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""}},"tool_mode":false},"HtmlLinkExtractor":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Extract hyperlinks from HTML content.","display_name":"HTML Link Extractor","documentation":"https://python.langchain.com/v0.2/api_reference/community/graph_vectorstores/langchain_community.graph_vectorstores.extractors.html_link_extractor.HtmlLinkExtractor.html","edited":false,"field_order":["kind","drop_fragments","data_input"],"frozen":false,"icon":"LangChain","legacy":false,"metadata":{"code_hash":"13cc6457f84c","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"langchain_core","version":"0.3.79"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.langchain_utilities.html_link_extractor.HtmlLinkExtractorComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"transform_data","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom langchain_community.graph_vectorstores.extractors import HtmlLinkExtractor, LinkExtractorTransformer\nfrom langchain_core.documents import BaseDocumentTransformer\n\nfrom lfx.base.document_transformers.model import LCDocumentTransformerComponent\nfrom lfx.inputs.inputs import BoolInput, DataInput, StrInput\n\n\nclass HtmlLinkExtractorComponent(LCDocumentTransformerComponent):\n    display_name = \"HTML Link Extractor\"\n    description = \"Extract hyperlinks from HTML content.\"\n    documentation = \"https://python.langchain.com/v0.2/api_reference/community/graph_vectorstores/langchain_community.graph_vectorstores.extractors.html_link_extractor.HtmlLinkExtractor.html\"\n    name = \"HtmlLinkExtractor\"\n    icon = \"LangChain\"\n\n    inputs = [\n        StrInput(name=\"kind\", display_name=\"Kind of edge\", value=\"hyperlink\", required=False),\n        BoolInput(name=\"drop_fragments\", display_name=\"Drop URL fragments\", value=True, required=False),\n        DataInput(\n            name=\"data_input\",\n            display_name=\"Input\",\n            info=\"The texts from which to extract links.\",\n            input_types=[\"Document\", \"Data\"],\n            required=True,\n        ),\n    ]\n\n    def get_data_input(self) -> Any:\n        return self.data_input\n\n    def build_document_transformer(self) -> BaseDocumentTransformer:\n        return LinkExtractorTransformer(\n            [HtmlLinkExtractor(kind=self.kind, drop_fragments=self.drop_fragments).as_document_extractor()]\n        )\n"},"data_input":{"_input_type":"DataInput","advanced":false,"display_name":"Input","dynamic":false,"info":"The texts from which to extract links.","input_types":["Document","Data"],"list":false,"list_add_label":"Add More","name":"data_input","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"drop_fragments":{"_input_type":"BoolInput","advanced":false,"display_name":"Drop URL fragments","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"drop_fragments","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"kind":{"_input_type":"StrInput","advanced":false,"display_name":"Kind of edge","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"kind","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"hyperlink"}},"tool_mode":false},"JsonAgent":{"base_classes":["AgentExecutor","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Construct a json agent from an LLM and tools.","display_name":"JsonAgent","documentation":"","edited":false,"field_order":["input_value","handle_parsing_errors","verbose","max_iterations","agent_description","llm","path"],"frozen":false,"legacy":true,"metadata":{"code_hash":"aabe43a3bb56","dependencies":{"dependencies":[{"name":"yaml","version":"6.0.3"},{"name":"langchain","version":"0.3.23"},{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.langchain_utilities.json_agent.JsonAgentComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Agent","group_outputs":false,"hidden":true,"method":"build_agent","name":"agent","selected":"AgentExecutor","tool_mode":false,"types":["AgentExecutor"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Response","group_outputs":false,"method":"message_response","name":"response","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","agent_description":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"Agent Description [Deprecated]","dynamic":false,"info":"The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"agent_description","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"A helpful assistant with access to the following tools:"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from pathlib import Path\n\nimport yaml\nfrom langchain.agents import AgentExecutor\nfrom langchain_community.agent_toolkits import create_json_agent\nfrom langchain_community.agent_toolkits.json.toolkit import JsonToolkit\nfrom langchain_community.tools.json.tool import JsonSpec\n\nfrom lfx.base.agents.agent import LCAgentComponent\nfrom lfx.inputs.inputs import FileInput, HandleInput\n\n\nclass JsonAgentComponent(LCAgentComponent):\n    display_name = \"JsonAgent\"\n    description = \"Construct a json agent from an LLM and tools.\"\n    name = \"JsonAgent\"\n    legacy: bool = True\n\n    inputs = [\n        *LCAgentComponent.get_base_inputs(),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        FileInput(\n            name=\"path\",\n            display_name=\"File Path\",\n            file_types=[\"json\", \"yaml\", \"yml\"],\n            required=True,\n        ),\n    ]\n\n    def build_agent(self) -> AgentExecutor:\n        path = Path(self.path)\n        if path.suffix in {\"yaml\", \"yml\"}:\n            with path.open(encoding=\"utf-8\") as file:\n                yaml_dict = yaml.safe_load(file)\n            spec = JsonSpec(dict_=yaml_dict)\n        else:\n            spec = JsonSpec.from_file(path)\n        toolkit = JsonToolkit(spec=spec)\n\n        return create_json_agent(llm=self.llm, toolkit=toolkit, **self.get_agent_kwargs())\n"},"handle_parsing_errors":{"_input_type":"BoolInput","advanced":true,"display_name":"Handle Parse Errors","dynamic":false,"info":"Should the Agent fix errors when reading user input for better processing?","list":false,"list_add_label":"Add More","name":"handle_parsing_errors","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"The input provided by the user for the agent to process.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"llm":{"_input_type":"HandleInput","advanced":false,"display_name":"Language Model","dynamic":false,"info":"","input_types":["LanguageModel"],"list":false,"list_add_label":"Add More","name":"llm","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"max_iterations":{"_input_type":"IntInput","advanced":true,"display_name":"Max Iterations","dynamic":false,"info":"The maximum number of attempts the agent can make to complete its task before it stops.","list":false,"list_add_label":"Add More","name":"max_iterations","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":15},"path":{"_input_type":"FileInput","advanced":false,"display_name":"File Path","dynamic":false,"fileTypes":["json","yaml","yml"],"file_path":"","info":"","list":false,"list_add_label":"Add More","name":"path","placeholder":"","required":true,"show":true,"temp_file":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"file","value":""},"verbose":{"_input_type":"BoolInput","advanced":true,"display_name":"Verbose","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"verbose","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false},"LLMCheckerChain":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Chain for question-answering with self-verification.","display_name":"LLMCheckerChain","documentation":"https://python.langchain.com/docs/modules/chains/additional/llm_checker","edited":false,"field_order":["input_value","llm"],"frozen":false,"icon":"LangChain","legacy":true,"metadata":{"code_hash":"81aa2c9910db","dependencies":{"dependencies":[{"name":"langchain","version":"0.3.23"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.langchain_utilities.llm_checker.LLMCheckerChainComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Text","group_outputs":false,"method":"invoke_chain","name":"text","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain.chains import LLMCheckerChain\n\nfrom lfx.base.chains.model import LCChainComponent\nfrom lfx.inputs.inputs import HandleInput, MultilineInput\nfrom lfx.schema import Message\n\n\nclass LLMCheckerChainComponent(LCChainComponent):\n    display_name = \"LLMCheckerChain\"\n    description = \"Chain for question-answering with self-verification.\"\n    documentation = \"https://python.langchain.com/docs/modules/chains/additional/llm_checker\"\n    name = \"LLMCheckerChain\"\n    legacy: bool = True\n    icon = \"LangChain\"\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"The input value to pass to the chain.\",\n            required=True,\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n    ]\n\n    def invoke_chain(self) -> Message:\n        chain = LLMCheckerChain.from_llm(llm=self.llm)\n        response = chain.invoke(\n            {chain.input_key: self.input_value},\n            config={\"callbacks\": self.get_langchain_callbacks()},\n        )\n        result = response.get(chain.output_key, \"\")\n        result = str(result)\n        self.status = result\n        return Message(text=result)\n"},"input_value":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Input","dynamic":false,"info":"The input value to pass to the chain.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"input_value","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"llm":{"_input_type":"HandleInput","advanced":false,"display_name":"Language Model","dynamic":false,"info":"","input_types":["LanguageModel"],"list":false,"list_add_label":"Add More","name":"llm","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""}},"tool_mode":false},"LLMMathChain":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Chain that interprets a prompt and executes python code to do math.","display_name":"LLMMathChain","documentation":"https://python.langchain.com/docs/modules/chains/additional/llm_math","edited":false,"field_order":["input_value","llm"],"frozen":false,"icon":"LangChain","legacy":true,"metadata":{"code_hash":"422d8e0d4614","dependencies":{"dependencies":[{"name":"langchain","version":"0.3.23"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.langchain_utilities.llm_math.LLMMathChainComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Message","group_outputs":false,"method":"invoke_chain","name":"text","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain.chains import LLMMathChain\n\nfrom lfx.base.chains.model import LCChainComponent\nfrom lfx.inputs.inputs import HandleInput, MultilineInput\nfrom lfx.schema import Message\nfrom lfx.template.field.base import Output\n\n\nclass LLMMathChainComponent(LCChainComponent):\n    display_name = \"LLMMathChain\"\n    description = \"Chain that interprets a prompt and executes python code to do math.\"\n    documentation = \"https://python.langchain.com/docs/modules/chains/additional/llm_math\"\n    name = \"LLMMathChain\"\n    legacy: bool = True\n    icon = \"LangChain\"\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"The input value to pass to the chain.\",\n            required=True,\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n    ]\n\n    outputs = [Output(display_name=\"Message\", name=\"text\", method=\"invoke_chain\")]\n\n    def invoke_chain(self) -> Message:\n        chain = LLMMathChain.from_llm(llm=self.llm)\n        response = chain.invoke(\n            {chain.input_key: self.input_value},\n            config={\"callbacks\": self.get_langchain_callbacks()},\n        )\n        result = response.get(chain.output_key, \"\")\n        result = str(result)\n        self.status = result\n        return Message(text=result)\n"},"input_value":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Input","dynamic":false,"info":"The input value to pass to the chain.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"input_value","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"llm":{"_input_type":"HandleInput","advanced":false,"display_name":"Language Model","dynamic":false,"info":"","input_types":["LanguageModel"],"list":false,"list_add_label":"Add More","name":"llm","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""}},"tool_mode":false},"LangChain Hub Prompt":{"base_classes":["Message"],"beta":true,"conditional_paths":[],"custom_fields":{},"description":"Prompt Component that uses LangChain Hub prompts","display_name":"Prompt Hub","documentation":"","edited":false,"field_order":["langchain_api_key","langchain_hub_prompt"],"frozen":false,"icon":"LangChain","legacy":false,"metadata":{"code_hash":"9f59bf236231","dependencies":{"dependencies":[{"name":"langchain_core","version":"0.3.79"},{"name":"lfx","version":null},{"name":"langchain","version":"0.3.23"}],"total_dependencies":3},"module":"lfx.components.langchain_utilities.langchain_hub.LangChainHubPromptComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Build Prompt","group_outputs":false,"method":"build_prompt","name":"prompt","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import re\n\nfrom langchain_core.prompts import HumanMessagePromptTemplate\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import DefaultPromptField, SecretStrInput, StrInput\nfrom lfx.io import Output\nfrom lfx.schema.message import Message\n\n\nclass LangChainHubPromptComponent(Component):\n    display_name: str = \"Prompt Hub\"\n    description: str = \"Prompt Component that uses LangChain Hub prompts\"\n    beta = True\n    icon = \"LangChain\"\n    trace_type = \"prompt\"\n    name = \"LangChain Hub Prompt\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"langchain_api_key\",\n            display_name=\"LangChain API Key\",\n            info=\"The LangChain API Key to use.\",\n            required=True,\n        ),\n        StrInput(\n            name=\"langchain_hub_prompt\",\n            display_name=\"LangChain Hub Prompt\",\n            info=\"The LangChain Hub prompt to use, i.e., 'efriis/my-first-prompt'\",\n            refresh_button=True,\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Build Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\n        # If the field is not langchain_hub_prompt or the value is empty, return the build config as is\n        if field_name != \"langchain_hub_prompt\" or not field_value:\n            return build_config\n\n        # Fetch the template\n        template = self._fetch_langchain_hub_template()\n\n        # Get the template's messages\n        if hasattr(template, \"messages\"):\n            template_messages = template.messages\n        else:\n            template_messages = [HumanMessagePromptTemplate(prompt=template)]\n\n        # Extract the messages from the prompt data\n        prompt_template = [message_data.prompt for message_data in template_messages]\n\n        # Regular expression to find all instances of {<string>}\n        pattern = r\"\\{(.*?)\\}\"\n\n        # Get all the custom fields\n        custom_fields: list[str] = []\n        full_template = \"\"\n        for message in prompt_template:\n            # Find all matches\n            matches = re.findall(pattern, message.template)\n            custom_fields += matches\n\n            # Create a string version of the full template\n            full_template = full_template + \"\\n\" + message.template\n\n        # No need to reprocess if we have them already\n        if all(\"param_\" + custom_field in build_config for custom_field in custom_fields):\n            return build_config\n\n        # Easter egg: Show template in info popup\n        build_config[\"langchain_hub_prompt\"][\"info\"] = full_template\n\n        # Remove old parameter inputs if any\n        for key in build_config.copy():\n            if key.startswith(\"param_\"):\n                del build_config[key]\n\n        # Now create inputs for each\n        for custom_field in custom_fields:\n            new_parameter = DefaultPromptField(\n                name=f\"param_{custom_field}\",\n                display_name=custom_field,\n                info=\"Fill in the value for {\" + custom_field + \"}\",\n            ).to_dict()\n\n            # Add the new parameter to the build config\n            build_config[f\"param_{custom_field}\"] = new_parameter\n\n        return build_config\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        # Fetch the template\n        template = self._fetch_langchain_hub_template()\n\n        # Get the parameters from the attributes\n        params_dict = {param: getattr(self, \"param_\" + param, f\"{{{param}}}\") for param in template.input_variables}\n        original_params = {k: v.text if hasattr(v, \"text\") else v for k, v in params_dict.items() if v is not None}\n        prompt_value = template.invoke(original_params)\n\n        # Update the template with the new value\n        original_params[\"template\"] = prompt_value.to_string()\n\n        # Now pass the filtered attributes to the function\n        prompt = Message.from_template(**original_params)\n\n        self.status = prompt.text\n\n        return prompt\n\n    def _fetch_langchain_hub_template(self):\n        import langchain.hub\n\n        # Check if the api key is provided\n        if not self.langchain_api_key:\n            msg = \"Please provide a LangChain API Key\"\n\n            raise ValueError(msg)\n\n        # Pull the prompt from LangChain Hub\n        return langchain.hub.pull(self.langchain_hub_prompt, api_key=self.langchain_api_key)\n"},"langchain_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"LangChain API Key","dynamic":false,"info":"The LangChain API Key to use.","input_types":[],"load_from_db":true,"name":"langchain_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"langchain_hub_prompt":{"_input_type":"StrInput","advanced":false,"display_name":"LangChain Hub Prompt","dynamic":false,"info":"The LangChain Hub prompt to use, i.e., 'efriis/my-first-prompt'","list":false,"list_add_label":"Add More","load_from_db":false,"name":"langchain_hub_prompt","placeholder":"","refresh_button":true,"required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"LangChainFakeEmbeddings":{"base_classes":["Embeddings"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate fake embeddings, useful for initial testing and connecting components.","display_name":"Fake Embeddings","documentation":"","edited":false,"field_order":["dimensions"],"frozen":false,"icon":"LangChain","legacy":false,"metadata":{"code_hash":"faaa1be642a1","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.langchain_utilities.fake_embeddings.FakeEmbeddingsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Embedding Model","group_outputs":false,"method":"build_embeddings","name":"embeddings","selected":"Embeddings","tool_mode":true,"types":["Embeddings"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_community.embeddings import FakeEmbeddings\n\nfrom lfx.base.embeddings.model import LCEmbeddingsModel\nfrom lfx.field_typing import Embeddings\nfrom lfx.io import IntInput\n\n\nclass FakeEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"Fake Embeddings\"\n    description = \"Generate fake embeddings, useful for initial testing and connecting components.\"\n    icon = \"LangChain\"\n    name = \"LangChainFakeEmbeddings\"\n\n    inputs = [\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have.\",\n            value=5,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return FakeEmbeddings(\n            size=self.dimensions or 5,\n        )\n"},"dimensions":{"_input_type":"IntInput","advanced":false,"display_name":"Dimensions","dynamic":false,"info":"The number of dimensions the resulting output embeddings should have.","list":false,"list_add_label":"Add More","name":"dimensions","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5}},"tool_mode":false},"LanguageRecursiveTextSplitter":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Split text into chunks of a specified length based on language.","display_name":"Language Recursive Text Splitter","documentation":"https://docs.langflow.org/components/text-splitters#languagerecursivetextsplitter","edited":false,"field_order":["chunk_size","chunk_overlap","data_input","code_language"],"frozen":false,"icon":"LangChain","legacy":false,"metadata":{"code_hash":"723e1b5cfc0c","dependencies":{"dependencies":[{"name":"langchain_text_splitters","version":"0.3.11"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.langchain_utilities.language_recursive.LanguageRecursiveTextSplitterComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"transform_data","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","chunk_overlap":{"_input_type":"IntInput","advanced":false,"display_name":"Chunk Overlap","dynamic":false,"info":"The amount of overlap between chunks.","list":false,"list_add_label":"Add More","name":"chunk_overlap","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":200},"chunk_size":{"_input_type":"IntInput","advanced":false,"display_name":"Chunk Size","dynamic":false,"info":"The maximum length of each chunk.","list":false,"list_add_label":"Add More","name":"chunk_size","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1000},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom langchain_text_splitters import Language, RecursiveCharacterTextSplitter, TextSplitter\n\nfrom lfx.base.textsplitters.model import LCTextSplitterComponent\nfrom lfx.inputs.inputs import DataInput, DropdownInput, IntInput\n\n\nclass LanguageRecursiveTextSplitterComponent(LCTextSplitterComponent):\n    display_name: str = \"Language Recursive Text Splitter\"\n    description: str = \"Split text into chunks of a specified length based on language.\"\n    documentation: str = \"https://docs.langflow.org/components/text-splitters#languagerecursivetextsplitter\"\n    name = \"LanguageRecursiveTextSplitter\"\n    icon = \"LangChain\"\n\n    inputs = [\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum length of each chunk.\",\n            value=1000,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"The amount of overlap between chunks.\",\n            value=200,\n        ),\n        DataInput(\n            name=\"data_input\",\n            display_name=\"Input\",\n            info=\"The texts to split.\",\n            input_types=[\"Document\", \"Data\"],\n            required=True,\n        ),\n        DropdownInput(\n            name=\"code_language\", display_name=\"Code Language\", options=[x.value for x in Language], value=\"python\"\n        ),\n    ]\n\n    def get_data_input(self) -> Any:\n        return self.data_input\n\n    def build_text_splitter(self) -> TextSplitter:\n        return RecursiveCharacterTextSplitter.from_language(\n            language=Language(self.code_language),\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n        )\n"},"code_language":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Code Language","dynamic":false,"external_options":{},"info":"","name":"code_language","options":["cpp","go","java","kotlin","js","ts","php","proto","python","rst","ruby","rust","scala","swift","markdown","latex","html","sol","csharp","cobol","c","lua","perl","haskell","elixir","powershell","visualbasic6"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"python"},"data_input":{"_input_type":"DataInput","advanced":false,"display_name":"Input","dynamic":false,"info":"The texts to split.","input_types":["Document","Data"],"list":false,"list_add_label":"Add More","name":"data_input","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""}},"tool_mode":false},"NaturalLanguageTextSplitter":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Split text based on natural language boundaries, optimized for a specified language.","display_name":"Natural Language Text Splitter","documentation":"https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/split_by_token/#nltk","edited":false,"field_order":["chunk_size","chunk_overlap","data_input","separator","language"],"frozen":false,"icon":"LangChain","legacy":false,"metadata":{"code_hash":"aed1e0bb411e","dependencies":{"dependencies":[{"name":"langchain_text_splitters","version":"0.3.11"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.langchain_utilities.natural_language.NaturalLanguageTextSplitterComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"transform_data","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","chunk_overlap":{"_input_type":"IntInput","advanced":false,"display_name":"Chunk Overlap","dynamic":false,"info":"The number of characters that overlap between consecutive chunks.","list":false,"list_add_label":"Add More","name":"chunk_overlap","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":200},"chunk_size":{"_input_type":"IntInput","advanced":false,"display_name":"Chunk Size","dynamic":false,"info":"The maximum number of characters in each chunk after splitting.","list":false,"list_add_label":"Add More","name":"chunk_size","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1000},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom langchain_text_splitters import NLTKTextSplitter, TextSplitter\n\nfrom lfx.base.textsplitters.model import LCTextSplitterComponent\nfrom lfx.inputs.inputs import DataInput, IntInput, MessageTextInput\nfrom lfx.utils.util import unescape_string\n\n\nclass NaturalLanguageTextSplitterComponent(LCTextSplitterComponent):\n    display_name = \"Natural Language Text Splitter\"\n    description = \"Split text based on natural language boundaries, optimized for a specified language.\"\n    documentation = (\n        \"https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/split_by_token/#nltk\"\n    )\n    name = \"NaturalLanguageTextSplitter\"\n    icon = \"LangChain\"\n    inputs = [\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum number of characters in each chunk after splitting.\",\n            value=1000,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"The number of characters that overlap between consecutive chunks.\",\n            value=200,\n        ),\n        DataInput(\n            name=\"data_input\",\n            display_name=\"Input\",\n            info=\"The text data to be split.\",\n            input_types=[\"Document\", \"Data\"],\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            info='The character(s) to use as a delimiter when splitting text.\\nDefaults to \"\\\\n\\\\n\" if left empty.',\n        ),\n        MessageTextInput(\n            name=\"language\",\n            display_name=\"Language\",\n            info='The language of the text. Default is \"English\". '\n            \"Supports multiple languages for better text boundary recognition.\",\n        ),\n    ]\n\n    def get_data_input(self) -> Any:\n        return self.data_input\n\n    def build_text_splitter(self) -> TextSplitter:\n        separator = unescape_string(self.separator) if self.separator else \"\\n\\n\"\n        return NLTKTextSplitter(\n            language=self.language.lower() if self.language else \"english\",\n            separator=separator,\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n        )\n"},"data_input":{"_input_type":"DataInput","advanced":false,"display_name":"Input","dynamic":false,"info":"The text data to be split.","input_types":["Document","Data"],"list":false,"list_add_label":"Add More","name":"data_input","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"language":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Language","dynamic":false,"info":"The language of the text. Default is \"English\". Supports multiple languages for better text boundary recognition.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"language","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"separator":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Separator","dynamic":false,"info":"The character(s) to use as a delimiter when splitting text.\nDefaults to \"\\n\\n\" if left empty.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"separator","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"OpenAIToolsAgent":{"base_classes":["AgentExecutor","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Agent that uses tools via openai-tools.","display_name":"OpenAI Tools Agent","documentation":"","edited":false,"field_order":["tools","input_value","handle_parsing_errors","verbose","max_iterations","agent_description","llm","system_prompt","user_prompt","chat_history"],"frozen":false,"icon":"LangChain","legacy":false,"metadata":{"code_hash":"b2ad248a3e6c","dependencies":{"dependencies":[{"name":"langchain","version":"0.3.23"},{"name":"langchain_core","version":"0.3.79"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.langchain_utilities.openai_tools.OpenAIToolsAgentComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Agent","group_outputs":false,"hidden":true,"method":"build_agent","name":"agent","selected":"AgentExecutor","tool_mode":false,"types":["AgentExecutor"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Response","group_outputs":false,"method":"message_response","name":"response","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","agent_description":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"Agent Description [Deprecated]","dynamic":false,"info":"The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"agent_description","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"A helpful assistant with access to the following tools:"},"chat_history":{"_input_type":"DataInput","advanced":true,"display_name":"Chat History","dynamic":false,"info":"","input_types":["Data"],"list":true,"list_add_label":"Add More","name":"chat_history","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain.agents import create_openai_tools_agent\nfrom langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n\nfrom lfx.base.agents.agent import LCToolsAgentComponent\nfrom lfx.inputs.inputs import (\n    DataInput,\n    HandleInput,\n    MultilineInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass OpenAIToolsAgentComponent(LCToolsAgentComponent):\n    display_name: str = \"OpenAI Tools Agent\"\n    description: str = \"Agent that uses tools via openai-tools.\"\n    icon = \"LangChain\"\n    name = \"OpenAIToolsAgent\"\n\n    inputs = [\n        *LCToolsAgentComponent.get_base_inputs(),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            input_types=[\"LanguageModel\", \"ToolEnabledLanguageModel\"],\n            required=True,\n        ),\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"System prompt for the agent.\",\n            value=\"You are a helpful assistant\",\n        ),\n        MultilineInput(\n            name=\"user_prompt\", display_name=\"Prompt\", info=\"This prompt must contain 'input' key.\", value=\"{input}\"\n        ),\n        DataInput(name=\"chat_history\", display_name=\"Chat History\", is_list=True, advanced=True),\n    ]\n\n    def get_chat_history_data(self) -> list[Data] | None:\n        return self.chat_history\n\n    def create_agent_runnable(self):\n        if \"input\" not in self.user_prompt:\n            msg = \"Prompt must contain 'input' key.\"\n            raise ValueError(msg)\n        messages = [\n            (\"system\", self.system_prompt),\n            (\"placeholder\", \"{chat_history}\"),\n            HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[\"input\"], template=self.user_prompt)),\n            (\"placeholder\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        return create_openai_tools_agent(self.llm, self.tools, prompt)\n"},"handle_parsing_errors":{"_input_type":"BoolInput","advanced":true,"display_name":"Handle Parse Errors","dynamic":false,"info":"Should the Agent fix errors when reading user input for better processing?","list":false,"list_add_label":"Add More","name":"handle_parsing_errors","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"The input provided by the user for the agent to process.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"llm":{"_input_type":"HandleInput","advanced":false,"display_name":"Language Model","dynamic":false,"info":"","input_types":["LanguageModel","ToolEnabledLanguageModel"],"list":false,"list_add_label":"Add More","name":"llm","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"max_iterations":{"_input_type":"IntInput","advanced":true,"display_name":"Max Iterations","dynamic":false,"info":"The maximum number of attempts the agent can make to complete its task before it stops.","list":false,"list_add_label":"Add More","name":"max_iterations","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":15},"system_prompt":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Prompt","dynamic":false,"info":"System prompt for the agent.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_prompt","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"You are a helpful assistant"},"tools":{"_input_type":"HandleInput","advanced":false,"display_name":"Tools","dynamic":false,"info":"These are the tools that the agent can use to help with tasks.","input_types":["Tool"],"list":true,"list_add_label":"Add More","name":"tools","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"user_prompt":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Prompt","dynamic":false,"info":"This prompt must contain 'input' key.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"user_prompt","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"{input}"},"verbose":{"_input_type":"BoolInput","advanced":true,"display_name":"Verbose","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"verbose","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false},"OpenAPIAgent":{"base_classes":["AgentExecutor","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Agent to interact with OpenAPI API.","display_name":"OpenAPI Agent","documentation":"","edited":false,"field_order":["input_value","handle_parsing_errors","verbose","max_iterations","agent_description","llm","path","allow_dangerous_requests"],"frozen":false,"icon":"LangChain","legacy":false,"metadata":{"code_hash":"3b817f0cd966","dependencies":{"dependencies":[{"name":"yaml","version":"6.0.3"},{"name":"langchain","version":"0.3.23"},{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.langchain_utilities.openapi.OpenAPIAgentComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Agent","group_outputs":false,"hidden":true,"method":"build_agent","name":"agent","selected":"AgentExecutor","tool_mode":false,"types":["AgentExecutor"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Response","group_outputs":false,"method":"message_response","name":"response","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","agent_description":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"Agent Description [Deprecated]","dynamic":false,"info":"The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"agent_description","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"A helpful assistant with access to the following tools:"},"allow_dangerous_requests":{"_input_type":"BoolInput","advanced":false,"display_name":"Allow Dangerous Requests","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"allow_dangerous_requests","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from pathlib import Path\n\nimport yaml\nfrom langchain.agents import AgentExecutor\nfrom langchain_community.agent_toolkits import create_openapi_agent\nfrom langchain_community.agent_toolkits.openapi.toolkit import OpenAPIToolkit\nfrom langchain_community.tools.json.tool import JsonSpec\nfrom langchain_community.utilities.requests import TextRequestsWrapper\n\nfrom lfx.base.agents.agent import LCAgentComponent\nfrom lfx.inputs.inputs import BoolInput, FileInput, HandleInput\n\n\nclass OpenAPIAgentComponent(LCAgentComponent):\n    display_name = \"OpenAPI Agent\"\n    description = \"Agent to interact with OpenAPI API.\"\n    name = \"OpenAPIAgent\"\n    icon = \"LangChain\"\n    inputs = [\n        *LCAgentComponent.get_base_inputs(),\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\n        FileInput(name=\"path\", display_name=\"File Path\", file_types=[\"json\", \"yaml\", \"yml\"], required=True),\n        BoolInput(name=\"allow_dangerous_requests\", display_name=\"Allow Dangerous Requests\", value=False, required=True),\n    ]\n\n    def build_agent(self) -> AgentExecutor:\n        path = Path(self.path)\n        if path.suffix in {\"yaml\", \"yml\"}:\n            with path.open(encoding=\"utf-8\") as file:\n                yaml_dict = yaml.safe_load(file)\n            spec = JsonSpec(dict_=yaml_dict)\n        else:\n            spec = JsonSpec.from_file(path)\n        requests_wrapper = TextRequestsWrapper()\n        toolkit = OpenAPIToolkit.from_llm(\n            llm=self.llm,\n            json_spec=spec,\n            requests_wrapper=requests_wrapper,\n            allow_dangerous_requests=self.allow_dangerous_requests,\n        )\n\n        agent_args = self.get_agent_kwargs()\n\n        # This is bit weird - generally other create_*_agent functions have max_iterations in the\n        # `agent_executor_kwargs`, but openai has this parameter passed directly.\n        agent_args[\"max_iterations\"] = agent_args[\"agent_executor_kwargs\"][\"max_iterations\"]\n        del agent_args[\"agent_executor_kwargs\"][\"max_iterations\"]\n        return create_openapi_agent(llm=self.llm, toolkit=toolkit, **agent_args)\n"},"handle_parsing_errors":{"_input_type":"BoolInput","advanced":true,"display_name":"Handle Parse Errors","dynamic":false,"info":"Should the Agent fix errors when reading user input for better processing?","list":false,"list_add_label":"Add More","name":"handle_parsing_errors","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"The input provided by the user for the agent to process.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"llm":{"_input_type":"HandleInput","advanced":false,"display_name":"Language Model","dynamic":false,"info":"","input_types":["LanguageModel"],"list":false,"list_add_label":"Add More","name":"llm","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"max_iterations":{"_input_type":"IntInput","advanced":true,"display_name":"Max Iterations","dynamic":false,"info":"The maximum number of attempts the agent can make to complete its task before it stops.","list":false,"list_add_label":"Add More","name":"max_iterations","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":15},"path":{"_input_type":"FileInput","advanced":false,"display_name":"File Path","dynamic":false,"fileTypes":["json","yaml","yml"],"file_path":"","info":"","list":false,"list_add_label":"Add More","name":"path","placeholder":"","required":true,"show":true,"temp_file":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"file","value":""},"verbose":{"_input_type":"BoolInput","advanced":true,"display_name":"Verbose","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"verbose","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false},"RecursiveCharacterTextSplitter":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Split text trying to keep all related text together.","display_name":"Recursive Character Text Splitter","documentation":"https://docs.langflow.org/components-processing","edited":false,"field_order":["chunk_size","chunk_overlap","data_input","separators"],"frozen":false,"icon":"LangChain","legacy":false,"metadata":{"code_hash":"9ed58a212804","dependencies":{"dependencies":[{"name":"langchain_text_splitters","version":"0.3.11"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.langchain_utilities.recursive_character.RecursiveCharacterTextSplitterComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"transform_data","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","chunk_overlap":{"_input_type":"IntInput","advanced":false,"display_name":"Chunk Overlap","dynamic":false,"info":"The amount of overlap between chunks.","list":false,"list_add_label":"Add More","name":"chunk_overlap","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":200},"chunk_size":{"_input_type":"IntInput","advanced":false,"display_name":"Chunk Size","dynamic":false,"info":"The maximum length of each chunk.","list":false,"list_add_label":"Add More","name":"chunk_size","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1000},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter, TextSplitter\n\nfrom lfx.base.textsplitters.model import LCTextSplitterComponent\nfrom lfx.inputs.inputs import DataInput, IntInput, MessageTextInput\nfrom lfx.utils.util import unescape_string\n\n\nclass RecursiveCharacterTextSplitterComponent(LCTextSplitterComponent):\n    display_name: str = \"Recursive Character Text Splitter\"\n    description: str = \"Split text trying to keep all related text together.\"\n    documentation: str = \"https://docs.langflow.org/components-processing\"\n    name = \"RecursiveCharacterTextSplitter\"\n    icon = \"LangChain\"\n\n    inputs = [\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum length of each chunk.\",\n            value=1000,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"The amount of overlap between chunks.\",\n            value=200,\n        ),\n        DataInput(\n            name=\"data_input\",\n            display_name=\"Input\",\n            info=\"The texts to split.\",\n            input_types=[\"Document\", \"Data\"],\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"separators\",\n            display_name=\"Separators\",\n            info='The characters to split on.\\nIf left empty defaults to [\"\\\\n\\\\n\", \"\\\\n\", \" \", \"\"].',\n            is_list=True,\n        ),\n    ]\n\n    def get_data_input(self) -> Any:\n        return self.data_input\n\n    def build_text_splitter(self) -> TextSplitter:\n        if not self.separators:\n            separators: list[str] | None = None\n        else:\n            # check if the separators list has escaped characters\n            # if there are escaped characters, unescape them\n            separators = [unescape_string(x) for x in self.separators]\n\n        return RecursiveCharacterTextSplitter(\n            separators=separators,\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n        )\n"},"data_input":{"_input_type":"DataInput","advanced":false,"display_name":"Input","dynamic":false,"info":"The texts to split.","input_types":["Document","Data"],"list":false,"list_add_label":"Add More","name":"data_input","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"separators":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Separators","dynamic":false,"info":"The characters to split on.\nIf left empty defaults to [\"\\n\\n\", \"\\n\", \" \", \"\"].","input_types":["Message"],"list":true,"list_add_label":"Add More","load_from_db":false,"name":"separators","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"RetrievalQA":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Chain for question-answering querying sources from a retriever.","display_name":"Retrieval QA","documentation":"","edited":false,"field_order":["input_value","chain_type","llm","retriever","memory","return_source_documents"],"frozen":false,"icon":"LangChain","legacy":true,"metadata":{"code_hash":"16c80b234abf","dependencies":{"dependencies":[{"name":"langchain","version":"0.3.23"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.langchain_utilities.retrieval_qa.RetrievalQAComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Text","group_outputs":false,"method":"invoke_chain","name":"text","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","chain_type":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Chain Type","dynamic":false,"external_options":{},"info":"Chain type to use.","name":"chain_type","options":["Stuff","Map Reduce","Refine","Map Rerank"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Stuff"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import cast\n\nfrom langchain.chains import RetrievalQA\n\nfrom lfx.base.chains.model import LCChainComponent\nfrom lfx.inputs.inputs import BoolInput, DropdownInput, HandleInput, MultilineInput\nfrom lfx.schema import Message\n\n\nclass RetrievalQAComponent(LCChainComponent):\n    display_name = \"Retrieval QA\"\n    description = \"Chain for question-answering querying sources from a retriever.\"\n    name = \"RetrievalQA\"\n    legacy: bool = True\n    icon = \"LangChain\"\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"The input value to pass to the chain.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"chain_type\",\n            display_name=\"Chain Type\",\n            info=\"Chain type to use.\",\n            options=[\"Stuff\", \"Map Reduce\", \"Refine\", \"Map Rerank\"],\n            value=\"Stuff\",\n            advanced=True,\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        HandleInput(\n            name=\"retriever\",\n            display_name=\"Retriever\",\n            input_types=[\"Retriever\"],\n            required=True,\n        ),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            input_types=[\"BaseChatMemory\"],\n        ),\n        BoolInput(\n            name=\"return_source_documents\",\n            display_name=\"Return Source Documents\",\n            value=False,\n        ),\n    ]\n\n    def invoke_chain(self) -> Message:\n        chain_type = self.chain_type.lower().replace(\" \", \"_\")\n        if self.memory:\n            self.memory.input_key = \"query\"\n            self.memory.output_key = \"result\"\n\n        runnable = RetrievalQA.from_chain_type(\n            llm=self.llm,\n            chain_type=chain_type,\n            retriever=self.retriever,\n            memory=self.memory,\n            # always include to help debugging\n            #\n            return_source_documents=True,\n        )\n\n        result = runnable.invoke(\n            {\"query\": self.input_value},\n            config={\"callbacks\": self.get_langchain_callbacks()},\n        )\n\n        source_docs = self.to_data(result.get(\"source_documents\", keys=[]))\n        result_str = str(result.get(\"result\", \"\"))\n        if self.return_source_documents and len(source_docs):\n            references_str = self.create_references_from_data(source_docs)\n            result_str = f\"{result_str}\\n{references_str}\"\n        # put the entire result to debug history, query and content\n        self.status = {**result, \"source_documents\": source_docs, \"output\": result_str}\n        return cast(\"Message\", result_str)\n"},"input_value":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Input","dynamic":false,"info":"The input value to pass to the chain.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"input_value","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"llm":{"_input_type":"HandleInput","advanced":false,"display_name":"Language Model","dynamic":false,"info":"","input_types":["LanguageModel"],"list":false,"list_add_label":"Add More","name":"llm","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"memory":{"_input_type":"HandleInput","advanced":false,"display_name":"Memory","dynamic":false,"info":"","input_types":["BaseChatMemory"],"list":false,"list_add_label":"Add More","name":"memory","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"retriever":{"_input_type":"HandleInput","advanced":false,"display_name":"Retriever","dynamic":false,"info":"","input_types":["Retriever"],"list":false,"list_add_label":"Add More","name":"retriever","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"return_source_documents":{"_input_type":"BoolInput","advanced":false,"display_name":"Return Source Documents","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"return_source_documents","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false},"RunnableExecutor":{"base_classes":["Message"],"beta":true,"conditional_paths":[],"custom_fields":{},"description":"Execute a runnable. It will try to guess the input and output keys.","display_name":"Runnable Executor","documentation":"","edited":false,"field_order":["input_value","runnable","input_key","output_key","use_stream"],"frozen":false,"icon":"LangChain","legacy":false,"metadata":{"code_hash":"32135f41efe5","dependencies":{"dependencies":[{"name":"langchain","version":"0.3.23"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.langchain_utilities.runnable_executor.RunnableExecComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Message","group_outputs":false,"method":"build_executor","name":"text","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain.agents import AgentExecutor\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import BoolInput, HandleInput, MessageTextInput\nfrom lfx.schema.message import Message\nfrom lfx.template.field.base import Output\n\n\nclass RunnableExecComponent(Component):\n    description = \"Execute a runnable. It will try to guess the input and output keys.\"\n    display_name = \"Runnable Executor\"\n    name = \"RunnableExecutor\"\n    beta: bool = True\n    icon = \"LangChain\"\n\n    inputs = [\n        MessageTextInput(name=\"input_value\", display_name=\"Input\", required=True),\n        HandleInput(\n            name=\"runnable\",\n            display_name=\"Agent Executor\",\n            input_types=[\"Chain\", \"AgentExecutor\", \"Agent\", \"Runnable\"],\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"input_key\",\n            display_name=\"Input Key\",\n            value=\"input\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"output_key\",\n            display_name=\"Output Key\",\n            value=\"output\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"use_stream\",\n            display_name=\"Stream\",\n            value=False,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            method=\"build_executor\",\n        ),\n    ]\n\n    def get_output(self, result, input_key, output_key):\n        \"\"\"Retrieves the output value from the given result dictionary based on the specified input and output keys.\n\n        Args:\n            result (dict): The result dictionary containing the output value.\n            input_key (str): The key used to retrieve the input value from the result dictionary.\n            output_key (str): The key used to retrieve the output value from the result dictionary.\n\n        Returns:\n            tuple: A tuple containing the output value and the status message.\n\n        \"\"\"\n        possible_output_keys = [\"answer\", \"response\", \"output\", \"result\", \"text\"]\n        status = \"\"\n        result_value = None\n\n        if output_key in result:\n            result_value = result.get(output_key)\n        elif len(result) == 2 and input_key in result:  # noqa: PLR2004\n            # get the other key from the result dict\n            other_key = next(k for k in result if k != input_key)\n            if other_key == output_key:\n                result_value = result.get(output_key)\n            else:\n                status += f\"Warning: The output key is not '{output_key}'. The output key is '{other_key}'.\"\n                result_value = result.get(other_key)\n        elif len(result) == 1:\n            result_value = next(iter(result.values()))\n        elif any(k in result for k in possible_output_keys):\n            for key in possible_output_keys:\n                if key in result:\n                    result_value = result.get(key)\n                    status += f\"Output key: '{key}'.\"\n                    break\n            if result_value is None:\n                result_value = result\n                status += f\"Warning: The output key is not '{output_key}'.\"\n        else:\n            result_value = result\n            status += f\"Warning: The output key is not '{output_key}'.\"\n\n        return result_value, status\n\n    def get_input_dict(self, runnable, input_key, input_value):\n        \"\"\"Returns a dictionary containing the input key-value pair for the given runnable.\n\n        Args:\n            runnable: The runnable object.\n            input_key: The key for the input value.\n            input_value: The value for the input key.\n\n        Returns:\n            input_dict: A dictionary containing the input key-value pair.\n            status: A status message indicating if the input key is not in the runnable's input keys.\n        \"\"\"\n        input_dict = {}\n        status = \"\"\n        if hasattr(runnable, \"input_keys\"):\n            # Check if input_key is in the runnable's input_keys\n            if input_key in runnable.input_keys:\n                input_dict[input_key] = input_value\n            else:\n                input_dict = dict.fromkeys(runnable.input_keys, input_value)\n                status = f\"Warning: The input key is not '{input_key}'. The input key is '{runnable.input_keys}'.\"\n        return input_dict, status\n\n    async def build_executor(self) -> Message:\n        input_dict, status = self.get_input_dict(self.runnable, self.input_key, self.input_value)\n        if not isinstance(self.runnable, AgentExecutor):\n            msg = \"The runnable must be an AgentExecutor\"\n            raise TypeError(msg)\n\n        if self.use_stream:\n            return self.astream_events(input_dict)\n        result = await self.runnable.ainvoke(input_dict)\n        result_value, status_ = self.get_output(result, self.input_key, self.output_key)\n        status += status_\n        status += f\"\\n\\nOutput: {result_value}\\n\\nRaw Output: {result}\"\n        self.status = status\n        return result_value\n\n    async def astream_events(self, runnable_input):\n        async for event in self.runnable.astream_events(runnable_input, version=\"v1\"):\n            if event.get(\"event\") != \"on_chat_model_stream\":\n                continue\n\n            yield event.get(\"data\").get(\"chunk\")\n"},"input_key":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Input Key","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"input"},"input_value":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"output_key":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Output Key","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"output_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"output"},"runnable":{"_input_type":"HandleInput","advanced":false,"display_name":"Agent Executor","dynamic":false,"info":"","input_types":["Chain","AgentExecutor","Agent","Runnable"],"list":false,"list_add_label":"Add More","name":"runnable","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"use_stream":{"_input_type":"BoolInput","advanced":false,"display_name":"Stream","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"use_stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false},"SQLAgent":{"base_classes":["AgentExecutor","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Construct an SQL agent from an LLM and tools.","display_name":"SQLAgent","documentation":"","edited":false,"field_order":["input_value","handle_parsing_errors","verbose","max_iterations","agent_description","llm","database_uri","extra_tools"],"frozen":false,"icon":"LangChain","legacy":false,"metadata":{"code_hash":"8d02598705fc","dependencies":{"dependencies":[{"name":"langchain","version":"0.3.23"},{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.langchain_utilities.sql.SQLAgentComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Response","group_outputs":false,"method":"message_response","name":"response","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Agent","group_outputs":false,"method":"build_agent","name":"agent","selected":"AgentExecutor","tool_mode":false,"types":["AgentExecutor"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","agent_description":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"Agent Description [Deprecated]","dynamic":false,"info":"The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"agent_description","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"A helpful assistant with access to the following tools:"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain.agents import AgentExecutor\nfrom langchain_community.agent_toolkits import SQLDatabaseToolkit\nfrom langchain_community.agent_toolkits.sql.base import create_sql_agent\nfrom langchain_community.utilities import SQLDatabase\n\nfrom lfx.base.agents.agent import LCAgentComponent\nfrom lfx.inputs.inputs import HandleInput, MessageTextInput\nfrom lfx.io import Output\n\n\nclass SQLAgentComponent(LCAgentComponent):\n    display_name = \"SQLAgent\"\n    description = \"Construct an SQL agent from an LLM and tools.\"\n    name = \"SQLAgent\"\n    icon = \"LangChain\"\n    inputs = [\n        *LCAgentComponent.get_base_inputs(),\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\n        MessageTextInput(name=\"database_uri\", display_name=\"Database URI\", required=True),\n        HandleInput(\n            name=\"extra_tools\",\n            display_name=\"Extra Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Response\", name=\"response\", method=\"message_response\"),\n        Output(display_name=\"Agent\", name=\"agent\", method=\"build_agent\", tool_mode=False),\n    ]\n\n    def build_agent(self) -> AgentExecutor:\n        db = SQLDatabase.from_uri(self.database_uri)\n        toolkit = SQLDatabaseToolkit(db=db, llm=self.llm)\n        agent_args = self.get_agent_kwargs()\n        agent_args[\"max_iterations\"] = agent_args[\"agent_executor_kwargs\"][\"max_iterations\"]\n        del agent_args[\"agent_executor_kwargs\"][\"max_iterations\"]\n        return create_sql_agent(llm=self.llm, toolkit=toolkit, extra_tools=self.extra_tools or [], **agent_args)\n"},"database_uri":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Database URI","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"database_uri","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"extra_tools":{"_input_type":"HandleInput","advanced":true,"display_name":"Extra Tools","dynamic":false,"info":"","input_types":["Tool"],"list":true,"list_add_label":"Add More","name":"extra_tools","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"handle_parsing_errors":{"_input_type":"BoolInput","advanced":true,"display_name":"Handle Parse Errors","dynamic":false,"info":"Should the Agent fix errors when reading user input for better processing?","list":false,"list_add_label":"Add More","name":"handle_parsing_errors","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"The input provided by the user for the agent to process.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"llm":{"_input_type":"HandleInput","advanced":false,"display_name":"Language Model","dynamic":false,"info":"","input_types":["LanguageModel"],"list":false,"list_add_label":"Add More","name":"llm","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"max_iterations":{"_input_type":"IntInput","advanced":true,"display_name":"Max Iterations","dynamic":false,"info":"The maximum number of attempts the agent can make to complete its task before it stops.","list":false,"list_add_label":"Add More","name":"max_iterations","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":15},"verbose":{"_input_type":"BoolInput","advanced":true,"display_name":"Verbose","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"verbose","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false},"SQLDatabase":{"base_classes":["SQLDatabase"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"SQL Database","display_name":"SQLDatabase","documentation":"","edited":false,"field_order":["uri"],"frozen":false,"icon":"LangChain","legacy":false,"metadata":{"code_hash":"7d07b7faa341","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"sqlalchemy","version":"2.0.44"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.langchain_utilities.sql_database.SQLDatabaseComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"SQLDatabase","group_outputs":false,"method":"build_sqldatabase","name":"SQLDatabase","selected":"SQLDatabase","tool_mode":true,"types":["SQLDatabase"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_community.utilities.sql_database import SQLDatabase\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.pool import StaticPool\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import (\n    Output,\n    StrInput,\n)\n\n\nclass SQLDatabaseComponent(Component):\n    display_name = \"SQLDatabase\"\n    description = \"SQL Database\"\n    name = \"SQLDatabase\"\n    icon = \"LangChain\"\n\n    inputs = [\n        StrInput(name=\"uri\", display_name=\"URI\", info=\"URI to the database.\", required=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"SQLDatabase\", name=\"SQLDatabase\", method=\"build_sqldatabase\"),\n    ]\n\n    def clean_up_uri(self, uri: str) -> str:\n        if uri.startswith(\"postgres://\"):\n            uri = uri.replace(\"postgres://\", \"postgresql://\")\n        return uri.strip()\n\n    def build_sqldatabase(self) -> SQLDatabase:\n        uri = self.clean_up_uri(self.uri)\n        # Create an engine using SQLAlchemy with StaticPool\n        engine = create_engine(uri, poolclass=StaticPool)\n        return SQLDatabase(engine)\n"},"uri":{"_input_type":"StrInput","advanced":false,"display_name":"URI","dynamic":false,"info":"URI to the database.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"uri","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"SQLGenerator":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate SQL from natural language.","display_name":"Natural Language to SQL","documentation":"","edited":false,"field_order":["input_value","llm","db","top_k","prompt"],"frozen":false,"icon":"LangChain","legacy":true,"metadata":{"code_hash":"971a82407ec6","dependencies":{"dependencies":[{"name":"langchain","version":"0.3.23"},{"name":"langchain_core","version":"0.3.79"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.langchain_utilities.sql_generator.SQLGeneratorComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Message","group_outputs":false,"method":"invoke_chain","name":"text","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import TYPE_CHECKING\n\nfrom langchain.chains import create_sql_query_chain\nfrom langchain_core.prompts import PromptTemplate\n\nfrom lfx.base.chains.model import LCChainComponent\nfrom lfx.inputs.inputs import HandleInput, IntInput, MultilineInput\nfrom lfx.schema import Message\nfrom lfx.template.field.base import Output\n\nif TYPE_CHECKING:\n    from langchain_core.runnables import Runnable\n\n\nclass SQLGeneratorComponent(LCChainComponent):\n    display_name = \"Natural Language to SQL\"\n    description = \"Generate SQL from natural language.\"\n    name = \"SQLGenerator\"\n    legacy: bool = True\n    icon = \"LangChain\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"The input value to pass to the chain.\",\n            required=True,\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        HandleInput(\n            name=\"db\",\n            display_name=\"SQLDatabase\",\n            input_types=[\"SQLDatabase\"],\n            required=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            info=\"The number of results per select statement to return.\",\n            value=5,\n        ),\n        MultilineInput(\n            name=\"prompt\",\n            display_name=\"Prompt\",\n            info=\"The prompt must contain `{question}`.\",\n        ),\n    ]\n\n    outputs = [Output(display_name=\"Message\", name=\"text\", method=\"invoke_chain\")]\n\n    def invoke_chain(self) -> Message:\n        prompt_template = PromptTemplate.from_template(template=self.prompt) if self.prompt else None\n\n        if self.top_k < 1:\n            msg = \"Top K must be greater than 0.\"\n            raise ValueError(msg)\n\n        if not prompt_template:\n            sql_query_chain = create_sql_query_chain(llm=self.llm, db=self.db, k=self.top_k)\n        else:\n            # Check if {question} is in the prompt\n            if \"{question}\" not in prompt_template.template or \"question\" not in prompt_template.input_variables:\n                msg = \"Prompt must contain `{question}` to be used with Natural Language to SQL.\"\n                raise ValueError(msg)\n            sql_query_chain = create_sql_query_chain(llm=self.llm, db=self.db, prompt=prompt_template, k=self.top_k)\n        query_writer: Runnable = sql_query_chain | {\"query\": lambda x: x.replace(\"SQLQuery:\", \"\").strip()}\n        response = query_writer.invoke(\n            {\"question\": self.input_value},\n            config={\"callbacks\": self.get_langchain_callbacks()},\n        )\n        query = response.get(\"query\")\n        self.status = query\n        return query\n"},"db":{"_input_type":"HandleInput","advanced":false,"display_name":"SQLDatabase","dynamic":false,"info":"","input_types":["SQLDatabase"],"list":false,"list_add_label":"Add More","name":"db","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"input_value":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Input","dynamic":false,"info":"The input value to pass to the chain.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"input_value","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"llm":{"_input_type":"HandleInput","advanced":false,"display_name":"Language Model","dynamic":false,"info":"","input_types":["LanguageModel"],"list":false,"list_add_label":"Add More","name":"llm","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"prompt":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Prompt","dynamic":false,"info":"The prompt must contain `{question}`.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"prompt","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"top_k":{"_input_type":"IntInput","advanced":false,"display_name":"Top K","dynamic":false,"info":"The number of results per select statement to return.","list":false,"list_add_label":"Add More","name":"top_k","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5}},"tool_mode":false},"SelfQueryRetriever":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Retriever that uses a vector store and an LLM to generate the vector store queries.","display_name":"Self Query Retriever","documentation":"","edited":false,"field_order":["query","vectorstore","attribute_infos","document_content_description","llm"],"frozen":false,"icon":"LangChain","legacy":true,"metadata":{"code_hash":"a18169f36371","dependencies":{"dependencies":[{"name":"langchain","version":"0.3.23"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.langchain_utilities.self_query.SelfQueryRetrieverComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Retrieved Documents","group_outputs":false,"method":"retrieve_documents","name":"documents","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","attribute_infos":{"_input_type":"HandleInput","advanced":false,"display_name":"Metadata Field Info","dynamic":false,"info":"Metadata Field Info to be passed as input.","input_types":["Data"],"list":true,"list_add_label":"Add More","name":"attribute_infos","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain.chains.query_constructor.base import AttributeInfo\nfrom langchain.retrievers.self_query.base import SelfQueryRetriever\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import HandleInput, MessageTextInput\nfrom lfx.io import Output\nfrom lfx.schema.data import Data\nfrom lfx.schema.message import Message\n\n\nclass SelfQueryRetrieverComponent(Component):\n    display_name = \"Self Query Retriever\"\n    description = \"Retriever that uses a vector store and an LLM to generate the vector store queries.\"\n    name = \"SelfQueryRetriever\"\n    icon = \"LangChain\"\n    legacy: bool = True\n\n    inputs = [\n        HandleInput(\n            name=\"query\",\n            display_name=\"Query\",\n            info=\"Query to be passed as input.\",\n            input_types=[\"Message\"],\n        ),\n        HandleInput(\n            name=\"vectorstore\",\n            display_name=\"Vector Store\",\n            info=\"Vector Store to be passed as input.\",\n            input_types=[\"VectorStore\"],\n        ),\n        HandleInput(\n            name=\"attribute_infos\",\n            display_name=\"Metadata Field Info\",\n            info=\"Metadata Field Info to be passed as input.\",\n            input_types=[\"Data\"],\n            is_list=True,\n        ),\n        MessageTextInput(\n            name=\"document_content_description\",\n            display_name=\"Document Content Description\",\n            info=\"Document Content Description to be passed as input.\",\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"LLM\",\n            info=\"LLM to be passed as input.\",\n            input_types=[\"LanguageModel\"],\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Retrieved Documents\",\n            name=\"documents\",\n            method=\"retrieve_documents\",\n        ),\n    ]\n\n    def retrieve_documents(self) -> list[Data]:\n        metadata_field_infos = [AttributeInfo(**value.data) for value in self.attribute_infos]\n        self_query_retriever = SelfQueryRetriever.from_llm(\n            llm=self.llm,\n            vectorstore=self.vectorstore,\n            document_contents=self.document_content_description,\n            metadata_field_info=metadata_field_infos,\n            enable_limit=True,\n        )\n\n        if isinstance(self.query, Message):\n            input_text = self.query.text\n        elif isinstance(self.query, str):\n            input_text = self.query\n        else:\n            msg = f\"Query type {type(self.query)} not supported.\"\n            raise TypeError(msg)\n\n        documents = self_query_retriever.invoke(input=input_text, config={\"callbacks\": self.get_langchain_callbacks()})\n        data = [Data.from_document(document) for document in documents]\n        self.status = data\n        return data\n"},"document_content_description":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Document Content Description","dynamic":false,"info":"Document Content Description to be passed as input.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"document_content_description","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"llm":{"_input_type":"HandleInput","advanced":false,"display_name":"LLM","dynamic":false,"info":"LLM to be passed as input.","input_types":["LanguageModel"],"list":false,"list_add_label":"Add More","name":"llm","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"query":{"_input_type":"HandleInput","advanced":false,"display_name":"Query","dynamic":false,"info":"Query to be passed as input.","input_types":["Message"],"list":false,"list_add_label":"Add More","name":"query","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"vectorstore":{"_input_type":"HandleInput","advanced":false,"display_name":"Vector Store","dynamic":false,"info":"Vector Store to be passed as input.","input_types":["VectorStore"],"list":false,"list_add_label":"Add More","name":"vectorstore","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""}},"tool_mode":false},"SemanticTextSplitter":{"base_classes":["Data"],"beta":true,"conditional_paths":[],"custom_fields":{},"description":"Split text into semantically meaningful chunks using semantic similarity.","display_name":"Semantic Text Splitter","documentation":"https://python.langchain.com/docs/how_to/semantic-chunker/","edited":false,"field_order":["data_inputs","embeddings","breakpoint_threshold_type","breakpoint_threshold_amount","number_of_chunks","sentence_split_regex","buffer_size"],"frozen":false,"icon":"LangChain","legacy":false,"metadata":{"code_hash":"e9178757dea0","dependencies":{"dependencies":[{"name":"langchain","version":"0.3.23"},{"name":"langchain_experimental","version":"0.3.4"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.langchain_utilities.language_semantic.SemanticTextSplitterComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Chunks","group_outputs":false,"method":"split_text","name":"chunks","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","breakpoint_threshold_amount":{"_input_type":"FloatInput","advanced":false,"display_name":"Breakpoint Threshold Amount","dynamic":false,"info":"Numerical amount for the breakpoint threshold.","list":false,"list_add_label":"Add More","name":"breakpoint_threshold_amount","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.5},"breakpoint_threshold_type":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Breakpoint Threshold Type","dynamic":false,"external_options":{},"info":"Method to determine breakpoints. Options: 'percentile', 'standard_deviation', 'interquartile'. Defaults to 'percentile'.","name":"breakpoint_threshold_type","options":["percentile","standard_deviation","interquartile"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"percentile"},"buffer_size":{"_input_type":"IntInput","advanced":true,"display_name":"Buffer Size","dynamic":false,"info":"Size of the buffer.","list":false,"list_add_label":"Add More","name":"buffer_size","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":0},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain.docstore.document import Document\nfrom langchain_experimental.text_splitter import SemanticChunker\n\nfrom lfx.base.textsplitters.model import LCTextSplitterComponent\nfrom lfx.io import (\n    DropdownInput,\n    FloatInput,\n    HandleInput,\n    IntInput,\n    MessageTextInput,\n    Output,\n)\nfrom lfx.schema.data import Data\n\n\nclass SemanticTextSplitterComponent(LCTextSplitterComponent):\n    \"\"\"Split text into semantically meaningful chunks using semantic similarity.\"\"\"\n\n    display_name: str = \"Semantic Text Splitter\"\n    name: str = \"SemanticTextSplitter\"\n    description: str = \"Split text into semantically meaningful chunks using semantic similarity.\"\n    documentation = \"https://python.langchain.com/docs/how_to/semantic-chunker/\"\n    beta = True  # this component is beta because it is imported from langchain_experimental\n    icon = \"LangChain\"\n\n    inputs = [\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Data Inputs\",\n            info=\"List of Data objects containing text and metadata to split.\",\n            input_types=[\"Data\"],\n            is_list=True,\n            required=True,\n        ),\n        HandleInput(\n            name=\"embeddings\",\n            display_name=\"Embeddings\",\n            info=\"Embeddings model to use for semantic similarity. Required.\",\n            input_types=[\"Embeddings\"],\n            is_list=False,\n            required=True,\n        ),\n        DropdownInput(\n            name=\"breakpoint_threshold_type\",\n            display_name=\"Breakpoint Threshold Type\",\n            info=(\n                \"Method to determine breakpoints. Options: 'percentile', \"\n                \"'standard_deviation', 'interquartile'. Defaults to 'percentile'.\"\n            ),\n            value=\"percentile\",\n            options=[\"percentile\", \"standard_deviation\", \"interquartile\"],\n        ),\n        FloatInput(\n            name=\"breakpoint_threshold_amount\",\n            display_name=\"Breakpoint Threshold Amount\",\n            info=\"Numerical amount for the breakpoint threshold.\",\n            value=0.5,\n        ),\n        IntInput(\n            name=\"number_of_chunks\",\n            display_name=\"Number of Chunks\",\n            info=\"Number of chunks to split the text into.\",\n            value=5,\n        ),\n        MessageTextInput(\n            name=\"sentence_split_regex\",\n            display_name=\"Sentence Split Regex\",\n            info=\"Regular expression to split sentences. Optional.\",\n            value=\"\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"buffer_size\",\n            display_name=\"Buffer Size\",\n            info=\"Size of the buffer.\",\n            value=0,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chunks\", name=\"chunks\", method=\"split_text\"),\n    ]\n\n    def _docs_to_data(self, docs: list[Document]) -> list[Data]:\n        \"\"\"Convert a list of Document objects to Data objects.\"\"\"\n        return [Data(text=doc.page_content, data=doc.metadata) for doc in docs]\n\n    def split_text(self) -> list[Data]:\n        \"\"\"Split the input data into semantically meaningful chunks.\"\"\"\n        try:\n            embeddings = getattr(self, \"embeddings\", None)\n            if embeddings is None:\n                error_msg = \"An embeddings model is required for SemanticTextSplitter.\"\n                raise ValueError(error_msg)\n\n            if not self.data_inputs:\n                error_msg = \"Data inputs cannot be empty.\"\n                raise ValueError(error_msg)\n\n            documents = []\n            for _input in self.data_inputs:\n                if isinstance(_input, Data):\n                    documents.append(_input.to_lc_document())\n                else:\n                    error_msg = f\"Invalid data input type: {_input}\"\n                    raise TypeError(error_msg)\n\n            if not documents:\n                error_msg = \"No valid Data objects found in data_inputs.\"\n                raise ValueError(error_msg)\n\n            texts = [doc.page_content for doc in documents]\n            metadatas = [doc.metadata for doc in documents]\n\n            splitter_params = {\n                \"embeddings\": embeddings,\n                \"breakpoint_threshold_type\": self.breakpoint_threshold_type or \"percentile\",\n                \"breakpoint_threshold_amount\": self.breakpoint_threshold_amount,\n                \"number_of_chunks\": self.number_of_chunks,\n                \"buffer_size\": self.buffer_size,\n            }\n\n            if self.sentence_split_regex:\n                splitter_params[\"sentence_split_regex\"] = self.sentence_split_regex\n\n            splitter = SemanticChunker(**splitter_params)\n            docs = splitter.create_documents(texts, metadatas=metadatas)\n\n            data = self._docs_to_data(docs)\n            self.status = data\n\n        except Exception as e:\n            error_msg = f\"An error occurred during semantic splitting: {e}\"\n            raise RuntimeError(error_msg) from e\n\n        else:\n            return data\n"},"data_inputs":{"_input_type":"HandleInput","advanced":false,"display_name":"Data Inputs","dynamic":false,"info":"List of Data objects containing text and metadata to split.","input_types":["Data"],"list":true,"list_add_label":"Add More","name":"data_inputs","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"embeddings":{"_input_type":"HandleInput","advanced":false,"display_name":"Embeddings","dynamic":false,"info":"Embeddings model to use for semantic similarity. Required.","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embeddings","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"number_of_chunks":{"_input_type":"IntInput","advanced":false,"display_name":"Number of Chunks","dynamic":false,"info":"Number of chunks to split the text into.","list":false,"list_add_label":"Add More","name":"number_of_chunks","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5},"sentence_split_regex":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Sentence Split Regex","dynamic":false,"info":"Regular expression to split sentences. Optional.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"sentence_split_regex","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"SpiderTool":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Spider API for web crawling and scraping.","display_name":"Spider Web Crawler & Scraper","documentation":"https://spider.cloud/docs/api","edited":false,"field_order":["spider_api_key","url","mode","limit","depth","blacklist","whitelist","readability","request_timeout","metadata","params"],"frozen":false,"legacy":false,"metadata":{"code_hash":"08c823a20237","dependencies":{"dependencies":[{"name":"spider","version":"0.1.24"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.langchain_utilities.spider.SpiderTool"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Markdown","group_outputs":false,"method":"crawl","name":"content","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","blacklist":{"_input_type":"StrInput","advanced":true,"display_name":"Blacklist","dynamic":false,"info":"Blacklist paths that you do not want to crawl. Use Regex patterns.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"blacklist","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from spider.spider import Spider\n\nfrom lfx.base.langchain_utilities.spider_constants import MODES\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    IntInput,\n    Output,\n    SecretStrInput,\n    StrInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass SpiderTool(Component):\n    display_name: str = \"Spider Web Crawler & Scraper\"\n    description: str = \"Spider API for web crawling and scraping.\"\n    output_types: list[str] = [\"Document\"]\n    documentation: str = \"https://spider.cloud/docs/api\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"spider_api_key\",\n            display_name=\"Spider API Key\",\n            required=True,\n            password=True,\n            info=\"The Spider API Key, get it from https://spider.cloud\",\n        ),\n        StrInput(\n            name=\"url\",\n            display_name=\"URL\",\n            required=True,\n            info=\"The URL to scrape or crawl\",\n        ),\n        DropdownInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            required=True,\n            options=MODES,\n            value=MODES[0],\n            info=\"The mode of operation: scrape or crawl\",\n        ),\n        IntInput(\n            name=\"limit\",\n            display_name=\"Limit\",\n            info=\"The maximum amount of pages allowed to crawl per website. Set to 0 to crawl all pages.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"depth\",\n            display_name=\"Depth\",\n            info=\"The crawl limit for maximum depth. If 0, no limit will be applied.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"blacklist\",\n            display_name=\"Blacklist\",\n            info=\"Blacklist paths that you do not want to crawl. Use Regex patterns.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"whitelist\",\n            display_name=\"Whitelist\",\n            info=\"Whitelist paths that you want to crawl, ignoring all other routes. Use Regex patterns.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"readability\",\n            display_name=\"Use Readability\",\n            info=\"Use readability to pre-process the content for reading.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"request_timeout\",\n            display_name=\"Request Timeout\",\n            info=\"Timeout for the request in seconds.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"metadata\",\n            display_name=\"Metadata\",\n            info=\"Include metadata in the response.\",\n            advanced=True,\n        ),\n        DictInput(\n            name=\"params\",\n            display_name=\"Additional Parameters\",\n            info=\"Additional parameters to pass to the API. If provided, other inputs will be ignored.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Markdown\", name=\"content\", method=\"crawl\"),\n    ]\n\n    def crawl(self) -> list[Data]:\n        if self.params:\n            parameters = self.params[\"data\"]\n        else:\n            parameters = {\n                \"limit\": self.limit or None,\n                \"depth\": self.depth or None,\n                \"blacklist\": self.blacklist or None,\n                \"whitelist\": self.whitelist or None,\n                \"readability\": self.readability,\n                \"request_timeout\": self.request_timeout or None,\n                \"metadata\": self.metadata,\n                \"return_format\": \"markdown\",\n            }\n\n        app = Spider(api_key=self.spider_api_key)\n        if self.mode == \"scrape\":\n            parameters[\"limit\"] = 1\n            result = app.scrape_url(self.url, parameters)\n        elif self.mode == \"crawl\":\n            result = app.crawl_url(self.url, parameters)\n        else:\n            msg = f\"Invalid mode: {self.mode}. Must be 'scrape' or 'crawl'.\"\n            raise ValueError(msg)\n\n        records = []\n\n        for record in result:\n            if self.metadata:\n                records.append(\n                    Data(\n                        data={\n                            \"content\": record[\"content\"],\n                            \"url\": record[\"url\"],\n                            \"metadata\": record[\"metadata\"],\n                        }\n                    )\n                )\n            else:\n                records.append(Data(data={\"content\": record[\"content\"], \"url\": record[\"url\"]}))\n        return records\n\n\nclass SpiderToolError(Exception):\n    \"\"\"SpiderTool error.\"\"\"\n"},"depth":{"_input_type":"IntInput","advanced":true,"display_name":"Depth","dynamic":false,"info":"The crawl limit for maximum depth. If 0, no limit will be applied.","list":false,"list_add_label":"Add More","name":"depth","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"limit":{"_input_type":"IntInput","advanced":true,"display_name":"Limit","dynamic":false,"info":"The maximum amount of pages allowed to crawl per website. Set to 0 to crawl all pages.","list":false,"list_add_label":"Add More","name":"limit","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"metadata":{"_input_type":"BoolInput","advanced":true,"display_name":"Metadata","dynamic":false,"info":"Include metadata in the response.","list":false,"list_add_label":"Add More","name":"metadata","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"mode":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Mode","dynamic":false,"external_options":{},"info":"The mode of operation: scrape or crawl","name":"mode","options":["scrape","crawl"],"options_metadata":[],"placeholder":"","required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"scrape"},"params":{"_input_type":"DictInput","advanced":false,"display_name":"Additional Parameters","dynamic":false,"info":"Additional parameters to pass to the API. If provided, other inputs will be ignored.","list":false,"list_add_label":"Add More","name":"params","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"readability":{"_input_type":"BoolInput","advanced":true,"display_name":"Use Readability","dynamic":false,"info":"Use readability to pre-process the content for reading.","list":false,"list_add_label":"Add More","name":"readability","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"request_timeout":{"_input_type":"IntInput","advanced":true,"display_name":"Request Timeout","dynamic":false,"info":"Timeout for the request in seconds.","list":false,"list_add_label":"Add More","name":"request_timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"spider_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Spider API Key","dynamic":false,"info":"The Spider API Key, get it from https://spider.cloud","input_types":[],"load_from_db":true,"name":"spider_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"url":{"_input_type":"StrInput","advanced":false,"display_name":"URL","dynamic":false,"info":"The URL to scrape or crawl","list":false,"list_add_label":"Add More","load_from_db":false,"name":"url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"whitelist":{"_input_type":"StrInput","advanced":true,"display_name":"Whitelist","dynamic":false,"info":"Whitelist paths that you want to crawl, ignoring all other routes. Use Regex patterns.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"whitelist","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ToolCallingAgent":{"base_classes":["AgentExecutor","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"An agent designed to utilize various tools seamlessly within workflows.","display_name":"Tool Calling Agent","documentation":"","edited":false,"field_order":["tools","input_value","handle_parsing_errors","verbose","max_iterations","agent_description","llm","system_prompt","chat_history"],"frozen":false,"icon":"LangChain","legacy":false,"metadata":{"code_hash":"66d6a728a58d","dependencies":{"dependencies":[{"name":"langchain","version":"0.3.23"},{"name":"langchain_core","version":"0.3.79"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.langchain_utilities.tool_calling.ToolCallingAgentComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Agent","group_outputs":false,"hidden":true,"method":"build_agent","name":"agent","selected":"AgentExecutor","tool_mode":false,"types":["AgentExecutor"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Response","group_outputs":false,"method":"message_response","name":"response","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","agent_description":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"Agent Description [Deprecated]","dynamic":false,"info":"The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"agent_description","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"A helpful assistant with access to the following tools:"},"chat_history":{"_input_type":"DataInput","advanced":true,"display_name":"Chat Memory","dynamic":false,"info":"This input stores the chat history, allowing the agent to remember previous conversations.","input_types":["Data"],"list":true,"list_add_label":"Add More","name":"chat_history","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain.agents import create_tool_calling_agent\nfrom langchain_core.prompts import ChatPromptTemplate\n\nfrom lfx.base.agents.agent import LCToolsAgentComponent\nfrom lfx.inputs.inputs import (\n    DataInput,\n    HandleInput,\n    MessageTextInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass ToolCallingAgentComponent(LCToolsAgentComponent):\n    display_name: str = \"Tool Calling Agent\"\n    description: str = \"An agent designed to utilize various tools seamlessly within workflows.\"\n    icon = \"LangChain\"\n    name = \"ToolCallingAgent\"\n\n    inputs = [\n        *LCToolsAgentComponent.get_base_inputs(),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n            info=\"Language model that the agent utilizes to perform tasks effectively.\",\n        ),\n        MessageTextInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"System prompt to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n        ),\n        DataInput(\n            name=\"chat_history\",\n            display_name=\"Chat Memory\",\n            is_list=True,\n            advanced=True,\n            info=\"This input stores the chat history, allowing the agent to remember previous conversations.\",\n        ),\n    ]\n\n    def get_chat_history_data(self) -> list[Data] | None:\n        return self.chat_history\n\n    def create_agent_runnable(self):\n        messages = [\n            (\"system\", \"{system_prompt}\"),\n            (\"placeholder\", \"{chat_history}\"),\n            (\"human\", \"{input}\"),\n            (\"placeholder\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        self.validate_tool_names()\n        try:\n            return create_tool_calling_agent(self.llm, self.tools or [], prompt)\n        except NotImplementedError as e:\n            message = f\"{self.display_name} does not support tool calling. Please try using a compatible model.\"\n            raise NotImplementedError(message) from e\n"},"handle_parsing_errors":{"_input_type":"BoolInput","advanced":true,"display_name":"Handle Parse Errors","dynamic":false,"info":"Should the Agent fix errors when reading user input for better processing?","list":false,"list_add_label":"Add More","name":"handle_parsing_errors","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"The input provided by the user for the agent to process.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"llm":{"_input_type":"HandleInput","advanced":false,"display_name":"Language Model","dynamic":false,"info":"Language model that the agent utilizes to perform tasks effectively.","input_types":["LanguageModel"],"list":false,"list_add_label":"Add More","name":"llm","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"max_iterations":{"_input_type":"IntInput","advanced":true,"display_name":"Max Iterations","dynamic":false,"info":"The maximum number of attempts the agent can make to complete its task before it stops.","list":false,"list_add_label":"Add More","name":"max_iterations","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":15},"system_prompt":{"_input_type":"MessageTextInput","advanced":false,"display_name":"System Prompt","dynamic":false,"info":"System prompt to guide the agent's behavior.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"system_prompt","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"You are a helpful assistant that can use tools to answer questions and perform tasks."},"tools":{"_input_type":"HandleInput","advanced":false,"display_name":"Tools","dynamic":false,"info":"These are the tools that the agent can use to help with tasks.","input_types":["Tool"],"list":true,"list_add_label":"Add More","name":"tools","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"verbose":{"_input_type":"BoolInput","advanced":true,"display_name":"Verbose","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"verbose","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false},"VectorStoreInfo":{"base_classes":["VectorStoreInfo"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Information about a VectorStore","display_name":"VectorStoreInfo","documentation":"","edited":false,"field_order":["vectorstore_name","vectorstore_description","input_vectorstore"],"frozen":false,"icon":"LangChain","legacy":true,"metadata":{"code_hash":"62f06efeec2c","dependencies":{"dependencies":[{"name":"langchain","version":"0.3.23"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.langchain_utilities.vector_store_info.VectorStoreInfoComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Vector Store Info","group_outputs":false,"method":"build_info","name":"info","selected":"VectorStoreInfo","tool_mode":true,"types":["VectorStoreInfo"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain.agents.agent_toolkits.vectorstore.toolkit import VectorStoreInfo\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import HandleInput, MessageTextInput, MultilineInput\nfrom lfx.template.field.base import Output\n\n\nclass VectorStoreInfoComponent(Component):\n    display_name = \"VectorStoreInfo\"\n    description = \"Information about a VectorStore\"\n    name = \"VectorStoreInfo\"\n    legacy: bool = True\n    icon = \"LangChain\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"vectorstore_name\",\n            display_name=\"Name\",\n            info=\"Name of the VectorStore\",\n            required=True,\n        ),\n        MultilineInput(\n            name=\"vectorstore_description\",\n            display_name=\"Description\",\n            info=\"Description of the VectorStore\",\n            required=True,\n        ),\n        HandleInput(\n            name=\"input_vectorstore\",\n            display_name=\"Vector Store\",\n            input_types=[\"VectorStore\"],\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Vector Store Info\", name=\"info\", method=\"build_info\"),\n    ]\n\n    def build_info(self) -> VectorStoreInfo:\n        self.status = {\n            \"name\": self.vectorstore_name,\n            \"description\": self.vectorstore_description,\n        }\n        return VectorStoreInfo(\n            vectorstore=self.input_vectorstore,\n            description=self.vectorstore_description,\n            name=self.vectorstore_name,\n        )\n"},"input_vectorstore":{"_input_type":"HandleInput","advanced":false,"display_name":"Vector Store","dynamic":false,"info":"","input_types":["VectorStore"],"list":false,"list_add_label":"Add More","name":"input_vectorstore","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"vectorstore_description":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Description","dynamic":false,"info":"Description of the VectorStore","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"vectorstore_description","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"vectorstore_name":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Name","dynamic":false,"info":"Name of the VectorStore","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"vectorstore_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"VectorStoreRouterAgent":{"base_classes":["AgentExecutor","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Construct an agent from a Vector Store Router.","display_name":"VectorStoreRouterAgent","documentation":"","edited":false,"field_order":["input_value","handle_parsing_errors","verbose","max_iterations","agent_description","llm","vectorstores"],"frozen":false,"legacy":true,"metadata":{"code_hash":"b16515f6e722","dependencies":{"dependencies":[{"name":"langchain","version":"0.3.23"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.langchain_utilities.vector_store_router.VectorStoreRouterAgentComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Agent","group_outputs":false,"hidden":true,"method":"build_agent","name":"agent","selected":"AgentExecutor","tool_mode":false,"types":["AgentExecutor"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Response","group_outputs":false,"method":"message_response","name":"response","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","agent_description":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"Agent Description [Deprecated]","dynamic":false,"info":"The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"agent_description","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"A helpful assistant with access to the following tools:"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain.agents import AgentExecutor, create_vectorstore_router_agent\nfrom langchain.agents.agent_toolkits.vectorstore.toolkit import VectorStoreRouterToolkit\n\nfrom lfx.base.agents.agent import LCAgentComponent\nfrom lfx.inputs.inputs import HandleInput\n\n\nclass VectorStoreRouterAgentComponent(LCAgentComponent):\n    display_name = \"VectorStoreRouterAgent\"\n    description = \"Construct an agent from a Vector Store Router.\"\n    name = \"VectorStoreRouterAgent\"\n    legacy: bool = True\n\n    inputs = [\n        *LCAgentComponent.get_base_inputs(),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        HandleInput(\n            name=\"vectorstores\",\n            display_name=\"Vector Stores\",\n            input_types=[\"VectorStoreInfo\"],\n            is_list=True,\n            required=True,\n        ),\n    ]\n\n    def build_agent(self) -> AgentExecutor:\n        toolkit = VectorStoreRouterToolkit(vectorstores=self.vectorstores, llm=self.llm)\n        return create_vectorstore_router_agent(llm=self.llm, toolkit=toolkit, **self.get_agent_kwargs())\n"},"handle_parsing_errors":{"_input_type":"BoolInput","advanced":true,"display_name":"Handle Parse Errors","dynamic":false,"info":"Should the Agent fix errors when reading user input for better processing?","list":false,"list_add_label":"Add More","name":"handle_parsing_errors","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"The input provided by the user for the agent to process.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"llm":{"_input_type":"HandleInput","advanced":false,"display_name":"Language Model","dynamic":false,"info":"","input_types":["LanguageModel"],"list":false,"list_add_label":"Add More","name":"llm","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"max_iterations":{"_input_type":"IntInput","advanced":true,"display_name":"Max Iterations","dynamic":false,"info":"The maximum number of attempts the agent can make to complete its task before it stops.","list":false,"list_add_label":"Add More","name":"max_iterations","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":15},"vectorstores":{"_input_type":"HandleInput","advanced":false,"display_name":"Vector Stores","dynamic":false,"info":"","input_types":["VectorStoreInfo"],"list":true,"list_add_label":"Add More","name":"vectorstores","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"verbose":{"_input_type":"BoolInput","advanced":true,"display_name":"Verbose","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"verbose","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false},"XMLAgent":{"base_classes":["AgentExecutor","Message"],"beta":true,"conditional_paths":[],"custom_fields":{},"description":"Agent that uses tools formatting instructions as xml to the Language Model.","display_name":"XML Agent","documentation":"","edited":false,"field_order":["tools","input_value","handle_parsing_errors","verbose","max_iterations","agent_description","llm","chat_history","system_prompt","user_prompt"],"frozen":false,"icon":"LangChain","legacy":false,"metadata":{"code_hash":"338332984901","dependencies":{"dependencies":[{"name":"langchain","version":"0.3.23"},{"name":"langchain_core","version":"0.3.79"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.langchain_utilities.xml_agent.XMLAgentComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Agent","group_outputs":false,"hidden":true,"method":"build_agent","name":"agent","selected":"AgentExecutor","tool_mode":false,"types":["AgentExecutor"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Response","group_outputs":false,"method":"message_response","name":"response","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","agent_description":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"Agent Description [Deprecated]","dynamic":false,"info":"The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"agent_description","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"A helpful assistant with access to the following tools:"},"chat_history":{"_input_type":"DataInput","advanced":true,"display_name":"Chat History","dynamic":false,"info":"","input_types":["Data"],"list":true,"list_add_label":"Add More","name":"chat_history","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain.agents import create_xml_agent\nfrom langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n\nfrom lfx.base.agents.agent import LCToolsAgentComponent\nfrom lfx.inputs.inputs import (\n    DataInput,\n    HandleInput,\n    MultilineInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass XMLAgentComponent(LCToolsAgentComponent):\n    display_name: str = \"XML Agent\"\n    description: str = \"Agent that uses tools formatting instructions as xml to the Language Model.\"\n    icon = \"LangChain\"\n    beta = True\n    name = \"XMLAgent\"\n    inputs = [\n        *LCToolsAgentComponent.get_base_inputs(),\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\n        DataInput(name=\"chat_history\", display_name=\"Chat History\", is_list=True, advanced=True),\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"System prompt for the agent.\",\n            value=\"\"\"You are a helpful assistant. Help the user answer any questions.\n\nYou have access to the following tools:\n\n{tools}\n\nIn order to use a tool, you can use <tool></tool> and <tool_input></tool_input> tags. You will then get back a response in the form <observation></observation>\n\nFor example, if you have a tool called 'search' that could run a google search, in order to search for the weather in SF you would respond:\n\n<tool>search</tool><tool_input>weather in SF</tool_input>\n\n<observation>64 degrees</observation>\n\nWhen you are done, respond with a final answer between <final_answer></final_answer>. For example:\n\n<final_answer>The weather in SF is 64 degrees</final_answer>\n\nBegin!\n\nQuestion: {input}\n\n{agent_scratchpad}\n            \"\"\",  # noqa: E501\n        ),\n        MultilineInput(\n            name=\"user_prompt\", display_name=\"Prompt\", info=\"This prompt must contain 'input' key.\", value=\"{input}\"\n        ),\n    ]\n\n    def get_chat_history_data(self) -> list[Data] | None:\n        return self.chat_history\n\n    def create_agent_runnable(self):\n        if \"input\" not in self.user_prompt:\n            msg = \"Prompt must contain 'input' key.\"\n            raise ValueError(msg)\n        messages = [\n            (\"system\", self.system_prompt),\n            (\"placeholder\", \"{chat_history}\"),\n            HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[\"input\"], template=self.user_prompt)),\n            (\"ai\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        return create_xml_agent(self.llm, self.tools, prompt)\n"},"handle_parsing_errors":{"_input_type":"BoolInput","advanced":true,"display_name":"Handle Parse Errors","dynamic":false,"info":"Should the Agent fix errors when reading user input for better processing?","list":false,"list_add_label":"Add More","name":"handle_parsing_errors","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"The input provided by the user for the agent to process.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"llm":{"_input_type":"HandleInput","advanced":false,"display_name":"Language Model","dynamic":false,"info":"","input_types":["LanguageModel"],"list":false,"list_add_label":"Add More","name":"llm","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"max_iterations":{"_input_type":"IntInput","advanced":true,"display_name":"Max Iterations","dynamic":false,"info":"The maximum number of attempts the agent can make to complete its task before it stops.","list":false,"list_add_label":"Add More","name":"max_iterations","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":15},"system_prompt":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Prompt","dynamic":false,"info":"System prompt for the agent.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_prompt","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"You are a helpful assistant. Help the user answer any questions.\n\nYou have access to the following tools:\n\n{tools}\n\nIn order to use a tool, you can use <tool></tool> and <tool_input></tool_input> tags. You will then get back a response in the form <observation></observation>\n\nFor example, if you have a tool called 'search' that could run a google search, in order to search for the weather in SF you would respond:\n\n<tool>search</tool><tool_input>weather in SF</tool_input>\n\n<observation>64 degrees</observation>\n\nWhen you are done, respond with a final answer between <final_answer></final_answer>. For example:\n\n<final_answer>The weather in SF is 64 degrees</final_answer>\n\nBegin!\n\nQuestion: {input}\n\n{agent_scratchpad}\n            "},"tools":{"_input_type":"HandleInput","advanced":false,"display_name":"Tools","dynamic":false,"info":"These are the tools that the agent can use to help with tasks.","input_types":["Tool"],"list":true,"list_add_label":"Add More","name":"tools","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"user_prompt":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Prompt","dynamic":false,"info":"This prompt must contain 'input' key.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"user_prompt","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"{input}"},"verbose":{"_input_type":"BoolInput","advanced":true,"display_name":"Verbose","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"verbose","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false}}],["langwatch",{"LangWatchEvaluator":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Evaluates various aspects of language models using LangWatch's evaluation endpoints.","display_name":"LangWatch Evaluator","documentation":"https://docs.langwatch.ai/langevals/documentation/introduction","edited":false,"field_order":["evaluator_name","api_key","input","output","expected_output","contexts","timeout"],"frozen":false,"icon":"Langwatch","legacy":false,"metadata":{"code_hash":"6db3bccd5945","dependencies":{"dependencies":[{"name":"httpx","version":"0.28.1"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.langwatch.langwatch.LangWatchComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Evaluation Result","group_outputs":false,"method":"evaluate","name":"evaluation_result","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"LangWatch API Key","dynamic":false,"info":"Enter your LangWatch API key.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nimport os\nfrom typing import Any\n\nimport httpx\n\nfrom lfx.base.langwatch.utils import get_cached_evaluators\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import MultilineInput\nfrom lfx.io import (\n    BoolInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    MessageTextInput,\n    NestedDictInput,\n    Output,\n    SecretStrInput,\n)\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.dotdict import dotdict\n\n\nclass LangWatchComponent(Component):\n    display_name: str = \"LangWatch Evaluator\"\n    description: str = \"Evaluates various aspects of language models using LangWatch's evaluation endpoints.\"\n    documentation: str = \"https://docs.langwatch.ai/langevals/documentation/introduction\"\n    icon: str = \"Langwatch\"\n    name: str = \"LangWatchEvaluator\"\n\n    inputs = [\n        DropdownInput(\n            name=\"evaluator_name\",\n            display_name=\"Evaluator Name\",\n            options=[],\n            required=True,\n            info=\"Select an evaluator.\",\n            refresh_button=True,\n            real_time_refresh=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"LangWatch API Key\",\n            required=True,\n            info=\"Enter your LangWatch API key.\",\n        ),\n        MessageTextInput(\n            name=\"input\",\n            display_name=\"Input\",\n            required=False,\n            info=\"The input text for evaluation.\",\n        ),\n        MessageTextInput(\n            name=\"output\",\n            display_name=\"Output\",\n            required=False,\n            info=\"The output text for evaluation.\",\n        ),\n        MessageTextInput(\n            name=\"expected_output\",\n            display_name=\"Expected Output\",\n            required=False,\n            info=\"The expected output for evaluation.\",\n        ),\n        MessageTextInput(\n            name=\"contexts\",\n            display_name=\"Contexts\",\n            required=False,\n            info=\"The contexts for evaluation (comma-separated).\",\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The maximum time (in seconds) allowed for the server to respond before timing out.\",\n            value=30,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"evaluation_result\", display_name=\"Evaluation Result\", method=\"evaluate\"),\n    ]\n\n    def set_evaluators(self, endpoint: str):\n        url = f\"{endpoint}/api/evaluations/list\"\n        self.evaluators = get_cached_evaluators(url)\n        if not self.evaluators or len(self.evaluators) == 0:\n            self.status = f\"No evaluators found from {endpoint}\"\n            msg = f\"No evaluators found from {endpoint}\"\n            raise ValueError(msg)\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        try:\n            logger.info(f\"Updating build config. Field name: {field_name}, Field value: {field_value}\")\n\n            if field_name is None or field_name == \"evaluator_name\":\n                self.evaluators = self.get_evaluators(os.getenv(\"LANGWATCH_ENDPOINT\", \"https://app.langwatch.ai\"))\n                build_config[\"evaluator_name\"][\"options\"] = list(self.evaluators.keys())\n\n                # Set a default evaluator if none is selected\n                if not getattr(self, \"current_evaluator\", None) and self.evaluators:\n                    self.current_evaluator = next(iter(self.evaluators))\n                    build_config[\"evaluator_name\"][\"value\"] = self.current_evaluator\n\n                # Define default keys that should always be present\n                default_keys = [\"code\", \"_type\", \"evaluator_name\", \"api_key\", \"input\", \"output\", \"timeout\"]\n\n                if field_value and field_value in self.evaluators and self.current_evaluator != field_value:\n                    self.current_evaluator = field_value\n                    evaluator = self.evaluators[field_value]\n\n                    # Clear previous dynamic inputs\n                    keys_to_remove = [key for key in build_config if key not in default_keys]\n                    for key in keys_to_remove:\n                        del build_config[key]\n\n                    # Clear component's dynamic attributes\n                    for attr in list(self.__dict__.keys()):\n                        if attr not in default_keys and attr not in {\n                            \"evaluators\",\n                            \"dynamic_inputs\",\n                            \"_code\",\n                            \"current_evaluator\",\n                        }:\n                            delattr(self, attr)\n\n                    # Add new dynamic inputs\n                    self.dynamic_inputs = self.get_dynamic_inputs(evaluator)\n                    for name, input_config in self.dynamic_inputs.items():\n                        build_config[name] = input_config.to_dict()\n\n                    # Update required fields\n                    required_fields = {\"api_key\", \"evaluator_name\"}.union(evaluator.get(\"requiredFields\", []))\n                    for key in build_config:\n                        if isinstance(build_config[key], dict):\n                            build_config[key][\"required\"] = key in required_fields\n\n                # Validate presence of default keys\n                missing_keys = [key for key in default_keys if key not in build_config]\n                if missing_keys:\n                    logger.warning(f\"Missing required keys in build_config: {missing_keys}\")\n                    # Add missing keys with default values\n                    for key in missing_keys:\n                        build_config[key] = {\"value\": None, \"type\": \"str\"}\n\n            # Ensure the current_evaluator is always set in the build_config\n            build_config[\"evaluator_name\"][\"value\"] = self.current_evaluator\n\n            logger.info(f\"Current evaluator set to: {self.current_evaluator}\")\n\n        except (KeyError, AttributeError, ValueError) as e:\n            self.status = f\"Error updating component: {e!s}\"\n        return build_config\n\n    def get_dynamic_inputs(self, evaluator: dict[str, Any]):\n        try:\n            dynamic_inputs = {}\n\n            input_fields = [\n                field\n                for field in evaluator.get(\"requiredFields\", []) + evaluator.get(\"optionalFields\", [])\n                if field not in {\"input\", \"output\"}\n            ]\n\n            for field in input_fields:\n                input_params = {\n                    \"name\": field,\n                    \"display_name\": field.replace(\"_\", \" \").title(),\n                    \"required\": field in evaluator.get(\"requiredFields\", []),\n                }\n                if field == \"contexts\":\n                    dynamic_inputs[field] = MultilineInput(**input_params, multiline=True)\n                else:\n                    dynamic_inputs[field] = MessageTextInput(**input_params)\n\n            settings = evaluator.get(\"settings\", {})\n            for setting_name, setting_config in settings.items():\n                schema = evaluator.get(\"settings_json_schema\", {}).get(\"properties\", {}).get(setting_name, {})\n\n                input_params = {\n                    \"name\": setting_name,\n                    \"display_name\": setting_name.replace(\"_\", \" \").title(),\n                    \"info\": setting_config.get(\"description\", \"\"),\n                    \"required\": False,\n                }\n\n                if schema.get(\"type\") == \"object\":\n                    input_type = NestedDictInput\n                    input_params[\"value\"] = schema.get(\"default\", setting_config.get(\"default\", {}))\n                elif schema.get(\"type\") == \"boolean\":\n                    input_type = BoolInput\n                    input_params[\"value\"] = schema.get(\"default\", setting_config.get(\"default\", False))\n                elif schema.get(\"type\") == \"number\":\n                    is_float = isinstance(schema.get(\"default\", setting_config.get(\"default\")), float)\n                    input_type = FloatInput if is_float else IntInput\n                    input_params[\"value\"] = schema.get(\"default\", setting_config.get(\"default\", 0))\n                elif \"enum\" in schema:\n                    input_type = DropdownInput\n                    input_params[\"options\"] = schema[\"enum\"]\n                    input_params[\"value\"] = schema.get(\"default\", setting_config.get(\"default\"))\n                else:\n                    input_type = MessageTextInput\n                    default_value = schema.get(\"default\", setting_config.get(\"default\"))\n                    input_params[\"value\"] = str(default_value) if default_value is not None else \"\"\n\n                dynamic_inputs[setting_name] = input_type(**input_params)\n\n        except (KeyError, AttributeError, ValueError, TypeError) as e:\n            self.status = f\"Error creating dynamic inputs: {e!s}\"\n            return {}\n        return dynamic_inputs\n\n    async def evaluate(self) -> Data:\n        if not self.api_key:\n            return Data(data={\"error\": \"API key is required\"})\n\n        self.set_evaluators(os.getenv(\"LANGWATCH_ENDPOINT\", \"https://app.langwatch.ai\"))\n        self.dynamic_inputs = {}\n        if getattr(self, \"current_evaluator\", None) is None and self.evaluators:\n            self.current_evaluator = next(iter(self.evaluators))\n\n        # Prioritize evaluator_name if it exists\n        evaluator_name = getattr(self, \"evaluator_name\", None) or self.current_evaluator\n\n        if not evaluator_name:\n            if self.evaluators:\n                evaluator_name = next(iter(self.evaluators))\n                await logger.ainfo(f\"No evaluator was selected. Using default: {evaluator_name}\")\n            else:\n                return Data(\n                    data={\"error\": \"No evaluator selected and no evaluators available. Please choose an evaluator.\"}\n                )\n\n        try:\n            evaluator = self.evaluators.get(evaluator_name)\n            if not evaluator:\n                return Data(data={\"error\": f\"Selected evaluator '{evaluator_name}' not found.\"})\n\n            await logger.ainfo(f\"Evaluating with evaluator: {evaluator_name}\")\n\n            endpoint = f\"/api/evaluations/{evaluator_name}/evaluate\"\n            url = f\"{os.getenv('LANGWATCH_ENDPOINT', 'https://app.langwatch.ai')}{endpoint}\"\n\n            headers = {\"Content-Type\": \"application/json\", \"X-Auth-Token\": self.api_key}\n\n            payload = {\n                \"data\": {\n                    \"input\": self.input,\n                    \"output\": self.output,\n                    \"expected_output\": self.expected_output,\n                    \"contexts\": self.contexts.split(\",\") if self.contexts else [],\n                },\n                \"settings\": {},\n            }\n\n            if self._tracing_service:\n                tracer = self._tracing_service.get_tracer(\"langwatch\")\n                if tracer is not None and hasattr(tracer, \"trace_id\"):\n                    payload[\"settings\"][\"trace_id\"] = str(tracer.trace_id)\n\n            for setting_name in self.dynamic_inputs:\n                payload[\"settings\"][setting_name] = getattr(self, setting_name, None)\n\n            async with httpx.AsyncClient(timeout=self.timeout) as client:\n                response = await client.post(url, json=payload, headers=headers)\n\n            response.raise_for_status()\n            result = response.json()\n\n            formatted_result = json.dumps(result, indent=2)\n            self.status = f\"Evaluation completed successfully. Result:\\n{formatted_result}\"\n            return Data(data=result)\n\n        except (httpx.RequestError, KeyError, AttributeError, ValueError) as e:\n            error_message = f\"Evaluation error: {e!s}\"\n            self.status = error_message\n            return Data(data={\"error\": error_message})\n"},"contexts":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Contexts","dynamic":false,"info":"The contexts for evaluation (comma-separated).","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"contexts","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"evaluator_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Evaluator Name","dynamic":false,"external_options":{},"info":"Select an evaluator.","name":"evaluator_name","options":[],"options_metadata":[],"placeholder":"","real_time_refresh":true,"refresh_button":true,"required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"expected_output":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Expected Output","dynamic":false,"info":"The expected output for evaluation.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"expected_output","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"input":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Input","dynamic":false,"info":"The input text for evaluation.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"output":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Output","dynamic":false,"info":"The output text for evaluation.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"output","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"timeout":{"_input_type":"IntInput","advanced":true,"display_name":"Timeout","dynamic":false,"info":"The maximum time (in seconds) allowed for the server to respond before timing out.","list":false,"list_add_label":"Add More","name":"timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":30}},"tool_mode":false}}],["lmstudio",{"LMStudioEmbeddingsComponent":{"base_classes":["Embeddings"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate embeddings using LM Studio.","display_name":"LM Studio Embeddings","documentation":"","edited":false,"field_order":["model","base_url","api_key","temperature"],"frozen":false,"icon":"LMStudio","legacy":false,"metadata":{"code_hash":"ecd584b7a486","dependencies":{"dependencies":[{"name":"httpx","version":"0.28.1"},{"name":"lfx","version":null},{"name":"langchain_nvidia_ai_endpoints","version":"0.3.8"}],"total_dependencies":3},"module":"lfx.components.lmstudio.lmstudioembeddings.LMStudioEmbeddingsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Embedding Model","group_outputs":false,"method":"build_embeddings","name":"embeddings","selected":"Embeddings","tool_mode":true,"types":["Embeddings"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":true,"display_name":"LM Studio API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":"LMSTUDIO_API_KEY"},"base_url":{"_input_type":"MessageTextInput","advanced":false,"display_name":"LM Studio Base URL","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","refresh_button":true,"required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"http://localhost:1234/v1"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\nfrom urllib.parse import urljoin\n\nimport httpx\n\nfrom lfx.base.embeddings.model import LCEmbeddingsModel\nfrom lfx.field_typing import Embeddings\nfrom lfx.inputs.inputs import DropdownInput, SecretStrInput\nfrom lfx.io import FloatInput, MessageTextInput\n\n\nclass LMStudioEmbeddingsComponent(LCEmbeddingsModel):\n    display_name: str = \"LM Studio Embeddings\"\n    description: str = \"Generate embeddings using LM Studio.\"\n    icon = \"LMStudio\"\n\n    async def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None):  # noqa: ARG002\n        if field_name == \"model\":\n            base_url_dict = build_config.get(\"base_url\", {})\n            base_url_load_from_db = base_url_dict.get(\"load_from_db\", False)\n            base_url_value = base_url_dict.get(\"value\")\n            if base_url_load_from_db:\n                base_url_value = await self.get_variables(base_url_value, field_name)\n            elif not base_url_value:\n                base_url_value = \"http://localhost:1234/v1\"\n            build_config[\"model\"][\"options\"] = await self.get_model(base_url_value)\n\n        return build_config\n\n    @staticmethod\n    async def get_model(base_url_value: str) -> list[str]:\n        try:\n            url = urljoin(base_url_value, \"/v1/models\")\n            async with httpx.AsyncClient() as client:\n                response = await client.get(url)\n                response.raise_for_status()\n                data = response.json()\n\n                return [model[\"id\"] for model in data.get(\"data\", [])]\n        except Exception as e:\n            msg = \"Could not retrieve models. Please, make sure the LM Studio server is running.\"\n            raise ValueError(msg) from e\n\n    inputs = [\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            refresh_button=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"base_url\",\n            display_name=\"LM Studio Base URL\",\n            refresh_button=True,\n            value=\"http://localhost:1234/v1\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"LM Studio API Key\",\n            advanced=True,\n            value=\"LMSTUDIO_API_KEY\",\n        ),\n        FloatInput(\n            name=\"temperature\",\n            display_name=\"Model Temperature\",\n            value=0.1,\n            advanced=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        try:\n            from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n        except ImportError as e:\n            msg = \"Please install langchain-nvidia-ai-endpoints to use LM Studio Embeddings.\"\n            raise ImportError(msg) from e\n        try:\n            output = NVIDIAEmbeddings(\n                model=self.model,\n                base_url=self.base_url,\n                temperature=self.temperature,\n                nvidia_api_key=self.api_key,\n            )\n        except Exception as e:\n            msg = f\"Could not connect to LM Studio API. Error: {e}\"\n            raise ValueError(msg) from e\n        return output\n"},"model":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model","dynamic":false,"external_options":{},"info":"","name":"model","options":[],"options_metadata":[],"placeholder":"","refresh_button":true,"required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"FloatInput","advanced":true,"display_name":"Model Temperature","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"temperature","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.1}},"tool_mode":false},"LMStudioModel":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate text using LM Studio Local LLMs.","display_name":"LM Studio","documentation":"","edited":false,"field_order":["input_value","system_message","stream","max_tokens","model_kwargs","model_name","base_url","api_key","temperature","seed"],"frozen":false,"icon":"LMStudio","legacy":false,"metadata":{"code_hash":"da4b3b155dc4","dependencies":{"dependencies":[{"name":"httpx","version":"0.28.1"},{"name":"langchain_openai","version":"0.3.23"},{"name":"lfx","version":null},{"name":"openai","version":"1.82.1"}],"total_dependencies":4},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.lmstudio.lmstudiomodel.LMStudioModelComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":true,"display_name":"LM Studio API Key","dynamic":false,"info":"The LM Studio API Key to use for LM Studio.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":"LMSTUDIO_API_KEY"},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"Endpoint of the LM Studio API. Defaults to 'http://localhost:1234/v1' if not specified.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"http://localhost:1234/v1"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\nfrom urllib.parse import urljoin\n\nimport httpx\nfrom langchain_openai import ChatOpenAI\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.inputs.inputs import DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\n\n\nclass LMStudioModelComponent(LCModelComponent):\n    display_name = \"LM Studio\"\n    description = \"Generate text using LM Studio Local LLMs.\"\n    icon = \"LMStudio\"\n    name = \"LMStudioModel\"\n\n    async def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None):  # noqa: ARG002\n        if field_name == \"model_name\":\n            base_url_dict = build_config.get(\"base_url\", {})\n            base_url_load_from_db = base_url_dict.get(\"load_from_db\", False)\n            base_url_value = base_url_dict.get(\"value\")\n            if base_url_load_from_db:\n                base_url_value = await self.get_variables(base_url_value, field_name)\n            try:\n                async with httpx.AsyncClient() as client:\n                    response = await client.get(urljoin(base_url_value, \"/v1/models\"), timeout=2.0)\n                    response.raise_for_status()\n            except httpx.HTTPError:\n                msg = \"Could not access the default LM Studio URL. Please, specify the 'Base URL' field.\"\n                self.log(msg)\n                return build_config\n            build_config[\"model_name\"][\"options\"] = await self.get_model(base_url_value)\n\n        return build_config\n\n    @staticmethod\n    async def get_model(base_url_value: str) -> list[str]:\n        try:\n            url = urljoin(base_url_value, \"/v1/models\")\n            async with httpx.AsyncClient() as client:\n                response = await client.get(url)\n                response.raise_for_status()\n                data = response.json()\n\n                return [model[\"id\"] for model in data.get(\"data\", [])]\n        except Exception as e:\n            msg = \"Could not retrieve models. Please, make sure the LM Studio server is running.\"\n            raise ValueError(msg) from e\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            refresh_button=True,\n        ),\n        StrInput(\n            name=\"base_url\",\n            display_name=\"Base URL\",\n            advanced=False,\n            info=\"Endpoint of the LM Studio API. Defaults to 'http://localhost:1234/v1' if not specified.\",\n            value=\"http://localhost:1234/v1\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"LM Studio API Key\",\n            info=\"The LM Studio API Key to use for LM Studio.\",\n            advanced=True,\n            value=\"LMSTUDIO_API_KEY\",\n        ),\n        FloatInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        lmstudio_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        base_url = self.base_url or \"http://localhost:1234/v1\"\n        seed = self.seed\n\n        return ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=base_url,\n            api_key=lmstudio_api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an LM Studio exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n"},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"max_tokens":{"_input_type":"IntInput","advanced":true,"display_name":"Max Tokens","dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","list":false,"list_add_label":"Add More","name":"max_tokens","placeholder":"","range_spec":{"max":128000.0,"min":0.0,"step":0.1,"step_type":"float"},"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"model_kwargs":{"_input_type":"DictInput","advanced":true,"display_name":"Model Kwargs","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"model_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model Name","dynamic":false,"external_options":{},"info":"","name":"model_name","options":[],"options_metadata":[],"placeholder":"","refresh_button":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"seed":{"_input_type":"IntInput","advanced":true,"display_name":"Seed","dynamic":false,"info":"The seed controls the reproducibility of the job.","list":false,"list_add_label":"Add More","name":"seed","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"FloatInput","advanced":true,"display_name":"Temperature","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"temperature","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.1}},"tool_mode":false}}],["logic",{"ConditionalRouter":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Routes an input message to a corresponding output based on text comparison.","display_name":"If-Else","documentation":"https://docs.langflow.org/components-logic#conditional-router-if-else-component","edited":false,"field_order":["input_text","operator","match_text","case_sensitive","true_case_message","false_case_message","max_iterations","default_route"],"frozen":false,"icon":"split","legacy":false,"metadata":{"code_hash":"4506a833d145","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.logic.conditional_router.ConditionalRouterComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"True","group_outputs":true,"method":"true_response","name":"true_result","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"False","group_outputs":true,"method":"false_response","name":"false_result","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","case_sensitive":{"_input_type":"BoolInput","advanced":true,"display_name":"Case Sensitive","dynamic":false,"info":"If true, the comparison will be case sensitive.","list":false,"list_add_label":"Add More","name":"case_sensitive","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import re\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\nfrom lfx.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"If-Else\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    documentation: str = \"https://docs.langflow.org/components-logic#conditional-router-if-else-component\"\n    icon = \"split\"\n    name = \"ConditionalRouter\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Text Input\",\n            info=\"The primary text input for the operation.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\n                \"equals\",\n                \"not equals\",\n                \"contains\",\n                \"starts with\",\n                \"ends with\",\n                \"regex\",\n                \"less than\",\n                \"less than or equal\",\n                \"greater than\",\n                \"greater than or equal\",\n            ],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=True,\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"true_case_message\",\n            display_name=\"Case True\",\n            info=\"The message to pass if the condition is True.\",\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"false_case_message\",\n            display_name=\"Case False\",\n            info=\"The message to pass if the condition is False.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_iterations\",\n            display_name=\"Max Iterations\",\n            info=\"The maximum number of iterations for the conditional router.\",\n            value=10,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"default_route\",\n            display_name=\"Default Route\",\n            options=[\"true_result\", \"false_result\"],\n            info=\"The default route to take when max iterations are reached.\",\n            value=\"false_result\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\", group_outputs=True),\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\", group_outputs=True),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, *, case_sensitive: bool) -> bool:\n        if not case_sensitive and operator != \"regex\":\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        if operator == \"not equals\":\n            return input_text != match_text\n        if operator == \"contains\":\n            return match_text in input_text\n        if operator == \"starts with\":\n            return input_text.startswith(match_text)\n        if operator == \"ends with\":\n            return input_text.endswith(match_text)\n        if operator == \"regex\":\n            try:\n                return bool(re.match(match_text, input_text))\n            except re.error:\n                return False  # Return False if the regex is invalid\n        if operator in [\"less than\", \"less than or equal\", \"greater than\", \"greater than or equal\"]:\n            try:\n                input_num = float(input_text)\n                match_num = float(match_text)\n                if operator == \"less than\":\n                    return input_num < match_num\n                if operator == \"less than or equal\":\n                    return input_num <= match_num\n                if operator == \"greater than\":\n                    return input_num > match_num\n                if operator == \"greater than or equal\":\n                    return input_num >= match_num\n            except ValueError:\n                return False  # Invalid number format for comparison\n        return False\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n        \"\"\"Handles cycle iteration counting and branch exclusion.\n\n        Uses two complementary mechanisms:\n        1. stop() - ACTIVE/INACTIVE state for cycle management (gets reset each iteration)\n        2. exclude_branch_conditionally() - Persistent exclusion for conditional routing\n\n        When max_iterations is reached, breaks the cycle by allowing the default_route to execute.\n        \"\"\"\n        if not self.__iteration_updated:\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n            self.__iteration_updated = True\n            current_iteration = self.ctx.get(f\"{self._id}_iteration\", 0)\n\n            # Check if max iterations reached and we're trying to stop the default route\n            if current_iteration >= self.max_iterations and route_to_stop == self.default_route:\n                # Clear ALL conditional exclusions to allow default route to execute\n                if self._id in self.graph.conditional_exclusion_sources:\n                    previous_exclusions = self.graph.conditional_exclusion_sources[self._id]\n                    self.graph.conditionally_excluded_vertices -= previous_exclusions\n                    del self.graph.conditional_exclusion_sources[self._id]\n\n                # Switch which route to stop - stop the NON-default route to break the cycle\n                route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\n\n                # Call stop to break the cycle\n                self.stop(route_to_stop)\n                # Don't apply conditional exclusion when breaking cycle\n                return\n\n            # Normal case: Use BOTH mechanisms\n            # 1. stop() for cycle management (marks INACTIVE, updates run manager, gets reset)\n            self.stop(route_to_stop)\n\n            # 2. Conditional exclusion for persistent routing (doesn't get reset except by this router)\n            self.graph.exclude_branch_conditionally(self._id, output_name=route_to_stop)\n\n    def true_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n\n        # Check if we should force output due to max_iterations on default route\n        current_iteration = self.ctx.get(f\"{self._id}_iteration\", 0)\n        force_output = current_iteration >= self.max_iterations and self.default_route == \"true_result\"\n\n        if result or force_output:\n            self.status = self.true_case_message\n            if not force_output:  # Only stop the other branch if not forcing due to max iterations\n                self.iterate_and_stop_once(\"false_result\")\n            return self.true_case_message\n        self.iterate_and_stop_once(\"true_result\")\n        return Message(content=\"\")\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n\n        if not result:\n            self.status = self.false_case_message\n            self.iterate_and_stop_once(\"true_result\")\n            return self.false_case_message\n\n        self.iterate_and_stop_once(\"false_result\")\n        return Message(content=\"\")\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        if field_name == \"operator\":\n            if field_value == \"regex\":\n                build_config.pop(\"case_sensitive\", None)\n            elif \"case_sensitive\" not in build_config:\n                case_sensitive_input = next(\n                    (input_field for input_field in self.inputs if input_field.name == \"case_sensitive\"), None\n                )\n                if case_sensitive_input:\n                    build_config[\"case_sensitive\"] = case_sensitive_input.to_dict()\n        return build_config\n"},"default_route":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Default Route","dynamic":false,"external_options":{},"info":"The default route to take when max iterations are reached.","name":"default_route","options":["true_result","false_result"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"false_result"},"false_case_message":{"_input_type":"MessageInput","advanced":true,"display_name":"Case False","dynamic":false,"info":"The message to pass if the condition is False.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"false_case_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"input_text":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Text Input","dynamic":false,"info":"The primary text input for the operation.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_text","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"match_text":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Match Text","dynamic":false,"info":"The text input to compare against.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"match_text","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"max_iterations":{"_input_type":"IntInput","advanced":true,"display_name":"Max Iterations","dynamic":false,"info":"The maximum number of iterations for the conditional router.","list":false,"list_add_label":"Add More","name":"max_iterations","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":10},"operator":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Operator","dynamic":false,"external_options":{},"info":"The operator to apply for comparing the texts.","name":"operator","options":["equals","not equals","contains","starts with","ends with","regex","less than","less than or equal","greater than","greater than or equal"],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"equals"},"true_case_message":{"_input_type":"MessageInput","advanced":true,"display_name":"Case True","dynamic":false,"info":"The message to pass if the condition is True.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"true_case_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"DataConditionalRouter":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Route Data object(s) based on a condition applied to a specified key, including boolean validation.","display_name":"Condition","documentation":"","edited":false,"field_order":["data_input","key_name","operator","compare_value"],"frozen":false,"icon":"split","legacy":true,"metadata":{"code_hash":"6fa1bf4166a3","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.logic.data_conditional_router.DataConditionalRouterComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"True Output","group_outputs":false,"method":"process_data","name":"true_output","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"False Output","group_outputs":false,"method":"process_data","name":"false_output","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["logic.ConditionalRouter"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import DataInput, DropdownInput, MessageTextInput, Output\nfrom lfx.schema.data import Data\nfrom lfx.schema.dotdict import dotdict\n\n\nclass DataConditionalRouterComponent(Component):\n    display_name = \"Condition\"\n    description = \"Route Data object(s) based on a condition applied to a specified key, including boolean validation.\"\n    icon = \"split\"\n    name = \"DataConditionalRouter\"\n    legacy = True\n    replacement = [\"logic.ConditionalRouter\"]\n\n    inputs = [\n        DataInput(\n            name=\"data_input\",\n            display_name=\"Data Input\",\n            info=\"The Data object or list of Data objects to process\",\n            is_list=True,\n        ),\n        MessageTextInput(\n            name=\"key_name\",\n            display_name=\"Key Name\",\n            info=\"The name of the key in the Data object(s) to check\",\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\", \"boolean validator\"],\n            info=\"The operator to apply for comparing the values. 'boolean validator' treats the value as a boolean.\",\n            value=\"equals\",\n        ),\n        MessageTextInput(\n            name=\"compare_value\",\n            display_name=\"Match Text\",\n            info=\"The value to compare against (not used for boolean validator)\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True Output\", name=\"true_output\", method=\"process_data\"),\n        Output(display_name=\"False Output\", name=\"false_output\", method=\"process_data\"),\n    ]\n\n    def compare_values(self, item_value: str, compare_value: str, operator: str) -> bool:\n        if operator == \"equals\":\n            return item_value == compare_value\n        if operator == \"not equals\":\n            return item_value != compare_value\n        if operator == \"contains\":\n            return compare_value in item_value\n        if operator == \"starts with\":\n            return item_value.startswith(compare_value)\n        if operator == \"ends with\":\n            return item_value.endswith(compare_value)\n        if operator == \"boolean validator\":\n            return self.parse_boolean(item_value)\n        return False\n\n    def parse_boolean(self, value):\n        if isinstance(value, bool):\n            return value\n        if isinstance(value, str):\n            return value.lower() in {\"true\", \"1\", \"yes\", \"y\", \"on\"}\n        return bool(value)\n\n    def validate_input(self, data_item: Data) -> bool:\n        if not isinstance(data_item, Data):\n            self.status = \"Input is not a Data object\"\n            return False\n        if self.key_name not in data_item.data:\n            self.status = f\"Key '{self.key_name}' not found in Data\"\n            return False\n        return True\n\n    def process_data(self) -> Data | list[Data]:\n        if isinstance(self.data_input, list):\n            true_output = []\n            false_output = []\n            for item in self.data_input:\n                if self.validate_input(item):\n                    result = self.process_single_data(item)\n                    if result:\n                        true_output.append(item)\n                    else:\n                        false_output.append(item)\n            self.stop(\"false_output\" if true_output else \"true_output\")\n            return true_output or false_output\n        if not self.validate_input(self.data_input):\n            return Data(data={\"error\": self.status})\n        result = self.process_single_data(self.data_input)\n        self.stop(\"false_output\" if result else \"true_output\")\n        return self.data_input\n\n    def process_single_data(self, data_item: Data) -> bool:\n        item_value = data_item.data[self.key_name]\n        operator = self.operator\n\n        if operator == \"boolean validator\":\n            condition_met = self.parse_boolean(item_value)\n            condition_description = f\"Boolean validation of '{self.key_name}'\"\n        else:\n            compare_value = self.compare_value\n            condition_met = self.compare_values(str(item_value), compare_value, operator)\n            condition_description = f\"{self.key_name} {operator} {compare_value}\"\n\n        if condition_met:\n            self.status = f\"Condition met: {condition_description}\"\n            return True\n        self.status = f\"Condition not met: {condition_description}\"\n        return False\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"operator\":\n            if field_value == \"boolean validator\":\n                build_config[\"compare_value\"][\"show\"] = False\n                build_config[\"compare_value\"][\"advanced\"] = True\n                build_config[\"compare_value\"][\"value\"] = None\n            else:\n                build_config[\"compare_value\"][\"show\"] = True\n                build_config[\"compare_value\"][\"advanced\"] = False\n\n        return build_config\n"},"compare_value":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Match Text","dynamic":false,"info":"The value to compare against (not used for boolean validator)","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"compare_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"data_input":{"_input_type":"DataInput","advanced":false,"display_name":"Data Input","dynamic":false,"info":"The Data object or list of Data objects to process","input_types":["Data"],"list":true,"list_add_label":"Add More","name":"data_input","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"key_name":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Key Name","dynamic":false,"info":"The name of the key in the Data object(s) to check","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"key_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"operator":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Operator","dynamic":false,"external_options":{},"info":"The operator to apply for comparing the values. 'boolean validator' treats the value as a boolean.","name":"operator","options":["equals","not equals","contains","starts with","ends with","boolean validator"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"equals"}},"tool_mode":false},"FlowTool":{"base_classes":["Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Construct a Tool from a function that runs the loaded Flow.","display_name":"Flow as Tool","documentation":"","edited":false,"field_order":["flow_name","tool_name","tool_description","return_direct"],"frozen":false,"icon":"hammer","legacy":true,"metadata":{"code_hash":"9348d79d19f4","dependencies":{"dependencies":[{"name":"typing_extensions","version":"4.15.0"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.logic.flow_tool.FlowToolComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"api_build_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["logic.RunFlow"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom typing_extensions import override\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.base.tools.flow_tool import FlowTool\nfrom lfx.field_typing import Tool\nfrom lfx.graph.graph.base import Graph\nfrom lfx.helpers import get_flow_inputs\nfrom lfx.io import BoolInput, DropdownInput, Output, StrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.dotdict import dotdict\n\n\nclass FlowToolComponent(LCToolComponent):\n    display_name = \"Flow as Tool\"\n    description = \"Construct a Tool from a function that runs the loaded Flow.\"\n    field_order = [\"flow_name\", \"name\", \"description\", \"return_direct\"]\n    trace_type = \"tool\"\n    name = \"FlowTool\"\n    legacy: bool = True\n    replacement = [\"logic.RunFlow\"]\n    icon = \"hammer\"\n\n    async def get_flow_names(self) -> list[str]:\n        flow_datas = await self.alist_flows()\n        return [flow_data.data[\"name\"] for flow_data in flow_datas]\n\n    async def get_flow(self, flow_name: str) -> Data | None:\n        \"\"\"Retrieves a flow by its name.\n\n        Args:\n            flow_name (str): The name of the flow to retrieve.\n\n        Returns:\n            Optional[Text]: The flow record if found, None otherwise.\n        \"\"\"\n        flow_datas = await self.alist_flows()\n        for flow_data in flow_datas:\n            if flow_data.data[\"name\"] == flow_name:\n                return flow_data\n        return None\n\n    @override\n    async def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"flow_name\":\n            build_config[\"flow_name\"][\"options\"] = self.get_flow_names()\n\n        return build_config\n\n    inputs = [\n        DropdownInput(\n            name=\"flow_name\", display_name=\"Flow Name\", info=\"The name of the flow to run.\", refresh_button=True\n        ),\n        StrInput(\n            name=\"tool_name\",\n            display_name=\"Name\",\n            info=\"The name of the tool.\",\n        ),\n        StrInput(\n            name=\"tool_description\",\n            display_name=\"Description\",\n            info=\"The description of the tool; defaults to the Flow's description.\",\n        ),\n        BoolInput(\n            name=\"return_direct\",\n            display_name=\"Return Direct\",\n            info=\"Return the result directly from the Tool.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"api_build_tool\", display_name=\"Tool\", method=\"build_tool\"),\n    ]\n\n    async def build_tool(self) -> Tool:\n        FlowTool.model_rebuild()\n        if \"flow_name\" not in self._attributes or not self._attributes[\"flow_name\"]:\n            msg = \"Flow name is required\"\n            raise ValueError(msg)\n        flow_name = self._attributes[\"flow_name\"]\n        flow_data = await self.get_flow(flow_name)\n        if not flow_data:\n            msg = \"Flow not found.\"\n            raise ValueError(msg)\n        graph = Graph.from_payload(\n            flow_data.data[\"data\"],\n            user_id=str(self.user_id),\n        )\n        try:\n            graph.set_run_id(self.graph.run_id)\n        except Exception:  # noqa: BLE001\n            logger.warning(\"Failed to set run_id\", exc_info=True)\n        inputs = get_flow_inputs(graph)\n        tool_description = self.tool_description.strip() or flow_data.description\n        tool = FlowTool(\n            name=self.tool_name,\n            description=tool_description,\n            graph=graph,\n            return_direct=self.return_direct,\n            inputs=inputs,\n            flow_id=str(flow_data.id),\n            user_id=str(self.user_id),\n            session_id=self.graph.session_id if hasattr(self, \"graph\") else None,\n        )\n        description_repr = repr(tool.description).strip(\"'\")\n        args_str = \"\\n\".join([f\"- {arg_name}: {arg_data['description']}\" for arg_name, arg_data in tool.args.items()])\n        self.status = f\"{description_repr}\\nArguments:\\n{args_str}\"\n        return tool\n"},"flow_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Flow Name","dynamic":false,"external_options":{},"info":"The name of the flow to run.","name":"flow_name","options":[],"options_metadata":[],"placeholder":"","refresh_button":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"return_direct":{"_input_type":"BoolInput","advanced":true,"display_name":"Return Direct","dynamic":false,"info":"Return the result directly from the Tool.","list":false,"list_add_label":"Add More","name":"return_direct","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"tool_description":{"_input_type":"StrInput","advanced":false,"display_name":"Description","dynamic":false,"info":"The description of the tool; defaults to the Flow's description.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tool_description","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tool_name":{"_input_type":"StrInput","advanced":false,"display_name":"Name","dynamic":false,"info":"The name of the tool.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tool_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"Listen":{"base_classes":["Data"],"beta":true,"conditional_paths":[],"custom_fields":{},"description":"A component to listen for a notification.","display_name":"Listen","documentation":"","edited":false,"field_order":["context_key"],"frozen":false,"icon":"Radio","legacy":false,"metadata":{"code_hash":"93fc11377c96","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.logic.listen.ListenComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":false,"display_name":"Data","group_outputs":false,"method":"listen_for_data","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom import Component\nfrom lfx.io import Output, StrInput\nfrom lfx.schema.data import Data\n\n\nclass ListenComponent(Component):\n    display_name = \"Listen\"\n    description = \"A component to listen for a notification.\"\n    name = \"Listen\"\n    beta: bool = True\n    icon = \"Radio\"\n    inputs = [\n        StrInput(\n            name=\"context_key\",\n            display_name=\"Context Key\",\n            info=\"The key of the context to listen for.\",\n            input_types=[\"Message\"],\n            required=True,\n        )\n    ]\n\n    outputs = [Output(name=\"data\", display_name=\"Data\", method=\"listen_for_data\", cache=False)]\n\n    def listen_for_data(self) -> Data:\n        \"\"\"Retrieves a Data object from the component context using the provided context key.\n\n        If the specified context key does not exist in the context, returns an empty Data object.\n        \"\"\"\n        return self.ctx.get(self.context_key, Data(text=\"\"))\n"},"context_key":{"_input_type":"StrInput","advanced":false,"display_name":"Context Key","dynamic":false,"info":"The key of the context to listen for.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"context_key","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"LoopComponent":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Iterates over a list of Data objects, outputting one item at a time and aggregating results from loop inputs.","display_name":"Loop","documentation":"https://docs.langflow.org/components-logic#loop","edited":false,"field_order":["data"],"frozen":false,"icon":"infinity","legacy":false,"metadata":{"code_hash":"394284181e18","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.logic.loop.LoopComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":true,"cache":true,"display_name":"Item","group_outputs":true,"method":"item_output","name":"item","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Done","group_outputs":true,"method":"done_output","name":"done","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import HandleInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.template.field.base import Output\n\n\nclass LoopComponent(Component):\n    display_name = \"Loop\"\n    description = (\n        \"Iterates over a list of Data objects, outputting one item at a time and aggregating results from loop inputs.\"\n    )\n    documentation: str = \"https://docs.langflow.org/components-logic#loop\"\n    icon = \"infinity\"\n\n    inputs = [\n        HandleInput(\n            name=\"data\",\n            display_name=\"Inputs\",\n            info=\"The initial list of Data objects or DataFrame to iterate over.\",\n            input_types=[\"DataFrame\"],\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Item\", name=\"item\", method=\"item_output\", allows_loop=True, group_outputs=True),\n        Output(display_name=\"Done\", name=\"done\", method=\"done_output\", group_outputs=True),\n    ]\n\n    def initialize_data(self) -> None:\n        \"\"\"Initialize the data list, context index, and aggregated list.\"\"\"\n        if self.ctx.get(f\"{self._id}_initialized\", False):\n            return\n\n        # Ensure data is a list of Data objects\n        data_list = self._validate_data(self.data)\n\n        # Store the initial data and context variables\n        self.update_ctx(\n            {\n                f\"{self._id}_data\": data_list,\n                f\"{self._id}_index\": 0,\n                f\"{self._id}_aggregated\": [],\n                f\"{self._id}_initialized\": True,\n            }\n        )\n\n    def _validate_data(self, data):\n        \"\"\"Validate and return a list of Data objects.\"\"\"\n        if isinstance(data, DataFrame):\n            return data.to_data_list()\n        if isinstance(data, Data):\n            return [data]\n        if isinstance(data, list) and all(isinstance(item, Data) for item in data):\n            return data\n        msg = \"The 'data' input must be a DataFrame, a list of Data objects, or a single Data object.\"\n        raise TypeError(msg)\n\n    def evaluate_stop_loop(self) -> bool:\n        \"\"\"Evaluate whether to stop item or done output.\"\"\"\n        current_index = self.ctx.get(f\"{self._id}_index\", 0)\n        data_length = len(self.ctx.get(f\"{self._id}_data\", []))\n        return current_index > data_length\n\n    def item_output(self) -> Data:\n        \"\"\"Output the next item in the list or stop if done.\"\"\"\n        self.initialize_data()\n        current_item = Data(text=\"\")\n\n        if self.evaluate_stop_loop():\n            self.stop(\"item\")\n        else:\n            # Get data list and current index\n            data_list, current_index = self.loop_variables()\n            if current_index < len(data_list):\n                # Output current item and increment index\n                try:\n                    current_item = data_list[current_index]\n                except IndexError:\n                    current_item = Data(text=\"\")\n            self.aggregated_output()\n            self.update_ctx({f\"{self._id}_index\": current_index + 1})\n\n        # Now we need to update the dependencies for the next run\n        self.update_dependency()\n        return current_item\n\n    def update_dependency(self):\n        item_dependency_id = self.get_incoming_edge_by_target_param(\"item\")\n        if item_dependency_id not in self.graph.run_manager.run_predecessors[self._id]:\n            self.graph.run_manager.run_predecessors[self._id].append(item_dependency_id)\n            # CRITICAL: Also update run_map so remove_from_predecessors() works correctly\n            # run_map[predecessor] = list of vertices that depend on predecessor\n            if self._id not in self.graph.run_manager.run_map[item_dependency_id]:\n                self.graph.run_manager.run_map[item_dependency_id].append(self._id)\n\n    def done_output(self) -> DataFrame:\n        \"\"\"Trigger the done output when iteration is complete.\"\"\"\n        self.initialize_data()\n\n        if self.evaluate_stop_loop():\n            self.stop(\"item\")\n            self.start(\"done\")\n\n            aggregated = self.ctx.get(f\"{self._id}_aggregated\", [])\n\n            return DataFrame(aggregated)\n        self.stop(\"done\")\n        return DataFrame([])\n\n    def loop_variables(self):\n        \"\"\"Retrieve loop variables from context.\"\"\"\n        return (\n            self.ctx.get(f\"{self._id}_data\", []),\n            self.ctx.get(f\"{self._id}_index\", 0),\n        )\n\n    def aggregated_output(self) -> list[Data]:\n        \"\"\"Return the aggregated list once all items are processed.\"\"\"\n        self.initialize_data()\n\n        # Get data list and aggregated list\n        data_list = self.ctx.get(f\"{self._id}_data\", [])\n        aggregated = self.ctx.get(f\"{self._id}_aggregated\", [])\n        loop_input = self.item\n        if loop_input is not None and not isinstance(loop_input, str) and len(aggregated) <= len(data_list):\n            aggregated.append(loop_input)\n            self.update_ctx({f\"{self._id}_aggregated\": aggregated})\n        return aggregated\n"},"data":{"_input_type":"HandleInput","advanced":false,"display_name":"Inputs","dynamic":false,"info":"The initial list of Data objects or DataFrame to iterate over.","input_types":["DataFrame"],"list":false,"list_add_label":"Add More","name":"data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""}},"tool_mode":false},"Notify":{"base_classes":["Data"],"beta":true,"conditional_paths":[],"custom_fields":{},"description":"A component to generate a notification to Get Notified component.","display_name":"Notify","documentation":"","edited":false,"field_order":["context_key","input_value","append"],"frozen":false,"icon":"Notify","legacy":false,"metadata":{"code_hash":"03d68ba28530","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.logic.notify.NotifyComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":false,"display_name":"Data","group_outputs":false,"method":"notify_components","name":"result","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","append":{"_input_type":"BoolInput","advanced":false,"display_name":"Append","dynamic":false,"info":"If True, the record will be appended to the notification.","list":false,"list_add_label":"Add More","name":"append","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import cast\n\nfrom lfx.custom import Component\nfrom lfx.io import BoolInput, HandleInput, Output, StrInput\nfrom lfx.schema.data import Data\n\n\nclass NotifyComponent(Component):\n    display_name = \"Notify\"\n    description = \"A component to generate a notification to Get Notified component.\"\n    icon = \"Notify\"\n    name = \"Notify\"\n    beta: bool = True\n\n    inputs = [\n        StrInput(\n            name=\"context_key\",\n            display_name=\"Context Key\",\n            info=\"The key of the context to store the notification.\",\n            required=True,\n        ),\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Input Data\",\n            info=\"The data to store.\",\n            required=False,\n            input_types=[\"Data\", \"Message\", \"DataFrame\"],\n        ),\n        BoolInput(\n            name=\"append\",\n            display_name=\"Append\",\n            info=\"If True, the record will be appended to the notification.\",\n            value=False,\n            required=False,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Data\",\n            name=\"result\",\n            method=\"notify_components\",\n            cache=False,\n        ),\n    ]\n\n    async def notify_components(self) -> Data:\n        \"\"\"Processes and stores a notification in the component's context.\n\n        Normalizes the input value to a `Data` object and stores it under the\n        specified context key. If `append` is True, adds the value to a list\n        of notifications; otherwise, replaces the existing value. Updates the\n        component's status and activates related state vertices in the graph.\n\n        Returns:\n            The processed `Data` object stored in the context.\n\n        Raises:\n            ValueError: If the component is not part of a graph.\n        \"\"\"\n        if not self._vertex:\n            msg = \"Notify component must be used in a graph.\"\n            raise ValueError(msg)\n        input_value: Data | str | dict | None = self.input_value\n        if input_value is None:\n            input_value = Data(text=\"\")\n        elif not isinstance(input_value, Data):\n            if isinstance(input_value, str):\n                input_value = Data(text=input_value)\n            elif isinstance(input_value, dict):\n                input_value = Data(data=input_value)\n            else:\n                input_value = Data(text=str(input_value))\n        if input_value:\n            if self.append:\n                current_data = self.ctx.get(self.context_key, [])\n                if not isinstance(current_data, list):\n                    current_data = [current_data]\n                current_data.append(input_value)\n                self.update_ctx({self.context_key: current_data})\n            else:\n                self.update_ctx({self.context_key: input_value})\n            self.status = input_value\n        else:\n            self.status = \"No record provided.\"\n        self._vertex.is_state = True\n        self.graph.activate_state_vertices(name=self.context_key, caller=self._id)\n        return cast(\"Data\", input_value)\n"},"context_key":{"_input_type":"StrInput","advanced":false,"display_name":"Context Key","dynamic":false,"info":"The key of the context to store the notification.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"context_key","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"input_value":{"_input_type":"HandleInput","advanced":false,"display_name":"Input Data","dynamic":false,"info":"The data to store.","input_types":["Data","Message","DataFrame"],"list":false,"list_add_label":"Add More","name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""}},"tool_mode":false},"Pass":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Forwards the input message, unchanged.","display_name":"Pass","documentation":"","edited":false,"field_order":["input_message","ignored_message"],"frozen":false,"icon":"arrow-right","legacy":true,"metadata":{"code_hash":"04d3e1ed3390","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.logic.pass_message.PassMessageComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Output Message","group_outputs":false,"method":"pass_message","name":"output_message","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["logic.ConditionalRouter"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.io import MessageInput\nfrom lfx.schema.message import Message\nfrom lfx.template.field.base import Output\n\n\nclass PassMessageComponent(Component):\n    display_name = \"Pass\"\n    description = \"Forwards the input message, unchanged.\"\n    name = \"Pass\"\n    icon = \"arrow-right\"\n    legacy: bool = True\n    replacement = [\"logic.ConditionalRouter\"]\n\n    inputs = [\n        MessageInput(\n            name=\"input_message\",\n            display_name=\"Input Message\",\n            info=\"The message to be passed forward.\",\n            required=True,\n        ),\n        MessageInput(\n            name=\"ignored_message\",\n            display_name=\"Ignored Message\",\n            info=\"A second message to be ignored. Used as a workaround for continuity.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output Message\", name=\"output_message\", method=\"pass_message\"),\n    ]\n\n    def pass_message(self) -> Message:\n        self.status = self.input_message\n        return self.input_message\n"},"ignored_message":{"_input_type":"MessageInput","advanced":true,"display_name":"Ignored Message","dynamic":false,"info":"A second message to be ignored. Used as a workaround for continuity.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"ignored_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"input_message":{"_input_type":"MessageInput","advanced":false,"display_name":"Input Message","dynamic":false,"info":"The message to be passed forward.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_message","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"RunFlow":{"base_classes":["Data","DataFrame","Message"],"beta":true,"conditional_paths":[],"custom_fields":{},"description":"Creates a tool component from a Flow that takes all its inputs and runs it.  \n **Select a Flow to use the tool mode**","display_name":"Run Flow","documentation":"https://docs.langflow.org/components-logic#run-flow","edited":false,"field_order":["flow_name_selected","session_id"],"frozen":false,"icon":"Workflow","legacy":false,"metadata":{"code_hash":"0c0d3c1be2d8","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.logic.run_flow.RunFlowComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Flow Data Output","group_outputs":true,"hidden":true,"method":"data_output","name":"flow_outputs_data","selected":"Data","tool_mode":false,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Flow Dataframe Output","group_outputs":true,"hidden":true,"method":"dataframe_output","name":"flow_outputs_dataframe","selected":"DataFrame","tool_mode":false,"types":["DataFrame"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Flow Message Output","group_outputs":true,"method":"message_output","name":"flow_outputs_message","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom lfx.base.tools.run_flow import RunFlowBaseComponent\nfrom lfx.helpers import run_flow\nfrom lfx.log.logger import logger\nfrom lfx.schema.dotdict import dotdict\n\n\nclass RunFlowComponent(RunFlowBaseComponent):\n    display_name = \"Run Flow\"\n    description = (\n        \"Creates a tool component from a Flow that takes all its inputs and runs it. \"\n        \" \\n **Select a Flow to use the tool mode**\"\n    )\n    documentation: str = \"https://docs.langflow.org/components-logic#run-flow\"\n    beta = True\n    name = \"RunFlow\"\n    icon = \"Workflow\"\n\n    inputs = RunFlowBaseComponent.get_base_inputs()\n    outputs = RunFlowBaseComponent.get_base_outputs()\n\n    async def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"flow_name_selected\":\n            build_config[\"flow_name_selected\"][\"options\"] = await self.get_flow_names()\n            missing_keys = [key for key in self.default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n            if field_value is not None:\n                try:\n                    graph = await self.get_graph(field_value)\n                    build_config = self.update_build_config_from_graph(build_config, graph)\n                except Exception as e:\n                    msg = f\"Error building graph for flow {field_value}\"\n                    await logger.aexception(msg)\n                    raise RuntimeError(msg) from e\n        return build_config\n\n    async def run_flow_with_tweaks(self):\n        tweaks: dict = {}\n\n        flow_name_selected = self._attributes.get(\"flow_name_selected\")\n        parsed_flow_tweak_data = self._attributes.get(\"flow_tweak_data\", {})\n        if not isinstance(parsed_flow_tweak_data, dict):\n            parsed_flow_tweak_data = parsed_flow_tweak_data.dict()\n\n        if parsed_flow_tweak_data != {}:\n            for field in parsed_flow_tweak_data:\n                if \"~\" in field:\n                    [node, name] = field.split(\"~\")\n                    if node not in tweaks:\n                        tweaks[node] = {}\n                    tweaks[node][name] = parsed_flow_tweak_data[field]\n        else:\n            for field in self._attributes:\n                if field not in self.default_keys and \"~\" in field:\n                    [node, name] = field.split(\"~\")\n                    if node not in tweaks:\n                        tweaks[node] = {}\n                    tweaks[node][name] = self._attributes[field]\n\n        return await run_flow(\n            inputs=None,\n            output_type=\"all\",\n            flow_id=None,\n            flow_name=flow_name_selected,\n            tweaks=tweaks,\n            user_id=str(self.user_id),\n            session_id=self.graph.session_id or self.session_id,\n        )\n"},"flow_name_selected":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Flow Name","dynamic":false,"external_options":{},"info":"The name of the flow to run.","name":"flow_name_selected","options":[],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str"},"session_id":{"_input_type":"MessageInput","advanced":true,"display_name":"Session ID","dynamic":false,"info":"The session ID to run the flow in.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"session_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"SmartRouter":{"base_classes":[],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Routes an input message using LLM-based categorization.","display_name":"Smart Router","documentation":"","edited":false,"field_order":["llm","input_text","routes","message","enable_else_output","custom_prompt"],"frozen":false,"icon":"equal","legacy":false,"metadata":{"code_hash":"c07080af208a","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.logic.llm_conditional_router.SmartRouterComponent"},"minimized":false,"output_types":[],"outputs":[],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom lfx.custom import Component\nfrom lfx.io import BoolInput, HandleInput, MessageInput, MessageTextInput, MultilineInput, Output, TableInput\nfrom lfx.schema.message import Message\nfrom lfx.schema.table import EditMode\n\n\nclass SmartRouterComponent(Component):\n    display_name = \"Smart Router\"\n    description = \"Routes an input message using LLM-based categorization.\"\n    icon = \"equal\"\n    name = \"SmartRouter\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self._matched_category = None\n\n    inputs = [\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"LLM to use for categorization.\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Input\",\n            info=\"The primary text input for the operation.\",\n            required=True,\n        ),\n        TableInput(\n            name=\"routes\",\n            display_name=\"Routes\",\n            info=(\n                \"Define the categories for routing. Each row should have a route/category name \"\n                \"and optionally a custom output value.\"\n            ),\n            table_schema=[\n                {\n                    \"name\": \"route_category\",\n                    \"display_name\": \"Route Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Name for the route (used for both output name and category matching)\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"route_description\",\n                    \"display_name\": \"Route Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Description of when this route should be used (helps LLM understand the category)\",\n                    \"default\": \"\",\n                    \"edit_mode\": EditMode.POPOVER,\n                },\n                {\n                    \"name\": \"output_value\",\n                    \"display_name\": \"Route Message (Optional)\",\n                    \"type\": \"str\",\n                    \"description\": (\n                        \"Optional message to send when this route is matched.\"\n                        \"Leave empty to pass through the original input text.\"\n                    ),\n                    \"default\": \"\",\n                    \"edit_mode\": EditMode.POPOVER,\n                },\n            ],\n            value=[\n                {\n                    \"route_category\": \"Positive\",\n                    \"route_description\": \"Positive feedback, satisfaction, or compliments\",\n                    \"output_value\": \"\",\n                },\n                {\n                    \"route_category\": \"Negative\",\n                    \"route_description\": \"Complaints, issues, or dissatisfaction\",\n                    \"output_value\": \"\",\n                },\n            ],\n            real_time_refresh=True,\n            required=True,\n        ),\n        MessageInput(\n            name=\"message\",\n            display_name=\"Override Output\",\n            info=(\n                \"Optional override message that will replace both the Input and Output Value \"\n                \"for all routes when filled.\"\n            ),\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"enable_else_output\",\n            display_name=\"Include Else Output\",\n            info=\"Include an Else output for cases that don't match any route.\",\n            value=False,\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"custom_prompt\",\n            display_name=\"Additional Instructions\",\n            info=(\n                \"Additional instructions for LLM-based categorization. \"\n                \"These will be added to the base prompt. \"\n                \"Use {input_text} for the input text and {routes} for the available categories.\"\n            ),\n            advanced=True,\n        ),\n    ]\n\n    outputs: list[Output] = []\n\n    def update_outputs(self, frontend_node: dict, field_name: str, field_value: Any) -> dict:\n        \"\"\"Create a dynamic output for each category in the categories table.\"\"\"\n        if field_name in {\"routes\", \"enable_else_output\"}:\n            frontend_node[\"outputs\"] = []\n\n            # Get the routes data - either from field_value (if routes field) or from component state\n            routes_data = field_value if field_name == \"routes\" else getattr(self, \"routes\", [])\n\n            # Add a dynamic output for each category - all using the same method\n            for i, row in enumerate(routes_data):\n                route_category = row.get(\"route_category\", f\"Category {i + 1}\")\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=route_category,\n                        name=f\"category_{i + 1}_result\",\n                        method=\"process_case\",\n                        group_outputs=True,\n                    )\n                )\n            # Add default output only if enabled\n            if field_name == \"enable_else_output\":\n                enable_else = field_value\n            else:\n                enable_else = getattr(self, \"enable_else_output\", False)\n\n            if enable_else:\n                frontend_node[\"outputs\"].append(\n                    Output(display_name=\"Else\", name=\"default_result\", method=\"default_response\", group_outputs=True)\n                )\n        return frontend_node\n\n    def process_case(self) -> Message:\n        \"\"\"Process all categories using LLM categorization and return message for matching category.\"\"\"\n        # Clear any previous match state\n        self._matched_category = None\n\n        # Get categories and input text\n        categories = getattr(self, \"routes\", [])\n        input_text = getattr(self, \"input_text\", \"\")\n\n        # Find the matching category using LLM-based categorization\n        matched_category = None\n        llm = getattr(self, \"llm\", None)\n\n        if llm and categories:\n            # Create prompt for categorization\n            category_info = []\n            for i, category in enumerate(categories):\n                cat_name = category.get(\"route_category\", f\"Category {i + 1}\")\n                cat_desc = category.get(\"route_description\", \"\")\n                if cat_desc and cat_desc.strip():\n                    category_info.append(f'\"{cat_name}\": {cat_desc}')\n                else:\n                    category_info.append(f'\"{cat_name}\"')\n\n            categories_text = \"\\n\".join([f\"- {info}\" for info in category_info if info])\n\n            # Create base prompt\n            base_prompt = (\n                f\"You are a text classifier. Given the following text and categories, \"\n                f\"determine which category best matches the text.\\n\\n\"\n                f'Text to classify: \"{input_text}\"\\n\\n'\n                f\"Available categories:\\n{categories_text}\\n\\n\"\n                f\"Respond with ONLY the exact category name that best matches the text. \"\n                f'If none match well, respond with \"NONE\".\\n\\n'\n                f\"Category:\"\n            )\n\n            # Use custom prompt as additional instructions if provided\n            custom_prompt = getattr(self, \"custom_prompt\", \"\")\n            if custom_prompt and custom_prompt.strip():\n                self.status = \"Using custom prompt as additional instructions\"\n                # Format custom prompt with variables\n                # For the routes variable, create a simpler format for custom prompt usage\n                simple_routes = \", \".join(\n                    [f'\"{cat.get(\"route_category\", f\"Category {i + 1}\")}\"' for i, cat in enumerate(categories)]\n                )\n                formatted_custom = custom_prompt.format(input_text=input_text, routes=simple_routes)\n                # Combine base prompt with custom instructions\n                prompt = f\"{base_prompt}\\n\\nAdditional Instructions:\\n{formatted_custom}\"\n            else:\n                self.status = \"Using default prompt for LLM categorization\"\n                prompt = base_prompt\n\n            # Log the final prompt being sent to LLM\n            self.status = f\"Prompt sent to LLM:\\n{prompt}\"\n\n            try:\n                # Use the LLM to categorize\n                if hasattr(llm, \"invoke\"):\n                    response = llm.invoke(prompt)\n                    if hasattr(response, \"content\"):\n                        categorization = response.content.strip().strip('\"')\n                    else:\n                        categorization = str(response).strip().strip('\"')\n                else:\n                    categorization = str(llm(prompt)).strip().strip('\"')\n\n                # Log the categorization process\n                self.status = f\"LLM response: '{categorization}'\"\n\n                # Find matching category based on LLM response\n                for i, category in enumerate(categories):\n                    route_category = category.get(\"route_category\", \"\")\n\n                    # Log each comparison attempt\n                    self.status = (\n                        f\"Comparing '{categorization}' with category {i + 1}: route_category='{route_category}'\"\n                    )\n\n                    # Case-insensitive match\n                    if categorization.lower() == route_category.lower():\n                        matched_category = i\n                        self.status = f\"MATCH FOUND! Category {i + 1} matched with '{categorization}'\"\n                        break\n\n                if matched_category is None:\n                    self.status = (\n                        f\"No match found for '{categorization}'. Available categories: \"\n                        f\"{[category.get('route_category', '') for category in categories]}\"\n                    )\n\n            except RuntimeError as e:\n                self.status = f\"Error in LLM categorization: {e!s}\"\n        else:\n            self.status = \"No LLM provided for categorization\"\n\n        if matched_category is not None:\n            # Store the matched category for other outputs to check\n            self._matched_category = matched_category\n\n            # Stop all category outputs except the matched one\n            for i in range(len(categories)):\n                if i != matched_category:\n                    self.stop(f\"category_{i + 1}_result\")\n\n            # Also stop the default output (if it exists)\n            enable_else = getattr(self, \"enable_else_output\", False)\n            if enable_else:\n                self.stop(\"default_result\")\n\n            route_category = categories[matched_category].get(\"route_category\", f\"Category {matched_category + 1}\")\n            self.status = f\"Categorized as {route_category}\"\n\n            # Check if there's an override output (takes precedence over everything)\n            override_output = getattr(self, \"message\", None)\n            if (\n                override_output\n                and hasattr(override_output, \"text\")\n                and override_output.text\n                and str(override_output.text).strip()\n            ):\n                return Message(text=str(override_output.text))\n            if override_output and isinstance(override_output, str) and override_output.strip():\n                return Message(text=str(override_output))\n\n            # Check if there's a custom output value for this category\n            custom_output = categories[matched_category].get(\"output_value\", \"\")\n            # Treat None, empty string, or whitespace as blank\n            if custom_output and str(custom_output).strip() and str(custom_output).strip().lower() != \"none\":\n                # Use custom output value\n                return Message(text=str(custom_output))\n            # Use input as default output\n            return Message(text=input_text)\n        # No match found, stop all category outputs\n        for i in range(len(categories)):\n            self.stop(f\"category_{i + 1}_result\")\n\n        # Check if else output is enabled\n        enable_else = getattr(self, \"enable_else_output\", False)\n        if enable_else:\n            # The default_response will handle the else case\n            self.stop(\"process_case\")\n            return Message(text=\"\")\n        # No else output, so no output at all\n        self.status = \"No match found and Else output is disabled\"\n        return Message(text=\"\")\n\n    def default_response(self) -> Message:\n        \"\"\"Handle the else case when no conditions match.\"\"\"\n        # Check if else output is enabled\n        enable_else = getattr(self, \"enable_else_output\", False)\n        if not enable_else:\n            self.status = \"Else output is disabled\"\n            return Message(text=\"\")\n\n        # Clear any previous match state if not already set\n        if not hasattr(self, \"_matched_category\"):\n            self._matched_category = None\n\n        categories = getattr(self, \"routes\", [])\n        input_text = getattr(self, \"input_text\", \"\")\n\n        # Check if a match was already found in process_case\n        if hasattr(self, \"_matched_category\") and self._matched_category is not None:\n            self.status = (\n                f\"Match already found in process_case (Category {self._matched_category + 1}), \"\n                \"stopping default_response\"\n            )\n            self.stop(\"default_result\")\n            return Message(text=\"\")\n\n        # Check if any category matches using LLM categorization\n        has_match = False\n        llm = getattr(self, \"llm\", None)\n\n        if llm and categories:\n            try:\n                # Create prompt for categorization\n                category_info = []\n                for i, category in enumerate(categories):\n                    cat_name = category.get(\"route_category\", f\"Category {i + 1}\")\n                    cat_desc = category.get(\"route_description\", \"\")\n                    if cat_desc and cat_desc.strip():\n                        category_info.append(f'\"{cat_name}\": {cat_desc}')\n                    else:\n                        category_info.append(f'\"{cat_name}\"')\n\n                categories_text = \"\\n\".join([f\"- {info}\" for info in category_info if info])\n\n                # Create base prompt\n                base_prompt = (\n                    \"You are a text classifier. Given the following text and categories, \"\n                    \"determine which category best matches the text.\\n\\n\"\n                    f'Text to classify: \"{input_text}\"\\n\\n'\n                    f\"Available categories:\\n{categories_text}\\n\\n\"\n                    \"Respond with ONLY the exact category name that best matches the text. \"\n                    'If none match well, respond with \"NONE\".\\n\\n'\n                    \"Category:\"\n                )\n\n                # Use custom prompt as additional instructions if provided\n                custom_prompt = getattr(self, \"custom_prompt\", \"\")\n                if custom_prompt and custom_prompt.strip():\n                    self.status = \"Using custom prompt as additional instructions (default check)\"\n                    # Format custom prompt with variables\n                    # For the routes variable, create a simpler format for custom prompt usage\n                    simple_routes = \", \".join(\n                        [f'\"{cat.get(\"route_category\", f\"Category {i + 1}\")}\"' for i, cat in enumerate(categories)]\n                    )\n                    formatted_custom = custom_prompt.format(input_text=input_text, routes=simple_routes)\n                    # Combine base prompt with custom instructions\n                    prompt = f\"{base_prompt}\\n\\nAdditional Instructions:\\n{formatted_custom}\"\n                else:\n                    self.status = \"Using default prompt for LLM categorization (default check)\"\n                    prompt = base_prompt\n\n                # Log the final prompt being sent to LLM for default check\n                self.status = f\"Default check - Prompt sent to LLM:\\n{prompt}\"\n\n                # Use the LLM to categorize\n                if hasattr(llm, \"invoke\"):\n                    response = llm.invoke(prompt)\n                    if hasattr(response, \"content\"):\n                        categorization = response.content.strip().strip('\"')\n                    else:\n                        categorization = str(response).strip().strip('\"')\n                else:\n                    categorization = str(llm(prompt)).strip().strip('\"')\n\n                # Log the categorization process for default check\n                self.status = f\"Default check - LLM response: '{categorization}'\"\n\n                # Check if LLM response matches any category\n                for i, category in enumerate(categories):\n                    route_category = category.get(\"route_category\", \"\")\n\n                    # Log each comparison attempt\n                    self.status = (\n                        f\"Default check - Comparing '{categorization}' with category {i + 1}: \"\n                        f\"route_category='{route_category}'\"\n                    )\n\n                    if categorization.lower() == route_category.lower():\n                        has_match = True\n                        self.status = f\"Default check - MATCH FOUND! Category {i + 1} matched with '{categorization}'\"\n                        break\n\n                if not has_match:\n                    self.status = (\n                        f\"Default check - No match found for '{categorization}'. \"\n                        f\"Available categories: \"\n                        f\"{[category.get('route_category', '') for category in categories]}\"\n                    )\n\n            except RuntimeError:\n                pass  # If there's an error, treat as no match\n\n        if has_match:\n            # A case matches, stop this output\n            self.stop(\"default_result\")\n            return Message(text=\"\")\n\n        # No case matches, check for override output first, then use input as default\n        override_output = getattr(self, \"message\", None)\n        if (\n            override_output\n            and hasattr(override_output, \"text\")\n            and override_output.text\n            and str(override_output.text).strip()\n        ):\n            self.status = \"Routed to Else (no match) - using override output\"\n            return Message(text=str(override_output.text))\n        if override_output and isinstance(override_output, str) and override_output.strip():\n            self.status = \"Routed to Else (no match) - using override output\"\n            return Message(text=str(override_output))\n        self.status = \"Routed to Else (no match) - using input as default\"\n        return Message(text=input_text)\n"},"custom_prompt":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"Additional Instructions","dynamic":false,"info":"Additional instructions for LLM-based categorization. These will be added to the base prompt. Use {input_text} for the input text and {routes} for the available categories.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"custom_prompt","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"enable_else_output":{"_input_type":"BoolInput","advanced":true,"display_name":"Include Else Output","dynamic":false,"info":"Include an Else output for cases that don't match any route.","list":false,"list_add_label":"Add More","name":"enable_else_output","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"input_text":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Input","dynamic":false,"info":"The primary text input for the operation.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_text","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"llm":{"_input_type":"HandleInput","advanced":false,"display_name":"Language Model","dynamic":false,"info":"LLM to use for categorization.","input_types":["LanguageModel"],"list":false,"list_add_label":"Add More","name":"llm","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"message":{"_input_type":"MessageInput","advanced":true,"display_name":"Override Output","dynamic":false,"info":"Optional override message that will replace both the Input and Output Value for all routes when filled.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"routes":{"_input_type":"TableInput","advanced":false,"display_name":"Routes","dynamic":false,"info":"Define the categories for routing. Each row should have a route/category name and optionally a custom output value.","is_list":true,"list_add_label":"Add More","name":"routes","placeholder":"","real_time_refresh":true,"required":true,"show":true,"table_icon":"Table","table_schema":[{"description":"Name for the route (used for both output name and category matching)","display_name":"Route Name","edit_mode":"inline","name":"route_category","type":"str"},{"default":"","description":"Description of when this route should be used (helps LLM understand the category)","display_name":"Route Description","edit_mode":"popover","name":"route_description","type":"str"},{"default":"","description":"Optional message to send when this route is matched.Leave empty to pass through the original input text.","display_name":"Route Message (Optional)","edit_mode":"popover","name":"output_value","type":"str"}],"title_case":false,"tool_mode":false,"trace_as_metadata":true,"trigger_icon":"Table","trigger_text":"Open table","type":"table","value":[{"output_value":"","route_category":"Positive","route_description":"Positive feedback, satisfaction, or compliments"},{"output_value":"","route_category":"Negative","route_description":"Complaints, issues, or dissatisfaction"}]}},"tool_mode":false},"SubFlow":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generates a Component from a Flow, with all of its inputs, and ","display_name":"Sub Flow","documentation":"","edited":false,"field_order":["flow_name"],"frozen":false,"icon":"Workflow","legacy":true,"metadata":{"code_hash":"8ba6fbc5ca3a","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.logic.sub_flow.SubFlowComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Flow Outputs","group_outputs":false,"method":"generate_results","name":"flow_outputs","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["logic.RunFlow"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom lfx.base.flow_processing.utils import build_data_from_result_data\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.graph.graph.base import Graph\nfrom lfx.graph.vertex.base import Vertex\nfrom lfx.helpers import get_flow_inputs\nfrom lfx.io import DropdownInput, Output\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.dotdict import dotdict\n\n\nclass SubFlowComponent(Component):\n    display_name = \"Sub Flow\"\n    description = \"Generates a Component from a Flow, with all of its inputs, and \"\n    name = \"SubFlow\"\n    legacy: bool = True\n    replacement = [\"logic.RunFlow\"]\n    icon = \"Workflow\"\n\n    async def get_flow_names(self) -> list[str]:\n        flow_data = await self.alist_flows()\n        return [flow_data.data[\"name\"] for flow_data in flow_data]\n\n    async def get_flow(self, flow_name: str) -> Data | None:\n        flow_datas = await self.alist_flows()\n        for flow_data in flow_datas:\n            if flow_data.data[\"name\"] == flow_name:\n                return flow_data\n        return None\n\n    async def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"flow_name\":\n            build_config[\"flow_name\"][\"options\"] = await self.get_flow_names()\n\n        for key in list(build_config.keys()):\n            if key not in [x.name for x in self.inputs] + [\"code\", \"_type\", \"get_final_results_only\"]:\n                del build_config[key]\n        if field_value is not None and field_name == \"flow_name\":\n            try:\n                flow_data = await self.get_flow(field_value)\n            except Exception:  # noqa: BLE001\n                await logger.aexception(f\"Error getting flow {field_value}\")\n            else:\n                if not flow_data:\n                    msg = f\"Flow {field_value} not found.\"\n                    await logger.aerror(msg)\n                else:\n                    try:\n                        graph = Graph.from_payload(flow_data.data[\"data\"])\n                        # Get all inputs from the graph\n                        inputs = get_flow_inputs(graph)\n                        # Add inputs to the build config\n                        build_config = self.add_inputs_to_build_config(inputs, build_config)\n                    except Exception:  # noqa: BLE001\n                        await logger.aexception(f\"Error building graph for flow {field_value}\")\n\n        return build_config\n\n    def add_inputs_to_build_config(self, inputs_vertex: list[Vertex], build_config: dotdict):\n        new_fields: list[dotdict] = []\n\n        for vertex in inputs_vertex:\n            new_vertex_inputs = []\n            field_template = vertex.data[\"node\"][\"template\"]\n            for inp in field_template:\n                if inp not in {\"code\", \"_type\"}:\n                    field_template[inp][\"display_name\"] = (\n                        vertex.display_name + \" - \" + field_template[inp][\"display_name\"]\n                    )\n                    field_template[inp][\"name\"] = vertex.id + \"|\" + inp\n                    new_vertex_inputs.append(field_template[inp])\n            new_fields += new_vertex_inputs\n        for field in new_fields:\n            build_config[field[\"name\"]] = field\n        return build_config\n\n    inputs = [\n        DropdownInput(\n            name=\"flow_name\",\n            display_name=\"Flow Name\",\n            info=\"The name of the flow to run.\",\n            options=[],\n            refresh_button=True,\n            real_time_refresh=True,\n        ),\n    ]\n\n    outputs = [Output(name=\"flow_outputs\", display_name=\"Flow Outputs\", method=\"generate_results\")]\n\n    async def generate_results(self) -> list[Data]:\n        tweaks: dict = {}\n        for field in self._attributes:\n            if field != \"flow_name\" and \"|\" in field:\n                [node, name] = field.split(\"|\")\n                if node not in tweaks:\n                    tweaks[node] = {}\n                tweaks[node][name] = self._attributes[field]\n        flow_name = self._attributes.get(\"flow_name\")\n        run_outputs = await self.run_flow(\n            tweaks=tweaks,\n            flow_name=flow_name,\n            output_type=\"all\",\n        )\n        data: list[Data] = []\n        if not run_outputs:\n            return data\n        run_output = run_outputs[0]\n\n        if run_output is not None:\n            for output in run_output.outputs:\n                if output:\n                    data.extend(build_data_from_result_data(output))\n        return data\n"},"flow_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Flow Name","dynamic":false,"external_options":{},"info":"The name of the flow to run.","name":"flow_name","options":[],"options_metadata":[],"placeholder":"","real_time_refresh":true,"refresh_button":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["maritalk",{"Maritalk":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generates text using MariTalk LLMs.","display_name":"MariTalk","documentation":"","edited":false,"field_order":["input_value","system_message","stream","max_tokens","model_name","api_key","temperature"],"frozen":false,"icon":"Maritalk","legacy":false,"metadata":{"code_hash":"25c5da31181e","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":2},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.maritalk.maritalk.MaritalkModelComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"MariTalk API Key","dynamic":false,"info":"The MariTalk API Key to use for authentication.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_community.chat_models import ChatMaritalk\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.inputs.inputs import DropdownInput, FloatInput, IntInput, SecretStrInput\n\n\nclass MaritalkModelComponent(LCModelComponent):\n    display_name = \"MariTalk\"\n    description = \"Generates text using MariTalk LLMs.\"\n    icon = \"Maritalk\"\n    name = \"Maritalk\"\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            value=512,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=[\"sabia-2-small\", \"sabia-2-medium\"],\n            value=[\"sabia-2-small\"],\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"MariTalk API Key\",\n            info=\"The MariTalk API Key to use for authentication.\",\n            advanced=False,\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1, range_spec=RangeSpec(min=0, max=1)),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schea is a list of dictionarie s\n        # let's convert it to a dictionary\n        api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n\n        return ChatMaritalk(\n            max_tokens=max_tokens,\n            model=model_name,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n        )\n"},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"max_tokens":{"_input_type":"IntInput","advanced":true,"display_name":"Max Tokens","dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","list":false,"list_add_label":"Add More","name":"max_tokens","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":512},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model Name","dynamic":false,"external_options":{},"info":"","name":"model_name","options":["sabia-2-small","sabia-2-medium"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":["sabia-2-small"]},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"FloatInput","advanced":false,"display_name":"Temperature","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"temperature","placeholder":"","range_spec":{"max":1.0,"min":0.0,"step":0.1,"step_type":"float"},"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.1}},"tool_mode":false}}],["mem0",{"mem0_chat_memory":{"base_classes":["Data","Memory"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Retrieves and stores chat messages using Mem0 memory storage.","display_name":"Mem0 Chat Memory","documentation":"","edited":false,"field_order":["mem0_config","ingest_message","existing_memory","user_id","search_query","mem0_api_key","metadata","openai_api_key"],"frozen":false,"icon":"Mem0","legacy":false,"metadata":{"code_hash":"54047af46591","dependencies":{"dependencies":[{"name":"mem0","version":"0.1.34"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.mem0.mem0_chat_memory.Mem0MemoryComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Mem0 Memory","group_outputs":false,"method":"ingest_data","name":"memory","selected":"Memory","tool_mode":true,"types":["Memory"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"build_search_results","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import os\n\nfrom mem0 import Memory, MemoryClient\n\nfrom lfx.base.memory.model import LCChatMemoryComponent\nfrom lfx.inputs.inputs import DictInput, HandleInput, MessageTextInput, NestedDictInput, SecretStrInput\nfrom lfx.io import Output\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\n\n\nclass Mem0MemoryComponent(LCChatMemoryComponent):\n    display_name = \"Mem0 Chat Memory\"\n    description = \"Retrieves and stores chat messages using Mem0 memory storage.\"\n    name = \"mem0_chat_memory\"\n    icon: str = \"Mem0\"\n    inputs = [\n        NestedDictInput(\n            name=\"mem0_config\",\n            display_name=\"Mem0 Configuration\",\n            info=\"\"\"Configuration dictionary for initializing Mem0 memory instance.\n                    Example:\n                    {\n                        \"graph_store\": {\n                            \"provider\": \"neo4j\",\n                            \"config\": {\n                                \"url\": \"neo4j+s://your-neo4j-url\",\n                                \"username\": \"neo4j\",\n                                \"password\": \"your-password\"\n                            }\n                        },\n                        \"version\": \"v1.1\"\n                    }\"\"\",\n            input_types=[\"Data\"],\n        ),\n        MessageTextInput(\n            name=\"ingest_message\",\n            display_name=\"Message to Ingest\",\n            info=\"The message content to be ingested into Mem0 memory.\",\n        ),\n        HandleInput(\n            name=\"existing_memory\",\n            display_name=\"Existing Memory Instance\",\n            input_types=[\"Memory\"],\n            info=\"Optional existing Mem0 memory instance. If not provided, a new instance will be created.\",\n        ),\n        MessageTextInput(\n            name=\"user_id\", display_name=\"User ID\", info=\"Identifier for the user associated with the messages.\"\n        ),\n        MessageTextInput(\n            name=\"search_query\", display_name=\"Search Query\", info=\"Input text for searching related memories in Mem0.\"\n        ),\n        SecretStrInput(\n            name=\"mem0_api_key\",\n            display_name=\"Mem0 API Key\",\n            info=\"API key for Mem0 platform. Leave empty to use the local version.\",\n        ),\n        DictInput(\n            name=\"metadata\",\n            display_name=\"Metadata\",\n            info=\"Additional metadata to associate with the ingested message.\",\n            advanced=True,\n        ),\n        SecretStrInput(\n            name=\"openai_api_key\",\n            display_name=\"OpenAI API Key\",\n            required=False,\n            info=\"API key for OpenAI. Required if using OpenAI Embeddings without a provided configuration.\",\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"memory\", display_name=\"Mem0 Memory\", method=\"ingest_data\"),\n        Output(\n            name=\"search_results\",\n            display_name=\"Search Results\",\n            method=\"build_search_results\",\n        ),\n    ]\n\n    def build_mem0(self) -> Memory:\n        \"\"\"Initializes a Mem0 memory instance based on provided configuration and API keys.\"\"\"\n        if self.openai_api_key:\n            os.environ[\"OPENAI_API_KEY\"] = self.openai_api_key\n\n        try:\n            if not self.mem0_api_key:\n                return Memory.from_config(config_dict=dict(self.mem0_config)) if self.mem0_config else Memory()\n            if self.mem0_config:\n                return MemoryClient.from_config(api_key=self.mem0_api_key, config_dict=dict(self.mem0_config))\n            return MemoryClient(api_key=self.mem0_api_key)\n        except ImportError as e:\n            msg = \"Mem0 is not properly installed. Please install it with 'pip install -U mem0ai'.\"\n            raise ImportError(msg) from e\n\n    def ingest_data(self) -> Memory:\n        \"\"\"Ingests a new message into Mem0 memory and returns the updated memory instance.\"\"\"\n        mem0_memory = self.existing_memory or self.build_mem0()\n\n        if not self.ingest_message or not self.user_id:\n            logger.warning(\"Missing 'ingest_message' or 'user_id'; cannot ingest data.\")\n            return mem0_memory\n\n        metadata = self.metadata or {}\n\n        logger.info(\"Ingesting message for user_id: %s\", self.user_id)\n\n        try:\n            mem0_memory.add(self.ingest_message, user_id=self.user_id, metadata=metadata)\n        except Exception:\n            logger.exception(\"Failed to add message to Mem0 memory.\")\n            raise\n\n        return mem0_memory\n\n    def build_search_results(self) -> Data:\n        \"\"\"Searches the Mem0 memory for related messages based on the search query and returns the results.\"\"\"\n        mem0_memory = self.ingest_data()\n        search_query = self.search_query\n        user_id = self.user_id\n\n        logger.info(\"Search query: %s\", search_query)\n\n        try:\n            if search_query:\n                logger.info(\"Performing search with query.\")\n                related_memories = mem0_memory.search(query=search_query, user_id=user_id)\n            else:\n                logger.info(\"Retrieving all memories for user_id: %s\", user_id)\n                related_memories = mem0_memory.get_all(user_id=user_id)\n        except Exception:\n            logger.exception(\"Failed to retrieve related memories from Mem0.\")\n            raise\n\n        logger.info(\"Related memories retrieved: %s\", related_memories)\n        return related_memories\n"},"existing_memory":{"_input_type":"HandleInput","advanced":false,"display_name":"Existing Memory Instance","dynamic":false,"info":"Optional existing Mem0 memory instance. If not provided, a new instance will be created.","input_types":["Memory"],"list":false,"list_add_label":"Add More","name":"existing_memory","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"ingest_message":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Message to Ingest","dynamic":false,"info":"The message content to be ingested into Mem0 memory.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"ingest_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"mem0_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Mem0 API Key","dynamic":false,"info":"API key for Mem0 platform. Leave empty to use the local version.","input_types":[],"load_from_db":true,"name":"mem0_api_key","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"mem0_config":{"_input_type":"NestedDictInput","advanced":false,"display_name":"Mem0 Configuration","dynamic":false,"info":"Configuration dictionary for initializing Mem0 memory instance.\n                    Example:\n                    {\n                        \"graph_store\": {\n                            \"provider\": \"neo4j\",\n                            \"config\": {\n                                \"url\": \"neo4j+s://your-neo4j-url\",\n                                \"username\": \"neo4j\",\n                                \"password\": \"your-password\"\n                            }\n                        },\n                        \"version\": \"v1.1\"\n                    }","input_types":["Data"],"list":false,"list_add_label":"Add More","name":"mem0_config","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"NestedDict","value":{}},"metadata":{"_input_type":"DictInput","advanced":true,"display_name":"Metadata","dynamic":false,"info":"Additional metadata to associate with the ingested message.","list":false,"list_add_label":"Add More","name":"metadata","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"openai_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"OpenAI API Key","dynamic":false,"info":"API key for OpenAI. Required if using OpenAI Embeddings without a provided configuration.","input_types":[],"load_from_db":true,"name":"openai_api_key","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"search_query":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Input text for searching related memories in Mem0.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"user_id":{"_input_type":"MessageTextInput","advanced":false,"display_name":"User ID","dynamic":false,"info":"Identifier for the user associated with the messages.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"user_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["milvus",{"Milvus":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Milvus vector store with search capabilities","display_name":"Milvus","documentation":"","edited":false,"field_order":["collection_name","collection_description","uri","password","connection_args","primary_field","text_field","vector_field","consistency_level","index_params","search_params","drop_old","timeout","ingest_data","search_query","should_cache_vector_store","embedding","number_of_results"],"frozen":false,"icon":"Milvus","legacy":false,"metadata":{"code_hash":"2b5efe313b31","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"langchain_milvus","version":"0.1.7"}],"total_dependencies":2},"module":"lfx.components.milvus.milvus.MilvusVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.io import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    HandleInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass MilvusVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"Milvus vector store with search capabilities.\"\"\"\n\n    display_name: str = \"Milvus\"\n    description: str = \"Milvus vector store with search capabilities\"\n    name = \"Milvus\"\n    icon = \"Milvus\"\n\n    inputs = [\n        StrInput(name=\"collection_name\", display_name=\"Collection Name\", value=\"langflow\"),\n        StrInput(name=\"collection_description\", display_name=\"Collection Description\", value=\"\"),\n        StrInput(\n            name=\"uri\",\n            display_name=\"Connection URI\",\n            value=\"http://localhost:19530\",\n        ),\n        SecretStrInput(\n            name=\"password\",\n            display_name=\"Milvus Token\",\n            value=\"\",\n            info=\"Ignore this field if no token is required to make connection.\",\n        ),\n        DictInput(name=\"connection_args\", display_name=\"Other Connection Arguments\", advanced=True),\n        StrInput(name=\"primary_field\", display_name=\"Primary Field Name\", value=\"pk\"),\n        StrInput(name=\"text_field\", display_name=\"Text Field Name\", value=\"text\"),\n        StrInput(name=\"vector_field\", display_name=\"Vector Field Name\", value=\"vector\"),\n        DropdownInput(\n            name=\"consistency_level\",\n            display_name=\"Consistencey Level\",\n            options=[\"Bounded\", \"Session\", \"Strong\", \"Eventual\"],\n            value=\"Session\",\n            advanced=True,\n        ),\n        DictInput(name=\"index_params\", display_name=\"Index Parameters\", advanced=True),\n        DictInput(name=\"search_params\", display_name=\"Search Parameters\", advanced=True),\n        BoolInput(name=\"drop_old\", display_name=\"Drop Old Collection\", value=False, advanced=True),\n        FloatInput(name=\"timeout\", display_name=\"Timeout\", advanced=True),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self):\n        try:\n            from langchain_milvus.vectorstores import Milvus as LangchainMilvus\n        except ImportError as e:\n            msg = \"Could not import Milvus integration package. Please install it with `pip install langchain-milvus`.\"\n            raise ImportError(msg) from e\n        self.connection_args.update(uri=self.uri, token=self.password)\n        milvus_store = LangchainMilvus(\n            embedding_function=self.embedding,\n            collection_name=self.collection_name,\n            collection_description=self.collection_description,\n            connection_args=self.connection_args,\n            consistency_level=self.consistency_level,\n            index_params=self.index_params,\n            search_params=self.search_params,\n            drop_old=self.drop_old,\n            auto_id=True,\n            primary_field=self.primary_field,\n            text_field=self.text_field,\n            vector_field=self.vector_field,\n            timeout=self.timeout,\n        )\n\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents:\n            milvus_store.add_documents(documents)\n\n        return milvus_store\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n"},"collection_description":{"_input_type":"StrInput","advanced":false,"display_name":"Collection Description","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_description","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"collection_name":{"_input_type":"StrInput","advanced":false,"display_name":"Collection Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"langflow"},"connection_args":{"_input_type":"DictInput","advanced":true,"display_name":"Other Connection Arguments","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"connection_args","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"consistency_level":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Consistencey Level","dynamic":false,"external_options":{},"info":"","name":"consistency_level","options":["Bounded","Session","Strong","Eventual"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Session"},"drop_old":{"_input_type":"BoolInput","advanced":true,"display_name":"Drop Old Collection","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"drop_old","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"index_params":{"_input_type":"DictInput","advanced":true,"display_name":"Index Parameters","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"index_params","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Milvus Token","dynamic":false,"info":"Ignore this field if no token is required to make connection.","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"primary_field":{"_input_type":"StrInput","advanced":false,"display_name":"Primary Field Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"primary_field","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"pk"},"search_params":{"_input_type":"DictInput","advanced":true,"display_name":"Search Parameters","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"search_params","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"text_field":{"_input_type":"StrInput","advanced":false,"display_name":"Text Field Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"text_field","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"text"},"timeout":{"_input_type":"FloatInput","advanced":true,"display_name":"Timeout","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":""},"uri":{"_input_type":"StrInput","advanced":false,"display_name":"Connection URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"uri","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"http://localhost:19530"},"vector_field":{"_input_type":"StrInput","advanced":false,"display_name":"Vector Field Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"vector_field","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"vector"}},"tool_mode":false}}],["mistral",{"MistalAIEmbeddings":{"base_classes":["Embeddings"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate embeddings using MistralAI models.","display_name":"MistralAI Embeddings","documentation":"","edited":false,"field_order":["model","mistral_api_key","max_concurrent_requests","max_retries","timeout","endpoint"],"frozen":false,"icon":"MistralAI","legacy":false,"metadata":{"code_hash":"34d046148a1c","dependencies":{"dependencies":[{"name":"langchain_mistralai","version":"0.2.3"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":3},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.mistral.mistral_embeddings.MistralAIEmbeddingsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Embeddings","group_outputs":false,"method":"build_embeddings","name":"embeddings","selected":"Embeddings","tool_mode":true,"types":["Embeddings"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_mistralai.embeddings import MistralAIEmbeddings\nfrom pydantic.v1 import SecretStr\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import Embeddings\nfrom lfx.io import DropdownInput, IntInput, MessageTextInput, Output, SecretStrInput\n\n\nclass MistralAIEmbeddingsComponent(LCModelComponent):\n    display_name = \"MistralAI Embeddings\"\n    description = \"Generate embeddings using MistralAI models.\"\n    icon = \"MistralAI\"\n    name = \"MistalAIEmbeddings\"\n\n    inputs = [\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=[\"mistral-embed\"],\n            value=\"mistral-embed\",\n        ),\n        SecretStrInput(name=\"mistral_api_key\", display_name=\"Mistral API Key\", required=True),\n        IntInput(\n            name=\"max_concurrent_requests\",\n            display_name=\"Max Concurrent Requests\",\n            advanced=True,\n            value=64,\n        ),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", advanced=True, value=5),\n        IntInput(name=\"timeout\", display_name=\"Request Timeout\", advanced=True, value=120),\n        MessageTextInput(\n            name=\"endpoint\",\n            display_name=\"API Endpoint\",\n            advanced=True,\n            value=\"https://api.mistral.ai/v1/\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        if not self.mistral_api_key:\n            msg = \"Mistral API Key is required\"\n            raise ValueError(msg)\n\n        api_key = SecretStr(self.mistral_api_key).get_secret_value()\n\n        return MistralAIEmbeddings(\n            api_key=api_key,\n            model=self.model,\n            endpoint=self.endpoint,\n            max_concurrent_requests=self.max_concurrent_requests,\n            max_retries=self.max_retries,\n            timeout=self.timeout,\n        )\n"},"endpoint":{"_input_type":"MessageTextInput","advanced":true,"display_name":"API Endpoint","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"endpoint","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"https://api.mistral.ai/v1/"},"max_concurrent_requests":{"_input_type":"IntInput","advanced":true,"display_name":"Max Concurrent Requests","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"max_concurrent_requests","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":64},"max_retries":{"_input_type":"IntInput","advanced":true,"display_name":"Max Retries","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"max_retries","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5},"mistral_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Mistral API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"mistral_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"model":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model","dynamic":false,"external_options":{},"info":"","name":"model","options":["mistral-embed"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"mistral-embed"},"timeout":{"_input_type":"IntInput","advanced":true,"display_name":"Request Timeout","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":120}},"tool_mode":false},"MistralModel":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generates text using MistralAI LLMs.","display_name":"MistralAI","documentation":"","edited":false,"field_order":["input_value","system_message","stream","max_tokens","model_name","mistral_api_base","api_key","temperature","max_retries","timeout","max_concurrent_requests","top_p","random_seed","safe_mode"],"frozen":false,"icon":"MistralAI","legacy":false,"metadata":{"code_hash":"e21780948144","dependencies":{"dependencies":[{"name":"langchain_mistralai","version":"0.2.3"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":3},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.mistral.mistral.MistralAIModelComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Mistral API Key","dynamic":false,"info":"The Mistral API Key to use for the Mistral model.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"MISTRAL_API_KEY"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_mistralai import ChatMistralAI\nfrom pydantic.v1 import SecretStr\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import LanguageModel\nfrom lfx.io import BoolInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\n\n\nclass MistralAIModelComponent(LCModelComponent):\n    display_name = \"MistralAI\"\n    description = \"Generates text using MistralAI LLMs.\"\n    icon = \"MistralAI\"\n    name = \"MistralModel\"\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=[\n                \"open-mixtral-8x7b\",\n                \"open-mixtral-8x22b\",\n                \"mistral-small-latest\",\n                \"mistral-medium-latest\",\n                \"mistral-large-latest\",\n                \"codestral-latest\",\n            ],\n            value=\"codestral-latest\",\n        ),\n        StrInput(\n            name=\"mistral_api_base\",\n            display_name=\"Mistral API Base\",\n            advanced=True,\n            info=\"The base URL of the Mistral API. Defaults to https://api.mistral.ai/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Mistral API Key\",\n            info=\"The Mistral API Key to use for the Mistral model.\",\n            advanced=False,\n            required=True,\n            value=\"MISTRAL_API_KEY\",\n        ),\n        FloatInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            advanced=True,\n            value=60,\n        ),\n        IntInput(\n            name=\"max_concurrent_requests\",\n            display_name=\"Max Concurrent Requests\",\n            advanced=True,\n            value=3,\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"random_seed\",\n            display_name=\"Random Seed\",\n            value=1,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"safe_mode\",\n            display_name=\"Safe Mode\",\n            advanced=True,\n            value=False,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            return ChatMistralAI(\n                model_name=self.model_name,\n                mistral_api_key=SecretStr(self.api_key).get_secret_value() if self.api_key else None,\n                endpoint=self.mistral_api_base or \"https://api.mistral.ai/v1\",\n                max_tokens=self.max_tokens or None,\n                temperature=self.temperature,\n                max_retries=self.max_retries,\n                timeout=self.timeout,\n                max_concurrent_requests=self.max_concurrent_requests,\n                top_p=self.top_p,\n                random_seed=self.random_seed,\n                safe_mode=self.safe_mode,\n                streaming=self.stream,\n            )\n        except Exception as e:\n            msg = \"Could not connect to MistralAI API.\"\n            raise ValueError(msg) from e\n"},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"max_concurrent_requests":{"_input_type":"IntInput","advanced":true,"display_name":"Max Concurrent Requests","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"max_concurrent_requests","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":3},"max_retries":{"_input_type":"IntInput","advanced":true,"display_name":"Max Retries","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"max_retries","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5},"max_tokens":{"_input_type":"IntInput","advanced":true,"display_name":"Max Tokens","dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","list":false,"list_add_label":"Add More","name":"max_tokens","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"mistral_api_base":{"_input_type":"StrInput","advanced":true,"display_name":"Mistral API Base","dynamic":false,"info":"The base URL of the Mistral API. Defaults to https://api.mistral.ai/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"mistral_api_base","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model Name","dynamic":false,"external_options":{},"info":"","name":"model_name","options":["open-mixtral-8x7b","open-mixtral-8x22b","mistral-small-latest","mistral-medium-latest","mistral-large-latest","codestral-latest"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"codestral-latest"},"random_seed":{"_input_type":"IntInput","advanced":true,"display_name":"Random Seed","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"random_seed","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1},"safe_mode":{"_input_type":"BoolInput","advanced":true,"display_name":"Safe Mode","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"safe_mode","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"FloatInput","advanced":true,"display_name":"Temperature","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"temperature","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.1},"timeout":{"_input_type":"IntInput","advanced":true,"display_name":"Timeout","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":60},"top_p":{"_input_type":"FloatInput","advanced":true,"display_name":"Top P","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"top_p","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":1.0}},"tool_mode":false}}],["models",{"EmbeddingModel":{"base_classes":["Embeddings"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate embeddings using a specified provider.","display_name":"Embedding Model","documentation":"https://docs.langflow.org/components-embedding-models","edited":false,"field_order":["provider","model","api_key","api_base","dimensions","chunk_size","request_timeout","max_retries","show_progress_bar","model_kwargs"],"frozen":false,"icon":"binary","legacy":false,"metadata":{"code_hash":"8607e963fdef","dependencies":{"dependencies":[{"name":"langchain_openai","version":"0.3.23"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.models.embedding_model.EmbeddingModelComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Embedding Model","group_outputs":false,"method":"build_embeddings","name":"embeddings","selected":"Embeddings","tool_mode":true,"types":["Embeddings"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_base":{"_input_type":"MessageTextInput","advanced":true,"display_name":"API Base URL","dynamic":false,"info":"Base URL for the API. Leave empty for default.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"api_base","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"OpenAI API Key","dynamic":false,"info":"Model Provider API key","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":""},"chunk_size":{"_input_type":"IntInput","advanced":true,"display_name":"Chunk Size","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"chunk_size","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1000},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom langchain_openai import OpenAIEmbeddings\n\nfrom lfx.base.embeddings.model import LCEmbeddingsModel\nfrom lfx.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom lfx.field_typing import Embeddings\nfrom lfx.io import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    MessageTextInput,\n    SecretStrInput,\n)\nfrom lfx.schema.dotdict import dotdict\n\n\nclass EmbeddingModelComponent(LCEmbeddingsModel):\n    display_name = \"Embedding Model\"\n    description = \"Generate embeddings using a specified provider.\"\n    documentation: str = \"https://docs.langflow.org/components-embedding-models\"\n    icon = \"binary\"\n    name = \"EmbeddingModel\"\n    category = \"models\"\n\n    inputs = [\n        DropdownInput(\n            name=\"provider\",\n            display_name=\"Model Provider\",\n            options=[\"OpenAI\"],\n            value=\"OpenAI\",\n            info=\"Select the embedding model provider\",\n            real_time_refresh=True,\n            options_metadata=[{\"icon\": \"OpenAI\"}],\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model Name\",\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=OPENAI_EMBEDDING_MODEL_NAMES[0],\n            info=\"Select the embedding model to use\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"Model Provider API key\",\n            required=True,\n            show=True,\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"api_base\",\n            display_name=\"API Base URL\",\n            info=\"Base URL for the API. Leave empty for default.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. \"\n            \"Only supported by certain models.\",\n            advanced=True,\n        ),\n        IntInput(name=\"chunk_size\", display_name=\"Chunk Size\", advanced=True, value=1000),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", advanced=True, value=3),\n        BoolInput(name=\"show_progress_bar\", display_name=\"Show Progress Bar\", advanced=True),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        provider = self.provider\n        model = self.model\n        api_key = self.api_key\n        api_base = self.api_base\n        dimensions = self.dimensions\n        chunk_size = self.chunk_size\n        request_timeout = self.request_timeout\n        max_retries = self.max_retries\n        show_progress_bar = self.show_progress_bar\n        model_kwargs = self.model_kwargs or {}\n\n        if provider == \"OpenAI\":\n            if not api_key:\n                msg = \"OpenAI API key is required when using OpenAI provider\"\n                raise ValueError(msg)\n            return OpenAIEmbeddings(\n                model=model,\n                dimensions=dimensions or None,\n                base_url=api_base or None,\n                api_key=api_key,\n                chunk_size=chunk_size,\n                max_retries=max_retries,\n                timeout=request_timeout or None,\n                show_progress_bar=show_progress_bar,\n                model_kwargs=model_kwargs,\n            )\n        msg = f\"Unknown provider: {provider}\"\n        raise ValueError(msg)\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name == \"provider\" and field_value == \"OpenAI\":\n            build_config[\"model\"][\"options\"] = OPENAI_EMBEDDING_MODEL_NAMES\n            build_config[\"model\"][\"value\"] = OPENAI_EMBEDDING_MODEL_NAMES[0]\n            build_config[\"api_key\"][\"display_name\"] = \"OpenAI API Key\"\n            build_config[\"api_base\"][\"display_name\"] = \"OpenAI API Base URL\"\n        return build_config\n"},"dimensions":{"_input_type":"IntInput","advanced":true,"display_name":"Dimensions","dynamic":false,"info":"The number of dimensions the resulting output embeddings should have. Only supported by certain models.","list":false,"list_add_label":"Add More","name":"dimensions","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"max_retries":{"_input_type":"IntInput","advanced":true,"display_name":"Max Retries","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"max_retries","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":3},"model":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model Name","dynamic":false,"external_options":{},"info":"Select the embedding model to use","name":"model","options":["text-embedding-3-small","text-embedding-3-large","text-embedding-ada-002"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"text-embedding-3-small"},"model_kwargs":{"_input_type":"DictInput","advanced":true,"display_name":"Model Kwargs","dynamic":false,"info":"Additional keyword arguments to pass to the model.","list":false,"list_add_label":"Add More","name":"model_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"provider":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model Provider","dynamic":false,"external_options":{},"info":"Select the embedding model provider","name":"provider","options":["OpenAI"],"options_metadata":[{"icon":"OpenAI"}],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"OpenAI"},"request_timeout":{"_input_type":"FloatInput","advanced":true,"display_name":"Request Timeout","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"request_timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":""},"show_progress_bar":{"_input_type":"BoolInput","advanced":true,"display_name":"Show Progress Bar","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"show_progress_bar","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false},"LanguageModelComponent":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Runs a language model given a specified provider.","display_name":"Language Model","documentation":"https://docs.langflow.org/components-models","edited":false,"field_order":["provider","model_name","api_key","input_value","system_message","stream","temperature"],"frozen":false,"icon":"brain-circuit","legacy":false,"metadata":{"code_hash":"4c0db80cc017","dependencies":{"dependencies":[{"name":"langchain_anthropic","version":"0.3.14"},{"name":"langchain_openai","version":"0.3.23"},{"name":"lfx","version":null}],"total_dependencies":3},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.models.language_model.LanguageModelComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"priority":0,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"OpenAI API Key","dynamic":false,"info":"Model Provider API key","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom langchain_anthropic import ChatAnthropic\nfrom langchain_openai import ChatOpenAI\n\nfrom lfx.base.models.anthropic_constants import ANTHROPIC_MODELS\nfrom lfx.base.models.google_generative_ai_constants import GOOGLE_GENERATIVE_AI_MODELS\nfrom lfx.base.models.google_generative_ai_model import ChatGoogleGenerativeAIFixed\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.base.models.openai_constants import OPENAI_CHAT_MODEL_NAMES, OPENAI_REASONING_MODEL_NAMES\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.inputs.inputs import BoolInput\nfrom lfx.io import DropdownInput, MessageInput, MultilineInput, SecretStrInput, SliderInput\nfrom lfx.schema.dotdict import dotdict\n\n\nclass LanguageModelComponent(LCModelComponent):\n    display_name = \"Language Model\"\n    description = \"Runs a language model given a specified provider.\"\n    documentation: str = \"https://docs.langflow.org/components-models\"\n    icon = \"brain-circuit\"\n    category = \"models\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        DropdownInput(\n            name=\"provider\",\n            display_name=\"Model Provider\",\n            options=[\"OpenAI\", \"Anthropic\", \"Google\"],\n            value=\"OpenAI\",\n            info=\"Select the model provider\",\n            real_time_refresh=True,\n            options_metadata=[{\"icon\": \"OpenAI\"}, {\"icon\": \"Anthropic\"}, {\"icon\": \"GoogleGenerativeAI\"}],\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            options=OPENAI_CHAT_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\n            value=OPENAI_CHAT_MODEL_NAMES[0],\n            info=\"Select the model to use\",\n            real_time_refresh=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"Model Provider API key\",\n            required=False,\n            show=True,\n            real_time_refresh=True,\n        ),\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"The input text to send to the model\",\n        ),\n        MultilineInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"A system message that helps set the behavior of the assistant\",\n            advanced=False,\n        ),\n        BoolInput(\n            name=\"stream\",\n            display_name=\"Stream\",\n            info=\"Whether to stream the response\",\n            value=False,\n            advanced=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            info=\"Controls randomness in responses\",\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:\n        provider = self.provider\n        model_name = self.model_name\n        temperature = self.temperature\n        stream = self.stream\n\n        if provider == \"OpenAI\":\n            if not self.api_key:\n                msg = \"OpenAI API key is required when using OpenAI provider\"\n                raise ValueError(msg)\n\n            if model_name in OPENAI_REASONING_MODEL_NAMES:\n                # reasoning models do not support temperature (yet)\n                temperature = None\n\n            return ChatOpenAI(\n                model_name=model_name,\n                temperature=temperature,\n                streaming=stream,\n                openai_api_key=self.api_key,\n            )\n        if provider == \"Anthropic\":\n            if not self.api_key:\n                msg = \"Anthropic API key is required when using Anthropic provider\"\n                raise ValueError(msg)\n            return ChatAnthropic(\n                model=model_name,\n                temperature=temperature,\n                streaming=stream,\n                anthropic_api_key=self.api_key,\n            )\n        if provider == \"Google\":\n            if not self.api_key:\n                msg = \"Google API key is required when using Google provider\"\n                raise ValueError(msg)\n            return ChatGoogleGenerativeAIFixed(\n                model=model_name,\n                temperature=temperature,\n                streaming=stream,\n                google_api_key=self.api_key,\n            )\n        msg = f\"Unknown provider: {provider}\"\n        raise ValueError(msg)\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name == \"provider\":\n            if field_value == \"OpenAI\":\n                build_config[\"model_name\"][\"options\"] = OPENAI_CHAT_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES\n                build_config[\"model_name\"][\"value\"] = OPENAI_CHAT_MODEL_NAMES[0]\n                build_config[\"api_key\"][\"display_name\"] = \"OpenAI API Key\"\n            elif field_value == \"Anthropic\":\n                build_config[\"model_name\"][\"options\"] = ANTHROPIC_MODELS\n                build_config[\"model_name\"][\"value\"] = ANTHROPIC_MODELS[0]\n                build_config[\"api_key\"][\"display_name\"] = \"Anthropic API Key\"\n            elif field_value == \"Google\":\n                build_config[\"model_name\"][\"options\"] = GOOGLE_GENERATIVE_AI_MODELS\n                build_config[\"model_name\"][\"value\"] = GOOGLE_GENERATIVE_AI_MODELS[0]\n                build_config[\"api_key\"][\"display_name\"] = \"Google API Key\"\n        elif field_name == \"model_name\" and field_value.startswith(\"o1\") and self.provider == \"OpenAI\":\n            # Hide system_message for o1 models - currently unsupported\n            if \"system_message\" in build_config:\n                build_config[\"system_message\"][\"show\"] = False\n        elif field_name == \"model_name\" and not field_value.startswith(\"o1\") and \"system_message\" in build_config:\n            build_config[\"system_message\"][\"show\"] = True\n        return build_config\n"},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"The input text to send to the model","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model Name","dynamic":false,"external_options":{},"info":"Select the model to use","name":"model_name","options":["gpt-4o-mini","gpt-4o","gpt-4.1","gpt-4.1-mini","gpt-4.1-nano","gpt-4-turbo","gpt-4-turbo-preview","gpt-4","gpt-3.5-turbo","gpt-5","gpt-5-mini","gpt-5-nano","gpt-5-chat-latest","o1","o3-mini","o3","o3-pro","o4-mini","o4-mini-high"],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"gpt-4o-mini"},"provider":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model Provider","dynamic":false,"external_options":{},"info":"Select the model provider","name":"provider","options":["OpenAI","Anthropic","Google"],"options_metadata":[{"icon":"OpenAI"},{"icon":"Anthropic"},{"icon":"GoogleGenerativeAI"}],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"OpenAI"},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Whether to stream the response","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"A system message that helps set the behavior of the assistant","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"SliderInput","advanced":true,"display_name":"Temperature","dynamic":false,"info":"Controls randomness in responses","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"temperature","placeholder":"","range_spec":{"max":1.0,"min":0.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":0.1}},"tool_mode":false}}],["mongodb",{"MongoDBAtlasVector":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"MongoDB Atlas Vector Store with search capabilities","display_name":"MongoDB Atlas","documentation":"","edited":false,"field_order":["mongodb_atlas_cluster_uri","enable_mtls","mongodb_atlas_client_cert","db_name","collection_name","index_name","ingest_data","search_query","should_cache_vector_store","insert_mode","embedding","number_of_results","index_field","filter_field","number_dimensions","similarity","quantization"],"frozen":false,"icon":"MongoDB","legacy":false,"metadata":{"code_hash":"3a502cb4d313","dependencies":{"dependencies":[{"name":"certifi","version":"2024.12.14"},{"name":"langchain_community","version":"0.3.21"},{"name":"pymongo","version":"4.10.1"},{"name":"lfx","version":null},{"name":"bson","version":"4.10.1"}],"total_dependencies":5},"module":"lfx.components.mongodb.mongodb_atlas.MongoVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import tempfile\nimport time\n\nimport certifi\nfrom langchain_community.vectorstores import MongoDBAtlasVectorSearch\nfrom pymongo.collection import Collection\nfrom pymongo.operations import SearchIndexModel\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.io import BoolInput, DropdownInput, HandleInput, IntInput, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass MongoVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"MongoDB Atlas\"\n    description = \"MongoDB Atlas Vector Store with search capabilities\"\n    name = \"MongoDBAtlasVector\"\n    icon = \"MongoDB\"\n    INSERT_MODES = [\"append\", \"overwrite\"]\n    SIMILARITY_OPTIONS = [\"cosine\", \"euclidean\", \"dotProduct\"]\n    QUANTIZATION_OPTIONS = [\"scalar\", \"binary\"]\n    inputs = [\n        SecretStrInput(name=\"mongodb_atlas_cluster_uri\", display_name=\"MongoDB Atlas Cluster URI\", required=True),\n        BoolInput(name=\"enable_mtls\", display_name=\"Enable mTLS\", value=False, advanced=True, required=True),\n        SecretStrInput(\n            name=\"mongodb_atlas_client_cert\",\n            display_name=\"MongoDB Atlas Combined Client Certificate\",\n            required=False,\n            info=\"Client Certificate combined with the private key in the following format:\\n \"\n            \"-----BEGIN PRIVATE KEY-----\\n...\\n -----END PRIVATE KEY-----\\n-----BEGIN CERTIFICATE-----\\n\"\n            \"...\\n-----END CERTIFICATE-----\\n\",\n        ),\n        StrInput(name=\"db_name\", display_name=\"Database Name\", required=True),\n        StrInput(name=\"collection_name\", display_name=\"Collection Name\", required=True),\n        StrInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            required=True,\n            info=\"The name of Atlas Search index, it should be a Vector Search.\",\n        ),\n        *LCVectorStoreComponent.inputs,\n        DropdownInput(\n            name=\"insert_mode\",\n            display_name=\"Insert Mode\",\n            options=INSERT_MODES,\n            value=INSERT_MODES[0],\n            info=\"How to insert new documents into the collection.\",\n            advanced=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n        StrInput(\n            name=\"index_field\",\n            display_name=\"Index Field\",\n            advanced=True,\n            required=True,\n            info=\"The field to index.\",\n            value=\"embedding\",\n        ),\n        StrInput(\n            name=\"filter_field\", display_name=\"Filter Field\", advanced=True, info=\"The field to filter the index.\"\n        ),\n        IntInput(\n            name=\"number_dimensions\",\n            display_name=\"Number of Dimensions\",\n            info=\"Embedding Context Length.\",\n            value=1536,\n            advanced=True,\n            required=True,\n        ),\n        DropdownInput(\n            name=\"similarity\",\n            display_name=\"Similarity\",\n            options=SIMILARITY_OPTIONS,\n            value=SIMILARITY_OPTIONS[0],\n            info=\"The method used to measure the similarity between vectors.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"quantization\",\n            display_name=\"Quantization\",\n            options=QUANTIZATION_OPTIONS,\n            value=None,\n            info=\"Quantization reduces memory costs converting 32-bit floats to smaller data types\",\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> MongoDBAtlasVectorSearch:\n        try:\n            from pymongo import MongoClient\n        except ImportError as e:\n            msg = \"Please install pymongo to use MongoDB Atlas Vector Store\"\n            raise ImportError(msg) from e\n\n        # Create temporary files for the client certificate\n        if self.enable_mtls:\n            client_cert_path = None\n            try:\n                client_cert = self.mongodb_atlas_client_cert.replace(\" \", \"\\n\")\n                client_cert = client_cert.replace(\"-----BEGIN\\nPRIVATE\\nKEY-----\", \"-----BEGIN PRIVATE KEY-----\")\n                client_cert = client_cert.replace(\n                    \"-----END\\nPRIVATE\\nKEY-----\\n-----BEGIN\\nCERTIFICATE-----\",\n                    \"-----END PRIVATE KEY-----\\n-----BEGIN CERTIFICATE-----\",\n                )\n                client_cert = client_cert.replace(\"-----END\\nCERTIFICATE-----\", \"-----END CERTIFICATE-----\")\n                with tempfile.NamedTemporaryFile(delete=False) as client_cert_file:\n                    client_cert_file.write(client_cert.encode(\"utf-8\"))\n                    client_cert_path = client_cert_file.name\n\n            except Exception as e:\n                msg = f\"Failed to write certificate to temporary file: {e}\"\n                raise ValueError(msg) from e\n\n        try:\n            mongo_client: MongoClient = (\n                MongoClient(\n                    self.mongodb_atlas_cluster_uri,\n                    tls=True,\n                    tlsCertificateKeyFile=client_cert_path,\n                    tlsCAFile=certifi.where(),\n                )\n                if self.enable_mtls\n                else MongoClient(self.mongodb_atlas_cluster_uri)\n            )\n\n            collection = mongo_client[self.db_name][self.collection_name]\n\n        except Exception as e:\n            msg = f\"Failed to connect to MongoDB Atlas: {e}\"\n            raise ValueError(msg) from e\n\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents:\n            self.__insert_mode(collection)\n\n            return MongoDBAtlasVectorSearch.from_documents(\n                documents=documents, embedding=self.embedding, collection=collection, index_name=self.index_name\n            )\n        return MongoDBAtlasVectorSearch(embedding=self.embedding, collection=collection, index_name=self.index_name)\n\n    def search_documents(self) -> list[Data]:\n        from bson.objectid import ObjectId\n\n        vector_store = self.build_vector_store()\n\n        self.verify_search_index(vector_store._collection)\n\n        if self.search_query and isinstance(self.search_query, str):\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n            for doc in docs:\n                doc.metadata = {\n                    key: str(value) if isinstance(value, ObjectId) else value for key, value in doc.metadata.items()\n                }\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n\n    def __insert_mode(self, collection: Collection) -> None:\n        if self.insert_mode == \"overwrite\":\n            collection.delete_many({})  # Delete all documents while preserving collection structure\n\n    def verify_search_index(self, collection: Collection) -> None:\n        \"\"\"Verify if the search index exists, if not, create it.\n\n        Args:\n            collection (Collection): The collection to verify the search index on.\n        \"\"\"\n        indexes = collection.list_search_indexes()\n\n        index_names_types = {idx[\"name\"]: idx[\"type\"] for idx in indexes}\n        index_names = list(index_names_types.keys())\n        index_type = index_names_types.get(self.index_name)\n        if self.index_name not in index_names and index_type != \"vectorSearch\":\n            collection.create_search_index(self.__create_index_definition())\n\n            time.sleep(20)  # Give some time for index to be ready\n\n    def __create_index_definition(self) -> SearchIndexModel:\n        fields = [\n            {\n                \"type\": \"vector\",\n                \"path\": self.index_field,\n                \"numDimensions\": self.number_dimensions,\n                \"similarity\": self.similarity,\n                \"quantization\": self.quantization,\n            }\n        ]\n        if self.filter_field:\n            fields.append({\"type\": \"filter\", \"path\": self.filter_field})\n        return SearchIndexModel(definition={\"fields\": fields}, name=self.index_name, type=\"vectorSearch\")\n"},"collection_name":{"_input_type":"StrInput","advanced":false,"display_name":"Collection Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"db_name":{"_input_type":"StrInput","advanced":false,"display_name":"Database Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"db_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"enable_mtls":{"_input_type":"BoolInput","advanced":true,"display_name":"Enable mTLS","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"enable_mtls","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"filter_field":{"_input_type":"StrInput","advanced":true,"display_name":"Filter Field","dynamic":false,"info":"The field to filter the index.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"filter_field","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"index_field":{"_input_type":"StrInput","advanced":true,"display_name":"Index Field","dynamic":false,"info":"The field to index.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"index_field","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"embedding"},"index_name":{"_input_type":"StrInput","advanced":false,"display_name":"Index Name","dynamic":false,"info":"The name of Atlas Search index, it should be a Vector Search.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"index_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"insert_mode":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Insert Mode","dynamic":false,"external_options":{},"info":"How to insert new documents into the collection.","name":"insert_mode","options":["append","overwrite"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"append"},"mongodb_atlas_client_cert":{"_input_type":"SecretStrInput","advanced":false,"display_name":"MongoDB Atlas Combined Client Certificate","dynamic":false,"info":"Client Certificate combined with the private key in the following format:\n -----BEGIN PRIVATE KEY-----\n...\n -----END PRIVATE KEY-----\n-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----\n","input_types":[],"load_from_db":true,"name":"mongodb_atlas_client_cert","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"mongodb_atlas_cluster_uri":{"_input_type":"SecretStrInput","advanced":false,"display_name":"MongoDB Atlas Cluster URI","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"mongodb_atlas_cluster_uri","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"number_dimensions":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Dimensions","dynamic":false,"info":"Embedding Context Length.","list":false,"list_add_label":"Add More","name":"number_dimensions","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1536},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"quantization":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Quantization","dynamic":false,"external_options":{},"info":"Quantization reduces memory costs converting 32-bit floats to smaller data types","name":"quantization","options":["scalar","binary"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str"},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"similarity":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Similarity","dynamic":false,"external_options":{},"info":"The method used to measure the similarity between vectors.","name":"similarity","options":["cosine","euclidean","dotProduct"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"cosine"}},"tool_mode":false}}],["needle",{"needle":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"A retriever that uses the Needle API to search collections.","display_name":"Needle Retriever","documentation":"https://docs.needle-ai.com","edited":false,"field_order":["needle_api_key","collection_id","query","top_k"],"frozen":false,"icon":"Needle","legacy":false,"metadata":{"code_hash":"5f6cedaa0217","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.needle.needle.NeedleComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Result","group_outputs":false,"method":"run","name":"result","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_community.retrievers.needle import NeedleRetriever\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import IntInput, MessageTextInput, Output, SecretStrInput\nfrom lfx.schema.message import Message\nfrom lfx.utils.constants import MESSAGE_SENDER_AI\n\n\nclass NeedleComponent(Component):\n    display_name = \"Needle Retriever\"\n    description = \"A retriever that uses the Needle API to search collections.\"\n    documentation = \"https://docs.needle-ai.com\"\n    icon = \"Needle\"\n    name = \"needle\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"needle_api_key\",\n            display_name=\"Needle API Key\",\n            info=\"Your Needle API key.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"collection_id\",\n            display_name=\"Collection ID\",\n            info=\"The ID of the Needle collection.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"User Query\",\n            info=\"Enter your question here. In tool mode, you can also specify top_k parameter (min: 20).\",\n            required=True,\n            tool_mode=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K Results\",\n            info=\"Number of search results to return (min: 20).\",\n            value=20,\n            required=True,\n        ),\n    ]\n\n    outputs = [Output(display_name=\"Result\", name=\"result\", type_=\"Message\", method=\"run\")]\n\n    def run(self) -> Message:\n        # Extract query and top_k\n        query_input = self.query\n        actual_query = query_input.get(\"query\", \"\") if isinstance(query_input, dict) else query_input\n\n        # Parse top_k from tool input or use default, always enforcing minimum of 20\n        try:\n            if isinstance(query_input, dict) and \"top_k\" in query_input:\n                agent_top_k = query_input.get(\"top_k\")\n                # Check if agent_top_k is not None before converting to int\n                top_k = max(20, int(agent_top_k)) if agent_top_k is not None else max(20, self.top_k)\n            else:\n                top_k = max(20, self.top_k)\n        except (ValueError, TypeError):\n            top_k = max(20, self.top_k)\n\n        # Validate required inputs\n        if not self.needle_api_key or not self.needle_api_key.strip():\n            error_msg = \"The Needle API key cannot be empty.\"\n            raise ValueError(error_msg)\n        if not self.collection_id or not self.collection_id.strip():\n            error_msg = \"The Collection ID cannot be empty.\"\n            raise ValueError(error_msg)\n        if not actual_query or not actual_query.strip():\n            error_msg = \"The query cannot be empty.\"\n            raise ValueError(error_msg)\n\n        try:\n            # Initialize the retriever and get documents\n            retriever = NeedleRetriever(\n                needle_api_key=self.needle_api_key,\n                collection_id=self.collection_id,\n                top_k=top_k,\n            )\n\n            docs = retriever.get_relevant_documents(actual_query)\n\n            # Format the response\n            if not docs:\n                text_content = \"No relevant documents found for the query.\"\n            else:\n                context = \"\\n\\n\".join([f\"Document {i + 1}:\\n{doc.page_content}\" for i, doc in enumerate(docs)])\n                text_content = f\"Question: {actual_query}\\n\\nContext:\\n{context}\"\n\n            # Return formatted message\n            return Message(\n                text=text_content,\n                type=\"assistant\",\n                sender=MESSAGE_SENDER_AI,\n                additional_kwargs={\n                    \"source_documents\": [{\"page_content\": doc.page_content, \"metadata\": doc.metadata} for doc in docs],\n                    \"top_k_used\": top_k,\n                },\n            )\n\n        except Exception as e:\n            error_msg = f\"Error processing query: {e!s}\"\n            raise ValueError(error_msg) from e\n"},"collection_id":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Collection ID","dynamic":false,"info":"The ID of the Needle collection.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_id","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"needle_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Needle API Key","dynamic":false,"info":"Your Needle API key.","input_types":[],"load_from_db":true,"name":"needle_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"query":{"_input_type":"MessageTextInput","advanced":false,"display_name":"User Query","dynamic":false,"info":"Enter your question here. In tool mode, you can also specify top_k parameter (min: 20).","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"query","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"top_k":{"_input_type":"IntInput","advanced":false,"display_name":"Top K Results","dynamic":false,"info":"Number of search results to return (min: 20).","list":false,"list_add_label":"Add More","name":"top_k","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":20}},"tool_mode":false}}],["notdiamond",{"NotDiamond":{"base_classes":["Message","Text"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Call the right model at the right time with the world's most powerful AI model router.","display_name":"Not Diamond Router","documentation":"https://docs.notdiamond.ai/","edited":false,"field_order":["input_value","system_message","models","api_key","preference_id","tradeoff","hash_content"],"frozen":false,"icon":"NotDiamond","legacy":false,"metadata":{"code_hash":"a26ebf501f67","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"langchain_core","version":"0.3.79"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.notdiamond.notdiamond.NotDiamondComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Output","group_outputs":false,"method":"model_select","name":"output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Selected Model","group_outputs":false,"method":"get_selected_model","name":"selected_model","required_inputs":["output"],"selected":"Text","tool_mode":true,"types":["Text"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Not Diamond API Key","dynamic":false,"info":"The Not Diamond API Key to use for routing.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"NOTDIAMOND_API_KEY"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import warnings\n\nimport requests\nfrom langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage\nfrom pydantic.v1 import SecretStr\n\nfrom lfx.base.models.chat_result import get_chat_result\nfrom lfx.base.models.model_utils import get_model_name\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import (\n    BoolInput,\n    DropdownInput,\n    HandleInput,\n    MessageInput,\n    MessageTextInput,\n    Output,\n    SecretStrInput,\n    StrInput,\n)\nfrom lfx.schema.message import Message\n\nND_MODEL_MAPPING = {\n    \"gpt-4o\": {\"provider\": \"openai\", \"model\": \"gpt-4o\"},\n    \"gpt-4o-mini\": {\"provider\": \"openai\", \"model\": \"gpt-4o-mini\"},\n    \"gpt-4-turbo\": {\"provider\": \"openai\", \"model\": \"gpt-4-turbo-2024-04-09\"},\n    \"claude-3-5-haiku-20241022\": {\"provider\": \"anthropic\", \"model\": \"claude-3-5-haiku-20241022\"},\n    \"claude-3-5-sonnet-20241022\": {\"provider\": \"anthropic\", \"model\": \"claude-3-5-sonnet-20241022\"},\n    \"anthropic.claude-3-5-sonnet-20241022-v2:0\": {\"provider\": \"anthropic\", \"model\": \"claude-3-5-sonnet-20241022\"},\n    \"anthropic.claude-3-5-haiku-20241022-v1:0\": {\"provider\": \"anthropic\", \"model\": \"claude-3-5-haiku-20241022\"},\n    \"gemini-1.5-pro\": {\"provider\": \"google\", \"model\": \"gemini-1.5-pro-latest\"},\n    \"gemini-1.5-flash\": {\"provider\": \"google\", \"model\": \"gemini-1.5-flash-latest\"},\n    \"llama-3.1-sonar-large-128k-online\": {\"provider\": \"perplexity\", \"model\": \"llama-3.1-sonar-large-128k-online\"},\n    \"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\": {\n        \"provider\": \"togetherai\",\n        \"model\": \"Meta-Llama-3.1-70B-Instruct-Turbo\",\n    },\n    \"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\": {\n        \"provider\": \"togetherai\",\n        \"model\": \"Meta-Llama-3.1-405B-Instruct-Turbo\",\n    },\n    \"mistral-large-latest\": {\"provider\": \"mistral\", \"model\": \"mistral-large-2407\"},\n}\n\n\nclass NotDiamondComponent(Component):\n    display_name = \"Not Diamond Router\"\n    description = \"Call the right model at the right time with the world's most powerful AI model router.\"\n    documentation: str = \"https://docs.notdiamond.ai/\"\n    icon = \"NotDiamond\"\n    name = \"NotDiamond\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self._selected_model_name = None\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\", required=True),\n        MessageTextInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=False,\n        ),\n        HandleInput(\n            name=\"models\",\n            display_name=\"Language Models\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n            is_list=True,\n            info=\"Link the models you want to route between.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Not Diamond API Key\",\n            info=\"The Not Diamond API Key to use for routing.\",\n            advanced=False,\n            value=\"NOTDIAMOND_API_KEY\",\n            required=True,\n        ),\n        StrInput(\n            name=\"preference_id\",\n            display_name=\"Preference ID\",\n            info=\"The ID of the router preference that was configured via the Dashboard.\",\n            advanced=False,\n        ),\n        DropdownInput(\n            name=\"tradeoff\",\n            display_name=\"Tradeoff\",\n            info=\"The tradeoff between cost and latency for the router to determine the best LLM for a given query.\",\n            advanced=False,\n            options=[\"quality\", \"cost\", \"latency\"],\n            value=\"quality\",\n        ),\n        BoolInput(\n            name=\"hash_content\",\n            display_name=\"Hash Content\",\n            info=\"Whether to hash the content before being sent to the NotDiamond API.\",\n            advanced=False,\n            value=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"model_select\"),\n        Output(\n            display_name=\"Selected Model\",\n            name=\"selected_model\",\n            method=\"get_selected_model\",\n            required_inputs=[\"output\"],\n        ),\n    ]\n\n    def get_selected_model(self) -> str:\n        return self._selected_model_name\n\n    def model_select(self) -> Message:\n        api_key = SecretStr(self.api_key).get_secret_value() if self.api_key else None\n        input_value = self.input_value\n        system_message = self.system_message\n        messages = self._format_input(input_value, system_message)\n\n        selected_models = []\n        mapped_selected_models = []\n        for model in self.models:\n            model_name = get_model_name(model)\n\n            if model_name in ND_MODEL_MAPPING:\n                selected_models.append(model)\n                mapped_selected_models.append(ND_MODEL_MAPPING[model_name])\n\n        payload = {\n            \"messages\": messages,\n            \"llm_providers\": mapped_selected_models,\n            \"hash_content\": self.hash_content,\n        }\n\n        if self.tradeoff != \"quality\":\n            payload[\"tradeoff\"] = self.tradeoff\n\n        if self.preference_id and self.preference_id != \"\":\n            payload[\"preference_id\"] = self.preference_id\n\n        header = {\n            \"Authorization\": f\"Bearer {api_key}\",\n            \"accept\": \"application/json\",\n            \"content-type\": \"application/json\",\n        }\n\n        response = requests.post(\n            \"https://api.notdiamond.ai/v2/modelRouter/modelSelect\",\n            json=payload,\n            headers=header,\n            timeout=10,\n        )\n\n        result = response.json()\n        chosen_model = self.models[0]  # By default there is a fallback model\n        self._selected_model_name = get_model_name(chosen_model)\n\n        if \"providers\" not in result:\n            # No provider returned by NotDiamond API, likely failed. Fallback to first model.\n            return self._call_get_chat_result(chosen_model, input_value, system_message)\n\n        providers = result[\"providers\"]\n\n        if len(providers) == 0:\n            # No provider returned by NotDiamond API, likely failed. Fallback to first model.\n            return self._call_get_chat_result(chosen_model, input_value, system_message)\n\n        nd_result = providers[0]\n\n        for nd_model, selected_model in zip(mapped_selected_models, selected_models, strict=False):\n            if nd_model[\"provider\"] == nd_result[\"provider\"] and nd_model[\"model\"] == nd_result[\"model\"]:\n                chosen_model = selected_model\n                self._selected_model_name = get_model_name(chosen_model)\n                break\n\n        return self._call_get_chat_result(chosen_model, input_value, system_message)\n\n    def _call_get_chat_result(self, chosen_model, input_value, system_message):\n        return get_chat_result(\n            runnable=chosen_model,\n            input_value=input_value,\n            system_message=system_message,\n        )\n\n    def _format_input(\n        self,\n        input_value: str | Message,\n        system_message: str | None = None,\n    ):\n        messages: list[BaseMessage] = []\n        if not input_value and not system_message:\n            msg = \"The message you want to send to the router is empty.\"\n            raise ValueError(msg)\n        system_message_added = False\n        if input_value:\n            if isinstance(input_value, Message):\n                with warnings.catch_warnings():\n                    warnings.simplefilter(\"ignore\")\n                    if \"prompt\" in input_value:\n                        prompt = input_value.load_lc_prompt()\n                        if system_message:\n                            prompt.messages = [\n                                SystemMessage(content=system_message),\n                                *prompt.messages,  # type: ignore[has-type]\n                            ]\n                            system_message_added = True\n                        messages.extend(prompt.messages)\n                    else:\n                        messages.append(input_value.to_lc_message())\n            else:\n                messages.append(HumanMessage(content=input_value))\n\n        if system_message and not system_message_added:\n            messages.insert(0, SystemMessage(content=system_message))\n\n        # Convert Langchain messages to OpenAI format\n        openai_messages = []\n        for msg in messages:\n            if isinstance(msg, HumanMessage):\n                openai_messages.append({\"role\": \"user\", \"content\": msg.content})\n            elif isinstance(msg, AIMessage):\n                openai_messages.append({\"role\": \"assistant\", \"content\": msg.content})\n            elif isinstance(msg, SystemMessage):\n                openai_messages.append({\"role\": \"system\", \"content\": msg.content})\n\n        return openai_messages\n"},"hash_content":{"_input_type":"BoolInput","advanced":false,"display_name":"Hash Content","dynamic":false,"info":"Whether to hash the content before being sent to the NotDiamond API.","list":false,"list_add_label":"Add More","name":"hash_content","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"models":{"_input_type":"HandleInput","advanced":false,"display_name":"Language Models","dynamic":false,"info":"Link the models you want to route between.","input_types":["LanguageModel"],"list":true,"list_add_label":"Add More","name":"models","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"preference_id":{"_input_type":"StrInput","advanced":false,"display_name":"Preference ID","dynamic":false,"info":"The ID of the router preference that was configured via the Dashboard.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"preference_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"system_message":{"_input_type":"MessageTextInput","advanced":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"tradeoff":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Tradeoff","dynamic":false,"external_options":{},"info":"The tradeoff between cost and latency for the router to determine the best LLM for a given query.","name":"tradeoff","options":["quality","cost","latency"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"quality"}},"tool_mode":false}}],["novita",{"NovitaModel":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generates text using Novita AI LLMs (OpenAI compatible).","display_name":"Novita AI","documentation":"","edited":false,"field_order":["input_value","system_message","stream","max_tokens","model_kwargs","json_mode","model_name","api_key","temperature","seed","output_parser"],"frozen":false,"icon":"Novita","legacy":false,"metadata":{"code_hash":"2142c4dd2b64","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"langchain_openai","version":"0.3.23"},{"name":"pydantic","version":"2.10.6"},{"name":"typing_extensions","version":"4.15.0"},{"name":"lfx","version":null}],"total_dependencies":5},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.novita.novita.NovitaModelComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Novita API Key","dynamic":false,"info":"The Novita API Key to use for Novita AI models.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"type":"str","value":"NOVITA_API_KEY"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import requests\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\nfrom typing_extensions import override\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.base.models.novita_constants import MODEL_NAMES\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.inputs.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    SecretStrInput,\n    SliderInput,\n)\n\n\nclass NovitaModelComponent(LCModelComponent):\n    display_name = \"Novita AI\"\n    description = \"Generates text using Novita AI LLMs (OpenAI compatible).\"\n    icon = \"Novita\"\n    name = \"NovitaModel\"\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=MODEL_NAMES,\n            value=MODEL_NAMES[0],\n            refresh_button=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Novita API Key\",\n            info=\"The Novita API Key to use for Novita AI models.\",\n            advanced=False,\n            value=\"NOVITA_API_KEY\",\n            real_time_refresh=True,\n        ),\n        SliderInput(name=\"temperature\", display_name=\"Temperature\", value=0.1, range_spec=RangeSpec(min=0, max=1)),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def get_models(self) -> list[str]:\n        base_url = \"https://api.novita.ai/v3/openai\"\n        url = f\"{base_url}/models\"\n\n        headers = {\"Content-Type\": \"application/json\"}\n\n        try:\n            response = requests.get(url, headers=headers, timeout=10)\n            response.raise_for_status()\n            model_list = response.json()\n            return [model[\"id\"] for model in model_list.get(\"data\", [])]\n        except requests.RequestException as e:\n            self.status = f\"Error fetching models: {e}\"\n            return MODEL_NAMES\n\n    @override\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\n        if field_name in {\"api_key\", \"model_name\"}:\n            models = self.get_models()\n            build_config[\"model_name\"][\"options\"] = models\n        return build_config\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        json_mode = self.json_mode\n        seed = self.seed\n\n        try:\n            output = ChatOpenAI(\n                model=model_name,\n                api_key=(SecretStr(api_key).get_secret_value() if api_key else None),\n                max_tokens=max_tokens or None,\n                temperature=temperature,\n                model_kwargs=model_kwargs,\n                streaming=self.stream,\n                seed=seed,\n                base_url=\"https://api.novita.ai/v3/openai\",\n            )\n        except Exception as e:\n            msg = \"Could not connect to Novita API.\"\n            raise ValueError(msg) from e\n\n        if json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n"},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"json_mode":{"_input_type":"BoolInput","advanced":true,"display_name":"JSON Mode","dynamic":false,"info":"If True, it will output JSON regardless of passing a schema.","list":false,"list_add_label":"Add More","name":"json_mode","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"max_tokens":{"_input_type":"IntInput","advanced":true,"display_name":"Max Tokens","dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","list":false,"list_add_label":"Add More","name":"max_tokens","placeholder":"","range_spec":{"max":128000.0,"min":0.0,"step":0.1,"step_type":"float"},"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"model_kwargs":{"_input_type":"DictInput","advanced":true,"display_name":"Model Kwargs","dynamic":false,"info":"Additional keyword arguments to pass to the model.","list":false,"list_add_label":"Add More","name":"model_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model Name","dynamic":false,"external_options":{},"info":"","name":"model_name","options":["deepseek/deepseek-r1","deepseek/deepseek_v3","meta-llama/llama-3.3-70b-instruct","meta-llama/llama-3.1-8b-instruct","meta-llama/llama-3.1-70b-instruct","mistralai/mistral-nemo","Sao10K/L3-8B-Stheno-v3.2","gryphe/mythomax-l2-13b","qwen/qwen-2.5-72b-instruct","meta-llama/llama-3-8b-instruct","microsoft/wizardlm-2-8x22b","google/gemma-2-9b-it","mistralai/mistral-7b-instruct","meta-llama/llama-3-70b-instruct","openchat/openchat-7b","nousresearch/hermes-2-pro-llama-3-8b","sao10k/l3-70b-euryale-v2.1","cognitivecomputations/dolphin-mixtral-8x22b","jondurbin/airoboros-l2-70b","nousresearch/nous-hermes-llama2-13b","teknium/openhermes-2.5-mistral-7b","sophosympatheia/midnight-rose-70b","meta-llama/llama-3.1-8b-instruct-max","sao10k/l3-8b-lunaris","qwen/qwen-2-vl-72b-instruct","meta-llama/llama-3.2-1b-instruct","meta-llama/llama-3.2-11b-vision-instruct","meta-llama/llama-3.2-3b-instruct","meta-llama/llama-3.1-8b-instruct-bf16","sao10k/l31-70b-euryale-v2.2","qwen/qwen-2-7b-instruct","qwen/qwen-2-72b-instruct"],"options_metadata":[],"placeholder":"","refresh_button":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"deepseek/deepseek-r1"},"output_parser":{"_input_type":"HandleInput","advanced":true,"display_name":"Output Parser","dynamic":false,"info":"The parser to use to parse the output of the model","input_types":["OutputParser"],"list":false,"list_add_label":"Add More","name":"output_parser","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"seed":{"_input_type":"IntInput","advanced":true,"display_name":"Seed","dynamic":false,"info":"The seed controls the reproducibility of the job.","list":false,"list_add_label":"Add More","name":"seed","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"SliderInput","advanced":false,"display_name":"Temperature","dynamic":false,"info":"","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"temperature","placeholder":"","range_spec":{"max":1.0,"min":0.0,"step":0.1,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":0.1}},"tool_mode":false}}],["nvidia",{"NVIDIAEmbeddingsComponent":{"base_classes":["Embeddings"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate embeddings using NVIDIA models.","display_name":"NVIDIA Embeddings","documentation":"","edited":false,"field_order":["model","base_url","nvidia_api_key","temperature"],"frozen":false,"icon":"NVIDIA","legacy":false,"metadata":{"code_hash":"0fded038082d","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"langchain_nvidia_ai_endpoints","version":"0.3.8"}],"total_dependencies":2},"module":"lfx.components.nvidia.nvidia_embedding.NVIDIAEmbeddingsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Embedding Model","group_outputs":false,"method":"build_embeddings","name":"embeddings","selected":"Embeddings","tool_mode":true,"types":["Embeddings"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","base_url":{"_input_type":"MessageTextInput","advanced":false,"display_name":"NVIDIA Base URL","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","refresh_button":true,"required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"https://integrate.api.nvidia.com/v1"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom lfx.base.embeddings.model import LCEmbeddingsModel\nfrom lfx.field_typing import Embeddings\nfrom lfx.inputs.inputs import DropdownInput, SecretStrInput\nfrom lfx.io import FloatInput, MessageTextInput\nfrom lfx.schema.dotdict import dotdict\n\n\nclass NVIDIAEmbeddingsComponent(LCEmbeddingsModel):\n    display_name: str = \"NVIDIA Embeddings\"\n    description: str = \"Generate embeddings using NVIDIA models.\"\n    icon = \"NVIDIA\"\n\n    inputs = [\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\n                \"nvidia/nv-embed-v1\",\n                \"snowflake/arctic-embed-I\",\n            ],\n            value=\"nvidia/nv-embed-v1\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"base_url\",\n            display_name=\"NVIDIA Base URL\",\n            refresh_button=True,\n            value=\"https://integrate.api.nvidia.com/v1\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"nvidia_api_key\",\n            display_name=\"NVIDIA API Key\",\n            info=\"The NVIDIA API Key.\",\n            advanced=False,\n            value=\"NVIDIA_API_KEY\",\n            required=True,\n        ),\n        FloatInput(\n            name=\"temperature\",\n            display_name=\"Model Temperature\",\n            value=0.1,\n            advanced=True,\n        ),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"base_url\" and field_value:\n            try:\n                build_model = self.build_embeddings()\n                ids = [model.id for model in build_model.available_models]\n                build_config[\"model\"][\"options\"] = ids\n                build_config[\"model\"][\"value\"] = ids[0]\n            except Exception as e:\n                msg = f\"Error getting model names: {e}\"\n                raise ValueError(msg) from e\n        return build_config\n\n    def build_embeddings(self) -> Embeddings:\n        try:\n            from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n        except ImportError as e:\n            msg = \"Please install langchain-nvidia-ai-endpoints to use the Nvidia model.\"\n            raise ImportError(msg) from e\n        try:\n            output = NVIDIAEmbeddings(\n                model=self.model,\n                base_url=self.base_url,\n                temperature=self.temperature,\n                nvidia_api_key=self.nvidia_api_key,\n            )\n        except Exception as e:\n            msg = f\"Could not connect to NVIDIA API. Error: {e}\"\n            raise ValueError(msg) from e\n        return output\n"},"model":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model","dynamic":false,"external_options":{},"info":"","name":"model","options":["nvidia/nv-embed-v1","snowflake/arctic-embed-I"],"options_metadata":[],"placeholder":"","required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"nvidia/nv-embed-v1"},"nvidia_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"NVIDIA API Key","dynamic":false,"info":"The NVIDIA API Key.","input_types":[],"load_from_db":true,"name":"nvidia_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"NVIDIA_API_KEY"},"temperature":{"_input_type":"FloatInput","advanced":true,"display_name":"Model Temperature","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"temperature","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.1}},"tool_mode":false},"NVIDIAModelComponent":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generates text using NVIDIA LLMs.","display_name":"NVIDIA","documentation":"","edited":false,"field_order":["input_value","system_message","stream","max_tokens","model_name","detailed_thinking","tool_model_enabled","base_url","api_key","temperature","seed"],"frozen":false,"icon":"NVIDIA","legacy":false,"metadata":{"code_hash":"fd6cae31c2a0","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"langchain_nvidia_ai_endpoints","version":"0.3.8"}],"total_dependencies":2},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.nvidia.nvidia.NVIDIAModelComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"NVIDIA API Key","dynamic":false,"info":"The NVIDIA API Key.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":"NVIDIA_API_KEY"},"base_url":{"_input_type":"MessageTextInput","advanced":false,"display_name":"NVIDIA Base URL","dynamic":false,"info":"The base URL of the NVIDIA API. Defaults to https://integrate.api.nvidia.com/v1.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"https://integrate.api.nvidia.com/v1"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.inputs.inputs import BoolInput, DropdownInput, IntInput, MessageTextInput, SecretStrInput, SliderInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.dotdict import dotdict\n\n\nclass NVIDIAModelComponent(LCModelComponent):\n    display_name = \"NVIDIA\"\n    description = \"Generates text using NVIDIA LLMs.\"\n    icon = \"NVIDIA\"\n\n    try:\n        import warnings\n\n        # Suppresses repeated warnings about NIM key in langchain_nvidia_ai_endpoints==0.3.8\n        warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"langchain_nvidia_ai_endpoints._common\")\n        from langchain_nvidia_ai_endpoints import ChatNVIDIA\n\n        all_models = ChatNVIDIA().get_available_models()\n    except ImportError as e:\n        msg = \"Please install langchain-nvidia-ai-endpoints to use the NVIDIA model.\"\n        raise ImportError(msg) from e\n    except Exception as e:  # noqa: BLE001\n        logger.warning(f\"Failed to fetch NVIDIA models during initialization: {e}. Model list will be unavailable.\")\n        all_models = []\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            info=\"The name of the NVIDIA model to use.\",\n            advanced=False,\n            value=None,\n            options=sorted(model.id for model in all_models),\n            combobox=True,\n            refresh_button=True,\n        ),\n        BoolInput(\n            name=\"detailed_thinking\",\n            display_name=\"Detailed Thinking\",\n            info=\"If true, the model will return a detailed thought process. Only supported by reasoning models.\",\n            value=False,\n            show=False,\n        ),\n        BoolInput(\n            name=\"tool_model_enabled\",\n            display_name=\"Enable Tool Models\",\n            info=\"If enabled, only show models that support tool-calling.\",\n            advanced=False,\n            value=False,\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"base_url\",\n            display_name=\"NVIDIA Base URL\",\n            value=\"https://integrate.api.nvidia.com/v1\",\n            info=\"The base URL of the NVIDIA API. Defaults to https://integrate.api.nvidia.com/v1.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"NVIDIA API Key\",\n            info=\"The NVIDIA API Key.\",\n            advanced=False,\n            value=\"NVIDIA_API_KEY\",\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            info=\"Run inference with this temperature.\",\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def get_models(self, *, tool_model_enabled: bool | None = None) -> list[str]:\n        try:\n            from langchain_nvidia_ai_endpoints import ChatNVIDIA\n        except ImportError as e:\n            msg = \"Please install langchain-nvidia-ai-endpoints to use the NVIDIA model.\"\n            raise ImportError(msg) from e\n\n        # Note: don't include the previous model, as it may not exist in available models from the new base url\n        model = ChatNVIDIA(base_url=self.base_url, api_key=self.api_key)\n        if tool_model_enabled:\n            tool_models = [m for m in model.get_available_models() if m.supports_tools]\n            return sorted(m.id for m in tool_models)\n        return sorted(m.id for m in model.available_models)\n\n    def update_build_config(self, build_config: dotdict, _field_value: Any, field_name: str | None = None):\n        if field_name in {\"model_name\", \"tool_model_enabled\", \"base_url\", \"api_key\"}:\n            try:\n                ids = self.get_models(tool_model_enabled=self.tool_model_enabled)\n                build_config[\"model_name\"][\"options\"] = ids\n\n                if \"value\" not in build_config[\"model_name\"] or build_config[\"model_name\"][\"value\"] is None:\n                    build_config[\"model_name\"][\"value\"] = ids[0]\n                elif build_config[\"model_name\"][\"value\"] not in ids:\n                    build_config[\"model_name\"][\"value\"] = None\n\n                # TODO: use api to determine if model supports detailed thinking\n                if build_config[\"model_name\"][\"value\"] == \"nemotron\":\n                    build_config[\"detailed_thinking\"][\"show\"] = True\n                else:\n                    build_config[\"detailed_thinking\"][\"value\"] = False\n                    build_config[\"detailed_thinking\"][\"show\"] = False\n            except Exception as e:\n                msg = f\"Error getting model names: {e}\"\n                build_config[\"model_name\"][\"value\"] = None\n                build_config[\"model_name\"][\"options\"] = []\n                raise ValueError(msg) from e\n\n        return build_config\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_nvidia_ai_endpoints import ChatNVIDIA\n        except ImportError as e:\n            msg = \"Please install langchain-nvidia-ai-endpoints to use the NVIDIA model.\"\n            raise ImportError(msg) from e\n        api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        seed = self.seed\n        return ChatNVIDIA(\n            max_tokens=max_tokens or None,\n            model=model_name,\n            base_url=self.base_url,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n            seed=seed,\n        )\n"},"detailed_thinking":{"_input_type":"BoolInput","advanced":false,"display_name":"Detailed Thinking","dynamic":false,"info":"If true, the model will return a detailed thought process. Only supported by reasoning models.","list":false,"list_add_label":"Add More","name":"detailed_thinking","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"max_tokens":{"_input_type":"IntInput","advanced":true,"display_name":"Max Tokens","dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","list":false,"list_add_label":"Add More","name":"max_tokens","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":true,"dialog_inputs":{},"display_name":"Model Name","dynamic":false,"external_options":{},"info":"The name of the NVIDIA model to use.","name":"model_name","options":["01-ai/yi-large","abacusai/dracarys-llama-3.1-70b-instruct","adept/fuyu-8b","ai21labs/jamba-1.5-large-instruct","ai21labs/jamba-1.5-mini-instruct","aisingapore/sea-lion-7b-instruct","baichuan-inc/baichuan2-13b-chat","databricks/dbrx-instruct","deepseek-ai/deepseek-coder-6.7b-instruct","google/codegemma-1.1-7b","google/codegemma-7b","google/deplot","google/gemma-2-27b-it","google/gemma-2-2b-it","google/gemma-2-9b-it","google/gemma-2b","google/gemma-7b","google/paligemma","google/recurrentgemma-2b","ibm/granite-3.0-3b-a800m-instruct","ibm/granite-3.0-8b-instruct","ibm/granite-34b-code-instruct","ibm/granite-8b-code-instruct","institute-of-science-tokyo/llama-3.1-swallow-70b-instruct-v0.1","institute-of-science-tokyo/llama-3.1-swallow-8b-instruct-v0.1","mediatek/breeze-7b-instruct","meta/codellama-70b","meta/llama-3.1-405b-instruct","meta/llama-3.1-70b-instruct","meta/llama-3.1-8b-instruct","meta/llama-3.2-11b-vision-instruct","meta/llama-3.2-1b-instruct","meta/llama-3.2-3b-instruct","meta/llama-3.2-90b-vision-instruct","meta/llama-3.3-70b-instruct","meta/llama2-70b","meta/llama3-70b-instruct","meta/llama3-8b-instruct","microsoft/kosmos-2","microsoft/phi-3-medium-128k-instruct","microsoft/phi-3-medium-4k-instruct","microsoft/phi-3-mini-128k-instruct","microsoft/phi-3-mini-4k-instruct","microsoft/phi-3-small-128k-instruct","microsoft/phi-3-small-8k-instruct","microsoft/phi-3-vision-128k-instruct","microsoft/phi-3.5-mini-instruct","microsoft/phi-3.5-moe-instruct","microsoft/phi-3.5-vision-instruct","mistralai/codestral-22b-instruct-v0.1","mistralai/mamba-codestral-7b-v0.1","mistralai/mathstral-7b-v0.1","mistralai/mistral-7b-instruct-v0.2","mistralai/mistral-7b-instruct-v0.3","mistralai/mistral-large","mistralai/mistral-large-2-instruct","mistralai/mixtral-8x22b-instruct-v0.1","mistralai/mixtral-8x7b-instruct-v0.1","nv-mistralai/mistral-nemo-12b-instruct","nvidia/llama-3.1-nemotron-51b-instruct","nvidia/llama-3.1-nemotron-70b-instruct","nvidia/llama-3.1-nemotron-70b-reward","nvidia/llama3-chatqa-1.5-70b","nvidia/llama3-chatqa-1.5-8b","nvidia/mistral-nemo-minitron-8b-8k-instruct","nvidia/nemotron-4-340b-instruct","nvidia/nemotron-4-mini-hindi-4b-instruct","nvidia/nemotron-mini-4b-instruct","nvidia/neva-22b","nvidia/usdcode-llama-3.1-70b-instruct","nvidia/usdcode-llama3-70b-instruct","nvidia/vila","qwen/qwen2-7b-instruct","qwen/qwen2.5-coder-32b-instruct","qwen/qwen2.5-coder-7b-instruct","rakuten/rakutenai-7b-chat","rakuten/rakutenai-7b-instruct","seallms/seallm-7b-v2.5","snowflake/arctic","thudm/chatglm3-6b","tokyotech-llm/llama-3-swallow-70b-instruct-v0.1","upstage/solar-10.7b-instruct","writer/palmyra-fin-70b-32k","writer/palmyra-med-70b","writer/palmyra-med-70b-32k","yentinglin/llama-3-taiwan-70b-instruct","zyphra/zamba2-7b-instruct"],"options_metadata":[],"placeholder":"","refresh_button":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str"},"seed":{"_input_type":"IntInput","advanced":true,"display_name":"Seed","dynamic":false,"info":"The seed controls the reproducibility of the job.","list":false,"list_add_label":"Add More","name":"seed","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"SliderInput","advanced":true,"display_name":"Temperature","dynamic":false,"info":"Run inference with this temperature.","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"temperature","placeholder":"","range_spec":{"max":1.0,"min":0.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":0.1},"tool_model_enabled":{"_input_type":"BoolInput","advanced":false,"display_name":"Enable Tool Models","dynamic":false,"info":"If enabled, only show models that support tool-calling.","list":false,"list_add_label":"Add More","name":"tool_model_enabled","placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false},"NvidiaIngestComponent":{"base_classes":["DataFrame"],"beta":true,"conditional_paths":[],"custom_fields":{},"description":"Multi-modal data extraction from documents using NVIDIA's NeMo API.","display_name":"NVIDIA Retriever Extraction","documentation":"https://docs.nvidia.com/nemo/retriever/extraction/overview/","edited":false,"field_order":["path","file_path","separator","silent_errors","delete_server_file_after_processing","ignore_unsupported_extensions","ignore_unspecified_files","base_url","api_key","extract_text","extract_charts","extract_tables","extract_images","extract_infographics","text_depth","split_text","chunk_size","chunk_overlap","filter_images","min_image_size","min_aspect_ratio","max_aspect_ratio","dedup_images","caption_images","high_resolution"],"frozen":false,"icon":"NVIDIA","legacy":false,"metadata":{"code_hash":"ff0c6660d991","dependencies":{"dependencies":[{"name":"pypdf","version":"5.1.0"},{"name":"lfx","version":null},{"name":"nv_ingest_client","version":null}],"total_dependencies":3},"module":"lfx.components.nvidia.nvidia_ingest.NvidiaIngestComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Files","group_outputs":false,"method":"load_files","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"NVIDIA API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"base_url":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"The URL of the NVIDIA NeMo Retriever Extraction API.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"caption_images":{"_input_type":"BoolInput","advanced":true,"display_name":"Caption Images","dynamic":false,"info":"Generate captions for images using the NVIDIA captioning model.","list":false,"list_add_label":"Add More","name":"caption_images","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"chunk_overlap":{"_input_type":"IntInput","advanced":true,"display_name":"Chunk Overlap","dynamic":false,"info":"Number of tokens to overlap from previous chunk","list":false,"list_add_label":"Add More","name":"chunk_overlap","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":150},"chunk_size":{"_input_type":"IntInput","advanced":true,"display_name":"Chunk size","dynamic":false,"info":"The number of tokens per chunk","list":false,"list_add_label":"Add More","name":"chunk_size","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":500},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from urllib.parse import urlparse\n\nfrom pypdf import PdfReader\n\nfrom lfx.base.data.base_file import BaseFileComponent\nfrom lfx.inputs.inputs import BoolInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\nfrom lfx.schema.data import Data\n\n\nclass NvidiaIngestComponent(BaseFileComponent):\n    display_name = \"NVIDIA Retriever Extraction\"\n    description = \"Multi-modal data extraction from documents using NVIDIA's NeMo API.\"\n    documentation: str = \"https://docs.nvidia.com/nemo/retriever/extraction/overview/\"\n    icon = \"NVIDIA\"\n    beta = True\n\n    try:\n        from nv_ingest_client.util.file_processing.extract import EXTENSION_TO_DOCUMENT_TYPE\n\n        # Supported file extensions from https://github.com/NVIDIA/nv-ingest/blob/main/README.md\n        VALID_EXTENSIONS = [\"pdf\", \"docx\", \"pptx\", \"jpeg\", \"png\", \"svg\", \"tiff\", \"txt\"]\n    except ImportError:\n        msg = (\n            \"NVIDIA Retriever Extraction (nv-ingest) is an optional dependency. \"\n            \"Install with `uv pip install 'langflow[nv-ingest]'` \"\n            \"(requires Python 3.12>=)\"\n        )\n        VALID_EXTENSIONS = [msg]\n\n    inputs = [\n        *BaseFileComponent.get_base_inputs(),\n        MessageTextInput(\n            name=\"base_url\",\n            display_name=\"Base URL\",\n            info=\"The URL of the NVIDIA NeMo Retriever Extraction API.\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"NVIDIA API Key\",\n        ),\n        BoolInput(\n            name=\"extract_text\",\n            display_name=\"Extract Text\",\n            info=\"Extract text from documents\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"extract_charts\",\n            display_name=\"Extract Charts\",\n            info=\"Extract text from charts\",\n            value=False,\n        ),\n        BoolInput(\n            name=\"extract_tables\",\n            display_name=\"Extract Tables\",\n            info=\"Extract text from tables\",\n            value=False,\n        ),\n        BoolInput(\n            name=\"extract_images\",\n            display_name=\"Extract Images\",\n            info=\"Extract images from document\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"extract_infographics\",\n            display_name=\"Extract Infographics\",\n            info=\"Extract infographics from document\",\n            value=False,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"text_depth\",\n            display_name=\"Text Depth\",\n            info=(\n                \"Level at which text is extracted (applies before splitting). \"\n                \"Support for 'block', 'line', 'span' varies by document type.\"\n            ),\n            options=[\"document\", \"page\", \"block\", \"line\", \"span\"],\n            value=\"page\",  # Default value\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"split_text\",\n            display_name=\"Split Text\",\n            info=\"Split text into smaller chunks\",\n            value=True,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk size\",\n            info=\"The number of tokens per chunk\",\n            value=500,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"Number of tokens to overlap from previous chunk\",\n            value=150,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"filter_images\",\n            display_name=\"Filter Images\",\n            info=\"Filter images (see advanced options for filtering criteria).\",\n            advanced=True,\n            value=False,\n        ),\n        IntInput(\n            name=\"min_image_size\",\n            display_name=\"Minimum Image Size Filter\",\n            info=\"Minimum image width/length in pixels\",\n            value=128,\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"min_aspect_ratio\",\n            display_name=\"Minimum Aspect Ratio Filter\",\n            info=\"Minimum allowed aspect ratio (width / height). Images narrower than this will be filtered out.\",\n            value=0.2,\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"max_aspect_ratio\",\n            display_name=\"Maximum Aspect Ratio Filter\",\n            info=\"Maximum allowed aspect ratio (width / height). Images taller than this will be filtered out.\",\n            value=5.0,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"dedup_images\",\n            display_name=\"Deduplicate Images\",\n            info=\"Filter duplicated images.\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"caption_images\",\n            display_name=\"Caption Images\",\n            info=\"Generate captions for images using the NVIDIA captioning model.\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"high_resolution\",\n            display_name=\"High Resolution (PDF only)\",\n            info=(\"Process pdf in high-resolution mode for better quality extraction from scanned pdf.\"),\n            advanced=True,\n            value=False,\n        ),\n    ]\n\n    outputs = [\n        *BaseFileComponent.get_base_outputs(),\n    ]\n\n    def process_files(self, file_list: list[BaseFileComponent.BaseFile]) -> list[BaseFileComponent.BaseFile]:\n        try:\n            from nv_ingest_client.client import Ingestor\n        except ImportError as e:\n            msg = (\n                \"NVIDIA Retriever Extraction (nv-ingest) dependencies missing. \"\n                \"Please install them using your package manager. (e.g. uv pip install langflow[nv-ingest])\"\n            )\n            raise ImportError(msg) from e\n\n        if not file_list:\n            err_msg = \"No files to process.\"\n            self.log(err_msg)\n            raise ValueError(err_msg)\n\n        # Check if all files are PDFs when high resolution mode is enabled\n        if self.high_resolution:\n            for file in file_list:\n                try:\n                    with file.path.open(\"rb\") as f:\n                        PdfReader(f)\n                except Exception as exc:\n                    error_msg = \"High-resolution mode only supports valid PDF files.\"\n                    self.log(error_msg)\n                    raise ValueError(error_msg) from exc\n\n        file_paths = [str(file.path) for file in file_list]\n\n        self.base_url: str | None = self.base_url.strip() if self.base_url else None\n        if self.base_url:\n            try:\n                urlparse(self.base_url)\n            except Exception as e:\n                error_msg = f\"Invalid Base URL format: {e}\"\n                self.log(error_msg)\n                raise ValueError(error_msg) from e\n        else:\n            base_url_error = \"Base URL is required\"\n            raise ValueError(base_url_error)\n\n        self.log(\n            f\"Creating Ingestor for Base URL: {self.base_url!r}\",\n        )\n\n        try:\n            ingestor = (\n                Ingestor(\n                    message_client_kwargs={\n                        \"base_url\": self.base_url,\n                        \"headers\": {\"Authorization\": f\"Bearer {self.api_key}\"},\n                        \"max_retries\": 3,\n                        \"timeout\": 60,\n                    }\n                )\n                .files(file_paths)\n                .extract(\n                    extract_text=self.extract_text,\n                    extract_tables=self.extract_tables,\n                    extract_charts=self.extract_charts,\n                    extract_images=self.extract_images,\n                    extract_infographics=self.extract_infographics,\n                    text_depth=self.text_depth,\n                    **({\"extract_method\": \"nemoretriever_parse\"} if self.high_resolution else {}),\n                )\n            )\n\n            if self.extract_images:\n                if self.dedup_images:\n                    ingestor = ingestor.dedup(content_type=\"image\", filter=True)\n\n                if self.filter_images:\n                    ingestor = ingestor.filter(\n                        content_type=\"image\",\n                        min_size=self.min_image_size,\n                        min_aspect_ratio=self.min_aspect_ratio,\n                        max_aspect_ratio=self.max_aspect_ratio,\n                        filter=True,\n                    )\n\n                if self.caption_images:\n                    ingestor = ingestor.caption()\n\n            if self.extract_text and self.split_text:\n                ingestor = ingestor.split(\n                    tokenizer=\"intfloat/e5-large-unsupervised\",\n                    chunk_size=self.chunk_size,\n                    chunk_overlap=self.chunk_overlap,\n                    params={\"split_source_types\": [\"PDF\"]},\n                )\n\n            result = ingestor.ingest()\n        except Exception as e:\n            ingest_error = f\"Error during ingestion: {e}\"\n            self.log(ingest_error)\n            raise\n\n        self.log(f\"Results: {result}\")\n\n        data: list[Data | None] = []\n        document_type_text = \"text\"\n        document_type_structured = \"structured\"\n\n        # Result is a list of segments as determined by the text_depth option (if \"document\" then only one segment)\n        # each segment is a list of elements (text, structured, image)\n        for segment in result:\n            if segment:\n                for element in segment:\n                    document_type = element.get(\"document_type\")\n                    metadata = element.get(\"metadata\", {})\n                    source_metadata = metadata.get(\"source_metadata\", {})\n\n                    if document_type == document_type_text:\n                        data.append(\n                            Data(\n                                text=metadata.get(\"content\", \"\"),\n                                file_path=source_metadata.get(\"source_name\", \"\"),\n                                document_type=document_type,\n                                metadata=metadata,\n                            )\n                        )\n                    # Both charts and tables are returned as \"structured\" document type,\n                    # with extracted text in \"table_content\"\n                    elif document_type == document_type_structured:\n                        table_metadata = metadata.get(\"table_metadata\", {})\n\n                        # reformat chart/table images as binary data\n                        if \"content\" in metadata:\n                            metadata[\"content\"] = {\"$binary\": metadata[\"content\"]}\n\n                        data.append(\n                            Data(\n                                text=table_metadata.get(\"table_content\", \"\"),\n                                file_path=source_metadata.get(\"source_name\", \"\"),\n                                document_type=document_type,\n                                metadata=metadata,\n                            )\n                        )\n                    elif document_type == \"image\":\n                        image_metadata = metadata.get(\"image_metadata\", {})\n\n                        # reformat images as binary data\n                        if \"content\" in metadata:\n                            metadata[\"content\"] = {\"$binary\": metadata[\"content\"]}\n\n                        data.append(\n                            Data(\n                                text=image_metadata.get(\"caption\", \"No caption available\"),\n                                file_path=source_metadata.get(\"source_name\", \"\"),\n                                document_type=document_type,\n                                metadata=metadata,\n                            )\n                        )\n                    else:\n                        self.log(f\"Unsupported document type {document_type}\")\n        self.status = data or \"No data\"\n\n        # merge processed data with BaseFile objects\n        return self.rollup_data(file_list, data)\n"},"dedup_images":{"_input_type":"BoolInput","advanced":true,"display_name":"Deduplicate Images","dynamic":false,"info":"Filter duplicated images.","list":false,"list_add_label":"Add More","name":"dedup_images","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"delete_server_file_after_processing":{"_input_type":"BoolInput","advanced":true,"display_name":"Delete Server File After Processing","dynamic":false,"info":"If true, the Server File Path will be deleted after processing.","list":false,"list_add_label":"Add More","name":"delete_server_file_after_processing","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"extract_charts":{"_input_type":"BoolInput","advanced":false,"display_name":"Extract Charts","dynamic":false,"info":"Extract text from charts","list":false,"list_add_label":"Add More","name":"extract_charts","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"extract_images":{"_input_type":"BoolInput","advanced":false,"display_name":"Extract Images","dynamic":false,"info":"Extract images from document","list":false,"list_add_label":"Add More","name":"extract_images","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"extract_infographics":{"_input_type":"BoolInput","advanced":true,"display_name":"Extract Infographics","dynamic":false,"info":"Extract infographics from document","list":false,"list_add_label":"Add More","name":"extract_infographics","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"extract_tables":{"_input_type":"BoolInput","advanced":false,"display_name":"Extract Tables","dynamic":false,"info":"Extract text from tables","list":false,"list_add_label":"Add More","name":"extract_tables","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"extract_text":{"_input_type":"BoolInput","advanced":false,"display_name":"Extract Text","dynamic":false,"info":"Extract text from documents","list":false,"list_add_label":"Add More","name":"extract_text","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"file_path":{"_input_type":"HandleInput","advanced":true,"display_name":"Server File Path","dynamic":false,"info":"Data object with a 'file_path' property pointing to server file or a Message object with a path to the file. Supercedes 'Path' but supports same file types.","input_types":["Data","Message"],"list":true,"list_add_label":"Add More","name":"file_path","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"filter_images":{"_input_type":"BoolInput","advanced":true,"display_name":"Filter Images","dynamic":false,"info":"Filter images (see advanced options for filtering criteria).","list":false,"list_add_label":"Add More","name":"filter_images","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"high_resolution":{"_input_type":"BoolInput","advanced":true,"display_name":"High Resolution (PDF only)","dynamic":false,"info":"Process pdf in high-resolution mode for better quality extraction from scanned pdf.","list":false,"list_add_label":"Add More","name":"high_resolution","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"ignore_unspecified_files":{"_input_type":"BoolInput","advanced":true,"display_name":"Ignore Unspecified Files","dynamic":false,"info":"If true, Data with no 'file_path' property will be ignored.","list":false,"list_add_label":"Add More","name":"ignore_unspecified_files","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"ignore_unsupported_extensions":{"_input_type":"BoolInput","advanced":true,"display_name":"Ignore Unsupported Extensions","dynamic":false,"info":"If true, files with unsupported extensions will not be processed.","list":false,"list_add_label":"Add More","name":"ignore_unsupported_extensions","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"max_aspect_ratio":{"_input_type":"FloatInput","advanced":true,"display_name":"Maximum Aspect Ratio Filter","dynamic":false,"info":"Maximum allowed aspect ratio (width / height). Images taller than this will be filtered out.","list":false,"list_add_label":"Add More","name":"max_aspect_ratio","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":5.0},"min_aspect_ratio":{"_input_type":"FloatInput","advanced":true,"display_name":"Minimum Aspect Ratio Filter","dynamic":false,"info":"Minimum allowed aspect ratio (width / height). Images narrower than this will be filtered out.","list":false,"list_add_label":"Add More","name":"min_aspect_ratio","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.2},"min_image_size":{"_input_type":"IntInput","advanced":true,"display_name":"Minimum Image Size Filter","dynamic":false,"info":"Minimum image width/length in pixels","list":false,"list_add_label":"Add More","name":"min_image_size","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":128},"path":{"_input_type":"FileInput","advanced":false,"display_name":"Files","dynamic":false,"fileTypes":["NVIDIA Retriever Extraction (nv-ingest) is an optional dependency. Install with `uv pip install 'langflow[nv-ingest]'` (requires Python 3.12>=)","zip","tar","tgz","bz2","gz"],"file_path":"","info":"Supported file extensions: NVIDIA Retriever Extraction (nv-ingest) is an optional dependency. Install with `uv pip install 'langflow[nv-ingest]'` (requires Python 3.12>=); optionally bundled in file extensions: zip, tar, tgz, bz2, gz","list":true,"list_add_label":"Add More","name":"path","placeholder":"","required":false,"show":true,"temp_file":false,"title_case":false,"tool_mode":true,"trace_as_metadata":true,"type":"file","value":[]},"separator":{"_input_type":"StrInput","advanced":true,"display_name":"Separator","dynamic":false,"info":"Specify the separator to use between multiple outputs in Message format.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"separator","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"\n\n"},"silent_errors":{"_input_type":"BoolInput","advanced":true,"display_name":"Silent Errors","dynamic":false,"info":"If true, errors will not raise an exception.","list":false,"list_add_label":"Add More","name":"silent_errors","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"split_text":{"_input_type":"BoolInput","advanced":true,"display_name":"Split Text","dynamic":false,"info":"Split text into smaller chunks","list":false,"list_add_label":"Add More","name":"split_text","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"text_depth":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Text Depth","dynamic":false,"external_options":{},"info":"Level at which text is extracted (applies before splitting). Support for 'block', 'line', 'span' varies by document type.","name":"text_depth","options":["document","page","block","line","span"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"page"}},"tool_mode":false},"NvidiaRerankComponent":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Rerank documents using the NVIDIA API.","display_name":"NVIDIA Rerank","documentation":"","edited":false,"field_order":["search_query","search_results","top_n","api_key","base_url","model"],"frozen":false,"icon":"NVIDIA","legacy":false,"metadata":{"code_hash":"cf3976b241f1","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"langchain_nvidia_ai_endpoints","version":"0.3.8"}],"total_dependencies":2},"module":"lfx.components.nvidia.nvidia_rerank.NvidiaRerankComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Reranked Documents","group_outputs":false,"method":"compress_documents","name":"reranked_documents","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"NVIDIA API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"base_url":{"_input_type":"StrInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"The base URL of the NVIDIA API. Defaults to https://integrate.api.nvidia.com/v1.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","refresh_button":true,"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"https://integrate.api.nvidia.com/v1"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom lfx.base.compressors.model import LCCompressorComponent\nfrom lfx.field_typing import BaseDocumentCompressor\nfrom lfx.inputs.inputs import SecretStrInput\nfrom lfx.io import DropdownInput, StrInput\nfrom lfx.schema.dotdict import dotdict\nfrom lfx.template.field.base import Output\n\n\nclass NvidiaRerankComponent(LCCompressorComponent):\n    display_name = \"NVIDIA Rerank\"\n    description = \"Rerank documents using the NVIDIA API.\"\n    icon = \"NVIDIA\"\n\n    inputs = [\n        *LCCompressorComponent.inputs,\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"NVIDIA API Key\",\n        ),\n        StrInput(\n            name=\"base_url\",\n            display_name=\"Base URL\",\n            value=\"https://integrate.api.nvidia.com/v1\",\n            refresh_button=True,\n            info=\"The base URL of the NVIDIA API. Defaults to https://integrate.api.nvidia.com/v1.\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            options=[\"nv-rerank-qa-mistral-4b:1\"],\n            value=\"nv-rerank-qa-mistral-4b:1\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Reranked Documents\",\n            name=\"reranked_documents\",\n            method=\"compress_documents\",\n        ),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"base_url\" and field_value:\n            try:\n                build_model = self.build_compressor()\n                ids = [model.id for model in build_model.available_models]\n                build_config[\"model\"][\"options\"] = ids\n                build_config[\"model\"][\"value\"] = ids[0]\n            except Exception as e:\n                msg = f\"Error getting model names: {e}\"\n                raise ValueError(msg) from e\n        return build_config\n\n    def build_compressor(self) -> BaseDocumentCompressor:\n        try:\n            from langchain_nvidia_ai_endpoints import NVIDIARerank\n        except ImportError as e:\n            msg = \"Please install langchain-nvidia-ai-endpoints to use the NVIDIA model.\"\n            raise ImportError(msg) from e\n        return NVIDIARerank(api_key=self.api_key, model=self.model, base_url=self.base_url, top_n=self.top_n)\n"},"model":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model","dynamic":false,"external_options":{},"info":"","name":"model","options":["nv-rerank-qa-mistral-4b:1"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"nv-rerank-qa-mistral-4b:1"},"search_query":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Search Query","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"search_query","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"search_results":{"_input_type":"DataInput","advanced":false,"display_name":"Search Results","dynamic":false,"info":"Search Results from a Vector Store.","input_types":["Data"],"list":true,"list_add_label":"Add More","name":"search_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"top_n":{"_input_type":"IntInput","advanced":true,"display_name":"Top N","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"top_n","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":3}},"tool_mode":false},"NvidiaSystemAssistComponent":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"(Windows only) Prompts NVIDIA System-Assist to interact with the NVIDIA GPU Driver. The user may query GPU specifications, state, and ask the NV-API to perform several GPU-editing acations. The prompt must be human-readable language.","display_name":"NVIDIA System-Assist","documentation":"https://docs.langflow.org/integrations-nvidia-g-assist","edited":false,"field_order":["prompt"],"frozen":false,"icon":"NVIDIA","legacy":false,"metadata":{"code_hash":"1bc720b0b431","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"gassist","version":null}],"total_dependencies":2},"module":"lfx.components.nvidia.system_assist.NvidiaSystemAssistComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Response","group_outputs":false,"method":"sys_assist_prompt","name":"response","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import asyncio\n\nfrom lfx.custom.custom_component.component_with_cache import ComponentWithCache\nfrom lfx.io import MessageTextInput, Output\nfrom lfx.schema import Message\nfrom lfx.services.cache.utils import CacheMiss\n\nRISE_INITIALIZED_KEY = \"rise_initialized\"\n\n\nclass NvidiaSystemAssistComponent(ComponentWithCache):\n    display_name = \"NVIDIA System-Assist\"\n    description = (\n        \"(Windows only) Prompts NVIDIA System-Assist to interact with the NVIDIA GPU Driver. \"\n        \"The user may query GPU specifications, state, and ask the NV-API to perform \"\n        \"several GPU-editing acations. The prompt must be human-readable language.\"\n    )\n    documentation = \"https://docs.langflow.org/integrations-nvidia-g-assist\"\n    icon = \"NVIDIA\"\n    rise_initialized = False\n\n    inputs = [\n        MessageTextInput(\n            name=\"prompt\",\n            display_name=\"System-Assist Prompt\",\n            info=\"Enter a prompt for NVIDIA System-Assist to process. Example: 'What is my GPU?'\",\n            value=\"\",\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Response\", name=\"response\", method=\"sys_assist_prompt\"),\n    ]\n\n    def maybe_register_rise_client(self):\n        try:\n            from gassist.rise import register_rise_client\n\n            rise_initialized = self._shared_component_cache.get(RISE_INITIALIZED_KEY)\n            if not isinstance(rise_initialized, CacheMiss) and rise_initialized:\n                return\n            self.log(\"Initializing Rise Client\")\n\n            register_rise_client()\n            self._shared_component_cache.set(key=RISE_INITIALIZED_KEY, value=True)\n        except ImportError as e:\n            msg = \"NVIDIA System-Assist is Windows only and not supported on this platform\"\n            raise ValueError(msg) from e\n        except Exception as e:\n            msg = f\"An error occurred initializing NVIDIA System-Assist: {e}\"\n            raise ValueError(msg) from e\n\n    async def sys_assist_prompt(self) -> Message:\n        try:\n            from gassist.rise import send_rise_command\n        except ImportError as e:\n            msg = \"NVIDIA System-Assist is Windows only and not supported on this platform\"\n            raise ValueError(msg) from e\n\n        self.maybe_register_rise_client()\n\n        response = await asyncio.to_thread(send_rise_command, self.prompt)\n\n        return Message(text=response[\"completed_response\"]) if response is not None else Message(text=None)\n"},"prompt":{"_input_type":"MessageTextInput","advanced":false,"display_name":"System-Assist Prompt","dynamic":false,"info":"Enter a prompt for NVIDIA System-Assist to process. Example: 'What is my GPU?'","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"prompt","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["olivya",{"OlivyaComponent":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"A component to create an outbound call request from Olivya's platform.","display_name":"Place Call","documentation":"http://docs.langflow.org/components/olivya","edited":false,"field_order":["api_key","from_number","to_number","first_message","system_prompt","conversation_history"],"frozen":false,"icon":"Olivya","legacy":false,"metadata":{"code_hash":"3c39ac9fc741","dependencies":{"dependencies":[{"name":"httpx","version":"0.28.1"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.olivya.olivya.OlivyaComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Output","group_outputs":false,"method":"build_output","name":"output","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Olivya API Key","dynamic":false,"info":"Your API key for authentication","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"api_key","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\n\nimport httpx\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import MessageTextInput, Output\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\n\n\nclass OlivyaComponent(Component):\n    display_name = \"Place Call\"\n    description = \"A component to create an outbound call request from Olivya's platform.\"\n    documentation: str = \"http://docs.langflow.org/components/olivya\"\n    icon = \"Olivya\"\n    name = \"OlivyaComponent\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"api_key\",\n            display_name=\"Olivya API Key\",\n            info=\"Your API key for authentication\",\n            value=\"\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"from_number\",\n            display_name=\"From Number\",\n            info=\"The Agent's phone number\",\n            value=\"\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"to_number\",\n            display_name=\"To Number\",\n            info=\"The recipient's phone number\",\n            value=\"\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"first_message\",\n            display_name=\"First Message\",\n            info=\"The Agent's introductory message\",\n            value=\"\",\n            required=False,\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"The system prompt to guide the interaction\",\n            value=\"\",\n            required=False,\n        ),\n        MessageTextInput(\n            name=\"conversation_history\",\n            display_name=\"Conversation History\",\n            info=\"The summary of the conversation\",\n            value=\"\",\n            required=False,\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n    ]\n\n    async def build_output(self) -> Data:\n        try:\n            payload = {\n                \"variables\": {\n                    \"first_message\": self.first_message.strip() if self.first_message else None,\n                    \"system_prompt\": self.system_prompt.strip() if self.system_prompt else None,\n                    \"conversation_history\": self.conversation_history.strip() if self.conversation_history else None,\n                },\n                \"from_number\": self.from_number.strip(),\n                \"to_number\": self.to_number.strip(),\n            }\n\n            headers = {\n                \"Authorization\": self.api_key.strip(),\n                \"Content-Type\": \"application/json\",\n            }\n\n            await logger.ainfo(\"Sending POST request with payload: %s\", payload)\n\n            # Send the POST request with a timeout\n            async with httpx.AsyncClient() as client:\n                response = await client.post(\n                    \"https://phone.olivya.io/create_zap_call\",\n                    headers=headers,\n                    json=payload,\n                    timeout=10.0,\n                )\n                response.raise_for_status()\n\n                # Parse and return the successful response\n                response_data = response.json()\n                await logger.ainfo(\"Request successful: %s\", response_data)\n\n        except httpx.HTTPStatusError as http_err:\n            await logger.aexception(\"HTTP error occurred\")\n            response_data = {\"error\": f\"HTTP error occurred: {http_err}\", \"response_text\": response.text}\n        except httpx.RequestError as req_err:\n            await logger.aexception(\"Request failed\")\n            response_data = {\"error\": f\"Request failed: {req_err}\"}\n        except json.JSONDecodeError as json_err:\n            await logger.aexception(\"Response parsing failed\")\n            response_data = {\"error\": f\"Response parsing failed: {json_err}\", \"raw_response\": response.text}\n        except Exception as e:  # noqa: BLE001\n            await logger.aexception(\"An unexpected error occurred\")\n            response_data = {\"error\": f\"An unexpected error occurred: {e!s}\"}\n\n        # Return the response as part of the output\n        return Data(value=response_data)\n"},"conversation_history":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Conversation History","dynamic":false,"info":"The summary of the conversation","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"conversation_history","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"first_message":{"_input_type":"MessageTextInput","advanced":false,"display_name":"First Message","dynamic":false,"info":"The Agent's introductory message","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"first_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"from_number":{"_input_type":"MessageTextInput","advanced":false,"display_name":"From Number","dynamic":false,"info":"The Agent's phone number","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"from_number","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"system_prompt":{"_input_type":"MessageTextInput","advanced":false,"display_name":"System Prompt","dynamic":false,"info":"The system prompt to guide the interaction","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"system_prompt","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"to_number":{"_input_type":"MessageTextInput","advanced":false,"display_name":"To Number","dynamic":false,"info":"The recipient's phone number","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"to_number","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["ollama",{"OllamaEmbeddings":{"base_classes":["Embeddings"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate embeddings using Ollama models.","display_name":"Ollama Embeddings","documentation":"https://python.langchain.com/docs/integrations/text_embedding/ollama","edited":false,"field_order":["model_name","base_url"],"frozen":false,"icon":"Ollama","legacy":false,"metadata":{"code_hash":"9ef83e250bee","dependencies":{"dependencies":[{"name":"httpx","version":"0.28.1"},{"name":"langchain_ollama","version":"0.2.1"},{"name":"lfx","version":null}],"total_dependencies":3},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.ollama.ollama_embeddings.OllamaEmbeddingsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Embeddings","group_outputs":false,"method":"build_embeddings","name":"embeddings","selected":"Embeddings","tool_mode":true,"types":["Embeddings"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","base_url":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Ollama Base URL","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\nfrom urllib.parse import urljoin\n\nimport httpx\nfrom langchain_ollama import OllamaEmbeddings\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.base.models.ollama_constants import OLLAMA_EMBEDDING_MODELS\nfrom lfx.field_typing import Embeddings\nfrom lfx.io import DropdownInput, MessageTextInput, Output\nfrom lfx.utils.util import transform_localhost_url\n\nHTTP_STATUS_OK = 200\n\n\nclass OllamaEmbeddingsComponent(LCModelComponent):\n    display_name: str = \"Ollama Embeddings\"\n    description: str = \"Generate embeddings using Ollama models.\"\n    documentation = \"https://python.langchain.com/docs/integrations/text_embedding/ollama\"\n    icon = \"Ollama\"\n    name = \"OllamaEmbeddings\"\n\n    inputs = [\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Ollama Model\",\n            value=\"\",\n            options=[],\n            real_time_refresh=True,\n            refresh_button=True,\n            combobox=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"base_url\",\n            display_name=\"Ollama Base URL\",\n            value=\"\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        transformed_base_url = transform_localhost_url(self.base_url)\n        try:\n            output = OllamaEmbeddings(model=self.model_name, base_url=transformed_base_url)\n        except Exception as e:\n            msg = (\n                \"Unable to connect to the Ollama API. \",\n                \"Please verify the base URL, ensure the relevant Ollama model is pulled, and try again.\",\n            )\n            raise ValueError(msg) from e\n        return output\n\n    async def update_build_config(self, build_config: dict, _field_value: Any, field_name: str | None = None):\n        if field_name in {\"base_url\", \"model_name\"} and not await self.is_valid_ollama_url(self.base_url):\n            msg = \"Ollama is not running on the provided base URL. Please start Ollama and try again.\"\n            raise ValueError(msg)\n        if field_name in {\"model_name\", \"base_url\", \"tool_model_enabled\"}:\n            if await self.is_valid_ollama_url(self.base_url):\n                build_config[\"model_name\"][\"options\"] = await self.get_model(self.base_url)\n            else:\n                build_config[\"model_name\"][\"options\"] = []\n\n        return build_config\n\n    async def get_model(self, base_url_value: str) -> list[str]:\n        \"\"\"Get the model names from Ollama.\"\"\"\n        model_ids = []\n        try:\n            base_url_value = transform_localhost_url(base_url_value)\n            url = urljoin(base_url_value, \"/api/tags\")\n            async with httpx.AsyncClient() as client:\n                response = await client.get(url)\n                response.raise_for_status()\n                data = response.json()\n\n            model_ids = [model[\"name\"] for model in data.get(\"models\", [])]\n            # this to ensure that not embedding models are included.\n            # not even the base models since models can have 1b 2b etc\n            # handles cases when embeddings models have tags like :latest - etc.\n            model_ids = [\n                model\n                for model in model_ids\n                if any(model.startswith(f\"{embedding_model}\") for embedding_model in OLLAMA_EMBEDDING_MODELS)\n            ]\n\n        except (ImportError, ValueError, httpx.RequestError) as e:\n            msg = \"Could not get model names from Ollama.\"\n            raise ValueError(msg) from e\n\n        return model_ids\n\n    async def is_valid_ollama_url(self, url: str) -> bool:\n        try:\n            async with httpx.AsyncClient() as client:\n                url = transform_localhost_url(url)\n                return (await client.get(f\"{url}/api/tags\")).status_code == HTTP_STATUS_OK\n        except httpx.RequestError:\n            return False\n"},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":true,"dialog_inputs":{},"display_name":"Ollama Model","dynamic":false,"external_options":{},"info":"","name":"model_name","options":[],"options_metadata":[],"placeholder":"","real_time_refresh":true,"refresh_button":true,"required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"OllamaModel":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate text using Ollama Local LLMs.","display_name":"Ollama","documentation":"","edited":false,"field_order":["base_url","model_name","temperature","format","metadata","mirostat","mirostat_eta","mirostat_tau","num_ctx","num_gpu","num_thread","repeat_last_n","repeat_penalty","tfs_z","timeout","top_k","top_p","verbose","tags","stop_tokens","system","tool_model_enabled","template","input_value","system_message","stream"],"frozen":false,"icon":"Ollama","legacy":false,"metadata":{"code_hash":"29268101d832","dependencies":{"dependencies":[{"name":"httpx","version":"0.28.1"},{"name":"langchain_ollama","version":"0.2.1"},{"name":"lfx","version":null}],"total_dependencies":3},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.ollama.ollama.ChatOllamaComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","base_url":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Base URL","dynamic":false,"info":"Endpoint of the Ollama API. Defaults to http://localhost:11434 .","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"http://localhost:11434"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import asyncio\nfrom typing import Any\nfrom urllib.parse import urljoin\n\nimport httpx\nfrom langchain_ollama import ChatOllama\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SliderInput\nfrom lfx.log.logger import logger\nfrom lfx.utils.util import transform_localhost_url\n\nHTTP_STATUS_OK = 200\n\n\nclass ChatOllamaComponent(LCModelComponent):\n    display_name = \"Ollama\"\n    description = \"Generate text using Ollama Local LLMs.\"\n    icon = \"Ollama\"\n    name = \"OllamaModel\"\n\n    # Define constants for JSON keys\n    JSON_MODELS_KEY = \"models\"\n    JSON_NAME_KEY = \"name\"\n    JSON_CAPABILITIES_KEY = \"capabilities\"\n    DESIRED_CAPABILITY = \"completion\"\n    TOOL_CALLING_CAPABILITY = \"tools\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"base_url\",\n            display_name=\"Base URL\",\n            info=\"Endpoint of the Ollama API. Defaults to http://localhost:11434 .\",\n            value=\"http://localhost:11434\",\n            real_time_refresh=True,\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            options=[],\n            info=\"Refer to https://ollama.com/library for more models.\",\n            refresh_button=True,\n            real_time_refresh=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"format\", display_name=\"Format\", info=\"Specify the format of the output (e.g., json).\", advanced=True\n        ),\n        DictInput(name=\"metadata\", display_name=\"Metadata\", info=\"Metadata to add to the run trace.\", advanced=True),\n        DropdownInput(\n            name=\"mirostat\",\n            display_name=\"Mirostat\",\n            options=[\"Disabled\", \"Mirostat\", \"Mirostat 2.0\"],\n            info=\"Enable/disable Mirostat sampling for controlling perplexity.\",\n            value=\"Disabled\",\n            advanced=True,\n            real_time_refresh=True,\n        ),\n        FloatInput(\n            name=\"mirostat_eta\",\n            display_name=\"Mirostat Eta\",\n            info=\"Learning rate for Mirostat algorithm. (Default: 0.1)\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"mirostat_tau\",\n            display_name=\"Mirostat Tau\",\n            info=\"Controls the balance between coherence and diversity of the output. (Default: 5.0)\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"num_ctx\",\n            display_name=\"Context Window Size\",\n            info=\"Size of the context window for generating tokens. (Default: 2048)\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"num_gpu\",\n            display_name=\"Number of GPUs\",\n            info=\"Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"num_thread\",\n            display_name=\"Number of Threads\",\n            info=\"Number of threads to use during computation. (Default: detected for optimal performance)\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"repeat_last_n\",\n            display_name=\"Repeat Last N\",\n            info=\"How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"repeat_penalty\",\n            display_name=\"Repeat Penalty\",\n            info=\"Penalty for repetitions in generated text. (Default: 1.1)\",\n            advanced=True,\n        ),\n        FloatInput(name=\"tfs_z\", display_name=\"TFS Z\", info=\"Tail free sampling value. (Default: 1)\", advanced=True),\n        IntInput(name=\"timeout\", display_name=\"Timeout\", info=\"Timeout for the request stream.\", advanced=True),\n        IntInput(\n            name=\"top_k\", display_name=\"Top K\", info=\"Limits token selection to top K. (Default: 40)\", advanced=True\n        ),\n        FloatInput(name=\"top_p\", display_name=\"Top P\", info=\"Works together with top-k. (Default: 0.9)\", advanced=True),\n        BoolInput(name=\"verbose\", display_name=\"Verbose\", info=\"Whether to print out response text.\", advanced=True),\n        MessageTextInput(\n            name=\"tags\",\n            display_name=\"Tags\",\n            info=\"Comma-separated list of tags to add to the run trace.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"stop_tokens\",\n            display_name=\"Stop Tokens\",\n            info=\"Comma-separated list of tokens to signal the model to stop generating text.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"system\", display_name=\"System\", info=\"System to use for generating text.\", advanced=True\n        ),\n        BoolInput(\n            name=\"tool_model_enabled\",\n            display_name=\"Tool Model Enabled\",\n            info=\"Whether to enable tool calling in the model.\",\n            value=True,\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"template\", display_name=\"Template\", info=\"Template to use for generating text.\", advanced=True\n        ),\n        *LCModelComponent.get_base_inputs(),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # Mapping mirostat settings to their corresponding values\n        mirostat_options = {\"Mirostat\": 1, \"Mirostat 2.0\": 2}\n\n        # Default to 0 for 'Disabled'\n        mirostat_value = mirostat_options.get(self.mirostat, 0)\n\n        # Set mirostat_eta and mirostat_tau to None if mirostat is disabled\n        if mirostat_value == 0:\n            mirostat_eta = None\n            mirostat_tau = None\n        else:\n            mirostat_eta = self.mirostat_eta\n            mirostat_tau = self.mirostat_tau\n\n        transformed_base_url = transform_localhost_url(self.base_url)\n\n        # Check if URL contains /v1 suffix (OpenAI-compatible mode)\n        if transformed_base_url and transformed_base_url.rstrip(\"/\").endswith(\"/v1\"):\n            # Strip /v1 suffix and log warning\n            transformed_base_url = transformed_base_url.rstrip(\"/\").removesuffix(\"/v1\")\n            logger.warning(\n                \"Detected '/v1' suffix in base URL. The Ollama component uses the native Ollama API, \"\n                \"not the OpenAI-compatible API. The '/v1' suffix has been automatically removed. \"\n                \"If you want to use the OpenAI-compatible API, please use the OpenAI component instead. \"\n                \"Learn more at https://docs.ollama.com/openai#openai-compatibility\"\n            )\n\n        # Mapping system settings to their corresponding values\n        llm_params = {\n            \"base_url\": transformed_base_url,\n            \"model\": self.model_name,\n            \"mirostat\": mirostat_value,\n            \"format\": self.format,\n            \"metadata\": self.metadata,\n            \"tags\": self.tags.split(\",\") if self.tags else None,\n            \"mirostat_eta\": mirostat_eta,\n            \"mirostat_tau\": mirostat_tau,\n            \"num_ctx\": self.num_ctx or None,\n            \"num_gpu\": self.num_gpu or None,\n            \"num_thread\": self.num_thread or None,\n            \"repeat_last_n\": self.repeat_last_n or None,\n            \"repeat_penalty\": self.repeat_penalty or None,\n            \"temperature\": self.temperature or None,\n            \"stop\": self.stop_tokens.split(\",\") if self.stop_tokens else None,\n            \"system\": self.system,\n            \"tfs_z\": self.tfs_z or None,\n            \"timeout\": self.timeout or None,\n            \"top_k\": self.top_k or None,\n            \"top_p\": self.top_p or None,\n            \"verbose\": self.verbose,\n            \"template\": self.template,\n        }\n\n        # Remove parameters with None values\n        llm_params = {k: v for k, v in llm_params.items() if v is not None}\n\n        try:\n            output = ChatOllama(**llm_params)\n        except Exception as e:\n            msg = (\n                \"Unable to connect to the Ollama API. \"\n                \"Please verify the base URL, ensure the relevant Ollama model is pulled, and try again.\"\n            )\n            raise ValueError(msg) from e\n\n        return output\n\n    async def is_valid_ollama_url(self, url: str) -> bool:\n        try:\n            async with httpx.AsyncClient() as client:\n                url = transform_localhost_url(url)\n                if not url:\n                    return False\n                # Strip /v1 suffix if present, as Ollama API endpoints are at root level\n                url = url.rstrip(\"/\").removesuffix(\"/v1\")\n                if not url.endswith(\"/\"):\n                    url = url + \"/\"\n                return (await client.get(urljoin(url, \"api/tags\"))).status_code == HTTP_STATUS_OK\n        except httpx.RequestError:\n            return False\n\n    async def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None):\n        if field_name == \"mirostat\":\n            if field_value == \"Disabled\":\n                build_config[\"mirostat_eta\"][\"advanced\"] = True\n                build_config[\"mirostat_tau\"][\"advanced\"] = True\n                build_config[\"mirostat_eta\"][\"value\"] = None\n                build_config[\"mirostat_tau\"][\"value\"] = None\n\n            else:\n                build_config[\"mirostat_eta\"][\"advanced\"] = False\n                build_config[\"mirostat_tau\"][\"advanced\"] = False\n\n                if field_value == \"Mirostat 2.0\":\n                    build_config[\"mirostat_eta\"][\"value\"] = 0.2\n                    build_config[\"mirostat_tau\"][\"value\"] = 10\n                else:\n                    build_config[\"mirostat_eta\"][\"value\"] = 0.1\n                    build_config[\"mirostat_tau\"][\"value\"] = 5\n\n        if field_name in {\"model_name\", \"base_url\", \"tool_model_enabled\"}:\n            if await self.is_valid_ollama_url(self.base_url):\n                tool_model_enabled = build_config[\"tool_model_enabled\"].get(\"value\", False) or self.tool_model_enabled\n                build_config[\"model_name\"][\"options\"] = await self.get_models(\n                    self.base_url, tool_model_enabled=tool_model_enabled\n                )\n            else:\n                build_config[\"model_name\"][\"options\"] = []\n        if field_name == \"keep_alive_flag\":\n            if field_value == \"Keep\":\n                build_config[\"keep_alive\"][\"value\"] = \"-1\"\n                build_config[\"keep_alive\"][\"advanced\"] = True\n            elif field_value == \"Immediately\":\n                build_config[\"keep_alive\"][\"value\"] = \"0\"\n                build_config[\"keep_alive\"][\"advanced\"] = True\n            else:\n                build_config[\"keep_alive\"][\"advanced\"] = False\n\n        return build_config\n\n    async def get_models(self, base_url_value: str, *, tool_model_enabled: bool | None = None) -> list[str]:\n        \"\"\"Fetches a list of models from the Ollama API that do not have the \"embedding\" capability.\n\n        Args:\n            base_url_value (str): The base URL of the Ollama API.\n            tool_model_enabled (bool | None, optional): If True, filters the models further to include\n                only those that support tool calling. Defaults to None.\n\n        Returns:\n            list[str]: A list of model names that do not have the \"embedding\" capability. If\n                `tool_model_enabled` is True, only models supporting tool calling are included.\n\n        Raises:\n            ValueError: If there is an issue with the API request or response, or if the model\n                names cannot be retrieved.\n        \"\"\"\n        try:\n            # Strip /v1 suffix if present, as Ollama API endpoints are at root level\n            base_url = base_url_value.rstrip(\"/\").removesuffix(\"/v1\")\n            if not base_url.endswith(\"/\"):\n                base_url = base_url + \"/\"\n            base_url = transform_localhost_url(base_url)\n\n            # Ollama REST API to return models\n            tags_url = urljoin(base_url, \"api/tags\")\n\n            # Ollama REST API to return model capabilities\n            show_url = urljoin(base_url, \"api/show\")\n\n            async with httpx.AsyncClient() as client:\n                # Fetch available models\n                tags_response = await client.get(tags_url)\n                tags_response.raise_for_status()\n                models = tags_response.json()\n                if asyncio.iscoroutine(models):\n                    models = await models\n                await logger.adebug(f\"Available models: {models}\")\n\n                # Filter models that are NOT embedding models\n                model_ids = []\n                for model in models[self.JSON_MODELS_KEY]:\n                    model_name = model[self.JSON_NAME_KEY]\n                    await logger.adebug(f\"Checking model: {model_name}\")\n\n                    payload = {\"model\": model_name}\n                    show_response = await client.post(show_url, json=payload)\n                    show_response.raise_for_status()\n                    json_data = show_response.json()\n                    if asyncio.iscoroutine(json_data):\n                        json_data = await json_data\n                    capabilities = json_data.get(self.JSON_CAPABILITIES_KEY, [])\n                    await logger.adebug(f\"Model: {model_name}, Capabilities: {capabilities}\")\n\n                    if self.DESIRED_CAPABILITY in capabilities and (\n                        not tool_model_enabled or self.TOOL_CALLING_CAPABILITY in capabilities\n                    ):\n                        model_ids.append(model_name)\n\n        except (httpx.RequestError, ValueError) as e:\n            msg = \"Could not get model names from Ollama.\"\n            raise ValueError(msg) from e\n\n        return model_ids\n"},"format":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Format","dynamic":false,"info":"Specify the format of the output (e.g., json).","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"format","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"metadata":{"_input_type":"DictInput","advanced":true,"display_name":"Metadata","dynamic":false,"info":"Metadata to add to the run trace.","list":false,"list_add_label":"Add More","name":"metadata","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"mirostat":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Mirostat","dynamic":false,"external_options":{},"info":"Enable/disable Mirostat sampling for controlling perplexity.","name":"mirostat","options":["Disabled","Mirostat","Mirostat 2.0"],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Disabled"},"mirostat_eta":{"_input_type":"FloatInput","advanced":true,"display_name":"Mirostat Eta","dynamic":false,"info":"Learning rate for Mirostat algorithm. (Default: 0.1)","list":false,"list_add_label":"Add More","name":"mirostat_eta","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":""},"mirostat_tau":{"_input_type":"FloatInput","advanced":true,"display_name":"Mirostat Tau","dynamic":false,"info":"Controls the balance between coherence and diversity of the output. (Default: 5.0)","list":false,"list_add_label":"Add More","name":"mirostat_tau","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":""},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model Name","dynamic":false,"external_options":{},"info":"Refer to https://ollama.com/library for more models.","name":"model_name","options":[],"options_metadata":[],"placeholder":"","real_time_refresh":true,"refresh_button":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"num_ctx":{"_input_type":"IntInput","advanced":true,"display_name":"Context Window Size","dynamic":false,"info":"Size of the context window for generating tokens. (Default: 2048)","list":false,"list_add_label":"Add More","name":"num_ctx","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"num_gpu":{"_input_type":"IntInput","advanced":true,"display_name":"Number of GPUs","dynamic":false,"info":"Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)","list":false,"list_add_label":"Add More","name":"num_gpu","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"num_thread":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Threads","dynamic":false,"info":"Number of threads to use during computation. (Default: detected for optimal performance)","list":false,"list_add_label":"Add More","name":"num_thread","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"repeat_last_n":{"_input_type":"IntInput","advanced":true,"display_name":"Repeat Last N","dynamic":false,"info":"How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)","list":false,"list_add_label":"Add More","name":"repeat_last_n","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"repeat_penalty":{"_input_type":"FloatInput","advanced":true,"display_name":"Repeat Penalty","dynamic":false,"info":"Penalty for repetitions in generated text. (Default: 1.1)","list":false,"list_add_label":"Add More","name":"repeat_penalty","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":""},"stop_tokens":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Stop Tokens","dynamic":false,"info":"Comma-separated list of tokens to signal the model to stop generating text.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"stop_tokens","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system":{"_input_type":"MessageTextInput","advanced":true,"display_name":"System","dynamic":false,"info":"System to use for generating text.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"system","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"tags":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Tags","dynamic":false,"info":"Comma-separated list of tags to add to the run trace.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"tags","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"SliderInput","advanced":true,"display_name":"Temperature","dynamic":false,"info":"","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"temperature","placeholder":"","range_spec":{"max":1.0,"min":0.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":0.1},"template":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Template","dynamic":false,"info":"Template to use for generating text.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"template","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"tfs_z":{"_input_type":"FloatInput","advanced":true,"display_name":"TFS Z","dynamic":false,"info":"Tail free sampling value. (Default: 1)","list":false,"list_add_label":"Add More","name":"tfs_z","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":""},"timeout":{"_input_type":"IntInput","advanced":true,"display_name":"Timeout","dynamic":false,"info":"Timeout for the request stream.","list":false,"list_add_label":"Add More","name":"timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"tool_model_enabled":{"_input_type":"BoolInput","advanced":false,"display_name":"Tool Model Enabled","dynamic":false,"info":"Whether to enable tool calling in the model.","list":false,"list_add_label":"Add More","name":"tool_model_enabled","placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"top_k":{"_input_type":"IntInput","advanced":true,"display_name":"Top K","dynamic":false,"info":"Limits token selection to top K. (Default: 40)","list":false,"list_add_label":"Add More","name":"top_k","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"top_p":{"_input_type":"FloatInput","advanced":true,"display_name":"Top P","dynamic":false,"info":"Works together with top-k. (Default: 0.9)","list":false,"list_add_label":"Add More","name":"top_p","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":""},"verbose":{"_input_type":"BoolInput","advanced":true,"display_name":"Verbose","dynamic":false,"info":"Whether to print out response text.","list":false,"list_add_label":"Add More","name":"verbose","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false}}],["openai",{"OpenAIEmbeddings":{"base_classes":["Embeddings"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate embeddings using OpenAI models.","display_name":"OpenAI Embeddings","documentation":"","edited":false,"field_order":["default_headers","default_query","chunk_size","client","deployment","embedding_ctx_length","max_retries","model","model_kwargs","openai_api_key","openai_api_base","openai_api_type","openai_api_version","openai_organization","openai_proxy","request_timeout","show_progress_bar","skip_empty","tiktoken_model_name","tiktoken_enable","dimensions"],"frozen":false,"icon":"OpenAI","legacy":false,"metadata":{"code_hash":"8a658ed6d4c9","dependencies":{"dependencies":[{"name":"langchain_openai","version":"0.3.23"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.openai.openai.OpenAIEmbeddingsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Embedding Model","group_outputs":false,"method":"build_embeddings","name":"embeddings","selected":"Embeddings","tool_mode":true,"types":["Embeddings"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","chunk_size":{"_input_type":"IntInput","advanced":true,"display_name":"Chunk Size","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"chunk_size","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1000},"client":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Client","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"client","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_openai import OpenAIEmbeddings\n\nfrom lfx.base.embeddings.model import LCEmbeddingsModel\nfrom lfx.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom lfx.field_typing import Embeddings\nfrom lfx.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass OpenAIEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIEmbeddings\"\n\n    inputs = [\n        DictInput(\n            name=\"default_headers\",\n            display_name=\"Default Headers\",\n            advanced=True,\n            info=\"Default headers to use for the API request.\",\n        ),\n        DictInput(\n            name=\"default_query\",\n            display_name=\"Default Query\",\n            advanced=True,\n            info=\"Default query parameters to use for the API request.\",\n        ),\n        IntInput(name=\"chunk_size\", display_name=\"Chunk Size\", advanced=True, value=1000),\n        MessageTextInput(name=\"client\", display_name=\"Client\", advanced=True),\n        MessageTextInput(name=\"deployment\", display_name=\"Deployment\", advanced=True),\n        IntInput(name=\"embedding_ctx_length\", display_name=\"Embedding Context Length\", advanced=True, value=1536),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=\"text-embedding-3-small\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\", required=True),\n        MessageTextInput(name=\"openai_api_base\", display_name=\"OpenAI API Base\", advanced=True),\n        MessageTextInput(name=\"openai_api_type\", display_name=\"OpenAI API Type\", advanced=True),\n        MessageTextInput(name=\"openai_api_version\", display_name=\"OpenAI API Version\", advanced=True),\n        MessageTextInput(\n            name=\"openai_organization\",\n            display_name=\"OpenAI Organization\",\n            advanced=True,\n        ),\n        MessageTextInput(name=\"openai_proxy\", display_name=\"OpenAI Proxy\", advanced=True),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n        BoolInput(name=\"show_progress_bar\", display_name=\"Show Progress Bar\", advanced=True),\n        BoolInput(name=\"skip_empty\", display_name=\"Skip Empty\", advanced=True),\n        MessageTextInput(\n            name=\"tiktoken_model_name\",\n            display_name=\"TikToken Model Name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tiktoken_enable\",\n            display_name=\"TikToken Enable\",\n            advanced=True,\n            value=True,\n            info=\"If False, you must have transformers installed.\",\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. \"\n            \"Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return OpenAIEmbeddings(\n            client=self.client or None,\n            model=self.model,\n            dimensions=self.dimensions or None,\n            deployment=self.deployment or None,\n            api_version=self.openai_api_version or None,\n            base_url=self.openai_api_base or None,\n            openai_api_type=self.openai_api_type or None,\n            openai_proxy=self.openai_proxy or None,\n            embedding_ctx_length=self.embedding_ctx_length,\n            api_key=self.openai_api_key or None,\n            organization=self.openai_organization or None,\n            allowed_special=\"all\",\n            disallowed_special=\"all\",\n            chunk_size=self.chunk_size,\n            max_retries=self.max_retries,\n            timeout=self.request_timeout or None,\n            tiktoken_enabled=self.tiktoken_enable,\n            tiktoken_model_name=self.tiktoken_model_name or None,\n            show_progress_bar=self.show_progress_bar,\n            model_kwargs=self.model_kwargs,\n            skip_empty=self.skip_empty,\n            default_headers=self.default_headers or None,\n            default_query=self.default_query or None,\n        )\n"},"default_headers":{"_input_type":"DictInput","advanced":true,"display_name":"Default Headers","dynamic":false,"info":"Default headers to use for the API request.","list":false,"list_add_label":"Add More","name":"default_headers","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"default_query":{"_input_type":"DictInput","advanced":true,"display_name":"Default Query","dynamic":false,"info":"Default query parameters to use for the API request.","list":false,"list_add_label":"Add More","name":"default_query","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"deployment":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Deployment","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"deployment","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"dimensions":{"_input_type":"IntInput","advanced":true,"display_name":"Dimensions","dynamic":false,"info":"The number of dimensions the resulting output embeddings should have. Only supported by certain models.","list":false,"list_add_label":"Add More","name":"dimensions","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"embedding_ctx_length":{"_input_type":"IntInput","advanced":true,"display_name":"Embedding Context Length","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"embedding_ctx_length","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1536},"max_retries":{"_input_type":"IntInput","advanced":true,"display_name":"Max Retries","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"max_retries","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":3},"model":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model","dynamic":false,"external_options":{},"info":"","name":"model","options":["text-embedding-3-small","text-embedding-3-large","text-embedding-ada-002"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"text-embedding-3-small"},"model_kwargs":{"_input_type":"DictInput","advanced":true,"display_name":"Model Kwargs","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"model_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"openai_api_base":{"_input_type":"MessageTextInput","advanced":true,"display_name":"OpenAI API Base","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"openai_api_base","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"openai_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"OpenAI API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"openai_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"OPENAI_API_KEY"},"openai_api_type":{"_input_type":"MessageTextInput","advanced":true,"display_name":"OpenAI API Type","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"openai_api_type","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"openai_api_version":{"_input_type":"MessageTextInput","advanced":true,"display_name":"OpenAI API Version","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"openai_api_version","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"openai_organization":{"_input_type":"MessageTextInput","advanced":true,"display_name":"OpenAI Organization","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"openai_organization","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"openai_proxy":{"_input_type":"MessageTextInput","advanced":true,"display_name":"OpenAI Proxy","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"openai_proxy","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"request_timeout":{"_input_type":"FloatInput","advanced":true,"display_name":"Request Timeout","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"request_timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":""},"show_progress_bar":{"_input_type":"BoolInput","advanced":true,"display_name":"Show Progress Bar","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"show_progress_bar","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"skip_empty":{"_input_type":"BoolInput","advanced":true,"display_name":"Skip Empty","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"skip_empty","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"tiktoken_enable":{"_input_type":"BoolInput","advanced":true,"display_name":"TikToken Enable","dynamic":false,"info":"If False, you must have transformers installed.","list":false,"list_add_label":"Add More","name":"tiktoken_enable","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"tiktoken_model_name":{"_input_type":"MessageTextInput","advanced":true,"display_name":"TikToken Model Name","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"tiktoken_model_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"OpenAIModel":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generates text using OpenAI LLMs.","display_name":"OpenAI","documentation":"","edited":false,"field_order":["input_value","system_message","stream","max_tokens","model_kwargs","json_mode","model_name","openai_api_base","api_key","temperature","seed","max_retries","timeout"],"frozen":false,"icon":"OpenAI","legacy":false,"metadata":{"code_hash":"8593bbf4fa92","dependencies":{"dependencies":[{"name":"langchain_openai","version":"0.3.23"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null},{"name":"openai","version":"1.82.1"}],"total_dependencies":4},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.openai.openai_chat_model.OpenAIModelComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"OpenAI API Key","dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"OPENAI_API_KEY"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.base.models.openai_constants import OPENAI_CHAT_MODEL_NAMES, OPENAI_REASONING_MODEL_NAMES\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.inputs.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\nfrom lfx.log.logger import logger\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_CHAT_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\n            value=OPENAI_CHAT_MODEL_NAMES[0],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        logger.debug(f\"Executing request with model: {self.model_name}\")\n        # Handle api_key - it can be string or SecretStr\n        api_key_value = None\n        if self.api_key:\n            logger.debug(f\"API key type: {type(self.api_key)}, value: {self.api_key!r}\")\n            if isinstance(self.api_key, SecretStr):\n                api_key_value = self.api_key.get_secret_value()\n            else:\n                api_key_value = str(self.api_key)\n        logger.debug(f\"Final api_key_value type: {type(api_key_value)}, value: {'***' if api_key_value else None}\")\n\n        # Handle model_kwargs and ensure api_key doesn't conflict\n        model_kwargs = self.model_kwargs or {}\n        # Remove api_key from model_kwargs if it exists to prevent conflicts\n        if \"api_key\" in model_kwargs:\n            logger.warning(\"api_key found in model_kwargs, removing to prevent conflicts\")\n            model_kwargs = dict(model_kwargs)  # Make a copy\n            del model_kwargs[\"api_key\"]\n\n        parameters = {\n            \"api_key\": api_key_value,\n            \"model_name\": self.model_name,\n            \"max_tokens\": self.max_tokens or None,\n            \"model_kwargs\": model_kwargs,\n            \"base_url\": self.openai_api_base or \"https://api.openai.com/v1\",\n            \"max_retries\": self.max_retries,\n            \"timeout\": self.timeout,\n        }\n\n        # TODO: Revisit if/once parameters are supported for reasoning models\n        unsupported_params_for_reasoning_models = [\"temperature\", \"seed\"]\n\n        if self.model_name not in OPENAI_REASONING_MODEL_NAMES:\n            parameters[\"temperature\"] = self.temperature if self.temperature is not None else 0.1\n            parameters[\"seed\"] = self.seed\n        else:\n            params_str = \", \".join(unsupported_params_for_reasoning_models)\n            logger.debug(f\"{self.model_name} is a reasoning model, {params_str} are not configurable. Ignoring.\")\n\n        # Ensure all parameter values are the correct types\n        if isinstance(parameters.get(\"api_key\"), SecretStr):\n            parameters[\"api_key\"] = parameters[\"api_key\"].get_secret_value()\n        output = ChatOpenAI(**parameters)\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_REASONING_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = False\n            build_config[\"seed\"][\"show\"] = False\n            # Hide system_message for o1 models - currently unsupported\n            if field_value.startswith(\"o1\") and \"system_message\" in build_config:\n                build_config[\"system_message\"][\"show\"] = False\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_CHAT_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = True\n            build_config[\"seed\"][\"show\"] = True\n            if \"system_message\" in build_config:\n                build_config[\"system_message\"][\"show\"] = True\n        return build_config\n"},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"json_mode":{"_input_type":"BoolInput","advanced":true,"display_name":"JSON Mode","dynamic":false,"info":"If True, it will output JSON regardless of passing a schema.","list":false,"list_add_label":"Add More","name":"json_mode","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"max_retries":{"_input_type":"IntInput","advanced":true,"display_name":"Max Retries","dynamic":false,"info":"The maximum number of retries to make when generating.","list":false,"list_add_label":"Add More","name":"max_retries","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5},"max_tokens":{"_input_type":"IntInput","advanced":true,"display_name":"Max Tokens","dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","list":false,"list_add_label":"Add More","name":"max_tokens","placeholder":"","range_spec":{"max":128000.0,"min":0.0,"step":0.1,"step_type":"float"},"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"model_kwargs":{"_input_type":"DictInput","advanced":true,"display_name":"Model Kwargs","dynamic":false,"info":"Additional keyword arguments to pass to the model.","list":false,"list_add_label":"Add More","name":"model_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":true,"dialog_inputs":{},"display_name":"Model Name","dynamic":false,"external_options":{},"info":"","name":"model_name","options":["gpt-4o-mini","gpt-4o","gpt-4.1","gpt-4.1-mini","gpt-4.1-nano","gpt-4-turbo","gpt-4-turbo-preview","gpt-4","gpt-3.5-turbo","gpt-5","gpt-5-mini","gpt-5-nano","gpt-5-chat-latest","o1","o3-mini","o3","o3-pro","o4-mini","o4-mini-high"],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"gpt-4o-mini"},"openai_api_base":{"_input_type":"StrInput","advanced":true,"display_name":"OpenAI API Base","dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"openai_api_base","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"seed":{"_input_type":"IntInput","advanced":true,"display_name":"Seed","dynamic":false,"info":"The seed controls the reproducibility of the job.","list":false,"list_add_label":"Add More","name":"seed","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"SliderInput","advanced":false,"display_name":"Temperature","dynamic":false,"info":"","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"temperature","placeholder":"","range_spec":{"max":1.0,"min":0.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":0.1},"timeout":{"_input_type":"IntInput","advanced":true,"display_name":"Timeout","dynamic":false,"info":"The timeout for requests to OpenAI completion API.","list":false,"list_add_label":"Add More","name":"timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":700}},"tool_mode":false}}],["openrouter",{"OpenRouterComponent":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"OpenRouter provides unified access to multiple AI models from different providers through a single API.","display_name":"OpenRouter","documentation":"","edited":false,"field_order":["input_value","system_message","stream","api_key","site_url","app_name","provider","model_name","temperature","max_tokens"],"frozen":false,"icon":"OpenRouter","legacy":false,"metadata":{"code_hash":"9cdc0a300538","dependencies":{"dependencies":[{"name":"httpx","version":"0.28.1"},{"name":"langchain_openai","version":"0.3.23"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null},{"name":"openai","version":"1.82.1"}],"total_dependencies":5},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.openrouter.openrouter.OpenRouterComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"OpenRouter API Key","dynamic":false,"info":"Your OpenRouter API key","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"app_name":{"_input_type":"StrInput","advanced":true,"display_name":"App Name","dynamic":false,"info":"Your app name for OpenRouter rankings","list":false,"list_add_label":"Add More","load_from_db":false,"name":"app_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from collections import defaultdict\nfrom typing import Any\n\nimport httpx\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.inputs.inputs import (\n    DropdownInput,\n    IntInput,\n    SecretStrInput,\n    SliderInput,\n    StrInput,\n)\n\n\nclass OpenRouterComponent(LCModelComponent):\n    \"\"\"OpenRouter API component for language models.\"\"\"\n\n    display_name = \"OpenRouter\"\n    description = (\n        \"OpenRouter provides unified access to multiple AI models from different providers through a single API.\"\n    )\n    icon = \"OpenRouter\"\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        SecretStrInput(\n            name=\"api_key\", display_name=\"OpenRouter API Key\", required=True, info=\"Your OpenRouter API key\"\n        ),\n        StrInput(\n            name=\"site_url\",\n            display_name=\"Site URL\",\n            info=\"Your site URL for OpenRouter rankings\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"app_name\",\n            display_name=\"App Name\",\n            info=\"Your app name for OpenRouter rankings\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"provider\",\n            display_name=\"Provider\",\n            info=\"The AI model provider\",\n            options=[\"Loading providers...\"],\n            value=\"Loading providers...\",\n            real_time_refresh=True,\n            required=True,\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model\",\n            info=\"The model to use for chat completion\",\n            options=[\"Select a provider first\"],\n            value=\"Select a provider first\",\n            real_time_refresh=True,\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.7,\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\n            info=\"Controls randomness. Lower values are more deterministic, higher values are more creative.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            info=\"Maximum number of tokens to generate\",\n            advanced=True,\n        ),\n    ]\n\n    def fetch_models(self) -> dict[str, list]:\n        \"\"\"Fetch available models from OpenRouter API and organize them by provider.\"\"\"\n        url = \"https://openrouter.ai/api/v1/models\"\n\n        try:\n            with httpx.Client() as client:\n                response = client.get(url)\n                response.raise_for_status()\n\n                models_data = response.json().get(\"data\", [])\n                provider_models = defaultdict(list)\n\n                for model in models_data:\n                    model_id = model.get(\"id\", \"\")\n                    if \"/\" in model_id:\n                        provider = model_id.split(\"/\")[0].title()\n                        provider_models[provider].append(\n                            {\n                                \"id\": model_id,\n                                \"name\": model.get(\"name\", \"\"),\n                                \"description\": model.get(\"description\", \"\"),\n                                \"context_length\": model.get(\"context_length\", 0),\n                            }\n                        )\n\n                return dict(provider_models)\n\n        except httpx.HTTPError as e:\n            self.log(f\"Error fetching models: {e!s}\")\n            return {\"Error\": [{\"id\": \"error\", \"name\": f\"Error fetching models: {e!s}\"}]}\n\n    def build_model(self) -> LanguageModel:\n        \"\"\"Build and return the OpenRouter language model.\"\"\"\n        model_not_selected = \"Please select a model\"\n        api_key_required = \"API key is required\"\n\n        if not self.model_name or self.model_name == \"Select a provider first\":\n            raise ValueError(model_not_selected)\n\n        if not self.api_key:\n            raise ValueError(api_key_required)\n\n        api_key = SecretStr(self.api_key).get_secret_value()\n\n        # Build base configuration\n        kwargs: dict[str, Any] = {\n            \"model\": self.model_name,\n            \"openai_api_key\": api_key,\n            \"openai_api_base\": \"https://openrouter.ai/api/v1\",\n            \"temperature\": self.temperature if self.temperature is not None else 0.7,\n        }\n\n        # Add optional parameters\n        if self.max_tokens:\n            kwargs[\"max_tokens\"] = self.max_tokens\n\n        headers = {}\n        if self.site_url:\n            headers[\"HTTP-Referer\"] = self.site_url\n        if self.app_name:\n            headers[\"X-Title\"] = self.app_name\n\n        if headers:\n            kwargs[\"default_headers\"] = headers\n\n        try:\n            return ChatOpenAI(**kwargs)\n        except (ValueError, httpx.HTTPError) as err:\n            error_msg = f\"Failed to build model: {err!s}\"\n            self.log(error_msg)\n            raise ValueError(error_msg) from err\n\n    def _get_exception_message(self, e: Exception) -> str | None:\n        \"\"\"Get a message from an OpenRouter exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str | None: The message from the exception, or None if no specific message can be extracted.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n\n            if isinstance(e, BadRequestError):\n                message = e.body.get(\"message\")\n                if message:\n                    return message\n        except ImportError:\n            pass\n        return None\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        \"\"\"Update build configuration based on field updates.\"\"\"\n        try:\n            if field_name is None or field_name == \"provider\":\n                provider_models = self.fetch_models()\n                build_config[\"provider\"][\"options\"] = sorted(provider_models.keys())\n                if build_config[\"provider\"][\"value\"] not in provider_models:\n                    build_config[\"provider\"][\"value\"] = build_config[\"provider\"][\"options\"][0]\n\n            if field_name == \"provider\" and field_value in self.fetch_models():\n                provider_models = self.fetch_models()\n                models = provider_models[field_value]\n\n                build_config[\"model_name\"][\"options\"] = [model[\"id\"] for model in models]\n                if models:\n                    build_config[\"model_name\"][\"value\"] = models[0][\"id\"]\n\n                tooltips = {\n                    model[\"id\"]: (f\"{model['name']}\\nContext Length: {model['context_length']}\\n{model['description']}\")\n                    for model in models\n                }\n                build_config[\"model_name\"][\"tooltips\"] = tooltips\n\n        except httpx.HTTPError as e:\n            self.log(f\"Error updating build config: {e!s}\")\n            build_config[\"provider\"][\"options\"] = [\"Error loading providers\"]\n            build_config[\"provider\"][\"value\"] = \"Error loading providers\"\n            build_config[\"model_name\"][\"options\"] = [\"Error loading models\"]\n            build_config[\"model_name\"][\"value\"] = \"Error loading models\"\n\n        return build_config\n"},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"max_tokens":{"_input_type":"IntInput","advanced":true,"display_name":"Max Tokens","dynamic":false,"info":"Maximum number of tokens to generate","list":false,"list_add_label":"Add More","name":"max_tokens","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model","dynamic":false,"external_options":{},"info":"The model to use for chat completion","name":"model_name","options":["Select a provider first"],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Select a provider first"},"provider":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Provider","dynamic":false,"external_options":{},"info":"The AI model provider","name":"provider","options":["Loading providers..."],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Loading providers..."},"site_url":{"_input_type":"StrInput","advanced":true,"display_name":"Site URL","dynamic":false,"info":"Your site URL for OpenRouter rankings","list":false,"list_add_label":"Add More","load_from_db":false,"name":"site_url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"SliderInput","advanced":true,"display_name":"Temperature","dynamic":false,"info":"Controls randomness. Lower values are more deterministic, higher values are more creative.","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"temperature","placeholder":"","range_spec":{"max":2.0,"min":0.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":0.7}},"tool_mode":false}}],["perplexity",{"PerplexityModel":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate text using Perplexity LLMs.","display_name":"Perplexity","documentation":"https://python.langchain.com/v0.2/docs/integrations/chat/perplexity/","edited":false,"field_order":["input_value","system_message","stream","model_name","max_tokens","api_key","temperature","top_p","n"],"frozen":false,"icon":"Perplexity","legacy":false,"metadata":{"code_hash":"b970844e376e","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":3},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.perplexity.perplexity.PerplexityComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Perplexity API Key","dynamic":false,"info":"The Perplexity API Key to use for the Perplexity model.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_community.chat_models import ChatPerplexity\nfrom pydantic.v1 import SecretStr\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.io import DropdownInput, FloatInput, IntInput, SecretStrInput, SliderInput\n\n\nclass PerplexityComponent(LCModelComponent):\n    display_name = \"Perplexity\"\n    description = \"Generate text using Perplexity LLMs.\"\n    documentation = \"https://python.langchain.com/v0.2/docs/integrations/chat/perplexity/\"\n    icon = \"Perplexity\"\n    name = \"PerplexityModel\"\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=[\n                \"llama-3.1-sonar-small-128k-online\",\n                \"llama-3.1-sonar-large-128k-online\",\n                \"llama-3.1-sonar-huge-128k-online\",\n                \"llama-3.1-sonar-small-128k-chat\",\n                \"llama-3.1-sonar-large-128k-chat\",\n                \"llama-3.1-8b-instruct\",\n                \"llama-3.1-70b-instruct\",\n            ],\n            value=\"llama-3.1-sonar-small-128k-online\",\n        ),\n        IntInput(name=\"max_tokens\", display_name=\"Max Output Tokens\", info=\"The maximum number of tokens to generate.\"),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Perplexity API Key\",\n            info=\"The Perplexity API Key to use for the Perplexity model.\",\n            advanced=False,\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\", display_name=\"Temperature\", value=0.75, range_spec=RangeSpec(min=0, max=2, step=0.05)\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"The maximum cumulative probability of tokens to consider when sampling.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. \"\n            \"Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        api_key = SecretStr(self.api_key).get_secret_value()\n        temperature = self.temperature\n        model = self.model_name\n        max_tokens = self.max_tokens\n        top_p = self.top_p\n        n = self.n\n\n        return ChatPerplexity(\n            model=model,\n            temperature=temperature or 0.75,\n            pplx_api_key=api_key,\n            top_p=top_p or None,\n            n=n or 1,\n            max_tokens=max_tokens,\n        )\n"},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"max_tokens":{"_input_type":"IntInput","advanced":false,"display_name":"Max Output Tokens","dynamic":false,"info":"The maximum number of tokens to generate.","list":false,"list_add_label":"Add More","name":"max_tokens","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model Name","dynamic":false,"external_options":{},"info":"","name":"model_name","options":["llama-3.1-sonar-small-128k-online","llama-3.1-sonar-large-128k-online","llama-3.1-sonar-huge-128k-online","llama-3.1-sonar-small-128k-chat","llama-3.1-sonar-large-128k-chat","llama-3.1-8b-instruct","llama-3.1-70b-instruct"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"llama-3.1-sonar-small-128k-online"},"n":{"_input_type":"IntInput","advanced":true,"display_name":"N","dynamic":false,"info":"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.","list":false,"list_add_label":"Add More","name":"n","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"SliderInput","advanced":false,"display_name":"Temperature","dynamic":false,"info":"","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"temperature","placeholder":"","range_spec":{"max":2.0,"min":0.0,"step":0.05,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":0.75},"top_p":{"_input_type":"FloatInput","advanced":true,"display_name":"Top P","dynamic":false,"info":"The maximum cumulative probability of tokens to consider when sampling.","list":false,"list_add_label":"Add More","name":"top_p","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":""}},"tool_mode":false}}],["pgvector",{"pgvector":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"PGVector Vector Store with search capabilities","display_name":"PGVector","documentation":"","edited":false,"field_order":["pg_server_url","collection_name","ingest_data","search_query","should_cache_vector_store","embedding","number_of_results"],"frozen":false,"icon":"cpu","legacy":false,"metadata":{"code_hash":"50117607bf5e","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.pgvector.pgvector.PGVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_community.vectorstores import PGVector\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.io import HandleInput, IntInput, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\nfrom lfx.utils.connection_string_parser import transform_connection_string\n\n\nclass PGVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"PGVector\"\n    description = \"PGVector Vector Store with search capabilities\"\n    name = \"pgvector\"\n    icon = \"cpu\"\n\n    inputs = [\n        SecretStrInput(name=\"pg_server_url\", display_name=\"PostgreSQL Server Connection String\", required=True),\n        StrInput(name=\"collection_name\", display_name=\"Table\", required=True),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"], required=True),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> PGVector:\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        connection_string_parsed = transform_connection_string(self.pg_server_url)\n\n        if documents:\n            pgvector = PGVector.from_documents(\n                embedding=self.embedding,\n                documents=documents,\n                collection_name=self.collection_name,\n                connection_string=connection_string_parsed,\n            )\n        else:\n            pgvector = PGVector.from_existing_index(\n                embedding=self.embedding,\n                collection_name=self.collection_name,\n                connection_string=connection_string_parsed,\n            )\n\n        return pgvector\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n"},"collection_name":{"_input_type":"StrInput","advanced":false,"display_name":"Table","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"pg_server_url":{"_input_type":"SecretStrInput","advanced":false,"display_name":"PostgreSQL Server Connection String","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"pg_server_url","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false}}],["pinecone",{"Pinecone":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Pinecone Vector Store with search capabilities","display_name":"Pinecone","documentation":"","edited":false,"field_order":["index_name","namespace","distance_strategy","pinecone_api_key","text_key","ingest_data","search_query","should_cache_vector_store","embedding","number_of_results"],"frozen":false,"icon":"Pinecone","legacy":false,"metadata":{"code_hash":"564ca0a0e9ab","dependencies":{"dependencies":[{"name":"numpy","version":"2.2.6"},{"name":"langchain_core","version":"0.3.79"},{"name":"lfx","version":null},{"name":"langchain_pinecone","version":"0.2.12"}],"total_dependencies":4},"module":"lfx.components.pinecone.pinecone.PineconeVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import numpy as np\nfrom langchain_core.vectorstores import VectorStore\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.io import DropdownInput, HandleInput, IntInput, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass PineconeVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Pinecone\"\n    description = \"Pinecone Vector Store with search capabilities\"\n    name = \"Pinecone\"\n    icon = \"Pinecone\"\n    inputs = [\n        StrInput(name=\"index_name\", display_name=\"Index Name\", required=True),\n        StrInput(name=\"namespace\", display_name=\"Namespace\", info=\"Namespace for the index.\"),\n        DropdownInput(\n            name=\"distance_strategy\",\n            display_name=\"Distance Strategy\",\n            options=[\"Cosine\", \"Euclidean\", \"Dot Product\"],\n            value=\"Cosine\",\n            advanced=True,\n        ),\n        SecretStrInput(name=\"pinecone_api_key\", display_name=\"Pinecone API Key\", required=True),\n        StrInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"Key in the record to use as text.\",\n            value=\"text\",\n            advanced=True,\n        ),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> VectorStore:\n        \"\"\"Build and return a Pinecone vector store instance.\"\"\"\n        try:\n            from langchain_pinecone import PineconeVectorStore\n        except ImportError as e:\n            msg = \"langchain-pinecone is not installed. Please install it with `pip install langchain-pinecone`.\"\n            raise ValueError(msg) from e\n\n        try:\n            from langchain_pinecone._utilities import DistanceStrategy\n\n            # Wrap the embedding model to ensure float32 output\n            wrapped_embeddings = Float32Embeddings(self.embedding)\n\n            # Convert distance strategy\n            distance_strategy = self.distance_strategy.replace(\" \", \"_\").upper()\n            distance_strategy = DistanceStrategy[distance_strategy]\n\n            # Initialize Pinecone instance with wrapped embeddings\n            pinecone = PineconeVectorStore(\n                index_name=self.index_name,\n                embedding=wrapped_embeddings,  # Use wrapped embeddings\n                text_key=self.text_key,\n                namespace=self.namespace,\n                distance_strategy=distance_strategy,\n                pinecone_api_key=self.pinecone_api_key,\n            )\n        except Exception as e:\n            error_msg = \"Error building Pinecone vector store\"\n            raise ValueError(error_msg) from e\n        else:\n            self.ingest_data = self._prepare_ingest_data()\n\n            # Process documents if any\n            documents = []\n            if self.ingest_data:\n                # Convert DataFrame to Data if needed using parent's method\n\n                for doc in self.ingest_data:\n                    if isinstance(doc, Data):\n                        documents.append(doc.to_lc_document())\n                    else:\n                        documents.append(doc)\n\n                if documents:\n                    pinecone.add_documents(documents)\n\n            return pinecone\n\n    def search_documents(self) -> list[Data]:\n        \"\"\"Search documents in the vector store.\"\"\"\n        try:\n            if not self.search_query or not isinstance(self.search_query, str) or not self.search_query.strip():\n                return []\n\n            vector_store = self.build_vector_store()\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n        except Exception as e:\n            error_msg = \"Error searching documents\"\n            raise ValueError(error_msg) from e\n        else:\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n\n\nclass Float32Embeddings:\n    \"\"\"Wrapper class to ensure float32 embeddings.\"\"\"\n\n    def __init__(self, base_embeddings):\n        self.base_embeddings = base_embeddings\n\n    def embed_documents(self, texts):\n        embeddings = self.base_embeddings.embed_documents(texts)\n        if isinstance(embeddings, np.ndarray):\n            return [[self._force_float32(x) for x in vec] for vec in embeddings]\n        return [[self._force_float32(x) for x in vec] for vec in embeddings]\n\n    def embed_query(self, text):\n        embedding = self.base_embeddings.embed_query(text)\n        if isinstance(embedding, np.ndarray):\n            return [self._force_float32(x) for x in embedding]\n        return [self._force_float32(x) for x in embedding]\n\n    def _force_float32(self, value):\n        \"\"\"Convert any numeric type to Python float.\"\"\"\n        return float(np.float32(value))\n"},"distance_strategy":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Distance Strategy","dynamic":false,"external_options":{},"info":"","name":"distance_strategy","options":["Cosine","Euclidean","Dot Product"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Cosine"},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"index_name":{"_input_type":"StrInput","advanced":false,"display_name":"Index Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"index_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"namespace":{"_input_type":"StrInput","advanced":false,"display_name":"Namespace","dynamic":false,"info":"Namespace for the index.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"namespace","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"pinecone_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Pinecone API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"pinecone_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"text_key":{"_input_type":"StrInput","advanced":true,"display_name":"Text Key","dynamic":false,"info":"Key in the record to use as text.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"text_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"text"}},"tool_mode":false}}],["processing",{"AlterMetadata":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Adds/Removes Metadata Dictionary on inputs","display_name":"Alter Metadata","documentation":"","edited":false,"field_order":["input_value","text_in","metadata","remove_fields"],"frozen":false,"icon":"merge","legacy":true,"metadata":{"code_hash":"0b2fe62eaec4","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.processing.alter_metadata.AlterMetadataComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"process_output","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["processing.DataOperations"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import MessageTextInput\nfrom lfx.io import HandleInput, NestedDictInput, Output, StrInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\n\n\nclass AlterMetadataComponent(Component):\n    display_name = \"Alter Metadata\"\n    description = \"Adds/Removes Metadata Dictionary on inputs\"\n    icon = \"merge\"\n    name = \"AlterMetadata\"\n    legacy = True\n    replacement = [\"processing.DataOperations\"]\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"Object(s) to which Metadata should be added\",\n            required=False,\n            input_types=[\"Message\", \"Data\"],\n            is_list=True,\n        ),\n        StrInput(\n            name=\"text_in\",\n            display_name=\"User Text\",\n            info=\"Text input; value will be in 'text' attribute of Data object. Empty text entries are ignored.\",\n            required=False,\n        ),\n        NestedDictInput(\n            name=\"metadata\",\n            display_name=\"Metadata\",\n            info=\"Metadata to add to each object\",\n            input_types=[\"Data\"],\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"remove_fields\",\n            display_name=\"Fields to Remove\",\n            info=\"Metadata Fields to Remove\",\n            required=False,\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"List of Input objects each with added Metadata\",\n            method=\"process_output\",\n        ),\n        Output(\n            display_name=\"DataFrame\",\n            name=\"dataframe\",\n            info=\"Data objects as a DataFrame, with metadata as columns\",\n            method=\"as_dataframe\",\n        ),\n    ]\n\n    def _as_clean_dict(self, obj):\n        \"\"\"Convert a Data object or a standard dictionary to a standard dictionary.\"\"\"\n        if isinstance(obj, dict):\n            as_dict = obj\n        elif isinstance(obj, Data):\n            as_dict = obj.data\n        else:\n            msg = f\"Expected a Data object or a dictionary but got {type(obj)}.\"\n            raise TypeError(msg)\n\n        return {k: v for k, v in (as_dict or {}).items() if k and k.strip()}\n\n    def process_output(self) -> list[Data]:\n        # Ensure metadata is a dictionary, filtering out any empty keys\n        metadata = self._as_clean_dict(self.metadata)\n\n        # Convert text_in to a Data object if it exists, and initialize our list of Data objects\n        data_objects = [Data(text=self.text_in)] if self.text_in else []\n\n        # Append existing Data objects from input_value, if any\n        if self.input_value:\n            data_objects.extend(self.input_value)\n\n        # Update each Data object with the new metadata, preserving existing fields\n        for data in data_objects:\n            data.data.update(metadata)\n\n        # Handle removal of fields specified in remove_fields\n        if self.remove_fields:\n            fields_to_remove = {field.strip() for field in self.remove_fields if field.strip()}\n\n            # Remove specified fields from each Data object's metadata\n            for data in data_objects:\n                data.data = {k: v for k, v in data.data.items() if k not in fields_to_remove}\n\n        # Set the status for tracking/debugging purposes\n        self.status = data_objects\n        return data_objects\n\n    def as_dataframe(self) -> DataFrame:\n        \"\"\"Convert the processed data objects into a DataFrame.\n\n        Returns:\n            DataFrame: A DataFrame where each row corresponds to a Data object,\n                    with metadata fields as columns.\n        \"\"\"\n        data_list = self.process_output()\n        return DataFrame(data_list)\n"},"input_value":{"_input_type":"HandleInput","advanced":false,"display_name":"Input","dynamic":false,"info":"Object(s) to which Metadata should be added","input_types":["Message","Data"],"list":true,"list_add_label":"Add More","name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"metadata":{"_input_type":"NestedDictInput","advanced":false,"display_name":"Metadata","dynamic":false,"info":"Metadata to add to each object","input_types":["Data"],"list":false,"list_add_label":"Add More","name":"metadata","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"NestedDict","value":{}},"remove_fields":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Fields to Remove","dynamic":false,"info":"Metadata Fields to Remove","input_types":["Message"],"list":true,"list_add_label":"Add More","load_from_db":false,"name":"remove_fields","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"text_in":{"_input_type":"StrInput","advanced":false,"display_name":"User Text","dynamic":false,"info":"Text input; value will be in 'text' attribute of Data object. Empty text entries are ignored.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"text_in","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"BatchRunComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Runs an LLM on each row of a DataFrame column. If no column is specified, all columns are used.","display_name":"Batch Run","documentation":"https://docs.langflow.org/components-processing#batch-run","edited":false,"field_order":["model","system_message","df","column_name","output_column_name","enable_metadata"],"frozen":false,"icon":"List","legacy":false,"metadata":{"code_hash":"299b4469032e","dependencies":{"dependencies":[{"name":"toml","version":"0.10.2"},{"name":"lfx","version":null},{"name":"langchain_core","version":"0.3.79"}],"total_dependencies":3},"module":"lfx.components.processing.batch_run.BatchRunComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"LLM Results","group_outputs":false,"method":"run_batch","name":"batch_results","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any, cast\n\nimport toml  # type: ignore[import-untyped]\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import BoolInput, DataFrameInput, HandleInput, MessageTextInput, MultilineInput, Output\nfrom lfx.log.logger import logger\nfrom lfx.schema.dataframe import DataFrame\n\nif TYPE_CHECKING:\n    from langchain_core.runnables import Runnable\n\n\nclass BatchRunComponent(Component):\n    display_name = \"Batch Run\"\n    description = \"Runs an LLM on each row of a DataFrame column. If no column is specified, all columns are used.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#batch-run\"\n    icon = \"List\"\n\n    inputs = [\n        HandleInput(\n            name=\"model\",\n            display_name=\"Language Model\",\n            info=\"Connect the 'Language Model' output from your LLM component here.\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        MultilineInput(\n            name=\"system_message\",\n            display_name=\"Instructions\",\n            info=\"Multi-line system instruction for all rows in the DataFrame.\",\n            required=False,\n        ),\n        DataFrameInput(\n            name=\"df\",\n            display_name=\"DataFrame\",\n            info=\"The DataFrame whose column (specified by 'column_name') we'll treat as text messages.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"column_name\",\n            display_name=\"Column Name\",\n            info=(\n                \"The name of the DataFrame column to treat as text messages. \"\n                \"If empty, all columns will be formatted in TOML.\"\n            ),\n            required=False,\n            advanced=False,\n        ),\n        MessageTextInput(\n            name=\"output_column_name\",\n            display_name=\"Output Column Name\",\n            info=\"Name of the column where the model's response will be stored.\",\n            value=\"model_response\",\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"enable_metadata\",\n            display_name=\"Enable Metadata\",\n            info=\"If True, add metadata to the output DataFrame.\",\n            value=False,\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"LLM Results\",\n            name=\"batch_results\",\n            method=\"run_batch\",\n            info=\"A DataFrame with all original columns plus the model's response column.\",\n        ),\n    ]\n\n    def _format_row_as_toml(self, row: dict[str, Any]) -> str:\n        \"\"\"Convert a dictionary (row) into a TOML-formatted string.\"\"\"\n        formatted_dict = {str(col): {\"value\": str(val)} for col, val in row.items()}\n        return toml.dumps(formatted_dict)\n\n    def _create_base_row(\n        self, original_row: dict[str, Any], model_response: str = \"\", batch_index: int = -1\n    ) -> dict[str, Any]:\n        \"\"\"Create a base row with original columns and additional metadata.\"\"\"\n        row = original_row.copy()\n        row[self.output_column_name] = model_response\n        row[\"batch_index\"] = batch_index\n        return row\n\n    def _add_metadata(\n        self, row: dict[str, Any], *, success: bool = True, system_msg: str = \"\", error: str | None = None\n    ) -> None:\n        \"\"\"Add metadata to a row if enabled.\"\"\"\n        if not self.enable_metadata:\n            return\n\n        if success:\n            row[\"metadata\"] = {\n                \"has_system_message\": bool(system_msg),\n                \"input_length\": len(row.get(\"text_input\", \"\")),\n                \"response_length\": len(row[self.output_column_name]),\n                \"processing_status\": \"success\",\n            }\n        else:\n            row[\"metadata\"] = {\n                \"error\": error,\n                \"processing_status\": \"failed\",\n            }\n\n    async def run_batch(self) -> DataFrame:\n        \"\"\"Process each row in df[column_name] with the language model asynchronously.\n\n        Returns:\n            DataFrame: A new DataFrame containing:\n                - All original columns\n                - The model's response column (customizable name)\n                - 'batch_index' column for processing order\n                - 'metadata' (optional)\n\n        Raises:\n            ValueError: If the specified column is not found in the DataFrame\n            TypeError: If the model is not compatible or input types are wrong\n        \"\"\"\n        model: Runnable = self.model\n        system_msg = self.system_message or \"\"\n        df: DataFrame = self.df\n        col_name = self.column_name or \"\"\n\n        # Validate inputs first\n        if not isinstance(df, DataFrame):\n            msg = f\"Expected DataFrame input, got {type(df)}\"\n            raise TypeError(msg)\n\n        if col_name and col_name not in df.columns:\n            msg = f\"Column '{col_name}' not found in the DataFrame. Available columns: {', '.join(df.columns)}\"\n            raise ValueError(msg)\n\n        try:\n            # Determine text input for each row\n            if col_name:\n                user_texts = df[col_name].astype(str).tolist()\n            else:\n                user_texts = [\n                    self._format_row_as_toml(cast(\"dict[str, Any]\", row)) for row in df.to_dict(orient=\"records\")\n                ]\n\n            total_rows = len(user_texts)\n            await logger.ainfo(f\"Processing {total_rows} rows with batch run\")\n\n            # Prepare the batch of conversations\n            conversations = [\n                [{\"role\": \"system\", \"content\": system_msg}, {\"role\": \"user\", \"content\": text}]\n                if system_msg\n                else [{\"role\": \"user\", \"content\": text}]\n                for text in user_texts\n            ]\n\n            # Configure the model with project info and callbacks\n            model = model.with_config(\n                {\n                    \"run_name\": self.display_name,\n                    \"project_name\": self.get_project_name(),\n                    \"callbacks\": self.get_langchain_callbacks(),\n                }\n            )\n            # Process batches and track progress\n            responses_with_idx = list(\n                zip(\n                    range(len(conversations)),\n                    await model.abatch(list(conversations)),\n                    strict=True,\n                )\n            )\n\n            # Sort by index to maintain order\n            responses_with_idx.sort(key=lambda x: x[0])\n\n            # Build the final data with enhanced metadata\n            rows: list[dict[str, Any]] = []\n            for idx, (original_row, response) in enumerate(\n                zip(df.to_dict(orient=\"records\"), responses_with_idx, strict=False)\n            ):\n                response_text = response[1].content if hasattr(response[1], \"content\") else str(response[1])\n                row = self._create_base_row(\n                    cast(\"dict[str, Any]\", original_row), model_response=response_text, batch_index=idx\n                )\n                self._add_metadata(row, success=True, system_msg=system_msg)\n                rows.append(row)\n\n                # Log progress\n                if (idx + 1) % max(1, total_rows // 10) == 0:\n                    await logger.ainfo(f\"Processed {idx + 1}/{total_rows} rows\")\n\n            await logger.ainfo(\"Batch processing completed successfully\")\n            return DataFrame(rows)\n\n        except (KeyError, AttributeError) as e:\n            # Handle data structure and attribute access errors\n            await logger.aerror(f\"Data processing error: {e!s}\")\n            error_row = self._create_base_row(dict.fromkeys(df.columns, \"\"), model_response=\"\", batch_index=-1)\n            self._add_metadata(error_row, success=False, error=str(e))\n            return DataFrame([error_row])\n"},"column_name":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Column Name","dynamic":false,"info":"The name of the DataFrame column to treat as text messages. If empty, all columns will be formatted in TOML.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"column_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"df":{"_input_type":"DataFrameInput","advanced":false,"display_name":"DataFrame","dynamic":false,"info":"The DataFrame whose column (specified by 'column_name') we'll treat as text messages.","input_types":["DataFrame"],"list":false,"list_add_label":"Add More","name":"df","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"enable_metadata":{"_input_type":"BoolInput","advanced":true,"display_name":"Enable Metadata","dynamic":false,"info":"If True, add metadata to the output DataFrame.","list":false,"list_add_label":"Add More","name":"enable_metadata","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"model":{"_input_type":"HandleInput","advanced":false,"display_name":"Language Model","dynamic":false,"info":"Connect the 'Language Model' output from your LLM component here.","input_types":["LanguageModel"],"list":false,"list_add_label":"Add More","name":"model","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"output_column_name":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Output Column Name","dynamic":false,"info":"Name of the column where the model's response will be stored.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"output_column_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"model_response"},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Instructions","dynamic":false,"info":"Multi-line system instruction for all rows in the DataFrame.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"CombineText":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Concatenate two text sources into a single text chunk using a specified delimiter.","display_name":"Combine Text","documentation":"","edited":false,"field_order":["text1","text2","delimiter"],"frozen":false,"icon":"merge","legacy":true,"metadata":{"code_hash":"10ffb6543dd9","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.processing.combine_text.CombineTextComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Combined Text","group_outputs":false,"method":"combine_texts","name":"combined_text","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["processing.DataOperations"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.io import MessageTextInput, Output\nfrom lfx.schema.message import Message\n\n\nclass CombineTextComponent(Component):\n    display_name = \"Combine Text\"\n    description = \"Concatenate two text sources into a single text chunk using a specified delimiter.\"\n    icon = \"merge\"\n    name = \"CombineText\"\n    legacy: bool = True\n    replacement = [\"processing.DataOperations\"]\n\n    inputs = [\n        MessageTextInput(\n            name=\"text1\",\n            display_name=\"First Text\",\n            info=\"The first text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text2\",\n            display_name=\"Second Text\",\n            info=\"The second text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"delimiter\",\n            display_name=\"Delimiter\",\n            info=\"A string used to separate the two text inputs. Defaults to a whitespace.\",\n            value=\" \",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Combined Text\", name=\"combined_text\", method=\"combine_texts\"),\n    ]\n\n    def combine_texts(self) -> Message:\n        combined = self.delimiter.join([self.text1, self.text2])\n        self.status = combined\n        return Message(text=combined)\n"},"delimiter":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Delimiter","dynamic":false,"info":"A string used to separate the two text inputs. Defaults to a whitespace.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"delimiter","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":" "},"text1":{"_input_type":"MessageTextInput","advanced":false,"display_name":"First Text","dynamic":false,"info":"The first text input to concatenate.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"text1","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"text2":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Second Text","dynamic":false,"info":"The second text input to concatenate.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"text2","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"CreateData":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Dynamically create a Data with a specified number of fields.","display_name":"Create Data","documentation":"","edited":false,"field_order":["number_of_fields","text_key","text_key_validator"],"frozen":false,"icon":"ListFilter","legacy":true,"metadata":{"code_hash":"3e313525090d","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.processing.create_data.CreateDataComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"build_data","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["processing.DataOperations"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.inputs.inputs import BoolInput, DictInput, IntInput, MessageTextInput\nfrom lfx.io import Output\nfrom lfx.schema.data import Data\nfrom lfx.schema.dotdict import dotdict\n\n\nclass CreateDataComponent(Component):\n    display_name: str = \"Create Data\"\n    description: str = \"Dynamically create a Data with a specified number of fields.\"\n    name: str = \"CreateData\"\n    MAX_FIELDS = 15  # Define a constant for maximum number of fields\n    legacy = True\n    replacement = [\"processing.DataOperations\"]\n    icon = \"ListFilter\"\n\n    inputs = [\n        IntInput(\n            name=\"number_of_fields\",\n            display_name=\"Number of Fields\",\n            info=\"Number of fields to be added to the record.\",\n            real_time_refresh=True,\n            value=1,\n            range_spec=RangeSpec(min=1, max=MAX_FIELDS, step=1, step_type=\"int\"),\n        ),\n        MessageTextInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"Key that identifies the field to be used as the text content.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"text_key_validator\",\n            display_name=\"Text Key Validator\",\n            advanced=True,\n            info=\"If enabled, checks if the given 'Text Key' is present in the given 'Data'.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"build_data\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"number_of_fields\":\n            default_keys = [\"code\", \"_type\", \"number_of_fields\", \"text_key\", \"text_key_validator\"]\n            try:\n                field_value_int = int(field_value)\n            except ValueError:\n                return build_config\n            existing_fields = {}\n            if field_value_int > self.MAX_FIELDS:\n                build_config[\"number_of_fields\"][\"value\"] = self.MAX_FIELDS\n                msg = (\n                    f\"Number of fields cannot exceed {self.MAX_FIELDS}. \"\n                    \"Please adjust the number of fields to be within the allowed limit.\"\n                )\n                raise ValueError(msg)\n            if len(build_config) > len(default_keys):\n                # back up the existing template fields\n                for key in build_config.copy():\n                    if key not in default_keys:\n                        existing_fields[key] = build_config.pop(key)\n\n            for i in range(1, field_value_int + 1):\n                key = f\"field_{i}_key\"\n                if key in existing_fields:\n                    field = existing_fields[key]\n                    build_config[key] = field\n                else:\n                    field = DictInput(\n                        display_name=f\"Field {i}\",\n                        name=key,\n                        info=f\"Key for field {i}.\",\n                        input_types=[\"Message\", \"Data\"],\n                    )\n                    build_config[field.name] = field.to_dict()\n\n            build_config[\"number_of_fields\"][\"value\"] = field_value_int\n        return build_config\n\n    async def build_data(self) -> Data:\n        data = self.get_data()\n        return_data = Data(data=data, text_key=self.text_key)\n        self.status = return_data\n        if self.text_key_validator:\n            self.validate_text_key()\n        return return_data\n\n    def get_data(self):\n        \"\"\"Function to get the Data from the attributes.\"\"\"\n        data = {}\n        for value_dict in self._attributes.values():\n            if isinstance(value_dict, dict):\n                # Check if the value of the value_dict is a Data\n                value_dict_ = {\n                    key: value.get_text() if isinstance(value, Data) else value for key, value in value_dict.items()\n                }\n                data.update(value_dict_)\n        return data\n\n    def validate_text_key(self) -> None:\n        \"\"\"This function validates that the Text Key is one of the keys in the Data.\"\"\"\n        data_keys = self.get_data().keys()\n        if self.text_key not in data_keys and self.text_key != \"\":\n            formatted_data_keys = \", \".join(data_keys)\n            msg = f\"Text Key: '{self.text_key}' not found in the Data keys: '{formatted_data_keys}'\"\n            raise ValueError(msg)\n"},"number_of_fields":{"_input_type":"IntInput","advanced":false,"display_name":"Number of Fields","dynamic":false,"info":"Number of fields to be added to the record.","list":false,"list_add_label":"Add More","name":"number_of_fields","placeholder":"","range_spec":{"max":15.0,"min":1.0,"step":1.0,"step_type":"int"},"real_time_refresh":true,"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1},"text_key":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Text Key","dynamic":false,"info":"Key that identifies the field to be used as the text content.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"text_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"text_key_validator":{"_input_type":"BoolInput","advanced":true,"display_name":"Text Key Validator","dynamic":false,"info":"If enabled, checks if the given 'Text Key' is present in the given 'Data'.","list":false,"list_add_label":"Add More","name":"text_key_validator","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false},"DataFrameOperations":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Perform various operations on a DataFrame.","display_name":"DataFrame Operations","documentation":"https://docs.langflow.org/components-processing#dataframe-operations","edited":false,"field_order":["df","operation","column_name","filter_value","filter_operator","ascending","new_column_name","new_column_value","columns_to_select","num_rows","replace_value","replacement_value"],"frozen":false,"icon":"table","legacy":false,"metadata":{"code_hash":"b4d6b19b6eef","dependencies":{"dependencies":[{"name":"pandas","version":"2.2.3"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.processing.dataframe_operations.DataFrameOperationsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"perform_operation","name":"output","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","ascending":{"_input_type":"BoolInput","advanced":false,"display_name":"Sort Ascending","dynamic":true,"info":"Whether to sort in ascending order.","list":false,"list_add_label":"Add More","name":"ascending","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import pandas as pd\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs import SortableListInput\nfrom lfx.io import BoolInput, DataFrameInput, DropdownInput, IntInput, MessageTextInput, Output, StrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.dataframe import DataFrame\n\n\nclass DataFrameOperationsComponent(Component):\n    display_name = \"DataFrame Operations\"\n    description = \"Perform various operations on a DataFrame.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#dataframe-operations\"\n    icon = \"table\"\n    name = \"DataFrameOperations\"\n\n    OPERATION_CHOICES = [\n        \"Add Column\",\n        \"Drop Column\",\n        \"Filter\",\n        \"Head\",\n        \"Rename Column\",\n        \"Replace Value\",\n        \"Select Columns\",\n        \"Sort\",\n        \"Tail\",\n        \"Drop Duplicates\",\n    ]\n\n    inputs = [\n        DataFrameInput(\n            name=\"df\",\n            display_name=\"DataFrame\",\n            info=\"The input DataFrame to operate on.\",\n            required=True,\n        ),\n        SortableListInput(\n            name=\"operation\",\n            display_name=\"Operation\",\n            placeholder=\"Select Operation\",\n            info=\"Select the DataFrame operation to perform.\",\n            options=[\n                {\"name\": \"Add Column\", \"icon\": \"plus\"},\n                {\"name\": \"Drop Column\", \"icon\": \"minus\"},\n                {\"name\": \"Filter\", \"icon\": \"filter\"},\n                {\"name\": \"Head\", \"icon\": \"arrow-up\"},\n                {\"name\": \"Rename Column\", \"icon\": \"pencil\"},\n                {\"name\": \"Replace Value\", \"icon\": \"replace\"},\n                {\"name\": \"Select Columns\", \"icon\": \"columns\"},\n                {\"name\": \"Sort\", \"icon\": \"arrow-up-down\"},\n                {\"name\": \"Tail\", \"icon\": \"arrow-down\"},\n                {\"name\": \"Drop Duplicates\", \"icon\": \"copy-x\"},\n            ],\n            real_time_refresh=True,\n            limit=1,\n        ),\n        StrInput(\n            name=\"column_name\",\n            display_name=\"Column Name\",\n            info=\"The column name to use for the operation.\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"filter_value\",\n            display_name=\"Filter Value\",\n            info=\"The value to filter rows by.\",\n            dynamic=True,\n            show=False,\n        ),\n        DropdownInput(\n            name=\"filter_operator\",\n            display_name=\"Filter Operator\",\n            options=[\n                \"equals\",\n                \"not equals\",\n                \"contains\",\n                \"not contains\",\n                \"starts with\",\n                \"ends with\",\n                \"greater than\",\n                \"less than\",\n            ],\n            value=\"equals\",\n            info=\"The operator to apply for filtering rows.\",\n            advanced=False,\n            dynamic=True,\n            show=False,\n        ),\n        BoolInput(\n            name=\"ascending\",\n            display_name=\"Sort Ascending\",\n            info=\"Whether to sort in ascending order.\",\n            dynamic=True,\n            show=False,\n            value=True,\n        ),\n        StrInput(\n            name=\"new_column_name\",\n            display_name=\"New Column Name\",\n            info=\"The new column name when renaming or adding a column.\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"new_column_value\",\n            display_name=\"New Column Value\",\n            info=\"The value to populate the new column with.\",\n            dynamic=True,\n            show=False,\n        ),\n        StrInput(\n            name=\"columns_to_select\",\n            display_name=\"Columns to Select\",\n            dynamic=True,\n            is_list=True,\n            show=False,\n        ),\n        IntInput(\n            name=\"num_rows\",\n            display_name=\"Number of Rows\",\n            info=\"Number of rows to return (for head/tail).\",\n            dynamic=True,\n            show=False,\n            value=5,\n        ),\n        MessageTextInput(\n            name=\"replace_value\",\n            display_name=\"Value to Replace\",\n            info=\"The value to replace in the column.\",\n            dynamic=True,\n            show=False,\n        ),\n        MessageTextInput(\n            name=\"replacement_value\",\n            display_name=\"Replacement Value\",\n            info=\"The value to replace with.\",\n            dynamic=True,\n            show=False,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"DataFrame\",\n            name=\"output\",\n            method=\"perform_operation\",\n            info=\"The resulting DataFrame after the operation.\",\n        )\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        dynamic_fields = [\n            \"column_name\",\n            \"filter_value\",\n            \"filter_operator\",\n            \"ascending\",\n            \"new_column_name\",\n            \"new_column_value\",\n            \"columns_to_select\",\n            \"num_rows\",\n            \"replace_value\",\n            \"replacement_value\",\n        ]\n        for field in dynamic_fields:\n            build_config[field][\"show\"] = False\n\n        if field_name == \"operation\":\n            # Handle SortableListInput format\n            if isinstance(field_value, list):\n                operation_name = field_value[0].get(\"name\", \"\") if field_value else \"\"\n            else:\n                operation_name = field_value or \"\"\n\n            # If no operation selected, all dynamic fields stay hidden (already set to False above)\n            if not operation_name:\n                return build_config\n\n            if operation_name == \"Filter\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"filter_value\"][\"show\"] = True\n                build_config[\"filter_operator\"][\"show\"] = True\n            elif operation_name == \"Sort\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"ascending\"][\"show\"] = True\n            elif operation_name == \"Drop Column\":\n                build_config[\"column_name\"][\"show\"] = True\n            elif operation_name == \"Rename Column\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"new_column_name\"][\"show\"] = True\n            elif operation_name == \"Add Column\":\n                build_config[\"new_column_name\"][\"show\"] = True\n                build_config[\"new_column_value\"][\"show\"] = True\n            elif operation_name == \"Select Columns\":\n                build_config[\"columns_to_select\"][\"show\"] = True\n            elif operation_name in {\"Head\", \"Tail\"}:\n                build_config[\"num_rows\"][\"show\"] = True\n            elif operation_name == \"Replace Value\":\n                build_config[\"column_name\"][\"show\"] = True\n                build_config[\"replace_value\"][\"show\"] = True\n                build_config[\"replacement_value\"][\"show\"] = True\n            elif operation_name == \"Drop Duplicates\":\n                build_config[\"column_name\"][\"show\"] = True\n\n        return build_config\n\n    def perform_operation(self) -> DataFrame:\n        df_copy = self.df.copy()\n\n        # Handle SortableListInput format for operation\n        operation_input = getattr(self, \"operation\", [])\n        if isinstance(operation_input, list) and len(operation_input) > 0:\n            op = operation_input[0].get(\"name\", \"\")\n        else:\n            op = \"\"\n\n        # If no operation selected, return original DataFrame\n        if not op:\n            return df_copy\n\n        if op == \"Filter\":\n            return self.filter_rows_by_value(df_copy)\n        if op == \"Sort\":\n            return self.sort_by_column(df_copy)\n        if op == \"Drop Column\":\n            return self.drop_column(df_copy)\n        if op == \"Rename Column\":\n            return self.rename_column(df_copy)\n        if op == \"Add Column\":\n            return self.add_column(df_copy)\n        if op == \"Select Columns\":\n            return self.select_columns(df_copy)\n        if op == \"Head\":\n            return self.head(df_copy)\n        if op == \"Tail\":\n            return self.tail(df_copy)\n        if op == \"Replace Value\":\n            return self.replace_values(df_copy)\n        if op == \"Drop Duplicates\":\n            return self.drop_duplicates(df_copy)\n        msg = f\"Unsupported operation: {op}\"\n        logger.error(msg)\n        raise ValueError(msg)\n\n    def filter_rows_by_value(self, df: DataFrame) -> DataFrame:\n        column = df[self.column_name]\n        filter_value = self.filter_value\n\n        # Handle regular DropdownInput format (just a string value)\n        operator = getattr(self, \"filter_operator\", \"equals\")  # Default to equals for backward compatibility\n\n        if operator == \"equals\":\n            mask = column == filter_value\n        elif operator == \"not equals\":\n            mask = column != filter_value\n        elif operator == \"contains\":\n            mask = column.astype(str).str.contains(str(filter_value), na=False)\n        elif operator == \"not contains\":\n            mask = ~column.astype(str).str.contains(str(filter_value), na=False)\n        elif operator == \"starts with\":\n            mask = column.astype(str).str.startswith(str(filter_value), na=False)\n        elif operator == \"ends with\":\n            mask = column.astype(str).str.endswith(str(filter_value), na=False)\n        elif operator == \"greater than\":\n            try:\n                # Try to convert filter_value to numeric for comparison\n                numeric_value = pd.to_numeric(filter_value)\n                mask = column > numeric_value\n            except (ValueError, TypeError):\n                # If conversion fails, compare as strings\n                mask = column.astype(str) > str(filter_value)\n        elif operator == \"less than\":\n            try:\n                # Try to convert filter_value to numeric for comparison\n                numeric_value = pd.to_numeric(filter_value)\n                mask = column < numeric_value\n            except (ValueError, TypeError):\n                # If conversion fails, compare as strings\n                mask = column.astype(str) < str(filter_value)\n        else:\n            mask = column == filter_value  # Fallback to equals\n\n        return DataFrame(df[mask])\n\n    def sort_by_column(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.sort_values(by=self.column_name, ascending=self.ascending))\n\n    def drop_column(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.drop(columns=[self.column_name]))\n\n    def rename_column(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.rename(columns={self.column_name: self.new_column_name}))\n\n    def add_column(self, df: DataFrame) -> DataFrame:\n        df[self.new_column_name] = [self.new_column_value] * len(df)\n        return DataFrame(df)\n\n    def select_columns(self, df: DataFrame) -> DataFrame:\n        columns = [col.strip() for col in self.columns_to_select]\n        return DataFrame(df[columns])\n\n    def head(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.head(self.num_rows))\n\n    def tail(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.tail(self.num_rows))\n\n    def replace_values(self, df: DataFrame) -> DataFrame:\n        df[self.column_name] = df[self.column_name].replace(self.replace_value, self.replacement_value)\n        return DataFrame(df)\n\n    def drop_duplicates(self, df: DataFrame) -> DataFrame:\n        return DataFrame(df.drop_duplicates(subset=self.column_name))\n"},"column_name":{"_input_type":"StrInput","advanced":false,"display_name":"Column Name","dynamic":true,"info":"The column name to use for the operation.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"column_name","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"columns_to_select":{"_input_type":"StrInput","advanced":false,"display_name":"Columns to Select","dynamic":true,"info":"","list":true,"list_add_label":"Add More","load_from_db":false,"name":"columns_to_select","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"df":{"_input_type":"DataFrameInput","advanced":false,"display_name":"DataFrame","dynamic":false,"info":"The input DataFrame to operate on.","input_types":["DataFrame"],"list":false,"list_add_label":"Add More","name":"df","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"filter_operator":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Filter Operator","dynamic":true,"external_options":{},"info":"The operator to apply for filtering rows.","name":"filter_operator","options":["equals","not equals","contains","not contains","starts with","ends with","greater than","less than"],"options_metadata":[],"placeholder":"","required":false,"show":false,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"equals"},"filter_value":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Filter Value","dynamic":true,"info":"The value to filter rows by.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"filter_value","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"new_column_name":{"_input_type":"StrInput","advanced":false,"display_name":"New Column Name","dynamic":true,"info":"The new column name when renaming or adding a column.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"new_column_name","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"new_column_value":{"_input_type":"MessageTextInput","advanced":false,"display_name":"New Column Value","dynamic":true,"info":"The value to populate the new column with.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"new_column_value","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"num_rows":{"_input_type":"IntInput","advanced":false,"display_name":"Number of Rows","dynamic":true,"info":"Number of rows to return (for head/tail).","list":false,"list_add_label":"Add More","name":"num_rows","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5},"operation":{"_input_type":"SortableListInput","advanced":false,"display_name":"Operation","dynamic":false,"info":"Select the DataFrame operation to perform.","limit":1,"name":"operation","options":[{"icon":"plus","name":"Add Column"},{"icon":"minus","name":"Drop Column"},{"icon":"filter","name":"Filter"},{"icon":"arrow-up","name":"Head"},{"icon":"pencil","name":"Rename Column"},{"icon":"replace","name":"Replace Value"},{"icon":"columns","name":"Select Columns"},{"icon":"arrow-up-down","name":"Sort"},{"icon":"arrow-down","name":"Tail"},{"icon":"copy-x","name":"Drop Duplicates"}],"placeholder":"Select Operation","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":""},"replace_value":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Value to Replace","dynamic":true,"info":"The value to replace in the column.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"replace_value","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"replacement_value":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Replacement Value","dynamic":true,"info":"The value to replace with.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"replacement_value","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"DataFrameToToolset":{"base_classes":["Message","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Convert each row of a DataFrame into a callable tool/action in a toolset.","display_name":"DataFrame to Toolset","documentation":"","edited":false,"field_order":["dataframe","tool_name_column","tool_output_column"],"frozen":false,"icon":"wrench","legacy":false,"metadata":{"code_hash":"8e75ddcce3eb","dependencies":{"dependencies":[{"name":"langchain","version":"0.3.23"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.processing.dataframe_to_toolset.DataFrameToToolsetComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Tools","group_outputs":false,"method":"build_tools","name":"tools","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Message","group_outputs":false,"method":"get_message","name":"message","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"\"\"\"DataFrame to Toolset Component.\n\nThis component converts each row of a DataFrame into a callable tool/action within a toolset.\nEach row becomes a tool where the action name comes from one column and the content/response\ncomes from another column.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport re\nfrom typing import TYPE_CHECKING\n\nfrom langchain.tools import StructuredTool\nfrom pydantic import BaseModel, create_model\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.field_typing.constants import Tool\nfrom lfx.io import HandleInput, Output, StrInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.message import Message\n\nif TYPE_CHECKING:\n    from lfx.field_typing.constants import Tool\n\n\nclass DataFrameToToolsetComponent(LCToolComponent):\n    \"\"\"Component that converts DataFrame rows into a toolset with multiple callable actions.\"\"\"\n\n    display_name = \"DataFrame to Toolset\"\n    description = \"Convert each row of a DataFrame into a callable tool/action in a toolset.\"\n    icon = \"wrench\"\n    name = \"DataFrameToToolset\"\n\n    inputs = [\n        HandleInput(\n            name=\"dataframe\",\n            display_name=\"DataFrame\",\n            input_types=[\"DataFrame\"],\n            info=\"DataFrame where each row will become a tool/action\",\n            required=True,\n        ),\n        StrInput(\n            name=\"tool_name_column\",\n            display_name=\"Tool Name Column\",\n            info=\"Column with tool names\",\n            required=True,\n        ),\n        StrInput(\n            name=\"tool_output_column\",\n            display_name=\"Tool Output Column\",\n            info=\"Column with tool outputs/responses\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Tools\", name=\"tools\", method=\"build_tools\"),\n        Output(display_name=\"Message\", name=\"message\", method=\"get_message\"),\n    ]\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self._tools_cache: list[Tool] = []\n        self._action_data: dict[str, dict[str, str]] = {}\n\n    def _sanitize_tool_name(self, name: str) -> str:\n        \"\"\"Sanitize tool name to match required format '^[a-zA-Z0-9_-]+$'.\"\"\"\n        # Replace any non-alphanumeric characters (except _ and -) with underscores\n        sanitized = re.sub(r\"[^a-zA-Z0-9_-]\", \"_\", str(name))\n        # Ensure it starts with a letter or underscore\n        if sanitized and not sanitized[0].isalpha() and sanitized[0] != \"_\":\n            sanitized = f\"tool_{sanitized}\"\n        return sanitized or \"unnamed_tool\"\n\n    def _prepare_action_data(self) -> None:\n        \"\"\"Prepare action data from DataFrame.\"\"\"\n        # Check if dataframe exists and is valid\n        if not hasattr(self, \"dataframe\") or self.dataframe is None:\n            self._action_data = {}\n            return\n\n        if not isinstance(self.dataframe, DataFrame):\n            self._action_data = {}\n            return\n\n        if not hasattr(self.dataframe, \"columns\"):\n            self._action_data = {}\n            return\n\n        # Check if column names are provided\n        if not self.tool_name_column or not self.tool_output_column:\n            self._action_data = {}\n            return\n\n        if self.tool_name_column not in self.dataframe.columns:\n            msg = (\n                f\"Tool name column '{self.tool_name_column}' not found in DataFrame columns: \"\n                f\"{list(self.dataframe.columns)}\"\n            )\n            raise ValueError(msg)\n\n        if self.tool_output_column not in self.dataframe.columns:\n            msg = (\n                f\"Tool output column '{self.tool_output_column}' not found in DataFrame columns: \"\n                f\"{list(self.dataframe.columns)}\"\n            )\n            raise ValueError(msg)\n\n        # Clear previous data\n        self._action_data = {}\n\n        # Process each row to create action mappings\n        for _, row in self.dataframe.iterrows():\n            action_name = str(row[self.tool_name_column]).strip()\n            content = str(row[self.tool_output_column]).strip()\n\n            if action_name and content:\n                sanitized_name = self._sanitize_tool_name(action_name)\n                self._action_data[sanitized_name] = {\n                    \"original_name\": action_name,\n                    \"content\": content,\n                    \"sanitized_name\": sanitized_name,\n                }\n\n    def _create_action_function(self, action_name: str, content: str):\n        \"\"\"Create a function for a specific action that returns the content.\"\"\"\n\n        def action_function(**kwargs) -> str:\n            # You could extend this to use kwargs to modify the content\n            # For now, just return the stored content\n            self.log(kwargs)  # TODO: Coming soon: implement arguments to modify content\n            return content\n\n        action_function.__name__ = f\"execute_{action_name}\"\n        action_function.__doc__ = f\"Execute {action_name} action and return the associated content.\"\n        return action_function\n\n    def build_tools(self) -> list[Tool]:\n        \"\"\"Build the toolset from DataFrame data.\"\"\"\n        # Handle case where inputs are not ready\n        if not hasattr(self, \"dataframe\") or self.dataframe is None:\n            return []\n\n        self._prepare_action_data()\n\n        if not self._action_data:\n            return []\n\n        tools_description_preview_length = 100\n        tools_description_content_length = 200\n\n        tools = []\n\n        for sanitized_name, action_info in self._action_data.items():\n            original_name = action_info[\"original_name\"]\n            content = action_info[\"content\"]\n\n            # Create a simple schema for this tool (no parameters needed)\n            # But we could extend this to accept parameters if needed\n            tool_schema = create_model(\n                f\"{sanitized_name}Schema\",\n                __base__=BaseModel,\n                # Add parameters here if you want the tools to accept inputs\n                # For now, keeping it simple with no parameters\n            )\n\n            # Create the tool function\n            tool_function = self._create_action_function(sanitized_name, content)\n\n            # Create the StructuredTool\n            tool = StructuredTool(\n                name=sanitized_name,\n                description=(\n                    f\"Execute {original_name} action. Returns: \"\n                    f\"{content[:tools_description_preview_length]}\"\n                    f\"{'...' if len(content) > tools_description_preview_length else ''}\"\n                ),\n                func=tool_function,\n                args_schema=tool_schema,\n                handle_tool_error=True,\n                tags=[sanitized_name],\n                metadata={\n                    \"display_name\": original_name,\n                    \"display_description\": f\"Action: {original_name}\",\n                    \"original_name\": original_name,\n                    \"content_preview\": content[:tools_description_content_length],\n                },\n            )\n\n            tools.append(tool)\n\n        self._tools_cache = tools\n        return tools\n\n    def build_tool(self) -> Tool:\n        \"\"\"Build a single tool (for compatibility with LCToolComponent).\"\"\"\n        tools = self.build_tools()\n        if not tools:\n            # Return a placeholder tool when no data is available\n            def placeholder_function(**kwargs) -> str:\n                self.log(kwargs)  # TODO: Coming soon: implement arguments to modify content\n                return \"No tools available. Please connect a DataFrame with appropriate columns.\"\n\n            return StructuredTool(\n                name=\"placeholder_tool\",\n                description=\"Placeholder tool - waiting for DataFrame input\",\n                func=placeholder_function,\n                args_schema=create_model(\"PlaceholderSchema\", __base__=BaseModel),\n            )\n\n        # Return the first tool, or create a composite tool\n        return tools[0]\n\n    def get_message(self) -> Message:\n        \"\"\"Get a message describing the created toolset.\"\"\"\n        # Handle case where inputs are not ready\n        if not hasattr(self, \"dataframe\") or self.dataframe is None:\n            return Message(text=\"Waiting for DataFrame input...\")\n\n        self._prepare_action_data()\n\n        if not self._action_data:\n            return Message(text=\"No tools were created. Please check your DataFrame and column selections.\")\n\n        tool_count = len(self._action_data)\n        tool_names = [info[\"original_name\"] for info in self._action_data.values()]\n\n        message_text = f\"Created toolset with {tool_count} tools:\\n\"\n        for i, name in enumerate(tool_names, 1):\n            message_text += f\"{i}. {name}\\n\"\n\n        return Message(text=message_text)\n\n    def run_model(self) -> list[Data]:\n        \"\"\"Run the model and return tool information as Data objects.\"\"\"\n        # Handle case where inputs are not ready\n        if not hasattr(self, \"dataframe\") or self.dataframe is None:\n            return [Data(data={\"status\": \"Waiting for DataFrame input\"})]\n\n        tools = self.build_tools()\n\n        if not tools:\n            return [Data(data={\"status\": \"No tools created. Check DataFrame and column selections.\"})]\n\n        results = []\n        for tool in tools:\n            tool_data = {\n                \"tool_name\": tool.name,\n                \"display_name\": tool.metadata.get(\"display_name\", tool.name)\n                if hasattr(tool, \"metadata\")\n                else tool.name,\n                \"description\": tool.description,\n                \"original_name\": tool.metadata.get(\"original_name\", \"\") if hasattr(tool, \"metadata\") else \"\",\n                \"content_preview\": tool.metadata.get(\"content_preview\", \"\") if hasattr(tool, \"metadata\") else \"\",\n            }\n            results.append(Data(data=tool_data))\n\n        return results\n"},"dataframe":{"_input_type":"HandleInput","advanced":false,"display_name":"DataFrame","dynamic":false,"info":"DataFrame where each row will become a tool/action","input_types":["DataFrame"],"list":false,"list_add_label":"Add More","name":"dataframe","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"tool_name_column":{"_input_type":"StrInput","advanced":false,"display_name":"Tool Name Column","dynamic":false,"info":"Column with tool names","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tool_name_column","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tool_output_column":{"_input_type":"StrInput","advanced":false,"display_name":"Tool Output Column","dynamic":false,"info":"Column with tool outputs/responses","list":false,"list_add_label":"Add More","load_from_db":false,"name":"tool_output_column","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"DataOperations":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Perform various operations on a Data object.","display_name":"Data Operations","documentation":"","edited":false,"field_order":["data","operations","select_keys_input","filter_key","operator","filter_values","append_update_data","remove_keys_input","rename_keys_input","mapped_json_display","selected_key","query"],"frozen":false,"icon":"file-json","legacy":false,"metadata":{"code_hash":"f5d9680f8644","dependencies":{"dependencies":[{"name":"jq","version":"1.8.0"},{"name":"json_repair","version":"0.30.3"},{"name":"lfx","version":null}],"total_dependencies":3},"keywords":["data","operations","filter values","Append or Update","remove keys","rename keys","select keys","literal eval","combine","filter","append","update","remove","rename","data operations","data manipulation","data transformation","data filtering","data selection","data combination","Parse JSON","JSON Query","JQ Query"],"module":"lfx.components.processing.data_operations.DataOperationsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"as_data","name":"data_output","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","append_update_data":{"_input_type":"DictInput","advanced":false,"display_name":"Append or Update","dynamic":false,"info":"Data to append or update the existing data with. Only top-level keys are checked.","list":true,"list_add_label":"Add More","name":"append_update_data","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{"key":"value"}},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import ast\nimport json\nfrom typing import TYPE_CHECKING, Any\n\nimport jq\nfrom json_repair import repair_json\n\nfrom lfx.custom import Component\nfrom lfx.inputs import DictInput, DropdownInput, MessageTextInput, SortableListInput\nfrom lfx.io import DataInput, MultilineInput, Output\nfrom lfx.log.logger import logger\nfrom lfx.schema import Data\nfrom lfx.schema.dotdict import dotdict\nfrom lfx.utils.component_utils import set_current_fields, set_field_display\n\nif TYPE_CHECKING:\n    from collections.abc import Callable\n\nACTION_CONFIG = {\n    \"Select Keys\": {\"is_list\": False, \"log_msg\": \"setting filter fields\"},\n    \"Literal Eval\": {\"is_list\": False, \"log_msg\": \"setting evaluate fields\"},\n    \"Combine\": {\"is_list\": True, \"log_msg\": \"setting combine fields\"},\n    \"Filter Values\": {\"is_list\": False, \"log_msg\": \"setting filter values fields\"},\n    \"Append or Update\": {\"is_list\": False, \"log_msg\": \"setting Append or Update fields\"},\n    \"Remove Keys\": {\"is_list\": False, \"log_msg\": \"setting remove keys fields\"},\n    \"Rename Keys\": {\"is_list\": False, \"log_msg\": \"setting rename keys fields\"},\n    \"Path Selection\": {\"is_list\": False, \"log_msg\": \"setting mapped key extractor fields\"},\n    \"JQ Expression\": {\"is_list\": False, \"log_msg\": \"setting parse json fields\"},\n}\nOPERATORS = {\n    \"equals\": lambda a, b: str(a) == str(b),\n    \"not equals\": lambda a, b: str(a) != str(b),\n    \"contains\": lambda a, b: str(b) in str(a),\n    \"starts with\": lambda a, b: str(a).startswith(str(b)),\n    \"ends with\": lambda a, b: str(a).endswith(str(b)),\n}\n\n\nclass DataOperationsComponent(Component):\n    display_name = \"Data Operations\"\n    description = \"Perform various operations on a Data object.\"\n    icon = \"file-json\"\n    name = \"DataOperations\"\n    default_keys = [\"operations\", \"data\"]\n    metadata = {\n        \"keywords\": [\n            \"data\",\n            \"operations\",\n            \"filter values\",\n            \"Append or Update\",\n            \"remove keys\",\n            \"rename keys\",\n            \"select keys\",\n            \"literal eval\",\n            \"combine\",\n            \"filter\",\n            \"append\",\n            \"update\",\n            \"remove\",\n            \"rename\",\n            \"data operations\",\n            \"data manipulation\",\n            \"data transformation\",\n            \"data filtering\",\n            \"data selection\",\n            \"data combination\",\n            \"Parse JSON\",\n            \"JSON Query\",\n            \"JQ Query\",\n        ],\n    }\n    actions_data = {\n        \"Select Keys\": [\"select_keys_input\", \"operations\"],\n        \"Literal Eval\": [],\n        \"Combine\": [],\n        \"Filter Values\": [\"filter_values\", \"operations\", \"operator\", \"filter_key\"],\n        \"Append or Update\": [\"append_update_data\", \"operations\"],\n        \"Remove Keys\": [\"remove_keys_input\", \"operations\"],\n        \"Rename Keys\": [\"rename_keys_input\", \"operations\"],\n        \"Path Selection\": [\"mapped_json_display\", \"selected_key\", \"operations\"],\n        \"JQ Expression\": [\"query\", \"operations\"],\n    }\n\n    @staticmethod\n    def extract_all_paths(obj, path=\"\"):\n        paths = []\n        if isinstance(obj, dict):\n            for k, v in obj.items():\n                new_path = f\"{path}.{k}\" if path else f\".{k}\"\n                paths.append(new_path)\n                paths.extend(DataOperationsComponent.extract_all_paths(v, new_path))\n        elif isinstance(obj, list) and obj:\n            new_path = f\"{path}[0]\"\n            paths.append(new_path)\n            paths.extend(DataOperationsComponent.extract_all_paths(obj[0], new_path))\n        return paths\n\n    @staticmethod\n    def remove_keys_recursive(obj, keys_to_remove):\n        if isinstance(obj, dict):\n            return {\n                k: DataOperationsComponent.remove_keys_recursive(v, keys_to_remove)\n                for k, v in obj.items()\n                if k not in keys_to_remove\n            }\n        if isinstance(obj, list):\n            return [DataOperationsComponent.remove_keys_recursive(item, keys_to_remove) for item in obj]\n        return obj\n\n    @staticmethod\n    def rename_keys_recursive(obj, rename_map):\n        if isinstance(obj, dict):\n            return {\n                rename_map.get(k, k): DataOperationsComponent.rename_keys_recursive(v, rename_map)\n                for k, v in obj.items()\n            }\n        if isinstance(obj, list):\n            return [DataOperationsComponent.rename_keys_recursive(item, rename_map) for item in obj]\n        return obj\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"Data object to filter.\", required=True, is_list=True),\n        SortableListInput(\n            name=\"operations\",\n            display_name=\"Operations\",\n            placeholder=\"Select Operation\",\n            info=\"List of operations to perform on the data.\",\n            options=[\n                {\"name\": \"Select Keys\", \"icon\": \"lasso-select\"},\n                {\"name\": \"Literal Eval\", \"icon\": \"braces\"},\n                {\"name\": \"Combine\", \"icon\": \"merge\"},\n                {\"name\": \"Filter Values\", \"icon\": \"filter\"},\n                {\"name\": \"Append or Update\", \"icon\": \"circle-plus\"},\n                {\"name\": \"Remove Keys\", \"icon\": \"eraser\"},\n                {\"name\": \"Rename Keys\", \"icon\": \"pencil-line\"},\n                {\"name\": \"Path Selection\", \"icon\": \"mouse-pointer\"},\n                {\"name\": \"JQ Expression\", \"icon\": \"terminal\"},\n            ],\n            real_time_refresh=True,\n            limit=1,\n        ),\n        # select keys inputs\n        MessageTextInput(\n            name=\"select_keys_input\",\n            display_name=\"Select Keys\",\n            info=\"List of keys to select from the data. Only top-level keys can be selected.\",\n            show=False,\n            is_list=True,\n        ),\n        # filter values inputs\n        MessageTextInput(\n            name=\"filter_key\",\n            display_name=\"Filter Key\",\n            info=(\n                \"Name of the key containing the list to filter. \"\n                \"It must be a top-level key in the JSON and its value must be a list.\"\n            ),\n            is_list=True,\n            show=False,\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Comparison Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\"],\n            info=\"The operator to apply for comparing the values.\",\n            value=\"equals\",\n            advanced=False,\n            show=False,\n        ),\n        DictInput(\n            name=\"filter_values\",\n            display_name=\"Filter Values\",\n            info=\"List of values to filter by.\",\n            show=False,\n            is_list=True,\n        ),\n        # update/ Append data inputs\n        DictInput(\n            name=\"append_update_data\",\n            display_name=\"Append or Update\",\n            info=\"Data to append or update the existing data with. Only top-level keys are checked.\",\n            show=False,\n            value={\"key\": \"value\"},\n            is_list=True,\n        ),\n        # remove keys inputs\n        MessageTextInput(\n            name=\"remove_keys_input\",\n            display_name=\"Remove Keys\",\n            info=\"List of keys to remove from the data.\",\n            show=False,\n            is_list=True,\n        ),\n        # rename keys inputs\n        DictInput(\n            name=\"rename_keys_input\",\n            display_name=\"Rename Keys\",\n            info=\"List of keys to rename in the data.\",\n            show=False,\n            is_list=True,\n            value={\"old_key\": \"new_key\"},\n        ),\n        MultilineInput(\n            name=\"mapped_json_display\",\n            display_name=\"JSON to Map\",\n            info=\"Paste or preview your JSON here to explore its structure and select a path for extraction.\",\n            required=False,\n            refresh_button=True,\n            real_time_refresh=True,\n            placeholder=\"Add a JSON example.\",\n            show=False,\n        ),\n        DropdownInput(\n            name=\"selected_key\", display_name=\"Select Path\", options=[], required=False, dynamic=True, show=False\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"JQ Expression\",\n            info=\"JSON Query to filter the data. Used by Parse JSON operation.\",\n            placeholder=\"e.g., .properties.id\",\n            show=False,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Data\", name=\"data_output\", method=\"as_data\"),\n    ]\n\n    # Helper methods for data operations\n    def get_data_dict(self) -> dict:\n        \"\"\"Extract data dictionary from Data object.\"\"\"\n        data = self.data[0] if isinstance(self.data, list) and len(self.data) == 1 else self.data\n        return data.model_dump()\n\n    def json_query(self) -> Data:\n        import json\n\n        import jq\n\n        if not self.query or not self.query.strip():\n            msg = \"JSON Query is required and cannot be blank.\"\n            raise ValueError(msg)\n        raw_data = self.get_data_dict()\n        try:\n            input_str = json.dumps(raw_data)\n            repaired = repair_json(input_str)\n            data_json = json.loads(repaired)\n            jq_input = data_json[\"data\"] if isinstance(data_json, dict) and \"data\" in data_json else data_json\n            results = jq.compile(self.query).input(jq_input).all()\n            if not results:\n                msg = \"No result from JSON query.\"\n                raise ValueError(msg)\n            result = results[0] if len(results) == 1 else results\n            if result is None or result == \"None\":\n                msg = \"JSON query returned null/None. Check if the path exists in your data.\"\n                raise ValueError(msg)\n            if isinstance(result, dict):\n                return Data(data=result)\n            return Data(data={\"result\": result})\n        except (ValueError, TypeError, KeyError, json.JSONDecodeError) as e:\n            logger.error(f\"JSON Query failed: {e}\")\n            msg = f\"JSON Query error: {e}\"\n            raise ValueError(msg) from e\n\n    def get_normalized_data(self) -> dict:\n        \"\"\"Get normalized data dictionary, handling the 'data' key if present.\"\"\"\n        data_dict = self.get_data_dict()\n        return data_dict.get(\"data\", data_dict)\n\n    def data_is_list(self) -> bool:\n        \"\"\"Check if data contains multiple items.\"\"\"\n        return isinstance(self.data, list) and len(self.data) > 1\n\n    def validate_single_data(self, operation: str) -> None:\n        \"\"\"Validate that the operation is being performed on a single data object.\"\"\"\n        if self.data_is_list():\n            msg = f\"{operation} operation is not supported for multiple data objects.\"\n            raise ValueError(msg)\n\n    def operation_exception(self, operations: list[str]) -> None:\n        \"\"\"Raise exception for incompatible operations.\"\"\"\n        msg = f\"{operations} operations are not supported in combination with each other.\"\n        raise ValueError(msg)\n\n    # Data transformation operations\n    def select_keys(self, *, evaluate: bool | None = None) -> Data:\n        \"\"\"Select specific keys from the data dictionary.\"\"\"\n        self.validate_single_data(\"Select Keys\")\n        data_dict = self.get_normalized_data()\n        filter_criteria: list[str] = self.select_keys_input\n\n        # Filter the data\n        if len(filter_criteria) == 1 and filter_criteria[0] == \"data\":\n            filtered = data_dict[\"data\"]\n        else:\n            if not all(key in data_dict for key in filter_criteria):\n                msg = f\"Select key not found in data. Available keys: {list(data_dict.keys())}\"\n                raise ValueError(msg)\n            filtered = {key: value for key, value in data_dict.items() if key in filter_criteria}\n\n        # Create a new Data object with the filtered data\n        if evaluate:\n            filtered = self.recursive_eval(filtered)\n\n        # Return a new Data object with the filtered data directly in the data attribute\n        return Data(data=filtered)\n\n    def remove_keys(self) -> Data:\n        \"\"\"Remove specified keys from the data dictionary, recursively.\"\"\"\n        self.validate_single_data(\"Remove Keys\")\n        data_dict = self.get_normalized_data()\n        remove_keys_input: list[str] = self.remove_keys_input\n\n        filtered = DataOperationsComponent.remove_keys_recursive(data_dict, set(remove_keys_input))\n        return Data(data=filtered)\n\n    def rename_keys(self) -> Data:\n        \"\"\"Rename keys in the data dictionary, recursively.\"\"\"\n        self.validate_single_data(\"Rename Keys\")\n        data_dict = self.get_normalized_data()\n        rename_keys_input: dict[str, str] = self.rename_keys_input\n\n        renamed = DataOperationsComponent.rename_keys_recursive(data_dict, rename_keys_input)\n        return Data(data=renamed)\n\n    def recursive_eval(self, data: Any) -> Any:\n        \"\"\"Recursively evaluate string values in a dictionary or list.\n\n        If the value is a string that can be evaluated, it will be evaluated.\n        Otherwise, the original value is returned.\n        \"\"\"\n        if isinstance(data, dict):\n            return {k: self.recursive_eval(v) for k, v in data.items()}\n        if isinstance(data, list):\n            return [self.recursive_eval(item) for item in data]\n        if isinstance(data, str):\n            try:\n                # Only attempt to evaluate strings that look like Python literals\n                if (\n                    data.strip().startswith((\"{\", \"[\", \"(\", \"'\", '\"'))\n                    or data.strip().lower() in (\"true\", \"false\", \"none\")\n                    or data.strip().replace(\".\", \"\").isdigit()\n                ):\n                    return ast.literal_eval(data)\n                # return data\n            except (ValueError, SyntaxError, TypeError, MemoryError):\n                # If evaluation fails for any reason, return the original string\n                return data\n            else:\n                return data\n        return data\n\n    def evaluate_data(self) -> Data:\n        \"\"\"Evaluate string values in the data dictionary.\"\"\"\n        self.validate_single_data(\"Literal Eval\")\n        logger.info(\"evaluating data\")\n        return Data(**self.recursive_eval(self.get_data_dict()))\n\n    def combine_data(self, *, evaluate: bool | None = None) -> Data:\n        \"\"\"Combine multiple data objects into one.\"\"\"\n        logger.info(\"combining data\")\n        if not self.data_is_list():\n            return self.data[0] if self.data else Data(data={})\n\n        if len(self.data) == 1:\n            msg = \"Combine operation requires multiple data inputs.\"\n            raise ValueError(msg)\n\n        data_dicts = [data.model_dump().get(\"data\", data.model_dump()) for data in self.data]\n        combined_data = {}\n\n        for data_dict in data_dicts:\n            for key, value in data_dict.items():\n                if key not in combined_data:\n                    combined_data[key] = value\n                elif isinstance(combined_data[key], list):\n                    if isinstance(value, list):\n                        combined_data[key].extend(value)\n                    else:\n                        combined_data[key].append(value)\n                else:\n                    # If current value is not a list, convert it to list and add new value\n                    combined_data[key] = (\n                        [combined_data[key], value] if not isinstance(value, list) else [combined_data[key], *value]\n                    )\n\n        if evaluate:\n            combined_data = self.recursive_eval(combined_data)\n\n        return Data(**combined_data)\n\n    def filter_data(self, input_data: list[dict[str, Any]], filter_key: str, filter_value: str, operator: str) -> list:\n        \"\"\"Filter list data based on key, value, and operator.\"\"\"\n        # Validate inputs\n        if not input_data:\n            self.status = \"Input data is empty.\"\n            return []\n\n        if not filter_key or not filter_value:\n            self.status = \"Filter key or value is missing.\"\n            return input_data\n\n        # Filter the data\n        filtered_data = []\n        for item in input_data:\n            if isinstance(item, dict) and filter_key in item:\n                if self.compare_values(item[filter_key], filter_value, operator):\n                    filtered_data.append(item)\n            else:\n                self.status = f\"Warning: Some items don't have the key '{filter_key}' or are not dictionaries.\"\n\n        return filtered_data\n\n    def compare_values(self, item_value: Any, filter_value: str, operator: str) -> bool:\n        comparison_func = OPERATORS.get(operator)\n        if comparison_func:\n            return comparison_func(item_value, filter_value)\n        return False\n\n    def multi_filter_data(self) -> Data:\n        \"\"\"Apply multiple filters to the data.\"\"\"\n        self.validate_single_data(\"Filter Values\")\n        data_filtered = self.get_normalized_data()\n\n        for filter_key in self.filter_key:\n            if filter_key not in data_filtered:\n                msg = f\"Filter key '{filter_key}' not found in data. Available keys: {list(data_filtered.keys())}\"\n                raise ValueError(msg)\n\n            if isinstance(data_filtered[filter_key], list):\n                for filter_data in self.filter_values:\n                    filter_value = self.filter_values.get(filter_data)\n                    if filter_value is not None:\n                        data_filtered[filter_key] = self.filter_data(\n                            input_data=data_filtered[filter_key],\n                            filter_key=filter_data,\n                            filter_value=filter_value,\n                            operator=self.operator,\n                        )\n            else:\n                msg = f\"Filter key '{filter_key}' is not a list.\"\n                raise TypeError(msg)\n\n        return Data(**data_filtered)\n\n    def append_update(self) -> Data:\n        \"\"\"Append or Update with new key-value pairs.\"\"\"\n        self.validate_single_data(\"Append or Update\")\n        data_filtered = self.get_normalized_data()\n\n        for key, value in self.append_update_data.items():\n            data_filtered[key] = value\n\n        return Data(**data_filtered)\n\n    # Configuration and execution methods\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name == \"operations\":\n            build_config[\"operations\"][\"value\"] = field_value\n            selected_actions = [action[\"name\"] for action in field_value]\n            if len(selected_actions) == 1 and selected_actions[0] in ACTION_CONFIG:\n                action = selected_actions[0]\n                config = ACTION_CONFIG[action]\n                build_config[\"data\"][\"is_list\"] = config[\"is_list\"]\n                logger.info(config[\"log_msg\"])\n                return set_current_fields(\n                    build_config=build_config,\n                    action_fields=self.actions_data,\n                    selected_action=action,\n                    default_fields=[\"operations\", \"data\"],\n                    func=set_field_display,\n                )\n\n        if field_name == \"mapped_json_display\":\n            try:\n                parsed_json = json.loads(field_value)\n                keys = DataOperationsComponent.extract_all_paths(parsed_json)\n                build_config[\"selected_key\"][\"options\"] = keys\n                build_config[\"selected_key\"][\"show\"] = True\n            except (json.JSONDecodeError, TypeError, ValueError) as e:\n                logger.error(f\"Error parsing mapped JSON: {e}\")\n                build_config[\"selected_key\"][\"show\"] = False\n\n        return build_config\n\n    def json_path(self) -> Data:\n        try:\n            if not self.data or not self.selected_key:\n                msg = \"Missing input data or selected key.\"\n                raise ValueError(msg)\n            input_payload = self.data[0].data if isinstance(self.data, list) else self.data.data\n            compiled = jq.compile(self.selected_key)\n            result = compiled.input(input_payload).first()\n            if isinstance(result, dict):\n                return Data(data=result)\n            return Data(data={\"result\": result})\n        except (ValueError, TypeError, KeyError) as e:\n            self.status = f\"Error: {e!s}\"\n            self.log(self.status)\n            return Data(data={\"error\": str(e)})\n\n    def as_data(self) -> Data:\n        if not hasattr(self, \"operations\") or not self.operations:\n            return Data(data={})\n\n        selected_actions = [action[\"name\"] for action in self.operations]\n        logger.info(f\"selected_actions: {selected_actions}\")\n        if len(selected_actions) != 1:\n            return Data(data={})\n\n        action_map: dict[str, Callable[[], Data]] = {\n            \"Select Keys\": self.select_keys,\n            \"Literal Eval\": self.evaluate_data,\n            \"Combine\": self.combine_data,\n            \"Filter Values\": self.multi_filter_data,\n            \"Append or Update\": self.append_update,\n            \"Remove Keys\": self.remove_keys,\n            \"Rename Keys\": self.rename_keys,\n            \"Path Selection\": self.json_path,\n            \"JQ Expression\": self.json_query,\n        }\n        handler: Callable[[], Data] | None = action_map.get(selected_actions[0])\n        if handler:\n            try:\n                return handler()\n            except Exception as e:\n                logger.error(f\"Error executing {selected_actions[0]}: {e!s}\")\n                raise\n        return Data(data={})\n"},"data":{"_input_type":"DataInput","advanced":false,"display_name":"Data","dynamic":false,"info":"Data object to filter.","input_types":["Data"],"list":true,"list_add_label":"Add More","name":"data","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"filter_key":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Filter Key","dynamic":false,"info":"Name of the key containing the list to filter. It must be a top-level key in the JSON and its value must be a list.","input_types":["Message"],"list":true,"list_add_label":"Add More","load_from_db":false,"name":"filter_key","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"filter_values":{"_input_type":"DictInput","advanced":false,"display_name":"Filter Values","dynamic":false,"info":"List of values to filter by.","list":true,"list_add_label":"Add More","name":"filter_values","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"mapped_json_display":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"JSON to Map","dynamic":false,"info":"Paste or preview your JSON here to explore its structure and select a path for extraction.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"mapped_json_display","placeholder":"Add a JSON example.","real_time_refresh":true,"refresh_button":true,"required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"operations":{"_input_type":"SortableListInput","advanced":false,"display_name":"Operations","dynamic":false,"info":"List of operations to perform on the data.","limit":1,"name":"operations","options":[{"icon":"lasso-select","name":"Select Keys"},{"icon":"braces","name":"Literal Eval"},{"icon":"merge","name":"Combine"},{"icon":"filter","name":"Filter Values"},{"icon":"circle-plus","name":"Append or Update"},{"icon":"eraser","name":"Remove Keys"},{"icon":"pencil-line","name":"Rename Keys"},{"icon":"mouse-pointer","name":"Path Selection"},{"icon":"terminal","name":"JQ Expression"}],"placeholder":"Select Operation","real_time_refresh":true,"required":false,"search_category":[],"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"sortableList","value":""},"operator":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Comparison Operator","dynamic":false,"external_options":{},"info":"The operator to apply for comparing the values.","name":"operator","options":["equals","not equals","contains","starts with","ends with"],"options_metadata":[],"placeholder":"","required":false,"show":false,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"equals"},"query":{"_input_type":"MessageTextInput","advanced":false,"display_name":"JQ Expression","dynamic":false,"info":"JSON Query to filter the data. Used by Parse JSON operation.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"query","placeholder":"e.g., .properties.id","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"remove_keys_input":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Remove Keys","dynamic":false,"info":"List of keys to remove from the data.","input_types":["Message"],"list":true,"list_add_label":"Add More","load_from_db":false,"name":"remove_keys_input","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"rename_keys_input":{"_input_type":"DictInput","advanced":false,"display_name":"Rename Keys","dynamic":false,"info":"List of keys to rename in the data.","list":true,"list_add_label":"Add More","name":"rename_keys_input","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{"old_key":"new_key"}},"select_keys_input":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Select Keys","dynamic":false,"info":"List of keys to select from the data. Only top-level keys can be selected.","input_types":["Message"],"list":true,"list_add_label":"Add More","load_from_db":false,"name":"select_keys_input","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"selected_key":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Select Path","dynamic":true,"external_options":{},"info":"","name":"selected_key","options":[],"options_metadata":[],"placeholder":"","required":false,"show":false,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"DataToDataFrame":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Converts one or multiple Data objects into a DataFrame. Each Data object corresponds to one row. Fields from `.data` become columns, and the `.text` (if present) is placed in a 'text' column.","display_name":"Data → DataFrame","documentation":"","edited":false,"field_order":["data_list"],"frozen":false,"icon":"table","legacy":true,"metadata":{"code_hash":"57b9f79028e9","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.processing.data_to_dataframe.DataToDataFrameComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"build_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["processing.DataOperations","processing.TypeConverterComponent"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.io import DataInput, Output\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\n\n\nclass DataToDataFrameComponent(Component):\n    display_name = \"Data → DataFrame\"\n    description = (\n        \"Converts one or multiple Data objects into a DataFrame. \"\n        \"Each Data object corresponds to one row. Fields from `.data` become columns, \"\n        \"and the `.text` (if present) is placed in a 'text' column.\"\n    )\n    icon = \"table\"\n    name = \"DataToDataFrame\"\n    legacy = True\n    replacement = [\"processing.DataOperations\", \"processing.TypeConverterComponent\"]\n\n    inputs = [\n        DataInput(\n            name=\"data_list\",\n            display_name=\"Data or Data List\",\n            info=\"One or multiple Data objects to transform into a DataFrame.\",\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"DataFrame\",\n            name=\"dataframe\",\n            method=\"build_dataframe\",\n            info=\"A DataFrame built from each Data object's fields plus a 'text' column.\",\n        ),\n    ]\n\n    def build_dataframe(self) -> DataFrame:\n        \"\"\"Builds a DataFrame from Data objects by combining their fields.\n\n        For each Data object:\n          - Merge item.data (dictionary) as columns\n          - If item.text is present, add 'text' column\n\n        Returns a DataFrame with one row per Data object.\n        \"\"\"\n        data_input = self.data_list\n\n        # If user passed a single Data, it might come in as a single object rather than a list\n        if not isinstance(data_input, list):\n            data_input = [data_input]\n\n        rows = []\n        for item in data_input:\n            if not isinstance(item, Data):\n                msg = f\"Expected Data objects, got {type(item)} instead.\"\n                raise TypeError(msg)\n\n            # Start with a copy of item.data or an empty dict\n            row_dict = dict(item.data) if item.data else {}\n\n            # If the Data object has text, store it under 'text' col\n            text_val = item.get_text()\n            if text_val:\n                row_dict[\"text\"] = text_val\n\n            rows.append(row_dict)\n\n        # Build a DataFrame from these row dictionaries\n        df_result = DataFrame(rows)\n        self.status = df_result  # store in self.status for logs\n        return df_result\n"},"data_list":{"_input_type":"DataInput","advanced":false,"display_name":"Data or Data List","dynamic":false,"info":"One or multiple Data objects to transform into a DataFrame.","input_types":["Data"],"list":true,"list_add_label":"Add More","name":"data_list","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""}},"tool_mode":false},"DynamicCreateData":{"base_classes":["Data","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Dynamically create a Data with a specified number of fields.","display_name":"Dynamic Create Data","documentation":"","edited":false,"field_order":["form_fields","include_metadata"],"frozen":false,"icon":"ListFilter","legacy":false,"metadata":{"code_hash":"0457c4acdf45","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.processing.dynamic_create_data.DynamicCreateDataComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"process_form","name":"form_data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Message","group_outputs":false,"method":"get_message","name":"message","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom lfx.custom import Component\nfrom lfx.io import (\n    BoolInput,\n    FloatInput,\n    HandleInput,\n    IntInput,\n    MultilineInput,\n    Output,\n    StrInput,\n    TableInput,\n)\nfrom lfx.schema.data import Data\nfrom lfx.schema.message import Message\n\n\nclass DynamicCreateDataComponent(Component):\n    display_name: str = \"Dynamic Create Data\"\n    description: str = \"Dynamically create a Data with a specified number of fields.\"\n    name: str = \"DynamicCreateData\"\n    MAX_FIELDS = 15  # Define a constant for maximum number of fields\n    icon = \"ListFilter\"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    inputs = [\n        TableInput(\n            name=\"form_fields\",\n            display_name=\"Input Configuration\",\n            info=(\n                \"Define the dynamic form fields. Each row creates a new input field \"\n                \"that can connect to other components.\"\n            ),\n            table_schema=[\n                {\n                    \"name\": \"field_name\",\n                    \"display_name\": \"Field Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Name for the field (used as both internal name and display label)\",\n                },\n                {\n                    \"name\": \"field_type\",\n                    \"display_name\": \"Field Type\",\n                    \"type\": \"str\",\n                    \"description\": \"Type of input field to create\",\n                    \"options\": [\"Text\", \"Data\", \"Number\", \"Handle\", \"Boolean\"],\n                    \"value\": \"Text\",\n                },\n            ],\n            value=[],\n            real_time_refresh=True,\n        ),\n        BoolInput(\n            name=\"include_metadata\",\n            display_name=\"Include Metadata\",\n            info=\"Include form configuration metadata in the output.\",\n            value=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"form_data\", method=\"process_form\"),\n        Output(display_name=\"Message\", name=\"message\", method=\"get_message\"),\n    ]\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        \"\"\"Update build configuration to add dynamic inputs that can connect to other components.\"\"\"\n        if field_name == \"form_fields\":\n            # Clear existing dynamic inputs from build config\n            keys_to_remove = [key for key in build_config if key.startswith(\"dynamic_\")]\n            for key in keys_to_remove:\n                del build_config[key]\n\n            # Add dynamic inputs based on table configuration\n            # Safety check to ensure field_value is not None and is iterable\n            if field_value is None:\n                field_value = []\n\n            for i, field_config in enumerate(field_value):\n                # Safety check to ensure field_config is not None\n                if field_config is None:\n                    continue\n\n                field_name = field_config.get(\"field_name\", f\"field_{i}\")\n                display_name = field_name  # Use field_name as display_name\n                field_type_option = field_config.get(\"field_type\", \"Text\")\n                default_value = \"\"  # All fields have empty default value\n                required = False  # All fields are optional by default\n                help_text = \"\"  # All fields have empty help text\n\n                # Map field type options to actual field types and input types\n                field_type_mapping = {\n                    \"Text\": {\"field_type\": \"multiline\", \"input_types\": [\"Text\", \"Message\"]},\n                    \"Data\": {\"field_type\": \"data\", \"input_types\": [\"Data\"]},\n                    \"Number\": {\"field_type\": \"number\", \"input_types\": [\"Text\", \"Message\"]},\n                    \"Handle\": {\"field_type\": \"handle\", \"input_types\": [\"Text\", \"Data\", \"Message\"]},\n                    \"Boolean\": {\"field_type\": \"boolean\", \"input_types\": None},\n                }\n\n                field_config_mapped = field_type_mapping.get(\n                    field_type_option, {\"field_type\": \"text\", \"input_types\": []}\n                )\n                if not isinstance(field_config_mapped, dict):\n                    field_config_mapped = {\"field_type\": \"text\", \"input_types\": []}\n                field_type = field_config_mapped[\"field_type\"]\n                input_types_list = field_config_mapped[\"input_types\"]\n\n                # Create the appropriate input type based on field_type\n                dynamic_input_name = f\"dynamic_{field_name}\"\n\n                if field_type == \"text\":\n                    if input_types_list:\n                        build_config[dynamic_input_name] = StrInput(\n                            name=dynamic_input_name,\n                            display_name=display_name,\n                            info=f\"{help_text} (Can connect to: {', '.join(input_types_list)})\",\n                            value=default_value,\n                            required=required,\n                            input_types=input_types_list,\n                        )\n                    else:\n                        build_config[dynamic_input_name] = StrInput(\n                            name=dynamic_input_name,\n                            display_name=display_name,\n                            info=help_text,\n                            value=default_value,\n                            required=required,\n                        )\n\n                elif field_type == \"multiline\":\n                    if input_types_list:\n                        build_config[dynamic_input_name] = MultilineInput(\n                            name=dynamic_input_name,\n                            display_name=display_name,\n                            info=f\"{help_text} (Can connect to: {', '.join(input_types_list)})\",\n                            value=default_value,\n                            required=required,\n                            input_types=input_types_list,\n                        )\n                    else:\n                        build_config[dynamic_input_name] = MultilineInput(\n                            name=dynamic_input_name,\n                            display_name=display_name,\n                            info=help_text,\n                            value=default_value,\n                            required=required,\n                        )\n\n                elif field_type == \"number\":\n                    try:\n                        default_int = int(default_value) if default_value else 0\n                    except ValueError:\n                        default_int = 0\n\n                    if input_types_list:\n                        build_config[dynamic_input_name] = IntInput(\n                            name=dynamic_input_name,\n                            display_name=display_name,\n                            info=f\"{help_text} (Can connect to: {', '.join(input_types_list)})\",\n                            value=default_int,\n                            required=required,\n                            input_types=input_types_list,\n                        )\n                    else:\n                        build_config[dynamic_input_name] = IntInput(\n                            name=dynamic_input_name,\n                            display_name=display_name,\n                            info=help_text,\n                            value=default_int,\n                            required=required,\n                        )\n\n                elif field_type == \"float\":\n                    try:\n                        default_float = float(default_value) if default_value else 0.0\n                    except ValueError:\n                        default_float = 0.0\n\n                    if input_types_list:\n                        build_config[dynamic_input_name] = FloatInput(\n                            name=dynamic_input_name,\n                            display_name=display_name,\n                            info=f\"{help_text} (Can connect to: {', '.join(input_types_list)})\",\n                            value=default_float,\n                            required=required,\n                            input_types=input_types_list,\n                        )\n                    else:\n                        build_config[dynamic_input_name] = FloatInput(\n                            name=dynamic_input_name,\n                            display_name=display_name,\n                            info=help_text,\n                            value=default_float,\n                            required=required,\n                        )\n\n                elif field_type == \"boolean\":\n                    default_bool = default_value.lower() in [\"true\", \"1\", \"yes\"] if default_value else False\n\n                    # Boolean fields don't use input_types parameter to avoid errors\n                    build_config[dynamic_input_name] = BoolInput(\n                        name=dynamic_input_name,\n                        display_name=display_name,\n                        info=help_text,\n                        value=default_bool,\n                        input_types=[],\n                        required=required,\n                    )\n\n                elif field_type == \"handle\":\n                    # HandleInput for generic data connections\n                    build_config[dynamic_input_name] = HandleInput(\n                        name=dynamic_input_name,\n                        display_name=display_name,\n                        info=f\"{help_text} (Accepts: {', '.join(input_types_list) if input_types_list else 'Any'})\",\n                        input_types=input_types_list if input_types_list else [\"Data\", \"Text\", \"Message\"],\n                        required=required,\n                    )\n\n                elif field_type == \"data\":\n                    # Specialized for Data type connections\n                    build_config[dynamic_input_name] = HandleInput(\n                        name=dynamic_input_name,\n                        display_name=display_name,\n                        info=f\"{help_text} (Data input)\",\n                        input_types=input_types_list if input_types_list else [\"Data\"],\n                        required=required,\n                    )\n\n                else:\n                    # Default to text input for unknown types\n                    build_config[dynamic_input_name] = StrInput(\n                        name=dynamic_input_name,\n                        display_name=display_name,\n                        info=f\"{help_text} (Unknown type '{field_type}', defaulting to text)\",\n                        value=default_value,\n                        required=required,\n                    )\n\n        return build_config\n\n    def get_dynamic_values(self) -> dict[str, Any]:\n        \"\"\"Extract simple values from all dynamic inputs, handling both manual and connected inputs.\"\"\"\n        dynamic_values = {}\n        connection_info = {}\n        form_fields = getattr(self, \"form_fields\", [])\n\n        for field_config in form_fields:\n            # Safety check to ensure field_config is not None\n            if field_config is None:\n                continue\n\n            field_name = field_config.get(\"field_name\", \"\")\n            if field_name:\n                dynamic_input_name = f\"dynamic_{field_name}\"\n                value = getattr(self, dynamic_input_name, None)\n\n                # Extract simple values from connections or manual input\n                if value is not None:\n                    try:\n                        extracted_value = self._extract_simple_value(value)\n                        dynamic_values[field_name] = extracted_value\n\n                        # Determine connection type for status\n                        if hasattr(value, \"text\") and hasattr(value, \"timestamp\"):\n                            connection_info[field_name] = \"Connected (Message)\"\n                        elif hasattr(value, \"data\"):\n                            connection_info[field_name] = \"Connected (Data)\"\n                        elif isinstance(value, (str, int, float, bool, list, dict)):\n                            connection_info[field_name] = \"Manual input\"\n                        else:\n                            connection_info[field_name] = \"Connected (Object)\"\n\n                    except (AttributeError, TypeError, ValueError):\n                        # Fallback to string representation if all else fails\n                        dynamic_values[field_name] = str(value)\n                        connection_info[field_name] = \"Error\"\n                else:\n                    # Use empty default value if nothing connected\n                    dynamic_values[field_name] = \"\"\n                    connection_info[field_name] = \"Empty default\"\n\n        # Store connection info for status output\n        self._connection_info = connection_info\n        return dynamic_values\n\n    def _extract_simple_value(self, value: Any) -> Any:\n        \"\"\"Extract the simplest, most useful value from any input type.\"\"\"\n        # Handle None\n        if value is None:\n            return None\n\n        # Handle simple types directly\n        if isinstance(value, (str, int, float, bool)):\n            return value\n\n        # Handle lists and tuples - keep simple\n        if isinstance(value, (list, tuple)):\n            return [self._extract_simple_value(item) for item in value]\n\n        # Handle dictionaries - keep simple\n        if isinstance(value, dict):\n            return {str(k): self._extract_simple_value(v) for k, v in value.items()}\n\n        # Handle Message objects - extract only the text\n        if hasattr(value, \"text\"):\n            return str(value.text) if value.text is not None else \"\"\n\n        # Handle Data objects - extract the data content\n        if hasattr(value, \"data\") and value.data is not None:\n            return self._extract_simple_value(value.data)\n\n        # For any other object, convert to string\n        return str(value)\n\n    def process_form(self) -> Data:\n        \"\"\"Process all dynamic form inputs and return clean data with just field values.\"\"\"\n        # Get all dynamic values (just the key:value pairs)\n        dynamic_values = self.get_dynamic_values()\n\n        # Update status with connection info\n        connected_fields = len([v for v in getattr(self, \"_connection_info\", {}).values() if \"Connected\" in v])\n        total_fields = len(dynamic_values)\n\n        self.status = f\"Form processed successfully. {connected_fields}/{total_fields} fields connected to components.\"\n\n        # Return clean Data object with just the field values\n        return Data(data=dynamic_values)\n\n    def get_message(self) -> Message:\n        \"\"\"Return form data as a formatted text message.\"\"\"\n        # Get all dynamic values\n        dynamic_values = self.get_dynamic_values()\n\n        if not dynamic_values:\n            return Message(text=\"No form data available\")\n\n        # Format as text message\n        message_lines = [\"📋 Form Data:\"]\n        message_lines.append(\"=\" * 40)\n\n        for field_name, value in dynamic_values.items():\n            # Use field_name as display_name\n            display_name = field_name\n\n            message_lines.append(f\"• {display_name}: {value}\")\n\n        message_lines.append(\"=\" * 40)\n        message_lines.append(f\"Total fields: {len(dynamic_values)}\")\n\n        message_text = \"\\n\".join(message_lines)\n        self.status = f\"Message formatted with {len(dynamic_values)} fields\"\n\n        return Message(text=message_text)\n"},"form_fields":{"_input_type":"TableInput","advanced":false,"display_name":"Input Configuration","dynamic":false,"info":"Define the dynamic form fields. Each row creates a new input field that can connect to other components.","is_list":true,"list_add_label":"Add More","name":"form_fields","placeholder":"","real_time_refresh":true,"required":false,"show":true,"table_icon":"Table","table_schema":[{"description":"Name for the field (used as both internal name and display label)","display_name":"Field Name","name":"field_name","type":"str"},{"description":"Type of input field to create","display_name":"Field Type","name":"field_type","options":["Text","Data","Number","Handle","Boolean"],"type":"str","value":"Text"}],"title_case":false,"tool_mode":false,"trace_as_metadata":true,"trigger_icon":"Table","trigger_text":"Open table","type":"table","value":[]},"include_metadata":{"_input_type":"BoolInput","advanced":true,"display_name":"Include Metadata","dynamic":false,"info":"Include form configuration metadata in the output.","list":false,"list_add_label":"Add More","name":"include_metadata","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false},"ExtractaKey":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Extract a specific key from a Data object or a list of Data objects and return the extracted value(s) as Data object(s).","display_name":"Extract Key","documentation":"","edited":false,"field_order":["data_input","key"],"frozen":false,"icon":"key","legacy":true,"metadata":{"code_hash":"eded3f4e1533","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.processing.extract_key.ExtractDataKeyComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Extracted Data","group_outputs":false,"method":"extract_key","name":"extracted_data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["processing.DataOperations"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.io import DataInput, Output, StrInput\nfrom lfx.schema.data import Data\n\n\nclass ExtractDataKeyComponent(Component):\n    display_name = \"Extract Key\"\n    description = (\n        \"Extract a specific key from a Data object or a list of \"\n        \"Data objects and return the extracted value(s) as Data object(s).\"\n    )\n    icon = \"key\"\n    name = \"ExtractaKey\"\n    legacy = True\n    replacement = [\"processing.DataOperations\"]\n\n    inputs = [\n        DataInput(\n            name=\"data_input\",\n            display_name=\"Data Input\",\n            info=\"The Data object or list of Data objects to extract the key from.\",\n        ),\n        StrInput(\n            name=\"key\",\n            display_name=\"Key to Extract\",\n            info=\"The key in the Data object(s) to extract.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Extracted Data\", name=\"extracted_data\", method=\"extract_key\"),\n    ]\n\n    def extract_key(self) -> Data | list[Data]:\n        key = self.key\n\n        if isinstance(self.data_input, list):\n            result = []\n            for item in self.data_input:\n                if isinstance(item, Data) and key in item.data:\n                    extracted_value = item.data[key]\n                    result.append(Data(data={key: extracted_value}))\n            self.status = result\n            return result\n        if isinstance(self.data_input, Data):\n            if key in self.data_input.data:\n                extracted_value = self.data_input.data[key]\n                result = Data(data={key: extracted_value})\n                self.status = result\n                return result\n            self.status = f\"Key '{key}' not found in Data object.\"\n            return Data(data={\"error\": f\"Key '{key}' not found in Data object.\"})\n        self.status = \"Invalid input. Expected Data object or list of Data objects.\"\n        return Data(data={\"error\": \"Invalid input. Expected Data object or list of Data objects.\"})\n"},"data_input":{"_input_type":"DataInput","advanced":false,"display_name":"Data Input","dynamic":false,"info":"The Data object or list of Data objects to extract the key from.","input_types":["Data"],"list":false,"list_add_label":"Add More","name":"data_input","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"key":{"_input_type":"StrInput","advanced":false,"display_name":"Key to Extract","dynamic":false,"info":"The key in the Data object(s) to extract.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"FilterData":{"base_classes":["Data"],"beta":true,"conditional_paths":[],"custom_fields":{},"description":"Filters a Data object based on a list of keys.","display_name":"Filter Data","documentation":"","edited":false,"field_order":["data","filter_criteria"],"frozen":false,"icon":"filter","legacy":true,"metadata":{"code_hash":"04c50937216d","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.processing.filter_data.FilterDataComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Filtered Data","group_outputs":false,"method":"filter_data","name":"filtered_data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["processing.DataOperations"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.io import DataInput, MessageTextInput, Output\nfrom lfx.schema.data import Data\n\n\nclass FilterDataComponent(Component):\n    display_name = \"Filter Data\"\n    description = \"Filters a Data object based on a list of keys.\"\n    icon = \"filter\"\n    beta = True\n    name = \"FilterData\"\n    legacy = True\n    replacement = [\"processing.DataOperations\"]\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"Data object to filter.\",\n        ),\n        MessageTextInput(\n            name=\"filter_criteria\",\n            display_name=\"Filter Criteria\",\n            info=\"List of keys to filter by.\",\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\n    ]\n\n    def filter_data(self) -> Data:\n        filter_criteria: list[str] = self.filter_criteria\n        data = self.data.data if isinstance(self.data, Data) else {}\n\n        # Filter the data\n        filtered = {key: value for key, value in data.items() if key in filter_criteria}\n\n        # Create a new Data object with the filtered data\n        filtered_data = Data(data=filtered)\n        self.status = filtered_data\n        return filtered_data\n"},"data":{"_input_type":"DataInput","advanced":false,"display_name":"Data","dynamic":false,"info":"Data object to filter.","input_types":["Data"],"list":false,"list_add_label":"Add More","name":"data","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"filter_criteria":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Filter Criteria","dynamic":false,"info":"List of keys to filter by.","input_types":["Message"],"list":true,"list_add_label":"Add More","load_from_db":false,"name":"filter_criteria","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"FilterDataValues":{"base_classes":["Data"],"beta":true,"conditional_paths":[],"custom_fields":{},"description":"Filter a list of data items based on a specified key, filter value, and comparison operator. Check advanced options to select match comparision.","display_name":"Filter Values","documentation":"","edited":false,"field_order":["input_data","filter_key","filter_value","operator"],"frozen":false,"icon":"filter","legacy":true,"metadata":{"code_hash":"847522549c67","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.processing.filter_data_values.DataFilterComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Filtered Data","group_outputs":false,"method":"filter_data","name":"filtered_data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["processing.DataOperations"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import DataInput, DropdownInput, MessageTextInput, Output\nfrom lfx.schema.data import Data\n\n\nclass DataFilterComponent(Component):\n    display_name = \"Filter Values\"\n    description = (\n        \"Filter a list of data items based on a specified key, filter value,\"\n        \" and comparison operator. Check advanced options to select match comparision.\"\n    )\n    icon = \"filter\"\n    beta = True\n    name = \"FilterDataValues\"\n    legacy = True\n    replacement = [\"processing.DataOperations\"]\n\n    inputs = [\n        DataInput(name=\"input_data\", display_name=\"Input Data\", info=\"The list of data items to filter.\", is_list=True),\n        MessageTextInput(\n            name=\"filter_key\",\n            display_name=\"Filter Key\",\n            info=\"The key to filter on (e.g., 'route').\",\n            value=\"route\",\n            input_types=[\"Data\"],\n        ),\n        MessageTextInput(\n            name=\"filter_value\",\n            display_name=\"Filter Value\",\n            info=\"The value to filter by (e.g., 'CMIP').\",\n            value=\"CMIP\",\n            input_types=[\"Data\"],\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Comparison Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\"],\n            info=\"The operator to apply for comparing the values.\",\n            value=\"equals\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\n    ]\n\n    def compare_values(self, item_value: Any, filter_value: str, operator: str) -> bool:\n        if operator == \"equals\":\n            return str(item_value) == filter_value\n        if operator == \"not equals\":\n            return str(item_value) != filter_value\n        if operator == \"contains\":\n            return filter_value in str(item_value)\n        if operator == \"starts with\":\n            return str(item_value).startswith(filter_value)\n        if operator == \"ends with\":\n            return str(item_value).endswith(filter_value)\n        return False\n\n    def filter_data(self) -> list[Data]:\n        # Extract inputs\n        input_data: list[Data] = self.input_data\n        filter_key: str = self.filter_key.text\n        filter_value: str = self.filter_value.text\n        operator: str = self.operator\n\n        # Validate inputs\n        if not input_data:\n            self.status = \"Input data is empty.\"\n            return []\n\n        if not filter_key or not filter_value:\n            self.status = \"Filter key or value is missing.\"\n            return input_data\n\n        # Filter the data\n        filtered_data = []\n        for item in input_data:\n            if isinstance(item.data, dict) and filter_key in item.data:\n                if self.compare_values(item.data[filter_key], filter_value, operator):\n                    filtered_data.append(item)\n            else:\n                self.status = f\"Warning: Some items don't have the key '{filter_key}' or are not dictionaries.\"\n\n        self.status = filtered_data\n        return filtered_data\n"},"filter_key":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Filter Key","dynamic":false,"info":"The key to filter on (e.g., 'route').","input_types":["Data"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"filter_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"route"},"filter_value":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Filter Value","dynamic":false,"info":"The value to filter by (e.g., 'CMIP').","input_types":["Data"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"filter_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"CMIP"},"input_data":{"_input_type":"DataInput","advanced":false,"display_name":"Input Data","dynamic":false,"info":"The list of data items to filter.","input_types":["Data"],"list":true,"list_add_label":"Add More","name":"input_data","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"operator":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Comparison Operator","dynamic":false,"external_options":{},"info":"The operator to apply for comparing the values.","name":"operator","options":["equals","not equals","contains","starts with","ends with"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"equals"}},"tool_mode":false},"JSONCleaner":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Cleans the messy and sometimes incorrect JSON strings produced by LLMs so that they are fully compliant with the JSON spec.","display_name":"JSON Cleaner","documentation":"","edited":false,"field_order":["json_str","remove_control_chars","normalize_unicode","validate_json"],"frozen":false,"icon":"braces","legacy":true,"metadata":{"code_hash":"5c150997aec4","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"json_repair","version":"0.30.3"}],"total_dependencies":2},"module":"lfx.components.processing.json_cleaner.JSONCleaner"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Cleaned JSON String","group_outputs":false,"method":"clean_json","name":"output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["processing.ParserComponent"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nimport unicodedata\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import BoolInput, MessageTextInput\nfrom lfx.schema.message import Message\nfrom lfx.template.field.base import Output\n\n\nclass JSONCleaner(Component):\n    icon = \"braces\"\n    display_name = \"JSON Cleaner\"\n    description = (\n        \"Cleans the messy and sometimes incorrect JSON strings produced by LLMs \"\n        \"so that they are fully compliant with the JSON spec.\"\n    )\n    legacy = True\n    replacement = [\"processing.ParserComponent\"]\n    inputs = [\n        MessageTextInput(\n            name=\"json_str\", display_name=\"JSON String\", info=\"The JSON string to be cleaned.\", required=True\n        ),\n        BoolInput(\n            name=\"remove_control_chars\",\n            display_name=\"Remove Control Characters\",\n            info=\"Remove control characters from the JSON string.\",\n            required=False,\n        ),\n        BoolInput(\n            name=\"normalize_unicode\",\n            display_name=\"Normalize Unicode\",\n            info=\"Normalize Unicode characters in the JSON string.\",\n            required=False,\n        ),\n        BoolInput(\n            name=\"validate_json\",\n            display_name=\"Validate JSON\",\n            info=\"Validate the JSON string to ensure it is well-formed.\",\n            required=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Cleaned JSON String\", name=\"output\", method=\"clean_json\"),\n    ]\n\n    def clean_json(self) -> Message:\n        try:\n            from json_repair import repair_json\n        except ImportError as e:\n            msg = \"Could not import the json_repair package. Please install it with `pip install json_repair`.\"\n            raise ImportError(msg) from e\n\n        \"\"\"Clean the input JSON string based on provided options and return the cleaned JSON string.\"\"\"\n        json_str = self.json_str\n        remove_control_chars = self.remove_control_chars\n        normalize_unicode = self.normalize_unicode\n        validate_json = self.validate_json\n\n        start = json_str.find(\"{\")\n        end = json_str.rfind(\"}\")\n        if start == -1 or end == -1:\n            msg = \"Invalid JSON string: Missing '{' or '}'\"\n            raise ValueError(msg)\n        try:\n            json_str = json_str[start : end + 1]\n\n            if remove_control_chars:\n                json_str = self._remove_control_characters(json_str)\n            if normalize_unicode:\n                json_str = self._normalize_unicode(json_str)\n            if validate_json:\n                json_str = self._validate_json(json_str)\n\n            cleaned_json_str = repair_json(json_str)\n            result = str(cleaned_json_str)\n\n            self.status = result\n            return Message(text=result)\n        except Exception as e:\n            msg = f\"Error cleaning JSON string: {e}\"\n            raise ValueError(msg) from e\n\n    def _remove_control_characters(self, s: str) -> str:\n        \"\"\"Remove control characters from the string.\"\"\"\n        return s.translate(self.translation_table)\n\n    def _normalize_unicode(self, s: str) -> str:\n        \"\"\"Normalize Unicode characters in the string.\"\"\"\n        return unicodedata.normalize(\"NFC\", s)\n\n    def _validate_json(self, s: str) -> str:\n        \"\"\"Validate the JSON string.\"\"\"\n        try:\n            json.loads(s)\n        except json.JSONDecodeError as e:\n            msg = f\"Invalid JSON string: {e}\"\n            raise ValueError(msg) from e\n        return s\n\n    def __init__(self, *args, **kwargs):\n        # Create a translation table that maps control characters to None\n        super().__init__(*args, **kwargs)\n        self.translation_table = str.maketrans(\"\", \"\", \"\".join(chr(i) for i in range(32)) + chr(127))\n"},"json_str":{"_input_type":"MessageTextInput","advanced":false,"display_name":"JSON String","dynamic":false,"info":"The JSON string to be cleaned.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"json_str","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"normalize_unicode":{"_input_type":"BoolInput","advanced":false,"display_name":"Normalize Unicode","dynamic":false,"info":"Normalize Unicode characters in the JSON string.","list":false,"list_add_label":"Add More","name":"normalize_unicode","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"remove_control_chars":{"_input_type":"BoolInput","advanced":false,"display_name":"Remove Control Characters","dynamic":false,"info":"Remove control characters from the JSON string.","list":false,"list_add_label":"Add More","name":"remove_control_chars","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"validate_json":{"_input_type":"BoolInput","advanced":false,"display_name":"Validate JSON","dynamic":false,"info":"Validate the JSON string to ensure it is well-formed.","list":false,"list_add_label":"Add More","name":"validate_json","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false},"LLMRouterComponent":{"base_classes":["Data","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Routes the input to the most appropriate LLM based on OpenRouter model specifications","display_name":"LLM Router","documentation":"https://docs.langflow.org/components-processing#llm-router","edited":false,"field_order":["models","input_value","judge_llm","optimization","use_openrouter_specs","timeout","fallback_to_first"],"frozen":false,"icon":"git-branch","legacy":false,"metadata":{"code_hash":"1580b44b295b","dependencies":{"dependencies":[{"name":"aiohttp","version":"3.13.0"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.processing.llm_router.LLMRouterComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Output","group_outputs":false,"method":"route_to_model","name":"output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Selected Model Info","group_outputs":false,"method":"get_selected_model_info","name":"selected_model_info","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Routing Decision","group_outputs":false,"method":"get_routing_decision","name":"routing_decision","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import asyncio\nimport http  # Added for HTTPStatus\nimport json\nfrom typing import Any\n\nimport aiohttp\n\nfrom lfx.base.models.chat_result import get_chat_result\nfrom lfx.base.models.model_utils import get_model_name\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import BoolInput, DropdownInput, HandleInput, IntInput, MultilineInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.message import Message\nfrom lfx.template.field.base import Output\n\n\nclass LLMRouterComponent(Component):\n    display_name = \"LLM Router\"\n    description = \"Routes the input to the most appropriate LLM based on OpenRouter model specifications\"\n    documentation: str = \"https://docs.langflow.org/components-processing#llm-router\"\n    icon = \"git-branch\"\n\n    # Constants for magic values\n    MAX_DESCRIPTION_LENGTH = 500\n    QUERY_PREVIEW_MAX_LENGTH = 1000\n\n    inputs = [\n        HandleInput(\n            name=\"models\",\n            display_name=\"Language Models\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n            is_list=True,\n            info=\"List of LLMs to route between\",\n        ),\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            required=True,\n            info=\"The input message to be routed\",\n        ),\n        HandleInput(\n            name=\"judge_llm\",\n            display_name=\"Judge LLM\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n            info=\"LLM that will evaluate and select the most appropriate model\",\n        ),\n        DropdownInput(\n            name=\"optimization\",\n            display_name=\"Optimization\",\n            options=[\"quality\", \"speed\", \"cost\", \"balanced\"],\n            value=\"balanced\",\n            info=\"Optimization preference for model selection\",\n        ),\n        BoolInput(\n            name=\"use_openrouter_specs\",\n            display_name=\"Use OpenRouter Specs\",\n            value=True,\n            info=(\n                \"Fetch model specifications from OpenRouter API for enhanced routing decisions. \"\n                \"If false, only model names will be used.\"\n            ),\n            advanced=True,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"API Timeout\",\n            value=10,\n            info=\"Timeout for API requests in seconds\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"fallback_to_first\",\n            display_name=\"Fallback to First Model\",\n            value=True,\n            info=\"Use first model as fallback when routing fails\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"route_to_model\"),\n        Output(\n            display_name=\"Selected Model Info\",\n            name=\"selected_model_info\",\n            method=\"get_selected_model_info\",\n            types=[\"Data\"],\n        ),\n        Output(\n            display_name=\"Routing Decision\",\n            name=\"routing_decision\",\n            method=\"get_routing_decision\",\n        ),\n    ]\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self._selected_model_name: str | None = None\n        self._selected_api_model_id: str | None = None\n        self._routing_decision: str = \"\"\n        self._models_api_cache: dict[str, dict[str, Any]] = {}\n        self._model_name_to_api_id: dict[str, str] = {}\n\n    def _simplify_model_name(self, name: str) -> str:\n        \"\"\"Simplify model name for matching by lowercasing and removing non-alphanumerics.\"\"\"\n        return \"\".join(c.lower() for c in name if c.isalnum())\n\n    async def _fetch_openrouter_models_data(self) -> None:\n        \"\"\"Fetch all models from OpenRouter API and cache them along with name mappings.\"\"\"\n        if self._models_api_cache and self._model_name_to_api_id:\n            return\n\n        if not self.use_openrouter_specs:\n            self.log(\"OpenRouter specs are disabled. Skipping fetch.\")\n            return\n\n        try:\n            self.status = \"Fetching OpenRouter model specifications...\"\n            self.log(\"Fetching all model specifications from OpenRouter API: https://openrouter.ai/api/v1/models\")\n            async with (\n                aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=self.timeout)) as session,\n                session.get(\"https://openrouter.ai/api/v1/models\") as response,\n            ):\n                if response.status == http.HTTPStatus.OK:\n                    data = await response.json()\n                    models_list = data.get(\"data\", [])\n\n                    _models_api_cache_temp = {}\n                    _model_name_to_api_id_temp = {}\n\n                    for model_data in models_list:\n                        api_model_id = model_data.get(\"id\")\n                        if not api_model_id:\n                            continue\n\n                        _models_api_cache_temp[api_model_id] = model_data\n                        _model_name_to_api_id_temp[api_model_id] = api_model_id\n\n                        api_model_name = model_data.get(\"name\")\n                        if api_model_name:\n                            _model_name_to_api_id_temp[api_model_name] = api_model_id\n                            simplified_api_name = self._simplify_model_name(api_model_name)\n                            _model_name_to_api_id_temp[simplified_api_name] = api_model_id\n\n                        hugging_face_id = model_data.get(\"hugging_face_id\")\n                        if hugging_face_id:\n                            _model_name_to_api_id_temp[hugging_face_id] = api_model_id\n                            simplified_hf_id = self._simplify_model_name(hugging_face_id)\n                            _model_name_to_api_id_temp[simplified_hf_id] = api_model_id\n\n                        if \"/\" in api_model_id:\n                            try:\n                                model_name_part_of_id = api_model_id.split(\"/\", 1)[1]\n                                if model_name_part_of_id:\n                                    _model_name_to_api_id_temp[model_name_part_of_id] = api_model_id\n                                    simplified_part_id = self._simplify_model_name(model_name_part_of_id)\n                                    _model_name_to_api_id_temp[simplified_part_id] = api_model_id\n                            except IndexError:\n                                pass  # Should not happen if '/' is present\n\n                    self._models_api_cache = _models_api_cache_temp\n                    self._model_name_to_api_id = _model_name_to_api_id_temp\n                    log_msg = (\n                        f\"Successfully fetched and cached {len(self._models_api_cache)} \"\n                        f\"model specifications from OpenRouter.\"\n                    )\n                    self.log(log_msg)\n                else:\n                    err_text = await response.text()\n                    self.log(f\"Failed to fetch OpenRouter models: HTTP {response.status} - {err_text}\")\n                    self._models_api_cache = {}\n                    self._model_name_to_api_id = {}\n        except aiohttp.ClientError as e:\n            self.log(f\"AIOHTTP ClientError fetching OpenRouter models: {e!s}\", \"error\")\n            self._models_api_cache = {}\n            self._model_name_to_api_id = {}\n        except asyncio.TimeoutError:\n            self.log(\"Timeout fetching OpenRouter model specifications.\", \"error\")\n            self._models_api_cache = {}\n            self._model_name_to_api_id = {}\n        except json.JSONDecodeError as e:\n            self.log(f\"JSON decode error fetching OpenRouter models: {e!s}\", \"error\")\n            self._models_api_cache = {}\n            self._model_name_to_api_id = {}\n        finally:\n            self.status = \"\"\n\n    def _get_api_model_id_for_langflow_model(self, langflow_model_name: str) -> str | None:\n        \"\"\"Attempt to find the OpenRouter API ID for a given Langflow model name.\"\"\"\n        if not langflow_model_name:\n            return None\n\n        potential_names_to_check = [langflow_model_name, self._simplify_model_name(langflow_model_name)]\n\n        if langflow_model_name.startswith(\"models/\"):\n            name_without_prefix = langflow_model_name[len(\"models/\") :]\n            potential_names_to_check.append(name_without_prefix)\n            potential_names_to_check.append(self._simplify_model_name(name_without_prefix))\n\n        elif langflow_model_name.startswith(\"community_models/\"):\n            name_without_prefix = langflow_model_name[len(\"community_models/\") :]\n            potential_names_to_check.append(name_without_prefix)\n            simplified_no_prefix = self._simplify_model_name(name_without_prefix)\n            potential_names_to_check.append(simplified_no_prefix)\n\n        elif langflow_model_name.startswith(\"community_models/\"):\n            name_without_prefix = langflow_model_name[len(\"community_models/\") :]\n            potential_names_to_check.append(name_without_prefix)\n            simplified_no_prefix_comm = self._simplify_model_name(name_without_prefix)\n            potential_names_to_check.append(simplified_no_prefix_comm)\n\n        unique_names_to_check = list(dict.fromkeys(potential_names_to_check))\n\n        for name_variant in unique_names_to_check:\n            if name_variant in self._model_name_to_api_id:\n                return self._model_name_to_api_id[name_variant]\n\n        self.log(\n            f\"Could not map Langflow model name '{langflow_model_name}' \"\n            f\"(tried variants: {unique_names_to_check}) to an OpenRouter API ID.\"\n        )\n        return None\n\n    def _get_model_specs_dict(self, langflow_model_name: str) -> dict[str, Any]:\n        \"\"\"Get a dictionary of relevant model specifications for a given Langflow model name.\"\"\"\n        if not self.use_openrouter_specs or not self._models_api_cache:\n            return {\n                \"id\": langflow_model_name,\n                \"name\": langflow_model_name,\n                \"description\": \"Specifications not available.\",\n            }\n\n        api_model_id = self._get_api_model_id_for_langflow_model(langflow_model_name)\n\n        if not api_model_id or api_model_id not in self._models_api_cache:\n            log_msg = (\n                f\"No cached API data found for Langflow model '{langflow_model_name}' \"\n                f\"(mapped API ID: {api_model_id}). Returning basic info.\"\n            )\n            self.log(log_msg)\n            return {\n                \"id\": langflow_model_name,\n                \"name\": langflow_model_name,\n                \"description\": \"Full specifications not found in cache.\",\n            }\n\n        model_data = self._models_api_cache[api_model_id]\n        top_provider_data = model_data.get(\"top_provider\", {})\n        architecture_data = model_data.get(\"architecture\", {})\n        pricing_data = model_data.get(\"pricing\", {})\n        description = model_data.get(\"description\", \"No description available\")\n        truncated_description = (\n            description[: self.MAX_DESCRIPTION_LENGTH - 3] + \"...\"\n            if len(description) > self.MAX_DESCRIPTION_LENGTH\n            else description\n        )\n\n        specs = {\n            \"id\": model_data.get(\"id\"),\n            \"name\": model_data.get(\"name\"),\n            \"description\": truncated_description,\n            \"context_length\": top_provider_data.get(\"context_length\") or model_data.get(\"context_length\"),\n            \"max_completion_tokens\": (\n                top_provider_data.get(\"max_completion_tokens\") or model_data.get(\"max_completion_tokens\")\n            ),\n            \"tokenizer\": architecture_data.get(\"tokenizer\"),\n            \"input_modalities\": architecture_data.get(\"input_modalities\", []),\n            \"output_modalities\": architecture_data.get(\"output_modalities\", []),\n            \"pricing_prompt\": pricing_data.get(\"prompt\"),\n            \"pricing_completion\": pricing_data.get(\"completion\"),\n            \"is_moderated\": top_provider_data.get(\"is_moderated\"),\n            \"supported_parameters\": model_data.get(\"supported_parameters\", []),\n        }\n        return {k: v for k, v in specs.items() if v is not None}\n\n    def _create_system_prompt(self) -> str:\n        \"\"\"Create system prompt for the judge LLM.\"\"\"\n        return \"\"\"\\\nYou are an expert AI model selection specialist. Your task is to analyze the user's input query,\ntheir optimization preference, and a list of available models with their specifications,\nthen select the most appropriate model.\n\nEach model will be presented as a JSON object with its capabilities and characteristics.\n\nYour decision should be based on:\n1. Task complexity and requirements derived from the user's query.\n2. Context length needed for the input.\n3. Model capabilities (e.g., context window, input/output modalities, tokenizer).\n4. Pricing considerations, if relevant to the optimization preference.\n5. User's stated optimization preference (quality, speed, cost, balanced).\n\nReturn ONLY the index number (0, 1, 2, etc.) of the best model from the provided list.\nDo not provide any explanation or reasoning, just the index number.\nIf multiple models seem equally suitable according to the preference, you may pick the first one that matches.\nIf no model seems suitable, pick the first model in the list (index 0) as a fallback.\"\"\"\n\n    async def route_to_model(self) -> Message:\n        \"\"\"Main routing method.\"\"\"\n        if not self.models or not self.input_value or not self.judge_llm:\n            error_msg = \"Missing required inputs: models, input_value, or judge_llm\"\n            self.status = error_msg\n            self.log(f\"Validation Error: {error_msg}\", \"error\")\n            raise ValueError(error_msg)\n\n        successful_result: Message | None = None\n        try:\n            self.log(f\"Starting model routing with {len(self.models)} available Langflow models.\")\n            self.log(f\"Optimization preference: {self.optimization}\")\n            self.log(f\"Input length: {len(self.input_value)} characters\")\n\n            if self.use_openrouter_specs and not self._models_api_cache:\n                await self._fetch_openrouter_models_data()\n\n            system_prompt_content = self._create_system_prompt()\n            system_message = {\"role\": \"system\", \"content\": system_prompt_content}\n\n            self.status = \"Analyzing available models and preparing specifications...\"\n            model_specs_for_judge = []\n            for i, langflow_model_instance in enumerate(self.models):\n                langflow_model_name = get_model_name(langflow_model_instance)\n                if not langflow_model_name:\n                    self.log(f\"Warning: Could not determine name for model at index {i}. Using placeholder.\", \"warning\")\n                    spec_dict = {\n                        \"id\": f\"unknown_model_{i}\",\n                        \"name\": f\"Unknown Model {i}\",\n                        \"description\": \"Name could not be determined.\",\n                    }\n                else:\n                    spec_dict = self._get_model_specs_dict(langflow_model_name)\n\n                model_specs_for_judge.append({\"index\": i, \"langflow_name\": langflow_model_name, \"specs\": spec_dict})\n                self.log(\n                    f\"Prepared specs for Langflow model {i} ('{langflow_model_name}'): {spec_dict.get('name', 'N/A')}\"\n                )\n\n            estimated_tokens = len(self.input_value.split()) * 1.3\n            self.log(f\"Estimated input tokens: {int(estimated_tokens)}\")\n\n            query_preview = self.input_value[: self.QUERY_PREVIEW_MAX_LENGTH]\n            if len(self.input_value) > self.QUERY_PREVIEW_MAX_LENGTH:\n                query_preview += \"...\"\n\n            user_message_content = f\"\"\"User Query: \"{query_preview}\"\nOptimization Preference: {self.optimization}\nEstimated Input Tokens: ~{int(estimated_tokens)}\n\nAvailable Models (JSON list):\n{json.dumps(model_specs_for_judge, indent=2)}\n\nBased on the user query, optimization preference, and the detailed model specifications,\nselect the index of the most appropriate model.\nReturn ONLY the index number:\"\"\"\n\n            user_message = {\"role\": \"user\", \"content\": user_message_content}\n\n            self.log(\"Requesting model selection from judge LLM...\")\n            self.status = \"Judge LLM analyzing options...\"\n\n            response = await self.judge_llm.ainvoke([system_message, user_message])\n            selected_index, chosen_model_instance = self._parse_judge_response(response.content.strip())\n            self._selected_model_name = get_model_name(chosen_model_instance)\n            if self._selected_model_name:\n                self._selected_api_model_id = (\n                    self._get_api_model_id_for_langflow_model(self._selected_model_name) or self._selected_model_name\n                )\n            else:\n                self._selected_api_model_id = \"unknown_model\"\n\n            specs_source = (\n                \"OpenRouter API\"\n                if self.use_openrouter_specs and self._models_api_cache\n                else \"Basic (Langflow model names only)\"\n            )\n            self._routing_decision = f\"\"\"Model Selection Decision:\n- Selected Model Index: {selected_index}\n- Selected Langflow Model Name: {self._selected_model_name}\n- Selected API Model ID (if resolved): {self._selected_api_model_id}\n- Optimization Preference: {self.optimization}\n- Input Query Length: {len(self.input_value)} characters (~{int(estimated_tokens)} tokens)\n- Number of Models Considered: {len(self.models)}\n- Specifications Source: {specs_source}\"\"\"\n\n            log_msg = (\n                f\"DECISION by Judge LLM: Selected model index {selected_index} -> \"\n                f\"Langflow Name: '{self._selected_model_name}', API ID: '{self._selected_api_model_id}'\"\n            )\n            self.log(log_msg)\n\n            self.status = f\"Generating response with: {self._selected_model_name}\"\n            input_message_obj = Message(text=self.input_value)\n\n            raw_result = get_chat_result(\n                runnable=chosen_model_instance,\n                input_value=input_message_obj,\n            )\n            result = Message(text=str(raw_result)) if not isinstance(raw_result, Message) else raw_result\n\n            self.status = f\"Successfully routed to: {self._selected_model_name}\"\n            successful_result = result\n\n        except (ValueError, TypeError, AttributeError, KeyError, RuntimeError) as e:\n            error_msg = f\"Routing error: {type(e).__name__} - {e!s}\"\n            self.log(f\"{error_msg}\", \"error\")\n            self.log(\"Detailed routing error occurred. Check logs for details.\", \"error\")\n            self.status = error_msg\n\n            if self.fallback_to_first and self.models:\n                self.log(\"Activating fallback to first model due to error.\", \"warning\")\n                chosen_model_instance = self.models[0]\n                self._selected_model_name = get_model_name(chosen_model_instance)\n                if self._selected_model_name:\n                    mapped_id = self._get_api_model_id_for_langflow_model(self._selected_model_name)\n                    self._selected_api_model_id = mapped_id or self._selected_model_name\n                else:\n                    self._selected_api_model_id = \"fallback_model\"\n                self._routing_decision = f\"\"\"Fallback Decision:\n- Error During Routing: {error_msg}\n- Fallback Model Langflow Name: {self._selected_model_name}\n- Fallback Model API ID (if resolved): {self._selected_api_model_id}\n- Reason: Automatic fallback enabled\"\"\"\n\n                self.status = f\"Fallback: Using {self._selected_model_name}\"\n                input_message_obj = Message(text=self.input_value)\n\n                raw_fallback_result = get_chat_result(\n                    runnable=chosen_model_instance,\n                    input_value=input_message_obj,\n                )\n                if not isinstance(raw_fallback_result, Message):\n                    successful_result = Message(text=str(raw_fallback_result))\n                else:\n                    successful_result = raw_fallback_result\n            else:\n                self.log(\"No fallback model available or fallback disabled. Raising error.\", \"error\")\n                raise\n\n        if successful_result is None:\n            error_message = \"Unexpected state in route_to_model: No result produced.\"\n            self.log(f\"Error: {error_message}\", \"error\")\n            raise RuntimeError(error_message)\n        return successful_result\n\n    def _parse_judge_response(self, response_content: str) -> tuple[int, Any]:\n        \"\"\"Parse the judge's response to extract model index.\"\"\"\n        try:\n            cleaned_response = \"\".join(filter(str.isdigit, response_content.strip()))\n            if not cleaned_response:\n                self.log(f\"Judge LLM response was non-numeric: '{response_content}'. Defaulting to index 0.\", \"warning\")\n                return 0, self.models[0]\n\n            selected_index = int(cleaned_response)\n\n            if 0 <= selected_index < len(self.models):\n                self.log(f\"Judge LLM selected index: {selected_index}\")\n                return selected_index, self.models[selected_index]\n            log_msg = (\n                f\"Judge LLM selected index {selected_index} is out of bounds \"\n                f\"(0-{len(self.models) - 1}). Defaulting to index 0.\"\n            )\n            self.log(log_msg, \"warning\")\n            return 0, self.models[0]\n\n        except ValueError:\n            self.log(\n                f\"Could not parse judge LLM response to integer: '{response_content}'. Defaulting to index 0.\",\n                \"warning\",\n            )\n            return 0, self.models[0]\n        except (AttributeError, IndexError) as e:\n            self.log(f\"Error parsing judge response '{response_content}': {e!s}. Defaulting to index 0.\", \"error\")\n            return 0, self.models[0]\n\n    def get_selected_model_info(self) -> list[Data]:\n        \"\"\"Return detailed information about the selected model as a list of Data objects.\"\"\"\n        if self._selected_model_name:\n            specs_dict = self._get_model_specs_dict(self._selected_model_name)\n            if \"langflow_name\" not in specs_dict:\n                specs_dict[\"langflow_model_name_used_for_lookup\"] = self._selected_model_name\n            if self._selected_api_model_id and specs_dict.get(\"id\") != self._selected_api_model_id:\n                specs_dict[\"resolved_api_model_id\"] = self._selected_api_model_id\n            data_output = [Data(data=specs_dict)]\n            self.status = data_output\n            return data_output\n\n        data_output = [Data(data={\"info\": \"No model selected yet - run the router first.\"})]\n        self.status = data_output\n        return data_output\n\n    def get_routing_decision(self) -> Message:\n        \"\"\"Return the comprehensive routing decision explanation.\"\"\"\n        if self._routing_decision:\n            message_output = Message(text=f\"{self._routing_decision}\")\n            self.status = message_output\n            return message_output\n\n        message_output = Message(text=\"No routing decision made yet - run the router first.\")\n        self.status = message_output\n        return message_output\n"},"fallback_to_first":{"_input_type":"BoolInput","advanced":true,"display_name":"Fallback to First Model","dynamic":false,"info":"Use first model as fallback when routing fails","list":false,"list_add_label":"Add More","name":"fallback_to_first","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"input_value":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Input","dynamic":false,"info":"The input message to be routed","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"input_value","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"judge_llm":{"_input_type":"HandleInput","advanced":false,"display_name":"Judge LLM","dynamic":false,"info":"LLM that will evaluate and select the most appropriate model","input_types":["LanguageModel"],"list":false,"list_add_label":"Add More","name":"judge_llm","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"models":{"_input_type":"HandleInput","advanced":false,"display_name":"Language Models","dynamic":false,"info":"List of LLMs to route between","input_types":["LanguageModel"],"list":true,"list_add_label":"Add More","name":"models","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"optimization":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Optimization","dynamic":false,"external_options":{},"info":"Optimization preference for model selection","name":"optimization","options":["quality","speed","cost","balanced"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"balanced"},"timeout":{"_input_type":"IntInput","advanced":true,"display_name":"API Timeout","dynamic":false,"info":"Timeout for API requests in seconds","list":false,"list_add_label":"Add More","name":"timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":10},"use_openrouter_specs":{"_input_type":"BoolInput","advanced":true,"display_name":"Use OpenRouter Specs","dynamic":false,"info":"Fetch model specifications from OpenRouter API for enhanced routing decisions. If false, only model names will be used.","list":false,"list_add_label":"Add More","name":"use_openrouter_specs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false},"MergeDataComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Combines data using different operations","display_name":"Combine Data","documentation":"","edited":false,"field_order":["data_inputs","operation"],"frozen":false,"icon":"merge","legacy":true,"metadata":{"code_hash":"a2ecb813aac5","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.processing.merge_data.MergeDataComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"combine_data","name":"combined_data","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["processing.DataOperations"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from enum import Enum\nfrom typing import cast\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import DataInput, DropdownInput, Output\nfrom lfx.log.logger import logger\nfrom lfx.schema.dataframe import DataFrame\n\n\nclass DataOperation(str, Enum):\n    CONCATENATE = \"Concatenate\"\n    APPEND = \"Append\"\n    MERGE = \"Merge\"\n    JOIN = \"Join\"\n\n\nclass MergeDataComponent(Component):\n    display_name = \"Combine Data\"\n    description = \"Combines data using different operations\"\n    icon = \"merge\"\n    MIN_INPUTS_REQUIRED = 2\n    legacy = True\n    replacement = [\"processing.DataOperations\"]\n\n    inputs = [\n        DataInput(name=\"data_inputs\", display_name=\"Data Inputs\", info=\"Data to combine\", is_list=True, required=True),\n        DropdownInput(\n            name=\"operation\",\n            display_name=\"Operation Type\",\n            options=[op.value for op in DataOperation],\n            value=DataOperation.CONCATENATE.value,\n        ),\n    ]\n    outputs = [Output(display_name=\"DataFrame\", name=\"combined_data\", method=\"combine_data\")]\n\n    def combine_data(self) -> DataFrame:\n        if not self.data_inputs or len(self.data_inputs) < self.MIN_INPUTS_REQUIRED:\n            empty_dataframe = DataFrame()\n            self.status = empty_dataframe\n            return empty_dataframe\n\n        operation = DataOperation(self.operation)\n        try:\n            combined_dataframe = self._process_operation(operation)\n            self.status = combined_dataframe\n        except Exception as e:\n            logger.error(f\"Error during operation {operation}: {e!s}\")\n            raise\n        else:\n            return combined_dataframe\n\n    def _process_operation(self, operation: DataOperation) -> DataFrame:\n        if operation == DataOperation.CONCATENATE:\n            combined_data: dict[str, str | object] = {}\n            for data_input in self.data_inputs:\n                for key, value in data_input.data.items():\n                    if key in combined_data:\n                        if isinstance(combined_data[key], str) and isinstance(value, str):\n                            combined_data[key] = f\"{combined_data[key]}\\n{value}\"\n                        else:\n                            combined_data[key] = value\n                    else:\n                        combined_data[key] = value\n            return DataFrame([combined_data])\n\n        if operation == DataOperation.APPEND:\n            rows = [data_input.data for data_input in self.data_inputs]\n            return DataFrame(rows)\n\n        if operation == DataOperation.MERGE:\n            result_data: dict[str, str | list[str] | object] = {}\n            for data_input in self.data_inputs:\n                for key, value in data_input.data.items():\n                    if key in result_data and isinstance(value, str):\n                        if isinstance(result_data[key], list):\n                            cast(\"list[str]\", result_data[key]).append(value)\n                        else:\n                            result_data[key] = [result_data[key], value]\n                    else:\n                        result_data[key] = value\n            return DataFrame([result_data])\n\n        if operation == DataOperation.JOIN:\n            combined_data = {}\n            for idx, data_input in enumerate(self.data_inputs, 1):\n                for key, value in data_input.data.items():\n                    new_key = f\"{key}_doc{idx}\" if idx > 1 else key\n                    combined_data[new_key] = value\n            return DataFrame([combined_data])\n\n        return DataFrame()\n"},"data_inputs":{"_input_type":"DataInput","advanced":false,"display_name":"Data Inputs","dynamic":false,"info":"Data to combine","input_types":["Data"],"list":true,"list_add_label":"Add More","name":"data_inputs","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"operation":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Operation Type","dynamic":false,"external_options":{},"info":"","name":"operation","options":["Concatenate","Append","Merge","Join"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Concatenate"}},"tool_mode":false},"MessagetoData":{"base_classes":["Data"],"beta":true,"conditional_paths":[],"custom_fields":{},"description":"Convert a Message object to a Data object","display_name":"Message to Data","documentation":"","edited":false,"field_order":["message"],"frozen":false,"icon":"message-square-share","legacy":true,"metadata":{"code_hash":"d0af1222aeaf","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.processing.message_to_data.MessageToDataComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"convert_message_to_data","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["processing.TypeConverterComponent"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.io import MessageInput, Output\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\n\n\nclass MessageToDataComponent(Component):\n    display_name = \"Message to Data\"\n    description = \"Convert a Message object to a Data object\"\n    icon = \"message-square-share\"\n    beta = True\n    name = \"MessagetoData\"\n    legacy = True\n    replacement = [\"processing.TypeConverterComponent\"]\n\n    inputs = [\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The Message object to convert to a Data object\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"convert_message_to_data\"),\n    ]\n\n    def convert_message_to_data(self) -> Data:\n        # Check for Message by checking if it has the expected attributes instead of isinstance\n        if hasattr(self.message, \"data\") and hasattr(self.message, \"text\") and hasattr(self.message, \"get_text\"):\n            # Convert Message to Data - this works for both langflow.Message and lfx.Message\n            return Data(data=self.message.data)\n\n        msg = \"Error converting Message to Data: Input must be a Message object\"\n        logger.debug(msg, exc_info=True)\n        self.status = msg\n        return Data(data={\"error\": msg})\n"},"message":{"_input_type":"MessageInput","advanced":false,"display_name":"Message","dynamic":false,"info":"The Message object to convert to a Data object","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ParseData":{"base_classes":["Data","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Convert Data objects into Messages using any {field_name} from input data.","display_name":"Data to Message","documentation":"","edited":false,"field_order":["data","template","sep"],"frozen":false,"icon":"message-square","legacy":true,"metadata":{"code_hash":"3fac44a9bb37","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"legacy_name":"Parse Data","module":"lfx.components.processing.parse_data.ParseDataComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Message","group_outputs":false,"method":"parse_data","name":"text","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Data List","group_outputs":false,"method":"parse_data_as_list","name":"data_list","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["processing.DataOperations","processing.TypeConverterComponent"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.helpers.data import data_to_text, data_to_text_list\nfrom lfx.io import DataInput, MultilineInput, Output, StrInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    replacement = [\"processing.DataOperations\", \"processing.TypeConverterComponent\"]\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"},"data":{"_input_type":"DataInput","advanced":false,"display_name":"Data","dynamic":false,"info":"The data to convert to text.","input_types":["Data"],"list":true,"list_add_label":"Add More","name":"data","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"sep":{"_input_type":"StrInput","advanced":true,"display_name":"Separator","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"sep","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"\n"},"template":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Template","dynamic":false,"info":"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"template","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"{text}"}},"tool_mode":false},"ParseDataFrame":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Convert a DataFrame into plain text following a specified template. Each column in the DataFrame is treated as a possible template key, e.g. {col_name}.","display_name":"Parse DataFrame","documentation":"","edited":false,"field_order":["df","template","sep"],"frozen":false,"icon":"braces","legacy":true,"metadata":{"code_hash":"9d4b05cf1564","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.processing.parse_dataframe.ParseDataFrameComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Text","group_outputs":false,"method":"parse_data","name":"text","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["processing.DataFrameOperations","processing.TypeConverterComponent"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.io import DataFrameInput, MultilineInput, Output, StrInput\nfrom lfx.schema.message import Message\n\n\nclass ParseDataFrameComponent(Component):\n    display_name = \"Parse DataFrame\"\n    description = (\n        \"Convert a DataFrame into plain text following a specified template. \"\n        \"Each column in the DataFrame is treated as a possible template key, e.g. {col_name}.\"\n    )\n    icon = \"braces\"\n    name = \"ParseDataFrame\"\n    legacy = True\n    replacement = [\"processing.DataFrameOperations\", \"processing.TypeConverterComponent\"]\n\n    inputs = [\n        DataFrameInput(name=\"df\", display_name=\"DataFrame\", info=\"The DataFrame to convert to text rows.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=(\n                \"The template for formatting each row. \"\n                \"Use placeholders matching column names in the DataFrame, for example '{col1}', '{col2}'.\"\n            ),\n            value=\"{text}\",\n        ),\n        StrInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String that joins all row texts when building the single Text output.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Text\",\n            name=\"text\",\n            info=\"All rows combined into a single text, each row formatted by the template and separated by `sep`.\",\n            method=\"parse_data\",\n        ),\n    ]\n\n    def _clean_args(self):\n        dataframe = self.df\n        template = self.template or \"{text}\"\n        sep = self.sep or \"\\n\"\n        return dataframe, template, sep\n\n    def parse_data(self) -> Message:\n        \"\"\"Converts each row of the DataFrame into a formatted string using the template.\n\n        then joins them with `sep`. Returns a single combined string as a Message.\n        \"\"\"\n        dataframe, template, sep = self._clean_args()\n\n        lines = []\n        # For each row in the DataFrame, build a dict and format\n        for _, row in dataframe.iterrows():\n            row_dict = row.to_dict()\n            text_line = template.format(**row_dict)  # e.g. template=\"{text}\", row_dict={\"text\": \"Hello\"}\n            lines.append(text_line)\n\n        # Join all lines with the provided separator\n        result_string = sep.join(lines)\n        self.status = result_string  # store in self.status for UI logs\n        return Message(text=result_string)\n"},"df":{"_input_type":"DataFrameInput","advanced":false,"display_name":"DataFrame","dynamic":false,"info":"The DataFrame to convert to text rows.","input_types":["DataFrame"],"list":false,"list_add_label":"Add More","name":"df","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"sep":{"_input_type":"StrInput","advanced":true,"display_name":"Separator","dynamic":false,"info":"String that joins all row texts when building the single Text output.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"sep","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"\n"},"template":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Template","dynamic":false,"info":"The template for formatting each row. Use placeholders matching column names in the DataFrame, for example '{col1}', '{col2}'.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"template","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"{text}"}},"tool_mode":false},"ParseJSONData":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Convert and extract JSON fields.","display_name":"Parse JSON","documentation":"","edited":false,"field_order":["input_value","query"],"frozen":false,"icon":"braces","legacy":true,"metadata":{"code_hash":"39d999d8aa9d","dependencies":{"dependencies":[{"name":"jq","version":"1.8.0"},{"name":"json_repair","version":"0.30.3"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.processing.parse_json_data.ParseJSONDataComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Filtered Data","group_outputs":false,"method":"filter_data","name":"filtered_data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["processing.ParserComponent"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nfrom json import JSONDecodeError\n\nimport jq\nfrom json_repair import repair_json\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import HandleInput, MessageTextInput\nfrom lfx.io import Output\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.message import Message\n\n\nclass ParseJSONDataComponent(Component):\n    display_name = \"Parse JSON\"\n    description = \"Convert and extract JSON fields.\"\n    icon = \"braces\"\n    name = \"ParseJSONData\"\n    legacy: bool = True\n    replacement = [\"processing.ParserComponent\"]\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"Data object to filter.\",\n            required=True,\n            input_types=[\"Message\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"JQ Query\",\n            info=\"JQ Query to filter the data. The input is always a JSON list.\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Filtered Data\", name=\"filtered_data\", method=\"filter_data\"),\n    ]\n\n    def _parse_data(self, input_value) -> str:\n        if isinstance(input_value, Message) and isinstance(input_value.text, str):\n            return input_value.text\n        if isinstance(input_value, Data):\n            return json.dumps(input_value.data)\n        return str(input_value)\n\n    def filter_data(self) -> list[Data]:\n        to_filter = self.input_value\n        if not to_filter:\n            return []\n        # Check if input is a list\n        if isinstance(to_filter, list):\n            to_filter = [self._parse_data(f) for f in to_filter]\n        else:\n            to_filter = self._parse_data(to_filter)\n\n        # If input is not a list, don't wrap it in a list\n        if not isinstance(to_filter, list):\n            to_filter = repair_json(to_filter)\n            try:\n                to_filter_as_dict = json.loads(to_filter)\n            except JSONDecodeError:\n                try:\n                    to_filter_as_dict = json.loads(repair_json(to_filter))\n                except JSONDecodeError as e:\n                    msg = f\"Invalid JSON: {e}\"\n                    raise ValueError(msg) from e\n        else:\n            to_filter = [repair_json(f) for f in to_filter]\n            to_filter_as_dict = []\n            for f in to_filter:\n                try:\n                    to_filter_as_dict.append(json.loads(f))\n                except JSONDecodeError:\n                    try:\n                        to_filter_as_dict.append(json.loads(repair_json(f)))\n                    except JSONDecodeError as e:\n                        msg = f\"Invalid JSON: {e}\"\n                        raise ValueError(msg) from e\n            to_filter = to_filter_as_dict\n\n        full_filter_str = json.dumps(to_filter_as_dict)\n\n        logger.info(\"to_filter: \", to_filter)\n\n        results = jq.compile(self.query).input_text(full_filter_str).all()\n        logger.info(\"results: \", results)\n        return [Data(data=value) if isinstance(value, dict) else Data(text=str(value)) for value in results]\n"},"input_value":{"_input_type":"HandleInput","advanced":false,"display_name":"Input","dynamic":false,"info":"Data object to filter.","input_types":["Message","Data"],"list":false,"list_add_label":"Add More","name":"input_value","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"query":{"_input_type":"MessageTextInput","advanced":false,"display_name":"JQ Query","dynamic":false,"info":"JQ Query to filter the data. The input is always a JSON list.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"query","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ParserComponent":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Extracts text using a template.","display_name":"Parser","documentation":"https://docs.langflow.org/components-processing#parser","edited":false,"field_order":["input_data","mode","pattern","sep"],"frozen":false,"icon":"braces","legacy":false,"metadata":{"code_hash":"bf19ee6feee3","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.processing.parser.ParserComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Parsed Text","group_outputs":false,"method":"parse_combined_text","name":"parsed_text","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.helpers.data import safe_convert\nfrom lfx.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.message import Message\nfrom lfx.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"},"input_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Data or DataFrame","dynamic":false,"info":"Accepts either a DataFrame or a Data object.","input_types":["DataFrame","Data"],"list":false,"list_add_label":"Add More","name":"input_data","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"mode":{"_input_type":"TabInput","advanced":false,"display_name":"Mode","dynamic":false,"info":"Convert into raw string instead of using a template.","name":"mode","options":["Parser","Stringify"],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"tab","value":"Parser"},"pattern":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Template","dynamic":true,"info":"Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"pattern","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"Text: {text}"},"sep":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Separator","dynamic":false,"info":"String used to separate rows/items.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"sep","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"\n"}},"tool_mode":false},"Prompt Template":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Create a prompt template with dynamic variables.","display_name":"Prompt Template","documentation":"https://docs.langflow.org/components-prompts","edited":false,"field_order":["template","tool_placeholder"],"frozen":false,"icon":"braces","legacy":false,"metadata":{"code_hash":"7382d03ce412","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.processing.prompt.PromptComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Prompt","group_outputs":false,"method":"build_prompt","name":"prompt","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"priority":0,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.prompts.api_utils import process_prompt_template\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import DefaultPromptField\nfrom lfx.io import MessageTextInput, Output, PromptInput\nfrom lfx.schema.message import Message\nfrom lfx.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"},"template":{"_input_type":"PromptInput","advanced":false,"display_name":"Template","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"template","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"prompt","value":""},"tool_placeholder":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Tool Placeholder","dynamic":false,"info":"A placeholder input for tool mode.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"tool_placeholder","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"PythonREPLComponent":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Run Python code with optional imports. Use print() to see the output.","display_name":"Python Interpreter","documentation":"https://docs.langflow.org/components-processing#python-interpreter","edited":false,"field_order":["global_imports","python_code"],"frozen":false,"icon":"square-terminal","legacy":false,"metadata":{"code_hash":"ea43aeeb8a56","dependencies":{"dependencies":[{"name":"langchain_experimental","version":"0.3.4"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.processing.python_repl_core.PythonREPLComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Results","group_outputs":false,"method":"run_python_repl","name":"results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import importlib\n\nfrom langchain_experimental.utilities import PythonREPL\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import MultilineInput, Output, StrInput\nfrom lfx.schema.data import Data\n\n\nclass PythonREPLComponent(Component):\n    display_name = \"Python Interpreter\"\n    description = \"Run Python code with optional imports. Use print() to see the output.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#python-interpreter\"\n    icon = \"square-terminal\"\n\n    inputs = [\n        StrInput(\n            name=\"global_imports\",\n            display_name=\"Global Imports\",\n            info=\"A comma-separated list of modules to import globally, e.g. 'math,numpy,pandas'.\",\n            value=\"math,pandas\",\n            required=True,\n        ),\n        MultilineInput(\n            name=\"python_code\",\n            display_name=\"Python Code\",\n            info=\"The Python code to execute. Only modules specified in Global Imports can be used.\",\n            value=\"print('Hello, World!')\",\n            input_types=[\"Message\"],\n            tool_mode=True,\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Results\",\n            name=\"results\",\n            type_=Data,\n            method=\"run_python_repl\",\n        ),\n    ]\n\n    def get_globals(self, global_imports: str | list[str]) -> dict:\n        \"\"\"Create a globals dictionary with only the specified allowed imports.\"\"\"\n        global_dict = {}\n\n        try:\n            if isinstance(global_imports, str):\n                modules = [module.strip() for module in global_imports.split(\",\")]\n            elif isinstance(global_imports, list):\n                modules = global_imports\n            else:\n                msg = \"global_imports must be either a string or a list\"\n                raise TypeError(msg)\n\n            for module in modules:\n                try:\n                    imported_module = importlib.import_module(module)\n                    global_dict[imported_module.__name__] = imported_module\n                except ImportError as e:\n                    msg = f\"Could not import module {module}: {e!s}\"\n                    raise ImportError(msg) from e\n\n        except Exception as e:\n            self.log(f\"Error in global imports: {e!s}\")\n            raise\n        else:\n            self.log(f\"Successfully imported modules: {list(global_dict.keys())}\")\n            return global_dict\n\n    def run_python_repl(self) -> Data:\n        try:\n            globals_ = self.get_globals(self.global_imports)\n            python_repl = PythonREPL(_globals=globals_)\n            result = python_repl.run(self.python_code)\n            result = result.strip() if result else \"\"\n\n            self.log(\"Code execution completed successfully\")\n            return Data(data={\"result\": result})\n\n        except ImportError as e:\n            error_message = f\"Import Error: {e!s}\"\n            self.log(error_message)\n            return Data(data={\"error\": error_message})\n\n        except SyntaxError as e:\n            error_message = f\"Syntax Error: {e!s}\"\n            self.log(error_message)\n            return Data(data={\"error\": error_message})\n\n        except (NameError, TypeError, ValueError) as e:\n            error_message = f\"Error during execution: {e!s}\"\n            self.log(error_message)\n            return Data(data={\"error\": error_message})\n\n    def build(self):\n        return self.run_python_repl\n"},"global_imports":{"_input_type":"StrInput","advanced":false,"display_name":"Global Imports","dynamic":false,"info":"A comma-separated list of modules to import globally, e.g. 'math,numpy,pandas'.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"global_imports","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"math,pandas"},"python_code":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Python Code","dynamic":false,"info":"The Python code to execute. Only modules specified in Global Imports can be used.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"python_code","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"print('Hello, World!')"}},"tool_mode":false},"RegexExtractorComponent":{"base_classes":["Data","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Extract patterns from text using regular expressions.","display_name":"Regex Extractor","documentation":"","edited":false,"field_order":["input_text","pattern"],"frozen":false,"icon":"regex","legacy":true,"metadata":{"code_hash":"f67d7bd7f65e","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.processing.regex.RegexExtractorComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"extract_matches","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Message","group_outputs":false,"method":"get_matches_text","name":"text","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["processing.ParserComponent"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import re\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import MessageTextInput, Output\nfrom lfx.schema.data import Data\nfrom lfx.schema.message import Message\n\n\nclass RegexExtractorComponent(Component):\n    display_name = \"Regex Extractor\"\n    description = \"Extract patterns from text using regular expressions.\"\n    icon = \"regex\"\n    legacy = True\n    replacement = [\"processing.ParserComponent\"]\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Input Text\",\n            info=\"The text to analyze\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"pattern\",\n            display_name=\"Regex Pattern\",\n            info=\"The regular expression pattern to match\",\n            value=r\"\",\n            required=True,\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"extract_matches\"),\n        Output(display_name=\"Message\", name=\"text\", method=\"get_matches_text\"),\n    ]\n\n    def extract_matches(self) -> list[Data]:\n        if not self.pattern or not self.input_text:\n            self.status = []\n            return []\n\n        try:\n            # Compile regex pattern\n            pattern = re.compile(self.pattern)\n\n            # Find all matches in the input text\n            matches = pattern.findall(self.input_text)\n\n            # Filter out empty matches\n            filtered_matches = [match for match in matches if match]  # Remove empty matches\n\n            # Return empty list for no matches, or list of matches if found\n            result: list = [] if not filtered_matches else [Data(data={\"match\": match}) for match in filtered_matches]\n\n        except re.error as e:\n            error_message = f\"Invalid regex pattern: {e!s}\"\n            result = [Data(data={\"error\": error_message})]\n        except ValueError as e:\n            error_message = f\"Error extracting matches: {e!s}\"\n            result = [Data(data={\"error\": error_message})]\n\n        self.status = result\n        return result\n\n    def get_matches_text(self) -> Message:\n        \"\"\"Get matches as a formatted text message.\"\"\"\n        matches = self.extract_matches()\n\n        if not matches:\n            message = Message(text=\"No matches found\")\n            self.status = message\n            return message\n\n        if \"error\" in matches[0].data:\n            message = Message(text=matches[0].data[\"error\"])\n            self.status = message\n            return message\n\n        result = \"\\n\".join(match.data[\"match\"] for match in matches)\n        message = Message(text=result)\n        self.status = message\n        return message\n"},"input_text":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Input Text","dynamic":false,"info":"The text to analyze","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_text","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"pattern":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Regex Pattern","dynamic":false,"info":"The regular expression pattern to match","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"pattern","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"SelectData":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Select a single data from a list of data.","display_name":"Select Data","documentation":"","edited":false,"field_order":["data_list","data_index"],"frozen":false,"icon":"prototypes","legacy":true,"metadata":{"code_hash":"0512bd98ce4d","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.processing.select_data.SelectDataComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Selected Data","group_outputs":false,"method":"select_data","name":"selected_data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["processing.DataOperations"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.inputs.inputs import DataInput, IntInput\nfrom lfx.io import Output\nfrom lfx.schema.data import Data\n\n\nclass SelectDataComponent(Component):\n    display_name: str = \"Select Data\"\n    description: str = \"Select a single data from a list of data.\"\n    name: str = \"SelectData\"\n    icon = \"prototypes\"\n    legacy = True\n    replacement = [\"processing.DataOperations\"]\n\n    inputs = [\n        DataInput(\n            name=\"data_list\",\n            display_name=\"Data List\",\n            info=\"List of data to select from.\",\n            is_list=True,  # Specify that this input takes a list of Data objects\n        ),\n        IntInput(\n            name=\"data_index\",\n            display_name=\"Data Index\",\n            info=\"Index of the data to select.\",\n            value=0,  # Will be populated dynamically based on the length of data_list\n            range_spec=RangeSpec(min=0, max=15, step=1, step_type=\"int\"),\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Selected Data\", name=\"selected_data\", method=\"select_data\"),\n    ]\n\n    async def select_data(self) -> Data:\n        # Retrieve the selected index from the dropdown\n        selected_index = int(self.data_index)\n        # Get the data list\n\n        # Validate that the selected index is within bounds\n        if selected_index < 0 or selected_index >= len(self.data_list):\n            msg = f\"Selected index {selected_index} is out of range.\"\n            raise ValueError(msg)\n\n        # Return the selected Data object\n        selected_data = self.data_list[selected_index]\n        self.status = selected_data  # Update the component status to reflect the selected data\n        return selected_data\n"},"data_index":{"_input_type":"IntInput","advanced":false,"display_name":"Data Index","dynamic":false,"info":"Index of the data to select.","list":false,"list_add_label":"Add More","name":"data_index","placeholder":"","range_spec":{"max":15.0,"min":0.0,"step":1.0,"step_type":"int"},"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":0},"data_list":{"_input_type":"DataInput","advanced":false,"display_name":"Data List","dynamic":false,"info":"List of data to select from.","input_types":["Data"],"list":true,"list_add_label":"Add More","name":"data_list","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""}},"tool_mode":false},"Smart Transform":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Uses an LLM to generate a function for filtering or transforming structured data.","display_name":"Smart Transform","documentation":"https://docs.langflow.org/components-processing#smart-transform","edited":false,"field_order":["data","llm","filter_instruction","sample_size","max_size"],"frozen":false,"icon":"square-function","legacy":false,"metadata":{"code_hash":"2925e2f08d5f","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.processing.lambda_filter.LambdaFilterComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Output","group_outputs":false,"method":"process_as_data","name":"data_output","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Output","group_outputs":false,"method":"process_as_dataframe","name":"dataframe_output","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from __future__ import annotations\n\nimport json\nimport re\nfrom typing import TYPE_CHECKING, Any\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import DataInput, HandleInput, IntInput, MultilineInput, Output\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\n\nif TYPE_CHECKING:\n    from collections.abc import Callable\n\n\nclass LambdaFilterComponent(Component):\n    display_name = \"Smart Transform\"\n    description = \"Uses an LLM to generate a function for filtering or transforming structured data.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#smart-transform\"\n    icon = \"square-function\"\n    name = \"Smart Transform\"\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The structured data to filter or transform using a lambda function.\",\n            input_types=[\"Data\", \"DataFrame\"],\n            is_list=True,\n            required=True,\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Connect the 'Language Model' output from your LLM component here.\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        MultilineInput(\n            name=\"filter_instruction\",\n            display_name=\"Instructions\",\n            info=(\n                \"Natural language instructions for how to filter or transform the data using a lambda function. \"\n                \"Example: Filter the data to only include items where the 'status' is 'active'.\"\n            ),\n            value=\"Filter the data to...\",\n            required=True,\n        ),\n        IntInput(\n            name=\"sample_size\",\n            display_name=\"Sample Size\",\n            info=\"For large datasets, number of items to sample from head/tail.\",\n            value=1000,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_size\",\n            display_name=\"Max Size\",\n            info=\"Number of characters for the data to be considered large.\",\n            value=30000,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Output\",\n            name=\"data_output\",\n            method=\"process_as_data\",\n        ),\n        Output(\n            display_name=\"Output\",\n            name=\"dataframe_output\",\n            method=\"process_as_dataframe\",\n        ),\n    ]\n\n    def get_data_structure(self, data):\n        \"\"\"Extract the structure of data, replacing values with their types.\"\"\"\n        if isinstance(data, list):\n            # For lists, get structure of first item if available\n            if data:\n                return [self.get_data_structure(data[0])]\n            return []\n        if isinstance(data, dict):\n            return {k: self.get_data_structure(v) for k, v in data.items()}\n        # For primitive types, return the type name\n        return type(data).__name__\n\n    def _validate_lambda(self, lambda_text: str) -> bool:\n        \"\"\"Validate the provided lambda function text.\"\"\"\n        # Return False if the lambda function does not start with 'lambda' or does not contain a colon\n        return lambda_text.strip().startswith(\"lambda\") and \":\" in lambda_text\n\n    async def _execute_lambda(self) -> Any:\n        self.log(str(self.data))\n\n        # Convert input to a unified format\n        if isinstance(self.data, list):\n            # Handle list of Data or DataFrame objects\n            combined_data = []\n            for item in self.data:\n                if isinstance(item, DataFrame):\n                    # DataFrame to list of dicts\n                    combined_data.extend(item.to_dict(orient=\"records\"))\n                elif hasattr(item, \"data\"):\n                    # Data object\n                    if isinstance(item.data, dict):\n                        combined_data.append(item.data)\n                    elif isinstance(item.data, list):\n                        combined_data.extend(item.data)\n\n            # If we have a single dict, unwrap it so lambdas can access it directly\n            if len(combined_data) == 1 and isinstance(combined_data[0], dict):\n                data = combined_data[0]\n            elif len(combined_data) == 0:\n                data = {}\n            else:\n                data = combined_data  # type: ignore[assignment]\n        elif isinstance(self.data, DataFrame):\n            # Single DataFrame to list of dicts\n            data = self.data.to_dict(orient=\"records\")\n        elif hasattr(self.data, \"data\"):\n            # Single Data object\n            data = self.data.data\n        else:\n            data = self.data\n\n        dump = json.dumps(data)\n        self.log(str(data))\n\n        llm = self.llm\n        instruction = self.filter_instruction\n        sample_size = self.sample_size\n\n        # Get data structure and samples\n        data_structure = self.get_data_structure(data)\n        dump_structure = json.dumps(data_structure)\n        self.log(dump_structure)\n\n        # For large datasets, sample from head and tail\n        if len(dump) > self.max_size:\n            data_sample = (\n                f\"Data is too long to display... \\n\\n First lines (head): {dump[:sample_size]} \\n\\n\"\n                f\" Last lines (tail): {dump[-sample_size:]})\"\n            )\n        else:\n            data_sample = dump\n\n        self.log(data_sample)\n\n        prompt = f\"\"\"Given this data structure and examples, create a Python lambda function that\n                    implements the following instruction:\n\n                    Data Structure:\n                    {dump_structure}\n\n                    Example Items:\n                    {data_sample}\n\n                    Instruction: {instruction}\n\n                    Return ONLY the lambda function and nothing else. No need for ```python or whatever.\n                    Just a string starting with lambda.\n                    \"\"\"\n\n        response = await llm.ainvoke(prompt)\n        response_text = response.content if hasattr(response, \"content\") else str(response)\n        self.log(response_text)\n\n        # Extract lambda using regex\n        lambda_match = re.search(r\"lambda\\s+\\w+\\s*:.*?(?=\\n|$)\", response_text)\n        if not lambda_match:\n            msg = f\"Could not find lambda in response: {response_text}\"\n            raise ValueError(msg)\n\n        lambda_text = lambda_match.group().strip()\n        self.log(lambda_text)\n\n        # Validation is commented out as requested\n        if not self._validate_lambda(lambda_text):\n            msg = f\"Invalid lambda format: {lambda_text}\"\n            raise ValueError(msg)\n\n        # Create and apply the function\n        fn: Callable[[Any], Any] = eval(lambda_text)  # noqa: S307\n\n        # Apply the lambda function to the data\n        return fn(data)\n\n    async def process_as_data(self) -> Data:\n        \"\"\"Process the data and return as a Data object.\"\"\"\n        result = await self._execute_lambda()\n\n        # Convert result to Data based on type\n        if isinstance(result, dict):\n            return Data(data=result)\n        if isinstance(result, list):\n            return Data(data={\"_results\": result})\n        # For other types, convert to string\n        return Data(data={\"text\": str(result)})\n\n    async def process_as_dataframe(self) -> DataFrame:\n        \"\"\"Process the data and return as a DataFrame.\"\"\"\n        result = await self._execute_lambda()\n\n        # Convert result to DataFrame based on type\n        if isinstance(result, list):\n            # Check if it's a list of dicts\n            if all(isinstance(item, dict) for item in result):\n                return DataFrame(result)\n            # List of non-dicts: wrap each value\n            return DataFrame([{\"value\": item} for item in result])\n        if isinstance(result, dict):\n            # Single dict becomes single-row DataFrame\n            return DataFrame([result])\n        # Other types: convert to string and wrap\n        return DataFrame([{\"value\": str(result)}])\n"},"data":{"_input_type":"DataInput","advanced":false,"display_name":"Data","dynamic":false,"info":"The structured data to filter or transform using a lambda function.","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"data","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"filter_instruction":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Instructions","dynamic":false,"info":"Natural language instructions for how to filter or transform the data using a lambda function. Example: Filter the data to only include items where the 'status' is 'active'.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"filter_instruction","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"Filter the data to..."},"llm":{"_input_type":"HandleInput","advanced":false,"display_name":"Language Model","dynamic":false,"info":"Connect the 'Language Model' output from your LLM component here.","input_types":["LanguageModel"],"list":false,"list_add_label":"Add More","name":"llm","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"max_size":{"_input_type":"IntInput","advanced":true,"display_name":"Max Size","dynamic":false,"info":"Number of characters for the data to be considered large.","list":false,"list_add_label":"Add More","name":"max_size","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":30000},"sample_size":{"_input_type":"IntInput","advanced":true,"display_name":"Sample Size","dynamic":false,"info":"For large datasets, number of items to sample from head/tail.","list":false,"list_add_label":"Add More","name":"sample_size","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1000}},"tool_mode":false},"SplitText":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Split text into chunks based on specified criteria.","display_name":"Split Text","documentation":"https://docs.langflow.org/components-processing#split-text","edited":false,"field_order":["data_inputs","chunk_overlap","chunk_size","separator","text_key","keep_separator"],"frozen":false,"icon":"scissors-line-dashed","legacy":false,"metadata":{"code_hash":"f2867efda61f","dependencies":{"dependencies":[{"name":"langchain_text_splitters","version":"0.3.11"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.processing.split_text.SplitTextComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Chunks","group_outputs":false,"method":"split_text","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","chunk_overlap":{"_input_type":"IntInput","advanced":false,"display_name":"Chunk Overlap","dynamic":false,"info":"Number of characters to overlap between chunks.","list":false,"list_add_label":"Add More","name":"chunk_overlap","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":200},"chunk_size":{"_input_type":"IntInput","advanced":false,"display_name":"Chunk Size","dynamic":false,"info":"The maximum length of each chunk. Text is first split by separator, then chunks are merged up to this size. Individual splits larger than this won't be further divided.","list":false,"list_add_label":"Add More","name":"chunk_size","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1000},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_text_splitters import CharacterTextSplitter\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.io import DropdownInput, HandleInput, IntInput, MessageTextInput, Output\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.message import Message\nfrom lfx.utils.util import unescape_string\n\n\nclass SplitTextComponent(Component):\n    display_name: str = \"Split Text\"\n    description: str = \"Split text into chunks based on specified criteria.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#split-text\"\n    icon = \"scissors-line-dashed\"\n    name = \"SplitText\"\n\n    inputs = [\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Input\",\n            info=\"The data with texts to split in chunks.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"Number of characters to overlap between chunks.\",\n            value=200,\n        ),\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=(\n                \"The maximum length of each chunk. Text is first split by separator, \"\n                \"then chunks are merged up to this size. \"\n                \"Individual splits larger than this won't be further divided.\"\n            ),\n            value=1000,\n        ),\n        MessageTextInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            info=(\n                \"The character to split on. Use \\\\n for newline. \"\n                \"Examples: \\\\n\\\\n for paragraphs, \\\\n for lines, . for sentences\"\n            ),\n            value=\"\\n\",\n        ),\n        MessageTextInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"The key to use for the text column.\",\n            value=\"text\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"keep_separator\",\n            display_name=\"Keep Separator\",\n            info=\"Whether to keep the separator in the output chunks and where to place it.\",\n            options=[\"False\", \"True\", \"Start\", \"End\"],\n            value=\"False\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chunks\", name=\"dataframe\", method=\"split_text\"),\n    ]\n\n    def _docs_to_data(self, docs) -> list[Data]:\n        return [Data(text=doc.page_content, data=doc.metadata) for doc in docs]\n\n    def _fix_separator(self, separator: str) -> str:\n        \"\"\"Fix common separator issues and convert to proper format.\"\"\"\n        if separator == \"/n\":\n            return \"\\n\"\n        if separator == \"/t\":\n            return \"\\t\"\n        return separator\n\n    def split_text_base(self):\n        separator = self._fix_separator(self.separator)\n        separator = unescape_string(separator)\n\n        if isinstance(self.data_inputs, DataFrame):\n            if not len(self.data_inputs):\n                msg = \"DataFrame is empty\"\n                raise TypeError(msg)\n\n            self.data_inputs.text_key = self.text_key\n            try:\n                documents = self.data_inputs.to_lc_documents()\n            except Exception as e:\n                msg = f\"Error converting DataFrame to documents: {e}\"\n                raise TypeError(msg) from e\n        elif isinstance(self.data_inputs, Message):\n            self.data_inputs = [self.data_inputs.to_data()]\n            return self.split_text_base()\n        else:\n            if not self.data_inputs:\n                msg = \"No data inputs provided\"\n                raise TypeError(msg)\n\n            documents = []\n            if isinstance(self.data_inputs, Data):\n                self.data_inputs.text_key = self.text_key\n                documents = [self.data_inputs.to_lc_document()]\n            else:\n                try:\n                    documents = [input_.to_lc_document() for input_ in self.data_inputs if isinstance(input_, Data)]\n                    if not documents:\n                        msg = f\"No valid Data inputs found in {type(self.data_inputs)}\"\n                        raise TypeError(msg)\n                except AttributeError as e:\n                    msg = f\"Invalid input type in collection: {e}\"\n                    raise TypeError(msg) from e\n        try:\n            # Convert string 'False'/'True' to boolean\n            keep_sep = self.keep_separator\n            if isinstance(keep_sep, str):\n                if keep_sep.lower() == \"false\":\n                    keep_sep = False\n                elif keep_sep.lower() == \"true\":\n                    keep_sep = True\n                # 'start' and 'end' are kept as strings\n\n            splitter = CharacterTextSplitter(\n                chunk_overlap=self.chunk_overlap,\n                chunk_size=self.chunk_size,\n                separator=separator,\n                keep_separator=keep_sep,\n            )\n            return splitter.split_documents(documents)\n        except Exception as e:\n            msg = f\"Error splitting text: {e}\"\n            raise TypeError(msg) from e\n\n    def split_text(self) -> DataFrame:\n        return DataFrame(self._docs_to_data(self.split_text_base()))\n"},"data_inputs":{"_input_type":"HandleInput","advanced":false,"display_name":"Input","dynamic":false,"info":"The data with texts to split in chunks.","input_types":["Data","DataFrame","Message"],"list":false,"list_add_label":"Add More","name":"data_inputs","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"keep_separator":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Keep Separator","dynamic":false,"external_options":{},"info":"Whether to keep the separator in the output chunks and where to place it.","name":"keep_separator","options":["False","True","Start","End"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"False"},"separator":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Separator","dynamic":false,"info":"The character to split on. Use \\n for newline. Examples: \\n\\n for paragraphs, \\n for lines, . for sentences","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"separator","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"\n"},"text_key":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Text Key","dynamic":false,"info":"The key to use for the text column.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"text_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"text"}},"tool_mode":false},"StructuredOutput":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Uses an LLM to generate structured data. Ideal for extraction and consistency.","display_name":"Structured Output","documentation":"https://docs.langflow.org/components-processing#structured-output","edited":false,"field_order":["llm","input_value","system_prompt","schema_name","output_schema"],"frozen":false,"icon":"braces","legacy":false,"metadata":{"code_hash":"a5b1b04d9fcc","dependencies":{"dependencies":[{"name":"pydantic","version":"2.10.6"},{"name":"trustcall","version":"0.0.39"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.processing.structured_output.StructuredOutputComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Structured Output","group_outputs":false,"method":"build_structured_output","name":"structured_output","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Structured Output","group_outputs":false,"method":"build_structured_dataframe","name":"dataframe_output","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from pydantic import BaseModel, Field, create_model\nfrom trustcall import create_extractor\n\nfrom lfx.base.models.chat_result import get_chat_result\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.helpers.base_model import build_model_from_schema\nfrom lfx.io import (\n    HandleInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n    TableInput,\n)\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.table import EditMode\n\n\nclass StructuredOutputComponent(Component):\n    display_name = \"Structured Output\"\n    description = \"Uses an LLM to generate structured data. Ideal for extraction and consistency.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#structured-output\"\n    name = \"StructuredOutput\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"The language model to use to generate the structured output.\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n        ),\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input Message\",\n            info=\"The input message to the language model.\",\n            tool_mode=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Format Instructions\",\n            info=\"The instructions to the language model for formatting the output.\",\n            value=(\n                \"You are an AI that extracts structured JSON objects from unstructured text. \"\n                \"Use a predefined schema with expected types (str, int, float, bool, dict). \"\n                \"Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. \"\n                \"Fill missing or ambiguous values with defaults: null for missing values. \"\n                \"Remove exact duplicates but keep variations that have different field values. \"\n                \"Always return valid JSON in the expected format, never throw errors. \"\n                \"If multiple objects can be extracted, return them all in the structured format.\"\n            ),\n            required=True,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"schema_name\",\n            display_name=\"Schema Name\",\n            info=\"Provide a name for the output data schema.\",\n            advanced=True,\n        ),\n        TableInput(\n            name=\"output_schema\",\n            display_name=\"Output Schema\",\n            info=\"Define the structure and data types for the model's output.\",\n            required=True,\n            # TODO: remove deault value\n            table_schema=[\n                {\n                    \"name\": \"name\",\n                    \"display_name\": \"Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Specify the name of the output field.\",\n                    \"default\": \"field\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n                {\n                    \"name\": \"description\",\n                    \"display_name\": \"Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Describe the purpose of the output field.\",\n                    \"default\": \"description of field\",\n                    \"edit_mode\": EditMode.POPOVER,\n                },\n                {\n                    \"name\": \"type\",\n                    \"display_name\": \"Type\",\n                    \"type\": \"str\",\n                    \"edit_mode\": EditMode.INLINE,\n                    \"description\": (\"Indicate the data type of the output field (e.g., str, int, float, bool, dict).\"),\n                    \"options\": [\"str\", \"int\", \"float\", \"bool\", \"dict\"],\n                    \"default\": \"str\",\n                },\n                {\n                    \"name\": \"multiple\",\n                    \"display_name\": \"As List\",\n                    \"type\": \"boolean\",\n                    \"description\": \"Set to True if this output field should be a list of the specified type.\",\n                    \"default\": \"False\",\n                    \"edit_mode\": EditMode.INLINE,\n                },\n            ],\n            value=[\n                {\n                    \"name\": \"field\",\n                    \"description\": \"description of field\",\n                    \"type\": \"str\",\n                    \"multiple\": \"False\",\n                }\n            ],\n        ),\n    ]\n\n    outputs = [\n        Output(\n            name=\"structured_output\",\n            display_name=\"Structured Output\",\n            method=\"build_structured_output\",\n        ),\n        Output(\n            name=\"dataframe_output\",\n            display_name=\"Structured Output\",\n            method=\"build_structured_dataframe\",\n        ),\n    ]\n\n    def build_structured_output_base(self):\n        schema_name = self.schema_name or \"OutputModel\"\n\n        if not hasattr(self.llm, \"with_structured_output\"):\n            msg = \"Language model does not support structured output.\"\n            raise TypeError(msg)\n        if not self.output_schema:\n            msg = \"Output schema cannot be empty\"\n            raise ValueError(msg)\n\n        output_model_ = build_model_from_schema(self.output_schema)\n\n        output_model = create_model(\n            schema_name,\n            __doc__=f\"A list of {schema_name}.\",\n            objects=(list[output_model_], Field(description=f\"A list of {schema_name}.\")),  # type: ignore[valid-type]\n        )\n\n        try:\n            llm_with_structured_output = create_extractor(self.llm, tools=[output_model])\n        except NotImplementedError as exc:\n            msg = f\"{self.llm.__class__.__name__} does not support structured output.\"\n            raise TypeError(msg) from exc\n\n        config_dict = {\n            \"run_name\": self.display_name,\n            \"project_name\": self.get_project_name(),\n            \"callbacks\": self.get_langchain_callbacks(),\n        }\n        result = get_chat_result(\n            runnable=llm_with_structured_output,\n            system_message=self.system_prompt,\n            input_value=self.input_value,\n            config=config_dict,\n        )\n\n        # OPTIMIZATION NOTE: Simplified processing based on trustcall response structure\n        # Handle non-dict responses (shouldn't happen with trustcall, but defensive)\n        if not isinstance(result, dict):\n            return result\n\n        # Extract first response and convert BaseModel to dict\n        responses = result.get(\"responses\", [])\n        if not responses:\n            return result\n\n        # Convert BaseModel to dict (creates the \"objects\" key)\n        first_response = responses[0]\n        structured_data = first_response.model_dump() if isinstance(first_response, BaseModel) else first_response\n\n        # Extract the objects array (guaranteed to exist due to our Pydantic model structure)\n        return structured_data.get(\"objects\", structured_data)\n\n    def build_structured_output(self) -> Data:\n        output = self.build_structured_output_base()\n        if not isinstance(output, list) or not output:\n            # handle empty or unexpected type case\n            msg = \"No structured output returned\"\n            raise ValueError(msg)\n        if len(output) == 1:\n            return Data(data=output[0])\n        if len(output) > 1:\n            # Multiple outputs - wrap them in a results container\n            return Data(data={\"results\": output})\n        return Data()\n\n    def build_structured_dataframe(self) -> DataFrame:\n        output = self.build_structured_output_base()\n        if not isinstance(output, list) or not output:\n            # handle empty or unexpected type case\n            msg = \"No structured output returned\"\n            raise ValueError(msg)\n        if len(output) == 1:\n            # For single dictionary, wrap in a list to create DataFrame with one row\n            return DataFrame([output[0]])\n        if len(output) > 1:\n            # Multiple outputs - convert to DataFrame directly\n            return DataFrame(output)\n        return DataFrame()\n"},"input_value":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Input Message","dynamic":false,"info":"The input message to the language model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"input_value","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"llm":{"_input_type":"HandleInput","advanced":false,"display_name":"Language Model","dynamic":false,"info":"The language model to use to generate the structured output.","input_types":["LanguageModel"],"list":false,"list_add_label":"Add More","name":"llm","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"output_schema":{"_input_type":"TableInput","advanced":false,"display_name":"Output Schema","dynamic":false,"info":"Define the structure and data types for the model's output.","is_list":true,"list_add_label":"Add More","name":"output_schema","placeholder":"","required":true,"show":true,"table_icon":"Table","table_schema":[{"default":"field","description":"Specify the name of the output field.","display_name":"Name","edit_mode":"inline","name":"name","type":"str"},{"default":"description of field","description":"Describe the purpose of the output field.","display_name":"Description","edit_mode":"popover","name":"description","type":"str"},{"default":"str","description":"Indicate the data type of the output field (e.g., str, int, float, bool, dict).","display_name":"Type","edit_mode":"inline","name":"type","options":["str","int","float","bool","dict"],"type":"str"},{"default":"False","description":"Set to True if this output field should be a list of the specified type.","display_name":"As List","edit_mode":"inline","name":"multiple","type":"boolean"}],"title_case":false,"tool_mode":false,"trace_as_metadata":true,"trigger_icon":"Table","trigger_text":"Open table","type":"table","value":[{"description":"description of field","multiple":"False","name":"field","type":"str"}]},"schema_name":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Schema Name","dynamic":false,"info":"Provide a name for the output data schema.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"schema_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"system_prompt":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"Format Instructions","dynamic":false,"info":"The instructions to the language model for formatting the output.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_prompt","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"You are an AI that extracts structured JSON objects from unstructured text. Use a predefined schema with expected types (str, int, float, bool, dict). Extract ALL relevant instances that match the schema - if multiple patterns exist, capture them all. Fill missing or ambiguous values with defaults: null for missing values. Remove exact duplicates but keep variations that have different field values. Always return valid JSON in the expected format, never throw errors. If multiple objects can be extracted, return them all in the structured format."}},"tool_mode":false},"TypeConverterComponent":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Convert between different types (Message, Data, DataFrame)","display_name":"Type Convert","documentation":"https://docs.langflow.org/components-processing#type-convert","edited":false,"field_order":["input_data","auto_parse","output_type"],"frozen":false,"icon":"repeat","legacy":false,"metadata":{"code_hash":"aac23b807182","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"pandas","version":"2.2.3"}],"total_dependencies":2},"module":"lfx.components.processing.converter.TypeConverterComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Message Output","group_outputs":false,"method":"convert_to_message","name":"message_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","auto_parse":{"_input_type":"BoolInput","advanced":true,"display_name":"Auto Parse","dynamic":false,"info":"Detect and convert JSON/CSV strings automatically.","list":false,"list_add_label":"Add More","name":"auto_parse","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nfrom typing import Any\n\nfrom lfx.custom import Component\nfrom lfx.io import BoolInput, HandleInput, Output, TabInput\nfrom lfx.schema import Data, DataFrame, Message\n\nMIN_CSV_LINES = 2\n\n\ndef convert_to_message(v) -> Message:\n    \"\"\"Convert input to Message type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        Message: Converted Message object\n    \"\"\"\n    return v if isinstance(v, Message) else v.to_message()\n\n\ndef convert_to_data(v: DataFrame | Data | Message | dict, *, auto_parse: bool) -> Data:\n    \"\"\"Convert input to Data type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n        auto_parse: Enable automatic parsing of structured data (JSON/CSV)\n\n    Returns:\n        Data: Converted Data object\n    \"\"\"\n    if isinstance(v, dict):\n        return Data(v)\n    if isinstance(v, Message):\n        data = Data(data={\"text\": v.data[\"text\"]})\n        return parse_structured_data(data) if auto_parse else data\n\n    return v if isinstance(v, Data) else v.to_data()\n\n\ndef convert_to_dataframe(v: DataFrame | Data | Message | dict, *, auto_parse: bool) -> DataFrame:\n    \"\"\"Convert input to DataFrame type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n        auto_parse: Enable automatic parsing of structured data (JSON/CSV)\n\n    Returns:\n        DataFrame: Converted DataFrame object\n    \"\"\"\n    import pandas as pd\n\n    if isinstance(v, dict):\n        return DataFrame([v])\n    if isinstance(v, DataFrame):\n        return v\n    # Handle pandas DataFrame\n    if isinstance(v, pd.DataFrame):\n        # Convert pandas DataFrame to our DataFrame by creating Data objects\n        return DataFrame(data=v)\n\n    if isinstance(v, Message):\n        data = Data(data={\"text\": v.data[\"text\"]})\n        return parse_structured_data(data).to_dataframe() if auto_parse else data.to_dataframe()\n    # For other types, call to_dataframe method\n    return v.to_dataframe()\n\n\ndef parse_structured_data(data: Data) -> Data:\n    \"\"\"Parse structured data (JSON, CSV) from Data's text field.\n\n    Args:\n        data: Data object with text content to parse\n\n    Returns:\n        Data: Modified Data object with parsed content or original if parsing fails\n    \"\"\"\n    raw_text = data.get_text() or \"\"\n    text = raw_text.lstrip(\"\\ufeff\").strip()\n\n    # Try JSON parsing first\n    parsed_json = _try_parse_json(text)\n    if parsed_json is not None:\n        return parsed_json\n\n    # Try CSV parsing\n    if _looks_like_csv(text):\n        try:\n            return _parse_csv_to_data(text)\n        except Exception:  # noqa: BLE001\n            # Heuristic misfire or malformed CSV — keep original data\n            return data\n\n    # Return original data if no parsing succeeded\n    return data\n\n\ndef _try_parse_json(text: str) -> Data | None:\n    \"\"\"Try to parse text as JSON and return Data object.\"\"\"\n    try:\n        parsed = json.loads(text)\n\n        if isinstance(parsed, dict):\n            # Single JSON object\n            return Data(data=parsed)\n        if isinstance(parsed, list) and all(isinstance(item, dict) for item in parsed):\n            # Array of JSON objects - create Data with the list\n            return Data(data={\"records\": parsed})\n\n    except (json.JSONDecodeError, ValueError):\n        pass\n\n    return None\n\n\ndef _looks_like_csv(text: str) -> bool:\n    \"\"\"Simple heuristic to detect CSV content.\"\"\"\n    lines = text.strip().split(\"\\n\")\n    if len(lines) < MIN_CSV_LINES:\n        return False\n\n    header_line = lines[0]\n    return \",\" in header_line and len(lines) > 1\n\n\ndef _parse_csv_to_data(text: str) -> Data:\n    \"\"\"Parse CSV text and return Data object.\"\"\"\n    from io import StringIO\n\n    import pandas as pd\n\n    # Parse CSV to DataFrame, then convert to list of dicts\n    parsed_df = pd.read_csv(StringIO(text))\n    records = parsed_df.to_dict(orient=\"records\")\n\n    return Data(data={\"records\": records})\n\n\nclass TypeConverterComponent(Component):\n    display_name = \"Type Convert\"\n    description = \"Convert between different types (Message, Data, DataFrame)\"\n    documentation: str = \"https://docs.langflow.org/components-processing#type-convert\"\n    icon = \"repeat\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Input\",\n            input_types=[\"Message\", \"Data\", \"DataFrame\"],\n            info=\"Accept Message, Data or DataFrame as input\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"auto_parse\",\n            display_name=\"Auto Parse\",\n            info=\"Detect and convert JSON/CSV strings automatically.\",\n            advanced=True,\n            value=False,\n            required=False,\n        ),\n        TabInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Message\", \"Data\", \"DataFrame\"],\n            info=\"Select the desired output data type\",\n            real_time_refresh=True,\n            value=\"Message\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message Output\",\n            name=\"message_output\",\n            method=\"convert_to_message\",\n        )\n    ]\n\n    def update_outputs(self, frontend_node: dict, field_name: str, field_value: Any) -> dict:\n        \"\"\"Dynamically show only the relevant output based on the selected output type.\"\"\"\n        if field_name == \"output_type\":\n            # Start with empty outputs\n            frontend_node[\"outputs\"] = []\n\n            # Add only the selected output type\n            if field_value == \"Message\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"Message Output\",\n                        name=\"message_output\",\n                        method=\"convert_to_message\",\n                    ).to_dict()\n                )\n            elif field_value == \"Data\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"Data Output\",\n                        name=\"data_output\",\n                        method=\"convert_to_data\",\n                    ).to_dict()\n                )\n            elif field_value == \"DataFrame\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"DataFrame Output\",\n                        name=\"dataframe_output\",\n                        method=\"convert_to_dataframe\",\n                    ).to_dict()\n                )\n\n        return frontend_node\n\n    def convert_to_message(self) -> Message:\n        \"\"\"Convert input to Message type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_message(input_value)\n        self.status = result\n        return result\n\n    def convert_to_data(self) -> Data:\n        \"\"\"Convert input to Data type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_data(input_value, auto_parse=self.auto_parse)\n        self.status = result\n        return result\n\n    def convert_to_dataframe(self) -> DataFrame:\n        \"\"\"Convert input to DataFrame type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_dataframe(input_value, auto_parse=self.auto_parse)\n        self.status = result\n        return result\n"},"input_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Input","dynamic":false,"info":"Accept Message, Data or DataFrame as input","input_types":["Message","Data","DataFrame"],"list":false,"list_add_label":"Add More","name":"input_data","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"output_type":{"_input_type":"TabInput","advanced":false,"display_name":"Output Type","dynamic":false,"info":"Select the desired output data type","name":"output_type","options":["Message","Data","DataFrame"],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"tab","value":"Message"}},"tool_mode":false},"UpdateData":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Dynamically update or append data with the specified fields.","display_name":"Update Data","documentation":"","edited":false,"field_order":["old_data","number_of_fields","text_key","text_key_validator"],"frozen":false,"icon":"FolderSync","legacy":true,"metadata":{"code_hash":"d0790af3ac9b","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.processing.update_data.UpdateDataComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"build_data","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["processing.DataOperations"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.inputs.inputs import (\n    BoolInput,\n    DataInput,\n    DictInput,\n    IntInput,\n    MessageTextInput,\n)\nfrom lfx.io import Output\nfrom lfx.schema.data import Data\nfrom lfx.schema.dotdict import dotdict\n\n\nclass UpdateDataComponent(Component):\n    display_name: str = \"Update Data\"\n    description: str = \"Dynamically update or append data with the specified fields.\"\n    name: str = \"UpdateData\"\n    MAX_FIELDS = 15  # Define a constant for maximum number of fields\n    icon = \"FolderSync\"\n    legacy = True\n    replacement = [\"processing.DataOperations\"]\n\n    inputs = [\n        DataInput(\n            name=\"old_data\",\n            display_name=\"Data\",\n            info=\"The record to update.\",\n            is_list=True,  # Changed to True to handle list of Data objects\n            required=True,\n        ),\n        IntInput(\n            name=\"number_of_fields\",\n            display_name=\"Number of Fields\",\n            info=\"Number of fields to be added to the record.\",\n            real_time_refresh=True,\n            value=0,\n            range_spec=RangeSpec(min=1, max=MAX_FIELDS, step=1, step_type=\"int\"),\n        ),\n        MessageTextInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"Key that identifies the field to be used as the text content.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"text_key_validator\",\n            display_name=\"Text Key Validator\",\n            advanced=True,\n            info=\"If enabled, checks if the given 'Text Key' is present in the given 'Data'.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"build_data\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        \"\"\"Update the build configuration when the number of fields changes.\n\n        Args:\n            build_config (dotdict): The current build configuration.\n            field_value (Any): The new value for the field.\n            field_name (Optional[str]): The name of the field being updated.\n        \"\"\"\n        if field_name == \"number_of_fields\":\n            default_keys = {\n                \"code\",\n                \"_type\",\n                \"number_of_fields\",\n                \"text_key\",\n                \"old_data\",\n                \"text_key_validator\",\n            }\n            try:\n                field_value_int = int(field_value)\n            except ValueError:\n                return build_config\n\n            if field_value_int > self.MAX_FIELDS:\n                build_config[\"number_of_fields\"][\"value\"] = self.MAX_FIELDS\n                msg = f\"Number of fields cannot exceed {self.MAX_FIELDS}. Try using a Component to combine two Data.\"\n                raise ValueError(msg)\n\n            existing_fields = {}\n            # Back up the existing template fields\n            for key in list(build_config.keys()):\n                if key not in default_keys:\n                    existing_fields[key] = build_config.pop(key)\n\n            for i in range(1, field_value_int + 1):\n                key = f\"field_{i}_key\"\n                if key in existing_fields:\n                    field = existing_fields[key]\n                    build_config[key] = field\n                else:\n                    field = DictInput(\n                        display_name=f\"Field {i}\",\n                        name=key,\n                        info=f\"Key for field {i}.\",\n                        input_types=[\"Message\", \"Data\"],\n                    )\n                    build_config[field.name] = field.to_dict()\n\n            build_config[\"number_of_fields\"][\"value\"] = field_value_int\n        return build_config\n\n    async def build_data(self) -> Data | list[Data]:\n        \"\"\"Build the updated data by combining the old data with new fields.\"\"\"\n        new_data = self.get_data()\n        if isinstance(self.old_data, list):\n            for data_item in self.old_data:\n                if not isinstance(data_item, Data):\n                    continue  # Skip invalid items\n                data_item.data.update(new_data)\n                if self.text_key:\n                    data_item.text_key = self.text_key\n                self.validate_text_key(data_item)\n            self.status = self.old_data\n            return self.old_data  # Returns List[Data]\n        if isinstance(self.old_data, Data):\n            self.old_data.data.update(new_data)\n            if self.text_key:\n                self.old_data.text_key = self.text_key\n            self.status = self.old_data\n            self.validate_text_key(self.old_data)\n            return self.old_data  # Returns Data\n        msg = \"old_data is not a Data object or list of Data objects.\"\n        raise ValueError(msg)\n\n    def get_data(self):\n        \"\"\"Function to get the Data from the attributes.\"\"\"\n        data = {}\n        default_keys = {\n            \"code\",\n            \"_type\",\n            \"number_of_fields\",\n            \"text_key\",\n            \"old_data\",\n            \"text_key_validator\",\n        }\n        for attr_name, attr_value in self._attributes.items():\n            if attr_name in default_keys:\n                continue  # Skip default attributes\n            if isinstance(attr_value, dict):\n                for key, value in attr_value.items():\n                    data[key] = value.get_text() if isinstance(value, Data) else value\n            elif isinstance(attr_value, Data):\n                data[attr_name] = attr_value.get_text()\n            else:\n                data[attr_name] = attr_value\n        return data\n\n    def validate_text_key(self, data: Data) -> None:\n        \"\"\"This function validates that the Text Key is one of the keys in the Data.\"\"\"\n        data_keys = data.data.keys()\n        if self.text_key and self.text_key not in data_keys:\n            msg = f\"Text Key: '{self.text_key}' not found in the Data keys: {', '.join(data_keys)}\"\n            raise ValueError(msg)\n"},"number_of_fields":{"_input_type":"IntInput","advanced":false,"display_name":"Number of Fields","dynamic":false,"info":"Number of fields to be added to the record.","list":false,"list_add_label":"Add More","name":"number_of_fields","placeholder":"","range_spec":{"max":15.0,"min":1.0,"step":1.0,"step_type":"int"},"real_time_refresh":true,"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":0},"old_data":{"_input_type":"DataInput","advanced":false,"display_name":"Data","dynamic":false,"info":"The record to update.","input_types":["Data"],"list":true,"list_add_label":"Add More","name":"old_data","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""},"text_key":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Text Key","dynamic":false,"info":"Key that identifies the field to be used as the text content.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"text_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"text_key_validator":{"_input_type":"BoolInput","advanced":true,"display_name":"Text Key Validator","dynamic":false,"info":"If enabled, checks if the given 'Text Key' is present in the given 'Data'.","list":false,"list_add_label":"Add More","name":"text_key_validator","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false}}],["prototypes",{"PythonFunction":{"base_classes":["Callable","Data","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Define and execute a Python function that returns a Data object or a Message.","display_name":"Python Function","documentation":"","edited":false,"field_order":["function_code"],"frozen":false,"icon":"Python","legacy":true,"metadata":{"code_hash":"7da7d856a545","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.prototypes.python_function.PythonFunctionComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Function Callable","group_outputs":false,"method":"get_function_callable","name":"function_output","selected":"Callable","tool_mode":true,"types":["Callable"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Function Output (Data)","group_outputs":false,"method":"execute_function_data","name":"function_output_data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Function Output (Message)","group_outputs":false,"method":"execute_function_message","name":"function_output_str","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from collections.abc import Callable\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.custom.utils import get_function\nfrom lfx.io import CodeInput, Output\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.dotdict import dotdict\nfrom lfx.schema.message import Message\n\n\nclass PythonFunctionComponent(Component):\n    display_name = \"Python Function\"\n    description = \"Define and execute a Python function that returns a Data object or a Message.\"\n    icon = \"Python\"\n    name = \"PythonFunction\"\n    legacy = True\n\n    inputs = [\n        CodeInput(\n            name=\"function_code\",\n            display_name=\"Function Code\",\n            info=\"The code for the function.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            name=\"function_output\",\n            display_name=\"Function Callable\",\n            method=\"get_function_callable\",\n        ),\n        Output(\n            name=\"function_output_data\",\n            display_name=\"Function Output (Data)\",\n            method=\"execute_function_data\",\n        ),\n        Output(\n            name=\"function_output_str\",\n            display_name=\"Function Output (Message)\",\n            method=\"execute_function_message\",\n        ),\n    ]\n\n    def get_function_callable(self) -> Callable:\n        function_code = self.function_code\n        self.status = function_code\n        return get_function(function_code)\n\n    def execute_function(self) -> list[dotdict | str] | dotdict | str:\n        function_code = self.function_code\n\n        if not function_code:\n            return \"No function code provided.\"\n\n        try:\n            func = get_function(function_code)\n            return func()\n        except Exception as e:  # noqa: BLE001\n            logger.debug(\"Error executing function\", exc_info=True)\n            return f\"Error executing function: {e}\"\n\n    def execute_function_data(self) -> list[Data]:\n        results = self.execute_function()\n        results = results if isinstance(results, list) else [results]\n        return [(Data(text=x) if isinstance(x, str) else Data(**x)) for x in results]\n\n    def execute_function_message(self) -> Message:\n        results = self.execute_function()\n        results = results if isinstance(results, list) else [results]\n        results_list = [str(x) for x in results]\n        results_str = \"\\n\".join(results_list)\n        return Message(text=results_str)\n"},"function_code":{"_input_type":"CodeInput","advanced":false,"display_name":"Function Code","dynamic":false,"info":"The code for the function.","list":false,"list_add_label":"Add More","name":"function_code","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"code","value":""}},"tool_mode":false}}],["qdrant",{"QdrantVectorStoreComponent":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Qdrant Vector Store with search capabilities","display_name":"Qdrant","documentation":"","edited":false,"field_order":["collection_name","host","port","grpc_port","api_key","prefix","timeout","path","url","distance_func","content_payload_key","metadata_payload_key","ingest_data","search_query","should_cache_vector_store","embedding","number_of_results"],"frozen":false,"icon":"Qdrant","legacy":false,"metadata":{"code_hash":"f7caea98ea75","dependencies":{"dependencies":[{"name":"langchain","version":"0.3.23"},{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null},{"name":"qdrant_client","version":"1.9.2"}],"total_dependencies":4},"module":"lfx.components.qdrant.qdrant.QdrantVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":true,"display_name":"Qdrant API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain.embeddings.base import Embeddings\nfrom langchain_community.vectorstores import Qdrant\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.io import (\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass QdrantVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Qdrant\"\n    description = \"Qdrant Vector Store with search capabilities\"\n    icon = \"Qdrant\"\n\n    inputs = [\n        StrInput(name=\"collection_name\", display_name=\"Collection Name\", required=True),\n        StrInput(name=\"host\", display_name=\"Host\", value=\"localhost\", advanced=True),\n        IntInput(name=\"port\", display_name=\"Port\", value=6333, advanced=True),\n        IntInput(name=\"grpc_port\", display_name=\"gRPC Port\", value=6334, advanced=True),\n        SecretStrInput(name=\"api_key\", display_name=\"Qdrant API Key\", advanced=True),\n        StrInput(name=\"prefix\", display_name=\"Prefix\", advanced=True),\n        IntInput(name=\"timeout\", display_name=\"Timeout\", advanced=True),\n        StrInput(name=\"path\", display_name=\"Path\", advanced=True),\n        StrInput(name=\"url\", display_name=\"URL\", advanced=True),\n        DropdownInput(\n            name=\"distance_func\",\n            display_name=\"Distance Function\",\n            options=[\"Cosine\", \"Euclidean\", \"Dot Product\"],\n            value=\"Cosine\",\n            advanced=True,\n        ),\n        StrInput(name=\"content_payload_key\", display_name=\"Content Payload Key\", value=\"page_content\", advanced=True),\n        StrInput(name=\"metadata_payload_key\", display_name=\"Metadata Payload Key\", value=\"metadata\", advanced=True),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> Qdrant:\n        qdrant_kwargs = {\n            \"collection_name\": self.collection_name,\n            \"content_payload_key\": self.content_payload_key,\n            \"metadata_payload_key\": self.metadata_payload_key,\n        }\n\n        server_kwargs = {\n            \"host\": self.host or None,\n            \"port\": int(self.port),  # Ensure port is an integer\n            \"grpc_port\": int(self.grpc_port),  # Ensure grpc_port is an integer\n            \"api_key\": self.api_key,\n            \"prefix\": self.prefix,\n            # Ensure timeout is an integer\n            \"timeout\": int(self.timeout) if self.timeout else None,\n            \"path\": self.path or None,\n            \"url\": self.url or None,\n        }\n\n        server_kwargs = {k: v for k, v in server_kwargs.items() if v is not None}\n\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if not isinstance(self.embedding, Embeddings):\n            msg = \"Invalid embedding object\"\n            raise TypeError(msg)\n\n        if documents:\n            qdrant = Qdrant.from_documents(documents, embedding=self.embedding, **qdrant_kwargs, **server_kwargs)\n        else:\n            from qdrant_client import QdrantClient\n\n            client = QdrantClient(**server_kwargs)\n            qdrant = Qdrant(embeddings=self.embedding, client=client, **qdrant_kwargs)\n\n        return qdrant\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n"},"collection_name":{"_input_type":"StrInput","advanced":false,"display_name":"Collection Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"content_payload_key":{"_input_type":"StrInput","advanced":true,"display_name":"Content Payload Key","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"content_payload_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"page_content"},"distance_func":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Distance Function","dynamic":false,"external_options":{},"info":"","name":"distance_func","options":["Cosine","Euclidean","Dot Product"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Cosine"},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"grpc_port":{"_input_type":"IntInput","advanced":true,"display_name":"gRPC Port","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"grpc_port","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":6334},"host":{"_input_type":"StrInput","advanced":true,"display_name":"Host","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"host","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"localhost"},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"metadata_payload_key":{"_input_type":"StrInput","advanced":true,"display_name":"Metadata Payload Key","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"metadata_payload_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"metadata"},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"path":{"_input_type":"StrInput","advanced":true,"display_name":"Path","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"path","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"port":{"_input_type":"IntInput","advanced":true,"display_name":"Port","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"port","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":6333},"prefix":{"_input_type":"StrInput","advanced":true,"display_name":"Prefix","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"prefix","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"timeout":{"_input_type":"IntInput","advanced":true,"display_name":"Timeout","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"url":{"_input_type":"StrInput","advanced":true,"display_name":"URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["redis",{"Redis":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Implementation of Vector Store using Redis","display_name":"Redis","documentation":"","edited":false,"field_order":["redis_server_url","redis_index_name","code","schema","ingest_data","search_query","should_cache_vector_store","number_of_results","embedding"],"frozen":false,"icon":"Redis","legacy":false,"metadata":{"code_hash":"f2b0a3adecae","dependencies":{"dependencies":[{"name":"langchain","version":"0.3.23"},{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.redis.redis.RedisVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from pathlib import Path\n\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain_community.vectorstores.redis import Redis\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.io import HandleInput, IntInput, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass RedisVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"A custom component for implementing a Vector Store using Redis.\"\"\"\n\n    display_name: str = \"Redis\"\n    description: str = \"Implementation of Vector Store using Redis\"\n    name = \"Redis\"\n    icon = \"Redis\"\n\n    inputs = [\n        SecretStrInput(name=\"redis_server_url\", display_name=\"Redis Server Connection String\", required=True),\n        StrInput(\n            name=\"redis_index_name\",\n            display_name=\"Redis Index\",\n        ),\n        StrInput(name=\"code\", display_name=\"Code\", advanced=True),\n        StrInput(\n            name=\"schema\",\n            display_name=\"Schema\",\n        ),\n        *LCVectorStoreComponent.inputs,\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> Redis:\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n        Path(\"docuemnts.txt\").write_text(str(documents), encoding=\"utf-8\")\n\n        if not documents:\n            if self.schema is None:\n                msg = \"If no documents are provided, a schema must be provided.\"\n                raise ValueError(msg)\n            redis_vs = Redis.from_existing_index(\n                embedding=self.embedding,\n                index_name=self.redis_index_name,\n                schema=self.schema,\n                key_prefix=None,\n                redis_url=self.redis_server_url,\n            )\n        else:\n            text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n            docs = text_splitter.split_documents(documents)\n            redis_vs = Redis.from_documents(\n                documents=docs,\n                embedding=self.embedding,\n                redis_url=self.redis_server_url,\n                index_name=self.redis_index_name,\n            )\n        return redis_vs\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n"},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"redis_index_name":{"_input_type":"StrInput","advanced":false,"display_name":"Redis Index","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"redis_index_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"redis_server_url":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Redis Server Connection String","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"redis_server_url","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"schema":{"_input_type":"StrInput","advanced":false,"display_name":"Schema","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"schema","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false},"RedisChatMemory":{"base_classes":["Memory"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Retrieves and store chat messages from Redis.","display_name":"Redis Chat Memory","documentation":"","edited":false,"field_order":["host","port","database","username","password","key_prefix","session_id"],"frozen":false,"icon":"Redis","legacy":false,"metadata":{"code_hash":"01ec6e1e34a8","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.redis.redis_chat.RedisIndexChatMemory"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Memory","group_outputs":false,"method":"build_message_history","name":"memory","selected":"Memory","tool_mode":true,"types":["Memory"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from urllib import parse\n\nfrom langchain_community.chat_message_histories.redis import RedisChatMessageHistory\n\nfrom lfx.base.memory.model import LCChatMemoryComponent\nfrom lfx.field_typing.constants import Memory\nfrom lfx.inputs.inputs import IntInput, MessageTextInput, SecretStrInput, StrInput\n\n\nclass RedisIndexChatMemory(LCChatMemoryComponent):\n    display_name = \"Redis Chat Memory\"\n    description = \"Retrieves and store chat messages from Redis.\"\n    name = \"RedisChatMemory\"\n    icon = \"Redis\"\n\n    inputs = [\n        StrInput(\n            name=\"host\", display_name=\"hostname\", required=True, value=\"localhost\", info=\"IP address or hostname.\"\n        ),\n        IntInput(name=\"port\", display_name=\"port\", required=True, value=6379, info=\"Redis Port Number.\"),\n        StrInput(name=\"database\", display_name=\"database\", required=True, value=\"0\", info=\"Redis database.\"),\n        MessageTextInput(\n            name=\"username\", display_name=\"Username\", value=\"\", info=\"The Redis user name.\", advanced=True\n        ),\n        SecretStrInput(\n            name=\"password\", display_name=\"Redis Password\", value=\"\", info=\"The password for username.\", advanced=True\n        ),\n        StrInput(name=\"key_prefix\", display_name=\"Key prefix\", info=\"Key prefix.\", advanced=True),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n    ]\n\n    def build_message_history(self) -> Memory:\n        kwargs = {}\n        password: str | None = self.password\n        if self.key_prefix:\n            kwargs[\"key_prefix\"] = self.key_prefix\n        if password:\n            password = parse.quote_plus(password)\n\n        url = f\"redis://{self.username}:{self.password}@{self.host}:{self.port}/{self.database}\"\n        return RedisChatMessageHistory(session_id=self.session_id, url=url, **kwargs)\n"},"database":{"_input_type":"StrInput","advanced":false,"display_name":"database","dynamic":false,"info":"Redis database.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"database","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"0"},"host":{"_input_type":"StrInput","advanced":false,"display_name":"hostname","dynamic":false,"info":"IP address or hostname.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"host","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"localhost"},"key_prefix":{"_input_type":"StrInput","advanced":true,"display_name":"Key prefix","dynamic":false,"info":"Key prefix.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"key_prefix","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"password":{"_input_type":"SecretStrInput","advanced":true,"display_name":"Redis Password","dynamic":false,"info":"The password for username.","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"port":{"_input_type":"IntInput","advanced":false,"display_name":"port","dynamic":false,"info":"Redis Port Number.","list":false,"list_add_label":"Add More","name":"port","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":6379},"session_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Session ID","dynamic":false,"info":"Session ID for the message.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"session_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Username","dynamic":false,"info":"The Redis user name.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["sambanova",{"SambaNovaModel":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate text using Sambanova LLMs.","display_name":"SambaNova","documentation":"https://cloud.sambanova.ai/","edited":false,"field_order":["input_value","system_message","stream","base_url","model_name","api_key","max_tokens","top_p","temperature"],"frozen":false,"icon":"SambaNova","legacy":false,"metadata":{"code_hash":"f12728900b8d","dependencies":{"dependencies":[{"name":"langchain_sambanova","version":"0.1.0"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":3},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.sambanova.sambanova.SambaNovaComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Sambanova API Key","dynamic":false,"info":"The Sambanova API Key to use for the Sambanova model.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"SAMBANOVA_API_KEY"},"base_url":{"_input_type":"StrInput","advanced":true,"display_name":"SambaNova Cloud Base Url","dynamic":false,"info":"The base URL of the Sambanova Cloud API. Defaults to https://api.sambanova.ai/v1/chat/completions. You can change this to use other urls like Sambastudio","list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_sambanova import ChatSambaNovaCloud\nfrom pydantic.v1 import SecretStr\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.base.models.sambanova_constants import SAMBANOVA_MODEL_NAMES\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.io import DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\n\n\nclass SambaNovaComponent(LCModelComponent):\n    display_name = \"SambaNova\"\n    description = \"Generate text using Sambanova LLMs.\"\n    documentation = \"https://cloud.sambanova.ai/\"\n    icon = \"SambaNova\"\n    name = \"SambaNovaModel\"\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        StrInput(\n            name=\"base_url\",\n            display_name=\"SambaNova Cloud Base Url\",\n            advanced=True,\n            info=\"The base URL of the Sambanova Cloud API. \"\n            \"Defaults to https://api.sambanova.ai/v1/chat/completions. \"\n            \"You can change this to use other urls like Sambastudio\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=SAMBANOVA_MODEL_NAMES,\n            value=SAMBANOVA_MODEL_NAMES[0],\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Sambanova API Key\",\n            info=\"The Sambanova API Key to use for the Sambanova model.\",\n            advanced=False,\n            value=\"SAMBANOVA_API_KEY\",\n            required=True,\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            value=2048,\n            info=\"The maximum number of tokens to generate.\",\n        ),\n        SliderInput(\n            name=\"top_p\",\n            display_name=\"top_p\",\n            advanced=True,\n            value=1.0,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            info=\"Model top_p\",\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        sambanova_url = self.base_url\n        sambanova_api_key = self.api_key\n        model_name = self.model_name\n        max_tokens = self.max_tokens\n        top_p = self.top_p\n        temperature = self.temperature\n\n        api_key = SecretStr(sambanova_api_key).get_secret_value() if sambanova_api_key else None\n\n        return ChatSambaNovaCloud(\n            model=model_name,\n            max_tokens=max_tokens or 1024,\n            temperature=temperature or 0.07,\n            top_p=top_p,\n            sambanova_url=sambanova_url,\n            sambanova_api_key=api_key,\n        )\n"},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"max_tokens":{"_input_type":"IntInput","advanced":true,"display_name":"Max Tokens","dynamic":false,"info":"The maximum number of tokens to generate.","list":false,"list_add_label":"Add More","name":"max_tokens","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":2048},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model Name","dynamic":false,"external_options":{},"info":"","name":"model_name","options":["Meta-Llama-3.3-70B-Instruct","Meta-Llama-3.1-8B-Instruct","Meta-Llama-3.1-70B-Instruct","Meta-Llama-3.1-405B-Instruct","DeepSeek-R1-Distill-Llama-70B","DeepSeek-R1","Meta-Llama-3.2-1B-Instruct","Meta-Llama-3.2-3B-Instruct","Llama-3.2-11B-Vision-Instruct","Llama-3.2-90B-Vision-Instruct","Qwen2.5-Coder-32B-Instruct","Qwen2.5-72B-Instruct","QwQ-32B-Preview","Qwen2-Audio-7B-Instruct"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Meta-Llama-3.3-70B-Instruct"},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"SliderInput","advanced":true,"display_name":"Temperature","dynamic":false,"info":"","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"temperature","placeholder":"","range_spec":{"max":2.0,"min":0.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":0.1},"top_p":{"_input_type":"SliderInput","advanced":true,"display_name":"top_p","dynamic":false,"info":"Model top_p","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"top_p","placeholder":"","range_spec":{"max":1.0,"min":0.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":1.0}},"tool_mode":false}}],["scrapegraph",{"ScrapeGraphMarkdownifyApi":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Given a URL, it will return the markdownified content of the website.","display_name":"ScrapeGraph Markdownify API","documentation":"https://docs.scrapegraphai.com/services/markdownify","edited":false,"field_order":["api_key","url"],"frozen":false,"legacy":false,"metadata":{"code_hash":"0f5f12091af6","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"scrapegraph_py","version":"1.34.0"}],"total_dependencies":2},"module":"lfx.components.scrapegraph.scrapegraph_markdownify_api.ScrapeGraphMarkdownifyApi"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"scrape","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"ScrapeGraph API Key","dynamic":false,"info":"The API key to use ScrapeGraph API.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.io import (\n    MessageTextInput,\n    Output,\n    SecretStrInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass ScrapeGraphMarkdownifyApi(Component):\n    display_name: str = \"ScrapeGraph Markdownify API\"\n    description: str = \"Given a URL, it will return the markdownified content of the website.\"\n    name = \"ScrapeGraphMarkdownifyApi\"\n\n    output_types: list[str] = [\"Document\"]\n    documentation: str = \"https://docs.scrapegraphai.com/services/markdownify\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"ScrapeGraph API Key\",\n            required=True,\n            password=True,\n            info=\"The API key to use ScrapeGraph API.\",\n        ),\n        MessageTextInput(\n            name=\"url\",\n            display_name=\"URL\",\n            tool_mode=True,\n            info=\"The URL to markdownify.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"scrape\"),\n    ]\n\n    def scrape(self) -> list[Data]:\n        try:\n            from scrapegraph_py import Client\n            from scrapegraph_py.logger import sgai_logger\n        except ImportError as e:\n            msg = \"Could not import scrapegraph-py package. Please install it with `pip install scrapegraph-py`.\"\n            raise ImportError(msg) from e\n\n        # Set logging level\n        sgai_logger.set_logging(level=\"INFO\")\n\n        # Initialize the client with API key\n        sgai_client = Client(api_key=self.api_key)\n\n        try:\n            # Markdownify request\n            response = sgai_client.markdownify(\n                website_url=self.url,\n            )\n\n            # Close the client\n            sgai_client.close()\n\n            return Data(data=response)\n        except Exception:\n            sgai_client.close()\n            raise\n"},"url":{"_input_type":"MessageTextInput","advanced":false,"display_name":"URL","dynamic":false,"info":"The URL to markdownify.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ScrapeGraphSearchApi":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Given a search prompt, it will return search results using ScrapeGraph's search functionality.","display_name":"ScrapeGraph Search API","documentation":"https://docs.scrapegraphai.com/services/searchscraper","edited":false,"field_order":["api_key","user_prompt"],"frozen":false,"icon":"ScrapeGraph","legacy":false,"metadata":{"code_hash":"002d2af653ef","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"scrapegraph_py","version":"1.34.0"}],"total_dependencies":2},"module":"lfx.components.scrapegraph.scrapegraph_search_api.ScrapeGraphSearchApi"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"search","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"ScrapeGraph API Key","dynamic":false,"info":"The API key to use ScrapeGraph API.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.io import (\n    MessageTextInput,\n    Output,\n    SecretStrInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass ScrapeGraphSearchApi(Component):\n    display_name: str = \"ScrapeGraph Search API\"\n    description: str = \"Given a search prompt, it will return search results using ScrapeGraph's search functionality.\"\n    name = \"ScrapeGraphSearchApi\"\n\n    documentation: str = \"https://docs.scrapegraphai.com/services/searchscraper\"\n    icon = \"ScrapeGraph\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"ScrapeGraph API Key\",\n            required=True,\n            password=True,\n            info=\"The API key to use ScrapeGraph API.\",\n        ),\n        MessageTextInput(\n            name=\"user_prompt\",\n            display_name=\"Search Prompt\",\n            tool_mode=True,\n            info=\"The search prompt to use.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"search\"),\n    ]\n\n    def search(self) -> list[Data]:\n        try:\n            from scrapegraph_py import Client\n            from scrapegraph_py.logger import sgai_logger\n        except ImportError as e:\n            msg = \"Could not import scrapegraph-py package. Please install it with `pip install scrapegraph-py`.\"\n            raise ImportError(msg) from e\n\n        # Set logging level\n        sgai_logger.set_logging(level=\"INFO\")\n\n        # Initialize the client with API key\n        sgai_client = Client(api_key=self.api_key)\n\n        try:\n            # SearchScraper request\n            response = sgai_client.searchscraper(\n                user_prompt=self.user_prompt,\n            )\n\n            # Close the client\n            sgai_client.close()\n\n            return Data(data=response)\n        except Exception:\n            sgai_client.close()\n            raise\n"},"user_prompt":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Search Prompt","dynamic":false,"info":"The search prompt to use.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"user_prompt","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"ScrapeGraphSmartScraperApi":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Given a URL, it will return the structured data of the website.","display_name":"ScrapeGraph Smart Scraper API","documentation":"https://docs.scrapegraphai.com/services/smartscraper","edited":false,"field_order":["api_key","url","prompt"],"frozen":false,"legacy":false,"metadata":{"code_hash":"cb419bec02ed","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"scrapegraph_py","version":"1.34.0"}],"total_dependencies":2},"module":"lfx.components.scrapegraph.scrapegraph_smart_scraper_api.ScrapeGraphSmartScraperApi"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"scrape","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"ScrapeGraph API Key","dynamic":false,"info":"The API key to use ScrapeGraph API.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.io import (\n    MessageTextInput,\n    Output,\n    SecretStrInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass ScrapeGraphSmartScraperApi(Component):\n    display_name: str = \"ScrapeGraph Smart Scraper API\"\n    description: str = \"Given a URL, it will return the structured data of the website.\"\n    name = \"ScrapeGraphSmartScraperApi\"\n\n    output_types: list[str] = [\"Document\"]\n    documentation: str = \"https://docs.scrapegraphai.com/services/smartscraper\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"ScrapeGraph API Key\",\n            required=True,\n            password=True,\n            info=\"The API key to use ScrapeGraph API.\",\n        ),\n        MessageTextInput(\n            name=\"url\",\n            display_name=\"URL\",\n            tool_mode=True,\n            info=\"The URL to scrape.\",\n        ),\n        MessageTextInput(\n            name=\"prompt\",\n            display_name=\"Prompt\",\n            tool_mode=True,\n            info=\"The prompt to use for the smart scraper.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"scrape\"),\n    ]\n\n    def scrape(self) -> list[Data]:\n        try:\n            from scrapegraph_py import Client\n            from scrapegraph_py.logger import sgai_logger\n        except ImportError as e:\n            msg = \"Could not import scrapegraph-py package. Please install it with `pip install scrapegraph-py`.\"\n            raise ImportError(msg) from e\n\n        # Set logging level\n        sgai_logger.set_logging(level=\"INFO\")\n\n        # Initialize the client with API key\n        sgai_client = Client(api_key=self.api_key)\n\n        try:\n            # SmartScraper request\n            response = sgai_client.smartscraper(\n                website_url=self.url,\n                user_prompt=self.prompt,\n            )\n\n            # Close the client\n            sgai_client.close()\n\n            return Data(data=response)\n        except Exception:\n            sgai_client.close()\n            raise\n"},"prompt":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Prompt","dynamic":false,"info":"The prompt to use for the smart scraper.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"prompt","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"url":{"_input_type":"MessageTextInput","advanced":false,"display_name":"URL","dynamic":false,"info":"The URL to scrape.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["searchapi",{"SearchComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Calls the SearchApi API with result limiting. Supports Google, Bing and DuckDuckGo.","display_name":"SearchApi","documentation":"https://www.searchapi.io/docs/google","edited":false,"field_order":["engine","api_key","input_value","search_params","max_results","max_snippet_length"],"frozen":false,"icon":"SearchAPI","legacy":false,"metadata":{"code_hash":"625d1f5b3290","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.searchapi.search.SearchComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"fetch_content_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"SearchAPI API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom langchain_community.utilities.searchapi import SearchApiAPIWrapper\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import DictInput, DropdownInput, IntInput, MultilineInput, SecretStrInput\nfrom lfx.io import Output\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\n\n\nclass SearchComponent(Component):\n    display_name: str = \"SearchApi\"\n    description: str = \"Calls the SearchApi API with result limiting. Supports Google, Bing and DuckDuckGo.\"\n    documentation: str = \"https://www.searchapi.io/docs/google\"\n    icon = \"SearchAPI\"\n\n    inputs = [\n        DropdownInput(name=\"engine\", display_name=\"Engine\", value=\"google\", options=[\"google\", \"bing\", \"duckduckgo\"]),\n        SecretStrInput(name=\"api_key\", display_name=\"SearchAPI API Key\", required=True),\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            tool_mode=True,\n        ),\n        DictInput(name=\"search_params\", display_name=\"Search parameters\", advanced=True, is_list=True),\n        IntInput(name=\"max_results\", display_name=\"Max Results\", value=5, advanced=True),\n        IntInput(name=\"max_snippet_length\", display_name=\"Max Snippet Length\", value=100, advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"fetch_content_dataframe\"),\n    ]\n\n    def _build_wrapper(self):\n        return SearchApiAPIWrapper(engine=self.engine, searchapi_api_key=self.api_key)\n\n    def run_model(self) -> DataFrame:\n        return self.fetch_content_dataframe()\n\n    def fetch_content(self) -> list[Data]:\n        wrapper = self._build_wrapper()\n\n        def search_func(\n            query: str, params: dict[str, Any] | None = None, max_results: int = 5, max_snippet_length: int = 100\n        ) -> list[Data]:\n            params = params or {}\n            full_results = wrapper.results(query=query, **params)\n            organic_results = full_results.get(\"organic_results\", [])[:max_results]\n\n            return [\n                Data(\n                    text=result.get(\"snippet\", \"\"),\n                    data={\n                        \"title\": result.get(\"title\", \"\")[:max_snippet_length],\n                        \"link\": result.get(\"link\", \"\"),\n                        \"snippet\": result.get(\"snippet\", \"\")[:max_snippet_length],\n                    },\n                )\n                for result in organic_results\n            ]\n\n        results = search_func(\n            self.input_value,\n            self.search_params or {},\n            self.max_results,\n            self.max_snippet_length,\n        )\n        self.status = results\n        return results\n\n    def fetch_content_dataframe(self) -> DataFrame:\n        \"\"\"Convert the search results to a DataFrame.\n\n        Returns:\n            DataFrame: A DataFrame containing the search results.\n        \"\"\"\n        data = self.fetch_content()\n        return DataFrame(data)\n"},"engine":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Engine","dynamic":false,"external_options":{},"info":"","name":"engine","options":["google","bing","duckduckgo"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"google"},"input_value":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"max_results":{"_input_type":"IntInput","advanced":true,"display_name":"Max Results","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"max_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5},"max_snippet_length":{"_input_type":"IntInput","advanced":true,"display_name":"Max Snippet Length","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"max_snippet_length","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":100},"search_params":{"_input_type":"DictInput","advanced":true,"display_name":"Search parameters","dynamic":false,"info":"","list":true,"list_add_label":"Add More","name":"search_params","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}}},"tool_mode":false}}],["serpapi",{"Serp":{"base_classes":["Data","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Call Serp Search API with result limiting","display_name":"Serp Search API","documentation":"","edited":false,"field_order":["serpapi_api_key","input_value","search_params","max_results","max_snippet_length"],"frozen":false,"icon":"SerpSearch","legacy":false,"metadata":{"code_hash":"dcc2ecb44ff6","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"langchain_core","version":"0.3.79"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.serpapi.serp.SerpComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"fetch_content","name":"data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Text","group_outputs":false,"method":"fetch_content_text","name":"text","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom langchain_community.utilities.serpapi import SerpAPIWrapper\nfrom langchain_core.tools import ToolException\nfrom pydantic import BaseModel, Field\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import DictInput, IntInput, MultilineInput, SecretStrInput\nfrom lfx.io import Output\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.message import Message\n\n\nclass SerpAPISchema(BaseModel):\n    \"\"\"Schema for SerpAPI search parameters.\"\"\"\n\n    query: str = Field(..., description=\"The search query\")\n    params: dict[str, Any] | None = Field(\n        default={\n            \"engine\": \"google\",\n            \"google_domain\": \"google.com\",\n            \"gl\": \"us\",\n            \"hl\": \"en\",\n        },\n        description=\"Additional search parameters\",\n    )\n    max_results: int = Field(5, description=\"Maximum number of results to return\")\n    max_snippet_length: int = Field(100, description=\"Maximum length of each result snippet\")\n\n\nclass SerpComponent(Component):\n    display_name = \"Serp Search API\"\n    description = \"Call Serp Search API with result limiting\"\n    name = \"Serp\"\n    icon = \"SerpSearch\"\n\n    inputs = [\n        SecretStrInput(name=\"serpapi_api_key\", display_name=\"SerpAPI API Key\", required=True),\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            tool_mode=True,\n        ),\n        DictInput(name=\"search_params\", display_name=\"Parameters\", advanced=True, is_list=True),\n        IntInput(name=\"max_results\", display_name=\"Max Results\", value=5, advanced=True),\n        IntInput(name=\"max_snippet_length\", display_name=\"Max Snippet Length\", value=100, advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"fetch_content\"),\n        Output(display_name=\"Text\", name=\"text\", method=\"fetch_content_text\"),\n    ]\n\n    def _build_wrapper(self, params: dict[str, Any] | None = None) -> SerpAPIWrapper:\n        \"\"\"Build a SerpAPIWrapper with the provided parameters.\"\"\"\n        params = params or {}\n        if params:\n            return SerpAPIWrapper(\n                serpapi_api_key=self.serpapi_api_key,\n                params=params,\n            )\n        return SerpAPIWrapper(serpapi_api_key=self.serpapi_api_key)\n\n    def run_model(self) -> list[Data]:\n        return self.fetch_content()\n\n    def fetch_content(self) -> list[Data]:\n        wrapper = self._build_wrapper(self.search_params)\n\n        def search_func(\n            query: str, params: dict[str, Any] | None = None, max_results: int = 5, max_snippet_length: int = 100\n        ) -> list[Data]:\n            try:\n                local_wrapper = wrapper\n                if params:\n                    local_wrapper = self._build_wrapper(params)\n\n                full_results = local_wrapper.results(query)\n                organic_results = full_results.get(\"organic_results\", [])[:max_results]\n\n                limited_results = [\n                    Data(\n                        text=result.get(\"snippet\", \"\"),\n                        data={\n                            \"title\": result.get(\"title\", \"\")[:max_snippet_length],\n                            \"link\": result.get(\"link\", \"\"),\n                            \"snippet\": result.get(\"snippet\", \"\")[:max_snippet_length],\n                        },\n                    )\n                    for result in organic_results\n                ]\n\n            except Exception as e:\n                error_message = f\"Error in SerpAPI search: {e!s}\"\n                logger.debug(error_message)\n                raise ToolException(error_message) from e\n            return limited_results\n\n        results = search_func(\n            self.input_value,\n            params=self.search_params,\n            max_results=self.max_results,\n            max_snippet_length=self.max_snippet_length,\n        )\n        self.status = results\n        return results\n\n    def fetch_content_text(self) -> Message:\n        data = self.fetch_content()\n        result_string = \"\"\n        for item in data:\n            result_string += item.text + \"\\n\"\n        self.status = result_string\n        return Message(text=result_string)\n"},"input_value":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"max_results":{"_input_type":"IntInput","advanced":true,"display_name":"Max Results","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"max_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5},"max_snippet_length":{"_input_type":"IntInput","advanced":true,"display_name":"Max Snippet Length","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"max_snippet_length","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":100},"search_params":{"_input_type":"DictInput","advanced":true,"display_name":"Parameters","dynamic":false,"info":"","list":true,"list_add_label":"Add More","name":"search_params","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"serpapi_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"SerpAPI API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"serpapi_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""}},"tool_mode":false}}],["supabase",{"SupabaseVectorStore":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Supabase Vector Store with search capabilities","display_name":"Supabase","documentation":"","edited":false,"field_order":["supabase_url","supabase_service_key","table_name","query_name","ingest_data","search_query","should_cache_vector_store","embedding","number_of_results"],"frozen":false,"icon":"Supabase","legacy":false,"metadata":{"code_hash":"5045b81c340b","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"supabase","version":"2.22.0"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.supabase.supabase.SupabaseVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_community.vectorstores import SupabaseVectorStore\nfrom supabase.client import Client, create_client\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.io import HandleInput, IntInput, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass SupabaseVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Supabase\"\n    description = \"Supabase Vector Store with search capabilities\"\n    name = \"SupabaseVectorStore\"\n    icon = \"Supabase\"\n\n    inputs = [\n        StrInput(name=\"supabase_url\", display_name=\"Supabase URL\", required=True),\n        SecretStrInput(name=\"supabase_service_key\", display_name=\"Supabase Service Key\", required=True),\n        StrInput(name=\"table_name\", display_name=\"Table Name\", advanced=True),\n        StrInput(name=\"query_name\", display_name=\"Query Name\"),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> SupabaseVectorStore:\n        supabase: Client = create_client(self.supabase_url, supabase_key=self.supabase_service_key)\n\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents:\n            supabase_vs = SupabaseVectorStore.from_documents(\n                documents=documents,\n                embedding=self.embedding,\n                query_name=self.query_name,\n                client=supabase,\n                table_name=self.table_name,\n            )\n        else:\n            supabase_vs = SupabaseVectorStore(\n                client=supabase,\n                embedding=self.embedding,\n                table_name=self.table_name,\n                query_name=self.query_name,\n            )\n\n        return supabase_vs\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n"},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"query_name":{"_input_type":"StrInput","advanced":false,"display_name":"Query Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"query_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"supabase_service_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Supabase Service Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"supabase_service_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"supabase_url":{"_input_type":"StrInput","advanced":false,"display_name":"Supabase URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"supabase_url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"table_name":{"_input_type":"StrInput","advanced":true,"display_name":"Table Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"table_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["tavily",{"TavilyExtractComponent":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"**Tavily Extract** extract raw content from URLs.","display_name":"Tavily Extract API","documentation":"","edited":false,"field_order":["api_key","urls","extract_depth","include_images"],"frozen":false,"icon":"TavilyIcon","legacy":false,"metadata":{"code_hash":"fec95e2181d8","dependencies":{"dependencies":[{"name":"httpx","version":"0.28.1"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.tavily.tavily_extract.TavilyExtractComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"fetch_content","name":"dataframe","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Tavily API Key","dynamic":false,"info":"Your Tavily API Key.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import httpx\n\nfrom lfx.custom import Component\nfrom lfx.io import BoolInput, DropdownInput, MessageTextInput, Output, SecretStrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema import Data\nfrom lfx.schema.dataframe import DataFrame\n\n\nclass TavilyExtractComponent(Component):\n    \"\"\"Separate component specifically for Tavily Extract functionality.\"\"\"\n\n    display_name = \"Tavily Extract API\"\n    description = \"\"\"**Tavily Extract** extract raw content from URLs.\"\"\"\n    icon = \"TavilyIcon\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Tavily API Key\",\n            required=True,\n            info=\"Your Tavily API Key.\",\n        ),\n        MessageTextInput(\n            name=\"urls\",\n            display_name=\"URLs\",\n            info=\"Comma-separated list of URLs to extract content from.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"extract_depth\",\n            display_name=\"Extract Depth\",\n            info=\"The depth of the extraction process.\",\n            options=[\"basic\", \"advanced\"],\n            value=\"basic\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_images\",\n            display_name=\"Include Images\",\n            info=\"Include a list of images extracted from the URLs.\",\n            value=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"fetch_content\"),\n    ]\n\n    def run_model(self) -> DataFrame:\n        return self.fetch_content_dataframe()\n\n    def fetch_content(self) -> list[Data]:\n        \"\"\"Fetches and processes extracted content into a list of Data objects.\"\"\"\n        try:\n            # Split URLs by comma and clean them\n            urls = [url.strip() for url in (self.urls or \"\").split(\",\") if url.strip()]\n            if not urls:\n                error_message = \"No valid URLs provided\"\n                logger.error(error_message)\n                return [Data(text=error_message, data={\"error\": error_message})]\n\n            url = \"https://api.tavily.com/extract\"\n            headers = {\n                \"content-type\": \"application/json\",\n                \"accept\": \"application/json\",\n                \"Authorization\": f\"Bearer {self.api_key}\",\n            }\n            payload = {\n                \"urls\": urls,\n                \"extract_depth\": self.extract_depth,\n                \"include_images\": self.include_images,\n            }\n\n            with httpx.Client(timeout=90.0) as client:\n                response = client.post(url, json=payload, headers=headers)\n                response.raise_for_status()\n\n        except httpx.TimeoutException as exc:\n            error_message = f\"Request timed out (90s): {exc}\"\n            logger.error(error_message)\n            return [Data(text=error_message, data={\"error\": error_message})]\n        except httpx.HTTPStatusError as exc:\n            error_message = f\"HTTP error occurred: {exc.response.status_code} - {exc.response.text}\"\n            logger.error(error_message)\n            return [Data(text=error_message, data={\"error\": error_message})]\n        except (ValueError, KeyError, AttributeError, httpx.RequestError) as exc:\n            error_message = f\"Data processing error: {exc}\"\n            logger.error(error_message)\n            return [Data(text=error_message, data={\"error\": error_message})]\n        else:\n            extract_results = response.json()\n            data_results = []\n\n            # Process successful extractions\n            for result in extract_results.get(\"results\", []):\n                raw_content = result.get(\"raw_content\", \"\")\n                images = result.get(\"images\", [])\n                result_data = {\"url\": result.get(\"url\"), \"raw_content\": raw_content, \"images\": images}\n                data_results.append(Data(text=raw_content, data=result_data))\n\n            # Process failed extractions\n            if extract_results.get(\"failed_results\"):\n                data_results.append(\n                    Data(\n                        text=\"Failed extractions\",\n                        data={\"failed_results\": extract_results[\"failed_results\"]},\n                    )\n                )\n\n            self.status = data_results\n            return data_results\n\n    def fetch_content_dataframe(self) -> DataFrame:\n        data = self.fetch_content()\n        return DataFrame(data)\n"},"extract_depth":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Extract Depth","dynamic":false,"external_options":{},"info":"The depth of the extraction process.","name":"extract_depth","options":["basic","advanced"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"basic"},"include_images":{"_input_type":"BoolInput","advanced":true,"display_name":"Include Images","dynamic":false,"info":"Include a list of images extracted from the URLs.","list":false,"list_add_label":"Add More","name":"include_images","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"urls":{"_input_type":"MessageTextInput","advanced":false,"display_name":"URLs","dynamic":false,"info":"Comma-separated list of URLs to extract content from.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"urls","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"TavilySearchComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"**Tavily Search** is a search engine optimized for LLMs and RAG,         aimed at efficient, quick, and persistent search results.","display_name":"Tavily Search API","documentation":"","edited":false,"field_order":["api_key","query","search_depth","chunks_per_source","topic","days","max_results","include_answer","time_range","include_images","include_domains","exclude_domains","include_raw_content"],"frozen":false,"icon":"TavilyIcon","legacy":false,"metadata":{"code_hash":"e602eaec8316","dependencies":{"dependencies":[{"name":"httpx","version":"0.28.1"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.tavily.tavily_search.TavilySearchComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"fetch_content_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Tavily API Key","dynamic":false,"info":"Your Tavily API Key.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"chunks_per_source":{"_input_type":"IntInput","advanced":true,"display_name":"Chunks Per Source","dynamic":false,"info":"The number of content chunks to retrieve from each source (1-3). Only works with advanced search.","list":false,"list_add_label":"Add More","name":"chunks_per_source","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":3},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import httpx\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import BoolInput, DropdownInput, IntInput, MessageTextInput, SecretStrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.template.field.base import Output\n\n\nclass TavilySearchComponent(Component):\n    display_name = \"Tavily Search API\"\n    description = \"\"\"**Tavily Search** is a search engine optimized for LLMs and RAG, \\\n        aimed at efficient, quick, and persistent search results.\"\"\"\n    icon = \"TavilyIcon\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Tavily API Key\",\n            required=True,\n            info=\"Your Tavily API Key.\",\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"Search Query\",\n            info=\"The search query you want to execute with Tavily.\",\n            tool_mode=True,\n        ),\n        DropdownInput(\n            name=\"search_depth\",\n            display_name=\"Search Depth\",\n            info=\"The depth of the search.\",\n            options=[\"basic\", \"advanced\"],\n            value=\"advanced\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chunks_per_source\",\n            display_name=\"Chunks Per Source\",\n            info=(\"The number of content chunks to retrieve from each source (1-3). Only works with advanced search.\"),\n            value=3,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"topic\",\n            display_name=\"Search Topic\",\n            info=\"The category of the search.\",\n            options=[\"general\", \"news\"],\n            value=\"general\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"days\",\n            display_name=\"Days\",\n            info=\"Number of days back from current date to include. Only available with news topic.\",\n            value=7,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_results\",\n            display_name=\"Max Results\",\n            info=\"The maximum number of search results to return.\",\n            value=5,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_answer\",\n            display_name=\"Include Answer\",\n            info=\"Include a short answer to original query.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"time_range\",\n            display_name=\"Time Range\",\n            info=\"The time range back from the current date to filter results.\",\n            options=[\"day\", \"week\", \"month\", \"year\"],\n            value=None,  # Default to None to make it optional\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_images\",\n            display_name=\"Include Images\",\n            info=\"Include a list of query-related images in the response.\",\n            value=True,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"include_domains\",\n            display_name=\"Include Domains\",\n            info=\"Comma-separated list of domains to include in the search results.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"exclude_domains\",\n            display_name=\"Exclude Domains\",\n            info=\"Comma-separated list of domains to exclude from the search results.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_raw_content\",\n            display_name=\"Include Raw Content\",\n            info=\"Include the cleaned and parsed HTML content of each search result.\",\n            value=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"fetch_content_dataframe\"),\n    ]\n\n    def fetch_content(self) -> list[Data]:\n        try:\n            # Only process domains if they're provided\n            include_domains = None\n            exclude_domains = None\n\n            if self.include_domains:\n                include_domains = [domain.strip() for domain in self.include_domains.split(\",\") if domain.strip()]\n\n            if self.exclude_domains:\n                exclude_domains = [domain.strip() for domain in self.exclude_domains.split(\",\") if domain.strip()]\n\n            url = \"https://api.tavily.com/search\"\n            headers = {\n                \"content-type\": \"application/json\",\n                \"accept\": \"application/json\",\n            }\n\n            payload = {\n                \"api_key\": self.api_key,\n                \"query\": self.query,\n                \"search_depth\": self.search_depth,\n                \"topic\": self.topic,\n                \"max_results\": self.max_results,\n                \"include_images\": self.include_images,\n                \"include_answer\": self.include_answer,\n                \"include_raw_content\": self.include_raw_content,\n                \"days\": self.days,\n                \"time_range\": self.time_range,\n            }\n\n            # Only add domains to payload if they exist and have values\n            if include_domains:\n                payload[\"include_domains\"] = include_domains\n            if exclude_domains:\n                payload[\"exclude_domains\"] = exclude_domains\n\n            # Add conditional parameters only if they should be included\n            if self.search_depth == \"advanced\" and self.chunks_per_source:\n                payload[\"chunks_per_source\"] = self.chunks_per_source\n\n            if self.topic == \"news\" and self.days:\n                payload[\"days\"] = int(self.days)  # Ensure days is an integer\n\n            # Add time_range if it's set\n            if hasattr(self, \"time_range\") and self.time_range:\n                payload[\"time_range\"] = self.time_range\n\n            # Add timeout handling\n            with httpx.Client(timeout=90.0) as client:\n                response = client.post(url, json=payload, headers=headers)\n\n            response.raise_for_status()\n            search_results = response.json()\n\n            data_results = []\n\n            if self.include_answer and search_results.get(\"answer\"):\n                data_results.append(Data(text=search_results[\"answer\"]))\n\n            for result in search_results.get(\"results\", []):\n                content = result.get(\"content\", \"\")\n                result_data = {\n                    \"title\": result.get(\"title\"),\n                    \"url\": result.get(\"url\"),\n                    \"content\": content,\n                    \"score\": result.get(\"score\"),\n                }\n                if self.include_raw_content:\n                    result_data[\"raw_content\"] = result.get(\"raw_content\")\n\n                data_results.append(Data(text=content, data=result_data))\n\n            if self.include_images and search_results.get(\"images\"):\n                data_results.append(Data(text=\"Images found\", data={\"images\": search_results[\"images\"]}))\n\n        except httpx.TimeoutException:\n            error_message = \"Request timed out (90s). Please try again or adjust parameters.\"\n            logger.error(error_message)\n            return [Data(text=error_message, data={\"error\": error_message})]\n        except httpx.HTTPStatusError as exc:\n            error_message = f\"HTTP error occurred: {exc.response.status_code} - {exc.response.text}\"\n            logger.error(error_message)\n            return [Data(text=error_message, data={\"error\": error_message})]\n        except httpx.RequestError as exc:\n            error_message = f\"Request error occurred: {exc}\"\n            logger.error(error_message)\n            return [Data(text=error_message, data={\"error\": error_message})]\n        except ValueError as exc:\n            error_message = f\"Invalid response format: {exc}\"\n            logger.error(error_message)\n            return [Data(text=error_message, data={\"error\": error_message})]\n        else:\n            self.status = data_results\n            return data_results\n\n    def fetch_content_dataframe(self) -> DataFrame:\n        data = self.fetch_content()\n        return DataFrame(data)\n"},"days":{"_input_type":"IntInput","advanced":true,"display_name":"Days","dynamic":false,"info":"Number of days back from current date to include. Only available with news topic.","list":false,"list_add_label":"Add More","name":"days","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":7},"exclude_domains":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Exclude Domains","dynamic":false,"info":"Comma-separated list of domains to exclude from the search results.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"exclude_domains","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"include_answer":{"_input_type":"BoolInput","advanced":true,"display_name":"Include Answer","dynamic":false,"info":"Include a short answer to original query.","list":false,"list_add_label":"Add More","name":"include_answer","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"include_domains":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Include Domains","dynamic":false,"info":"Comma-separated list of domains to include in the search results.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"include_domains","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"include_images":{"_input_type":"BoolInput","advanced":true,"display_name":"Include Images","dynamic":false,"info":"Include a list of query-related images in the response.","list":false,"list_add_label":"Add More","name":"include_images","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"include_raw_content":{"_input_type":"BoolInput","advanced":true,"display_name":"Include Raw Content","dynamic":false,"info":"Include the cleaned and parsed HTML content of each search result.","list":false,"list_add_label":"Add More","name":"include_raw_content","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"max_results":{"_input_type":"IntInput","advanced":true,"display_name":"Max Results","dynamic":false,"info":"The maximum number of search results to return.","list":false,"list_add_label":"Add More","name":"max_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5},"query":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"The search query you want to execute with Tavily.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"query","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"search_depth":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Search Depth","dynamic":false,"external_options":{},"info":"The depth of the search.","name":"search_depth","options":["basic","advanced"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"advanced"},"time_range":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Time Range","dynamic":false,"external_options":{},"info":"The time range back from the current date to filter results.","name":"time_range","options":["day","week","month","year"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str"},"topic":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Search Topic","dynamic":false,"external_options":{},"info":"The category of the search.","name":"topic","options":["general","news"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"general"}},"tool_mode":false}}],["tools",{"CalculatorTool":{"base_classes":["Data","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Perform basic arithmetic operations on a given expression.","display_name":"Calculator","documentation":"","edited":false,"field_order":["expression"],"frozen":false,"icon":"calculator","legacy":true,"metadata":{"code_hash":"30008a17eb27","dependencies":{"dependencies":[{"name":"pytest","version":"8.4.2"},{"name":"langchain_core","version":"0.3.79"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null},{"name":"langchain","version":"0.3.23"}],"total_dependencies":5},"module":"lfx.components.tools.calculator.CalculatorToolComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"run_model","name":"api_run_model","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"api_build_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["helpers.CalculatorComponent"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import ast\nimport operator\n\nimport pytest\nfrom langchain_core.tools import ToolException\nfrom pydantic import BaseModel, Field\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.field_typing import Tool\nfrom lfx.inputs.inputs import MessageTextInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\n\n\nclass CalculatorToolComponent(LCToolComponent):\n    display_name = \"Calculator\"\n    description = \"Perform basic arithmetic operations on a given expression.\"\n    icon = \"calculator\"\n    name = \"CalculatorTool\"\n    legacy = True\n    replacement = [\"helpers.CalculatorComponent\"]\n\n    inputs = [\n        MessageTextInput(\n            name=\"expression\",\n            display_name=\"Expression\",\n            info=\"The arithmetic expression to evaluate (e.g., '4*4*(33/22)+12-20').\",\n        ),\n    ]\n\n    class CalculatorToolSchema(BaseModel):\n        expression: str = Field(..., description=\"The arithmetic expression to evaluate.\")\n\n    def run_model(self) -> list[Data]:\n        return self._evaluate_expression(self.expression)\n\n    def build_tool(self) -> Tool:\n        try:\n            from langchain.tools import StructuredTool\n        except Exception:  # noqa: BLE001\n            pytest.skip(\"langchain is not available\")\n\n        return StructuredTool.from_function(\n            name=\"calculator\",\n            description=\"Evaluate basic arithmetic expressions. Input should be a string containing the expression.\",\n            func=self._eval_expr_with_error,\n            args_schema=self.CalculatorToolSchema,\n        )\n\n    def _eval_expr(self, node):\n        if isinstance(node, ast.Num):\n            return node.n\n        if isinstance(node, ast.BinOp):\n            left_val = self._eval_expr(node.left)\n            right_val = self._eval_expr(node.right)\n            return self.operators[type(node.op)](left_val, right_val)\n        if isinstance(node, ast.UnaryOp):\n            operand_val = self._eval_expr(node.operand)\n            return self.operators[type(node.op)](operand_val)\n        if isinstance(node, ast.Call):\n            msg = (\n                \"Function calls like sqrt(), sin(), cos() etc. are not supported. \"\n                \"Only basic arithmetic operations (+, -, *, /, **) are allowed.\"\n            )\n            raise TypeError(msg)\n        msg = f\"Unsupported operation or expression type: {type(node).__name__}\"\n        raise TypeError(msg)\n\n    def _eval_expr_with_error(self, expression: str) -> list[Data]:\n        try:\n            return self._evaluate_expression(expression)\n        except Exception as e:\n            raise ToolException(str(e)) from e\n\n    def _evaluate_expression(self, expression: str) -> list[Data]:\n        try:\n            # Parse the expression and evaluate it\n            tree = ast.parse(expression, mode=\"eval\")\n            result = self._eval_expr(tree.body)\n\n            # Format the result to a reasonable number of decimal places\n            formatted_result = f\"{result:.6f}\".rstrip(\"0\").rstrip(\".\")\n\n            self.status = formatted_result\n            return [Data(data={\"result\": formatted_result})]\n\n        except (SyntaxError, TypeError, KeyError) as e:\n            error_message = f\"Invalid expression: {e}\"\n            self.status = error_message\n            return [Data(data={\"error\": error_message, \"input\": expression})]\n        except ZeroDivisionError:\n            error_message = \"Error: Division by zero\"\n            self.status = error_message\n            return [Data(data={\"error\": error_message, \"input\": expression})]\n        except Exception as e:  # noqa: BLE001\n            logger.debug(\"Error evaluating expression\", exc_info=True)\n            error_message = f\"Error: {e}\"\n            self.status = error_message\n            return [Data(data={\"error\": error_message, \"input\": expression})]\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.operators = {\n            ast.Add: operator.add,\n            ast.Sub: operator.sub,\n            ast.Mult: operator.mul,\n            ast.Div: operator.truediv,\n            ast.Pow: operator.pow,\n        }\n"},"expression":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Expression","dynamic":false,"info":"The arithmetic expression to evaluate (e.g., '4*4*(33/22)+12-20').","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"expression","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"GoogleSearchAPI":{"base_classes":["Data","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Call Google Search API.","display_name":"Google Search API [DEPRECATED]","documentation":"","edited":false,"field_order":["google_api_key","google_cse_id","input_value","k"],"frozen":false,"icon":"Google","legacy":true,"metadata":{"code_hash":"5f47bcd2163c","dependencies":{"dependencies":[{"name":"langchain_core","version":"0.3.79"},{"name":"lfx","version":null},{"name":"langchain_google_community","version":"2.0.3"}],"total_dependencies":3},"module":"lfx.components.tools.google_search_api.GoogleSearchAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"run_model","name":"api_run_model","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"api_build_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_core.tools import Tool\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.inputs.inputs import IntInput, MultilineInput, SecretStrInput\nfrom lfx.schema.data import Data\n\n\nclass GoogleSearchAPIComponent(LCToolComponent):\n    display_name = \"Google Search API [DEPRECATED]\"\n    description = \"Call Google Search API.\"\n    name = \"GoogleSearchAPI\"\n    icon = \"Google\"\n    legacy = True\n    inputs = [\n        SecretStrInput(name=\"google_api_key\", display_name=\"Google API Key\", required=True),\n        SecretStrInput(name=\"google_cse_id\", display_name=\"Google CSE ID\", required=True),\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n        ),\n        IntInput(name=\"k\", display_name=\"Number of results\", value=4, required=True),\n    ]\n\n    def run_model(self) -> Data | list[Data]:\n        wrapper = self._build_wrapper()\n        results = wrapper.results(query=self.input_value, num_results=self.k)\n        data = [Data(data=result, text=result[\"snippet\"]) for result in results]\n        self.status = data\n        return data\n\n    def build_tool(self) -> Tool:\n        wrapper = self._build_wrapper()\n        return Tool(\n            name=\"google_search\",\n            description=\"Search Google for recent results.\",\n            func=wrapper.run,\n        )\n\n    def _build_wrapper(self):\n        try:\n            from langchain_google_community import GoogleSearchAPIWrapper\n        except ImportError as e:\n            msg = \"Please install langchain-google-community to use GoogleSearchAPIWrapper.\"\n            raise ImportError(msg) from e\n        return GoogleSearchAPIWrapper(google_api_key=self.google_api_key, google_cse_id=self.google_cse_id, k=self.k)\n"},"google_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Google API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"google_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"google_cse_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Google CSE ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"google_cse_id","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"input_value":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"k":{"_input_type":"IntInput","advanced":false,"display_name":"Number of results","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"k","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4}},"tool_mode":false},"GoogleSerperAPI":{"base_classes":["Data","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Call the Serper.dev Google Search API.","display_name":"Google Serper API [DEPRECATED]","documentation":"","edited":false,"field_order":["serper_api_key","query","k","query_type","query_params"],"frozen":false,"icon":"Google","legacy":true,"metadata":{"code_hash":"f51b15d26440","dependencies":{"dependencies":[{"name":"langchain","version":"0.3.23"},{"name":"langchain_community","version":"0.3.21"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.tools.google_serper_api.GoogleSerperAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"run_model","name":"api_run_model","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"api_build_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom langchain.tools import StructuredTool\nfrom langchain_community.utilities.google_serper import GoogleSerperAPIWrapper\nfrom pydantic import BaseModel, Field\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.field_typing import Tool\nfrom lfx.inputs.inputs import (\n    DictInput,\n    DropdownInput,\n    IntInput,\n    MultilineInput,\n    SecretStrInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass QuerySchema(BaseModel):\n    query: str = Field(..., description=\"The query to search for.\")\n    query_type: str = Field(\n        \"search\",\n        description=\"The type of search to perform (e.g., 'news' or 'search').\",\n    )\n    k: int = Field(4, description=\"The number of results to return.\")\n    query_params: dict[str, Any] = Field({}, description=\"Additional query parameters to pass to the API.\")\n\n\nclass GoogleSerperAPIComponent(LCToolComponent):\n    display_name = \"Google Serper API [DEPRECATED]\"\n    description = \"Call the Serper.dev Google Search API.\"\n    name = \"GoogleSerperAPI\"\n    icon = \"Google\"\n    legacy = True\n    inputs = [\n        SecretStrInput(name=\"serper_api_key\", display_name=\"Serper API Key\", required=True),\n        MultilineInput(\n            name=\"query\",\n            display_name=\"Query\",\n        ),\n        IntInput(name=\"k\", display_name=\"Number of results\", value=4, required=True),\n        DropdownInput(\n            name=\"query_type\",\n            display_name=\"Query Type\",\n            required=False,\n            options=[\"news\", \"search\"],\n            value=\"search\",\n        ),\n        DictInput(\n            name=\"query_params\",\n            display_name=\"Query Params\",\n            required=False,\n            value={\n                \"gl\": \"us\",\n                \"hl\": \"en\",\n            },\n            list=True,\n        ),\n    ]\n\n    def run_model(self) -> Data | list[Data]:\n        wrapper = self._build_wrapper(self.k, self.query_type, self.query_params)\n        results = wrapper.results(query=self.query)\n\n        # Adjust the extraction based on the `type`\n        if self.query_type == \"search\":\n            list_results = results.get(\"organic\", [])\n        elif self.query_type == \"news\":\n            list_results = results.get(\"news\", [])\n        else:\n            list_results = []\n\n        data_list = []\n        for result in list_results:\n            result[\"text\"] = result.pop(\"snippet\", \"\")\n            data_list.append(Data(data=result))\n        self.status = data_list\n        return data_list\n\n    def build_tool(self) -> Tool:\n        return StructuredTool.from_function(\n            name=\"google_search\",\n            description=\"Search Google for recent results.\",\n            func=self._search,\n            args_schema=self.QuerySchema,\n        )\n\n    def _build_wrapper(\n        self,\n        k: int = 5,\n        query_type: str = \"search\",\n        query_params: dict | None = None,\n    ) -> GoogleSerperAPIWrapper:\n        wrapper_args = {\n            \"serper_api_key\": self.serper_api_key,\n            \"k\": k,\n            \"type\": query_type,\n        }\n\n        # Add query_params if provided\n        if query_params:\n            wrapper_args.update(query_params)  # Merge with additional query params\n\n        # Dynamically pass parameters to the wrapper\n        return GoogleSerperAPIWrapper(**wrapper_args)\n\n    def _search(\n        self,\n        query: str,\n        k: int = 5,\n        query_type: str = \"search\",\n        query_params: dict | None = None,\n    ) -> dict:\n        wrapper = self._build_wrapper(k, query_type, query_params)\n        return wrapper.results(query=query)\n"},"k":{"_input_type":"IntInput","advanced":false,"display_name":"Number of results","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"k","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"query":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Query","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"query","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"query_params":{"_input_type":"DictInput","advanced":false,"display_name":"Query Params","dynamic":false,"info":"","list":true,"list_add_label":"Add More","name":"query_params","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{"gl":"us","hl":"en"}},"query_type":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Query Type","dynamic":false,"external_options":{},"info":"","name":"query_type","options":["news","search"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"search"},"serper_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Serper API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"serper_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""}},"tool_mode":false},"PythonCodeStructuredTool":{"base_classes":["Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"structuredtool dataclass code to tool","display_name":"Python Code Structured","documentation":"https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass","edited":false,"field_order":["tool_code","tool_name","tool_description","return_direct","tool_function","global_variables","_classes","_functions"],"frozen":false,"icon":"Python","legacy":true,"metadata":{"code_hash":"99f294af525b","dependencies":{"dependencies":[{"name":"langchain","version":"0.3.23"},{"name":"langchain_core","version":"0.3.79"},{"name":"pydantic","version":"2.10.6"},{"name":"typing_extensions","version":"4.15.0"},{"name":"lfx","version":null}],"total_dependencies":5},"module":"lfx.components.tools.python_code_structured_tool.PythonCodeStructuredTool"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"result_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["processing.PythonREPLComponent"],"template":{"_classes":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Classes","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"_classes","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"_functions":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Functions","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"_functions","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import ast\nimport json\nfrom typing import Any\n\nfrom langchain.agents import Tool\nfrom langchain_core.tools import StructuredTool\nfrom pydantic.v1 import Field, create_model\nfrom pydantic.v1.fields import Undefined\nfrom typing_extensions import override\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.inputs.inputs import BoolInput, DropdownInput, FieldTypes, HandleInput, MessageTextInput, MultilineInput\nfrom lfx.io import Output\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.dotdict import dotdict\n\n\nclass PythonCodeStructuredTool(LCToolComponent):\n    DEFAULT_KEYS = [\n        \"code\",\n        \"_type\",\n        \"text_key\",\n        \"tool_code\",\n        \"tool_name\",\n        \"tool_description\",\n        \"return_direct\",\n        \"tool_function\",\n        \"global_variables\",\n        \"_classes\",\n        \"_functions\",\n    ]\n    display_name = \"Python Code Structured\"\n    description = \"structuredtool dataclass code to tool\"\n    documentation = \"https://python.langchain.com/docs/modules/tools/custom_tools/#structuredtool-dataclass\"\n    name = \"PythonCodeStructuredTool\"\n    icon = \"Python\"\n    field_order = [\"name\", \"description\", \"tool_code\", \"return_direct\", \"tool_function\"]\n    legacy: bool = True\n    replacement = [\"processing.PythonREPLComponent\"]\n\n    inputs = [\n        MultilineInput(\n            name=\"tool_code\",\n            display_name=\"Tool Code\",\n            info=\"Enter the dataclass code.\",\n            placeholder=\"def my_function(args):\\n    pass\",\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        MessageTextInput(\n            name=\"tool_name\",\n            display_name=\"Tool Name\",\n            info=\"Enter the name of the tool.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"tool_description\",\n            display_name=\"Description\",\n            info=\"Enter the description of the tool.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"return_direct\",\n            display_name=\"Return Directly\",\n            info=\"Should the tool return the function output directly?\",\n        ),\n        DropdownInput(\n            name=\"tool_function\",\n            display_name=\"Tool Function\",\n            info=\"Select the function for additional expressions.\",\n            options=[],\n            required=True,\n            real_time_refresh=True,\n            refresh_button=True,\n        ),\n        HandleInput(\n            name=\"global_variables\",\n            display_name=\"Global Variables\",\n            info=\"Enter the global variables or Create Data Component.\",\n            input_types=[\"Data\"],\n            field_type=FieldTypes.DICT,\n            is_list=True,\n        ),\n        MessageTextInput(name=\"_classes\", display_name=\"Classes\", advanced=True),\n        MessageTextInput(name=\"_functions\", display_name=\"Functions\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"result_tool\", method=\"build_tool\"),\n    ]\n\n    @override\n    async def update_build_config(\n        self, build_config: dotdict, field_value: Any, field_name: str | None = None\n    ) -> dotdict:\n        if field_name is None:\n            return build_config\n\n        if field_name not in {\"tool_code\", \"tool_function\"}:\n            return build_config\n\n        try:\n            named_functions = {}\n            [classes, functions] = self._parse_code(build_config[\"tool_code\"][\"value\"])\n            existing_fields = {}\n            if len(build_config) > len(self.DEFAULT_KEYS):\n                for key in build_config.copy():\n                    if key not in self.DEFAULT_KEYS:\n                        existing_fields[key] = build_config.pop(key)\n\n            names = []\n            for func in functions:\n                named_functions[func[\"name\"]] = func\n                names.append(func[\"name\"])\n\n                for arg in func[\"args\"]:\n                    field_name = f\"{func['name']}|{arg['name']}\"\n                    if field_name in existing_fields:\n                        build_config[field_name] = existing_fields[field_name]\n                        continue\n\n                    field = MessageTextInput(\n                        display_name=f\"{arg['name']}: Description\",\n                        name=field_name,\n                        info=f\"Enter the description for {arg['name']}\",\n                        required=True,\n                    )\n                    build_config[field_name] = field.to_dict()\n            build_config[\"_functions\"][\"value\"] = json.dumps(named_functions)\n            build_config[\"_classes\"][\"value\"] = json.dumps(classes)\n            build_config[\"tool_function\"][\"options\"] = names\n        except Exception as e:  # noqa: BLE001\n            self.status = f\"Failed to extract names: {e}\"\n            logger.debug(self.status, exc_info=True)\n            build_config[\"tool_function\"][\"options\"] = [\"Failed to parse\", str(e)]\n        return build_config\n\n    async def build_tool(self) -> Tool:\n        local_namespace = {}  # type: ignore[var-annotated]\n        modules = self._find_imports(self.tool_code)\n        import_code = \"\"\n        for module in modules[\"imports\"]:\n            import_code += f\"global {module}\\nimport {module}\\n\"\n        for from_module in modules[\"from_imports\"]:\n            for alias in from_module.names:\n                import_code += f\"global {alias.name}\\n\"\n            import_code += (\n                f\"from {from_module.module} import {', '.join([alias.name for alias in from_module.names])}\\n\"\n            )\n        exec(import_code, globals())\n        exec(self.tool_code, globals(), local_namespace)\n\n        class PythonCodeToolFunc:\n            params: dict = {}\n\n            def run(**kwargs):\n                for key, arg in kwargs.items():\n                    if key not in PythonCodeToolFunc.params:\n                        PythonCodeToolFunc.params[key] = arg\n                return local_namespace[self.tool_function](**PythonCodeToolFunc.params)\n\n        globals_ = globals()\n        local = {}\n        local[self.tool_function] = PythonCodeToolFunc\n        globals_.update(local)\n\n        if isinstance(self.global_variables, list):\n            for data in self.global_variables:\n                if isinstance(data, Data):\n                    globals_.update(data.data)\n        elif isinstance(self.global_variables, dict):\n            globals_.update(self.global_variables)\n\n        classes = json.loads(self._attributes[\"_classes\"])\n        for class_dict in classes:\n            exec(\"\\n\".join(class_dict[\"code\"]), globals_)\n\n        named_functions = json.loads(self._attributes[\"_functions\"])\n        schema_fields = {}\n\n        for attr in self._attributes:\n            if attr in self.DEFAULT_KEYS:\n                continue\n\n            func_name = attr.split(\"|\")[0]\n            field_name = attr.split(\"|\")[1]\n            func_arg = self._find_arg(named_functions, func_name, field_name)\n            if func_arg is None:\n                msg = f\"Failed to find arg: {field_name}\"\n                raise ValueError(msg)\n\n            field_annotation = func_arg[\"annotation\"]\n            field_description = self._get_value(self._attributes[attr], str)\n\n            if field_annotation:\n                exec(f\"temp_annotation_type = {field_annotation}\", globals_)\n                schema_annotation = globals_[\"temp_annotation_type\"]\n            else:\n                schema_annotation = Any\n            schema_fields[field_name] = (\n                schema_annotation,\n                Field(\n                    default=func_arg.get(\"default\", Undefined),\n                    description=field_description,\n                ),\n            )\n\n        if \"temp_annotation_type\" in globals_:\n            globals_.pop(\"temp_annotation_type\")\n\n        python_code_tool_schema = None\n        if schema_fields:\n            python_code_tool_schema = create_model(\"PythonCodeToolSchema\", **schema_fields)\n\n        return StructuredTool.from_function(\n            func=local[self.tool_function].run,\n            args_schema=python_code_tool_schema,\n            name=self.tool_name,\n            description=self.tool_description,\n            return_direct=self.return_direct,\n        )\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        frontend_node[\"template\"] = await self.update_build_config(\n            frontend_node[\"template\"],\n            frontend_node[\"template\"][\"tool_code\"][\"value\"],\n            \"tool_code\",\n        )\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        for key in frontend_node[\"template\"]:\n            if key in self.DEFAULT_KEYS:\n                continue\n            frontend_node[\"template\"] = await self.update_build_config(\n                frontend_node[\"template\"], frontend_node[\"template\"][key][\"value\"], key\n            )\n            frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        return frontend_node\n\n    def _parse_code(self, code: str) -> tuple[list[dict], list[dict]]:\n        parsed_code = ast.parse(code)\n        lines = code.split(\"\\n\")\n        classes = []\n        functions = []\n        for node in parsed_code.body:\n            if isinstance(node, ast.ClassDef):\n                class_lines = lines[node.lineno - 1 : node.end_lineno]\n                class_lines[-1] = class_lines[-1][: node.end_col_offset]\n                class_lines[0] = class_lines[0][node.col_offset :]\n                classes.append(\n                    {\n                        \"name\": node.name,\n                        \"code\": class_lines,\n                    }\n                )\n                continue\n\n            if not isinstance(node, ast.FunctionDef):\n                continue\n\n            func = {\"name\": node.name, \"args\": []}\n            for arg in node.args.args:\n                if arg.lineno != arg.end_lineno:\n                    msg = \"Multiline arguments are not supported\"\n                    raise ValueError(msg)\n\n                func_arg = {\n                    \"name\": arg.arg,\n                    \"annotation\": None,\n                }\n\n                for default in node.args.defaults:\n                    if (\n                        arg.lineno > default.lineno\n                        or arg.col_offset > default.col_offset\n                        or (\n                            arg.end_lineno is not None\n                            and default.end_lineno is not None\n                            and arg.end_lineno < default.end_lineno\n                        )\n                        or (\n                            arg.end_col_offset is not None\n                            and default.end_col_offset is not None\n                            and arg.end_col_offset < default.end_col_offset\n                        )\n                    ):\n                        continue\n\n                    if isinstance(default, ast.Name):\n                        func_arg[\"default\"] = default.id\n                    elif isinstance(default, ast.Constant):\n                        func_arg[\"default\"] = str(default.value) if default.value is not None else None\n\n                if arg.annotation:\n                    annotation_line = lines[arg.annotation.lineno - 1]\n                    annotation_line = annotation_line[: arg.annotation.end_col_offset]\n                    annotation_line = annotation_line[arg.annotation.col_offset :]\n                    func_arg[\"annotation\"] = annotation_line\n                    if isinstance(func_arg[\"annotation\"], str) and func_arg[\"annotation\"].count(\"=\") > 0:\n                        func_arg[\"annotation\"] = \"=\".join(func_arg[\"annotation\"].split(\"=\")[:-1]).strip()\n                if isinstance(func[\"args\"], list):\n                    func[\"args\"].append(func_arg)\n            functions.append(func)\n\n        return classes, functions\n\n    def _find_imports(self, code: str) -> dotdict:\n        imports: list[str] = []\n        from_imports = []\n        parsed_code = ast.parse(code)\n        for node in parsed_code.body:\n            if isinstance(node, ast.Import):\n                imports.extend(alias.name for alias in node.names)\n            elif isinstance(node, ast.ImportFrom):\n                from_imports.append(node)\n        return dotdict({\"imports\": imports, \"from_imports\": from_imports})\n\n    def _get_value(self, value: Any, annotation: Any) -> Any:\n        return value if isinstance(value, annotation) else value[\"value\"]\n\n    def _find_arg(self, named_functions: dict, func_name: str, arg_name: str) -> dict | None:\n        for arg in named_functions[func_name][\"args\"]:\n            if arg[\"name\"] == arg_name:\n                return arg\n        return None\n"},"global_variables":{"_input_type":"HandleInput","advanced":false,"display_name":"Global Variables","dynamic":false,"info":"Enter the global variables or Create Data Component.","input_types":["Data"],"list":true,"list_add_label":"Add More","name":"global_variables","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"dict","value":""},"return_direct":{"_input_type":"BoolInput","advanced":false,"display_name":"Return Directly","dynamic":false,"info":"Should the tool return the function output directly?","list":false,"list_add_label":"Add More","name":"return_direct","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"tool_code":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Tool Code","dynamic":false,"info":"Enter the dataclass code.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"tool_code","placeholder":"def my_function(args):\n    pass","real_time_refresh":true,"refresh_button":true,"required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"tool_description":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Description","dynamic":false,"info":"Enter the description of the tool.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"tool_description","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"tool_function":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Tool Function","dynamic":false,"external_options":{},"info":"Select the function for additional expressions.","name":"tool_function","options":[],"options_metadata":[],"placeholder":"","real_time_refresh":true,"refresh_button":true,"required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"tool_name":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Tool Name","dynamic":false,"info":"Enter the name of the tool.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"tool_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"PythonREPLTool":{"base_classes":["Data","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"A tool for running Python code in a REPL environment.","display_name":"Python REPL","documentation":"","edited":false,"field_order":["name","description","global_imports","code"],"frozen":false,"icon":"Python","legacy":true,"metadata":{"code_hash":"695ab612478d","dependencies":{"dependencies":[{"name":"langchain","version":"0.3.23"},{"name":"langchain_core","version":"0.3.79"},{"name":"langchain_experimental","version":"0.3.4"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":5},"module":"lfx.components.tools.python_repl.PythonREPLToolComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"run_model","name":"api_run_model","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"api_build_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["processing.PythonREPLComponent"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import importlib\n\nfrom langchain.tools import StructuredTool\nfrom langchain_core.tools import ToolException\nfrom langchain_experimental.utilities import PythonREPL\nfrom pydantic import BaseModel, Field\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.field_typing import Tool\nfrom lfx.inputs.inputs import StrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\n\n\nclass PythonREPLToolComponent(LCToolComponent):\n    display_name = \"Python REPL\"\n    description = \"A tool for running Python code in a REPL environment.\"\n    name = \"PythonREPLTool\"\n    icon = \"Python\"\n    legacy = True\n    replacement = [\"processing.PythonREPLComponent\"]\n\n    inputs = [\n        StrInput(\n            name=\"name\",\n            display_name=\"Tool Name\",\n            info=\"The name of the tool.\",\n            value=\"python_repl\",\n        ),\n        StrInput(\n            name=\"description\",\n            display_name=\"Tool Description\",\n            info=\"A description of the tool.\",\n            value=\"A Python shell. Use this to execute python commands. \"\n            \"Input should be a valid python command. \"\n            \"If you want to see the output of a value, you should print it out with `print(...)`.\",\n        ),\n        StrInput(\n            name=\"global_imports\",\n            display_name=\"Global Imports\",\n            info=\"A comma-separated list of modules to import globally, e.g. 'math,numpy'.\",\n            value=\"math\",\n        ),\n        StrInput(\n            name=\"code\",\n            display_name=\"Python Code\",\n            info=\"The Python code to execute.\",\n            value=\"print('Hello, World!')\",\n        ),\n    ]\n\n    class PythonREPLSchema(BaseModel):\n        code: str = Field(..., description=\"The Python code to execute.\")\n\n    def get_globals(self, global_imports: str | list[str]) -> dict:\n        global_dict = {}\n        if isinstance(global_imports, str):\n            modules = [module.strip() for module in global_imports.split(\",\")]\n        elif isinstance(global_imports, list):\n            modules = global_imports\n        else:\n            msg = \"global_imports must be either a string or a list\"\n            raise TypeError(msg)\n\n        for module in modules:\n            try:\n                imported_module = importlib.import_module(module)\n                global_dict[imported_module.__name__] = imported_module\n            except ImportError as e:\n                msg = f\"Could not import module {module}\"\n                raise ImportError(msg) from e\n        return global_dict\n\n    def build_tool(self) -> Tool:\n        globals_ = self.get_globals(self.global_imports)\n        python_repl = PythonREPL(_globals=globals_)\n\n        def run_python_code(code: str) -> str:\n            try:\n                return python_repl.run(code)\n            except Exception as e:\n                logger.debug(\"Error running Python code\", exc_info=True)\n                raise ToolException(str(e)) from e\n\n        tool = StructuredTool.from_function(\n            name=self.name,\n            description=self.description,\n            func=run_python_code,\n            args_schema=self.PythonREPLSchema,\n        )\n\n        self.status = f\"Python REPL Tool created with global imports: {self.global_imports}\"\n        return tool\n\n    def run_model(self) -> list[Data]:\n        tool = self.build_tool()\n        result = tool.run(self.code)\n        return [Data(data={\"result\": result})]\n"},"description":{"_input_type":"StrInput","advanced":false,"display_name":"Tool Description","dynamic":false,"info":"A description of the tool.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"description","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`."},"global_imports":{"_input_type":"StrInput","advanced":false,"display_name":"Global Imports","dynamic":false,"info":"A comma-separated list of modules to import globally, e.g. 'math,numpy'.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"global_imports","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"math"},"name":{"_input_type":"StrInput","advanced":false,"display_name":"Tool Name","dynamic":false,"info":"The name of the tool.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"python_repl"}},"tool_mode":false},"SearXNGTool":{"base_classes":["Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"A component that searches for tools using SearXNG.","display_name":"SearXNG Search","documentation":"","edited":false,"field_order":["url","max_results","categories","language"],"frozen":false,"legacy":true,"metadata":{"code_hash":"154e292dad2b","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"langchain","version":"0.3.23"},{"name":"langchain_core","version":"0.3.79"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":5},"module":"lfx.components.tools.searxng.SearXNGToolComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"result_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","categories":{"_input_type":"MultiselectInput","advanced":false,"combobox":false,"display_name":"Categories","dynamic":false,"info":"","list":true,"list_add_label":"Add More","name":"categories","options":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":[]},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nfrom collections.abc import Sequence\nfrom typing import Any\n\nimport requests\nfrom langchain.agents import Tool\nfrom langchain_core.tools import StructuredTool\nfrom pydantic.v1 import Field, create_model\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.inputs.inputs import DropdownInput, IntInput, MessageTextInput, MultiselectInput\nfrom lfx.io import Output\nfrom lfx.log.logger import logger\nfrom lfx.schema.dotdict import dotdict\n\n\nclass SearXNGToolComponent(LCToolComponent):\n    search_headers: dict = {}\n    display_name = \"SearXNG Search\"\n    description = \"A component that searches for tools using SearXNG.\"\n    name = \"SearXNGTool\"\n    legacy: bool = True\n\n    inputs = [\n        MessageTextInput(\n            name=\"url\",\n            display_name=\"URL\",\n            value=\"http://localhost\",\n            required=True,\n            refresh_button=True,\n        ),\n        IntInput(\n            name=\"max_results\",\n            display_name=\"Max Results\",\n            value=10,\n            required=True,\n        ),\n        MultiselectInput(\n            name=\"categories\",\n            display_name=\"Categories\",\n            options=[],\n            value=[],\n        ),\n        DropdownInput(\n            name=\"language\",\n            display_name=\"Language\",\n            options=[],\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Tool\", name=\"result_tool\", method=\"build_tool\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name is None:\n            return build_config\n\n        if field_name != \"url\":\n            return build_config\n\n        try:\n            url = f\"{field_value}/config\"\n\n            response = requests.get(url=url, headers=self.search_headers.copy(), timeout=10)\n            data = None\n            if response.headers.get(\"Content-Encoding\") == \"zstd\":\n                data = json.loads(response.content)\n            else:\n                data = response.json()\n            build_config[\"categories\"][\"options\"] = data[\"categories\"].copy()\n            for selected_category in build_config[\"categories\"][\"value\"]:\n                if selected_category not in build_config[\"categories\"][\"options\"]:\n                    build_config[\"categories\"][\"value\"].remove(selected_category)\n            languages = list(data[\"locales\"])\n            build_config[\"language\"][\"options\"] = languages.copy()\n        except Exception as e:  # noqa: BLE001\n            self.status = f\"Failed to extract names: {e}\"\n            logger.debug(self.status, exc_info=True)\n            build_config[\"categories\"][\"options\"] = [\"Failed to parse\", str(e)]\n        return build_config\n\n    def build_tool(self) -> Tool:\n        class SearxSearch:\n            _url: str = \"\"\n            _categories: list[str] = []\n            _language: str = \"\"\n            _headers: dict = {}\n            _max_results: int = 10\n\n            @staticmethod\n            def search(query: str, categories: Sequence[str] = ()) -> list:\n                if not SearxSearch._categories and not categories:\n                    msg = \"No categories provided.\"\n                    raise ValueError(msg)\n                all_categories = SearxSearch._categories + list(set(categories) - set(SearxSearch._categories))\n                try:\n                    url = f\"{SearxSearch._url}/\"\n                    headers = SearxSearch._headers.copy()\n                    response = requests.get(\n                        url=url,\n                        headers=headers,\n                        params={\n                            \"q\": query,\n                            \"categories\": \",\".join(all_categories),\n                            \"language\": SearxSearch._language,\n                            \"format\": \"json\",\n                        },\n                        timeout=10,\n                    ).json()\n\n                    num_results = min(SearxSearch._max_results, len(response[\"results\"]))\n                    return [response[\"results\"][i] for i in range(num_results)]\n                except Exception as e:  # noqa: BLE001\n                    logger.debug(\"Error running SearXNG Search\", exc_info=True)\n                    return [f\"Failed to search: {e}\"]\n\n        SearxSearch._url = self.url\n        SearxSearch._categories = self.categories.copy()\n        SearxSearch._language = self.language\n        SearxSearch._headers = self.search_headers.copy()\n        SearxSearch._max_results = self.max_results\n\n        globals_ = globals()\n        local = {}\n        local[\"SearxSearch\"] = SearxSearch\n        globals_.update(local)\n\n        schema_fields = {\n            \"query\": (str, Field(..., description=\"The query to search for.\")),\n            \"categories\": (\n                list[str],\n                Field(default=[], description=\"The categories to search in.\"),\n            ),\n        }\n\n        searx_search_schema = create_model(\"SearxSearchSchema\", **schema_fields)\n\n        return StructuredTool.from_function(\n            func=local[\"SearxSearch\"].search,\n            args_schema=searx_search_schema,\n            name=\"searxng_search_tool\",\n            description=\"A tool that searches for tools using SearXNG.\\nThe available categories are: \"\n            + \", \".join(self.categories),\n        )\n"},"language":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Language","dynamic":false,"external_options":{},"info":"","name":"language","options":[],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"max_results":{"_input_type":"IntInput","advanced":false,"display_name":"Max Results","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"max_results","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":10},"url":{"_input_type":"MessageTextInput","advanced":false,"display_name":"URL","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"url","placeholder":"","refresh_button":true,"required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"http://localhost"}},"tool_mode":false},"SearchAPI":{"base_classes":["Data","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Call the searchapi.io API with result limiting","display_name":"Search API","documentation":"https://www.searchapi.io/docs/google","edited":false,"field_order":["engine","api_key","input_value","search_params","max_results","max_snippet_length"],"frozen":false,"icon":"SearchAPI","legacy":true,"metadata":{"code_hash":"4a9c8b914b68","dependencies":{"dependencies":[{"name":"langchain","version":"0.3.23"},{"name":"langchain_community","version":"0.3.21"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.tools.search_api.SearchAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"run_model","name":"api_run_model","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"api_build_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["searchapi.SearchComponent"],"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"SearchAPI API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom langchain.tools import StructuredTool\nfrom langchain_community.utilities.searchapi import SearchApiAPIWrapper\nfrom pydantic import BaseModel, Field\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.field_typing import Tool\nfrom lfx.inputs.inputs import DictInput, IntInput, MessageTextInput, MultilineInput, SecretStrInput\nfrom lfx.schema.data import Data\n\n\nclass SearchAPIComponent(LCToolComponent):\n    display_name: str = \"Search API\"\n    description: str = \"Call the searchapi.io API with result limiting\"\n    name = \"SearchAPI\"\n    documentation: str = \"https://www.searchapi.io/docs/google\"\n    icon = \"SearchAPI\"\n    legacy = True\n    replacement = [\"searchapi.SearchComponent\"]\n\n    inputs = [\n        MessageTextInput(name=\"engine\", display_name=\"Engine\", value=\"google\"),\n        SecretStrInput(name=\"api_key\", display_name=\"SearchAPI API Key\", required=True),\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n        ),\n        DictInput(name=\"search_params\", display_name=\"Search parameters\", advanced=True, is_list=True),\n        IntInput(name=\"max_results\", display_name=\"Max Results\", value=5, advanced=True),\n        IntInput(name=\"max_snippet_length\", display_name=\"Max Snippet Length\", value=100, advanced=True),\n    ]\n\n    class SearchAPISchema(BaseModel):\n        query: str = Field(..., description=\"The search query\")\n        params: dict[str, Any] = Field(default_factory=dict, description=\"Additional search parameters\")\n        max_results: int = Field(5, description=\"Maximum number of results to return\")\n        max_snippet_length: int = Field(100, description=\"Maximum length of each result snippet\")\n\n    def _build_wrapper(self):\n        return SearchApiAPIWrapper(engine=self.engine, searchapi_api_key=self.api_key)\n\n    def build_tool(self) -> Tool:\n        wrapper = self._build_wrapper()\n\n        def search_func(\n            query: str, params: dict[str, Any] | None = None, max_results: int = 5, max_snippet_length: int = 100\n        ) -> list[dict[str, Any]]:\n            params = params or {}\n            full_results = wrapper.results(query=query, **params)\n            organic_results = full_results.get(\"organic_results\", [])[:max_results]\n\n            limited_results = []\n            for result in organic_results:\n                limited_result = {\n                    \"title\": result.get(\"title\", \"\")[:max_snippet_length],\n                    \"link\": result.get(\"link\", \"\"),\n                    \"snippet\": result.get(\"snippet\", \"\")[:max_snippet_length],\n                }\n                limited_results.append(limited_result)\n\n            return limited_results\n\n        tool = StructuredTool.from_function(\n            name=\"search_api\",\n            description=\"Search for recent results using searchapi.io with result limiting\",\n            func=search_func,\n            args_schema=self.SearchAPISchema,\n        )\n\n        self.status = f\"Search API Tool created with engine: {self.engine}\"\n        return tool\n\n    def run_model(self) -> list[Data]:\n        tool = self.build_tool()\n        results = tool.run(\n            {\n                \"query\": self.input_value,\n                \"params\": self.search_params or {},\n                \"max_results\": self.max_results,\n                \"max_snippet_length\": self.max_snippet_length,\n            }\n        )\n\n        data_list = [Data(data=result, text=result.get(\"snippet\", \"\")) for result in results]\n\n        self.status = data_list\n        return data_list\n"},"engine":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Engine","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"engine","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"google"},"input_value":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"max_results":{"_input_type":"IntInput","advanced":true,"display_name":"Max Results","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"max_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5},"max_snippet_length":{"_input_type":"IntInput","advanced":true,"display_name":"Max Snippet Length","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"max_snippet_length","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":100},"search_params":{"_input_type":"DictInput","advanced":true,"display_name":"Search parameters","dynamic":false,"info":"","list":true,"list_add_label":"Add More","name":"search_params","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}}},"tool_mode":false},"SerpAPI":{"base_classes":["Data","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Call Serp Search API with result limiting","display_name":"Serp Search API","documentation":"","edited":false,"field_order":["serpapi_api_key","input_value","search_params","max_results","max_snippet_length"],"frozen":false,"icon":"SerpSearch","legacy":true,"metadata":{"code_hash":"882d7b35a9d7","dependencies":{"dependencies":[{"name":"langchain","version":"0.3.23"},{"name":"langchain_community","version":"0.3.21"},{"name":"langchain_core","version":"0.3.79"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":5},"module":"lfx.components.tools.serp_api.SerpAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"run_model","name":"api_run_model","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"api_build_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["serpapi.Serp"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom langchain.tools import StructuredTool\nfrom langchain_community.utilities.serpapi import SerpAPIWrapper\nfrom langchain_core.tools import ToolException\nfrom pydantic import BaseModel, Field\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.field_typing import Tool\nfrom lfx.inputs.inputs import DictInput, IntInput, MultilineInput, SecretStrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\n\n\nclass SerpAPISchema(BaseModel):\n    \"\"\"Schema for SerpAPI search parameters.\"\"\"\n\n    query: str = Field(..., description=\"The search query\")\n    params: dict[str, Any] | None = Field(\n        default={\n            \"engine\": \"google\",\n            \"google_domain\": \"google.com\",\n            \"gl\": \"us\",\n            \"hl\": \"en\",\n        },\n        description=\"Additional search parameters\",\n    )\n    max_results: int = Field(5, description=\"Maximum number of results to return\")\n    max_snippet_length: int = Field(100, description=\"Maximum length of each result snippet\")\n\n\nclass SerpAPIComponent(LCToolComponent):\n    display_name = \"Serp Search API\"\n    description = \"Call Serp Search API with result limiting\"\n    name = \"SerpAPI\"\n    icon = \"SerpSearch\"\n    legacy = True\n    replacement = [\"serpapi.Serp\"]\n\n    inputs = [\n        SecretStrInput(name=\"serpapi_api_key\", display_name=\"SerpAPI API Key\", required=True),\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n        ),\n        DictInput(name=\"search_params\", display_name=\"Parameters\", advanced=True, is_list=True),\n        IntInput(name=\"max_results\", display_name=\"Max Results\", value=5, advanced=True),\n        IntInput(name=\"max_snippet_length\", display_name=\"Max Snippet Length\", value=100, advanced=True),\n    ]\n\n    def _build_wrapper(self, params: dict[str, Any] | None = None) -> SerpAPIWrapper:\n        \"\"\"Build a SerpAPIWrapper with the provided parameters.\"\"\"\n        params = params or {}\n        if params:\n            return SerpAPIWrapper(\n                serpapi_api_key=self.serpapi_api_key,\n                params=params,\n            )\n        return SerpAPIWrapper(serpapi_api_key=self.serpapi_api_key)\n\n    def build_tool(self) -> Tool:\n        wrapper = self._build_wrapper(self.search_params)\n\n        def search_func(\n            query: str, params: dict[str, Any] | None = None, max_results: int = 5, max_snippet_length: int = 100\n        ) -> list[dict[str, Any]]:\n            try:\n                local_wrapper = wrapper\n                if params:\n                    local_wrapper = self._build_wrapper(params)\n\n                full_results = local_wrapper.results(query)\n                organic_results = full_results.get(\"organic_results\", [])[:max_results]\n\n                limited_results = []\n                for result in organic_results:\n                    limited_result = {\n                        \"title\": result.get(\"title\", \"\")[:max_snippet_length],\n                        \"link\": result.get(\"link\", \"\"),\n                        \"snippet\": result.get(\"snippet\", \"\")[:max_snippet_length],\n                    }\n                    limited_results.append(limited_result)\n\n            except Exception as e:\n                error_message = f\"Error in SerpAPI search: {e!s}\"\n                logger.debug(error_message)\n                raise ToolException(error_message) from e\n            return limited_results\n\n        tool = StructuredTool.from_function(\n            name=\"serp_search_api\",\n            description=\"Search for recent results using SerpAPI with result limiting\",\n            func=search_func,\n            args_schema=SerpAPISchema,\n        )\n\n        self.status = \"SerpAPI Tool created\"\n        return tool\n\n    def run_model(self) -> list[Data]:\n        tool = self.build_tool()\n        try:\n            results = tool.run(\n                {\n                    \"query\": self.input_value,\n                    \"params\": self.search_params or {},\n                    \"max_results\": self.max_results,\n                    \"max_snippet_length\": self.max_snippet_length,\n                }\n            )\n\n            data_list = [Data(data=result, text=result.get(\"snippet\", \"\")) for result in results]\n\n        except Exception as e:  # noqa: BLE001\n            logger.debug(\"Error running SerpAPI\", exc_info=True)\n            self.status = f\"Error: {e}\"\n            return [Data(data={\"error\": str(e)}, text=str(e))]\n\n        self.status = data_list  # type: ignore[assignment]\n        return data_list\n"},"input_value":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"max_results":{"_input_type":"IntInput","advanced":true,"display_name":"Max Results","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"max_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5},"max_snippet_length":{"_input_type":"IntInput","advanced":true,"display_name":"Max Snippet Length","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"max_snippet_length","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":100},"search_params":{"_input_type":"DictInput","advanced":true,"display_name":"Parameters","dynamic":false,"info":"","list":true,"list_add_label":"Add More","name":"search_params","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"serpapi_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"SerpAPI API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"serpapi_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""}},"tool_mode":false},"TavilyAISearch":{"base_classes":["Data","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"**Tavily Search API** is a search engine optimized for LLMs and RAG,         aimed at efficient, quick, and persistent search results. It can be used independently or as an agent tool.\n\nNote: Check 'Advanced' for all options.\n","display_name":"Tavily Search API","documentation":"https://docs.tavily.com/","edited":false,"field_order":["api_key","query","search_depth","chunks_per_source","topic","days","max_results","include_answer","time_range","include_images","include_domains","exclude_domains","include_raw_content"],"frozen":false,"icon":"TavilyIcon","legacy":true,"metadata":{"code_hash":"70b5611e8fd6","dependencies":{"dependencies":[{"name":"httpx","version":"0.28.1"},{"name":"langchain","version":"0.3.23"},{"name":"langchain_core","version":"0.3.79"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":5},"module":"lfx.components.tools.tavily_search_tool.TavilySearchToolComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"run_model","name":"api_run_model","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"api_build_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["tavily.TavilySearchComponent"],"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Tavily API Key","dynamic":false,"info":"Your Tavily API Key.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"chunks_per_source":{"_input_type":"IntInput","advanced":true,"display_name":"Chunks Per Source","dynamic":false,"info":"The number of content chunks to retrieve from each source (1-3). Only works with advanced search.","list":false,"list_add_label":"Add More","name":"chunks_per_source","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":3},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from enum import Enum\n\nimport httpx\nfrom langchain.tools import StructuredTool\nfrom langchain_core.tools import ToolException\nfrom pydantic import BaseModel, Field\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.field_typing import Tool\nfrom lfx.inputs.inputs import BoolInput, DropdownInput, IntInput, MessageTextInput, SecretStrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\n\n# Add at the top with other constants\nMAX_CHUNKS_PER_SOURCE = 3\n\n\nclass TavilySearchDepth(Enum):\n    BASIC = \"basic\"\n    ADVANCED = \"advanced\"\n\n\nclass TavilySearchTopic(Enum):\n    GENERAL = \"general\"\n    NEWS = \"news\"\n\n\nclass TavilySearchTimeRange(Enum):\n    DAY = \"day\"\n    WEEK = \"week\"\n    MONTH = \"month\"\n    YEAR = \"year\"\n\n\nclass TavilySearchSchema(BaseModel):\n    query: str = Field(..., description=\"The search query you want to execute with Tavily.\")\n    search_depth: TavilySearchDepth = Field(TavilySearchDepth.BASIC, description=\"The depth of the search.\")\n    topic: TavilySearchTopic = Field(TavilySearchTopic.GENERAL, description=\"The category of the search.\")\n    max_results: int = Field(5, description=\"The maximum number of search results to return.\")\n    include_images: bool = Field(default=False, description=\"Include a list of query-related images in the response.\")\n    include_answer: bool = Field(default=False, description=\"Include a short answer to original query.\")\n    chunks_per_source: int = Field(\n        default=MAX_CHUNKS_PER_SOURCE,\n        description=(\n            \"The number of content chunks to retrieve from each source (max 500 chars each). Only for advanced search.\"\n        ),\n        ge=1,\n        le=MAX_CHUNKS_PER_SOURCE,\n    )\n    include_domains: list[str] = Field(\n        default=[],\n        description=\"A list of domains to specifically include in the search results.\",\n    )\n    exclude_domains: list[str] = Field(\n        default=[],\n        description=\"A list of domains to specifically exclude from the search results.\",\n    )\n    include_raw_content: bool = Field(\n        default=False,\n        description=\"Include the cleaned and parsed HTML content of each search result.\",\n    )\n    days: int = Field(\n        default=7,\n        description=\"Number of days back from the current date to include. Only available if topic is news.\",\n        ge=1,\n    )\n    time_range: TavilySearchTimeRange | None = Field(\n        default=None,\n        description=\"The time range back from the current date to filter results.\",\n    )\n\n\nclass TavilySearchToolComponent(LCToolComponent):\n    display_name = \"Tavily Search API\"\n    description = \"\"\"**Tavily Search API** is a search engine optimized for LLMs and RAG, \\\n        aimed at efficient, quick, and persistent search results. It can be used independently or as an agent tool.\n\nNote: Check 'Advanced' for all options.\n\"\"\"\n    icon = \"TavilyIcon\"\n    name = \"TavilyAISearch\"\n    documentation = \"https://docs.tavily.com/\"\n    legacy = True\n    replacement = [\"tavily.TavilySearchComponent\"]\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Tavily API Key\",\n            required=True,\n            info=\"Your Tavily API Key.\",\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"Search Query\",\n            info=\"The search query you want to execute with Tavily.\",\n        ),\n        DropdownInput(\n            name=\"search_depth\",\n            display_name=\"Search Depth\",\n            info=\"The depth of the search.\",\n            options=list(TavilySearchDepth),\n            value=TavilySearchDepth.ADVANCED,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chunks_per_source\",\n            display_name=\"Chunks Per Source\",\n            info=(\"The number of content chunks to retrieve from each source (1-3). Only works with advanced search.\"),\n            value=MAX_CHUNKS_PER_SOURCE,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"topic\",\n            display_name=\"Search Topic\",\n            info=\"The category of the search.\",\n            options=list(TavilySearchTopic),\n            value=TavilySearchTopic.GENERAL,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"days\",\n            display_name=\"Days\",\n            info=\"Number of days back from current date to include. Only available with news topic.\",\n            value=7,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_results\",\n            display_name=\"Max Results\",\n            info=\"The maximum number of search results to return.\",\n            value=5,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_answer\",\n            display_name=\"Include Answer\",\n            info=\"Include a short answer to original query.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"time_range\",\n            display_name=\"Time Range\",\n            info=\"The time range back from the current date to filter results.\",\n            options=list(TavilySearchTimeRange),\n            value=None,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_images\",\n            display_name=\"Include Images\",\n            info=\"Include a list of query-related images in the response.\",\n            value=True,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"include_domains\",\n            display_name=\"Include Domains\",\n            info=\"Comma-separated list of domains to include in the search results.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"exclude_domains\",\n            display_name=\"Exclude Domains\",\n            info=\"Comma-separated list of domains to exclude from the search results.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_raw_content\",\n            display_name=\"Include Raw Content\",\n            info=\"Include the cleaned and parsed HTML content of each search result.\",\n            value=False,\n            advanced=True,\n        ),\n    ]\n\n    def run_model(self) -> list[Data]:\n        # Convert string values to enum instances with validation\n        try:\n            search_depth_enum = (\n                self.search_depth\n                if isinstance(self.search_depth, TavilySearchDepth)\n                else TavilySearchDepth(str(self.search_depth).lower())\n            )\n        except ValueError as e:\n            error_message = f\"Invalid search depth value: {e!s}\"\n            self.status = error_message\n            return [Data(data={\"error\": error_message})]\n\n        try:\n            topic_enum = (\n                self.topic if isinstance(self.topic, TavilySearchTopic) else TavilySearchTopic(str(self.topic).lower())\n            )\n        except ValueError as e:\n            error_message = f\"Invalid topic value: {e!s}\"\n            self.status = error_message\n            return [Data(data={\"error\": error_message})]\n\n        try:\n            time_range_enum = (\n                self.time_range\n                if isinstance(self.time_range, TavilySearchTimeRange)\n                else TavilySearchTimeRange(str(self.time_range).lower())\n                if self.time_range\n                else None\n            )\n        except ValueError as e:\n            error_message = f\"Invalid time range value: {e!s}\"\n            self.status = error_message\n            return [Data(data={\"error\": error_message})]\n\n        # Initialize domain variables as None\n        include_domains = None\n        exclude_domains = None\n\n        # Only process domains if they're provided\n        if self.include_domains:\n            include_domains = [domain.strip() for domain in self.include_domains.split(\",\") if domain.strip()]\n\n        if self.exclude_domains:\n            exclude_domains = [domain.strip() for domain in self.exclude_domains.split(\",\") if domain.strip()]\n\n        return self._tavily_search(\n            self.query,\n            search_depth=search_depth_enum,\n            topic=topic_enum,\n            max_results=self.max_results,\n            include_images=self.include_images,\n            include_answer=self.include_answer,\n            chunks_per_source=self.chunks_per_source,\n            include_domains=include_domains,\n            exclude_domains=exclude_domains,\n            include_raw_content=self.include_raw_content,\n            days=self.days,\n            time_range=time_range_enum,\n        )\n\n    def build_tool(self) -> Tool:\n        return StructuredTool.from_function(\n            name=\"tavily_search\",\n            description=\"Perform a web search using the Tavily API.\",\n            func=self._tavily_search,\n            args_schema=TavilySearchSchema,\n        )\n\n    def _tavily_search(\n        self,\n        query: str,\n        *,\n        search_depth: TavilySearchDepth = TavilySearchDepth.BASIC,\n        topic: TavilySearchTopic = TavilySearchTopic.GENERAL,\n        max_results: int = 5,\n        include_images: bool = False,\n        include_answer: bool = False,\n        chunks_per_source: int = MAX_CHUNKS_PER_SOURCE,\n        include_domains: list[str] | None = None,\n        exclude_domains: list[str] | None = None,\n        include_raw_content: bool = False,\n        days: int = 7,\n        time_range: TavilySearchTimeRange | None = None,\n    ) -> list[Data]:\n        # Validate enum values\n        if not isinstance(search_depth, TavilySearchDepth):\n            msg = f\"Invalid search_depth value: {search_depth}\"\n            raise TypeError(msg)\n        if not isinstance(topic, TavilySearchTopic):\n            msg = f\"Invalid topic value: {topic}\"\n            raise TypeError(msg)\n\n        # Validate chunks_per_source range\n        if not 1 <= chunks_per_source <= MAX_CHUNKS_PER_SOURCE:\n            msg = f\"chunks_per_source must be between 1 and {MAX_CHUNKS_PER_SOURCE}, got {chunks_per_source}\"\n            raise ValueError(msg)\n\n        # Validate days is positive\n        if days < 1:\n            msg = f\"days must be greater than or equal to 1, got {days}\"\n            raise ValueError(msg)\n\n        try:\n            url = \"https://api.tavily.com/search\"\n            headers = {\n                \"content-type\": \"application/json\",\n                \"accept\": \"application/json\",\n            }\n            payload = {\n                \"api_key\": self.api_key,\n                \"query\": query,\n                \"search_depth\": search_depth.value,\n                \"topic\": topic.value,\n                \"max_results\": max_results,\n                \"include_images\": include_images,\n                \"include_answer\": include_answer,\n                \"chunks_per_source\": chunks_per_source if search_depth == TavilySearchDepth.ADVANCED else None,\n                \"include_domains\": include_domains if include_domains else None,\n                \"exclude_domains\": exclude_domains if exclude_domains else None,\n                \"include_raw_content\": include_raw_content,\n                \"days\": days if topic == TavilySearchTopic.NEWS else None,\n                \"time_range\": time_range.value if time_range else None,\n            }\n\n            with httpx.Client(timeout=90.0) as client:\n                response = client.post(url, json=payload, headers=headers)\n\n            response.raise_for_status()\n            search_results = response.json()\n\n            data_results = [\n                Data(\n                    data={\n                        \"title\": result.get(\"title\"),\n                        \"url\": result.get(\"url\"),\n                        \"content\": result.get(\"content\"),\n                        \"score\": result.get(\"score\"),\n                        \"raw_content\": result.get(\"raw_content\") if include_raw_content else None,\n                    }\n                )\n                for result in search_results.get(\"results\", [])\n            ]\n\n            if include_answer and search_results.get(\"answer\"):\n                data_results.insert(0, Data(data={\"answer\": search_results[\"answer\"]}))\n\n            if include_images and search_results.get(\"images\"):\n                data_results.append(Data(data={\"images\": search_results[\"images\"]}))\n\n            self.status = data_results  # type: ignore[assignment]\n\n        except httpx.TimeoutException as e:\n            error_message = \"Request timed out (90s). Please try again or adjust parameters.\"\n            logger.error(f\"Timeout error: {e}\")\n            self.status = error_message\n            raise ToolException(error_message) from e\n        except httpx.HTTPStatusError as e:\n            error_message = f\"HTTP error: {e.response.status_code} - {e.response.text}\"\n            logger.debug(error_message)\n            self.status = error_message\n            raise ToolException(error_message) from e\n        except Exception as e:\n            error_message = f\"Unexpected error: {e}\"\n            logger.debug(\"Error running Tavily Search\", exc_info=True)\n            self.status = error_message\n            raise ToolException(error_message) from e\n        return data_results\n"},"days":{"_input_type":"IntInput","advanced":true,"display_name":"Days","dynamic":false,"info":"Number of days back from current date to include. Only available with news topic.","list":false,"list_add_label":"Add More","name":"days","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":7},"exclude_domains":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Exclude Domains","dynamic":false,"info":"Comma-separated list of domains to exclude from the search results.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"exclude_domains","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"include_answer":{"_input_type":"BoolInput","advanced":true,"display_name":"Include Answer","dynamic":false,"info":"Include a short answer to original query.","list":false,"list_add_label":"Add More","name":"include_answer","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"include_domains":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Include Domains","dynamic":false,"info":"Comma-separated list of domains to include in the search results.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"include_domains","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"include_images":{"_input_type":"BoolInput","advanced":true,"display_name":"Include Images","dynamic":false,"info":"Include a list of query-related images in the response.","list":false,"list_add_label":"Add More","name":"include_images","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"include_raw_content":{"_input_type":"BoolInput","advanced":true,"display_name":"Include Raw Content","dynamic":false,"info":"Include the cleaned and parsed HTML content of each search result.","list":false,"list_add_label":"Add More","name":"include_raw_content","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"max_results":{"_input_type":"IntInput","advanced":true,"display_name":"Max Results","dynamic":false,"info":"The maximum number of search results to return.","list":false,"list_add_label":"Add More","name":"max_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5},"query":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"The search query you want to execute with Tavily.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"query","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"search_depth":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Search Depth","dynamic":false,"external_options":{},"info":"The depth of the search.","name":"search_depth","options":["basic","advanced"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"advanced"},"time_range":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Time Range","dynamic":false,"external_options":{},"info":"The time range back from the current date to filter results.","name":"time_range","options":["day","week","month","year"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str"},"topic":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Search Topic","dynamic":false,"external_options":{},"info":"The category of the search.","name":"topic","options":["general","news"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"general"}},"tool_mode":false},"WikidataAPI":{"base_classes":["Data","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Performs a search using the Wikidata API.","display_name":"Wikidata API","documentation":"","edited":false,"field_order":["query"],"frozen":false,"icon":"Wikipedia","legacy":true,"metadata":{"code_hash":"4752066f8971","dependencies":{"dependencies":[{"name":"httpx","version":"0.28.1"},{"name":"langchain_core","version":"0.3.79"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.tools.wikidata_api.WikidataAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"run_model","name":"api_run_model","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"api_build_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["wikipedia.WikidataComponent"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nimport httpx\nfrom langchain_core.tools import StructuredTool, ToolException\nfrom pydantic import BaseModel, Field\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.field_typing import Tool\nfrom lfx.inputs.inputs import MultilineInput\nfrom lfx.schema.data import Data\n\n\nclass WikidataSearchSchema(BaseModel):\n    query: str = Field(..., description=\"The search query for Wikidata\")\n\n\nclass WikidataAPIWrapper(BaseModel):\n    \"\"\"Wrapper around Wikidata API.\"\"\"\n\n    wikidata_api_url: str = \"https://www.wikidata.org/w/api.php\"\n\n    def results(self, query: str) -> list[dict[str, Any]]:\n        # Define request parameters for Wikidata API\n        params = {\n            \"action\": \"wbsearchentities\",\n            \"format\": \"json\",\n            \"search\": query,\n            \"language\": \"en\",\n        }\n\n        # Send request to Wikidata API\n        response = httpx.get(self.wikidata_api_url, params=params)\n        response.raise_for_status()\n        response_json = response.json()\n\n        # Extract and return search results\n        return response_json.get(\"search\", [])\n\n    def run(self, query: str) -> list[dict[str, Any]]:\n        try:\n            results = self.results(query)\n            if results:\n                return results\n\n            error_message = \"No search results found for the given query.\"\n\n            raise ToolException(error_message)\n\n        except Exception as e:\n            error_message = f\"Error in Wikidata Search API: {e!s}\"\n\n            raise ToolException(error_message) from e\n\n\nclass WikidataAPIComponent(LCToolComponent):\n    display_name = \"Wikidata API\"\n    description = \"Performs a search using the Wikidata API.\"\n    name = \"WikidataAPI\"\n    icon = \"Wikipedia\"\n    legacy = True\n    replacement = [\"wikipedia.WikidataComponent\"]\n\n    inputs = [\n        MultilineInput(\n            name=\"query\",\n            display_name=\"Query\",\n            info=\"The text query for similarity search on Wikidata.\",\n            required=True,\n        ),\n    ]\n\n    def build_tool(self) -> Tool:\n        wrapper = WikidataAPIWrapper()\n\n        # Define the tool using StructuredTool and wrapper's run method\n        tool = StructuredTool.from_function(\n            name=\"wikidata_search_api\",\n            description=\"Perform similarity search on Wikidata API\",\n            func=wrapper.run,\n            args_schema=WikidataSearchSchema,\n        )\n\n        self.status = \"Wikidata Search API Tool for Langchain\"\n\n        return tool\n\n    def run_model(self) -> list[Data]:\n        tool = self.build_tool()\n\n        results = tool.run({\"query\": self.query})\n\n        # Transform the API response into Data objects\n        data = [\n            Data(\n                text=result[\"label\"],\n                metadata=result,\n            )\n            for result in results\n        ]\n\n        self.status = data  # type: ignore[assignment]\n\n        return data\n"},"query":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Query","dynamic":false,"info":"The text query for similarity search on Wikidata.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"query","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"WikipediaAPI":{"base_classes":["Data","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Call Wikipedia API.","display_name":"Wikipedia API","documentation":"","edited":false,"field_order":["input_value","lang","k","load_all_available_meta","doc_content_chars_max"],"frozen":false,"icon":"Wikipedia","legacy":true,"metadata":{"code_hash":"d7ae953444c9","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.tools.wikipedia_api.WikipediaAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"run_model","name":"api_run_model","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"api_build_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["wikipedia.WikipediaComponent"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import cast\n\nfrom langchain_community.tools import WikipediaQueryRun\nfrom langchain_community.utilities.wikipedia import WikipediaAPIWrapper\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.field_typing import Tool\nfrom lfx.inputs.inputs import BoolInput, IntInput, MessageTextInput, MultilineInput\nfrom lfx.schema.data import Data\n\n\nclass WikipediaAPIComponent(LCToolComponent):\n    display_name = \"Wikipedia API\"\n    description = \"Call Wikipedia API.\"\n    name = \"WikipediaAPI\"\n    icon = \"Wikipedia\"\n    legacy = True\n    replacement = [\"wikipedia.WikipediaComponent\"]\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n        ),\n        MessageTextInput(name=\"lang\", display_name=\"Language\", value=\"en\"),\n        IntInput(name=\"k\", display_name=\"Number of results\", value=4, required=True),\n        BoolInput(name=\"load_all_available_meta\", display_name=\"Load all available meta\", value=False, advanced=True),\n        IntInput(\n            name=\"doc_content_chars_max\", display_name=\"Document content characters max\", value=4000, advanced=True\n        ),\n    ]\n\n    def run_model(self) -> list[Data]:\n        wrapper = self._build_wrapper()\n        docs = wrapper.load(self.input_value)\n        data = [Data.from_document(doc) for doc in docs]\n        self.status = data\n        return data\n\n    def build_tool(self) -> Tool:\n        wrapper = self._build_wrapper()\n        return cast(\"Tool\", WikipediaQueryRun(api_wrapper=wrapper))\n\n    def _build_wrapper(self) -> WikipediaAPIWrapper:\n        return WikipediaAPIWrapper(\n            top_k_results=self.k,\n            lang=self.lang,\n            load_all_available_meta=self.load_all_available_meta,\n            doc_content_chars_max=self.doc_content_chars_max,\n        )\n"},"doc_content_chars_max":{"_input_type":"IntInput","advanced":true,"display_name":"Document content characters max","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"doc_content_chars_max","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4000},"input_value":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"k":{"_input_type":"IntInput","advanced":false,"display_name":"Number of results","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"k","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"lang":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Language","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"lang","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"en"},"load_all_available_meta":{"_input_type":"BoolInput","advanced":true,"display_name":"Load all available meta","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"load_all_available_meta","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false},"YahooFinanceTool":{"base_classes":["Data","Tool"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Uses [yfinance](https://pypi.org/project/yfinance/) (unofficial package) to access financial data and market information from Yahoo! Finance.","display_name":"Yahoo! Finance","documentation":"","edited":false,"field_order":["symbol","method","num_news"],"frozen":false,"icon":"trending-up","legacy":true,"metadata":{"code_hash":"fda358f6395e","dependencies":{"dependencies":[{"name":"langchain","version":"0.3.23"},{"name":"langchain_core","version":"0.3.79"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null},{"name":"yfinance","version":"0.2.50"}],"total_dependencies":5},"module":"lfx.components.tools.yahoo_finance.YfinanceToolComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Data","group_outputs":false,"method":"run_model","name":"api_run_model","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Tool","group_outputs":false,"method":"build_tool","name":"api_build_tool","selected":"Tool","tool_mode":true,"types":["Tool"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["yahoosearch.YfinanceComponent"],"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import ast\nimport pprint\nfrom enum import Enum\n\nfrom langchain.tools import StructuredTool\nfrom langchain_core.tools import ToolException\nfrom pydantic import BaseModel, Field\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.field_typing import Tool\nfrom lfx.inputs.inputs import DropdownInput, IntInput, MessageTextInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\n\n\nclass YahooFinanceMethod(Enum):\n    GET_INFO = \"get_info\"\n    GET_NEWS = \"get_news\"\n    GET_ACTIONS = \"get_actions\"\n    GET_ANALYSIS = \"get_analysis\"\n    GET_BALANCE_SHEET = \"get_balance_sheet\"\n    GET_CALENDAR = \"get_calendar\"\n    GET_CASHFLOW = \"get_cashflow\"\n    GET_INSTITUTIONAL_HOLDERS = \"get_institutional_holders\"\n    GET_RECOMMENDATIONS = \"get_recommendations\"\n    GET_SUSTAINABILITY = \"get_sustainability\"\n    GET_MAJOR_HOLDERS = \"get_major_holders\"\n    GET_MUTUALFUND_HOLDERS = \"get_mutualfund_holders\"\n    GET_INSIDER_PURCHASES = \"get_insider_purchases\"\n    GET_INSIDER_TRANSACTIONS = \"get_insider_transactions\"\n    GET_INSIDER_ROSTER_HOLDERS = \"get_insider_roster_holders\"\n    GET_DIVIDENDS = \"get_dividends\"\n    GET_CAPITAL_GAINS = \"get_capital_gains\"\n    GET_SPLITS = \"get_splits\"\n    GET_SHARES = \"get_shares\"\n    GET_FAST_INFO = \"get_fast_info\"\n    GET_SEC_FILINGS = \"get_sec_filings\"\n    GET_RECOMMENDATIONS_SUMMARY = \"get_recommendations_summary\"\n    GET_UPGRADES_DOWNGRADES = \"get_upgrades_downgrades\"\n    GET_EARNINGS = \"get_earnings\"\n    GET_INCOME_STMT = \"get_income_stmt\"\n\n\nclass YahooFinanceSchema(BaseModel):\n    symbol: str = Field(..., description=\"The stock symbol to retrieve data for.\")\n    method: YahooFinanceMethod = Field(YahooFinanceMethod.GET_INFO, description=\"The type of data to retrieve.\")\n    num_news: int | None = Field(5, description=\"The number of news articles to retrieve.\")\n\n\nclass YfinanceToolComponent(LCToolComponent):\n    display_name = \"Yahoo! Finance\"\n    description = \"\"\"Uses [yfinance](https://pypi.org/project/yfinance/) (unofficial package) \\\nto access financial data and market information from Yahoo! Finance.\"\"\"\n    icon = \"trending-up\"\n    name = \"YahooFinanceTool\"\n    legacy = True\n    replacement = [\"yahoosearch.YfinanceComponent\"]\n\n    inputs = [\n        MessageTextInput(\n            name=\"symbol\",\n            display_name=\"Stock Symbol\",\n            info=\"The stock symbol to retrieve data for (e.g., AAPL, GOOG).\",\n        ),\n        DropdownInput(\n            name=\"method\",\n            display_name=\"Data Method\",\n            info=\"The type of data to retrieve.\",\n            options=list(YahooFinanceMethod),\n            value=\"get_news\",\n        ),\n        IntInput(\n            name=\"num_news\",\n            display_name=\"Number of News\",\n            info=\"The number of news articles to retrieve (only applicable for get_news).\",\n            value=5,\n        ),\n    ]\n\n    def run_model(self) -> list[Data]:\n        return self._yahoo_finance_tool(\n            self.symbol,\n            self.method,\n            self.num_news,\n        )\n\n    def build_tool(self) -> Tool:\n        return StructuredTool.from_function(\n            name=\"yahoo_finance\",\n            description=\"Access financial data and market information from Yahoo! Finance.\",\n            func=self._yahoo_finance_tool,\n            args_schema=YahooFinanceSchema,\n        )\n\n    def _yahoo_finance_tool(\n        self,\n        symbol: str,\n        method: YahooFinanceMethod,\n        num_news: int | None = 5,\n    ) -> list[Data]:\n        try:\n            import yfinance as yf\n        except ImportError as e:\n            msg = \"\"\n            raise ImportError(msg) from e\n\n        ticker = yf.Ticker(symbol)\n\n        try:\n            if method == YahooFinanceMethod.GET_INFO:\n                result = ticker.info\n            elif method == YahooFinanceMethod.GET_NEWS:\n                result = ticker.news[:num_news]\n            else:\n                result = getattr(ticker, method.value)()\n\n            result = pprint.pformat(result)\n\n            if method == YahooFinanceMethod.GET_NEWS:\n                data_list = [Data(data=article) for article in ast.literal_eval(result)]\n            else:\n                data_list = [Data(data={\"result\": result})]\n\n        except Exception as e:\n            error_message = f\"Error retrieving data: {e}\"\n            logger.debug(error_message)\n            self.status = error_message\n            raise ToolException(error_message) from e\n\n        return data_list\n"},"method":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Data Method","dynamic":false,"external_options":{},"info":"The type of data to retrieve.","name":"method","options":["get_info","get_news","get_actions","get_analysis","get_balance_sheet","get_calendar","get_cashflow","get_institutional_holders","get_recommendations","get_sustainability","get_major_holders","get_mutualfund_holders","get_insider_purchases","get_insider_transactions","get_insider_roster_holders","get_dividends","get_capital_gains","get_splits","get_shares","get_fast_info","get_sec_filings","get_recommendations_summary","get_upgrades_downgrades","get_earnings","get_income_stmt"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"get_news"},"num_news":{"_input_type":"IntInput","advanced":false,"display_name":"Number of News","dynamic":false,"info":"The number of news articles to retrieve (only applicable for get_news).","list":false,"list_add_label":"Add More","name":"num_news","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5},"symbol":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Stock Symbol","dynamic":false,"info":"The stock symbol to retrieve data for (e.g., AAPL, GOOG).","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"symbol","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["twelvelabs",{"ConvertAstraToTwelveLabs":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Converts Astra DB search results to inputs compatible with TwelveLabs Pegasus.","display_name":"Convert Astra DB to Pegasus Input","documentation":"https://github.com/twelvelabs-io/twelvelabs-developer-experience/blob/main/integrations/Langflow/TWELVE_LABS_COMPONENTS_README.md","edited":false,"field_order":["astra_results"],"frozen":false,"icon":"TwelveLabs","legacy":false,"metadata":{"code_hash":"90ad7b9b59eb","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.twelvelabs.convert_astra_results.ConvertAstraToTwelveLabs"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Index ID","group_outputs":false,"method":"get_index_id","name":"index_id","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Video ID","group_outputs":false,"method":"get_video_id","name":"video_id","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","astra_results":{"_input_type":"HandleInput","advanced":false,"display_name":"Astra DB Results","dynamic":false,"info":"Search results from Astra DB component","input_types":["Data"],"list":true,"list_add_label":"Add More","name":"astra_results","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom lfx.custom import Component\nfrom lfx.io import HandleInput, Output\nfrom lfx.schema import Data\nfrom lfx.schema.message import Message\n\n\nclass ConvertAstraToTwelveLabs(Component):\n    \"\"\"Convert Astra DB search results to TwelveLabs Pegasus inputs.\"\"\"\n\n    display_name = \"Convert Astra DB to Pegasus Input\"\n    description = \"Converts Astra DB search results to inputs compatible with TwelveLabs Pegasus.\"\n    icon = \"TwelveLabs\"\n    name = \"ConvertAstraToTwelveLabs\"\n    documentation = \"https://github.com/twelvelabs-io/twelvelabs-developer-experience/blob/main/integrations/Langflow/TWELVE_LABS_COMPONENTS_README.md\"\n\n    inputs = [\n        HandleInput(\n            name=\"astra_results\",\n            display_name=\"Astra DB Results\",\n            input_types=[\"Data\"],\n            info=\"Search results from Astra DB component\",\n            required=True,\n            is_list=True,\n        )\n    ]\n\n    outputs = [\n        Output(\n            name=\"index_id\",\n            display_name=\"Index ID\",\n            type_=Message,\n            method=\"get_index_id\",\n        ),\n        Output(\n            name=\"video_id\",\n            display_name=\"Video ID\",\n            type_=Message,\n            method=\"get_video_id\",\n        ),\n    ]\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self._video_id = None\n        self._index_id = None\n\n    def build(self, **kwargs: Any) -> None:  # noqa: ARG002 - Required for parent class compatibility\n        \"\"\"Process the Astra DB results and extract TwelveLabs index information.\"\"\"\n        if not self.astra_results:\n            return\n\n        # Convert to list if single item\n        results = self.astra_results if isinstance(self.astra_results, list) else [self.astra_results]\n\n        # Try to extract index information from metadata\n        for doc in results:\n            if not isinstance(doc, Data):\n                continue\n\n            # Get the metadata, handling the nested structure\n            metadata = {}\n            if hasattr(doc, \"metadata\") and isinstance(doc.metadata, dict):\n                # Handle nested metadata using .get() method\n                metadata = doc.metadata.get(\"metadata\", doc.metadata)\n\n            # Extract index_id and video_id\n            self._index_id = metadata.get(\"index_id\")\n            self._video_id = metadata.get(\"video_id\")\n\n            # If we found both, we can stop searching\n            if self._index_id and self._video_id:\n                break\n\n    def get_video_id(self) -> Message:\n        \"\"\"Return the extracted video ID as a Message.\"\"\"\n        self.build()\n        return Message(text=self._video_id if self._video_id else \"\")\n\n    def get_index_id(self) -> Message:\n        \"\"\"Return the extracted index ID as a Message.\"\"\"\n        self.build()\n        return Message(text=self._index_id if self._index_id else \"\")\n"}},"tool_mode":false},"SplitVideo":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Split a video into multiple clips of specified duration.","display_name":"Split Video","documentation":"https://github.com/twelvelabs-io/twelvelabs-developer-experience/blob/main/integrations/Langflow/TWELVE_LABS_COMPONENTS_README.md","edited":false,"field_order":["videodata","clip_duration","last_clip_handling","include_original"],"frozen":false,"icon":"TwelveLabs","legacy":false,"metadata":{"code_hash":"bbcef2ababc4","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.twelvelabs.split_video.SplitVideoComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Video Clips","group_outputs":false,"method":"process","name":"clips","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","clip_duration":{"_input_type":"IntInput","advanced":false,"display_name":"Clip Duration (seconds)","dynamic":false,"info":"Duration of each clip in seconds","list":false,"list_add_label":"Add More","name":"clip_duration","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":30},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import hashlib\nimport math\nimport subprocess\nfrom datetime import datetime, timezone\nfrom pathlib import Path\nfrom typing import Any\n\nfrom lfx.custom import Component\nfrom lfx.inputs import BoolInput, DropdownInput, HandleInput, IntInput\nfrom lfx.schema import Data\nfrom lfx.template import Output\n\n\nclass SplitVideoComponent(Component):\n    \"\"\"A component that splits a video into multiple clips of specified duration using FFmpeg.\"\"\"\n\n    display_name = \"Split Video\"\n    description = \"Split a video into multiple clips of specified duration.\"\n    icon = \"TwelveLabs\"\n    name = \"SplitVideo\"\n    documentation = \"https://github.com/twelvelabs-io/twelvelabs-developer-experience/blob/main/integrations/Langflow/TWELVE_LABS_COMPONENTS_README.md\"\n\n    inputs = [\n        HandleInput(\n            name=\"videodata\",\n            display_name=\"Video Data\",\n            info=\"Input video data from VideoFile component\",\n            required=True,\n            input_types=[\"Data\"],\n        ),\n        IntInput(\n            name=\"clip_duration\",\n            display_name=\"Clip Duration (seconds)\",\n            info=\"Duration of each clip in seconds\",\n            required=True,\n            value=30,\n        ),\n        DropdownInput(\n            name=\"last_clip_handling\",\n            display_name=\"Last Clip Handling\",\n            info=(\n                \"How to handle the final clip when it would be shorter than the specified duration:\\n\"\n                \"- Truncate: Skip the final clip entirely if it's shorter than the specified duration\\n\"\n                \"- Overlap Previous: Start the final clip earlier to maintain full duration, \"\n                \"overlapping with previous clip\\n\"\n                \"- Keep Short: Keep the final clip at its natural length, even if shorter than specified duration\"\n            ),\n            options=[\"Truncate\", \"Overlap Previous\", \"Keep Short\"],\n            value=\"Overlap Previous\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"include_original\",\n            display_name=\"Include Original Video\",\n            info=\"Whether to include the original video in the output\",\n            value=False,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            name=\"clips\",\n            display_name=\"Video Clips\",\n            method=\"process\",\n            output_types=[\"Data\"],\n        ),\n    ]\n\n    def get_video_duration(self, video_path: str) -> float:\n        \"\"\"Get video duration using FFmpeg.\"\"\"\n        try:\n            # Validate video path to prevent shell injection\n            if not isinstance(video_path, str) or any(c in video_path for c in \";&|`$(){}[]<>*?!#~\"):\n                error_msg = \"Invalid video path\"\n                raise ValueError(error_msg)\n\n            cmd = [\n                \"ffprobe\",\n                \"-v\",\n                \"error\",\n                \"-show_entries\",\n                \"format=duration\",\n                \"-of\",\n                \"default=noprint_wrappers=1:nokey=1\",\n                video_path,\n            ]\n            result = subprocess.run(  # noqa: S603\n                cmd,\n                capture_output=True,\n                text=True,\n                check=False,\n                shell=False,  # Explicitly set shell=False for security\n            )\n            if result.returncode != 0:\n                error_msg = f\"FFprobe error: {result.stderr}\"\n                raise RuntimeError(error_msg)\n            return float(result.stdout.strip())\n        except Exception as e:\n            self.log(f\"Error getting video duration: {e!s}\", \"ERROR\")\n            raise\n\n    def get_output_dir(self, video_path: str) -> str:\n        \"\"\"Create a unique output directory for clips based on video name and timestamp.\"\"\"\n        # Get the video filename without extension\n        path_obj = Path(video_path)\n        base_name = path_obj.stem\n\n        # Create a timestamp\n        timestamp = datetime.now(tz=timezone.utc).strftime(\"%Y-%m-%d_%H-%M-%S\")\n\n        # Create a unique hash from the video path\n        path_hash = hashlib.sha256(video_path.encode()).hexdigest()[:8]\n\n        # Create the output directory path\n        output_dir = Path(path_obj.parent) / f\"clips_{base_name}_{timestamp}_{path_hash}\"\n\n        # Create the directory if it doesn't exist\n        output_dir.mkdir(parents=True, exist_ok=True)\n\n        return str(output_dir)\n\n    def process_video(self, video_path: str, clip_duration: int, *, include_original: bool) -> list[Data]:\n        \"\"\"Process video and split it into clips using FFmpeg.\"\"\"\n        try:\n            # Get video duration\n            total_duration = self.get_video_duration(video_path)\n\n            # Calculate number of clips (ceiling to include partial clip)\n            num_clips = math.ceil(total_duration / clip_duration)\n            self.log(\n                f\"Total duration: {total_duration}s, Clip duration: {clip_duration}s, Number of clips: {num_clips}\"\n            )\n\n            # Create output directory for clips\n            output_dir = self.get_output_dir(video_path)\n\n            # Get original video info\n            path_obj = Path(video_path)\n            original_filename = path_obj.name\n            original_name = path_obj.stem\n\n            # List to store all video paths (including original if requested)\n            video_paths: list[Data] = []\n\n            # Add original video if requested\n            if include_original:\n                original_data: dict[str, Any] = {\n                    \"text\": video_path,\n                    \"metadata\": {\n                        \"source\": video_path,\n                        \"type\": \"video\",\n                        \"clip_index\": -1,  # -1 indicates original video\n                        \"duration\": int(total_duration),  # Convert to int\n                        \"original_video\": {\n                            \"name\": original_name,\n                            \"filename\": original_filename,\n                            \"path\": video_path,\n                            \"duration\": int(total_duration),  # Convert to int\n                            \"total_clips\": int(num_clips),\n                            \"clip_duration\": int(clip_duration),\n                        },\n                    },\n                }\n                video_paths.append(Data(data=original_data))\n\n            # Split video into clips\n            for i in range(int(num_clips)):  # Convert num_clips to int for range\n                start_time = float(i * clip_duration)  # Convert to float for time calculations\n                end_time = min(float((i + 1) * clip_duration), total_duration)\n                duration = end_time - start_time\n\n                # Handle last clip if it's shorter\n                if i == int(num_clips) - 1 and duration < clip_duration:  # Convert num_clips to int for comparison\n                    if self.last_clip_handling == \"Truncate\":\n                        # Skip if the last clip would be too short\n                        continue\n                    if self.last_clip_handling == \"Overlap Previous\" and i > 0:\n                        # Start from earlier to make full duration\n                        start_time = total_duration - clip_duration\n                        duration = clip_duration\n                    # For \"Keep Short\", we use the original start_time and duration\n\n                # Skip if duration is too small (less than 1 second)\n                if duration < 1:\n                    continue\n\n                # Generate output path\n                output_path = Path(output_dir) / f\"clip_{i:03d}.mp4\"\n                output_path_str = str(output_path)\n\n                try:\n                    # Use FFmpeg to split the video\n                    cmd = [\n                        \"ffmpeg\",\n                        \"-i\",\n                        video_path,\n                        \"-ss\",\n                        str(start_time),\n                        \"-t\",\n                        str(duration),\n                        \"-c:v\",\n                        \"libx264\",\n                        \"-c:a\",\n                        \"aac\",\n                        \"-y\",  # Overwrite output file if it exists\n                        output_path_str,\n                    ]\n\n                    result = subprocess.run(  # noqa: S603\n                        cmd,\n                        capture_output=True,\n                        text=True,\n                        check=False,\n                        shell=False,  # Explicitly set shell=False for security\n                    )\n                    if result.returncode != 0:\n                        error_msg = f\"FFmpeg error: {result.stderr}\"\n                        raise RuntimeError(error_msg)\n\n                    # Create timestamp string for metadata\n                    start_min = int(start_time // 60)\n                    start_sec = int(start_time % 60)\n                    end_min = int(end_time // 60)\n                    end_sec = int(end_time % 60)\n                    timestamp_str = f\"{start_min:02d}:{start_sec:02d} - {end_min:02d}:{end_sec:02d}\"\n\n                    # Create Data object for the clip\n                    clip_data: dict[str, Any] = {\n                        \"text\": output_path_str,\n                        \"metadata\": {\n                            \"source\": video_path,\n                            \"type\": \"video\",\n                            \"clip_index\": i,\n                            \"start_time\": float(start_time),\n                            \"end_time\": float(end_time),\n                            \"duration\": float(duration),\n                            \"original_video\": {\n                                \"name\": original_name,\n                                \"filename\": original_filename,\n                                \"path\": video_path,\n                                \"duration\": int(total_duration),\n                                \"total_clips\": int(num_clips),\n                                \"clip_duration\": int(clip_duration),\n                            },\n                            \"clip\": {\n                                \"index\": i,\n                                \"total\": int(num_clips),\n                                \"duration\": float(duration),\n                                \"start_time\": float(start_time),\n                                \"end_time\": float(end_time),\n                                \"timestamp\": timestamp_str,\n                            },\n                        },\n                    }\n                    video_paths.append(Data(data=clip_data))\n\n                except Exception as e:\n                    self.log(f\"Error processing clip {i}: {e!s}\", \"ERROR\")\n                    raise\n\n            self.log(f\"Created {len(video_paths)} clips in {output_dir}\")\n        except Exception as e:\n            self.log(f\"Error processing video: {e!s}\", \"ERROR\")\n            raise\n        else:\n            return video_paths\n\n    def process(self) -> list[Data]:\n        \"\"\"Process the input video and return a list of Data objects containing the clips.\"\"\"\n        try:\n            # Get the input video path from the previous component\n            if not hasattr(self, \"videodata\") or not isinstance(self.videodata, list) or len(self.videodata) != 1:\n                error_msg = \"Please provide exactly one video\"\n                raise ValueError(error_msg)\n\n            video_path = self.videodata[0].data.get(\"text\")\n            if not video_path or not Path(video_path).exists():\n                error_msg = \"Invalid video path\"\n                raise ValueError(error_msg)\n\n            # Validate video path to prevent shell injection\n            if not isinstance(video_path, str) or any(c in video_path for c in \";&|`$(){}[]<>*?!#~\"):\n                error_msg = \"Invalid video path contains unsafe characters\"\n                raise ValueError(error_msg)\n\n            # Process the video\n            return self.process_video(video_path, self.clip_duration, include_original=self.include_original)\n\n        except Exception as e:\n            self.log(f\"Error in split video component: {e!s}\", \"ERROR\")\n            raise\n"},"include_original":{"_input_type":"BoolInput","advanced":false,"display_name":"Include Original Video","dynamic":false,"info":"Whether to include the original video in the output","list":false,"list_add_label":"Add More","name":"include_original","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"last_clip_handling":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Last Clip Handling","dynamic":false,"external_options":{},"info":"How to handle the final clip when it would be shorter than the specified duration:\n- Truncate: Skip the final clip entirely if it's shorter than the specified duration\n- Overlap Previous: Start the final clip earlier to maintain full duration, overlapping with previous clip\n- Keep Short: Keep the final clip at its natural length, even if shorter than specified duration","name":"last_clip_handling","options":["Truncate","Overlap Previous","Keep Short"],"options_metadata":[],"placeholder":"","required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Overlap Previous"},"videodata":{"_input_type":"HandleInput","advanced":false,"display_name":"Video Data","dynamic":false,"info":"Input video data from VideoFile component","input_types":["Data"],"list":false,"list_add_label":"Add More","name":"videodata","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""}},"tool_mode":false},"TwelveLabsPegasus":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Chat with videos using TwelveLabs Pegasus API.","display_name":"TwelveLabs Pegasus","documentation":"https://github.com/twelvelabs-io/twelvelabs-developer-experience/blob/main/integrations/Langflow/TWELVE_LABS_COMPONENTS_README.md","edited":false,"field_order":["videodata","api_key","video_id","index_name","index_id","model_name","message","temperature"],"frozen":false,"icon":"TwelveLabs","legacy":false,"metadata":{"code_hash":"92cc032822a6","dependencies":{"dependencies":[{"name":"tenacity","version":"8.5.0"},{"name":"twelvelabs","version":"0.4.11"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.twelvelabs.twelvelabs_pegasus.TwelveLabsPegasus"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Message","group_outputs":false,"method":"process_video","name":"response","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Video ID","group_outputs":false,"method":"get_video_id","name":"processed_video_id","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"TwelveLabs API Key","dynamic":false,"info":"Enter your TwelveLabs API Key.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nimport subprocess\nimport time\nfrom pathlib import Path\nfrom typing import Any\n\nfrom tenacity import retry, stop_after_attempt, wait_exponential\nfrom twelvelabs import TwelveLabs\n\nfrom lfx.custom import Component\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.inputs import DataInput, DropdownInput, MessageInput, MultilineInput, SecretStrInput, SliderInput\nfrom lfx.io import Output\nfrom lfx.schema.message import Message\n\n\nclass TaskError(Exception):\n    \"\"\"Error raised when a task fails.\"\"\"\n\n\nclass TaskTimeoutError(Exception):\n    \"\"\"Error raised when a task times out.\"\"\"\n\n\nclass IndexCreationError(Exception):\n    \"\"\"Error raised when there's an issue with an index.\"\"\"\n\n\nclass ApiRequestError(Exception):\n    \"\"\"Error raised when an API request fails.\"\"\"\n\n\nclass VideoValidationError(Exception):\n    \"\"\"Error raised when video validation fails.\"\"\"\n\n\nclass TwelveLabsPegasus(Component):\n    display_name = \"TwelveLabs Pegasus\"\n    description = \"Chat with videos using TwelveLabs Pegasus API.\"\n    icon = \"TwelveLabs\"\n    name = \"TwelveLabsPegasus\"\n    documentation = \"https://github.com/twelvelabs-io/twelvelabs-developer-experience/blob/main/integrations/Langflow/TWELVE_LABS_COMPONENTS_README.md\"\n\n    inputs = [\n        DataInput(name=\"videodata\", display_name=\"Video Data\", info=\"Video Data\", is_list=True),\n        SecretStrInput(\n            name=\"api_key\", display_name=\"TwelveLabs API Key\", info=\"Enter your TwelveLabs API Key.\", required=True\n        ),\n        MessageInput(\n            name=\"video_id\",\n            display_name=\"Pegasus Video ID\",\n            info=\"Enter a Video ID for a previously indexed video.\",\n        ),\n        MessageInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            info=\"Name of the index to use. If the index doesn't exist, it will be created.\",\n            required=False,\n        ),\n        MessageInput(\n            name=\"index_id\",\n            display_name=\"Index ID\",\n            info=\"ID of an existing index to use. If provided, index_name will be ignored.\",\n            required=False,\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model\",\n            info=\"Pegasus model to use for indexing\",\n            options=[\"pegasus1.2\"],\n            value=\"pegasus1.2\",\n            advanced=False,\n        ),\n        MultilineInput(\n            name=\"message\",\n            display_name=\"Prompt\",\n            info=\"Message to chat with the video.\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.7,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            info=(\n                \"Controls randomness in responses. Lower values are more deterministic, \"\n                \"higher values are more creative.\"\n            ),\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"response\",\n            method=\"process_video\",\n            type_=Message,\n        ),\n        Output(\n            display_name=\"Video ID\",\n            name=\"processed_video_id\",\n            method=\"get_video_id\",\n            type_=Message,\n        ),\n    ]\n\n    def __init__(self, **kwargs) -> None:\n        super().__init__(**kwargs)\n\n        self._task_id: str | None = None\n        self._video_id: str | None = None\n        self._index_id: str | None = None\n        self._index_name: str | None = None\n        self._message: str | None = None\n\n    def _get_or_create_index(self, client: TwelveLabs) -> tuple[str, str]:\n        \"\"\"Get existing index or create new one.\n\n        Returns (index_id, index_name).\n        \"\"\"\n        # First check if index_id is provided and valid\n        if hasattr(self, \"_index_id\") and self._index_id:\n            try:\n                index = client.index.retrieve(id=self._index_id)\n                self.log(f\"Found existing index with ID: {self._index_id}\")\n            except (ValueError, KeyError) as e:\n                self.log(f\"Error retrieving index with ID {self._index_id}: {e!s}\", \"WARNING\")\n            else:\n                return self._index_id, index.name\n\n        # If index_name is provided, try to find it\n        if hasattr(self, \"_index_name\") and self._index_name:\n            try:\n                # List all indexes and find by name\n                indexes = client.index.list()\n                for idx in indexes:\n                    if idx.name == self._index_name:\n                        self.log(f\"Found existing index: {self._index_name} (ID: {idx.id})\")\n                        return idx.id, idx.name\n\n                # If we get here, index wasn't found - create it\n                self.log(f\"Creating new index: {self._index_name}\")\n                index = client.index.create(\n                    name=self._index_name,\n                    models=[\n                        {\n                            \"name\": self.model_name if hasattr(self, \"model_name\") else \"pegasus1.2\",\n                            \"options\": [\"visual\", \"audio\"],\n                        }\n                    ],\n                )\n            except (ValueError, KeyError) as e:\n                self.log(f\"Error with index name {self._index_name}: {e!s}\", \"ERROR\")\n                error_message = f\"Error with index name {self._index_name}\"\n                raise IndexCreationError(error_message) from e\n            else:\n                return index.id, index.name\n\n        # If neither is provided, create a new index with timestamp\n        try:\n            index_name = f\"index_{int(time.time())}\"\n            self.log(f\"Creating new index: {index_name}\")\n            index = client.index.create(\n                name=index_name,\n                models=[\n                    {\n                        \"name\": self.model_name if hasattr(self, \"model_name\") else \"pegasus1.2\",\n                        \"options\": [\"visual\", \"audio\"],\n                    }\n                ],\n            )\n        except (ValueError, KeyError) as e:\n            self.log(f\"Failed to create new index: {e!s}\", \"ERROR\")\n            error_message = \"Failed to create new index\"\n            raise IndexCreationError(error_message) from e\n        else:\n            return index.id, index.name\n\n    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10), reraise=True)\n    async def _make_api_request(self, method: Any, *args: Any, **kwargs: Any) -> Any:\n        \"\"\"Make API request with retry logic.\n\n        Retries failed requests with exponential backoff.\n        \"\"\"\n        try:\n            return await method(*args, **kwargs)\n        except (ValueError, KeyError) as e:\n            self.log(f\"API request failed: {e!s}\", \"ERROR\")\n            error_message = \"API request failed\"\n            raise ApiRequestError(error_message) from e\n\n    def wait_for_task_completion(\n        self, client: TwelveLabs, task_id: str, max_retries: int = 120, sleep_time: int = 5\n    ) -> Any:\n        \"\"\"Wait for task completion with timeout and improved error handling.\n\n        Polls the task status until completion or timeout.\n        \"\"\"\n        retries = 0\n        consecutive_errors = 0\n        max_consecutive_errors = 3\n\n        while retries < max_retries:\n            try:\n                self.log(f\"Checking task status (attempt {retries + 1})\")\n                result = client.task.retrieve(id=task_id)\n                consecutive_errors = 0  # Reset error counter on success\n\n                if result.status == \"ready\":\n                    self.log(\"Task completed successfully!\")\n                    return result\n                if result.status == \"failed\":\n                    error_msg = f\"Task failed with status: {result.status}\"\n                    self.log(error_msg, \"ERROR\")\n                    raise TaskError(error_msg)\n                if result.status == \"error\":\n                    error_msg = f\"Task encountered an error: {getattr(result, 'error', 'Unknown error')}\"\n                    self.log(error_msg, \"ERROR\")\n                    raise TaskError(error_msg)\n\n                time.sleep(sleep_time)\n                retries += 1\n                status_msg = f\"Processing video... {retries * sleep_time}s elapsed\"\n                self.status = status_msg\n                self.log(status_msg)\n\n            except (ValueError, KeyError) as e:\n                consecutive_errors += 1\n                error_msg = f\"Error checking task status: {e!s}\"\n                self.log(error_msg, \"WARNING\")\n\n                if consecutive_errors >= max_consecutive_errors:\n                    too_many_errors = \"Too many consecutive errors\"\n                    raise TaskError(too_many_errors) from e\n\n                time.sleep(sleep_time * 2)\n                continue\n\n        timeout_msg = f\"Timeout after {max_retries * sleep_time} seconds\"\n        self.log(timeout_msg, \"ERROR\")\n        raise TaskTimeoutError(timeout_msg)\n\n    def validate_video_file(self, filepath: str) -> tuple[bool, str]:\n        \"\"\"Validate video file using ffprobe.\n\n        Returns (is_valid, error_message).\n        \"\"\"\n        # Ensure filepath is a string and doesn't contain shell metacharacters\n        if not isinstance(filepath, str) or any(c in filepath for c in \";&|`$(){}[]<>*?!#~\"):\n            return False, \"Invalid filepath\"\n\n        try:\n            cmd = [\n                \"ffprobe\",\n                \"-loglevel\",\n                \"error\",\n                \"-show_entries\",\n                \"stream=codec_type,codec_name\",\n                \"-of\",\n                \"default=nw=1\",\n                \"-print_format\",\n                \"json\",\n                \"-show_format\",\n                filepath,\n            ]\n\n            # Use subprocess with a list of arguments to avoid shell injection\n            # We need to skip the S603 warning here as we're taking proper precautions\n            # with input validation and using shell=False\n            result = subprocess.run(  # noqa: S603\n                cmd,\n                capture_output=True,\n                text=True,\n                check=False,\n                shell=False,  # Explicitly set shell=False for security\n            )\n\n            if result.returncode != 0:\n                return False, f\"FFprobe error: {result.stderr}\"\n\n            probe_data = json.loads(result.stdout)\n\n            has_video = any(stream.get(\"codec_type\") == \"video\" for stream in probe_data.get(\"streams\", []))\n\n            if not has_video:\n                return False, \"No video stream found in file\"\n\n            self.log(f\"Video validation successful: {json.dumps(probe_data, indent=2)}\")\n        except subprocess.SubprocessError as e:\n            return False, f\"FFprobe process error: {e!s}\"\n        except json.JSONDecodeError as e:\n            return False, f\"FFprobe output parsing error: {e!s}\"\n        except (ValueError, OSError) as e:\n            return False, f\"Validation error: {e!s}\"\n        else:\n            return True, \"\"\n\n    def on_task_update(self, task: Any) -> None:\n        \"\"\"Callback for task status updates.\n\n        Updates the component status with the current task status.\n        \"\"\"\n        self.status = f\"Processing video... Status: {task.status}\"\n        self.log(self.status)\n\n    def process_video(self) -> Message:\n        \"\"\"Process video using Pegasus and generate response if message is provided.\n\n        Handles video indexing and question answering using the TwelveLabs API.\n        \"\"\"\n        # Check and initialize inputs\n        if hasattr(self, \"index_id\") and self.index_id:\n            self._index_id = self.index_id.text if hasattr(self.index_id, \"text\") else self.index_id\n\n        if hasattr(self, \"index_name\") and self.index_name:\n            self._index_name = self.index_name.text if hasattr(self.index_name, \"text\") else self.index_name\n\n        if hasattr(self, \"video_id\") and self.video_id:\n            self._video_id = self.video_id.text if hasattr(self.video_id, \"text\") else self.video_id\n\n        if hasattr(self, \"message\") and self.message:\n            self._message = self.message.text if hasattr(self.message, \"text\") else self.message\n\n        try:\n            # If we have a message and already processed video, use existing video_id\n            if self._message and self._video_id and self._video_id != \"\":\n                self.status = f\"Have video id: {self._video_id}\"\n\n                client = TwelveLabs(api_key=self.api_key)\n\n                self.status = f\"Processing query (w/ video ID): {self._video_id} {self._message}\"\n                self.log(self.status)\n\n                response = client.generate.text(\n                    video_id=self._video_id,\n                    prompt=self._message,\n                    temperature=self.temperature,\n                )\n                return Message(text=response.data)\n\n            # Otherwise process new video\n            if not self.videodata or not isinstance(self.videodata, list) or len(self.videodata) != 1:\n                return Message(text=\"Please provide exactly one video\")\n\n            video_path = self.videodata[0].data.get(\"text\")\n            if not video_path or not Path(video_path).exists():\n                return Message(text=\"Invalid video path\")\n\n            if not self.api_key:\n                return Message(text=\"No API key provided\")\n\n            client = TwelveLabs(api_key=self.api_key)\n\n            # Get or create index\n            try:\n                index_id, index_name = self._get_or_create_index(client)\n                self.status = f\"Using index: {index_name} (ID: {index_id})\"\n                self.log(f\"Using index: {index_name} (ID: {index_id})\")\n                self._index_id = index_id\n                self._index_name = index_name\n            except IndexCreationError as e:\n                return Message(text=f\"Failed to get/create index: {e}\")\n\n            with Path(video_path).open(\"rb\") as video_file:\n                task = client.task.create(index_id=self._index_id, file=video_file)\n            self._task_id = task.id\n\n            # Wait for processing to complete\n            task.wait_for_done(sleep_interval=5, callback=self.on_task_update)\n\n            if task.status != \"ready\":\n                return Message(text=f\"Processing failed with status {task.status}\")\n\n            # Store video_id for future use\n            self._video_id = task.video_id\n\n            # Generate response if message provided\n            if self._message:\n                self.status = f\"Processing query: {self._message}\"\n                self.log(self.status)\n\n                response = client.generate.text(\n                    video_id=self._video_id,\n                    prompt=self._message,\n                    temperature=self.temperature,\n                )\n                return Message(text=response.data)\n\n            success_msg = (\n                f\"Video processed successfully. You can now ask questions about the video. Video ID: {self._video_id}\"\n            )\n            return Message(text=success_msg)\n\n        except (ValueError, KeyError, IndexCreationError, TaskError, TaskTimeoutError) as e:\n            self.log(f\"Error: {e!s}\", \"ERROR\")\n            # Clear stored IDs on error\n            self._video_id = None\n            self._index_id = None\n            self._task_id = None\n            return Message(text=f\"Error: {e!s}\")\n\n    def get_video_id(self) -> Message:\n        \"\"\"Return the video ID of the processed video as a Message.\n\n        Returns an empty string if no video has been processed.\n        \"\"\"\n        video_id = self._video_id or \"\"\n        return Message(text=video_id)\n"},"index_id":{"_input_type":"MessageInput","advanced":false,"display_name":"Index ID","dynamic":false,"info":"ID of an existing index to use. If provided, index_name will be ignored.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"index_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"index_name":{"_input_type":"MessageInput","advanced":false,"display_name":"Index Name","dynamic":false,"info":"Name of the index to use. If the index doesn't exist, it will be created.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"index_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Prompt","dynamic":false,"info":"Message to chat with the video.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"message","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model","dynamic":false,"external_options":{},"info":"Pegasus model to use for indexing","name":"model_name","options":["pegasus1.2"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"pegasus1.2"},"temperature":{"_input_type":"SliderInput","advanced":false,"display_name":"Temperature","dynamic":false,"info":"Controls randomness in responses. Lower values are more deterministic, higher values are more creative.","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"temperature","placeholder":"","range_spec":{"max":1.0,"min":0.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":0.7},"video_id":{"_input_type":"MessageInput","advanced":false,"display_name":"Pegasus Video ID","dynamic":false,"info":"Enter a Video ID for a previously indexed video.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"video_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"videodata":{"_input_type":"DataInput","advanced":false,"display_name":"Video Data","dynamic":false,"info":"Video Data","input_types":["Data"],"list":true,"list_add_label":"Add More","name":"videodata","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""}},"tool_mode":false},"TwelveLabsPegasusIndexVideo":{"base_classes":["Data"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Index videos using TwelveLabs and add the video_id to metadata.","display_name":"TwelveLabs Pegasus Index Video","documentation":"https://github.com/twelvelabs-io/twelvelabs-developer-experience/blob/main/integrations/Langflow/TWELVE_LABS_COMPONENTS_README.md","edited":false,"field_order":["videodata","api_key","model_name","index_name","index_id"],"frozen":false,"icon":"TwelveLabs","legacy":false,"metadata":{"code_hash":"a2c0865be096","dependencies":{"dependencies":[{"name":"tenacity","version":"8.5.0"},{"name":"twelvelabs","version":"0.4.11"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.twelvelabs.pegasus_index.PegasusIndexVideo"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Indexed Data","group_outputs":false,"method":"index_videos","name":"indexed_data","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"TwelveLabs API Key","dynamic":false,"info":"Enter your TwelveLabs API Key.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import time\nfrom concurrent.futures import ThreadPoolExecutor\nfrom pathlib import Path\nfrom typing import Any\n\nfrom tenacity import retry, stop_after_attempt, wait_exponential\nfrom twelvelabs import TwelveLabs\n\nfrom lfx.custom import Component\nfrom lfx.inputs import DataInput, DropdownInput, SecretStrInput, StrInput\nfrom lfx.io import Output\nfrom lfx.schema import Data\n\n\nclass TwelveLabsError(Exception):\n    \"\"\"Base exception for TwelveLabs errors.\"\"\"\n\n\nclass IndexCreationError(TwelveLabsError):\n    \"\"\"Error raised when there's an issue with an index.\"\"\"\n\n\nclass TaskError(TwelveLabsError):\n    \"\"\"Error raised when a task fails.\"\"\"\n\n\nclass TaskTimeoutError(TwelveLabsError):\n    \"\"\"Error raised when a task times out.\"\"\"\n\n\nclass PegasusIndexVideo(Component):\n    \"\"\"Indexes videos using TwelveLabs Pegasus API and adds the video ID to metadata.\"\"\"\n\n    display_name = \"TwelveLabs Pegasus Index Video\"\n    description = \"Index videos using TwelveLabs and add the video_id to metadata.\"\n    icon = \"TwelveLabs\"\n    name = \"TwelveLabsPegasusIndexVideo\"\n    documentation = \"https://github.com/twelvelabs-io/twelvelabs-developer-experience/blob/main/integrations/Langflow/TWELVE_LABS_COMPONENTS_README.md\"\n\n    inputs = [\n        DataInput(\n            name=\"videodata\",\n            display_name=\"Video Data\",\n            info=\"Video Data objects (from VideoFile or SplitVideo)\",\n            is_list=True,\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\", display_name=\"TwelveLabs API Key\", info=\"Enter your TwelveLabs API Key.\", required=True\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model\",\n            info=\"Pegasus model to use for indexing\",\n            options=[\"pegasus1.2\"],\n            value=\"pegasus1.2\",\n            advanced=False,\n        ),\n        StrInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            info=\"Name of the index to use. If the index doesn't exist, it will be created.\",\n            required=False,\n        ),\n        StrInput(\n            name=\"index_id\",\n            display_name=\"Index ID\",\n            info=\"ID of an existing index to use. If provided, index_name will be ignored.\",\n            required=False,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Indexed Data\", name=\"indexed_data\", method=\"index_videos\", output_types=[\"Data\"], is_list=True\n        ),\n    ]\n\n    def _get_or_create_index(self, client: TwelveLabs) -> tuple[str, str]:\n        \"\"\"Get existing index or create new one.\n\n        Returns (index_id, index_name).\n        \"\"\"\n        # First check if index_id is provided and valid\n        if hasattr(self, \"index_id\") and self.index_id:\n            try:\n                index = client.index.retrieve(id=self.index_id)\n            except (ValueError, KeyError) as e:\n                if not hasattr(self, \"index_name\") or not self.index_name:\n                    error_msg = \"Invalid index ID provided and no index name specified for fallback\"\n                    raise IndexCreationError(error_msg) from e\n            else:\n                return self.index_id, index.name\n\n        # If index_name is provided, try to find it\n        if hasattr(self, \"index_name\") and self.index_name:\n            try:\n                # List all indexes and find by name\n                indexes = client.index.list()\n                for idx in indexes:\n                    if idx.name == self.index_name:\n                        return idx.id, idx.name\n\n                # If we get here, index wasn't found - create it\n                index = client.index.create(\n                    name=self.index_name,\n                    models=[\n                        {\n                            \"name\": self.model_name if hasattr(self, \"model_name\") else \"pegasus1.2\",\n                            \"options\": [\"visual\", \"audio\"],\n                        }\n                    ],\n                )\n            except (ValueError, KeyError) as e:\n                error_msg = f\"Error with index name {self.index_name}\"\n                raise IndexCreationError(error_msg) from e\n            else:\n                return index.id, index.name\n\n        # If we get here, neither index_id nor index_name was provided\n        error_msg = \"Either index_name or index_id must be provided\"\n        raise IndexCreationError(error_msg)\n\n    def on_task_update(self, task: Any, video_path: str) -> None:\n        \"\"\"Callback for task status updates.\n\n        Updates the component status with the current task status.\n        \"\"\"\n        video_name = Path(video_path).name\n        status_msg = f\"Indexing {video_name}... Status: {task.status}\"\n        self.status = status_msg\n\n    @retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=1, min=5, max=60), reraise=True)\n    def _check_task_status(\n        self,\n        client: TwelveLabs,\n        task_id: str,\n        video_path: str,\n    ) -> Any:\n        \"\"\"Check task status once.\n\n        Makes a single API call to check the status of a task.\n        \"\"\"\n        task = client.task.retrieve(id=task_id)\n        self.on_task_update(task, video_path)\n        return task\n\n    def _wait_for_task_completion(\n        self, client: TwelveLabs, task_id: str, video_path: str, max_retries: int = 120, sleep_time: int = 10\n    ) -> Any:\n        \"\"\"Wait for task completion with timeout and improved error handling.\n\n        Polls the task status until completion or timeout.\n        \"\"\"\n        retries = 0\n        consecutive_errors = 0\n        max_consecutive_errors = 5\n        video_name = Path(video_path).name\n\n        while retries < max_retries:\n            try:\n                self.status = f\"Checking task status for {video_name} (attempt {retries + 1})\"\n                task = self._check_task_status(client, task_id, video_path)\n\n                if task.status == \"ready\":\n                    self.status = f\"Indexing for {video_name} completed successfully!\"\n                    return task\n                if task.status == \"failed\":\n                    error_msg = f\"Task failed for {video_name}: {getattr(task, 'error', 'Unknown error')}\"\n                    self.status = error_msg\n                    raise TaskError(error_msg)\n                if task.status == \"error\":\n                    error_msg = f\"Task encountered an error for {video_name}: {getattr(task, 'error', 'Unknown error')}\"\n                    self.status = error_msg\n                    raise TaskError(error_msg)\n\n                time.sleep(sleep_time)\n                retries += 1\n                elapsed_time = retries * sleep_time\n                self.status = f\"Indexing {video_name}... {elapsed_time}s elapsed\"\n\n            except (ValueError, KeyError) as e:\n                consecutive_errors += 1\n                error_msg = f\"Error checking task status for {video_name}: {e!s}\"\n                self.status = error_msg\n\n                if consecutive_errors >= max_consecutive_errors:\n                    too_many_errors = f\"Too many consecutive errors checking task status for {video_name}\"\n                    raise TaskError(too_many_errors) from e\n\n                time.sleep(sleep_time * (2**consecutive_errors))\n                continue\n\n        timeout_msg = f\"Timeout waiting for indexing of {video_name} after {max_retries * sleep_time} seconds\"\n        self.status = timeout_msg\n        raise TaskTimeoutError(timeout_msg)\n\n    def _upload_video(self, client: TwelveLabs, video_path: str, index_id: str) -> str:\n        \"\"\"Upload a single video and return its task ID.\n\n        Uploads a video file to the specified index and returns the task ID.\n        \"\"\"\n        video_name = Path(video_path).name\n        with Path(video_path).open(\"rb\") as video_file:\n            self.status = f\"Uploading {video_name} to index {index_id}...\"\n            task = client.task.create(index_id=index_id, file=video_file)\n            task_id = task.id\n            self.status = f\"Upload complete for {video_name}. Task ID: {task_id}\"\n            return task_id\n\n    def index_videos(self) -> list[Data]:\n        \"\"\"Indexes each video and adds the video_id to its metadata.\"\"\"\n        if not self.videodata:\n            self.status = \"No video data provided.\"\n            return []\n\n        if not self.api_key:\n            error_msg = \"TwelveLabs API Key is required\"\n            raise IndexCreationError(error_msg)\n\n        if not (hasattr(self, \"index_name\") and self.index_name) and not (hasattr(self, \"index_id\") and self.index_id):\n            error_msg = \"Either index_name or index_id must be provided\"\n            raise IndexCreationError(error_msg)\n\n        client = TwelveLabs(api_key=self.api_key)\n        indexed_data_list: list[Data] = []\n\n        # Get or create the index\n        try:\n            index_id, index_name = self._get_or_create_index(client)\n            self.status = f\"Using index: {index_name} (ID: {index_id})\"\n        except IndexCreationError as e:\n            self.status = f\"Failed to get/create TwelveLabs index: {e!s}\"\n            raise\n\n        # First, validate all videos and create a list of valid ones\n        valid_videos: list[tuple[Data, str]] = []\n        for video_data_item in self.videodata:\n            if not isinstance(video_data_item, Data):\n                self.status = f\"Skipping invalid data item: {video_data_item}\"\n                continue\n\n            video_info = video_data_item.data\n            if not isinstance(video_info, dict):\n                self.status = f\"Skipping item with invalid data structure: {video_info}\"\n                continue\n\n            video_path = video_info.get(\"text\")\n            if not video_path or not isinstance(video_path, str):\n                self.status = f\"Skipping item with missing or invalid video path: {video_info}\"\n                continue\n\n            if not Path(video_path).exists():\n                self.status = f\"Video file not found, skipping: {video_path}\"\n                continue\n\n            valid_videos.append((video_data_item, video_path))\n\n        if not valid_videos:\n            self.status = \"No valid videos to process.\"\n            return []\n\n        # Upload all videos first and collect their task IDs\n        upload_tasks: list[tuple[Data, str, str]] = []  # (data_item, video_path, task_id)\n        for data_item, video_path in valid_videos:\n            try:\n                task_id = self._upload_video(client, video_path, index_id)\n                upload_tasks.append((data_item, video_path, task_id))\n            except (ValueError, KeyError) as e:\n                self.status = f\"Failed to upload {video_path}: {e!s}\"\n                continue\n\n        # Now check all tasks in parallel using a thread pool\n        with ThreadPoolExecutor(max_workers=min(10, len(upload_tasks))) as executor:\n            futures = []\n            for data_item, video_path, task_id in upload_tasks:\n                future = executor.submit(self._wait_for_task_completion, client, task_id, video_path)\n                futures.append((data_item, video_path, future))\n\n            # Process results as they complete\n            for data_item, video_path, future in futures:\n                try:\n                    completed_task = future.result()\n                    if completed_task.status == \"ready\":\n                        video_id = completed_task.video_id\n                        video_name = Path(video_path).name\n                        self.status = f\"Video {video_name} indexed successfully. Video ID: {video_id}\"\n\n                        # Add video_id to the metadata\n                        video_info = data_item.data\n                        if \"metadata\" not in video_info:\n                            video_info[\"metadata\"] = {}\n                        elif not isinstance(video_info[\"metadata\"], dict):\n                            self.status = f\"Warning: Overwriting non-dict metadata for {video_path}\"\n                            video_info[\"metadata\"] = {}\n\n                        video_info[\"metadata\"].update(\n                            {\"video_id\": video_id, \"index_id\": index_id, \"index_name\": index_name}\n                        )\n\n                        updated_data_item = Data(data=video_info)\n                        indexed_data_list.append(updated_data_item)\n                except (TaskError, TaskTimeoutError) as e:\n                    self.status = f\"Failed to process {video_path}: {e!s}\"\n\n        if not indexed_data_list:\n            self.status = \"No videos were successfully indexed.\"\n        else:\n            self.status = f\"Finished indexing {len(indexed_data_list)}/{len(self.videodata)} videos.\"\n\n        return indexed_data_list\n"},"index_id":{"_input_type":"StrInput","advanced":false,"display_name":"Index ID","dynamic":false,"info":"ID of an existing index to use. If provided, index_name will be ignored.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"index_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"index_name":{"_input_type":"StrInput","advanced":false,"display_name":"Index Name","dynamic":false,"info":"Name of the index to use. If the index doesn't exist, it will be created.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"index_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model","dynamic":false,"external_options":{},"info":"Pegasus model to use for indexing","name":"model_name","options":["pegasus1.2"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"pegasus1.2"},"videodata":{"_input_type":"DataInput","advanced":false,"display_name":"Video Data","dynamic":false,"info":"Video Data objects (from VideoFile or SplitVideo)","input_types":["Data"],"list":true,"list_add_label":"Add More","name":"videodata","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"other","value":""}},"tool_mode":false},"TwelveLabsTextEmbeddings":{"base_classes":["Embeddings"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate embeddings using TwelveLabs text embedding models.","display_name":"TwelveLabs Text Embeddings","documentation":"https://github.com/twelvelabs-io/twelvelabs-developer-experience/blob/main/integrations/Langflow/TWELVE_LABS_COMPONENTS_README.md","edited":false,"field_order":["api_key","model","max_retries","request_timeout"],"frozen":false,"icon":"TwelveLabs","legacy":false,"metadata":{"code_hash":"5c7501f5088c","dependencies":{"dependencies":[{"name":"twelvelabs","version":"0.4.11"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.twelvelabs.text_embeddings.TwelveLabsTextEmbeddingsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Embedding Model","group_outputs":false,"method":"build_embeddings","name":"embeddings","selected":"Embeddings","tool_mode":true,"types":["Embeddings"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"TwelveLabs API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"TWELVELABS_API_KEY"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from twelvelabs import TwelveLabs\n\nfrom lfx.base.embeddings.model import LCEmbeddingsModel\nfrom lfx.field_typing import Embeddings\nfrom lfx.io import DropdownInput, FloatInput, IntInput, SecretStrInput\n\n\nclass TwelveLabsTextEmbeddings(Embeddings):\n    def __init__(self, api_key: str, model: str) -> None:\n        self.client = TwelveLabs(api_key=api_key)\n        self.model = model\n\n    def embed_documents(self, texts: list[str]) -> list[list[float]]:\n        all_embeddings: list[list[float]] = []\n        for text in texts:\n            if not text:\n                continue\n\n            result = self.client.embed.create(model_name=self.model, text=text)\n\n            if result.text_embedding and result.text_embedding.segments:\n                for segment in result.text_embedding.segments:\n                    all_embeddings.append([float(x) for x in segment.embeddings_float])\n                    break  # Only take first segment for now\n\n        return all_embeddings\n\n    def embed_query(self, text: str) -> list[float]:\n        result = self.client.embed.create(model_name=self.model, text=text)\n\n        if result.text_embedding and result.text_embedding.segments:\n            return [float(x) for x in result.text_embedding.segments[0].embeddings_float]\n        return []\n\n\nclass TwelveLabsTextEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"TwelveLabs Text Embeddings\"\n    description = \"Generate embeddings using TwelveLabs text embedding models.\"\n    icon = \"TwelveLabs\"\n    name = \"TwelveLabsTextEmbeddings\"\n    documentation = \"https://github.com/twelvelabs-io/twelvelabs-developer-experience/blob/main/integrations/Langflow/TWELVE_LABS_COMPONENTS_README.md\"\n\n    inputs = [\n        SecretStrInput(name=\"api_key\", display_name=\"TwelveLabs API Key\", value=\"TWELVELABS_API_KEY\", required=True),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=[\"Marengo-retrieval-2.7\"],\n            value=\"Marengo-retrieval-2.7\",\n        ),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return TwelveLabsTextEmbeddings(api_key=self.api_key, model=self.model)\n"},"max_retries":{"_input_type":"IntInput","advanced":true,"display_name":"Max Retries","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"max_retries","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":3},"model":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model","dynamic":false,"external_options":{},"info":"","name":"model","options":["Marengo-retrieval-2.7"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Marengo-retrieval-2.7"},"request_timeout":{"_input_type":"FloatInput","advanced":true,"display_name":"Request Timeout","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"request_timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":""}},"tool_mode":false},"TwelveLabsVideoEmbeddings":{"base_classes":["Embeddings"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate embeddings from videos using TwelveLabs video embedding models.","display_name":"TwelveLabs Video Embeddings","documentation":"https://github.com/twelvelabs-io/twelvelabs-developer-experience/blob/main/integrations/Langflow/TWELVE_LABS_COMPONENTS_README.md","edited":false,"field_order":["api_key","model_name","request_timeout"],"frozen":false,"icon":"TwelveLabs","legacy":false,"metadata":{"code_hash":"294e3539629c","dependencies":{"dependencies":[{"name":"twelvelabs","version":"0.4.11"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.twelvelabs.video_embeddings.TwelveLabsVideoEmbeddingsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Embedding Model","group_outputs":false,"method":"build_embeddings","name":"embeddings","selected":"Embeddings","tool_mode":true,"types":["Embeddings"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"TwelveLabs API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import time\nfrom pathlib import Path\nfrom typing import Any, cast\n\nfrom twelvelabs import TwelveLabs\n\nfrom lfx.base.embeddings.model import LCEmbeddingsModel\nfrom lfx.field_typing import Embeddings\nfrom lfx.io import DropdownInput, IntInput, SecretStrInput\n\n\nclass TwelveLabsVideoEmbeddings(Embeddings):\n    def __init__(self, api_key: str, model_name: str = \"Marengo-retrieval-2.7\") -> None:\n        self.client = TwelveLabs(api_key=api_key)\n        self.model_name = model_name\n\n    def _wait_for_task_completion(self, task_id: str) -> Any:\n        while True:\n            result = self.client.embed.task.retrieve(id=task_id)\n            if result.status == \"ready\":\n                return result\n            time.sleep(5)\n\n    def embed_documents(self, texts: list[str]) -> list[list[float]]:\n        embeddings: list[list[float]] = []\n        for text in texts:\n            video_path = text.page_content if hasattr(text, \"page_content\") else str(text)\n            result = self.embed_video(video_path)\n\n            # First try to use video embedding, then fall back to clip embedding if available\n            if result[\"video_embedding\"] is not None:\n                embeddings.append(cast(\"list[float]\", result[\"video_embedding\"]))\n            elif result[\"clip_embeddings\"] and len(result[\"clip_embeddings\"]) > 0:\n                embeddings.append(cast(\"list[float]\", result[\"clip_embeddings\"][0]))\n            else:\n                # If neither is available, raise an error\n                error_msg = \"No embeddings were generated for the video\"\n                raise ValueError(error_msg)\n\n        return embeddings\n\n    def embed_query(self, text: str) -> list[float]:\n        video_path = text.page_content if hasattr(text, \"page_content\") else str(text)\n        result = self.embed_video(video_path)\n\n        # First try to use video embedding, then fall back to clip embedding if available\n        if result[\"video_embedding\"] is not None:\n            return cast(\"list[float]\", result[\"video_embedding\"])\n        if result[\"clip_embeddings\"] and len(result[\"clip_embeddings\"]) > 0:\n            return cast(\"list[float]\", result[\"clip_embeddings\"][0])\n        # If neither is available, raise an error\n        error_msg = \"No embeddings were generated for the video\"\n        raise ValueError(error_msg)\n\n    def embed_video(self, video_path: str) -> dict[str, list[float] | list[list[float]]]:\n        file_path = Path(video_path)\n        with file_path.open(\"rb\") as video_file:\n            task = self.client.embed.task.create(\n                model_name=self.model_name,\n                video_file=video_file,\n                video_embedding_scopes=[\"video\", \"clip\"],\n            )\n\n        result = self._wait_for_task_completion(task.id)\n\n        video_embedding: dict[str, list[float] | list[list[float]]] = {\n            \"video_embedding\": [],  # Initialize as empty list instead of None\n            \"clip_embeddings\": [],\n        }\n\n        if hasattr(result.video_embedding, \"segments\") and result.video_embedding.segments:\n            for seg in result.video_embedding.segments:\n                # Check for embeddings_float attribute (this is the correct attribute name)\n                if hasattr(seg, \"embeddings_float\") and seg.embedding_scope == \"video\":\n                    # Convert to list of floats\n                    video_embedding[\"video_embedding\"] = [float(x) for x in seg.embeddings_float]\n\n        return video_embedding\n\n\nclass TwelveLabsVideoEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"TwelveLabs Video Embeddings\"\n    description = \"Generate embeddings from videos using TwelveLabs video embedding models.\"\n    name = \"TwelveLabsVideoEmbeddings\"\n    icon = \"TwelveLabs\"\n    documentation = \"https://github.com/twelvelabs-io/twelvelabs-developer-experience/blob/main/integrations/Langflow/TWELVE_LABS_COMPONENTS_README.md\"\n    inputs = [\n        SecretStrInput(name=\"api_key\", display_name=\"TwelveLabs API Key\", required=True),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model\",\n            advanced=False,\n            options=[\"Marengo-retrieval-2.7\"],\n            value=\"Marengo-retrieval-2.7\",\n        ),\n        IntInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return TwelveLabsVideoEmbeddings(api_key=self.api_key, model_name=self.model_name)\n"},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Model","dynamic":false,"external_options":{},"info":"","name":"model_name","options":["Marengo-retrieval-2.7"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Marengo-retrieval-2.7"},"request_timeout":{"_input_type":"IntInput","advanced":true,"display_name":"Request Timeout","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"request_timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""}},"tool_mode":false},"VideoFile":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Load a video file in common video formats.","display_name":"Video File","documentation":"https://github.com/twelvelabs-io/twelvelabs-developer-experience/blob/main/integrations/Langflow/TWELVE_LABS_COMPONENTS_README.md","edited":false,"field_order":["file_path"],"frozen":false,"icon":"TwelveLabs","legacy":false,"metadata":{"code_hash":"6f9d51bcb20e","dependencies":{"dependencies":[{"name":"lfx","version":null}],"total_dependencies":1},"module":"lfx.components.twelvelabs.video_file.VideoFileComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Files","group_outputs":false,"method":"load_files","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from pathlib import Path\n\nfrom lfx.base.data import BaseFileComponent\nfrom lfx.io import FileInput\nfrom lfx.schema import Data, DataFrame\n\n\nclass VideoFileComponent(BaseFileComponent):\n    \"\"\"Handles loading and processing of video files.\n\n    This component supports processing video files in common video formats.\n    \"\"\"\n\n    display_name = \"Video File\"\n    description = \"Load a video file in common video formats.\"\n    icon = \"TwelveLabs\"\n    name = \"VideoFile\"\n    documentation = \"https://github.com/twelvelabs-io/twelvelabs-developer-experience/blob/main/integrations/Langflow/TWELVE_LABS_COMPONENTS_README.md\"\n\n    VALID_EXTENSIONS = [\n        # Common video formats\n        \"mp4\",\n        \"avi\",\n        \"mov\",\n        \"mkv\",\n        \"webm\",\n        \"flv\",\n        \"wmv\",\n        \"mpg\",\n        \"mpeg\",\n        \"m4v\",\n        \"3gp\",\n        \"3g2\",\n        \"m2v\",\n        # Professional video formats\n        \"mxf\",\n        \"dv\",\n        \"vob\",\n        # Additional video formats\n        \"ogv\",\n        \"rm\",\n        \"rmvb\",\n        \"amv\",\n        \"divx\",\n        \"m2ts\",\n        \"mts\",\n        \"ts\",\n        \"qt\",\n        \"yuv\",\n        \"y4m\",\n    ]\n\n    inputs = [\n        FileInput(\n            display_name=\"Video File\",\n            name=\"file_path\",\n            file_types=[\n                # Common video formats\n                \"mp4\",\n                \"avi\",\n                \"mov\",\n                \"mkv\",\n                \"webm\",\n                \"flv\",\n                \"wmv\",\n                \"mpg\",\n                \"mpeg\",\n                \"m4v\",\n                \"3gp\",\n                \"3g2\",\n                \"m2v\",\n                # Professional video formats\n                \"mxf\",\n                \"dv\",\n                \"vob\",\n                # Additional video formats\n                \"ogv\",\n                \"rm\",\n                \"rmvb\",\n                \"amv\",\n                \"divx\",\n                \"m2ts\",\n                \"mts\",\n                \"ts\",\n                \"qt\",\n                \"yuv\",\n                \"y4m\",\n            ],\n            required=True,\n            info=\"Upload a video file in any common video format supported by ffmpeg\",\n        ),\n    ]\n\n    outputs = [\n        *BaseFileComponent.get_base_outputs(),\n    ]\n\n    def process_files(self, file_list: list[BaseFileComponent.BaseFile]) -> list[BaseFileComponent.BaseFile]:\n        \"\"\"Process video files.\"\"\"\n        self.log(f\"DEBUG: Processing video files: {len(file_list)}\")\n\n        if not file_list:\n            msg = \"No files to process.\"\n            raise ValueError(msg)\n\n        processed_files = []\n        for file in file_list:\n            try:\n                file_path = str(file.path)\n                self.log(f\"DEBUG: Processing video file: {file_path}\")\n\n                # Verify file exists\n                file_path_obj = Path(file_path)\n                if not file_path_obj.exists():\n                    error_msg = f\"Video file not found: {file_path}\"\n                    raise FileNotFoundError(error_msg)\n\n                # Verify extension\n                if not file_path.lower().endswith(tuple(self.VALID_EXTENSIONS)):\n                    error_msg = f\"Invalid file type. Expected: {', '.join(self.VALID_EXTENSIONS)}\"\n                    raise ValueError(error_msg)\n\n                # Create a dictionary instead of a Document\n                doc_data = {\"text\": file_path, \"metadata\": {\"source\": file_path, \"type\": \"video\"}}\n\n                # Pass the dictionary to Data\n                file.data = Data(data=doc_data)\n\n                self.log(f\"DEBUG: Created data: {doc_data}\")\n                processed_files.append(file)\n\n            except Exception as e:\n                self.log(f\"Error processing video file: {e!s}\", \"ERROR\")\n                raise\n\n        return processed_files\n\n    def load_files(self) -> DataFrame:\n        \"\"\"Load video files and return a list of Data objects.\"\"\"\n        try:\n            self.log(\"DEBUG: Starting video file load\")\n            if not hasattr(self, \"file_path\") or not self.file_path:\n                self.log(\"DEBUG: No video file path provided\")\n                return DataFrame()\n\n            self.log(f\"DEBUG: Loading video from path: {self.file_path}\")\n\n            # Verify file exists\n            file_path_obj = Path(self.file_path)\n            if not file_path_obj.exists():\n                self.log(f\"DEBUG: Video file not found at path: {self.file_path}\")\n                return DataFrame()\n\n            # Verify file size\n            file_size = file_path_obj.stat().st_size\n            self.log(f\"DEBUG: Video file size: {file_size} bytes\")\n\n            # Create a proper Data object with the video path\n            video_data = {\n                \"text\": self.file_path,\n                \"metadata\": {\"source\": self.file_path, \"type\": \"video\", \"size\": file_size},\n            }\n\n            self.log(f\"DEBUG: Created video data: {video_data}\")\n            result = DataFrame(data=[video_data])\n\n            # Log the result to verify it's a proper Data object\n            self.log(\"DEBUG: Returning list with Data objects\")\n        except (FileNotFoundError, PermissionError, OSError) as e:\n            self.log(f\"DEBUG: File error in video load_files: {e!s}\", \"ERROR\")\n            return DataFrame()\n        except ImportError as e:\n            self.log(f\"DEBUG: Import error in video load_files: {e!s}\", \"ERROR\")\n            return DataFrame()\n        except (ValueError, TypeError) as e:\n            self.log(f\"DEBUG: Value or type error in video load_files: {e!s}\", \"ERROR\")\n            return DataFrame()\n        else:\n            return result\n"},"file_path":{"_input_type":"FileInput","advanced":false,"display_name":"Video File","dynamic":false,"fileTypes":["mp4","avi","mov","mkv","webm","flv","wmv","mpg","mpeg","m4v","3gp","3g2","m2v","mxf","dv","vob","ogv","rm","rmvb","amv","divx","m2ts","mts","ts","qt","yuv","y4m"],"file_path":"","info":"Upload a video file in any common video format supported by ffmpeg","list":false,"list_add_label":"Add More","name":"file_path","placeholder":"","required":true,"show":true,"temp_file":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"file","value":""}},"tool_mode":false}}],["unstructured",{"Unstructured":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Uses Unstructured.io API to extract clean text from raw source documents. Supports a wide range of file types.","display_name":"Unstructured API","documentation":"https://python.langchain.com/api_reference/unstructured/document_loaders/langchain_unstructured.document_loaders.UnstructuredLoader.html","edited":false,"field_order":["path","file_path","separator","silent_errors","delete_server_file_after_processing","ignore_unsupported_extensions","ignore_unspecified_files","api_key","api_url","chunking_strategy","unstructured_args"],"frozen":false,"icon":"Unstructured","legacy":false,"metadata":{"code_hash":"bbb4e71aee8e","dependencies":{"dependencies":[{"name":"langchain_unstructured","version":"0.1.5"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.unstructured.unstructured.UnstructuredComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Files","group_outputs":false,"method":"load_files","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Unstructured.io Serverless API Key","dynamic":false,"info":"Unstructured API Key. Create at: https://app.unstructured.io/","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"api_url":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Unstructured.io API URL","dynamic":false,"info":"Unstructured API URL.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"api_url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"chunking_strategy":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Chunking Strategy","dynamic":false,"external_options":{},"info":"Chunking strategy to use, see https://docs.unstructured.io/api-reference/api-services/chunking","name":"chunking_strategy","options":["","basic","by_title","by_page","by_similarity"],"options_metadata":[],"placeholder":"","real_time_refresh":false,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_unstructured import UnstructuredLoader\n\nfrom lfx.base.data.base_file import BaseFileComponent\nfrom lfx.inputs.inputs import DropdownInput, MessageTextInput, NestedDictInput, SecretStrInput\nfrom lfx.schema.data import Data\n\n\nclass UnstructuredComponent(BaseFileComponent):\n    display_name = \"Unstructured API\"\n    description = (\n        \"Uses Unstructured.io API to extract clean text from raw source documents. Supports a wide range of file types.\"\n    )\n    documentation = (\n        \"https://python.langchain.com/api_reference/unstructured/document_loaders/\"\n        \"langchain_unstructured.document_loaders.UnstructuredLoader.html\"\n    )\n    trace_type = \"tool\"\n    icon = \"Unstructured\"\n    name = \"Unstructured\"\n\n    # https://docs.unstructured.io/api-reference/api-services/overview#supported-file-types\n    VALID_EXTENSIONS = [\n        \"bmp\",\n        \"csv\",\n        \"doc\",\n        \"docx\",\n        \"eml\",\n        \"epub\",\n        \"heic\",\n        \"html\",\n        \"jpeg\",\n        \"png\",\n        \"md\",\n        \"msg\",\n        \"odt\",\n        \"org\",\n        \"p7s\",\n        \"pdf\",\n        \"png\",\n        \"ppt\",\n        \"pptx\",\n        \"rst\",\n        \"rtf\",\n        \"tiff\",\n        \"txt\",\n        \"tsv\",\n        \"xls\",\n        \"xlsx\",\n        \"xml\",\n    ]\n\n    inputs = [\n        *BaseFileComponent.get_base_inputs(),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Unstructured.io Serverless API Key\",\n            required=True,\n            info=\"Unstructured API Key. Create at: https://app.unstructured.io/\",\n        ),\n        MessageTextInput(\n            name=\"api_url\",\n            display_name=\"Unstructured.io API URL\",\n            required=False,\n            info=\"Unstructured API URL.\",\n        ),\n        DropdownInput(\n            name=\"chunking_strategy\",\n            display_name=\"Chunking Strategy\",\n            info=\"Chunking strategy to use, see https://docs.unstructured.io/api-reference/api-services/chunking\",\n            options=[\"\", \"basic\", \"by_title\", \"by_page\", \"by_similarity\"],\n            real_time_refresh=False,\n            value=\"\",\n        ),\n        NestedDictInput(\n            name=\"unstructured_args\",\n            display_name=\"Additional Arguments\",\n            required=False,\n            info=(\n                \"Optional dictionary of additional arguments to the Loader. \"\n                \"See https://docs.unstructured.io/api-reference/api-services/api-parameters for more information.\"\n            ),\n        ),\n    ]\n\n    outputs = [\n        *BaseFileComponent.get_base_outputs(),\n    ]\n\n    def process_files(self, file_list: list[BaseFileComponent.BaseFile]) -> list[BaseFileComponent.BaseFile]:\n        file_paths = [str(file.path) for file in file_list if file.path]\n\n        if not file_paths:\n            self.log(\"No files to process.\")\n            return file_list\n\n        # https://docs.unstructured.io/api-reference/api-services/api-parameters\n        args = self.unstructured_args or {}\n\n        if self.chunking_strategy:\n            args[\"chunking_strategy\"] = self.chunking_strategy\n\n        args[\"api_key\"] = self.api_key\n        args[\"partition_via_api\"] = True\n        if self.api_url:\n            args[\"url\"] = self.api_url\n\n        loader = UnstructuredLoader(\n            file_paths,\n            **args,\n        )\n\n        documents = loader.load()\n\n        processed_data: list[Data | None] = [Data.from_document(doc) if doc else None for doc in documents]\n\n        # Rename the `source` field to `self.SERVER_FILE_PATH_FIELDNAME`, to avoid conflicts with the `source` field\n        for data in processed_data:\n            if data and \"source\" in data.data:\n                data.data[self.SERVER_FILE_PATH_FIELDNAME] = data.data.pop(\"source\")\n\n        return self.rollup_data(file_list, processed_data)\n"},"delete_server_file_after_processing":{"_input_type":"BoolInput","advanced":true,"display_name":"Delete Server File After Processing","dynamic":false,"info":"If true, the Server File Path will be deleted after processing.","list":false,"list_add_label":"Add More","name":"delete_server_file_after_processing","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"file_path":{"_input_type":"HandleInput","advanced":true,"display_name":"Server File Path","dynamic":false,"info":"Data object with a 'file_path' property pointing to server file or a Message object with a path to the file. Supercedes 'Path' but supports same file types.","input_types":["Data","Message"],"list":true,"list_add_label":"Add More","name":"file_path","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"ignore_unspecified_files":{"_input_type":"BoolInput","advanced":true,"display_name":"Ignore Unspecified Files","dynamic":false,"info":"If true, Data with no 'file_path' property will be ignored.","list":false,"list_add_label":"Add More","name":"ignore_unspecified_files","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"ignore_unsupported_extensions":{"_input_type":"BoolInput","advanced":true,"display_name":"Ignore Unsupported Extensions","dynamic":false,"info":"If true, files with unsupported extensions will not be processed.","list":false,"list_add_label":"Add More","name":"ignore_unsupported_extensions","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"path":{"_input_type":"FileInput","advanced":false,"display_name":"Files","dynamic":false,"fileTypes":["bmp","csv","doc","docx","eml","epub","heic","html","jpeg","png","md","msg","odt","org","p7s","pdf","png","ppt","pptx","rst","rtf","tiff","txt","tsv","xls","xlsx","xml","zip","tar","tgz","bz2","gz"],"file_path":"","info":"Supported file extensions: bmp, csv, doc, docx, eml, epub, heic, html, jpeg, png, md, msg, odt, org, p7s, pdf, png, ppt, pptx, rst, rtf, tiff, txt, tsv, xls, xlsx, xml; optionally bundled in file extensions: zip, tar, tgz, bz2, gz","list":true,"list_add_label":"Add More","name":"path","placeholder":"","required":false,"show":true,"temp_file":false,"title_case":false,"tool_mode":true,"trace_as_metadata":true,"type":"file","value":[]},"separator":{"_input_type":"StrInput","advanced":true,"display_name":"Separator","dynamic":false,"info":"Specify the separator to use between multiple outputs in Message format.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"separator","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"\n\n"},"silent_errors":{"_input_type":"BoolInput","advanced":true,"display_name":"Silent Errors","dynamic":false,"info":"If true, errors will not raise an exception.","list":false,"list_add_label":"Add More","name":"silent_errors","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"unstructured_args":{"_input_type":"NestedDictInput","advanced":false,"display_name":"Additional Arguments","dynamic":false,"info":"Optional dictionary of additional arguments to the Loader. See https://docs.unstructured.io/api-reference/api-services/api-parameters for more information.","list":false,"list_add_label":"Add More","name":"unstructured_args","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"NestedDict","value":{}}},"tool_mode":false}}],["upstash",{"Upstash":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Upstash Vector Store with search capabilities","display_name":"Upstash","documentation":"","edited":false,"field_order":["index_url","index_token","text_key","namespace","ingest_data","search_query","should_cache_vector_store","metadata_filter","embedding","number_of_results"],"frozen":false,"icon":"Upstash","legacy":false,"metadata":{"code_hash":"b5b2d78e8c44","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.upstash.upstash.UpstashVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_community.vectorstores import UpstashVectorStore\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.io import (\n    HandleInput,\n    IntInput,\n    MultilineInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass UpstashVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Upstash\"\n    description = \"Upstash Vector Store with search capabilities\"\n    name = \"Upstash\"\n    icon = \"Upstash\"\n\n    inputs = [\n        StrInput(\n            name=\"index_url\",\n            display_name=\"Index URL\",\n            info=\"The URL of the Upstash index.\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"index_token\",\n            display_name=\"Upstash Index Token\",\n            info=\"The token for the Upstash index.\",\n            required=True,\n        ),\n        StrInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"The key in the record to use as text.\",\n            value=\"text\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"namespace\",\n            display_name=\"Namespace\",\n            info=\"Leave empty for default namespace.\",\n        ),\n        *LCVectorStoreComponent.inputs,\n        MultilineInput(\n            name=\"metadata_filter\",\n            display_name=\"Metadata Filter\",\n            info=\"Filters documents by metadata. Look at the documentation for more information.\",\n        ),\n        HandleInput(\n            name=\"embedding\",\n            display_name=\"Embedding\",\n            input_types=[\"Embeddings\"],\n            info=\"To use Upstash's embeddings, don't provide an embedding.\",\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> UpstashVectorStore:\n        use_upstash_embedding = self.embedding is None\n\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents:\n            if use_upstash_embedding:\n                upstash_vs = UpstashVectorStore(\n                    embedding=use_upstash_embedding,\n                    text_key=self.text_key,\n                    index_url=self.index_url,\n                    index_token=self.index_token,\n                    namespace=self.namespace,\n                )\n                upstash_vs.add_documents(documents)\n            else:\n                upstash_vs = UpstashVectorStore.from_documents(\n                    documents=documents,\n                    embedding=self.embedding,\n                    text_key=self.text_key,\n                    index_url=self.index_url,\n                    index_token=self.index_token,\n                    namespace=self.namespace,\n                )\n        else:\n            upstash_vs = UpstashVectorStore(\n                embedding=self.embedding or use_upstash_embedding,\n                text_key=self.text_key,\n                index_url=self.index_url,\n                index_token=self.index_token,\n                namespace=self.namespace,\n            )\n\n        return upstash_vs\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n                filter=self.metadata_filter,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n"},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"To use Upstash's embeddings, don't provide an embedding.","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"index_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Upstash Index Token","dynamic":false,"info":"The token for the Upstash index.","input_types":[],"load_from_db":true,"name":"index_token","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"index_url":{"_input_type":"StrInput","advanced":false,"display_name":"Index URL","dynamic":false,"info":"The URL of the Upstash index.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"index_url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"metadata_filter":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Metadata Filter","dynamic":false,"info":"Filters documents by metadata. Look at the documentation for more information.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"metadata_filter","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"namespace":{"_input_type":"StrInput","advanced":false,"display_name":"Namespace","dynamic":false,"info":"Leave empty for default namespace.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"namespace","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"text_key":{"_input_type":"StrInput","advanced":true,"display_name":"Text Key","dynamic":false,"info":"The key in the record to use as text.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"text_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"text"}},"tool_mode":false}}],["vectara",{"Vectara":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Vectara Vector Store with search capabilities","display_name":"Vectara","documentation":"","edited":false,"field_order":["vectara_customer_id","vectara_corpus_id","vectara_api_key","embedding","ingest_data","search_query","should_cache_vector_store","number_of_results"],"frozen":false,"icon":"Vectara","legacy":false,"metadata":{"code_hash":"a2309e046c06","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.vectara.vectara.VectaraVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import TYPE_CHECKING\n\nfrom langchain_community.vectorstores import Vectara\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.io import HandleInput, IntInput, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\nif TYPE_CHECKING:\n    from lfx.schema.dataframe import DataFrame\n\n\nclass VectaraVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"Vectara Vector Store with search capabilities.\"\"\"\n\n    display_name: str = \"Vectara\"\n    description: str = \"Vectara Vector Store with search capabilities\"\n    name = \"Vectara\"\n    icon = \"Vectara\"\n\n    inputs = [\n        StrInput(name=\"vectara_customer_id\", display_name=\"Vectara Customer ID\", required=True),\n        StrInput(name=\"vectara_corpus_id\", display_name=\"Vectara Corpus ID\", required=True),\n        SecretStrInput(name=\"vectara_api_key\", display_name=\"Vectara API Key\", required=True),\n        HandleInput(\n            name=\"embedding\",\n            display_name=\"Embedding\",\n            input_types=[\"Embeddings\"],\n        ),\n        *LCVectorStoreComponent.inputs,\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> Vectara:\n        \"\"\"Builds the Vectara object.\"\"\"\n        try:\n            from langchain_community.vectorstores import Vectara\n        except ImportError as e:\n            msg = \"Could not import Vectara. Please install it with `pip install langchain-community`.\"\n            raise ImportError(msg) from e\n\n        vectara = Vectara(\n            vectara_customer_id=self.vectara_customer_id,\n            vectara_corpus_id=self.vectara_corpus_id,\n            vectara_api_key=self.vectara_api_key,\n        )\n\n        self._add_documents_to_vector_store(vectara)\n        return vectara\n\n    def _add_documents_to_vector_store(self, vector_store: Vectara) -> None:\n        \"\"\"Adds documents to the Vector Store.\"\"\"\n        ingest_data: list | Data | DataFrame = self.ingest_data\n        if not ingest_data:\n            self.status = \"No documents to add to Vectara\"\n            return\n\n        # Convert DataFrame to Data if needed using parent's method\n        ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents:\n            self.log(f\"Adding {len(documents)} documents to Vectara.\")\n            vector_store.add_documents(documents)\n            self.status = f\"Added {len(documents)} documents to Vectara\"\n        else:\n            self.log(\"No documents to add to Vectara.\")\n            self.status = \"No valid documents to add to Vectara\"\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = f\"Found {len(data)} results for the query: {self.search_query}\"\n            return data\n        self.status = \"No search query provided\"\n        return []\n"},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"vectara_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Vectara API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"vectara_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"vectara_corpus_id":{"_input_type":"StrInput","advanced":false,"display_name":"Vectara Corpus ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"vectara_corpus_id","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"vectara_customer_id":{"_input_type":"StrInput","advanced":false,"display_name":"Vectara Customer ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"vectara_customer_id","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"VectaraRAG":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Vectara's full end to end RAG","display_name":"Vectara RAG","documentation":"https://docs.vectara.com/docs","edited":false,"field_order":["vectara_customer_id","vectara_corpus_id","vectara_api_key","search_query","lexical_interpolation","filter","reranker","reranker_k","diversity_bias","max_results","response_lang","prompt"],"frozen":false,"icon":"Vectara","legacy":false,"metadata":{"code_hash":"123c9eef9191","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"langchain_community","version":"0.3.21"}],"total_dependencies":2},"module":"lfx.components.vectara.vectara_rag.VectaraRagComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Answer","group_outputs":false,"method":"generate_response","name":"answer","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.io import DropdownInput, FloatInput, IntInput, MessageTextInput, Output, SecretStrInput, StrInput\nfrom lfx.schema.message import Message\n\n\nclass VectaraRagComponent(Component):\n    display_name = \"Vectara RAG\"\n    description = \"Vectara's full end to end RAG\"\n    documentation = \"https://docs.vectara.com/docs\"\n    icon = \"Vectara\"\n    name = \"VectaraRAG\"\n    SUMMARIZER_PROMPTS = [\n        \"vectara-summary-ext-24-05-sml\",\n        \"vectara-summary-ext-24-05-med-omni\",\n        \"vectara-summary-ext-24-05-large\",\n        \"vectara-summary-ext-24-05-med\",\n        \"vectara-summary-ext-v1.3.0\",\n    ]\n\n    RERANKER_TYPES = [\"mmr\", \"rerank_multilingual_v1\", \"none\"]\n\n    RESPONSE_LANGUAGES = [\n        \"auto\",\n        \"eng\",\n        \"spa\",\n        \"fra\",\n        \"zho\",\n        \"deu\",\n        \"hin\",\n        \"ara\",\n        \"por\",\n        \"ita\",\n        \"jpn\",\n        \"kor\",\n        \"rus\",\n        \"tur\",\n        \"fas\",\n        \"vie\",\n        \"tha\",\n        \"heb\",\n        \"nld\",\n        \"ind\",\n        \"pol\",\n        \"ukr\",\n        \"ron\",\n        \"swe\",\n        \"ces\",\n        \"ell\",\n        \"ben\",\n        \"msa\",\n        \"urd\",\n    ]\n\n    field_order = [\"vectara_customer_id\", \"vectara_corpus_id\", \"vectara_api_key\", \"search_query\", \"reranker\"]\n\n    inputs = [\n        StrInput(name=\"vectara_customer_id\", display_name=\"Vectara Customer ID\", required=True),\n        StrInput(name=\"vectara_corpus_id\", display_name=\"Vectara Corpus ID\", required=True),\n        SecretStrInput(name=\"vectara_api_key\", display_name=\"Vectara API Key\", required=True),\n        MessageTextInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n            info=\"The query to receive an answer on.\",\n            tool_mode=True,\n        ),\n        FloatInput(\n            name=\"lexical_interpolation\",\n            display_name=\"Hybrid Search Factor\",\n            range_spec=RangeSpec(min=0.005, max=0.1, step=0.005),\n            value=0.005,\n            advanced=True,\n            info=\"How much to weigh lexical scores compared to the embedding score. \"\n            \"0 means lexical search is not used at all, and 1 means only lexical search is used.\",\n        ),\n        MessageTextInput(\n            name=\"filter\",\n            display_name=\"Metadata Filters\",\n            value=\"\",\n            advanced=True,\n            info=\"The filter string to narrow the search to according to metadata attributes.\",\n        ),\n        DropdownInput(\n            name=\"reranker\",\n            display_name=\"Reranker Type\",\n            options=RERANKER_TYPES,\n            value=RERANKER_TYPES[0],\n            info=\"How to rerank the retrieved search results.\",\n        ),\n        IntInput(\n            name=\"reranker_k\",\n            display_name=\"Number of Results to Rerank\",\n            value=50,\n            range_spec=RangeSpec(min=1, max=100, step=1),\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"diversity_bias\",\n            display_name=\"Diversity Bias\",\n            value=0.2,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            advanced=True,\n            info=\"Ranges from 0 to 1, with higher values indicating greater diversity (only applies to MMR reranker).\",\n        ),\n        IntInput(\n            name=\"max_results\",\n            display_name=\"Max Results to Summarize\",\n            value=7,\n            range_spec=RangeSpec(min=1, max=100, step=1),\n            advanced=True,\n            info=\"The maximum number of search results to be available to the prompt.\",\n        ),\n        DropdownInput(\n            name=\"response_lang\",\n            display_name=\"Response Language\",\n            options=RESPONSE_LANGUAGES,\n            value=\"eng\",\n            advanced=True,\n            info=\"Use the ISO 639-1 or 639-3 language code or auto to automatically detect the language.\",\n        ),\n        DropdownInput(\n            name=\"prompt\",\n            display_name=\"Prompt Name\",\n            options=SUMMARIZER_PROMPTS,\n            value=SUMMARIZER_PROMPTS[0],\n            advanced=True,\n            info=\"Only vectara-summary-ext-24-05-sml is for Growth customers; \"\n            \"all other prompts are for Scale customers only.\",\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"answer\", display_name=\"Answer\", method=\"generate_response\"),\n    ]\n\n    def generate_response(\n        self,\n    ) -> Message:\n        text_output = \"\"\n\n        try:\n            from langchain_community.vectorstores import Vectara\n            from langchain_community.vectorstores.vectara import RerankConfig, SummaryConfig, VectaraQueryConfig\n        except ImportError as e:\n            msg = \"Could not import Vectara. Please install it with `pip install langchain-community`.\"\n            raise ImportError(msg) from e\n\n        vectara = Vectara(self.vectara_customer_id, self.vectara_corpus_id, self.vectara_api_key)\n        rerank_config = RerankConfig(self.reranker, self.reranker_k, self.diversity_bias)\n        summary_config = SummaryConfig(\n            is_enabled=True, max_results=self.max_results, response_lang=self.response_lang, prompt_name=self.prompt\n        )\n        config = VectaraQueryConfig(\n            lambda_val=self.lexical_interpolation,\n            filter=self.filter,\n            summary_config=summary_config,\n            rerank_config=rerank_config,\n        )\n        rag = vectara.as_rag(config)\n        response = rag.invoke(self.search_query, config={\"callbacks\": self.get_langchain_callbacks()})\n\n        text_output = response[\"answer\"]\n\n        return Message(text=text_output)\n"},"diversity_bias":{"_input_type":"FloatInput","advanced":true,"display_name":"Diversity Bias","dynamic":false,"info":"Ranges from 0 to 1, with higher values indicating greater diversity (only applies to MMR reranker).","list":false,"list_add_label":"Add More","name":"diversity_bias","placeholder":"","range_spec":{"max":1.0,"min":0.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.2},"filter":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Metadata Filters","dynamic":false,"info":"The filter string to narrow the search to according to metadata attributes.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"filter","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"lexical_interpolation":{"_input_type":"FloatInput","advanced":true,"display_name":"Hybrid Search Factor","dynamic":false,"info":"How much to weigh lexical scores compared to the embedding score. 0 means lexical search is not used at all, and 1 means only lexical search is used.","list":false,"list_add_label":"Add More","name":"lexical_interpolation","placeholder":"","range_spec":{"max":0.1,"min":0.005,"step":0.005,"step_type":"float"},"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.005},"max_results":{"_input_type":"IntInput","advanced":true,"display_name":"Max Results to Summarize","dynamic":false,"info":"The maximum number of search results to be available to the prompt.","list":false,"list_add_label":"Add More","name":"max_results","placeholder":"","range_spec":{"max":100.0,"min":1.0,"step":1.0,"step_type":"float"},"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":7},"prompt":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Prompt Name","dynamic":false,"external_options":{},"info":"Only vectara-summary-ext-24-05-sml is for Growth customers; all other prompts are for Scale customers only.","name":"prompt","options":["vectara-summary-ext-24-05-sml","vectara-summary-ext-24-05-med-omni","vectara-summary-ext-24-05-large","vectara-summary-ext-24-05-med","vectara-summary-ext-v1.3.0"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"vectara-summary-ext-24-05-sml"},"reranker":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Reranker Type","dynamic":false,"external_options":{},"info":"How to rerank the retrieved search results.","name":"reranker","options":["mmr","rerank_multilingual_v1","none"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"mmr"},"reranker_k":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results to Rerank","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"reranker_k","placeholder":"","range_spec":{"max":100.0,"min":1.0,"step":1.0,"step_type":"float"},"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":50},"response_lang":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Response Language","dynamic":false,"external_options":{},"info":"Use the ISO 639-1 or 639-3 language code or auto to automatically detect the language.","name":"response_lang","options":["auto","eng","spa","fra","zho","deu","hin","ara","por","ita","jpn","kor","rus","tur","fas","vie","tha","heb","nld","ind","pol","ukr","ron","swe","ces","ell","ben","msa","urd"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"eng"},"search_query":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"The query to receive an answer on.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"vectara_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Vectara API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"vectara_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"vectara_corpus_id":{"_input_type":"StrInput","advanced":false,"display_name":"Vectara Corpus ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"vectara_corpus_id","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"vectara_customer_id":{"_input_type":"StrInput","advanced":false,"display_name":"Vectara Customer ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"vectara_customer_id","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["vectorstores",{"AstraDB":{"base_classes":["Data","DataFrame","VectorStore"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Ingest and search documents in Astra DB","display_name":"Astra DB","documentation":"https://docs.datastax.com/en/langflow/astra-components.html","edited":false,"field_order":["token","environment","database_name","api_endpoint","keyspace","collection_name","embedding_model","ingest_data","search_query","should_cache_vector_store","search_method","reranker","lexical_terms","number_of_results","search_type","search_score_threshold","advanced_search_filter","autodetect_collection","content_field","deletion_field","ignore_invalid_documents","astradb_vectorstore_kwargs"],"frozen":false,"icon":"AstraDB","legacy":false,"metadata":{"code_hash":"0e26d8c1384d","dependencies":{"dependencies":[{"name":"astrapy","version":"2.1.0"},{"name":"langchain_astradb","version":"0.6.1"},{"name":"langchain_core","version":"0.3.79"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.vectorstores.astradb.AstraDBVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Vector Store Connection","group_outputs":false,"hidden":false,"method":"as_vector_store","name":"vectorstoreconnection","selected":"VectorStore","tool_mode":true,"types":["VectorStore"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","advanced_search_filter":{"_input_type":"NestedDictInput","advanced":true,"display_name":"Search Metadata Filter","dynamic":false,"info":"Optional dictionary of filters to apply to the search query.","list":false,"list_add_label":"Add More","name":"advanced_search_filter","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"NestedDict","value":{}},"api_endpoint":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Astra DB API Endpoint","dynamic":false,"external_options":{},"info":"The API Endpoint for the Astra DB instance. Supercedes database selection.","name":"api_endpoint","options":[],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"astradb_vectorstore_kwargs":{"_input_type":"NestedDictInput","advanced":true,"display_name":"AstraDBVectorStore Parameters","dynamic":false,"info":"Optional dictionary of additional parameters for the AstraDBVectorStore.","list":false,"list_add_label":"Add More","name":"astradb_vectorstore_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"NestedDict","value":{}},"autodetect_collection":{"_input_type":"BoolInput","advanced":true,"display_name":"Autodetect Collection","dynamic":false,"info":"Boolean flag to determine whether to autodetect the collection.","list":false,"list_add_label":"Add More","name":"autodetect_collection","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import re\nfrom collections import defaultdict\nfrom dataclasses import asdict, dataclass, field\n\nfrom astrapy import DataAPIClient, Database\nfrom astrapy.data.info.reranking import RerankServiceOptions\nfrom astrapy.info import CollectionDescriptor, CollectionLexicalOptions, CollectionRerankOptions\nfrom langchain_astradb import AstraDBVectorStore, VectorServiceOptions\nfrom langchain_astradb.utils.astradb import HybridSearchMode, _AstraDBCollectionEnvironment\nfrom langchain_core.documents import Document\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.base.vectorstores.vector_store_connection_decorator import vector_store_connection\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.inputs.inputs import FloatInput, NestedDictInput\nfrom lfx.io import (\n    BoolInput,\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    QueryInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom lfx.schema.data import Data\nfrom lfx.serialization import serialize\nfrom lfx.utils.version import get_version_info\n\n\n@vector_store_connection\nclass AstraDBVectorStoreComponent(LCVectorStoreComponent):\n    display_name: str = \"Astra DB\"\n    description: str = \"Ingest and search documents in Astra DB\"\n    documentation: str = \"https://docs.datastax.com/en/langflow/astra-components.html\"\n    name = \"AstraDB\"\n    icon: str = \"AstraDB\"\n\n    _cached_vector_store: AstraDBVectorStore | None = None\n\n    @dataclass\n    class NewDatabaseInput:\n        functionality: str = \"create\"\n        fields: dict[str, dict] = field(\n            default_factory=lambda: {\n                \"data\": {\n                    \"node\": {\n                        \"name\": \"create_database\",\n                        \"description\": \"Please allow several minutes for creation to complete.\",\n                        \"display_name\": \"Create new database\",\n                        \"field_order\": [\"01_new_database_name\", \"02_cloud_provider\", \"03_region\"],\n                        \"template\": {\n                            \"01_new_database_name\": StrInput(\n                                name=\"new_database_name\",\n                                display_name=\"Name\",\n                                info=\"Name of the new database to create in Astra DB.\",\n                                required=True,\n                            ),\n                            \"02_cloud_provider\": DropdownInput(\n                                name=\"cloud_provider\",\n                                display_name=\"Cloud provider\",\n                                info=\"Cloud provider for the new database.\",\n                                options=[],\n                                required=True,\n                                real_time_refresh=True,\n                            ),\n                            \"03_region\": DropdownInput(\n                                name=\"region\",\n                                display_name=\"Region\",\n                                info=\"Region for the new database.\",\n                                options=[],\n                                required=True,\n                            ),\n                        },\n                    },\n                }\n            }\n        )\n\n    @dataclass\n    class NewCollectionInput:\n        functionality: str = \"create\"\n        fields: dict[str, dict] = field(\n            default_factory=lambda: {\n                \"data\": {\n                    \"node\": {\n                        \"name\": \"create_collection\",\n                        \"description\": \"Please allow several seconds for creation to complete.\",\n                        \"display_name\": \"Create new collection\",\n                        \"field_order\": [\n                            \"01_new_collection_name\",\n                            \"02_embedding_generation_provider\",\n                            \"03_embedding_generation_model\",\n                            \"04_dimension\",\n                        ],\n                        \"template\": {\n                            \"01_new_collection_name\": StrInput(\n                                name=\"new_collection_name\",\n                                display_name=\"Name\",\n                                info=\"Name of the new collection to create in Astra DB.\",\n                                required=True,\n                            ),\n                            \"02_embedding_generation_provider\": DropdownInput(\n                                name=\"embedding_generation_provider\",\n                                display_name=\"Embedding generation method\",\n                                info=\"Provider to use for generating embeddings.\",\n                                helper_text=(\n                                    \"To create collections with more embedding provider options, go to \"\n                                    '<a class=\"underline\" href=\"https://astra.datastax.com/\" target=\" _blank\" '\n                                    'rel=\"noopener noreferrer\">your database in Astra DB</a>'\n                                ),\n                                real_time_refresh=True,\n                                required=True,\n                                options=[],\n                            ),\n                            \"03_embedding_generation_model\": DropdownInput(\n                                name=\"embedding_generation_model\",\n                                display_name=\"Embedding model\",\n                                info=\"Model to use for generating embeddings.\",\n                                real_time_refresh=True,\n                                options=[],\n                            ),\n                            \"04_dimension\": IntInput(\n                                name=\"dimension\",\n                                display_name=\"Dimensions\",\n                                info=\"Dimensions of the embeddings to generate.\",\n                                value=None,\n                            ),\n                        },\n                    },\n                }\n            }\n        )\n\n    inputs = [\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n            required=True,\n            real_time_refresh=True,\n            input_types=[],\n        ),\n        DropdownInput(\n            name=\"environment\",\n            display_name=\"Environment\",\n            info=\"The environment for the Astra DB API Endpoint.\",\n            options=[\"prod\", \"test\", \"dev\"],\n            value=\"prod\",\n            advanced=True,\n            real_time_refresh=True,\n            combobox=True,\n        ),\n        DropdownInput(\n            name=\"database_name\",\n            display_name=\"Database\",\n            info=\"The Database name for the Astra DB instance.\",\n            required=True,\n            refresh_button=True,\n            real_time_refresh=True,\n            dialog_inputs=asdict(NewDatabaseInput()),\n            combobox=True,\n        ),\n        DropdownInput(\n            name=\"api_endpoint\",\n            display_name=\"Astra DB API Endpoint\",\n            info=\"The API Endpoint for the Astra DB instance. Supercedes database selection.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"keyspace\",\n            display_name=\"Keyspace\",\n            info=\"Optional keyspace within Astra DB to use for the collection.\",\n            advanced=True,\n            options=[],\n            real_time_refresh=True,\n        ),\n        DropdownInput(\n            name=\"collection_name\",\n            display_name=\"Collection\",\n            info=\"The name of the collection within Astra DB where the vectors will be stored.\",\n            required=True,\n            refresh_button=True,\n            real_time_refresh=True,\n            dialog_inputs=asdict(NewCollectionInput()),\n            combobox=True,\n            show=False,\n        ),\n        HandleInput(\n            name=\"embedding_model\",\n            display_name=\"Embedding Model\",\n            input_types=[\"Embeddings\"],\n            info=\"Specify the Embedding Model. Not required for Astra Vectorize collections.\",\n            required=False,\n            show=False,\n        ),\n        *LCVectorStoreComponent.inputs,\n        DropdownInput(\n            name=\"search_method\",\n            display_name=\"Search Method\",\n            info=(\n                \"Determine how your content is matched: Vector finds semantic similarity, \"\n                \"and Hybrid Search (suggested) combines both approaches \"\n                \"with a reranker.\"\n            ),\n            options=[\"Hybrid Search\", \"Vector Search\"],  # TODO: Restore Lexical Search?\n            options_metadata=[{\"icon\": \"SearchHybrid\"}, {\"icon\": \"SearchVector\"}],\n            value=\"Vector Search\",\n            advanced=True,\n            real_time_refresh=True,\n        ),\n        DropdownInput(\n            name=\"reranker\",\n            display_name=\"Reranker\",\n            info=\"Post-retrieval model that re-scores results for optimal relevance ranking.\",\n            show=False,\n            toggle=True,\n        ),\n        QueryInput(\n            name=\"lexical_terms\",\n            display_name=\"Lexical Terms\",\n            info=\"Add additional terms/keywords to augment search precision.\",\n            placeholder=\"Enter terms to search...\",\n            separator=\" \",\n            show=False,\n            value=\"\",\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Search Results\",\n            info=\"Number of search results to return.\",\n            advanced=True,\n            value=4,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            info=\"Search type to use\",\n            options=[\"Similarity\", \"Similarity with score threshold\", \"MMR (Max Marginal Relevance)\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results. \"\n            \"(when using 'Similarity with score threshold')\",\n            value=0,\n            advanced=True,\n        ),\n        NestedDictInput(\n            name=\"advanced_search_filter\",\n            display_name=\"Search Metadata Filter\",\n            info=\"Optional dictionary of filters to apply to the search query.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"autodetect_collection\",\n            display_name=\"Autodetect Collection\",\n            info=\"Boolean flag to determine whether to autodetect the collection.\",\n            advanced=True,\n            value=True,\n        ),\n        StrInput(\n            name=\"content_field\",\n            display_name=\"Content Field\",\n            info=\"Field to use as the text content field for the vector store.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"deletion_field\",\n            display_name=\"Deletion Based On Field\",\n            info=\"When this parameter is provided, documents in the target collection with \"\n            \"metadata field values matching the input metadata field value will be deleted \"\n            \"before new data is loaded.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"ignore_invalid_documents\",\n            display_name=\"Ignore Invalid Documents\",\n            info=\"Boolean flag to determine whether to ignore invalid documents at runtime.\",\n            advanced=True,\n        ),\n        NestedDictInput(\n            name=\"astradb_vectorstore_kwargs\",\n            display_name=\"AstraDBVectorStore Parameters\",\n            info=\"Optional dictionary of additional parameters for the AstraDBVectorStore.\",\n            advanced=True,\n        ),\n    ]\n\n    @classmethod\n    def map_cloud_providers(cls):\n        # TODO: Programmatically fetch the regions for each cloud provider\n        return {\n            \"dev\": {\n                \"Amazon Web Services\": {\n                    \"id\": \"aws\",\n                    \"regions\": [\"us-west-2\"],\n                },\n                \"Google Cloud Platform\": {\n                    \"id\": \"gcp\",\n                    \"regions\": [\"us-central1\", \"europe-west4\"],\n                },\n            },\n            \"test\": {\n                \"Google Cloud Platform\": {\n                    \"id\": \"gcp\",\n                    \"regions\": [\"us-central1\"],\n                },\n            },\n            \"prod\": {\n                \"Amazon Web Services\": {\n                    \"id\": \"aws\",\n                    \"regions\": [\"us-east-2\", \"ap-south-1\", \"eu-west-1\"],\n                },\n                \"Google Cloud Platform\": {\n                    \"id\": \"gcp\",\n                    \"regions\": [\"us-east1\"],\n                },\n                \"Microsoft Azure\": {\n                    \"id\": \"azure\",\n                    \"regions\": [\"westus3\"],\n                },\n            },\n        }\n\n    @classmethod\n    def get_vectorize_providers(cls, token: str, environment: str | None = None, api_endpoint: str | None = None):\n        try:\n            # Get the admin object\n            client = DataAPIClient(environment=environment)\n            admin_client = client.get_admin()\n            db_admin = admin_client.get_database_admin(api_endpoint, token=token)\n\n            # Get the list of embedding providers\n            embedding_providers = db_admin.find_embedding_providers()\n\n            vectorize_providers_mapping = {}\n            # Map the provider display name to the provider key and models\n            for provider_key, provider_data in embedding_providers.embedding_providers.items():\n                # Get the provider display name and models\n                display_name = provider_data.display_name\n                models = [model.name for model in provider_data.models]\n\n                # Build our mapping\n                vectorize_providers_mapping[display_name] = [provider_key, models]\n\n            # Sort the resulting dictionary\n            return defaultdict(list, dict(sorted(vectorize_providers_mapping.items())))\n        except Exception as _:  # noqa: BLE001\n            return {}\n\n    @classmethod\n    async def create_database_api(\n        cls,\n        new_database_name: str,\n        cloud_provider: str,\n        region: str,\n        token: str,\n        environment: str | None = None,\n        keyspace: str | None = None,\n    ):\n        client = DataAPIClient(environment=environment)\n\n        # Get the admin object\n        admin_client = client.get_admin(token=token)\n\n        # Get the environment, set to prod if null like\n        my_env = environment or \"prod\"\n\n        # Raise a value error if name isn't provided\n        if not new_database_name:\n            msg = \"Database name is required to create a new database.\"\n            raise ValueError(msg)\n\n        # Call the create database function\n        return await admin_client.async_create_database(\n            name=new_database_name,\n            cloud_provider=cls.map_cloud_providers()[my_env][cloud_provider][\"id\"],\n            region=region,\n            keyspace=keyspace,\n            wait_until_active=False,\n        )\n\n    @classmethod\n    async def create_collection_api(\n        cls,\n        new_collection_name: str,\n        token: str,\n        api_endpoint: str,\n        environment: str | None = None,\n        keyspace: str | None = None,\n        dimension: int | None = None,\n        embedding_generation_provider: str | None = None,\n        embedding_generation_model: str | None = None,\n        reranker: str | None = None,\n    ):\n        # Build vectorize options, if needed\n        vectorize_options = None\n        if not dimension:\n            providers = cls.get_vectorize_providers(token=token, environment=environment, api_endpoint=api_endpoint)\n            vectorize_options = VectorServiceOptions(\n                provider=providers.get(embedding_generation_provider, [None, []])[0],\n                model_name=embedding_generation_model,\n            )\n\n        # Raise a value error if name isn't provided\n        if not new_collection_name:\n            msg = \"Collection name is required to create a new collection.\"\n            raise ValueError(msg)\n\n        # Define the base arguments being passed to the create collection function\n        base_args = {\n            \"collection_name\": new_collection_name,\n            \"token\": token,\n            \"api_endpoint\": api_endpoint,\n            \"keyspace\": keyspace,\n            \"environment\": environment,\n            \"embedding_dimension\": dimension,\n            \"collection_vector_service_options\": vectorize_options,\n        }\n\n        # Add optional arguments if the reranker is set\n        if reranker:\n            # Split the reranker field into a provider a model name\n            provider, _ = reranker.split(\"/\")\n            base_args[\"collection_rerank\"] = CollectionRerankOptions(\n                service=RerankServiceOptions(provider=provider, model_name=reranker),\n            )\n            base_args[\"collection_lexical\"] = CollectionLexicalOptions(analyzer=\"STANDARD\")\n\n        _AstraDBCollectionEnvironment(**base_args)\n\n    @classmethod\n    def get_database_list_static(cls, token: str, environment: str | None = None):\n        client = DataAPIClient(environment=environment)\n\n        # Get the admin object\n        admin_client = client.get_admin(token=token)\n\n        # Get the list of databases\n        db_list = admin_client.list_databases()\n\n        # Generate the api endpoint for each database\n        db_info_dict = {}\n        for db in db_list:\n            try:\n                # Get the API endpoint for the database\n                api_endpoints = [db_reg.api_endpoint for db_reg in db.regions]\n\n                # Get the number of collections\n                try:\n                    # Get the number of collections in the database\n                    num_collections = len(\n                        client.get_database(\n                            api_endpoints[0],\n                            token=token,\n                        ).list_collection_names()\n                    )\n                except Exception:  # noqa: BLE001\n                    if db.status != \"PENDING\":\n                        continue\n                    num_collections = 0\n\n                # Add the database to the dictionary\n                db_info_dict[db.name] = {\n                    \"api_endpoints\": api_endpoints,\n                    \"keyspaces\": db.keyspaces,\n                    \"collections\": num_collections,\n                    \"status\": db.status if db.status != \"ACTIVE\" else None,\n                    \"org_id\": db.org_id if db.org_id else None,\n                }\n            except Exception:  # noqa: BLE001\n                pass\n\n        return db_info_dict\n\n    def get_database_list(self):\n        return self.get_database_list_static(\n            token=self.token,\n            environment=self.environment,\n        )\n\n    @classmethod\n    def get_api_endpoint_static(\n        cls,\n        token: str,\n        environment: str | None = None,\n        api_endpoint: str | None = None,\n        database_name: str | None = None,\n    ):\n        # If the api_endpoint is set, return it\n        if api_endpoint:\n            return api_endpoint\n\n        # Check if the database_name is like a url\n        if database_name and database_name.startswith(\"https://\"):\n            return database_name\n\n        # If the database is not set, nothing we can do.\n        if not database_name:\n            return None\n\n        # Grab the database object\n        db = cls.get_database_list_static(token=token, environment=environment).get(database_name)\n        if not db:\n            return None\n\n        # Otherwise, get the URL from the database list\n        endpoints = db.get(\"api_endpoints\") or []\n        return endpoints[0] if endpoints else None\n\n    def get_api_endpoint(self):\n        return self.get_api_endpoint_static(\n            token=self.token,\n            environment=self.environment,\n            api_endpoint=self.api_endpoint,\n            database_name=self.database_name,\n        )\n\n    @classmethod\n    def get_database_id_static(cls, api_endpoint: str) -> str | None:\n        # Pattern matches standard UUID format: 8-4-4-4-12 hexadecimal characters\n        uuid_pattern = r\"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n        match = re.search(uuid_pattern, api_endpoint)\n\n        return match.group(0) if match else None\n\n    def get_database_id(self):\n        return self.get_database_id_static(api_endpoint=self.get_api_endpoint())\n\n    def get_keyspace(self):\n        keyspace = self.keyspace\n\n        if keyspace:\n            return keyspace.strip()\n\n        return \"default_keyspace\"\n\n    def get_database_object(self, api_endpoint: str | None = None):\n        try:\n            client = DataAPIClient(environment=self.environment)\n\n            return client.get_database(\n                api_endpoint or self.get_api_endpoint(),\n                token=self.token,\n                keyspace=self.get_keyspace(),\n            )\n        except Exception as e:\n            msg = f\"Error fetching database object: {e}\"\n            raise ValueError(msg) from e\n\n    def collection_data(self, collection_name: str, database: Database | None = None):\n        try:\n            if not database:\n                client = DataAPIClient(environment=self.environment)\n\n                database = client.get_database(\n                    self.get_api_endpoint(),\n                    token=self.token,\n                    keyspace=self.get_keyspace(),\n                )\n\n            collection = database.get_collection(collection_name)\n\n            return collection.estimated_document_count()\n        except Exception as e:  # noqa: BLE001\n            self.log(f\"Error checking collection data: {e}\")\n\n            return None\n\n    def _initialize_database_options(self):\n        try:\n            return [\n                {\n                    \"name\": name,\n                    \"status\": info[\"status\"],\n                    \"collections\": info[\"collections\"],\n                    \"api_endpoints\": info[\"api_endpoints\"],\n                    \"keyspaces\": info[\"keyspaces\"],\n                    \"org_id\": info[\"org_id\"],\n                }\n                for name, info in self.get_database_list().items()\n            ]\n        except Exception as e:\n            msg = f\"Error fetching database options: {e}\"\n            raise ValueError(msg) from e\n\n    @classmethod\n    def get_provider_icon(cls, collection: CollectionDescriptor | None = None, provider_name: str | None = None) -> str:\n        # Get the provider name from the collection\n        provider_name = provider_name or (\n            collection.definition.vector.service.provider\n            if (\n                collection\n                and collection.definition\n                and collection.definition.vector\n                and collection.definition.vector.service\n            )\n            else None\n        )\n\n        # If there is no provider, use the vector store icon\n        if not provider_name or provider_name.lower() == \"bring your own\":\n            return \"vectorstores\"\n\n        # Map provider casings\n        case_map = {\n            \"nvidia\": \"NVIDIA\",\n            \"openai\": \"OpenAI\",\n            \"amazon bedrock\": \"AmazonBedrockEmbeddings\",\n            \"azure openai\": \"AzureOpenAiEmbeddings\",\n            \"cohere\": \"Cohere\",\n            \"jina ai\": \"JinaAI\",\n            \"mistral ai\": \"MistralAI\",\n            \"upstage\": \"Upstage\",\n            \"voyage ai\": \"VoyageAI\",\n        }\n\n        # Adjust the casing on some like nvidia\n        return case_map[provider_name.lower()] if provider_name.lower() in case_map else provider_name.title()\n\n    def _initialize_collection_options(self, api_endpoint: str | None = None):\n        # Nothing to generate if we don't have an API endpoint yet\n        api_endpoint = api_endpoint or self.get_api_endpoint()\n        if not api_endpoint:\n            return []\n\n        # Retrieve the database object\n        database = self.get_database_object(api_endpoint=api_endpoint)\n\n        # Get the list of collections\n        collection_list = database.list_collections(keyspace=self.get_keyspace())\n\n        # Return the list of collections and metadata associated\n        return [\n            {\n                \"name\": col.name,\n                \"records\": self.collection_data(collection_name=col.name, database=database),\n                \"provider\": (\n                    col.definition.vector.service.provider\n                    if col.definition.vector and col.definition.vector.service\n                    else None\n                ),\n                \"icon\": self.get_provider_icon(collection=col),\n                \"model\": (\n                    col.definition.vector.service.model_name\n                    if col.definition.vector and col.definition.vector.service\n                    else None\n                ),\n            }\n            for col in collection_list\n        ]\n\n    def reset_provider_options(self, build_config: dict) -> dict:\n        \"\"\"Reset provider options and related configurations in the build_config dictionary.\"\"\"\n        # Extract template path for cleaner access\n        template = build_config[\"collection_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"]\n\n        # Get vectorize providers\n        vectorize_providers_api = self.get_vectorize_providers(\n            token=self.token,\n            environment=self.environment,\n            api_endpoint=build_config[\"api_endpoint\"][\"value\"],\n        )\n\n        # Create a new dictionary with \"Bring your own\" first\n        vectorize_providers: dict[str, list[list[str]]] = {\"Bring your own\": [[], []]}\n\n        # Add the remaining items (only Nvidia) from the original dictionary\n        vectorize_providers.update(\n            {\n                k: v\n                for k, v in vectorize_providers_api.items()\n                if k.lower() in [\"nvidia\"]  # TODO: Eventually support more\n            }\n        )\n\n        # Set provider options\n        provider_field = \"02_embedding_generation_provider\"\n        template[provider_field][\"options\"] = list(vectorize_providers.keys())\n\n        # Add metadata for each provider option\n        template[provider_field][\"options_metadata\"] = [\n            {\"icon\": self.get_provider_icon(provider_name=provider)} for provider in template[provider_field][\"options\"]\n        ]\n\n        # Get selected embedding provider\n        embedding_provider = template[provider_field][\"value\"]\n        is_bring_your_own = embedding_provider and embedding_provider == \"Bring your own\"\n\n        # Configure embedding model field\n        model_field = \"03_embedding_generation_model\"\n        template[model_field].update(\n            {\n                \"options\": vectorize_providers.get(embedding_provider, [[], []])[1],\n                \"placeholder\": \"Bring your own\" if is_bring_your_own else None,\n                \"readonly\": is_bring_your_own,\n                \"required\": not is_bring_your_own,\n                \"value\": None,\n            }\n        )\n\n        # If this is a bring your own, set dimensions to 0\n        return self.reset_dimension_field(build_config)\n\n    def reset_dimension_field(self, build_config: dict) -> dict:\n        \"\"\"Reset dimension field options based on provided configuration.\"\"\"\n        # Extract template path for cleaner access\n        template = build_config[\"collection_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"]\n\n        # Get selected embedding model\n        provider_field = \"02_embedding_generation_provider\"\n        embedding_provider = template[provider_field][\"value\"]\n        is_bring_your_own = embedding_provider and embedding_provider == \"Bring your own\"\n\n        # Configure dimension field\n        dimension_field = \"04_dimension\"\n        dimension_value = 1024 if not is_bring_your_own else None  # TODO: Dynamically figure this out\n        template[dimension_field].update(\n            {\n                \"placeholder\": dimension_value,\n                \"value\": dimension_value,\n                \"readonly\": not is_bring_your_own,\n                \"required\": is_bring_your_own,\n            }\n        )\n\n        return build_config\n\n    def reset_collection_list(self, build_config: dict) -> dict:\n        \"\"\"Reset collection list options based on provided configuration.\"\"\"\n        # Get collection options\n        collection_options = self._initialize_collection_options(api_endpoint=build_config[\"api_endpoint\"][\"value\"])\n        # Update collection configuration\n        collection_config = build_config[\"collection_name\"]\n        collection_config.update(\n            {\n                \"options\": [col[\"name\"] for col in collection_options],\n                \"options_metadata\": [{k: v for k, v in col.items() if k != \"name\"} for col in collection_options],\n            }\n        )\n\n        # Reset selected collection if not in options\n        if collection_config[\"value\"] not in collection_config[\"options\"]:\n            collection_config[\"value\"] = \"\"\n\n        # Set advanced status based on database selection\n        collection_config[\"show\"] = bool(build_config[\"database_name\"][\"value\"])\n\n        return build_config\n\n    def reset_database_list(self, build_config: dict) -> dict:\n        \"\"\"Reset database list options and related configurations.\"\"\"\n        # Get database options\n        database_options = self._initialize_database_options()\n\n        # Update cloud provider options\n        env = self.environment\n        template = build_config[\"database_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"]\n        template[\"02_cloud_provider\"][\"options\"] = list(self.map_cloud_providers()[env].keys())\n\n        # Update database configuration\n        database_config = build_config[\"database_name\"]\n        database_config.update(\n            {\n                \"options\": [db[\"name\"] for db in database_options],\n                \"options_metadata\": [{k: v for k, v in db.items() if k != \"name\"} for db in database_options],\n            }\n        )\n\n        # Reset selections if value not in options\n        if database_config[\"value\"] not in database_config[\"options\"]:\n            database_config[\"value\"] = \"\"\n            build_config[\"api_endpoint\"][\"options\"] = []\n            build_config[\"api_endpoint\"][\"value\"] = \"\"\n            build_config[\"collection_name\"][\"show\"] = False\n\n        # Set advanced status based on token presence\n        database_config[\"show\"] = bool(build_config[\"token\"][\"value\"])\n\n        return build_config\n\n    def reset_build_config(self, build_config: dict) -> dict:\n        \"\"\"Reset all build configuration options to default empty state.\"\"\"\n        # Reset database configuration\n        database_config = build_config[\"database_name\"]\n        database_config.update({\"options\": [], \"options_metadata\": [], \"value\": \"\", \"show\": False})\n        build_config[\"api_endpoint\"][\"options\"] = []\n        build_config[\"api_endpoint\"][\"value\"] = \"\"\n\n        # Reset collection configuration\n        collection_config = build_config[\"collection_name\"]\n        collection_config.update({\"options\": [], \"options_metadata\": [], \"value\": \"\", \"show\": False})\n\n        return build_config\n\n    def _handle_hybrid_search_options(self, build_config: dict) -> dict:\n        \"\"\"Set hybrid search options in the build configuration.\"\"\"\n        # Detect what hybrid options are available\n        # Get the admin object\n        client = DataAPIClient(environment=self.environment)\n        admin_client = client.get_admin()\n        db_admin = admin_client.get_database_admin(self.get_api_endpoint(), token=self.token)\n\n        # We will try to get the reranking providers to see if its hybrid emabled\n        try:\n            providers = db_admin.find_reranking_providers()\n            build_config[\"reranker\"][\"options\"] = [\n                model.name for provider_data in providers.reranking_providers.values() for model in provider_data.models\n            ]\n            build_config[\"reranker\"][\"options_metadata\"] = [\n                {\"icon\": self.get_provider_icon(provider_name=model.name.split(\"/\")[0])}\n                for provider in providers.reranking_providers.values()\n                for model in provider.models\n            ]\n            build_config[\"reranker\"][\"value\"] = build_config[\"reranker\"][\"options\"][0]\n\n            # Set the default search field to hybrid search\n            build_config[\"search_method\"][\"show\"] = True\n            build_config[\"search_method\"][\"options\"] = [\"Hybrid Search\", \"Vector Search\"]\n            build_config[\"search_method\"][\"value\"] = \"Hybrid Search\"\n        except Exception as _:  # noqa: BLE001\n            build_config[\"reranker\"][\"options\"] = []\n            build_config[\"reranker\"][\"options_metadata\"] = []\n\n            # Set the default search field to vector search\n            build_config[\"search_method\"][\"show\"] = False\n            build_config[\"search_method\"][\"options\"] = [\"Vector Search\"]\n            build_config[\"search_method\"][\"value\"] = \"Vector Search\"\n\n        return build_config\n\n    async def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        \"\"\"Update build configuration based on field name and value.\"\"\"\n        # Early return if no token provided\n        if not self.token:\n            return self.reset_build_config(build_config)\n\n        # Database creation callback\n        if field_name == \"database_name\" and isinstance(field_value, dict):\n            if \"01_new_database_name\" in field_value:\n                await self._create_new_database(build_config, field_value)\n                return self.reset_collection_list(build_config)\n            return self._update_cloud_regions(build_config, field_value)\n\n        # Collection creation callback\n        if field_name == \"collection_name\" and isinstance(field_value, dict):\n            # Case 1: New collection creation\n            if \"01_new_collection_name\" in field_value:\n                await self._create_new_collection(build_config, field_value)\n                return build_config\n\n            # Case 2: Update embedding provider options\n            if \"02_embedding_generation_provider\" in field_value:\n                return self.reset_provider_options(build_config)\n\n            # Case 3: Update dimension field\n            if \"03_embedding_generation_model\" in field_value:\n                return self.reset_dimension_field(build_config)\n\n        # Initial execution or token/environment change\n        first_run = field_name == \"collection_name\" and not field_value and not build_config[\"database_name\"][\"options\"]\n        if first_run or field_name in {\"token\", \"environment\"}:\n            return self.reset_database_list(build_config)\n\n        # Database selection change\n        if field_name == \"database_name\" and not isinstance(field_value, dict):\n            return self._handle_database_selection(build_config, field_value)\n\n        # Keyspace selection change\n        if field_name == \"keyspace\":\n            return self.reset_collection_list(build_config)\n\n        # Collection selection change\n        if field_name == \"collection_name\" and not isinstance(field_value, dict):\n            return self._handle_collection_selection(build_config, field_value)\n\n        # Search method selection change\n        if field_name == \"search_method\":\n            is_vector_search = field_value == \"Vector Search\"\n            is_autodetect = build_config[\"autodetect_collection\"][\"value\"]\n\n            # Configure lexical terms (same for both cases)\n            build_config[\"lexical_terms\"][\"show\"] = not is_vector_search\n            build_config[\"lexical_terms\"][\"value\"] = \"\" if is_vector_search else build_config[\"lexical_terms\"][\"value\"]\n\n            # Disable reranker disabling if hybrid search is selected\n            build_config[\"reranker\"][\"show\"] = not is_vector_search\n            build_config[\"reranker\"][\"toggle_disable\"] = not is_vector_search\n            build_config[\"reranker\"][\"toggle_value\"] = True\n            build_config[\"reranker\"][\"value\"] = build_config[\"reranker\"][\"options\"][0]\n\n            # Toggle search type and score threshold based on search method\n            build_config[\"search_type\"][\"show\"] = is_vector_search\n            build_config[\"search_score_threshold\"][\"show\"] = is_vector_search\n\n            # Make sure the search_type is set to \"Similarity\"\n            if not is_vector_search or is_autodetect:\n                build_config[\"search_type\"][\"value\"] = \"Similarity\"\n\n        return build_config\n\n    async def _create_new_database(self, build_config: dict, field_value: dict) -> None:\n        \"\"\"Create a new database and update build config options.\"\"\"\n        try:\n            await self.create_database_api(\n                new_database_name=field_value[\"01_new_database_name\"],\n                token=self.token,\n                keyspace=self.get_keyspace(),\n                environment=self.environment,\n                cloud_provider=field_value[\"02_cloud_provider\"],\n                region=field_value[\"03_region\"],\n            )\n        except Exception as e:\n            msg = f\"Error creating database: {e}\"\n            raise ValueError(msg) from e\n\n        build_config[\"database_name\"][\"options\"].append(field_value[\"01_new_database_name\"])\n        build_config[\"database_name\"][\"options_metadata\"].append(\n            {\n                \"status\": \"PENDING\",\n                \"collections\": 0,\n                \"api_endpoints\": [],\n                \"keyspaces\": [self.get_keyspace()],\n                \"org_id\": None,\n            }\n        )\n\n    def _update_cloud_regions(self, build_config: dict, field_value: dict) -> dict:\n        \"\"\"Update cloud provider regions in build config.\"\"\"\n        env = self.environment\n        cloud_provider = field_value[\"02_cloud_provider\"]\n\n        # Update the region options based on the selected cloud provider\n        template = build_config[\"database_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"]\n        template[\"03_region\"][\"options\"] = self.map_cloud_providers()[env][cloud_provider][\"regions\"]\n\n        # Reset the the 03_region value if it's not in the new options\n        if template[\"03_region\"][\"value\"] not in template[\"03_region\"][\"options\"]:\n            template[\"03_region\"][\"value\"] = None\n\n        return build_config\n\n    async def _create_new_collection(self, build_config: dict, field_value: dict) -> None:\n        \"\"\"Create a new collection and update build config options.\"\"\"\n        embedding_provider = field_value.get(\"02_embedding_generation_provider\")\n        try:\n            await self.create_collection_api(\n                new_collection_name=field_value[\"01_new_collection_name\"],\n                token=self.token,\n                api_endpoint=build_config[\"api_endpoint\"][\"value\"],\n                environment=self.environment,\n                keyspace=self.get_keyspace(),\n                dimension=field_value.get(\"04_dimension\") if embedding_provider == \"Bring your own\" else None,\n                embedding_generation_provider=embedding_provider,\n                embedding_generation_model=field_value.get(\"03_embedding_generation_model\"),\n                reranker=self.reranker,\n            )\n        except Exception as e:\n            msg = f\"Error creating collection: {e}\"\n            raise ValueError(msg) from e\n\n        provider = embedding_provider.lower() if embedding_provider and embedding_provider != \"Bring your own\" else None\n        build_config[\"collection_name\"].update(\n            {\n                \"value\": field_value[\"01_new_collection_name\"],\n                \"options\": build_config[\"collection_name\"][\"options\"] + [field_value[\"01_new_collection_name\"]],\n            }\n        )\n        build_config[\"embedding_model\"][\"show\"] = not bool(provider)\n        build_config[\"embedding_model\"][\"required\"] = not bool(provider)\n        build_config[\"collection_name\"][\"options_metadata\"].append(\n            {\n                \"records\": 0,\n                \"provider\": provider,\n                \"icon\": self.get_provider_icon(provider_name=provider),\n                \"model\": field_value.get(\"03_embedding_generation_model\"),\n            }\n        )\n\n        # Make sure we always show the reranker options if the collection is hybrid enabled\n        # And right now they always are\n        build_config[\"lexical_terms\"][\"show\"] = True\n\n    def _handle_database_selection(self, build_config: dict, field_value: str) -> dict:\n        \"\"\"Handle database selection and update related configurations.\"\"\"\n        build_config = self.reset_database_list(build_config)\n\n        # Reset collection list if database selection changes\n        if field_value not in build_config[\"database_name\"][\"options\"]:\n            build_config[\"database_name\"][\"value\"] = \"\"\n            return build_config\n\n        # Get the api endpoint for the selected database\n        index = build_config[\"database_name\"][\"options\"].index(field_value)\n        build_config[\"api_endpoint\"][\"options\"] = build_config[\"database_name\"][\"options_metadata\"][index][\n            \"api_endpoints\"\n        ]\n        build_config[\"api_endpoint\"][\"value\"] = build_config[\"database_name\"][\"options_metadata\"][index][\n            \"api_endpoints\"\n        ][0]\n\n        # Get the org_id for the selected database\n        org_id = build_config[\"database_name\"][\"options_metadata\"][index][\"org_id\"]\n        if not org_id:\n            return build_config\n\n        # Update the list of keyspaces based on the db info\n        build_config[\"keyspace\"][\"options\"] = build_config[\"database_name\"][\"options_metadata\"][index][\"keyspaces\"]\n        build_config[\"keyspace\"][\"value\"] = (\n            build_config[\"keyspace\"][\"options\"] and build_config[\"keyspace\"][\"options\"][0]\n            if build_config[\"keyspace\"][\"value\"] not in build_config[\"keyspace\"][\"options\"]\n            else build_config[\"keyspace\"][\"value\"]\n        )\n\n        # Get the database id for the selected database\n        db_id = self.get_database_id_static(api_endpoint=build_config[\"api_endpoint\"][\"value\"])\n        keyspace = self.get_keyspace()\n\n        # Update the helper text for the embedding provider field\n        template = build_config[\"collection_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"]\n        template[\"02_embedding_generation_provider\"][\"helper_text\"] = (\n            \"To create collections with more embedding provider options, go to \"\n            f'<a class=\"underline\" target=\"_blank\" rel=\"noopener noreferrer\" '\n            f'href=\"https://astra.datastax.com/org/{org_id}/database/{db_id}/data-explorer?createCollection=1&namespace={keyspace}\">'\n            \"your database in Astra DB</a>.\"\n        )\n\n        # Reset provider options\n        build_config = self.reset_provider_options(build_config)\n\n        # Handle hybrid search options\n        build_config = self._handle_hybrid_search_options(build_config)\n\n        return self.reset_collection_list(build_config)\n\n    def _handle_collection_selection(self, build_config: dict, field_value: str) -> dict:\n        \"\"\"Handle collection selection and update embedding options.\"\"\"\n        build_config[\"autodetect_collection\"][\"value\"] = True\n        build_config = self.reset_collection_list(build_config)\n\n        # Reset embedding model if collection selection changes\n        if field_value and field_value not in build_config[\"collection_name\"][\"options\"]:\n            build_config[\"collection_name\"][\"options\"].append(field_value)\n            build_config[\"collection_name\"][\"options_metadata\"].append(\n                {\n                    \"records\": 0,\n                    \"provider\": None,\n                    \"icon\": \"vectorstores\",\n                    \"model\": None,\n                }\n            )\n            build_config[\"autodetect_collection\"][\"value\"] = False\n\n        if not field_value:\n            return build_config\n\n        # Get the selected collection index\n        index = build_config[\"collection_name\"][\"options\"].index(field_value)\n\n        # Set the provider of the selected collection\n        provider = build_config[\"collection_name\"][\"options_metadata\"][index][\"provider\"]\n        build_config[\"embedding_model\"][\"show\"] = not bool(provider)\n        build_config[\"embedding_model\"][\"required\"] = not bool(provider)\n\n        # Grab the collection object\n        database = self.get_database_object(api_endpoint=build_config[\"api_endpoint\"][\"value\"])\n        collection = database.get_collection(\n            name=field_value,\n            keyspace=build_config[\"keyspace\"][\"value\"],\n        )\n\n        # Check if hybrid and lexical are enabled\n        col_options = collection.options()\n        hyb_enabled = col_options.rerank and col_options.rerank.enabled\n        lex_enabled = col_options.lexical and col_options.lexical.enabled\n        user_hyb_enabled = build_config[\"search_method\"][\"value\"] == \"Hybrid Search\"\n\n        # Reranker visible when both the collection supports it and the user selected Hybrid\n        hybrid_active = bool(hyb_enabled and user_hyb_enabled)\n        build_config[\"reranker\"][\"show\"] = hybrid_active\n        build_config[\"reranker\"][\"toggle_value\"] = hybrid_active\n        build_config[\"reranker\"][\"toggle_disable\"] = False  # allow user to toggle if visible\n\n        # If hybrid is active, lock search_type to \"Similarity\"\n        if hybrid_active:\n            build_config[\"search_type\"][\"value\"] = \"Similarity\"\n\n        # Show the lexical terms option only if the collection enables lexical search\n        build_config[\"lexical_terms\"][\"show\"] = bool(lex_enabled)\n\n        return build_config\n\n    @check_cached_vector_store\n    def build_vector_store(self):\n        try:\n            from langchain_astradb import AstraDBVectorStore\n        except ImportError as e:\n            msg = (\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n            raise ImportError(msg) from e\n\n        # Get the embedding model and additional params\n        embedding_params = {\"embedding\": self.embedding_model} if self.embedding_model else {}\n\n        # Get the additional parameters\n        additional_params = self.astradb_vectorstore_kwargs or {}\n\n        # Get Langflow version and platform information\n        __version__ = get_version_info()[\"version\"]\n        langflow_prefix = \"\"\n        # if os.getenv(\"AWS_EXECUTION_ENV\") == \"AWS_ECS_FARGATE\":  # TODO: More precise way of detecting\n        #     langflow_prefix = \"ds-\"\n\n        # Get the database object\n        database = self.get_database_object()\n        autodetect = self.collection_name in database.list_collection_names() and self.autodetect_collection\n\n        # Bundle up the auto-detect parameters\n        autodetect_params = {\n            \"autodetect_collection\": autodetect,\n            \"content_field\": (\n                self.content_field\n                if self.content_field and embedding_params\n                else (\n                    \"page_content\"\n                    if embedding_params\n                    and self.collection_data(collection_name=self.collection_name, database=database) == 0\n                    else None\n                )\n            ),\n            \"ignore_invalid_documents\": self.ignore_invalid_documents,\n        }\n\n        # Choose HybridSearchMode based on the selected param\n        hybrid_search_mode = HybridSearchMode.DEFAULT if self.search_method == \"Hybrid Search\" else HybridSearchMode.OFF\n\n        # Attempt to build the Vector Store object\n        try:\n            vector_store = AstraDBVectorStore(\n                # Astra DB Authentication Parameters\n                token=self.token,\n                api_endpoint=database.api_endpoint,\n                namespace=database.keyspace,\n                collection_name=self.collection_name,\n                environment=self.environment,\n                # Hybrid Search Parameters\n                hybrid_search=hybrid_search_mode,\n                # Astra DB Usage Tracking Parameters\n                ext_callers=[(f\"{langflow_prefix}langflow\", __version__)],\n                # Astra DB Vector Store Parameters\n                **autodetect_params,\n                **embedding_params,\n                **additional_params,\n            )\n        except Exception as e:\n            msg = f\"Error initializing AstraDBVectorStore: {e}\"\n            raise ValueError(msg) from e\n\n        # Add documents to the vector store\n        self._add_documents_to_vector_store(vector_store)\n\n        return vector_store\n\n    def _add_documents_to_vector_store(self, vector_store) -> None:\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                msg = \"Vector Store Inputs must be Data objects.\"\n                raise TypeError(msg)\n\n        documents = [\n            Document(page_content=doc.page_content, metadata=serialize(doc.metadata, to_str=True)) for doc in documents\n        ]\n\n        if documents and self.deletion_field:\n            self.log(f\"Deleting documents where {self.deletion_field}\")\n            try:\n                database = self.get_database_object()\n                collection = database.get_collection(self.collection_name, keyspace=database.keyspace)\n                delete_values = list({doc.metadata[self.deletion_field] for doc in documents})\n                self.log(f\"Deleting documents where {self.deletion_field} matches {delete_values}.\")\n                collection.delete_many({f\"metadata.{self.deletion_field}\": {\"$in\": delete_values}})\n            except Exception as e:\n                msg = f\"Error deleting documents from AstraDBVectorStore based on '{self.deletion_field}': {e}\"\n                raise ValueError(msg) from e\n\n        if documents:\n            self.log(f\"Adding {len(documents)} documents to the Vector Store.\")\n            try:\n                vector_store.add_documents(documents)\n            except Exception as e:\n                msg = f\"Error adding documents to AstraDBVectorStore: {e}\"\n                raise ValueError(msg) from e\n        else:\n            self.log(\"No documents to add to the Vector Store.\")\n\n    def _map_search_type(self) -> str:\n        search_type_mapping = {\n            \"Similarity with score threshold\": \"similarity_score_threshold\",\n            \"MMR (Max Marginal Relevance)\": \"mmr\",\n        }\n\n        return search_type_mapping.get(self.search_type, \"similarity\")\n\n    def _build_search_args(self):\n        # Clean up the search query\n        query = self.search_query if isinstance(self.search_query, str) and self.search_query.strip() else None\n        lexical_terms = self.lexical_terms or None\n\n        # Check if we have a search query, and if so set the args\n        if query:\n            args = {\n                \"query\": query,\n                \"search_type\": self._map_search_type(),\n                \"k\": self.number_of_results,\n                \"score_threshold\": self.search_score_threshold,\n                \"lexical_query\": lexical_terms,\n            }\n        elif self.advanced_search_filter:\n            args = {\n                \"n\": self.number_of_results,\n            }\n        else:\n            return {}\n\n        filter_arg = self.advanced_search_filter or {}\n        if filter_arg:\n            args[\"filter\"] = filter_arg\n\n        return args\n\n    def search_documents(self, vector_store=None) -> list[Data]:\n        vector_store = vector_store or self.build_vector_store()\n\n        self.log(f\"Search input: {self.search_query}\")\n        self.log(f\"Search type: {self.search_type}\")\n        self.log(f\"Number of results: {self.number_of_results}\")\n        self.log(f\"store.hybrid_search: {vector_store.hybrid_search}\")\n        self.log(f\"Lexical terms: {self.lexical_terms}\")\n        self.log(f\"Reranker: {self.reranker}\")\n\n        try:\n            search_args = self._build_search_args()\n        except Exception as e:\n            msg = f\"Error in AstraDBVectorStore._build_search_args: {e}\"\n            raise ValueError(msg) from e\n\n        if not search_args:\n            self.log(\"No search input or filters provided. Skipping search.\")\n            return []\n\n        docs = []\n        search_method = \"search\" if \"query\" in search_args else \"metadata_search\"\n\n        try:\n            self.log(f\"Calling vector_store.{search_method} with args: {search_args}\")\n            docs = getattr(vector_store, search_method)(**search_args)\n        except Exception as e:\n            msg = f\"Error performing {search_method} in AstraDBVectorStore: {e}\"\n            raise ValueError(msg) from e\n\n        self.log(f\"Retrieved documents: {len(docs)}\")\n\n        data = docs_to_data(docs)\n        self.log(f\"Converted documents to data: {len(data)}\")\n        self.status = data\n\n        return data\n\n    def get_retriever_kwargs(self):\n        search_args = self._build_search_args()\n\n        return {\n            \"search_type\": self._map_search_type(),\n            \"search_kwargs\": search_args,\n        }\n"},"collection_name":{"_input_type":"DropdownInput","advanced":false,"combobox":true,"dialog_inputs":{"fields":{"data":{"node":{"description":"Please allow several seconds for creation to complete.","display_name":"Create new collection","field_order":["01_new_collection_name","02_embedding_generation_provider","03_embedding_generation_model","04_dimension"],"name":"create_collection","template":{"01_new_collection_name":{"_input_type":"StrInput","advanced":false,"display_name":"Name","dynamic":false,"info":"Name of the new collection to create in Astra DB.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"new_collection_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"02_embedding_generation_provider":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Embedding generation method","dynamic":false,"external_options":{},"helper_text":"To create collections with more embedding provider options, go to <a class=\"underline\" href=\"https://astra.datastax.com/\" target=\" _blank\" rel=\"noopener noreferrer\">your database in Astra DB</a>","info":"Provider to use for generating embeddings.","name":"embedding_generation_provider","options":[],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"03_embedding_generation_model":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Embedding model","dynamic":false,"external_options":{},"info":"Model to use for generating embeddings.","name":"embedding_generation_model","options":[],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"04_dimension":{"_input_type":"IntInput","advanced":false,"display_name":"Dimensions","dynamic":false,"info":"Dimensions of the embeddings to generate.","list":false,"list_add_label":"Add More","name":"dimension","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int"}}}}},"functionality":"create"},"display_name":"Collection","dynamic":false,"external_options":{},"info":"The name of the collection within Astra DB where the vectors will be stored.","name":"collection_name","options":[],"options_metadata":[],"placeholder":"","real_time_refresh":true,"refresh_button":true,"required":true,"show":false,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"content_field":{"_input_type":"StrInput","advanced":true,"display_name":"Content Field","dynamic":false,"info":"Field to use as the text content field for the vector store.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"content_field","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"database_name":{"_input_type":"DropdownInput","advanced":false,"combobox":true,"dialog_inputs":{"fields":{"data":{"node":{"description":"Please allow several minutes for creation to complete.","display_name":"Create new database","field_order":["01_new_database_name","02_cloud_provider","03_region"],"name":"create_database","template":{"01_new_database_name":{"_input_type":"StrInput","advanced":false,"display_name":"Name","dynamic":false,"info":"Name of the new database to create in Astra DB.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"new_database_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"02_cloud_provider":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Cloud provider","dynamic":false,"external_options":{},"info":"Cloud provider for the new database.","name":"cloud_provider","options":[],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"03_region":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Region","dynamic":false,"external_options":{},"info":"Region for the new database.","name":"region","options":[],"options_metadata":[],"placeholder":"","required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}}}}},"functionality":"create"},"display_name":"Database","dynamic":false,"external_options":{},"info":"The Database name for the Astra DB instance.","name":"database_name","options":[],"options_metadata":[],"placeholder":"","real_time_refresh":true,"refresh_button":true,"required":true,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"deletion_field":{"_input_type":"StrInput","advanced":true,"display_name":"Deletion Based On Field","dynamic":false,"info":"When this parameter is provided, documents in the target collection with metadata field values matching the input metadata field value will be deleted before new data is loaded.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"deletion_field","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"embedding_model":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding Model","dynamic":false,"info":"Specify the Embedding Model. Not required for Astra Vectorize collections.","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding_model","placeholder":"","required":false,"show":false,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"environment":{"_input_type":"DropdownInput","advanced":true,"combobox":true,"dialog_inputs":{},"display_name":"Environment","dynamic":false,"external_options":{},"info":"The environment for the Astra DB API Endpoint.","name":"environment","options":["prod","test","dev"],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"prod"},"ignore_invalid_documents":{"_input_type":"BoolInput","advanced":true,"display_name":"Ignore Invalid Documents","dynamic":false,"info":"Boolean flag to determine whether to ignore invalid documents at runtime.","list":false,"list_add_label":"Add More","name":"ignore_invalid_documents","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"keyspace":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Keyspace","dynamic":false,"external_options":{},"info":"Optional keyspace within Astra DB to use for the collection.","name":"keyspace","options":[],"options_metadata":[],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"lexical_terms":{"_input_type":"QueryInput","advanced":false,"display_name":"Lexical Terms","dynamic":false,"info":"Add additional terms/keywords to augment search precision.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"lexical_terms","placeholder":"Enter terms to search...","required":false,"separator":" ","show":false,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Search Results","dynamic":false,"info":"Number of search results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"reranker":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Reranker","dynamic":false,"external_options":{},"info":"Post-retrieval model that re-scores results for optimal relevance ranking.","name":"reranker","options":[],"options_metadata":[],"placeholder":"","required":false,"show":false,"title_case":false,"toggle":true,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"search_method":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Search Method","dynamic":false,"external_options":{},"info":"Determine how your content is matched: Vector finds semantic similarity, and Hybrid Search (suggested) combines both approaches with a reranker.","name":"search_method","options":["Hybrid Search","Vector Search"],"options_metadata":[{"icon":"SearchHybrid"},{"icon":"SearchVector"}],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Vector Search"},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"search_score_threshold":{"_input_type":"FloatInput","advanced":true,"display_name":"Search Score Threshold","dynamic":false,"info":"Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')","list":false,"list_add_label":"Add More","name":"search_score_threshold","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.0},"search_type":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Search Type","dynamic":false,"external_options":{},"info":"Search type to use","name":"search_type","options":["Similarity","Similarity with score threshold","MMR (Max Marginal Relevance)"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Similarity"},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Astra DB Application Token","dynamic":false,"info":"Authentication token for accessing Astra DB.","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","real_time_refresh":true,"required":true,"show":true,"title_case":false,"type":"str","value":"ASTRA_DB_APPLICATION_TOKEN"}},"tool_mode":false},"AstraDBGraph":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Implementation of Graph Vector Store using Astra DB","display_name":"Astra DB Graph","documentation":"","edited":false,"field_order":["token","api_endpoint","collection_name","metadata_incoming_links_key","ingest_data","search_query","should_cache_vector_store","keyspace","embedding_model","metric","batch_size","bulk_insert_batch_concurrency","bulk_insert_overwrite_concurrency","bulk_delete_concurrency","setup_mode","pre_delete_collection","metadata_indexing_include","metadata_indexing_exclude","collection_indexing_policy","number_of_results","search_type","search_score_threshold","search_filter"],"frozen":false,"icon":"AstraDB","legacy":false,"metadata":{"code_hash":"f475279e342a","dependencies":{"dependencies":[{"name":"orjson","version":"3.10.15"},{"name":"langchain_core","version":"0.3.79"},{"name":"lfx","version":null},{"name":"astrapy","version":"2.1.0"},{"name":"langchain_astradb","version":"0.6.1"}],"total_dependencies":5},"module":"lfx.components.vectorstores.astradb_graph.AstraDBGraphVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_endpoint":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Endpoint","dynamic":false,"info":"API endpoint URL for the Astra DB service.","input_types":[],"load_from_db":true,"name":"api_endpoint","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"ASTRA_DB_API_ENDPOINT"},"batch_size":{"_input_type":"IntInput","advanced":true,"display_name":"Batch Size","dynamic":false,"info":"Optional number of data to process in a single batch.","list":false,"list_add_label":"Add More","name":"batch_size","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"bulk_delete_concurrency":{"_input_type":"IntInput","advanced":true,"display_name":"Bulk Delete Concurrency","dynamic":false,"info":"Optional concurrency level for bulk delete operations.","list":false,"list_add_label":"Add More","name":"bulk_delete_concurrency","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"bulk_insert_batch_concurrency":{"_input_type":"IntInput","advanced":true,"display_name":"Bulk Insert Batch Concurrency","dynamic":false,"info":"Optional concurrency level for bulk insert operations.","list":false,"list_add_label":"Add More","name":"bulk_insert_batch_concurrency","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"bulk_insert_overwrite_concurrency":{"_input_type":"IntInput","advanced":true,"display_name":"Bulk Insert Overwrite Concurrency","dynamic":false,"info":"Optional concurrency level for bulk insert operations that overwrite existing data.","list":false,"list_add_label":"Add More","name":"bulk_insert_overwrite_concurrency","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import os\n\nimport orjson\nfrom langchain_core.documents import Document\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.inputs.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    HandleInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom lfx.schema.data import Data\nfrom lfx.serialization import serialize\n\n\nclass AstraDBGraphVectorStoreComponent(LCVectorStoreComponent):\n    display_name: str = \"Astra DB Graph\"\n    description: str = \"Implementation of Graph Vector Store using Astra DB\"\n    name = \"AstraDBGraph\"\n    icon: str = \"AstraDB\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n            required=True,\n            advanced=os.getenv(\"ASTRA_ENHANCED\", \"false\").lower() == \"true\",\n        ),\n        SecretStrInput(\n            name=\"api_endpoint\",\n            display_name=\"Database\" if os.getenv(\"ASTRA_ENHANCED\", \"false\").lower() == \"true\" else \"API Endpoint\",\n            info=\"API endpoint URL for the Astra DB service.\",\n            value=\"ASTRA_DB_API_ENDPOINT\",\n            required=True,\n        ),\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            info=\"The name of the collection within Astra DB where the vectors will be stored.\",\n            required=True,\n        ),\n        StrInput(\n            name=\"metadata_incoming_links_key\",\n            display_name=\"Metadata incoming links key\",\n            info=\"Metadata key used for incoming links.\",\n            advanced=True,\n        ),\n        *LCVectorStoreComponent.inputs,\n        StrInput(\n            name=\"keyspace\",\n            display_name=\"Keyspace\",\n            info=\"Optional keyspace within Astra DB to use for the collection.\",\n            advanced=True,\n        ),\n        HandleInput(\n            name=\"embedding_model\",\n            display_name=\"Embedding Model\",\n            input_types=[\"Embeddings\"],\n            info=\"Allows an embedding model configuration.\",\n        ),\n        DropdownInput(\n            name=\"metric\",\n            display_name=\"Metric\",\n            info=\"Optional distance metric for vector comparisons in the vector store.\",\n            options=[\"cosine\", \"dot_product\", \"euclidean\"],\n            value=\"cosine\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"batch_size\",\n            display_name=\"Batch Size\",\n            info=\"Optional number of data to process in a single batch.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_batch_concurrency\",\n            display_name=\"Bulk Insert Batch Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_overwrite_concurrency\",\n            display_name=\"Bulk Insert Overwrite Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations that overwrite existing data.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_delete_concurrency\",\n            display_name=\"Bulk Delete Concurrency\",\n            info=\"Optional concurrency level for bulk delete operations.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"setup_mode\",\n            display_name=\"Setup Mode\",\n            info=\"Configuration mode for setting up the vector store, with options like 'Sync', or 'Off'.\",\n            options=[\"Sync\", \"Off\"],\n            advanced=True,\n            value=\"Sync\",\n        ),\n        BoolInput(\n            name=\"pre_delete_collection\",\n            display_name=\"Pre Delete Collection\",\n            info=\"Boolean flag to determine whether to delete the collection before creating a new one.\",\n            advanced=True,\n            value=False,\n        ),\n        StrInput(\n            name=\"metadata_indexing_include\",\n            display_name=\"Metadata Indexing Include\",\n            info=\"Optional list of metadata fields to include in the indexing.\",\n            advanced=True,\n            list=True,\n        ),\n        StrInput(\n            name=\"metadata_indexing_exclude\",\n            display_name=\"Metadata Indexing Exclude\",\n            info=\"Optional list of metadata fields to exclude from the indexing.\",\n            advanced=True,\n            list=True,\n        ),\n        StrInput(\n            name=\"collection_indexing_policy\",\n            display_name=\"Collection Indexing Policy\",\n            info='Optional JSON string for the \"indexing\" field of the collection. '\n            \"See https://docs.datastax.com/en/astra-db-serverless/api-reference/collections.html#the-indexing-option\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            info=\"Search type to use\",\n            options=[\n                \"Similarity\",\n                \"Similarity with score threshold\",\n                \"MMR (Max Marginal Relevance)\",\n                \"Graph Traversal\",\n                \"MMR (Max Marginal Relevance) Graph Traversal\",\n            ],\n            value=\"MMR (Max Marginal Relevance) Graph Traversal\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results. \"\n            \"(when using 'Similarity with score threshold')\",\n            value=0,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"search_filter\",\n            display_name=\"Search Metadata Filter\",\n            info=\"Optional dictionary of filters to apply to the search query.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self):\n        try:\n            from astrapy.admin import parse_api_endpoint\n            from langchain_astradb import AstraDBGraphVectorStore\n            from langchain_astradb.utils.astradb import SetupMode\n        except ImportError as e:\n            msg = (\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n            raise ImportError(msg) from e\n\n        try:\n            if not self.setup_mode:\n                self.setup_mode = self._inputs[\"setup_mode\"].options[0]\n\n            setup_mode_value = SetupMode[self.setup_mode.upper()]\n        except KeyError as e:\n            msg = f\"Invalid setup mode: {self.setup_mode}\"\n            raise ValueError(msg) from e\n\n        try:\n            self.log(f\"Initializing Graph Vector Store {self.collection_name}\")\n\n            vector_store = AstraDBGraphVectorStore(\n                embedding=self.embedding_model,\n                collection_name=self.collection_name,\n                metadata_incoming_links_key=self.metadata_incoming_links_key or \"incoming_links\",\n                token=self.token,\n                api_endpoint=self.api_endpoint,\n                namespace=self.keyspace or None,\n                environment=parse_api_endpoint(self.api_endpoint).environment if self.api_endpoint else None,\n                metric=self.metric or None,\n                batch_size=self.batch_size or None,\n                bulk_insert_batch_concurrency=self.bulk_insert_batch_concurrency or None,\n                bulk_insert_overwrite_concurrency=self.bulk_insert_overwrite_concurrency or None,\n                bulk_delete_concurrency=self.bulk_delete_concurrency or None,\n                setup_mode=setup_mode_value,\n                pre_delete_collection=self.pre_delete_collection,\n                metadata_indexing_include=[s for s in self.metadata_indexing_include if s] or None,\n                metadata_indexing_exclude=[s for s in self.metadata_indexing_exclude if s] or None,\n                collection_indexing_policy=orjson.loads(self.collection_indexing_policy.encode(\"utf-8\"))\n                if self.collection_indexing_policy\n                else None,\n            )\n        except Exception as e:\n            msg = f\"Error initializing AstraDBGraphVectorStore: {e}\"\n            raise ValueError(msg) from e\n\n        self.log(f\"Vector Store initialized: {vector_store.astra_env.collection_name}\")\n        self._add_documents_to_vector_store(vector_store)\n\n        return vector_store\n\n    def _add_documents_to_vector_store(self, vector_store) -> None:\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                msg = \"Vector Store Inputs must be Data objects.\"\n                raise TypeError(msg)\n\n        # Serialize metadata to handle Properties objects and other non-JSON serializable types\n        documents = [\n            Document(page_content=doc.page_content, metadata=serialize(doc.metadata, to_str=True)) for doc in documents\n        ]\n\n        if documents:\n            self.log(f\"Adding {len(documents)} documents to the Vector Store.\")\n            try:\n                vector_store.add_documents(documents)\n            except Exception as e:\n                msg = f\"Error adding documents to AstraDBGraphVectorStore: {e}\"\n                raise ValueError(msg) from e\n        else:\n            self.log(\"No documents to add to the Vector Store.\")\n\n    def _map_search_type(self) -> str:\n        match self.search_type:\n            case \"Similarity\":\n                return \"similarity\"\n            case \"Similarity with score threshold\":\n                return \"similarity_score_threshold\"\n            case \"MMR (Max Marginal Relevance)\":\n                return \"mmr\"\n            case \"Graph Traversal\":\n                return \"traversal\"\n            case \"MMR (Max Marginal Relevance) Graph Traversal\":\n                return \"mmr_traversal\"\n            case _:\n                return \"similarity\"\n\n    def _build_search_args(self):\n        args = {\n            \"k\": self.number_of_results,\n            \"score_threshold\": self.search_score_threshold,\n        }\n\n        if self.search_filter:\n            clean_filter = {k: v for k, v in self.search_filter.items() if k and v}\n            if len(clean_filter) > 0:\n                args[\"filter\"] = clean_filter\n        return args\n\n    def search_documents(self, vector_store=None) -> list[Data]:\n        if not vector_store:\n            vector_store = self.build_vector_store()\n\n        self.log(\"Searching for documents in AstraDBGraphVectorStore.\")\n        self.log(f\"Search query: {self.search_query}\")\n        self.log(f\"Search type: {self.search_type}\")\n        self.log(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            try:\n                search_type = self._map_search_type()\n                search_args = self._build_search_args()\n\n                docs = vector_store.search(query=self.search_query, search_type=search_type, **search_args)\n\n                # Drop links from the metadata. At this point the links don't add any value for building the\n                # context and haven't been restored to json which causes the conversion to fail.\n                self.log(\"Removing links from metadata.\")\n                for doc in docs:\n                    if \"links\" in doc.metadata:\n                        doc.metadata.pop(\"links\")\n\n            except Exception as e:\n                msg = f\"Error performing search in AstraDBGraphVectorStore: {e}\"\n                raise ValueError(msg) from e\n\n            self.log(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n\n            self.log(f\"Converted documents to data: {len(data)}\")\n\n            self.status = data\n            return data\n        self.log(\"No search input provided. Skipping search.\")\n        return []\n\n    def get_retriever_kwargs(self):\n        search_args = self._build_search_args()\n        return {\n            \"search_type\": self._map_search_type(),\n            \"search_kwargs\": search_args,\n        }\n"},"collection_indexing_policy":{"_input_type":"StrInput","advanced":true,"display_name":"Collection Indexing Policy","dynamic":false,"info":"Optional JSON string for the \"indexing\" field of the collection. See https://docs.datastax.com/en/astra-db-serverless/api-reference/collections.html#the-indexing-option","list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_indexing_policy","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"collection_name":{"_input_type":"StrInput","advanced":false,"display_name":"Collection Name","dynamic":false,"info":"The name of the collection within Astra DB where the vectors will be stored.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"embedding_model":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding Model","dynamic":false,"info":"Allows an embedding model configuration.","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding_model","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"keyspace":{"_input_type":"StrInput","advanced":true,"display_name":"Keyspace","dynamic":false,"info":"Optional keyspace within Astra DB to use for the collection.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"keyspace","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"metadata_incoming_links_key":{"_input_type":"StrInput","advanced":true,"display_name":"Metadata incoming links key","dynamic":false,"info":"Metadata key used for incoming links.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"metadata_incoming_links_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"metadata_indexing_exclude":{"_input_type":"StrInput","advanced":true,"display_name":"Metadata Indexing Exclude","dynamic":false,"info":"Optional list of metadata fields to exclude from the indexing.","list":true,"list_add_label":"Add More","load_from_db":false,"name":"metadata_indexing_exclude","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"metadata_indexing_include":{"_input_type":"StrInput","advanced":true,"display_name":"Metadata Indexing Include","dynamic":false,"info":"Optional list of metadata fields to include in the indexing.","list":true,"list_add_label":"Add More","load_from_db":false,"name":"metadata_indexing_include","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"metric":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Metric","dynamic":false,"external_options":{},"info":"Optional distance metric for vector comparisons in the vector store.","name":"metric","options":["cosine","dot_product","euclidean"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"cosine"},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"pre_delete_collection":{"_input_type":"BoolInput","advanced":true,"display_name":"Pre Delete Collection","dynamic":false,"info":"Boolean flag to determine whether to delete the collection before creating a new one.","list":false,"list_add_label":"Add More","name":"pre_delete_collection","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"search_filter":{"_input_type":"DictInput","advanced":true,"display_name":"Search Metadata Filter","dynamic":false,"info":"Optional dictionary of filters to apply to the search query.","list":true,"list_add_label":"Add More","name":"search_filter","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"search_score_threshold":{"_input_type":"FloatInput","advanced":true,"display_name":"Search Score Threshold","dynamic":false,"info":"Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')","list":false,"list_add_label":"Add More","name":"search_score_threshold","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.0},"search_type":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Search Type","dynamic":false,"external_options":{},"info":"Search type to use","name":"search_type","options":["Similarity","Similarity with score threshold","MMR (Max Marginal Relevance)","Graph Traversal","MMR (Max Marginal Relevance) Graph Traversal"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"MMR (Max Marginal Relevance) Graph Traversal"},"setup_mode":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Setup Mode","dynamic":false,"external_options":{},"info":"Configuration mode for setting up the vector store, with options like 'Sync', or 'Off'.","name":"setup_mode","options":["Sync","Off"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Sync"},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Astra DB Application Token","dynamic":false,"info":"Authentication token for accessing Astra DB.","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"ASTRA_DB_APPLICATION_TOKEN"}},"tool_mode":false},"Cassandra":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Cassandra Vector Store with search capabilities","display_name":"Cassandra","documentation":"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/cassandra","edited":false,"field_order":["database_ref","username","token","keyspace","table_name","ttl_seconds","batch_size","setup_mode","cluster_kwargs","ingest_data","search_query","should_cache_vector_store","embedding","number_of_results","search_type","search_score_threshold","search_filter","body_search","enable_body_search"],"frozen":false,"icon":"Cassandra","legacy":false,"metadata":{"code_hash":"833f277daab7","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null},{"name":"cassio","version":null}],"total_dependencies":3},"module":"lfx.components.vectorstores.cassandra.CassandraVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","batch_size":{"_input_type":"IntInput","advanced":true,"display_name":"Batch Size","dynamic":false,"info":"Optional number of data to process in a single batch.","list":false,"list_add_label":"Add More","name":"batch_size","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":16},"body_search":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Search Body","dynamic":false,"info":"Document textual search terms to apply to the search query.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"body_search","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"cluster_kwargs":{"_input_type":"DictInput","advanced":true,"display_name":"Cluster arguments","dynamic":false,"info":"Optional dictionary of additional keyword arguments for the Cassandra cluster.","list":true,"list_add_label":"Add More","name":"cluster_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_community.vectorstores import Cassandra\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.inputs.inputs import BoolInput, DictInput, FloatInput\nfrom lfx.io import (\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    MessageTextInput,\n    SecretStrInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass CassandraVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Cassandra\"\n    description = \"Cassandra Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/cassandra\"\n    name = \"Cassandra\"\n    icon = \"Cassandra\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"database_ref\",\n            display_name=\"Contact Points / Astra Database ID\",\n            info=\"Contact points for the database (or Astra DB database ID)\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"username\", display_name=\"Username\", info=\"Username for the database (leave empty for Astra DB).\"\n        ),\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Password / Astra DB Token\",\n            info=\"User password for the database (or Astra DB token).\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"keyspace\",\n            display_name=\"Keyspace\",\n            info=\"Table Keyspace (or Astra DB namespace).\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"table_name\",\n            display_name=\"Table Name\",\n            info=\"The name of the table (or Astra DB collection) where vectors will be stored.\",\n            required=True,\n        ),\n        IntInput(\n            name=\"ttl_seconds\",\n            display_name=\"TTL Seconds\",\n            info=\"Optional time-to-live for the added texts.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"batch_size\",\n            display_name=\"Batch Size\",\n            info=\"Optional number of data to process in a single batch.\",\n            value=16,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"setup_mode\",\n            display_name=\"Setup Mode\",\n            info=\"Configuration mode for setting up the Cassandra table, with options like 'Sync', 'Async', or 'Off'.\",\n            options=[\"Sync\", \"Async\", \"Off\"],\n            value=\"Sync\",\n            advanced=True,\n        ),\n        DictInput(\n            name=\"cluster_kwargs\",\n            display_name=\"Cluster arguments\",\n            info=\"Optional dictionary of additional keyword arguments for the Cassandra cluster.\",\n            advanced=True,\n            list=True,\n        ),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            info=\"Search type to use\",\n            options=[\"Similarity\", \"Similarity with score threshold\", \"MMR (Max Marginal Relevance)\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results. \"\n            \"(when using 'Similarity with score threshold')\",\n            value=0,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"search_filter\",\n            display_name=\"Search Metadata Filter\",\n            info=\"Optional dictionary of filters to apply to the search query.\",\n            advanced=True,\n            list=True,\n        ),\n        MessageTextInput(\n            name=\"body_search\",\n            display_name=\"Search Body\",\n            info=\"Document textual search terms to apply to the search query.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"enable_body_search\",\n            display_name=\"Enable Body Search\",\n            info=\"Flag to enable body search. This must be enabled BEFORE the table is created.\",\n            value=False,\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> Cassandra:\n        try:\n            import cassio\n            from langchain_community.utilities.cassandra import SetupMode\n        except ImportError as e:\n            msg = \"Could not import cassio integration package. Please install it with `pip install cassio`.\"\n            raise ImportError(msg) from e\n\n        from uuid import UUID\n\n        database_ref = self.database_ref\n\n        try:\n            UUID(self.database_ref)\n            is_astra = True\n        except ValueError:\n            is_astra = False\n            if \",\" in self.database_ref:\n                # use a copy because we can't change the type of the parameter\n                database_ref = self.database_ref.split(\",\")\n\n        if is_astra:\n            cassio.init(\n                database_id=database_ref,\n                token=self.token,\n                cluster_kwargs=self.cluster_kwargs,\n            )\n        else:\n            cassio.init(\n                contact_points=database_ref,\n                username=self.username,\n                password=self.token,\n                cluster_kwargs=self.cluster_kwargs,\n            )\n\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        body_index_options = [(\"index_analyzer\", \"STANDARD\")] if self.enable_body_search else None\n\n        if self.setup_mode == \"Off\":\n            setup_mode = SetupMode.OFF\n        elif self.setup_mode == \"Sync\":\n            setup_mode = SetupMode.SYNC\n        else:\n            setup_mode = SetupMode.ASYNC\n\n        if documents:\n            self.log(f\"Adding {len(documents)} documents to the Vector Store.\")\n            table = Cassandra.from_documents(\n                documents=documents,\n                embedding=self.embedding,\n                table_name=self.table_name,\n                keyspace=self.keyspace,\n                ttl_seconds=self.ttl_seconds or None,\n                batch_size=self.batch_size,\n                body_index_options=body_index_options,\n            )\n        else:\n            self.log(\"No documents to add to the Vector Store.\")\n            table = Cassandra(\n                embedding=self.embedding,\n                table_name=self.table_name,\n                keyspace=self.keyspace,\n                ttl_seconds=self.ttl_seconds or None,\n                body_index_options=body_index_options,\n                setup_mode=setup_mode,\n            )\n        return table\n\n    def _map_search_type(self) -> str:\n        if self.search_type == \"Similarity with score threshold\":\n            return \"similarity_score_threshold\"\n        if self.search_type == \"MMR (Max Marginal Relevance)\":\n            return \"mmr\"\n        return \"similarity\"\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        self.log(f\"Search input: {self.search_query}\")\n        self.log(f\"Search type: {self.search_type}\")\n        self.log(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            try:\n                search_type = self._map_search_type()\n                search_args = self._build_search_args()\n\n                self.log(f\"Search args: {search_args}\")\n\n                docs = vector_store.search(query=self.search_query, search_type=search_type, **search_args)\n            except KeyError as e:\n                if \"content\" in str(e):\n                    msg = (\n                        \"You should ingest data through Langflow (or LangChain) to query it in Langflow. \"\n                        \"Your collection does not contain a field name 'content'.\"\n                    )\n                    raise ValueError(msg) from e\n                raise\n\n            self.log(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n\n    def _build_search_args(self):\n        args = {\n            \"k\": self.number_of_results,\n            \"score_threshold\": self.search_score_threshold,\n        }\n\n        if self.search_filter:\n            clean_filter = {k: v for k, v in self.search_filter.items() if k and v}\n            if len(clean_filter) > 0:\n                args[\"filter\"] = clean_filter\n        if self.body_search:\n            if not self.enable_body_search:\n                msg = \"You should enable body search when creating the table to search the body field.\"\n                raise ValueError(msg)\n            args[\"body_search\"] = self.body_search\n        return args\n\n    def get_retriever_kwargs(self):\n        search_args = self._build_search_args()\n        return {\n            \"search_type\": self._map_search_type(),\n            \"search_kwargs\": search_args,\n        }\n"},"database_ref":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Contact Points / Astra Database ID","dynamic":false,"info":"Contact points for the database (or Astra DB database ID)","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"database_ref","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"enable_body_search":{"_input_type":"BoolInput","advanced":true,"display_name":"Enable Body Search","dynamic":false,"info":"Flag to enable body search. This must be enabled BEFORE the table is created.","list":false,"list_add_label":"Add More","name":"enable_body_search","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"keyspace":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Keyspace","dynamic":false,"info":"Table Keyspace (or Astra DB namespace).","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"keyspace","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"search_filter":{"_input_type":"DictInput","advanced":true,"display_name":"Search Metadata Filter","dynamic":false,"info":"Optional dictionary of filters to apply to the search query.","list":true,"list_add_label":"Add More","name":"search_filter","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"search_score_threshold":{"_input_type":"FloatInput","advanced":true,"display_name":"Search Score Threshold","dynamic":false,"info":"Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')","list":false,"list_add_label":"Add More","name":"search_score_threshold","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.0},"search_type":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Search Type","dynamic":false,"external_options":{},"info":"Search type to use","name":"search_type","options":["Similarity","Similarity with score threshold","MMR (Max Marginal Relevance)"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Similarity"},"setup_mode":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Setup Mode","dynamic":false,"external_options":{},"info":"Configuration mode for setting up the Cassandra table, with options like 'Sync', 'Async', or 'Off'.","name":"setup_mode","options":["Sync","Async","Off"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Sync"},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"table_name":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Table Name","dynamic":false,"info":"The name of the table (or Astra DB collection) where vectors will be stored.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"table_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password / Astra DB Token","dynamic":false,"info":"User password for the database (or Astra DB token).","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"ttl_seconds":{"_input_type":"IntInput","advanced":true,"display_name":"TTL Seconds","dynamic":false,"info":"Optional time-to-live for the added texts.","list":false,"list_add_label":"Add More","name":"ttl_seconds","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"username":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Username","dynamic":false,"info":"Username for the database (leave empty for Astra DB).","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"CassandraGraph":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Cassandra Graph Vector Store","display_name":"Cassandra Graph","documentation":"","edited":false,"field_order":["database_ref","username","token","keyspace","table_name","setup_mode","cluster_kwargs","ingest_data","search_query","should_cache_vector_store","embedding","number_of_results","search_type","depth","search_score_threshold","search_filter"],"frozen":false,"icon":"Cassandra","legacy":false,"metadata":{"code_hash":"26c63f80745e","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null},{"name":"cassio","version":null}],"total_dependencies":3},"module":"lfx.components.vectorstores.cassandra_graph.CassandraGraphVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","cluster_kwargs":{"_input_type":"DictInput","advanced":true,"display_name":"Cluster arguments","dynamic":false,"info":"Optional dictionary of additional keyword arguments for the Cassandra cluster.","list":true,"list_add_label":"Add More","name":"cluster_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from uuid import UUID\n\nfrom langchain_community.graph_vectorstores import CassandraGraphVectorStore\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.inputs.inputs import DictInput, FloatInput\nfrom lfx.io import (\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    MessageTextInput,\n    SecretStrInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass CassandraGraphVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Cassandra Graph\"\n    description = \"Cassandra Graph Vector Store\"\n    name = \"CassandraGraph\"\n    icon = \"Cassandra\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"database_ref\",\n            display_name=\"Contact Points / Astra Database ID\",\n            info=\"Contact points for the database (or Astra DB database ID)\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"username\", display_name=\"Username\", info=\"Username for the database (leave empty for Astra DB).\"\n        ),\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Password / Astra DB Token\",\n            info=\"User password for the database (or Astra DB token).\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"keyspace\",\n            display_name=\"Keyspace\",\n            info=\"Table Keyspace (or Astra DB namespace).\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"table_name\",\n            display_name=\"Table Name\",\n            info=\"The name of the table (or Astra DB collection) where vectors will be stored.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"setup_mode\",\n            display_name=\"Setup Mode\",\n            info=\"Configuration mode for setting up the Cassandra table, with options like 'Sync' or 'Off'.\",\n            options=[\"Sync\", \"Off\"],\n            value=\"Sync\",\n            advanced=True,\n        ),\n        DictInput(\n            name=\"cluster_kwargs\",\n            display_name=\"Cluster arguments\",\n            info=\"Optional dictionary of additional keyword arguments for the Cassandra cluster.\",\n            advanced=True,\n            list=True,\n        ),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            info=\"Search type to use\",\n            options=[\n                \"Traversal\",\n                \"MMR traversal\",\n                \"Similarity\",\n                \"Similarity with score threshold\",\n                \"MMR (Max Marginal Relevance)\",\n            ],\n            value=\"Traversal\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"depth\",\n            display_name=\"Depth of traversal\",\n            info=\"The maximum depth of edges to traverse. (when using 'Traversal' or 'MMR traversal')\",\n            value=1,\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results. \"\n            \"(when using 'Similarity with score threshold')\",\n            value=0,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"search_filter\",\n            display_name=\"Search Metadata Filter\",\n            info=\"Optional dictionary of filters to apply to the search query.\",\n            advanced=True,\n            list=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> CassandraGraphVectorStore:\n        try:\n            import cassio\n            from langchain_community.utilities.cassandra import SetupMode\n        except ImportError as e:\n            msg = \"Could not import cassio integration package. Please install it with `pip install cassio`.\"\n            raise ImportError(msg) from e\n\n        database_ref = self.database_ref\n\n        try:\n            UUID(self.database_ref)\n            is_astra = True\n        except ValueError:\n            is_astra = False\n            if \",\" in self.database_ref:\n                # use a copy because we can't change the type of the parameter\n                database_ref = self.database_ref.split(\",\")\n\n        if is_astra:\n            cassio.init(\n                database_id=database_ref,\n                token=self.token,\n                cluster_kwargs=self.cluster_kwargs,\n            )\n        else:\n            cassio.init(\n                contact_points=database_ref,\n                username=self.username,\n                password=self.token,\n                cluster_kwargs=self.cluster_kwargs,\n            )\n\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        setup_mode = SetupMode.OFF if self.setup_mode == \"Off\" else SetupMode.SYNC\n\n        if documents:\n            self.log(f\"Adding {len(documents)} documents to the Vector Store.\")\n            store = CassandraGraphVectorStore.from_documents(\n                documents=documents,\n                embedding=self.embedding,\n                node_table=self.table_name,\n                keyspace=self.keyspace,\n            )\n        else:\n            self.log(\"No documents to add to the Vector Store.\")\n            store = CassandraGraphVectorStore(\n                embedding=self.embedding,\n                node_table=self.table_name,\n                keyspace=self.keyspace,\n                setup_mode=setup_mode,\n            )\n        return store\n\n    def _map_search_type(self) -> str:\n        if self.search_type == \"Similarity\":\n            return \"similarity\"\n        if self.search_type == \"Similarity with score threshold\":\n            return \"similarity_score_threshold\"\n        if self.search_type == \"MMR (Max Marginal Relevance)\":\n            return \"mmr\"\n        if self.search_type == \"MMR Traversal\":\n            return \"mmr_traversal\"\n        return \"traversal\"\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        self.log(f\"Search input: {self.search_query}\")\n        self.log(f\"Search type: {self.search_type}\")\n        self.log(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            try:\n                search_type = self._map_search_type()\n                search_args = self._build_search_args()\n\n                self.log(f\"Search args: {search_args}\")\n\n                docs = vector_store.search(query=self.search_query, search_type=search_type, **search_args)\n            except KeyError as e:\n                if \"content\" in str(e):\n                    msg = (\n                        \"You should ingest data through Langflow (or LangChain) to query it in Langflow. \"\n                        \"Your collection does not contain a field name 'content'.\"\n                    )\n                    raise ValueError(msg) from e\n                raise\n\n            self.log(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n\n    def _build_search_args(self):\n        args = {\n            \"k\": self.number_of_results,\n            \"score_threshold\": self.search_score_threshold,\n            \"depth\": self.depth,\n        }\n\n        if self.search_filter:\n            clean_filter = {k: v for k, v in self.search_filter.items() if k and v}\n            if len(clean_filter) > 0:\n                args[\"filter\"] = clean_filter\n        return args\n\n    def get_retriever_kwargs(self):\n        search_args = self._build_search_args()\n        return {\n            \"search_type\": self._map_search_type(),\n            \"search_kwargs\": search_args,\n        }\n"},"database_ref":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Contact Points / Astra Database ID","dynamic":false,"info":"Contact points for the database (or Astra DB database ID)","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"database_ref","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"depth":{"_input_type":"IntInput","advanced":true,"display_name":"Depth of traversal","dynamic":false,"info":"The maximum depth of edges to traverse. (when using 'Traversal' or 'MMR traversal')","list":false,"list_add_label":"Add More","name":"depth","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"keyspace":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Keyspace","dynamic":false,"info":"Table Keyspace (or Astra DB namespace).","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"keyspace","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"search_filter":{"_input_type":"DictInput","advanced":true,"display_name":"Search Metadata Filter","dynamic":false,"info":"Optional dictionary of filters to apply to the search query.","list":true,"list_add_label":"Add More","name":"search_filter","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"search_score_threshold":{"_input_type":"FloatInput","advanced":true,"display_name":"Search Score Threshold","dynamic":false,"info":"Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')","list":false,"list_add_label":"Add More","name":"search_score_threshold","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.0},"search_type":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Search Type","dynamic":false,"external_options":{},"info":"Search type to use","name":"search_type","options":["Traversal","MMR traversal","Similarity","Similarity with score threshold","MMR (Max Marginal Relevance)"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Traversal"},"setup_mode":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Setup Mode","dynamic":false,"external_options":{},"info":"Configuration mode for setting up the Cassandra table, with options like 'Sync' or 'Off'.","name":"setup_mode","options":["Sync","Off"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Sync"},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"table_name":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Table Name","dynamic":false,"info":"The name of the table (or Astra DB collection) where vectors will be stored.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"table_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password / Astra DB Token","dynamic":false,"info":"User password for the database (or Astra DB token).","input_types":[],"load_from_db":true,"name":"token","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"username":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Username","dynamic":false,"info":"Username for the database (leave empty for Astra DB).","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"Chroma":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Chroma Vector Store with search capabilities","display_name":"Chroma DB","documentation":"","edited":false,"field_order":["collection_name","persist_directory","ingest_data","search_query","should_cache_vector_store","embedding","chroma_server_cors_allow_origins","chroma_server_host","chroma_server_http_port","chroma_server_grpc_port","chroma_server_ssl_enabled","allow_duplicates","search_type","number_of_results","limit"],"frozen":false,"icon":"Chroma","legacy":false,"metadata":{"code_hash":"0f1bc726a86a","dependencies":{"dependencies":[{"name":"chromadb","version":"1.1.1"},{"name":"langchain_chroma","version":"0.2.6"},{"name":"typing_extensions","version":"4.15.0"},{"name":"lfx","version":null},{"name":"langchain_community","version":"0.3.21"}],"total_dependencies":5},"module":"lfx.components.vectorstores.chroma.ChromaVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","allow_duplicates":{"_input_type":"BoolInput","advanced":true,"display_name":"Allow Duplicates","dynamic":false,"info":"If false, will not add documents that are already in the Vector Store.","list":false,"list_add_label":"Add More","name":"allow_duplicates","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"chroma_server_cors_allow_origins":{"_input_type":"StrInput","advanced":true,"display_name":"Server CORS Allow Origins","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"chroma_server_cors_allow_origins","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"chroma_server_grpc_port":{"_input_type":"IntInput","advanced":true,"display_name":"Server gRPC Port","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"chroma_server_grpc_port","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"chroma_server_host":{"_input_type":"StrInput","advanced":true,"display_name":"Server Host","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"chroma_server_host","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"chroma_server_http_port":{"_input_type":"IntInput","advanced":true,"display_name":"Server HTTP Port","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"chroma_server_http_port","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"chroma_server_ssl_enabled":{"_input_type":"BoolInput","advanced":true,"display_name":"Server SSL Enabled","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"chroma_server_ssl_enabled","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from copy import deepcopy\nfrom typing import TYPE_CHECKING\n\nfrom chromadb.config import Settings\nfrom langchain_chroma import Chroma\nfrom typing_extensions import override\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.base.vectorstores.utils import chroma_collection_to_data\nfrom lfx.inputs.inputs import BoolInput, DropdownInput, HandleInput, IntInput, StrInput\nfrom lfx.schema.data import Data\n\nif TYPE_CHECKING:\n    from lfx.schema.dataframe import DataFrame\n\n\nclass ChromaVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"Chroma Vector Store with search capabilities.\"\"\"\n\n    display_name: str = \"Chroma DB\"\n    description: str = \"Chroma Vector Store with search capabilities\"\n    name = \"Chroma\"\n    icon = \"Chroma\"\n\n    inputs = [\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            value=\"langflow\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"Persist Directory\",\n        ),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        StrInput(\n            name=\"chroma_server_cors_allow_origins\",\n            display_name=\"Server CORS Allow Origins\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"chroma_server_host\",\n            display_name=\"Server Host\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chroma_server_http_port\",\n            display_name=\"Server HTTP Port\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"chroma_server_grpc_port\",\n            display_name=\"Server gRPC Port\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"chroma_server_ssl_enabled\",\n            display_name=\"Server SSL Enabled\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"allow_duplicates\",\n            display_name=\"Allow Duplicates\",\n            advanced=True,\n            info=\"If false, will not add documents that are already in the Vector Store.\",\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            options=[\"Similarity\", \"MMR\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=10,\n        ),\n        IntInput(\n            name=\"limit\",\n            display_name=\"Limit\",\n            advanced=True,\n            info=\"Limit the number of records to compare when Allow Duplicates is False.\",\n        ),\n    ]\n\n    @override\n    @check_cached_vector_store\n    def build_vector_store(self) -> Chroma:\n        \"\"\"Builds the Chroma object.\"\"\"\n        try:\n            from chromadb import Client\n            from langchain_chroma import Chroma\n        except ImportError as e:\n            msg = \"Could not import Chroma integration package. Please install it with `pip install langchain-chroma`.\"\n            raise ImportError(msg) from e\n        # Chroma settings\n        chroma_settings = None\n        client = None\n        if self.chroma_server_host:\n            chroma_settings = Settings(\n                chroma_server_cors_allow_origins=self.chroma_server_cors_allow_origins or [],\n                chroma_server_host=self.chroma_server_host,\n                chroma_server_http_port=self.chroma_server_http_port or None,\n                chroma_server_grpc_port=self.chroma_server_grpc_port or None,\n                chroma_server_ssl_enabled=self.chroma_server_ssl_enabled,\n            )\n            client = Client(settings=chroma_settings)\n\n        # Check persist_directory and expand it if it is a relative path\n        persist_directory = self.resolve_path(self.persist_directory) if self.persist_directory is not None else None\n\n        chroma = Chroma(\n            persist_directory=persist_directory,\n            client=client,\n            embedding_function=self.embedding,\n            collection_name=self.collection_name,\n        )\n\n        self._add_documents_to_vector_store(chroma)\n        self.status = chroma_collection_to_data(chroma.get(limit=self.limit))\n        return chroma\n\n    def _add_documents_to_vector_store(self, vector_store: \"Chroma\") -> None:\n        \"\"\"Adds documents to the Vector Store.\"\"\"\n        ingest_data: list | Data | DataFrame = self.ingest_data\n        if not ingest_data:\n            self.status = \"\"\n            return\n\n        # Convert DataFrame to Data if needed using parent's method\n        ingest_data = self._prepare_ingest_data()\n\n        stored_documents_without_id = []\n        if self.allow_duplicates:\n            stored_data = []\n        else:\n            stored_data = chroma_collection_to_data(vector_store.get(limit=self.limit))\n            for value in deepcopy(stored_data):\n                del value.id\n                stored_documents_without_id.append(value)\n\n        documents = []\n        for _input in ingest_data or []:\n            if isinstance(_input, Data):\n                if _input not in stored_documents_without_id:\n                    documents.append(_input.to_lc_document())\n            else:\n                msg = \"Vector Store Inputs must be Data objects.\"\n                raise TypeError(msg)\n\n        if documents and self.embedding is not None:\n            self.log(f\"Adding {len(documents)} documents to the Vector Store.\")\n            # Filter complex metadata to prevent ChromaDB errors\n            try:\n                from langchain_community.vectorstores.utils import filter_complex_metadata\n\n                filtered_documents = filter_complex_metadata(documents)\n                vector_store.add_documents(filtered_documents)\n            except ImportError:\n                self.log(\"Warning: Could not import filter_complex_metadata. Adding documents without filtering.\")\n                vector_store.add_documents(documents)\n        else:\n            self.log(\"No documents to add to the Vector Store.\")\n"},"collection_name":{"_input_type":"StrInput","advanced":false,"display_name":"Collection Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"langflow"},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"limit":{"_input_type":"IntInput","advanced":true,"display_name":"Limit","dynamic":false,"info":"Limit the number of records to compare when Allow Duplicates is False.","list":false,"list_add_label":"Add More","name":"limit","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":10},"persist_directory":{"_input_type":"StrInput","advanced":false,"display_name":"Persist Directory","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"persist_directory","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"search_type":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Search Type","dynamic":false,"external_options":{},"info":"","name":"search_type","options":["Similarity","MMR"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Similarity"},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false},"Clickhouse":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"ClickHouse Vector Store with search capabilities","display_name":"ClickHouse","documentation":"","edited":false,"field_order":["host","port","database","table","username","password","index_type","metric","secure","index_param","index_query_params","ingest_data","search_query","should_cache_vector_store","embedding","number_of_results","score_threshold"],"frozen":false,"icon":"Clickhouse","legacy":false,"metadata":{"code_hash":"9109e813dc9c","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null},{"name":"clickhouse_connect","version":"0.7.19"}],"total_dependencies":3},"module":"lfx.components.vectorstores.clickhouse.ClickhouseVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_community.vectorstores import Clickhouse, ClickhouseSettings\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.inputs.inputs import BoolInput, FloatInput\nfrom lfx.io import (\n    DictInput,\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass ClickhouseVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"ClickHouse\"\n    description = \"ClickHouse Vector Store with search capabilities\"\n    name = \"Clickhouse\"\n    icon = \"Clickhouse\"\n\n    inputs = [\n        StrInput(name=\"host\", display_name=\"hostname\", required=True, value=\"localhost\"),\n        IntInput(name=\"port\", display_name=\"port\", required=True, value=8123),\n        StrInput(name=\"database\", display_name=\"database\", required=True),\n        StrInput(name=\"table\", display_name=\"Table name\", required=True),\n        StrInput(name=\"username\", display_name=\"The ClickHouse user name.\", required=True),\n        SecretStrInput(name=\"password\", display_name=\"The password for username.\", required=True),\n        DropdownInput(\n            name=\"index_type\",\n            display_name=\"index_type\",\n            options=[\"annoy\", \"vector_similarity\"],\n            info=\"Type of the index.\",\n            value=\"annoy\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"metric\",\n            display_name=\"metric\",\n            options=[\"angular\", \"euclidean\", \"manhattan\", \"hamming\", \"dot\"],\n            info=\"Metric to compute distance.\",\n            value=\"angular\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"secure\",\n            display_name=\"Use https/TLS. This overrides inferred values from the interface or port arguments.\",\n            value=False,\n            advanced=True,\n        ),\n        StrInput(name=\"index_param\", display_name=\"Param of the index\", value=\"100,'L2Distance'\", advanced=True),\n        DictInput(name=\"index_query_params\", display_name=\"index query params\", advanced=True),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n        FloatInput(name=\"score_threshold\", display_name=\"Score threshold\", advanced=True),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> Clickhouse:\n        try:\n            import clickhouse_connect\n        except ImportError as e:\n            msg = (\n                \"Failed to import ClickHouse dependencies. \"\n                \"Install it using `uv pip install langflow[clickhouse-connect] --pre`\"\n            )\n            raise ImportError(msg) from e\n\n        try:\n            client = clickhouse_connect.get_client(\n                host=self.host, port=self.port, username=self.username, password=self.password\n            )\n            client.command(\"SELECT 1\")\n        except Exception as e:\n            msg = f\"Failed to connect to Clickhouse: {e}\"\n            raise ValueError(msg) from e\n\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        kwargs = {}\n        if self.index_param:\n            kwargs[\"index_param\"] = self.index_param.split(\",\")\n        if self.index_query_params:\n            kwargs[\"index_query_params\"] = self.index_query_params\n\n        settings = ClickhouseSettings(\n            table=self.table,\n            database=self.database,\n            host=self.host,\n            index_type=self.index_type,\n            metric=self.metric,\n            password=self.password,\n            port=self.port,\n            secure=self.secure,\n            username=self.username,\n            **kwargs,\n        )\n        if documents:\n            clickhouse_vs = Clickhouse.from_documents(documents=documents, embedding=self.embedding, config=settings)\n\n        else:\n            clickhouse_vs = Clickhouse(embedding=self.embedding, config=settings)\n\n        return clickhouse_vs\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            kwargs = {}\n            if self.score_threshold:\n                kwargs[\"score_threshold\"] = self.score_threshold\n\n            docs = vector_store.similarity_search(query=self.search_query, k=self.number_of_results, **kwargs)\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n"},"database":{"_input_type":"StrInput","advanced":false,"display_name":"database","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"database","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"host":{"_input_type":"StrInput","advanced":false,"display_name":"hostname","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"host","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"localhost"},"index_param":{"_input_type":"StrInput","advanced":true,"display_name":"Param of the index","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"index_param","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"100,'L2Distance'"},"index_query_params":{"_input_type":"DictInput","advanced":true,"display_name":"index query params","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"index_query_params","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"index_type":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"index_type","dynamic":false,"external_options":{},"info":"Type of the index.","name":"index_type","options":["annoy","vector_similarity"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"annoy"},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"metric":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"metric","dynamic":false,"external_options":{},"info":"Metric to compute distance.","name":"metric","options":["angular","euclidean","manhattan","hamming","dot"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"angular"},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"The password for username.","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"port":{"_input_type":"IntInput","advanced":false,"display_name":"port","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"port","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":8123},"score_threshold":{"_input_type":"FloatInput","advanced":true,"display_name":"Score threshold","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"score_threshold","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":""},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"secure":{"_input_type":"BoolInput","advanced":true,"display_name":"Use https/TLS. This overrides inferred values from the interface or port arguments.","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"secure","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"table":{"_input_type":"StrInput","advanced":false,"display_name":"Table name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"table","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"username":{"_input_type":"StrInput","advanced":false,"display_name":"The ClickHouse user name.","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"Couchbase":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Couchbase Vector Store with search capabilities","display_name":"Couchbase","documentation":"","edited":false,"field_order":["couchbase_connection_string","couchbase_username","couchbase_password","bucket_name","scope_name","collection_name","index_name","ingest_data","search_query","should_cache_vector_store","embedding","number_of_results"],"frozen":false,"icon":"Couchbase","legacy":false,"metadata":{"code_hash":"70ed475a6f48","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null},{"name":"couchbase","version":null}],"total_dependencies":3},"module":"lfx.components.vectorstores.couchbase.CouchbaseVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","bucket_name":{"_input_type":"StrInput","advanced":false,"display_name":"Bucket Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"bucket_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from datetime import timedelta\n\nfrom langchain_community.vectorstores import CouchbaseVectorStore\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.io import HandleInput, IntInput, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass CouchbaseVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Couchbase\"\n    description = \"Couchbase Vector Store with search capabilities\"\n    name = \"Couchbase\"\n    icon = \"Couchbase\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"couchbase_connection_string\", display_name=\"Couchbase Cluster connection string\", required=True\n        ),\n        StrInput(name=\"couchbase_username\", display_name=\"Couchbase username\", required=True),\n        SecretStrInput(name=\"couchbase_password\", display_name=\"Couchbase password\", required=True),\n        StrInput(name=\"bucket_name\", display_name=\"Bucket Name\", required=True),\n        StrInput(name=\"scope_name\", display_name=\"Scope Name\", required=True),\n        StrInput(name=\"collection_name\", display_name=\"Collection Name\", required=True),\n        StrInput(name=\"index_name\", display_name=\"Index Name\", required=True),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> CouchbaseVectorStore:\n        try:\n            from couchbase.auth import PasswordAuthenticator\n            from couchbase.cluster import Cluster\n            from couchbase.options import ClusterOptions\n        except ImportError as e:\n            msg = \"Failed to import Couchbase dependencies. Install it using `uv pip install langflow[couchbase] --pre`\"\n            raise ImportError(msg) from e\n\n        try:\n            auth = PasswordAuthenticator(self.couchbase_username, self.couchbase_password)\n            options = ClusterOptions(auth)\n            cluster = Cluster(self.couchbase_connection_string, options)\n\n            cluster.wait_until_ready(timedelta(seconds=5))\n        except Exception as e:\n            msg = f\"Failed to connect to Couchbase: {e}\"\n            raise ValueError(msg) from e\n\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents:\n            couchbase_vs = CouchbaseVectorStore.from_documents(\n                documents=documents,\n                cluster=cluster,\n                bucket_name=self.bucket_name,\n                scope_name=self.scope_name,\n                collection_name=self.collection_name,\n                embedding=self.embedding,\n                index_name=self.index_name,\n            )\n\n        else:\n            couchbase_vs = CouchbaseVectorStore(\n                cluster=cluster,\n                bucket_name=self.bucket_name,\n                scope_name=self.scope_name,\n                collection_name=self.collection_name,\n                embedding=self.embedding,\n                index_name=self.index_name,\n            )\n\n        return couchbase_vs\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n"},"collection_name":{"_input_type":"StrInput","advanced":false,"display_name":"Collection Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"couchbase_connection_string":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Couchbase Cluster connection string","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"couchbase_connection_string","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"couchbase_password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Couchbase password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"couchbase_password","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"couchbase_username":{"_input_type":"StrInput","advanced":false,"display_name":"Couchbase username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"couchbase_username","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"index_name":{"_input_type":"StrInput","advanced":false,"display_name":"Index Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"index_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"scope_name":{"_input_type":"StrInput","advanced":false,"display_name":"Scope Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"scope_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false},"Elasticsearch":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Elasticsearch Vector Store with with advanced, customizable search capabilities.","display_name":"Elasticsearch","documentation":"","edited":false,"field_order":["elasticsearch_url","cloud_id","index_name","ingest_data","search_query","should_cache_vector_store","username","password","embedding","search_type","number_of_results","search_score_threshold","api_key","verify_certs"],"frozen":false,"icon":"ElasticsearchStore","legacy":false,"metadata":{"code_hash":"59c062f131dc","dependencies":{"dependencies":[{"name":"elasticsearch","version":"8.16.0"},{"name":"langchain","version":"0.3.23"},{"name":"langchain_elasticsearch","version":"0.3.0"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.vectorstores.elasticsearch.ElasticsearchVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":true,"display_name":"Elastic API Key","dynamic":false,"info":"API Key for Elastic Cloud authentication. If used, 'username' and 'password' are not required.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"cloud_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Elastic Cloud ID","dynamic":false,"info":"Use this for Elastic Cloud deployments. Do not use together with 'Elasticsearch URL'.","input_types":[],"load_from_db":true,"name":"cloud_id","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\n\nfrom elasticsearch import Elasticsearch\nfrom langchain.schema import Document\nfrom langchain_elasticsearch import ElasticsearchStore\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.io import (\n    BoolInput,\n    DropdownInput,\n    FloatInput,\n    HandleInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass ElasticsearchVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"Elasticsearch Vector Store with with advanced, customizable search capabilities.\"\"\"\n\n    display_name: str = \"Elasticsearch\"\n    description: str = \"Elasticsearch Vector Store with with advanced, customizable search capabilities.\"\n    name = \"Elasticsearch\"\n    icon = \"ElasticsearchStore\"\n\n    inputs = [\n        StrInput(\n            name=\"elasticsearch_url\",\n            display_name=\"Elasticsearch URL\",\n            value=\"http://localhost:9200\",\n            info=\"URL for self-managed Elasticsearch deployments (e.g., http://localhost:9200). \"\n            \"Do not use with Elastic Cloud deployments, use Elastic Cloud ID instead.\",\n        ),\n        SecretStrInput(\n            name=\"cloud_id\",\n            display_name=\"Elastic Cloud ID\",\n            value=\"\",\n            info=\"Use this for Elastic Cloud deployments. Do not use together with 'Elasticsearch URL'.\",\n        ),\n        StrInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            value=\"langflow\",\n            info=\"The index name where the vectors will be stored in Elasticsearch cluster.\",\n        ),\n        *LCVectorStoreComponent.inputs,\n        StrInput(\n            name=\"username\",\n            display_name=\"Username\",\n            value=\"\",\n            advanced=False,\n            info=(\n                \"Elasticsearch username (e.g., 'elastic'). \"\n                \"Required for both local and Elastic Cloud setups unless API keys are used.\"\n            ),\n        ),\n        SecretStrInput(\n            name=\"password\",\n            display_name=\"Password\",\n            value=\"\",\n            advanced=False,\n            info=(\n                \"Elasticsearch password for the specified user. \"\n                \"Required for both local and Elastic Cloud setups unless API keys are used.\"\n            ),\n        ),\n        HandleInput(\n            name=\"embedding\",\n            display_name=\"Embedding\",\n            input_types=[\"Embeddings\"],\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            options=[\"similarity\", \"mmr\"],\n            value=\"similarity\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results.\",\n            value=0.0,\n            advanced=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Elastic API Key\",\n            value=\"\",\n            advanced=True,\n            info=\"API Key for Elastic Cloud authentication. If used, 'username' and 'password' are not required.\",\n        ),\n        BoolInput(\n            name=\"verify_certs\",\n            display_name=\"Verify SSL Certificates\",\n            value=True,\n            advanced=True,\n            info=\"Whether to verify SSL certificates when connecting to Elasticsearch.\",\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> ElasticsearchStore:\n        \"\"\"Builds the Elasticsearch Vector Store object.\"\"\"\n        if self.cloud_id and self.elasticsearch_url:\n            msg = (\n                \"Both 'cloud_id' and 'elasticsearch_url' provided. \"\n                \"Please use only one based on your deployment (Cloud or Local).\"\n            )\n            raise ValueError(msg)\n\n        es_params = {\n            \"index_name\": self.index_name,\n            \"embedding\": self.embedding,\n            \"es_user\": self.username or None,\n            \"es_password\": self.password or None,\n        }\n\n        if self.cloud_id:\n            es_params[\"es_cloud_id\"] = self.cloud_id\n        else:\n            es_params[\"es_url\"] = self.elasticsearch_url\n\n        if self.api_key:\n            es_params[\"api_key\"] = self.api_key\n\n        # Check if we need to verify SSL certificates\n        if self.verify_certs is False:\n            # Build client parameters for Elasticsearch constructor\n            client_params: dict[str, Any] = {}\n            client_params[\"verify_certs\"] = False\n\n            if self.cloud_id:\n                client_params[\"cloud_id\"] = self.cloud_id\n            else:\n                client_params[\"hosts\"] = [self.elasticsearch_url]\n\n            if self.api_key:\n                client_params[\"api_key\"] = self.api_key\n            elif self.username and self.password:\n                client_params[\"basic_auth\"] = (self.username, self.password)\n\n            es_client = Elasticsearch(**client_params)\n            es_params[\"es_connection\"] = es_client\n\n        elasticsearch = ElasticsearchStore(**es_params)\n\n        # If documents are provided, add them to the store\n        if self.ingest_data:\n            documents = self._prepare_documents()\n            if documents:\n                elasticsearch.add_documents(documents)\n\n        return elasticsearch\n\n    def _prepare_documents(self) -> list[Document]:\n        \"\"\"Prepares documents from the input data to add to the vector store.\"\"\"\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for data in self.ingest_data:\n            if isinstance(data, Data):\n                documents.append(data.to_lc_document())\n            else:\n                error_message = \"Vector Store Inputs must be Data objects.\"\n                self.log(error_message)\n                raise TypeError(error_message)\n        return documents\n\n    def _add_documents_to_vector_store(self, vector_store: \"ElasticsearchStore\") -> None:\n        \"\"\"Adds documents to the Vector Store.\"\"\"\n        documents = self._prepare_documents()\n        if documents and self.embedding:\n            self.log(f\"Adding {len(documents)} documents to the Vector Store.\")\n            vector_store.add_documents(documents)\n        else:\n            self.log(\"No documents to add to the Vector Store.\")\n\n    def search(self, query: str | None = None) -> list[dict[str, Any]]:\n        \"\"\"Search for similar documents in the vector store or retrieve all documents if no query is provided.\"\"\"\n        vector_store = self.build_vector_store()\n        search_kwargs = {\n            \"k\": self.number_of_results,\n            \"score_threshold\": self.search_score_threshold,\n        }\n\n        if query:\n            search_type = self.search_type.lower()\n            if search_type not in {\"similarity\", \"mmr\"}:\n                msg = f\"Invalid search type: {self.search_type}\"\n                self.log(msg)\n                raise ValueError(msg)\n            try:\n                if search_type == \"similarity\":\n                    results = vector_store.similarity_search_with_score(query, **search_kwargs)\n                elif search_type == \"mmr\":\n                    results = vector_store.max_marginal_relevance_search(query, **search_kwargs)\n            except Exception as e:\n                msg = (\n                    \"Error occurred while querying the Elasticsearch VectorStore,\"\n                    \" there is no Data into the VectorStore.\"\n                )\n                self.log(msg)\n                raise ValueError(msg) from e\n            return [\n                {\"page_content\": doc.page_content, \"metadata\": doc.metadata, \"score\": score} for doc, score in results\n            ]\n        results = self.get_all_documents(vector_store, **search_kwargs)\n        return [{\"page_content\": doc.page_content, \"metadata\": doc.metadata, \"score\": score} for doc, score in results]\n\n    def get_all_documents(self, vector_store: ElasticsearchStore, **kwargs) -> list[tuple[Document, float]]:\n        \"\"\"Retrieve all documents from the vector store.\"\"\"\n        client = vector_store.client\n        index_name = self.index_name\n\n        query = {\n            \"query\": {\"match_all\": {}},\n            \"size\": kwargs.get(\"k\", self.number_of_results),\n        }\n\n        response = client.search(index=index_name, body=query)\n\n        results = []\n        for hit in response[\"hits\"][\"hits\"]:\n            doc = Document(\n                page_content=hit[\"_source\"].get(\"text\", \"\"),\n                metadata=hit[\"_source\"].get(\"metadata\", {}),\n            )\n            score = hit[\"_score\"]\n            results.append((doc, score))\n\n        return results\n\n    def search_documents(self) -> list[Data]:\n        \"\"\"Search for documents in the vector store based on the search input.\n\n        If no search input is provided, retrieve all documents.\n        \"\"\"\n        results = self.search(self.search_query)\n        retrieved_data = [\n            Data(\n                text=result[\"page_content\"],\n                file_path=result[\"metadata\"].get(\"file_path\", \"\"),\n            )\n            for result in results\n        ]\n        self.status = retrieved_data\n        return retrieved_data\n\n    def get_retriever_kwargs(self):\n        \"\"\"Get the keyword arguments for the retriever.\"\"\"\n        return {\n            \"search_type\": self.search_type.lower(),\n            \"search_kwargs\": {\n                \"k\": self.number_of_results,\n                \"score_threshold\": self.search_score_threshold,\n            },\n        }\n"},"elasticsearch_url":{"_input_type":"StrInput","advanced":false,"display_name":"Elasticsearch URL","dynamic":false,"info":"URL for self-managed Elasticsearch deployments (e.g., http://localhost:9200). Do not use with Elastic Cloud deployments, use Elastic Cloud ID instead.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"elasticsearch_url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"http://localhost:9200"},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"index_name":{"_input_type":"StrInput","advanced":false,"display_name":"Index Name","dynamic":false,"info":"The index name where the vectors will be stored in Elasticsearch cluster.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"index_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"langflow"},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Password","dynamic":false,"info":"Elasticsearch password for the specified user. Required for both local and Elastic Cloud setups unless API keys are used.","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"search_score_threshold":{"_input_type":"FloatInput","advanced":true,"display_name":"Search Score Threshold","dynamic":false,"info":"Minimum similarity score threshold for search results.","list":false,"list_add_label":"Add More","name":"search_score_threshold","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.0},"search_type":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Search Type","dynamic":false,"external_options":{},"info":"","name":"search_type","options":["similarity","mmr"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"similarity"},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"username":{"_input_type":"StrInput","advanced":false,"display_name":"Username","dynamic":false,"info":"Elasticsearch username (e.g., 'elastic'). Required for both local and Elastic Cloud setups unless API keys are used.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"verify_certs":{"_input_type":"BoolInput","advanced":true,"display_name":"Verify SSL Certificates","dynamic":false,"info":"Whether to verify SSL certificates when connecting to Elasticsearch.","list":false,"list_add_label":"Add More","name":"verify_certs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false},"FAISS":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"FAISS Vector Store with search capabilities","display_name":"FAISS","documentation":"","edited":false,"field_order":["index_name","persist_directory","ingest_data","search_query","should_cache_vector_store","allow_dangerous_deserialization","embedding","number_of_results"],"frozen":false,"icon":"FAISS","legacy":false,"metadata":{"code_hash":"2bd7a064d724","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.vectorstores.faiss.FaissVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","allow_dangerous_deserialization":{"_input_type":"BoolInput","advanced":true,"display_name":"Allow Dangerous Deserialization","dynamic":false,"info":"Set to True to allow loading pickle files from untrusted sources. Only enable this if you trust the source of the data.","list":false,"list_add_label":"Add More","name":"allow_dangerous_deserialization","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from pathlib import Path\n\nfrom langchain_community.vectorstores import FAISS\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.io import BoolInput, HandleInput, IntInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass FaissVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"FAISS Vector Store with search capabilities.\"\"\"\n\n    display_name: str = \"FAISS\"\n    description: str = \"FAISS Vector Store with search capabilities\"\n    name = \"FAISS\"\n    icon = \"FAISS\"\n\n    inputs = [\n        StrInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            value=\"langflow_index\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"Persist Directory\",\n            info=\"Path to save the FAISS index. It will be relative to where Langflow is running.\",\n        ),\n        *LCVectorStoreComponent.inputs,\n        BoolInput(\n            name=\"allow_dangerous_deserialization\",\n            display_name=\"Allow Dangerous Deserialization\",\n            info=\"Set to True to allow loading pickle files from untrusted sources. \"\n            \"Only enable this if you trust the source of the data.\",\n            advanced=True,\n            value=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n    ]\n\n    @staticmethod\n    def resolve_path(path: str) -> str:\n        \"\"\"Resolve the path relative to the Langflow root.\n\n        Args:\n            path: The path to resolve\n        Returns:\n            str: The resolved path as a string\n        \"\"\"\n        return str(Path(path).resolve())\n\n    def get_persist_directory(self) -> Path:\n        \"\"\"Returns the resolved persist directory path or the current directory if not set.\"\"\"\n        if self.persist_directory:\n            return Path(self.resolve_path(self.persist_directory))\n        return Path()\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> FAISS:\n        \"\"\"Builds the FAISS object.\"\"\"\n        path = self.get_persist_directory()\n        path.mkdir(parents=True, exist_ok=True)\n\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        faiss = FAISS.from_documents(documents=documents, embedding=self.embedding)\n        faiss.save_local(str(path), self.index_name)\n        return faiss\n\n    def search_documents(self) -> list[Data]:\n        \"\"\"Search for documents in the FAISS vector store.\"\"\"\n        path = self.get_persist_directory()\n        index_path = path / f\"{self.index_name}.faiss\"\n\n        if not index_path.exists():\n            vector_store = self.build_vector_store()\n        else:\n            vector_store = FAISS.load_local(\n                folder_path=str(path),\n                embeddings=self.embedding,\n                index_name=self.index_name,\n                allow_dangerous_deserialization=self.allow_dangerous_deserialization,\n            )\n\n        if not vector_store:\n            msg = \"Failed to load the FAISS index.\"\n            raise ValueError(msg)\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n            return docs_to_data(docs)\n        return []\n"},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"index_name":{"_input_type":"StrInput","advanced":false,"display_name":"Index Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"index_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"langflow_index"},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"persist_directory":{"_input_type":"StrInput","advanced":false,"display_name":"Persist Directory","dynamic":false,"info":"Path to save the FAISS index. It will be relative to where Langflow is running.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"persist_directory","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false},"Graph RAG":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Graph RAG traversal for vector store.","display_name":"Graph RAG","documentation":"","edited":false,"field_order":["embedding_model","vector_store","edge_definition","strategy","search_query","graphrag_strategy_kwargs"],"frozen":false,"icon":"AstraDB","legacy":false,"metadata":{"code_hash":"e0d9984248d2","dependencies":{"dependencies":[{"name":"graph_retriever","version":"0.8.0"},{"name":"langchain_graph_retriever","version":"0.8.0"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.vectorstores.graph_rag.GraphRAGComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import inspect\nfrom abc import ABC\n\nimport graph_retriever.strategies as strategies_module\nfrom langchain_graph_retriever import GraphRetriever\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.inputs.inputs import DropdownInput, HandleInput, MultilineInput, NestedDictInput, StrInput\nfrom lfx.schema.data import Data\n\n\ndef traversal_strategies() -> list[str]:\n    \"\"\"Retrieves a list of class names from the strategies_module.\n\n    This function uses the `inspect` module to get all the class members\n    from the `strategies_module` and returns their names as a list of strings.\n\n    Returns:\n        list[str]: A list of strategy class names.\n    \"\"\"\n    classes = inspect.getmembers(strategies_module, inspect.isclass)\n    return [name for name, cls in classes if ABC not in cls.__bases__]\n\n\nclass GraphRAGComponent(LCVectorStoreComponent):\n    \"\"\"GraphRAGComponent is a component for performing Graph RAG traversal in a vector store.\n\n    Attributes:\n        display_name (str): The display name of the component.\n        description (str): A brief description of the component.\n        name (str): The name of the component.\n        icon (str): The icon representing the component.\n        inputs (list): A list of input configurations for the component.\n\n    Methods:\n        _build_search_args():\n            Builds the arguments required for the search operation.\n        search_documents() -> list[Data]:\n            Searches for documents using the specified strategy, edge definition, and query.\n        _edge_definition_from_input() -> tuple:\n            Processes the edge definition input and returns it as a tuple.\n    \"\"\"\n\n    display_name: str = \"Graph RAG\"\n    description: str = \"Graph RAG traversal for vector store.\"\n    name = \"Graph RAG\"\n    icon: str = \"AstraDB\"\n\n    inputs = [\n        HandleInput(\n            name=\"embedding_model\",\n            display_name=\"Embedding Model\",\n            input_types=[\"Embeddings\"],\n            info=\"Specify the Embedding Model. Not required for Astra Vectorize collections.\",\n            required=False,\n        ),\n        HandleInput(\n            name=\"vector_store\",\n            display_name=\"Vector Store Connection\",\n            input_types=[\"VectorStore\"],\n            info=\"Connection to Vector Store.\",\n        ),\n        StrInput(\n            name=\"edge_definition\",\n            display_name=\"Edge Definition\",\n            info=\"Edge definition for the graph traversal.\",\n        ),\n        DropdownInput(\n            name=\"strategy\",\n            display_name=\"Traversal Strategies\",\n            options=traversal_strategies(),\n        ),\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n            tool_mode=True,\n        ),\n        NestedDictInput(\n            name=\"graphrag_strategy_kwargs\",\n            display_name=\"Strategy Parameters\",\n            info=(\n                \"Optional dictionary of additional parameters for the retrieval strategy. \"\n                \"Please see https://datastax.github.io/graph-rag/reference/graph_retriever/strategies/ for details.\"\n            ),\n            advanced=True,\n        ),\n    ]\n\n    def search_documents(self) -> list[Data]:\n        \"\"\"Searches for documents using the graph retriever based on the selected strategy, edge definition, and query.\n\n        Returns:\n            list[Data]: A list of retrieved documents.\n\n        Raises:\n            AttributeError: If there is an issue with attribute access.\n            TypeError: If there is a type mismatch.\n            ValueError: If there is a value error.\n        \"\"\"\n        additional_params = self.graphrag_strategy_kwargs or {}\n\n        # Invoke the graph retriever based on the selected strategy, edge definition, and query\n        strategy_class = getattr(strategies_module, self.strategy)\n        retriever = GraphRetriever(\n            store=self.vector_store,\n            edges=[self._evaluate_edge_definition_input()],\n            strategy=strategy_class(**additional_params),\n        )\n\n        return docs_to_data(retriever.invoke(self.search_query))\n\n    def _edge_definition_from_input(self) -> tuple:\n        \"\"\"Generates the edge definition from the input data.\n\n        Returns:\n            tuple: A tuple representing the edge definition.\n        \"\"\"\n        values = self.edge_definition.split(\",\")\n        values = [value.strip() for value in values]\n\n        return tuple(values)\n\n    def _evaluate_edge_definition_input(self) -> tuple:\n        from graph_retriever.edges.metadata import Id\n\n        \"\"\"Evaluates the edge definition, converting any function calls from strings.\n\n        Args:\n            edge_definition (tuple): The edge definition to evaluate.\n\n        Returns:\n            tuple: The evaluated edge definition.\n        \"\"\"\n        evaluated_values = []\n        for value in self._edge_definition_from_input():\n            if value == \"Id()\":\n                evaluated_values.append(Id())  # Evaluate Id() as a function call\n            else:\n                evaluated_values.append(value)\n        return tuple(evaluated_values)\n"},"edge_definition":{"_input_type":"StrInput","advanced":false,"display_name":"Edge Definition","dynamic":false,"info":"Edge definition for the graph traversal.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"edge_definition","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"embedding_model":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding Model","dynamic":false,"info":"Specify the Embedding Model. Not required for Astra Vectorize collections.","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding_model","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"graphrag_strategy_kwargs":{"_input_type":"NestedDictInput","advanced":true,"display_name":"Strategy Parameters","dynamic":false,"info":"Optional dictionary of additional parameters for the retrieval strategy. Please see https://datastax.github.io/graph-rag/reference/graph_retriever/strategies/ for details.","list":false,"list_add_label":"Add More","name":"graphrag_strategy_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"NestedDict","value":{}},"search_query":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Search Query","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"search_query","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"strategy":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Traversal Strategies","dynamic":false,"external_options":{},"info":"","name":"strategy","options":["Eager","Mmr","NodeTracker","Scored"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"vector_store":{"_input_type":"HandleInput","advanced":false,"display_name":"Vector Store Connection","dynamic":false,"info":"Connection to Vector Store.","input_types":["VectorStore"],"list":false,"list_add_label":"Add More","name":"vector_store","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""}},"tool_mode":false},"HCD":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Implementation of Vector Store using Hyper-Converged Database (HCD) with search capabilities","display_name":"Hyper-Converged Database","documentation":"","edited":false,"field_order":["collection_name","username","password","api_endpoint","ingest_data","search_query","should_cache_vector_store","namespace","ca_certificate","metric","batch_size","bulk_insert_batch_concurrency","bulk_insert_overwrite_concurrency","bulk_delete_concurrency","setup_mode","pre_delete_collection","metadata_indexing_include","embedding","metadata_indexing_exclude","collection_indexing_policy","number_of_results","search_type","search_score_threshold","search_filter"],"frozen":false,"icon":"HCD","legacy":false,"metadata":{"code_hash":"168ed98f853e","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"langchain_astradb","version":"0.6.1"},{"name":"astrapy","version":"2.1.0"}],"total_dependencies":3},"module":"lfx.components.vectorstores.hcd.HCDVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_endpoint":{"_input_type":"SecretStrInput","advanced":false,"display_name":"HCD API Endpoint","dynamic":false,"info":"API endpoint URL for the HCD service.","input_types":[],"load_from_db":true,"name":"api_endpoint","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"HCD_API_ENDPOINT"},"batch_size":{"_input_type":"IntInput","advanced":true,"display_name":"Batch Size","dynamic":false,"info":"Optional number of data to process in a single batch.","list":false,"list_add_label":"Add More","name":"batch_size","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"bulk_delete_concurrency":{"_input_type":"IntInput","advanced":true,"display_name":"Bulk Delete Concurrency","dynamic":false,"info":"Optional concurrency level for bulk delete operations.","list":false,"list_add_label":"Add More","name":"bulk_delete_concurrency","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"bulk_insert_batch_concurrency":{"_input_type":"IntInput","advanced":true,"display_name":"Bulk Insert Batch Concurrency","dynamic":false,"info":"Optional concurrency level for bulk insert operations.","list":false,"list_add_label":"Add More","name":"bulk_insert_batch_concurrency","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"bulk_insert_overwrite_concurrency":{"_input_type":"IntInput","advanced":true,"display_name":"Bulk Insert Overwrite Concurrency","dynamic":false,"info":"Optional concurrency level for bulk insert operations that overwrite existing data.","list":false,"list_add_label":"Add More","name":"bulk_insert_overwrite_concurrency","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"ca_certificate":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"CA Certificate","dynamic":false,"info":"Optional CA certificate for TLS connections to HCD.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"ca_certificate","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.inputs.inputs import DictInput, FloatInput\nfrom lfx.io import (\n    BoolInput,\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    MultilineInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass HCDVectorStoreComponent(LCVectorStoreComponent):\n    display_name: str = \"Hyper-Converged Database\"\n    description: str = \"Implementation of Vector Store using Hyper-Converged Database (HCD) with search capabilities\"\n    name = \"HCD\"\n    icon: str = \"HCD\"\n\n    inputs = [\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            info=\"The name of the collection within HCD where the vectors will be stored.\",\n            required=True,\n        ),\n        StrInput(\n            name=\"username\",\n            display_name=\"HCD Username\",\n            info=\"Authentication username for accessing HCD.\",\n            value=\"hcd-superuser\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"password\",\n            display_name=\"HCD Password\",\n            info=\"Authentication password for accessing HCD.\",\n            value=\"HCD_PASSWORD\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_endpoint\",\n            display_name=\"HCD API Endpoint\",\n            info=\"API endpoint URL for the HCD service.\",\n            value=\"HCD_API_ENDPOINT\",\n            required=True,\n        ),\n        *LCVectorStoreComponent.inputs,\n        StrInput(\n            name=\"namespace\",\n            display_name=\"Namespace\",\n            info=\"Optional namespace within HCD to use for the collection.\",\n            value=\"default_namespace\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"ca_certificate\",\n            display_name=\"CA Certificate\",\n            info=\"Optional CA certificate for TLS connections to HCD.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"metric\",\n            display_name=\"Metric\",\n            info=\"Optional distance metric for vector comparisons in the vector store.\",\n            options=[\"cosine\", \"dot_product\", \"euclidean\"],\n            advanced=True,\n        ),\n        IntInput(\n            name=\"batch_size\",\n            display_name=\"Batch Size\",\n            info=\"Optional number of data to process in a single batch.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_batch_concurrency\",\n            display_name=\"Bulk Insert Batch Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_overwrite_concurrency\",\n            display_name=\"Bulk Insert Overwrite Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations that overwrite existing data.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_delete_concurrency\",\n            display_name=\"Bulk Delete Concurrency\",\n            info=\"Optional concurrency level for bulk delete operations.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"setup_mode\",\n            display_name=\"Setup Mode\",\n            info=\"Configuration mode for setting up the vector store, with options like 'Sync', 'Async', or 'Off'.\",\n            options=[\"Sync\", \"Async\", \"Off\"],\n            advanced=True,\n            value=\"Sync\",\n        ),\n        BoolInput(\n            name=\"pre_delete_collection\",\n            display_name=\"Pre Delete Collection\",\n            info=\"Boolean flag to determine whether to delete the collection before creating a new one.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"metadata_indexing_include\",\n            display_name=\"Metadata Indexing Include\",\n            info=\"Optional list of metadata fields to include in the indexing.\",\n            advanced=True,\n        ),\n        HandleInput(\n            name=\"embedding\",\n            display_name=\"Embedding or Astra Vectorize\",\n            input_types=[\"Embeddings\", \"dict\"],\n            # TODO: This should be optional, but need to refactor langchain-astradb first.\n            info=\"Allows either an embedding model or an Astra Vectorize configuration.\",\n        ),\n        StrInput(\n            name=\"metadata_indexing_exclude\",\n            display_name=\"Metadata Indexing Exclude\",\n            info=\"Optional list of metadata fields to exclude from the indexing.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"collection_indexing_policy\",\n            display_name=\"Collection Indexing Policy\",\n            info=\"Optional dictionary defining the indexing policy for the collection.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            info=\"Search type to use\",\n            options=[\"Similarity\", \"Similarity with score threshold\", \"MMR (Max Marginal Relevance)\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results. \"\n            \"(when using 'Similarity with score threshold')\",\n            value=0,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"search_filter\",\n            display_name=\"Search Metadata Filter\",\n            info=\"Optional dictionary of filters to apply to the search query.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self):\n        try:\n            from langchain_astradb import AstraDBVectorStore\n            from langchain_astradb.utils.astradb import SetupMode\n        except ImportError as e:\n            msg = (\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n            raise ImportError(msg) from e\n\n        try:\n            from astrapy.authentication import UsernamePasswordTokenProvider\n            from astrapy.constants import Environment\n        except ImportError as e:\n            msg = \"Could not import astrapy integration package. Please install it with `pip install astrapy`.\"\n            raise ImportError(msg) from e\n\n        try:\n            if not self.setup_mode:\n                self.setup_mode = self._inputs[\"setup_mode\"].options[0]\n\n            setup_mode_value = SetupMode[self.setup_mode.upper()]\n        except KeyError as e:\n            msg = f\"Invalid setup mode: {self.setup_mode}\"\n            raise ValueError(msg) from e\n\n        if not isinstance(self.embedding, dict):\n            embedding_dict = {\"embedding\": self.embedding}\n        else:\n            from astrapy.info import VectorServiceOptions\n\n            dict_options = self.embedding.get(\"collection_vector_service_options\", {})\n            dict_options[\"authentication\"] = {\n                k: v for k, v in dict_options.get(\"authentication\", {}).items() if k and v\n            }\n            dict_options[\"parameters\"] = {k: v for k, v in dict_options.get(\"parameters\", {}).items() if k and v}\n            embedding_dict = {\"collection_vector_service_options\": VectorServiceOptions.from_dict(dict_options)}\n            collection_embedding_api_key = self.embedding.get(\"collection_embedding_api_key\")\n            if collection_embedding_api_key:\n                embedding_dict[\"collection_embedding_api_key\"] = collection_embedding_api_key\n\n        token_provider = UsernamePasswordTokenProvider(self.username, self.password)\n        vector_store_kwargs = {\n            **embedding_dict,\n            \"collection_name\": self.collection_name,\n            \"token\": token_provider,\n            \"api_endpoint\": self.api_endpoint,\n            \"namespace\": self.namespace,\n            \"metric\": self.metric or None,\n            \"batch_size\": self.batch_size or None,\n            \"bulk_insert_batch_concurrency\": self.bulk_insert_batch_concurrency or None,\n            \"bulk_insert_overwrite_concurrency\": self.bulk_insert_overwrite_concurrency or None,\n            \"bulk_delete_concurrency\": self.bulk_delete_concurrency or None,\n            \"setup_mode\": setup_mode_value,\n            \"pre_delete_collection\": self.pre_delete_collection or False,\n            \"environment\": Environment.HCD,\n        }\n\n        if self.metadata_indexing_include:\n            vector_store_kwargs[\"metadata_indexing_include\"] = self.metadata_indexing_include\n        elif self.metadata_indexing_exclude:\n            vector_store_kwargs[\"metadata_indexing_exclude\"] = self.metadata_indexing_exclude\n        elif self.collection_indexing_policy:\n            vector_store_kwargs[\"collection_indexing_policy\"] = self.collection_indexing_policy\n\n        try:\n            vector_store = AstraDBVectorStore(**vector_store_kwargs)\n        except Exception as e:\n            msg = f\"Error initializing AstraDBVectorStore: {e}\"\n            raise ValueError(msg) from e\n\n        self._add_documents_to_vector_store(vector_store)\n        return vector_store\n\n    def _add_documents_to_vector_store(self, vector_store) -> None:\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                msg = \"Vector Store Inputs must be Data objects.\"\n                raise TypeError(msg)\n\n        if documents:\n            self.log(f\"Adding {len(documents)} documents to the Vector Store.\")\n            try:\n                vector_store.add_documents(documents)\n            except Exception as e:\n                msg = f\"Error adding documents to AstraDBVectorStore: {e}\"\n                raise ValueError(msg) from e\n        else:\n            self.log(\"No documents to add to the Vector Store.\")\n\n    def _map_search_type(self) -> str:\n        if self.search_type == \"Similarity with score threshold\":\n            return \"similarity_score_threshold\"\n        if self.search_type == \"MMR (Max Marginal Relevance)\":\n            return \"mmr\"\n        return \"similarity\"\n\n    def _build_search_args(self):\n        args = {\n            \"k\": self.number_of_results,\n            \"score_threshold\": self.search_score_threshold,\n        }\n\n        if self.search_filter:\n            clean_filter = {k: v for k, v in self.search_filter.items() if k and v}\n            if len(clean_filter) > 0:\n                args[\"filter\"] = clean_filter\n        return args\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        self.log(f\"Search query: {self.search_query}\")\n        self.log(f\"Search type: {self.search_type}\")\n        self.log(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            try:\n                search_type = self._map_search_type()\n                search_args = self._build_search_args()\n\n                docs = vector_store.search(query=self.search_query, search_type=search_type, **search_args)\n            except Exception as e:\n                msg = f\"Error performing search in AstraDBVectorStore: {e}\"\n                raise ValueError(msg) from e\n\n            self.log(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n            self.log(f\"Converted documents to data: {len(data)}\")\n            self.status = data\n            return data\n        self.log(\"No search input provided. Skipping search.\")\n        return []\n\n    def get_retriever_kwargs(self):\n        search_args = self._build_search_args()\n        return {\n            \"search_type\": self._map_search_type(),\n            \"search_kwargs\": search_args,\n        }\n"},"collection_indexing_policy":{"_input_type":"StrInput","advanced":true,"display_name":"Collection Indexing Policy","dynamic":false,"info":"Optional dictionary defining the indexing policy for the collection.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_indexing_policy","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"collection_name":{"_input_type":"StrInput","advanced":false,"display_name":"Collection Name","dynamic":false,"info":"The name of the collection within HCD where the vectors will be stored.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding or Astra Vectorize","dynamic":false,"info":"Allows either an embedding model or an Astra Vectorize configuration.","input_types":["Embeddings","dict"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"metadata_indexing_exclude":{"_input_type":"StrInput","advanced":true,"display_name":"Metadata Indexing Exclude","dynamic":false,"info":"Optional list of metadata fields to exclude from the indexing.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"metadata_indexing_exclude","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"metadata_indexing_include":{"_input_type":"StrInput","advanced":true,"display_name":"Metadata Indexing Include","dynamic":false,"info":"Optional list of metadata fields to include in the indexing.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"metadata_indexing_include","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"metric":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Metric","dynamic":false,"external_options":{},"info":"Optional distance metric for vector comparisons in the vector store.","name":"metric","options":["cosine","dot_product","euclidean"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"namespace":{"_input_type":"StrInput","advanced":true,"display_name":"Namespace","dynamic":false,"info":"Optional namespace within HCD to use for the collection.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"namespace","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"default_namespace"},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"HCD Password","dynamic":false,"info":"Authentication password for accessing HCD.","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"HCD_PASSWORD"},"pre_delete_collection":{"_input_type":"BoolInput","advanced":true,"display_name":"Pre Delete Collection","dynamic":false,"info":"Boolean flag to determine whether to delete the collection before creating a new one.","list":false,"list_add_label":"Add More","name":"pre_delete_collection","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"search_filter":{"_input_type":"DictInput","advanced":true,"display_name":"Search Metadata Filter","dynamic":false,"info":"Optional dictionary of filters to apply to the search query.","list":true,"list_add_label":"Add More","name":"search_filter","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"search_score_threshold":{"_input_type":"FloatInput","advanced":true,"display_name":"Search Score Threshold","dynamic":false,"info":"Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')","list":false,"list_add_label":"Add More","name":"search_score_threshold","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.0},"search_type":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Search Type","dynamic":false,"external_options":{},"info":"Search type to use","name":"search_type","options":["Similarity","Similarity with score threshold","MMR (Max Marginal Relevance)"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Similarity"},"setup_mode":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Setup Mode","dynamic":false,"external_options":{},"info":"Configuration mode for setting up the vector store, with options like 'Sync', 'Async', or 'Off'.","name":"setup_mode","options":["Sync","Async","Off"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Sync"},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"username":{"_input_type":"StrInput","advanced":false,"display_name":"HCD Username","dynamic":false,"info":"Authentication username for accessing HCD.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"hcd-superuser"}},"tool_mode":false},"LocalDB":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Local Vector Store with search capabilities","display_name":"Local DB","documentation":"","edited":false,"field_order":["mode","collection_name","persist_directory","existing_collections","embedding","allow_duplicates","search_type","ingest_data","search_query","number_of_results","limit"],"frozen":false,"icon":"database","legacy":true,"metadata":{"code_hash":"6ebbb3a4493a","dependencies":{"dependencies":[{"name":"langchain_chroma","version":"0.2.6"},{"name":"typing_extensions","version":"4.15.0"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.vectorstores.local_db.LocalDBComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"perform_search","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","allow_duplicates":{"_input_type":"BoolInput","advanced":true,"display_name":"Allow Duplicates","dynamic":false,"info":"If false, will not add documents that are already in the Vector Store.","list":false,"list_add_label":"Add More","name":"allow_duplicates","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from copy import deepcopy\nfrom pathlib import Path\n\nfrom langchain_chroma import Chroma\nfrom typing_extensions import override\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.base.vectorstores.utils import chroma_collection_to_data\nfrom lfx.inputs.inputs import MultilineInput\nfrom lfx.io import BoolInput, DropdownInput, HandleInput, IntInput, MessageTextInput, TabInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.template.field.base import Output\n\n\nclass LocalDBComponent(LCVectorStoreComponent):\n    \"\"\"Chroma Vector Store with search capabilities.\"\"\"\n\n    display_name: str = \"Local DB\"\n    description: str = \"Local Vector Store with search capabilities\"\n    name = \"LocalDB\"\n    icon = \"database\"\n    legacy = True\n\n    inputs = [\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Ingest\", \"Retrieve\"],\n            info=\"Select the operation mode\",\n            value=\"Ingest\",\n            real_time_refresh=True,\n            show=True,\n        ),\n        MessageTextInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            value=\"langflow\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"persist_directory\",\n            display_name=\"Persist Directory\",\n            info=(\n                \"Custom base directory to save the vector store. \"\n                \"Collections will be stored under '{directory}/vector_stores/{collection_name}'. \"\n                \"If not specified, it will use your system's cache folder.\"\n            ),\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"existing_collections\",\n            display_name=\"Existing Collections\",\n            options=[],  # Will be populated dynamically\n            info=\"Select a previously created collection to search through its stored data.\",\n            show=False,\n            combobox=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", required=True, input_types=[\"Embeddings\"]),\n        BoolInput(\n            name=\"allow_duplicates\",\n            display_name=\"Allow Duplicates\",\n            advanced=True,\n            info=\"If false, will not add documents that are already in the Vector Store.\",\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            options=[\"Similarity\", \"MMR\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        HandleInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            input_types=[\"Data\", \"DataFrame\"],\n            is_list=True,\n            info=\"Data to store. It will be embedded and indexed for semantic search.\",\n            show=True,\n        ),\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n            tool_mode=True,\n            info=\"Enter text to search for similar content in the selected collection.\",\n            show=False,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=10,\n        ),\n        IntInput(\n            name=\"limit\",\n            display_name=\"Limit\",\n            advanced=True,\n            info=\"Limit the number of records to compare when Allow Duplicates is False.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"perform_search\"),\n    ]\n\n    def get_vector_store_directory(self, base_dir: str | Path) -> Path:\n        \"\"\"Get the full directory path for a collection.\"\"\"\n        # Ensure base_dir is a Path object\n        base_dir = Path(base_dir)\n        # Create the full path: base_dir/vector_stores/collection_name\n        full_path = base_dir / \"vector_stores\" / self.collection_name\n        # Create the directory if it doesn't exist\n        full_path.mkdir(parents=True, exist_ok=True)\n        return full_path\n\n    def get_default_persist_dir(self) -> str:\n        \"\"\"Get the default persist directory from cache.\"\"\"\n        from lfx.services.cache.utils import CACHE_DIR\n\n        return str(self.get_vector_store_directory(CACHE_DIR))\n\n    def list_existing_collections(self) -> list[str]:\n        \"\"\"List existing vector store collections from the persist directory.\"\"\"\n        from lfx.services.cache.utils import CACHE_DIR\n\n        # Get the base directory (either custom or cache)\n        base_dir = Path(self.persist_directory) if self.persist_directory else Path(CACHE_DIR)\n        # Get the vector_stores subdirectory\n        vector_stores_dir = base_dir / \"vector_stores\"\n        if not vector_stores_dir.exists():\n            return []\n\n        return [d.name for d in vector_stores_dir.iterdir() if d.is_dir()]\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        \"\"\"Update the build configuration when the mode changes.\"\"\"\n        if field_name == \"mode\":\n            # Hide all dynamic fields by default\n            dynamic_fields = [\n                \"ingest_data\",\n                \"search_query\",\n                \"search_type\",\n                \"number_of_results\",\n                \"existing_collections\",\n                \"collection_name\",\n                \"embedding\",\n                \"allow_duplicates\",\n                \"limit\",\n            ]\n            for field in dynamic_fields:\n                if field in build_config:\n                    build_config[field][\"show\"] = False\n\n            # Show/hide fields based on selected mode\n            if field_value == \"Ingest\":\n                if \"ingest_data\" in build_config:\n                    build_config[\"ingest_data\"][\"show\"] = True\n                if \"collection_name\" in build_config:\n                    build_config[\"collection_name\"][\"show\"] = True\n                    build_config[\"collection_name\"][\"display_name\"] = \"Name Your Collection\"\n                if \"persist\" in build_config:\n                    build_config[\"persist\"][\"show\"] = True\n                if \"persist_directory\" in build_config:\n                    build_config[\"persist_directory\"][\"show\"] = True\n                if \"embedding\" in build_config:\n                    build_config[\"embedding\"][\"show\"] = True\n                if \"allow_duplicates\" in build_config:\n                    build_config[\"allow_duplicates\"][\"show\"] = True\n                if \"limit\" in build_config:\n                    build_config[\"limit\"][\"show\"] = True\n            elif field_value == \"Retrieve\":\n                if \"persist\" in build_config:\n                    build_config[\"persist\"][\"show\"] = False\n                build_config[\"search_query\"][\"show\"] = True\n                build_config[\"search_type\"][\"show\"] = True\n                build_config[\"number_of_results\"][\"show\"] = True\n                build_config[\"embedding\"][\"show\"] = True\n                build_config[\"collection_name\"][\"show\"] = False\n                # Show existing collections dropdown and update its options\n                if \"existing_collections\" in build_config:\n                    build_config[\"existing_collections\"][\"show\"] = True\n                    build_config[\"existing_collections\"][\"options\"] = self.list_existing_collections()\n                # Hide collection_name in Retrieve mode since we use existing_collections\n        elif field_name == \"existing_collections\":\n            # Update collection_name when an existing collection is selected\n            if \"collection_name\" in build_config:\n                build_config[\"collection_name\"][\"value\"] = field_value\n\n        return build_config\n\n    @override\n    @check_cached_vector_store\n    def build_vector_store(self) -> Chroma:\n        \"\"\"Builds the Chroma object.\"\"\"\n        try:\n            from langchain_chroma import Chroma\n        except ImportError as e:\n            msg = \"Could not import Chroma integration package. Please install it with `pip install langchain-chroma`.\"\n            raise ImportError(msg) from e\n        # Chroma settings\n        # chroma_settings = None\n        if self.existing_collections:\n            self.collection_name = self.existing_collections\n\n        # Use user-provided directory or default cache directory\n        if self.persist_directory:\n            base_dir = self.resolve_path(self.persist_directory)\n            persist_directory = str(self.get_vector_store_directory(base_dir))\n            logger.debug(f\"Using custom persist directory: {persist_directory}\")\n        else:\n            persist_directory = self.get_default_persist_dir()\n            logger.debug(f\"Using default persist directory: {persist_directory}\")\n\n        chroma = Chroma(\n            persist_directory=persist_directory,\n            client=None,\n            embedding_function=self.embedding,\n            collection_name=self.collection_name,\n        )\n\n        self._add_documents_to_vector_store(chroma)\n        self.status = chroma_collection_to_data(chroma.get(limit=self.limit))\n        return chroma\n\n    def _add_documents_to_vector_store(self, vector_store: \"Chroma\") -> None:\n        \"\"\"Adds documents to the Vector Store.\"\"\"\n        ingest_data: list | Data | DataFrame = self.ingest_data\n        if not ingest_data:\n            self.status = \"\"\n            return\n\n        # Convert DataFrame to Data if needed using parent's method\n        ingest_data = self._prepare_ingest_data()\n\n        stored_documents_without_id = []\n        if self.allow_duplicates:\n            stored_data = []\n        else:\n            stored_data = chroma_collection_to_data(vector_store.get(limit=self.limit))\n            for value in deepcopy(stored_data):\n                del value.id\n                stored_documents_without_id.append(value)\n\n        documents = []\n        for _input in ingest_data or []:\n            if isinstance(_input, Data):\n                if _input not in stored_documents_without_id:\n                    documents.append(_input.to_lc_document())\n            else:\n                msg = \"Vector Store Inputs must be Data objects.\"\n                raise TypeError(msg)\n\n        if documents and self.embedding is not None:\n            self.log(f\"Adding {len(documents)} documents to the Vector Store.\")\n            vector_store.add_documents(documents)\n        else:\n            self.log(\"No documents to add to the Vector Store.\")\n\n    def perform_search(self) -> DataFrame:\n        return DataFrame(self.search_documents())\n"},"collection_name":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Collection Name","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"langflow"},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"existing_collections":{"_input_type":"DropdownInput","advanced":false,"combobox":true,"dialog_inputs":{},"display_name":"Existing Collections","dynamic":false,"external_options":{},"info":"Select a previously created collection to search through its stored data.","name":"existing_collections","options":[],"options_metadata":[],"placeholder":"","required":false,"show":false,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"Data to store. It will be embedded and indexed for semantic search.","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"limit":{"_input_type":"IntInput","advanced":true,"display_name":"Limit","dynamic":false,"info":"Limit the number of records to compare when Allow Duplicates is False.","list":false,"list_add_label":"Add More","name":"limit","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"mode":{"_input_type":"TabInput","advanced":false,"display_name":"Mode","dynamic":false,"info":"Select the operation mode","name":"mode","options":["Ingest","Retrieve"],"placeholder":"","real_time_refresh":true,"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"tab","value":"Ingest"},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":10},"persist_directory":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Persist Directory","dynamic":false,"info":"Custom base directory to save the vector store. Collections will be stored under '{directory}/vector_stores/{collection_name}'. If not specified, it will use your system's cache folder.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"persist_directory","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"search_query":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Search Query","dynamic":false,"info":"Enter text to search for similar content in the selected collection.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"search_query","placeholder":"","required":false,"show":false,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"search_type":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Search Type","dynamic":false,"external_options":{},"info":"","name":"search_type","options":["Similarity","MMR"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Similarity"}},"tool_mode":false},"Milvus":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Milvus vector store with search capabilities","display_name":"Milvus","documentation":"","edited":false,"field_order":["collection_name","collection_description","uri","password","connection_args","primary_field","text_field","vector_field","consistency_level","index_params","search_params","drop_old","timeout","ingest_data","search_query","should_cache_vector_store","embedding","number_of_results"],"frozen":false,"icon":"Milvus","legacy":false,"metadata":{"code_hash":"fe33323b8979","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"langchain_milvus","version":"0.1.7"}],"total_dependencies":2},"module":"lfx.components.vectorstores.milvus.MilvusVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.io import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    HandleInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass MilvusVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"Milvus vector store with search capabilities.\"\"\"\n\n    display_name: str = \"Milvus\"\n    description: str = \"Milvus vector store with search capabilities\"\n    name = \"Milvus\"\n    icon = \"Milvus\"\n\n    inputs = [\n        StrInput(name=\"collection_name\", display_name=\"Collection Name\", value=\"langflow\"),\n        StrInput(name=\"collection_description\", display_name=\"Collection Description\", value=\"\"),\n        StrInput(\n            name=\"uri\",\n            display_name=\"Connection URI\",\n            value=\"http://localhost:19530\",\n        ),\n        SecretStrInput(\n            name=\"password\",\n            display_name=\"Token\",\n            value=\"\",\n            info=\"Ignore this field if no token is required to make connection.\",\n        ),\n        DictInput(name=\"connection_args\", display_name=\"Other Connection Arguments\", advanced=True),\n        StrInput(name=\"primary_field\", display_name=\"Primary Field Name\", value=\"pk\"),\n        StrInput(name=\"text_field\", display_name=\"Text Field Name\", value=\"text\"),\n        StrInput(name=\"vector_field\", display_name=\"Vector Field Name\", value=\"vector\"),\n        DropdownInput(\n            name=\"consistency_level\",\n            display_name=\"Consistencey Level\",\n            options=[\"Bounded\", \"Session\", \"Strong\", \"Eventual\"],\n            value=\"Session\",\n            advanced=True,\n        ),\n        DictInput(name=\"index_params\", display_name=\"Index Parameters\", advanced=True),\n        DictInput(name=\"search_params\", display_name=\"Search Parameters\", advanced=True),\n        BoolInput(name=\"drop_old\", display_name=\"Drop Old Collection\", value=False, advanced=True),\n        FloatInput(name=\"timeout\", display_name=\"Timeout\", advanced=True),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self):\n        try:\n            from langchain_milvus.vectorstores import Milvus as LangchainMilvus\n        except ImportError as e:\n            msg = \"Could not import Milvus integration package. Please install it with `pip install langchain-milvus`.\"\n            raise ImportError(msg) from e\n        self.connection_args.update(uri=self.uri, token=self.password)\n        milvus_store = LangchainMilvus(\n            embedding_function=self.embedding,\n            collection_name=self.collection_name,\n            collection_description=self.collection_description,\n            connection_args=self.connection_args,\n            consistency_level=self.consistency_level,\n            index_params=self.index_params,\n            search_params=self.search_params,\n            drop_old=self.drop_old,\n            auto_id=True,\n            primary_field=self.primary_field,\n            text_field=self.text_field,\n            vector_field=self.vector_field,\n            timeout=self.timeout,\n        )\n\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents:\n            milvus_store.add_documents(documents)\n\n        return milvus_store\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n"},"collection_description":{"_input_type":"StrInput","advanced":false,"display_name":"Collection Description","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_description","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"collection_name":{"_input_type":"StrInput","advanced":false,"display_name":"Collection Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"langflow"},"connection_args":{"_input_type":"DictInput","advanced":true,"display_name":"Other Connection Arguments","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"connection_args","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"consistency_level":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Consistencey Level","dynamic":false,"external_options":{},"info":"","name":"consistency_level","options":["Bounded","Session","Strong","Eventual"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Session"},"drop_old":{"_input_type":"BoolInput","advanced":true,"display_name":"Drop Old Collection","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"drop_old","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"index_params":{"_input_type":"DictInput","advanced":true,"display_name":"Index Parameters","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"index_params","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"password":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Token","dynamic":false,"info":"Ignore this field if no token is required to make connection.","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"primary_field":{"_input_type":"StrInput","advanced":false,"display_name":"Primary Field Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"primary_field","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"pk"},"search_params":{"_input_type":"DictInput","advanced":true,"display_name":"Search Parameters","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"search_params","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"text_field":{"_input_type":"StrInput","advanced":false,"display_name":"Text Field Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"text_field","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"text"},"timeout":{"_input_type":"FloatInput","advanced":true,"display_name":"Timeout","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":""},"uri":{"_input_type":"StrInput","advanced":false,"display_name":"Connection URI","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"uri","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"http://localhost:19530"},"vector_field":{"_input_type":"StrInput","advanced":false,"display_name":"Vector Field Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"vector_field","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"vector"}},"tool_mode":false},"MongoDBAtlasVector":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"MongoDB Atlas Vector Store with search capabilities","display_name":"MongoDB Atlas","documentation":"","edited":false,"field_order":["mongodb_atlas_cluster_uri","enable_mtls","mongodb_atlas_client_cert","db_name","collection_name","index_name","ingest_data","search_query","should_cache_vector_store","insert_mode","embedding","number_of_results","index_field","filter_field","number_dimensions","similarity","quantization"],"frozen":false,"icon":"MongoDB","legacy":false,"metadata":{"code_hash":"3a502cb4d313","dependencies":{"dependencies":[{"name":"certifi","version":"2024.12.14"},{"name":"langchain_community","version":"0.3.21"},{"name":"pymongo","version":"4.10.1"},{"name":"lfx","version":null},{"name":"bson","version":"4.10.1"}],"total_dependencies":5},"module":"lfx.components.vectorstores.mongodb_atlas.MongoVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import tempfile\nimport time\n\nimport certifi\nfrom langchain_community.vectorstores import MongoDBAtlasVectorSearch\nfrom pymongo.collection import Collection\nfrom pymongo.operations import SearchIndexModel\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.io import BoolInput, DropdownInput, HandleInput, IntInput, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass MongoVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"MongoDB Atlas\"\n    description = \"MongoDB Atlas Vector Store with search capabilities\"\n    name = \"MongoDBAtlasVector\"\n    icon = \"MongoDB\"\n    INSERT_MODES = [\"append\", \"overwrite\"]\n    SIMILARITY_OPTIONS = [\"cosine\", \"euclidean\", \"dotProduct\"]\n    QUANTIZATION_OPTIONS = [\"scalar\", \"binary\"]\n    inputs = [\n        SecretStrInput(name=\"mongodb_atlas_cluster_uri\", display_name=\"MongoDB Atlas Cluster URI\", required=True),\n        BoolInput(name=\"enable_mtls\", display_name=\"Enable mTLS\", value=False, advanced=True, required=True),\n        SecretStrInput(\n            name=\"mongodb_atlas_client_cert\",\n            display_name=\"MongoDB Atlas Combined Client Certificate\",\n            required=False,\n            info=\"Client Certificate combined with the private key in the following format:\\n \"\n            \"-----BEGIN PRIVATE KEY-----\\n...\\n -----END PRIVATE KEY-----\\n-----BEGIN CERTIFICATE-----\\n\"\n            \"...\\n-----END CERTIFICATE-----\\n\",\n        ),\n        StrInput(name=\"db_name\", display_name=\"Database Name\", required=True),\n        StrInput(name=\"collection_name\", display_name=\"Collection Name\", required=True),\n        StrInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            required=True,\n            info=\"The name of Atlas Search index, it should be a Vector Search.\",\n        ),\n        *LCVectorStoreComponent.inputs,\n        DropdownInput(\n            name=\"insert_mode\",\n            display_name=\"Insert Mode\",\n            options=INSERT_MODES,\n            value=INSERT_MODES[0],\n            info=\"How to insert new documents into the collection.\",\n            advanced=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n        StrInput(\n            name=\"index_field\",\n            display_name=\"Index Field\",\n            advanced=True,\n            required=True,\n            info=\"The field to index.\",\n            value=\"embedding\",\n        ),\n        StrInput(\n            name=\"filter_field\", display_name=\"Filter Field\", advanced=True, info=\"The field to filter the index.\"\n        ),\n        IntInput(\n            name=\"number_dimensions\",\n            display_name=\"Number of Dimensions\",\n            info=\"Embedding Context Length.\",\n            value=1536,\n            advanced=True,\n            required=True,\n        ),\n        DropdownInput(\n            name=\"similarity\",\n            display_name=\"Similarity\",\n            options=SIMILARITY_OPTIONS,\n            value=SIMILARITY_OPTIONS[0],\n            info=\"The method used to measure the similarity between vectors.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"quantization\",\n            display_name=\"Quantization\",\n            options=QUANTIZATION_OPTIONS,\n            value=None,\n            info=\"Quantization reduces memory costs converting 32-bit floats to smaller data types\",\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> MongoDBAtlasVectorSearch:\n        try:\n            from pymongo import MongoClient\n        except ImportError as e:\n            msg = \"Please install pymongo to use MongoDB Atlas Vector Store\"\n            raise ImportError(msg) from e\n\n        # Create temporary files for the client certificate\n        if self.enable_mtls:\n            client_cert_path = None\n            try:\n                client_cert = self.mongodb_atlas_client_cert.replace(\" \", \"\\n\")\n                client_cert = client_cert.replace(\"-----BEGIN\\nPRIVATE\\nKEY-----\", \"-----BEGIN PRIVATE KEY-----\")\n                client_cert = client_cert.replace(\n                    \"-----END\\nPRIVATE\\nKEY-----\\n-----BEGIN\\nCERTIFICATE-----\",\n                    \"-----END PRIVATE KEY-----\\n-----BEGIN CERTIFICATE-----\",\n                )\n                client_cert = client_cert.replace(\"-----END\\nCERTIFICATE-----\", \"-----END CERTIFICATE-----\")\n                with tempfile.NamedTemporaryFile(delete=False) as client_cert_file:\n                    client_cert_file.write(client_cert.encode(\"utf-8\"))\n                    client_cert_path = client_cert_file.name\n\n            except Exception as e:\n                msg = f\"Failed to write certificate to temporary file: {e}\"\n                raise ValueError(msg) from e\n\n        try:\n            mongo_client: MongoClient = (\n                MongoClient(\n                    self.mongodb_atlas_cluster_uri,\n                    tls=True,\n                    tlsCertificateKeyFile=client_cert_path,\n                    tlsCAFile=certifi.where(),\n                )\n                if self.enable_mtls\n                else MongoClient(self.mongodb_atlas_cluster_uri)\n            )\n\n            collection = mongo_client[self.db_name][self.collection_name]\n\n        except Exception as e:\n            msg = f\"Failed to connect to MongoDB Atlas: {e}\"\n            raise ValueError(msg) from e\n\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents:\n            self.__insert_mode(collection)\n\n            return MongoDBAtlasVectorSearch.from_documents(\n                documents=documents, embedding=self.embedding, collection=collection, index_name=self.index_name\n            )\n        return MongoDBAtlasVectorSearch(embedding=self.embedding, collection=collection, index_name=self.index_name)\n\n    def search_documents(self) -> list[Data]:\n        from bson.objectid import ObjectId\n\n        vector_store = self.build_vector_store()\n\n        self.verify_search_index(vector_store._collection)\n\n        if self.search_query and isinstance(self.search_query, str):\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n            for doc in docs:\n                doc.metadata = {\n                    key: str(value) if isinstance(value, ObjectId) else value for key, value in doc.metadata.items()\n                }\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n\n    def __insert_mode(self, collection: Collection) -> None:\n        if self.insert_mode == \"overwrite\":\n            collection.delete_many({})  # Delete all documents while preserving collection structure\n\n    def verify_search_index(self, collection: Collection) -> None:\n        \"\"\"Verify if the search index exists, if not, create it.\n\n        Args:\n            collection (Collection): The collection to verify the search index on.\n        \"\"\"\n        indexes = collection.list_search_indexes()\n\n        index_names_types = {idx[\"name\"]: idx[\"type\"] for idx in indexes}\n        index_names = list(index_names_types.keys())\n        index_type = index_names_types.get(self.index_name)\n        if self.index_name not in index_names and index_type != \"vectorSearch\":\n            collection.create_search_index(self.__create_index_definition())\n\n            time.sleep(20)  # Give some time for index to be ready\n\n    def __create_index_definition(self) -> SearchIndexModel:\n        fields = [\n            {\n                \"type\": \"vector\",\n                \"path\": self.index_field,\n                \"numDimensions\": self.number_dimensions,\n                \"similarity\": self.similarity,\n                \"quantization\": self.quantization,\n            }\n        ]\n        if self.filter_field:\n            fields.append({\"type\": \"filter\", \"path\": self.filter_field})\n        return SearchIndexModel(definition={\"fields\": fields}, name=self.index_name, type=\"vectorSearch\")\n"},"collection_name":{"_input_type":"StrInput","advanced":false,"display_name":"Collection Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"db_name":{"_input_type":"StrInput","advanced":false,"display_name":"Database Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"db_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"enable_mtls":{"_input_type":"BoolInput","advanced":true,"display_name":"Enable mTLS","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"enable_mtls","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"filter_field":{"_input_type":"StrInput","advanced":true,"display_name":"Filter Field","dynamic":false,"info":"The field to filter the index.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"filter_field","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"index_field":{"_input_type":"StrInput","advanced":true,"display_name":"Index Field","dynamic":false,"info":"The field to index.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"index_field","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"embedding"},"index_name":{"_input_type":"StrInput","advanced":false,"display_name":"Index Name","dynamic":false,"info":"The name of Atlas Search index, it should be a Vector Search.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"index_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"insert_mode":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Insert Mode","dynamic":false,"external_options":{},"info":"How to insert new documents into the collection.","name":"insert_mode","options":["append","overwrite"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"append"},"mongodb_atlas_client_cert":{"_input_type":"SecretStrInput","advanced":false,"display_name":"MongoDB Atlas Combined Client Certificate","dynamic":false,"info":"Client Certificate combined with the private key in the following format:\n -----BEGIN PRIVATE KEY-----\n...\n -----END PRIVATE KEY-----\n-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----\n","input_types":[],"load_from_db":true,"name":"mongodb_atlas_client_cert","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"mongodb_atlas_cluster_uri":{"_input_type":"SecretStrInput","advanced":false,"display_name":"MongoDB Atlas Cluster URI","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"mongodb_atlas_cluster_uri","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"number_dimensions":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Dimensions","dynamic":false,"info":"Embedding Context Length.","list":false,"list_add_label":"Add More","name":"number_dimensions","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1536},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"quantization":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Quantization","dynamic":false,"external_options":{},"info":"Quantization reduces memory costs converting 32-bit floats to smaller data types","name":"quantization","options":["scalar","binary"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str"},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"similarity":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Similarity","dynamic":false,"external_options":{},"info":"The method used to measure the similarity between vectors.","name":"similarity","options":["cosine","euclidean","dotProduct"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"cosine"}},"tool_mode":false},"OpenSearch":{"base_classes":["Data","DataFrame","VectorStore"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"OpenSearch Vector Store with advanced, customizable search capabilities.","display_name":"OpenSearch","documentation":"","edited":false,"field_order":["opensearch_url","index_name","ingest_data","search_query","should_cache_vector_store","embedding","search_type","number_of_results","search_score_threshold","username","password","use_ssl","verify_certs","hybrid_search_query"],"frozen":false,"icon":"OpenSearch","legacy":false,"metadata":{"code_hash":"3fc12ae0ab23","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.vectorstores.opensearch.OpenSearchVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Vector Store Connection","group_outputs":false,"hidden":false,"method":"as_vector_store","name":"vectorstoreconnection","selected":"VectorStore","tool_mode":true,"types":["VectorStore"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import json\nfrom typing import Any\n\nfrom langchain_community.vectorstores import OpenSearchVectorSearch\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.base.vectorstores.vector_store_connection_decorator import vector_store_connection\nfrom lfx.io import (\n    BoolInput,\n    DropdownInput,\n    FloatInput,\n    HandleInput,\n    IntInput,\n    MultilineInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom lfx.schema.data import Data\n\n\n@vector_store_connection\nclass OpenSearchVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"OpenSearch Vector Store with advanced, customizable search capabilities.\"\"\"\n\n    display_name: str = \"OpenSearch\"\n    description: str = \"OpenSearch Vector Store with advanced, customizable search capabilities.\"\n    name = \"OpenSearch\"\n    icon = \"OpenSearch\"\n\n    inputs = [\n        StrInput(\n            name=\"opensearch_url\",\n            display_name=\"OpenSearch URL\",\n            value=\"http://localhost:9200\",\n            info=\"URL for OpenSearch cluster (e.g. https://192.168.1.1:9200).\",\n        ),\n        StrInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            value=\"langflow\",\n            info=\"The index name where the vectors will be stored in OpenSearch cluster.\",\n        ),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            options=[\"similarity\", \"similarity_score_threshold\", \"mmr\"],\n            value=\"similarity\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results.\",\n            value=0.0,\n            advanced=True,\n        ),\n        StrInput(\n            name=\"username\",\n            display_name=\"Username\",\n            value=\"admin\",\n            advanced=True,\n        ),\n        SecretStrInput(\n            name=\"password\",\n            display_name=\"Password\",\n            value=\"admin\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"use_ssl\",\n            display_name=\"Use SSL\",\n            value=True,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"verify_certs\",\n            display_name=\"Verify Certificates\",\n            value=False,\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"hybrid_search_query\",\n            display_name=\"Hybrid Search Query\",\n            value=\"\",\n            advanced=True,\n            info=(\n                \"Provide a custom hybrid search query in JSON format. This allows you to combine \"\n                \"vector similarity and keyword matching.\"\n            ),\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> OpenSearchVectorSearch:\n        \"\"\"Builds the OpenSearch Vector Store object.\"\"\"\n        try:\n            from langchain_community.vectorstores import OpenSearchVectorSearch\n        except ImportError as e:\n            error_message = f\"Failed to import required modules: {e}\"\n            self.log(error_message)\n            raise ImportError(error_message) from e\n\n        try:\n            opensearch = OpenSearchVectorSearch(\n                index_name=self.index_name,\n                embedding_function=self.embedding,\n                opensearch_url=self.opensearch_url,\n                http_auth=(self.username, self.password),\n                use_ssl=self.use_ssl,\n                verify_certs=self.verify_certs,\n                ssl_assert_hostname=False,\n                ssl_show_warn=False,\n            )\n        except Exception as e:\n            error_message = f\"Failed to create OpenSearchVectorSearch instance: {e}\"\n            self.log(error_message)\n            raise RuntimeError(error_message) from e\n\n        if self.ingest_data:\n            self._add_documents_to_vector_store(opensearch)\n\n        return opensearch\n\n    def _add_documents_to_vector_store(self, vector_store: \"OpenSearchVectorSearch\") -> None:\n        \"\"\"Adds documents to the Vector Store.\"\"\"\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                error_message = f\"Expected Data object, got {type(_input)}\"\n                self.log(error_message)\n                raise TypeError(error_message)\n\n        if documents and self.embedding is not None:\n            self.log(f\"Adding {len(documents)} documents to the Vector Store.\")\n            try:\n                vector_store.add_documents(documents)\n            except Exception as e:\n                error_message = f\"Error adding documents to Vector Store: {e}\"\n                self.log(error_message)\n                raise RuntimeError(error_message) from e\n        else:\n            self.log(\"No documents to add to the Vector Store.\")\n\n    def search(self, query: str | None = None) -> list[dict[str, Any]]:\n        \"\"\"Search for similar documents in the vector store or retrieve all documents if no query is provided.\"\"\"\n        try:\n            vector_store = self.build_vector_store()\n\n            query = query or \"\"\n\n            if self.hybrid_search_query.strip():\n                try:\n                    hybrid_query = json.loads(self.hybrid_search_query)\n                except json.JSONDecodeError as e:\n                    error_message = f\"Invalid hybrid search query JSON: {e}\"\n                    self.log(error_message)\n                    raise ValueError(error_message) from e\n\n                results = vector_store.client.search(index=self.index_name, body=hybrid_query)\n\n                processed_results = []\n                for hit in results.get(\"hits\", {}).get(\"hits\", []):\n                    source = hit.get(\"_source\", {})\n                    text = source.get(\"text\", \"\")\n                    metadata = source.get(\"metadata\", {})\n\n                    if isinstance(text, dict):\n                        text = text.get(\"text\", \"\")\n\n                    processed_results.append(\n                        {\n                            \"page_content\": text,\n                            \"metadata\": metadata,\n                        }\n                    )\n                return processed_results\n\n            search_kwargs = {\"k\": self.number_of_results}\n            search_type = self.search_type.lower()\n\n            if search_type == \"similarity\":\n                results = vector_store.similarity_search(query, **search_kwargs)\n                return [{\"page_content\": doc.page_content, \"metadata\": doc.metadata} for doc in results]\n            if search_type == \"similarity_score_threshold\":\n                search_kwargs[\"score_threshold\"] = self.search_score_threshold\n                results = vector_store.similarity_search_with_relevance_scores(query, **search_kwargs)\n                return [\n                    {\n                        \"page_content\": doc.page_content,\n                        \"metadata\": doc.metadata,\n                        \"score\": score,\n                    }\n                    for doc, score in results\n                ]\n            if search_type == \"mmr\":\n                results = vector_store.max_marginal_relevance_search(query, **search_kwargs)\n                return [{\"page_content\": doc.page_content, \"metadata\": doc.metadata} for doc in results]\n\n        except Exception as e:\n            error_message = f\"Error during search: {e}\"\n            self.log(error_message)\n            raise RuntimeError(error_message) from e\n\n        error_message = f\"Error during search. Invalid search type: {self.search_type}\"\n        self.log(error_message)\n        raise ValueError(error_message)\n\n    def search_documents(self) -> list[Data]:\n        \"\"\"Search for documents in the vector store based on the search input.\n\n        If no search input is provided, retrieve all documents.\n        \"\"\"\n        try:\n            query = self.search_query.strip() if self.search_query else None\n            results = self.search(query)\n            retrieved_data = [\n                Data(\n                    file_path=result[\"metadata\"].get(\"file_path\", \"\"),\n                    text=result[\"page_content\"],\n                )\n                for result in results\n            ]\n        except Exception as e:\n            error_message = f\"Error during document search: {e}\"\n            self.log(error_message)\n            raise RuntimeError(error_message) from e\n\n        self.status = retrieved_data\n        return retrieved_data\n"},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"hybrid_search_query":{"_input_type":"MultilineInput","advanced":true,"copy_field":false,"display_name":"Hybrid Search Query","dynamic":false,"info":"Provide a custom hybrid search query in JSON format. This allows you to combine vector similarity and keyword matching.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"hybrid_search_query","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"index_name":{"_input_type":"StrInput","advanced":false,"display_name":"Index Name","dynamic":false,"info":"The index name where the vectors will be stored in OpenSearch cluster.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"index_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"langflow"},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"opensearch_url":{"_input_type":"StrInput","advanced":false,"display_name":"OpenSearch URL","dynamic":false,"info":"URL for OpenSearch cluster (e.g. https://192.168.1.1:9200).","list":false,"list_add_label":"Add More","load_from_db":false,"name":"opensearch_url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"http://localhost:9200"},"password":{"_input_type":"SecretStrInput","advanced":true,"display_name":"Password","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"password","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":"admin"},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"search_score_threshold":{"_input_type":"FloatInput","advanced":true,"display_name":"Search Score Threshold","dynamic":false,"info":"Minimum similarity score threshold for search results.","list":false,"list_add_label":"Add More","name":"search_score_threshold","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.0},"search_type":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Search Type","dynamic":false,"external_options":{},"info":"","name":"search_type","options":["similarity","similarity_score_threshold","mmr"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"similarity"},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"use_ssl":{"_input_type":"BoolInput","advanced":true,"display_name":"Use SSL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"use_ssl","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"username":{"_input_type":"StrInput","advanced":true,"display_name":"Username","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"username","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"admin"},"verify_certs":{"_input_type":"BoolInput","advanced":true,"display_name":"Verify Certificates","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"verify_certs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false},"Pinecone":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Pinecone Vector Store with search capabilities","display_name":"Pinecone","documentation":"","edited":false,"field_order":["index_name","namespace","distance_strategy","pinecone_api_key","text_key","ingest_data","search_query","should_cache_vector_store","embedding","number_of_results"],"frozen":false,"icon":"Pinecone","legacy":false,"metadata":{"code_hash":"564ca0a0e9ab","dependencies":{"dependencies":[{"name":"numpy","version":"2.2.6"},{"name":"langchain_core","version":"0.3.79"},{"name":"lfx","version":null},{"name":"langchain_pinecone","version":"0.2.12"}],"total_dependencies":4},"module":"lfx.components.vectorstores.pinecone.PineconeVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import numpy as np\nfrom langchain_core.vectorstores import VectorStore\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.io import DropdownInput, HandleInput, IntInput, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass PineconeVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Pinecone\"\n    description = \"Pinecone Vector Store with search capabilities\"\n    name = \"Pinecone\"\n    icon = \"Pinecone\"\n    inputs = [\n        StrInput(name=\"index_name\", display_name=\"Index Name\", required=True),\n        StrInput(name=\"namespace\", display_name=\"Namespace\", info=\"Namespace for the index.\"),\n        DropdownInput(\n            name=\"distance_strategy\",\n            display_name=\"Distance Strategy\",\n            options=[\"Cosine\", \"Euclidean\", \"Dot Product\"],\n            value=\"Cosine\",\n            advanced=True,\n        ),\n        SecretStrInput(name=\"pinecone_api_key\", display_name=\"Pinecone API Key\", required=True),\n        StrInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"Key in the record to use as text.\",\n            value=\"text\",\n            advanced=True,\n        ),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> VectorStore:\n        \"\"\"Build and return a Pinecone vector store instance.\"\"\"\n        try:\n            from langchain_pinecone import PineconeVectorStore\n        except ImportError as e:\n            msg = \"langchain-pinecone is not installed. Please install it with `pip install langchain-pinecone`.\"\n            raise ValueError(msg) from e\n\n        try:\n            from langchain_pinecone._utilities import DistanceStrategy\n\n            # Wrap the embedding model to ensure float32 output\n            wrapped_embeddings = Float32Embeddings(self.embedding)\n\n            # Convert distance strategy\n            distance_strategy = self.distance_strategy.replace(\" \", \"_\").upper()\n            distance_strategy = DistanceStrategy[distance_strategy]\n\n            # Initialize Pinecone instance with wrapped embeddings\n            pinecone = PineconeVectorStore(\n                index_name=self.index_name,\n                embedding=wrapped_embeddings,  # Use wrapped embeddings\n                text_key=self.text_key,\n                namespace=self.namespace,\n                distance_strategy=distance_strategy,\n                pinecone_api_key=self.pinecone_api_key,\n            )\n        except Exception as e:\n            error_msg = \"Error building Pinecone vector store\"\n            raise ValueError(error_msg) from e\n        else:\n            self.ingest_data = self._prepare_ingest_data()\n\n            # Process documents if any\n            documents = []\n            if self.ingest_data:\n                # Convert DataFrame to Data if needed using parent's method\n\n                for doc in self.ingest_data:\n                    if isinstance(doc, Data):\n                        documents.append(doc.to_lc_document())\n                    else:\n                        documents.append(doc)\n\n                if documents:\n                    pinecone.add_documents(documents)\n\n            return pinecone\n\n    def search_documents(self) -> list[Data]:\n        \"\"\"Search documents in the vector store.\"\"\"\n        try:\n            if not self.search_query or not isinstance(self.search_query, str) or not self.search_query.strip():\n                return []\n\n            vector_store = self.build_vector_store()\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n        except Exception as e:\n            error_msg = \"Error searching documents\"\n            raise ValueError(error_msg) from e\n        else:\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n\n\nclass Float32Embeddings:\n    \"\"\"Wrapper class to ensure float32 embeddings.\"\"\"\n\n    def __init__(self, base_embeddings):\n        self.base_embeddings = base_embeddings\n\n    def embed_documents(self, texts):\n        embeddings = self.base_embeddings.embed_documents(texts)\n        if isinstance(embeddings, np.ndarray):\n            return [[self._force_float32(x) for x in vec] for vec in embeddings]\n        return [[self._force_float32(x) for x in vec] for vec in embeddings]\n\n    def embed_query(self, text):\n        embedding = self.base_embeddings.embed_query(text)\n        if isinstance(embedding, np.ndarray):\n            return [self._force_float32(x) for x in embedding]\n        return [self._force_float32(x) for x in embedding]\n\n    def _force_float32(self, value):\n        \"\"\"Convert any numeric type to Python float.\"\"\"\n        return float(np.float32(value))\n"},"distance_strategy":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Distance Strategy","dynamic":false,"external_options":{},"info":"","name":"distance_strategy","options":["Cosine","Euclidean","Dot Product"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Cosine"},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"index_name":{"_input_type":"StrInput","advanced":false,"display_name":"Index Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"index_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"namespace":{"_input_type":"StrInput","advanced":false,"display_name":"Namespace","dynamic":false,"info":"Namespace for the index.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"namespace","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"pinecone_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Pinecone API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"pinecone_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"text_key":{"_input_type":"StrInput","advanced":true,"display_name":"Text Key","dynamic":false,"info":"Key in the record to use as text.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"text_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"text"}},"tool_mode":false},"QdrantVectorStoreComponent":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Qdrant Vector Store with search capabilities","display_name":"Qdrant","documentation":"","edited":false,"field_order":["collection_name","host","port","grpc_port","api_key","prefix","timeout","path","url","distance_func","content_payload_key","metadata_payload_key","ingest_data","search_query","should_cache_vector_store","embedding","number_of_results"],"frozen":false,"icon":"Qdrant","legacy":false,"metadata":{"code_hash":"d54da976a5db","dependencies":{"dependencies":[{"name":"langchain","version":"0.3.23"},{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null},{"name":"qdrant_client","version":"1.9.2"}],"total_dependencies":4},"module":"lfx.components.vectorstores.qdrant.QdrantVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":true,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain.embeddings.base import Embeddings\nfrom langchain_community.vectorstores import Qdrant\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.io import (\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass QdrantVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Qdrant\"\n    description = \"Qdrant Vector Store with search capabilities\"\n    icon = \"Qdrant\"\n\n    inputs = [\n        StrInput(name=\"collection_name\", display_name=\"Collection Name\", required=True),\n        StrInput(name=\"host\", display_name=\"Host\", value=\"localhost\", advanced=True),\n        IntInput(name=\"port\", display_name=\"Port\", value=6333, advanced=True),\n        IntInput(name=\"grpc_port\", display_name=\"gRPC Port\", value=6334, advanced=True),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\", advanced=True),\n        StrInput(name=\"prefix\", display_name=\"Prefix\", advanced=True),\n        IntInput(name=\"timeout\", display_name=\"Timeout\", advanced=True),\n        StrInput(name=\"path\", display_name=\"Path\", advanced=True),\n        StrInput(name=\"url\", display_name=\"URL\", advanced=True),\n        DropdownInput(\n            name=\"distance_func\",\n            display_name=\"Distance Function\",\n            options=[\"Cosine\", \"Euclidean\", \"Dot Product\"],\n            value=\"Cosine\",\n            advanced=True,\n        ),\n        StrInput(name=\"content_payload_key\", display_name=\"Content Payload Key\", value=\"page_content\", advanced=True),\n        StrInput(name=\"metadata_payload_key\", display_name=\"Metadata Payload Key\", value=\"metadata\", advanced=True),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> Qdrant:\n        qdrant_kwargs = {\n            \"collection_name\": self.collection_name,\n            \"content_payload_key\": self.content_payload_key,\n            \"metadata_payload_key\": self.metadata_payload_key,\n        }\n\n        server_kwargs = {\n            \"host\": self.host or None,\n            \"port\": int(self.port),  # Ensure port is an integer\n            \"grpc_port\": int(self.grpc_port),  # Ensure grpc_port is an integer\n            \"api_key\": self.api_key,\n            \"prefix\": self.prefix,\n            # Ensure timeout is an integer\n            \"timeout\": int(self.timeout) if self.timeout else None,\n            \"path\": self.path or None,\n            \"url\": self.url or None,\n        }\n\n        server_kwargs = {k: v for k, v in server_kwargs.items() if v is not None}\n\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if not isinstance(self.embedding, Embeddings):\n            msg = \"Invalid embedding object\"\n            raise TypeError(msg)\n\n        if documents:\n            qdrant = Qdrant.from_documents(documents, embedding=self.embedding, **qdrant_kwargs, **server_kwargs)\n        else:\n            from qdrant_client import QdrantClient\n\n            client = QdrantClient(**server_kwargs)\n            qdrant = Qdrant(embeddings=self.embedding, client=client, **qdrant_kwargs)\n\n        return qdrant\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n"},"collection_name":{"_input_type":"StrInput","advanced":false,"display_name":"Collection Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"content_payload_key":{"_input_type":"StrInput","advanced":true,"display_name":"Content Payload Key","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"content_payload_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"page_content"},"distance_func":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Distance Function","dynamic":false,"external_options":{},"info":"","name":"distance_func","options":["Cosine","Euclidean","Dot Product"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Cosine"},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"grpc_port":{"_input_type":"IntInput","advanced":true,"display_name":"gRPC Port","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"grpc_port","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":6334},"host":{"_input_type":"StrInput","advanced":true,"display_name":"Host","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"host","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"localhost"},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"metadata_payload_key":{"_input_type":"StrInput","advanced":true,"display_name":"Metadata Payload Key","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"metadata_payload_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"metadata"},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"path":{"_input_type":"StrInput","advanced":true,"display_name":"Path","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"path","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"port":{"_input_type":"IntInput","advanced":true,"display_name":"Port","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"port","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":6333},"prefix":{"_input_type":"StrInput","advanced":true,"display_name":"Prefix","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"prefix","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"timeout":{"_input_type":"IntInput","advanced":true,"display_name":"Timeout","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"timeout","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"url":{"_input_type":"StrInput","advanced":true,"display_name":"URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"SupabaseVectorStore":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Supabase Vector Store with search capabilities","display_name":"Supabase","documentation":"","edited":false,"field_order":["supabase_url","supabase_service_key","table_name","query_name","ingest_data","search_query","should_cache_vector_store","embedding","number_of_results"],"frozen":false,"icon":"Supabase","legacy":false,"metadata":{"code_hash":"5045b81c340b","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"supabase","version":"2.22.0"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.vectorstores.supabase.SupabaseVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_community.vectorstores import SupabaseVectorStore\nfrom supabase.client import Client, create_client\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.io import HandleInput, IntInput, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass SupabaseVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Supabase\"\n    description = \"Supabase Vector Store with search capabilities\"\n    name = \"SupabaseVectorStore\"\n    icon = \"Supabase\"\n\n    inputs = [\n        StrInput(name=\"supabase_url\", display_name=\"Supabase URL\", required=True),\n        SecretStrInput(name=\"supabase_service_key\", display_name=\"Supabase Service Key\", required=True),\n        StrInput(name=\"table_name\", display_name=\"Table Name\", advanced=True),\n        StrInput(name=\"query_name\", display_name=\"Query Name\"),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> SupabaseVectorStore:\n        supabase: Client = create_client(self.supabase_url, supabase_key=self.supabase_service_key)\n\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents:\n            supabase_vs = SupabaseVectorStore.from_documents(\n                documents=documents,\n                embedding=self.embedding,\n                query_name=self.query_name,\n                client=supabase,\n                table_name=self.table_name,\n            )\n        else:\n            supabase_vs = SupabaseVectorStore(\n                client=supabase,\n                embedding=self.embedding,\n                table_name=self.table_name,\n                query_name=self.query_name,\n            )\n\n        return supabase_vs\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n"},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"query_name":{"_input_type":"StrInput","advanced":false,"display_name":"Query Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"query_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"supabase_service_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Supabase Service Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"supabase_service_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"supabase_url":{"_input_type":"StrInput","advanced":false,"display_name":"Supabase URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"supabase_url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"table_name":{"_input_type":"StrInput","advanced":true,"display_name":"Table Name","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"table_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"Upstash":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Upstash Vector Store with search capabilities","display_name":"Upstash","documentation":"","edited":false,"field_order":["index_url","index_token","text_key","namespace","ingest_data","search_query","should_cache_vector_store","metadata_filter","embedding","number_of_results"],"frozen":false,"icon":"Upstash","legacy":false,"metadata":{"code_hash":"6da6f9b3e00b","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.vectorstores.upstash.UpstashVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_community.vectorstores import UpstashVectorStore\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.io import (\n    HandleInput,\n    IntInput,\n    MultilineInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom lfx.schema.data import Data\n\n\nclass UpstashVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Upstash\"\n    description = \"Upstash Vector Store with search capabilities\"\n    name = \"Upstash\"\n    icon = \"Upstash\"\n\n    inputs = [\n        StrInput(\n            name=\"index_url\",\n            display_name=\"Index URL\",\n            info=\"The URL of the Upstash index.\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"index_token\",\n            display_name=\"Index Token\",\n            info=\"The token for the Upstash index.\",\n            required=True,\n        ),\n        StrInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"The key in the record to use as text.\",\n            value=\"text\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"namespace\",\n            display_name=\"Namespace\",\n            info=\"Leave empty for default namespace.\",\n        ),\n        *LCVectorStoreComponent.inputs,\n        MultilineInput(\n            name=\"metadata_filter\",\n            display_name=\"Metadata Filter\",\n            info=\"Filters documents by metadata. Look at the documentation for more information.\",\n        ),\n        HandleInput(\n            name=\"embedding\",\n            display_name=\"Embedding\",\n            input_types=[\"Embeddings\"],\n            info=\"To use Upstash's embeddings, don't provide an embedding.\",\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> UpstashVectorStore:\n        use_upstash_embedding = self.embedding is None\n\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents:\n            if use_upstash_embedding:\n                upstash_vs = UpstashVectorStore(\n                    embedding=use_upstash_embedding,\n                    text_key=self.text_key,\n                    index_url=self.index_url,\n                    index_token=self.index_token,\n                    namespace=self.namespace,\n                )\n                upstash_vs.add_documents(documents)\n            else:\n                upstash_vs = UpstashVectorStore.from_documents(\n                    documents=documents,\n                    embedding=self.embedding,\n                    text_key=self.text_key,\n                    index_url=self.index_url,\n                    index_token=self.index_token,\n                    namespace=self.namespace,\n                )\n        else:\n            upstash_vs = UpstashVectorStore(\n                embedding=self.embedding or use_upstash_embedding,\n                text_key=self.text_key,\n                index_url=self.index_url,\n                index_token=self.index_token,\n                namespace=self.namespace,\n            )\n\n        return upstash_vs\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n                filter=self.metadata_filter,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n"},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"To use Upstash's embeddings, don't provide an embedding.","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"index_token":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Index Token","dynamic":false,"info":"The token for the Upstash index.","input_types":[],"load_from_db":true,"name":"index_token","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"index_url":{"_input_type":"StrInput","advanced":false,"display_name":"Index URL","dynamic":false,"info":"The URL of the Upstash index.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"index_url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"metadata_filter":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Metadata Filter","dynamic":false,"info":"Filters documents by metadata. Look at the documentation for more information.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"metadata_filter","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"namespace":{"_input_type":"StrInput","advanced":false,"display_name":"Namespace","dynamic":false,"info":"Leave empty for default namespace.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"namespace","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"text_key":{"_input_type":"StrInput","advanced":true,"display_name":"Text Key","dynamic":false,"info":"The key in the record to use as text.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"text_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"text"}},"tool_mode":false},"Vectara":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Vectara Vector Store with search capabilities","display_name":"Vectara","documentation":"","edited":false,"field_order":["vectara_customer_id","vectara_corpus_id","vectara_api_key","embedding","ingest_data","search_query","should_cache_vector_store","number_of_results"],"frozen":false,"icon":"Vectara","legacy":false,"metadata":{"code_hash":"a2309e046c06","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.vectorstores.vectara.VectaraVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import TYPE_CHECKING\n\nfrom langchain_community.vectorstores import Vectara\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.io import HandleInput, IntInput, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\nif TYPE_CHECKING:\n    from lfx.schema.dataframe import DataFrame\n\n\nclass VectaraVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"Vectara Vector Store with search capabilities.\"\"\"\n\n    display_name: str = \"Vectara\"\n    description: str = \"Vectara Vector Store with search capabilities\"\n    name = \"Vectara\"\n    icon = \"Vectara\"\n\n    inputs = [\n        StrInput(name=\"vectara_customer_id\", display_name=\"Vectara Customer ID\", required=True),\n        StrInput(name=\"vectara_corpus_id\", display_name=\"Vectara Corpus ID\", required=True),\n        SecretStrInput(name=\"vectara_api_key\", display_name=\"Vectara API Key\", required=True),\n        HandleInput(\n            name=\"embedding\",\n            display_name=\"Embedding\",\n            input_types=[\"Embeddings\"],\n        ),\n        *LCVectorStoreComponent.inputs,\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> Vectara:\n        \"\"\"Builds the Vectara object.\"\"\"\n        try:\n            from langchain_community.vectorstores import Vectara\n        except ImportError as e:\n            msg = \"Could not import Vectara. Please install it with `pip install langchain-community`.\"\n            raise ImportError(msg) from e\n\n        vectara = Vectara(\n            vectara_customer_id=self.vectara_customer_id,\n            vectara_corpus_id=self.vectara_corpus_id,\n            vectara_api_key=self.vectara_api_key,\n        )\n\n        self._add_documents_to_vector_store(vectara)\n        return vectara\n\n    def _add_documents_to_vector_store(self, vector_store: Vectara) -> None:\n        \"\"\"Adds documents to the Vector Store.\"\"\"\n        ingest_data: list | Data | DataFrame = self.ingest_data\n        if not ingest_data:\n            self.status = \"No documents to add to Vectara\"\n            return\n\n        # Convert DataFrame to Data if needed using parent's method\n        ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents:\n            self.log(f\"Adding {len(documents)} documents to Vectara.\")\n            vector_store.add_documents(documents)\n            self.status = f\"Added {len(documents)} documents to Vectara\"\n        else:\n            self.log(\"No documents to add to Vectara.\")\n            self.status = \"No valid documents to add to Vectara\"\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = f\"Found {len(data)} results for the query: {self.search_query}\"\n            return data\n        self.status = \"No search query provided\"\n        return []\n"},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"vectara_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Vectara API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"vectara_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"vectara_corpus_id":{"_input_type":"StrInput","advanced":false,"display_name":"Vectara Corpus ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"vectara_corpus_id","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"vectara_customer_id":{"_input_type":"StrInput","advanced":false,"display_name":"Vectara Customer ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"vectara_customer_id","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"VectaraRAG":{"base_classes":["Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Vectara's full end to end RAG","display_name":"Vectara RAG","documentation":"https://docs.vectara.com/docs","edited":false,"field_order":["vectara_customer_id","vectara_corpus_id","vectara_api_key","search_query","lexical_interpolation","filter","reranker","reranker_k","diversity_bias","max_results","response_lang","prompt"],"frozen":false,"icon":"Vectara","legacy":false,"metadata":{"code_hash":"123c9eef9191","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"langchain_community","version":"0.3.21"}],"total_dependencies":2},"module":"lfx.components.vectorstores.vectara_rag.VectaraRagComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Answer","group_outputs":false,"method":"generate_response","name":"answer","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.custom.custom_component.component import Component\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.io import DropdownInput, FloatInput, IntInput, MessageTextInput, Output, SecretStrInput, StrInput\nfrom lfx.schema.message import Message\n\n\nclass VectaraRagComponent(Component):\n    display_name = \"Vectara RAG\"\n    description = \"Vectara's full end to end RAG\"\n    documentation = \"https://docs.vectara.com/docs\"\n    icon = \"Vectara\"\n    name = \"VectaraRAG\"\n    SUMMARIZER_PROMPTS = [\n        \"vectara-summary-ext-24-05-sml\",\n        \"vectara-summary-ext-24-05-med-omni\",\n        \"vectara-summary-ext-24-05-large\",\n        \"vectara-summary-ext-24-05-med\",\n        \"vectara-summary-ext-v1.3.0\",\n    ]\n\n    RERANKER_TYPES = [\"mmr\", \"rerank_multilingual_v1\", \"none\"]\n\n    RESPONSE_LANGUAGES = [\n        \"auto\",\n        \"eng\",\n        \"spa\",\n        \"fra\",\n        \"zho\",\n        \"deu\",\n        \"hin\",\n        \"ara\",\n        \"por\",\n        \"ita\",\n        \"jpn\",\n        \"kor\",\n        \"rus\",\n        \"tur\",\n        \"fas\",\n        \"vie\",\n        \"tha\",\n        \"heb\",\n        \"nld\",\n        \"ind\",\n        \"pol\",\n        \"ukr\",\n        \"ron\",\n        \"swe\",\n        \"ces\",\n        \"ell\",\n        \"ben\",\n        \"msa\",\n        \"urd\",\n    ]\n\n    field_order = [\"vectara_customer_id\", \"vectara_corpus_id\", \"vectara_api_key\", \"search_query\", \"reranker\"]\n\n    inputs = [\n        StrInput(name=\"vectara_customer_id\", display_name=\"Vectara Customer ID\", required=True),\n        StrInput(name=\"vectara_corpus_id\", display_name=\"Vectara Corpus ID\", required=True),\n        SecretStrInput(name=\"vectara_api_key\", display_name=\"Vectara API Key\", required=True),\n        MessageTextInput(\n            name=\"search_query\",\n            display_name=\"Search Query\",\n            info=\"The query to receive an answer on.\",\n            tool_mode=True,\n        ),\n        FloatInput(\n            name=\"lexical_interpolation\",\n            display_name=\"Hybrid Search Factor\",\n            range_spec=RangeSpec(min=0.005, max=0.1, step=0.005),\n            value=0.005,\n            advanced=True,\n            info=\"How much to weigh lexical scores compared to the embedding score. \"\n            \"0 means lexical search is not used at all, and 1 means only lexical search is used.\",\n        ),\n        MessageTextInput(\n            name=\"filter\",\n            display_name=\"Metadata Filters\",\n            value=\"\",\n            advanced=True,\n            info=\"The filter string to narrow the search to according to metadata attributes.\",\n        ),\n        DropdownInput(\n            name=\"reranker\",\n            display_name=\"Reranker Type\",\n            options=RERANKER_TYPES,\n            value=RERANKER_TYPES[0],\n            info=\"How to rerank the retrieved search results.\",\n        ),\n        IntInput(\n            name=\"reranker_k\",\n            display_name=\"Number of Results to Rerank\",\n            value=50,\n            range_spec=RangeSpec(min=1, max=100, step=1),\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"diversity_bias\",\n            display_name=\"Diversity Bias\",\n            value=0.2,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            advanced=True,\n            info=\"Ranges from 0 to 1, with higher values indicating greater diversity (only applies to MMR reranker).\",\n        ),\n        IntInput(\n            name=\"max_results\",\n            display_name=\"Max Results to Summarize\",\n            value=7,\n            range_spec=RangeSpec(min=1, max=100, step=1),\n            advanced=True,\n            info=\"The maximum number of search results to be available to the prompt.\",\n        ),\n        DropdownInput(\n            name=\"response_lang\",\n            display_name=\"Response Language\",\n            options=RESPONSE_LANGUAGES,\n            value=\"eng\",\n            advanced=True,\n            info=\"Use the ISO 639-1 or 639-3 language code or auto to automatically detect the language.\",\n        ),\n        DropdownInput(\n            name=\"prompt\",\n            display_name=\"Prompt Name\",\n            options=SUMMARIZER_PROMPTS,\n            value=SUMMARIZER_PROMPTS[0],\n            advanced=True,\n            info=\"Only vectara-summary-ext-24-05-sml is for Growth customers; \"\n            \"all other prompts are for Scale customers only.\",\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"answer\", display_name=\"Answer\", method=\"generate_response\"),\n    ]\n\n    def generate_response(\n        self,\n    ) -> Message:\n        text_output = \"\"\n\n        try:\n            from langchain_community.vectorstores import Vectara\n            from langchain_community.vectorstores.vectara import RerankConfig, SummaryConfig, VectaraQueryConfig\n        except ImportError as e:\n            msg = \"Could not import Vectara. Please install it with `pip install langchain-community`.\"\n            raise ImportError(msg) from e\n\n        vectara = Vectara(self.vectara_customer_id, self.vectara_corpus_id, self.vectara_api_key)\n        rerank_config = RerankConfig(self.reranker, self.reranker_k, self.diversity_bias)\n        summary_config = SummaryConfig(\n            is_enabled=True, max_results=self.max_results, response_lang=self.response_lang, prompt_name=self.prompt\n        )\n        config = VectaraQueryConfig(\n            lambda_val=self.lexical_interpolation,\n            filter=self.filter,\n            summary_config=summary_config,\n            rerank_config=rerank_config,\n        )\n        rag = vectara.as_rag(config)\n        response = rag.invoke(self.search_query, config={\"callbacks\": self.get_langchain_callbacks()})\n\n        text_output = response[\"answer\"]\n\n        return Message(text=text_output)\n"},"diversity_bias":{"_input_type":"FloatInput","advanced":true,"display_name":"Diversity Bias","dynamic":false,"info":"Ranges from 0 to 1, with higher values indicating greater diversity (only applies to MMR reranker).","list":false,"list_add_label":"Add More","name":"diversity_bias","placeholder":"","range_spec":{"max":1.0,"min":0.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.2},"filter":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Metadata Filters","dynamic":false,"info":"The filter string to narrow the search to according to metadata attributes.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"filter","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"lexical_interpolation":{"_input_type":"FloatInput","advanced":true,"display_name":"Hybrid Search Factor","dynamic":false,"info":"How much to weigh lexical scores compared to the embedding score. 0 means lexical search is not used at all, and 1 means only lexical search is used.","list":false,"list_add_label":"Add More","name":"lexical_interpolation","placeholder":"","range_spec":{"max":0.1,"min":0.005,"step":0.005,"step_type":"float"},"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.005},"max_results":{"_input_type":"IntInput","advanced":true,"display_name":"Max Results to Summarize","dynamic":false,"info":"The maximum number of search results to be available to the prompt.","list":false,"list_add_label":"Add More","name":"max_results","placeholder":"","range_spec":{"max":100.0,"min":1.0,"step":1.0,"step_type":"float"},"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":7},"prompt":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Prompt Name","dynamic":false,"external_options":{},"info":"Only vectara-summary-ext-24-05-sml is for Growth customers; all other prompts are for Scale customers only.","name":"prompt","options":["vectara-summary-ext-24-05-sml","vectara-summary-ext-24-05-med-omni","vectara-summary-ext-24-05-large","vectara-summary-ext-24-05-med","vectara-summary-ext-v1.3.0"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"vectara-summary-ext-24-05-sml"},"reranker":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Reranker Type","dynamic":false,"external_options":{},"info":"How to rerank the retrieved search results.","name":"reranker","options":["mmr","rerank_multilingual_v1","none"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"mmr"},"reranker_k":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results to Rerank","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"reranker_k","placeholder":"","range_spec":{"max":100.0,"min":1.0,"step":1.0,"step_type":"float"},"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":50},"response_lang":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Response Language","dynamic":false,"external_options":{},"info":"Use the ISO 639-1 or 639-3 language code or auto to automatically detect the language.","name":"response_lang","options":["auto","eng","spa","fra","zho","deu","hin","ara","por","ita","jpn","kor","rus","tur","fas","vie","tha","heb","nld","ind","pol","ukr","ron","swe","ces","ell","ben","msa","urd"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"eng"},"search_query":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"The query to receive an answer on.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"vectara_api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Vectara API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"vectara_api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"vectara_corpus_id":{"_input_type":"StrInput","advanced":false,"display_name":"Vectara Corpus ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"vectara_corpus_id","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"vectara_customer_id":{"_input_type":"StrInput","advanced":false,"display_name":"Vectara Customer ID","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"vectara_customer_id","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"Weaviate":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Weaviate Vector Store with search capabilities","display_name":"Weaviate","documentation":"","edited":false,"field_order":["url","api_key","index_name","text_key","ingest_data","search_query","should_cache_vector_store","embedding","number_of_results","search_by_text"],"frozen":false,"icon":"Weaviate","legacy":false,"metadata":{"code_hash":"66ba91d6a440","dependencies":{"dependencies":[{"name":"weaviate","version":"4.10.2"},{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.vectorstores.weaviate.WeaviateVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Weaviate API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import weaviate\nfrom langchain_community.vectorstores import Weaviate\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.io import BoolInput, HandleInput, IntInput, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass WeaviateVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Weaviate\"\n    description = \"Weaviate Vector Store with search capabilities\"\n    name = \"Weaviate\"\n    icon = \"Weaviate\"\n\n    inputs = [\n        StrInput(name=\"url\", display_name=\"Weaviate URL\", value=\"http://localhost:8080\", required=True),\n        SecretStrInput(name=\"api_key\", display_name=\"Weaviate API Key\", required=False),\n        StrInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            required=True,\n            info=\"Requires capitalized index name.\",\n        ),\n        StrInput(name=\"text_key\", display_name=\"Text Key\", value=\"text\", advanced=True),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n        BoolInput(name=\"search_by_text\", display_name=\"Search By Text\", advanced=True),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> Weaviate:\n        if self.api_key:\n            auth_config = weaviate.AuthApiKey(api_key=self.api_key)\n            client = weaviate.Client(url=self.url, auth_client_secret=auth_config)\n        else:\n            client = weaviate.Client(url=self.url)\n\n        if self.index_name != self.index_name.capitalize():\n            msg = f\"Weaviate requires the index name to be capitalized. Use: {self.index_name.capitalize()}\"\n            raise ValueError(msg)\n\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents and self.embedding:\n            return Weaviate.from_documents(\n                client=client,\n                index_name=self.index_name,\n                documents=documents,\n                embedding=self.embedding,\n                by_text=self.search_by_text,\n            )\n\n        return Weaviate(\n            client=client,\n            index_name=self.index_name,\n            text_key=self.text_key,\n            embedding=self.embedding,\n            by_text=self.search_by_text,\n        )\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n"},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"index_name":{"_input_type":"StrInput","advanced":false,"display_name":"Index Name","dynamic":false,"info":"Requires capitalized index name.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"index_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"search_by_text":{"_input_type":"BoolInput","advanced":true,"display_name":"Search By Text","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"search_by_text","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"text_key":{"_input_type":"StrInput","advanced":true,"display_name":"Text Key","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"text_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"text"},"url":{"_input_type":"StrInput","advanced":false,"display_name":"Weaviate URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"http://localhost:8080"}},"tool_mode":false},"pgvector":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"PGVector Vector Store with search capabilities","display_name":"PGVector","documentation":"","edited":false,"field_order":["pg_server_url","collection_name","ingest_data","search_query","should_cache_vector_store","embedding","number_of_results"],"frozen":false,"icon":"cpu","legacy":false,"metadata":{"code_hash":"50117607bf5e","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.vectorstores.pgvector.PGVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_community.vectorstores import PGVector\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.io import HandleInput, IntInput, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\nfrom lfx.utils.connection_string_parser import transform_connection_string\n\n\nclass PGVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"PGVector\"\n    description = \"PGVector Vector Store with search capabilities\"\n    name = \"pgvector\"\n    icon = \"cpu\"\n\n    inputs = [\n        SecretStrInput(name=\"pg_server_url\", display_name=\"PostgreSQL Server Connection String\", required=True),\n        StrInput(name=\"collection_name\", display_name=\"Table\", required=True),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"], required=True),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> PGVector:\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        connection_string_parsed = transform_connection_string(self.pg_server_url)\n\n        if documents:\n            pgvector = PGVector.from_documents(\n                embedding=self.embedding,\n                documents=documents,\n                collection_name=self.collection_name,\n                connection_string=connection_string_parsed,\n            )\n        else:\n            pgvector = PGVector.from_existing_index(\n                embedding=self.embedding,\n                collection_name=self.collection_name,\n                connection_string=connection_string_parsed,\n            )\n\n        return pgvector\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n"},"collection_name":{"_input_type":"StrInput","advanced":false,"display_name":"Table","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"collection_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":true,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"pg_server_url":{"_input_type":"SecretStrInput","advanced":false,"display_name":"PostgreSQL Server Connection String","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"pg_server_url","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false}}],["vertexai",{"VertexAIEmbeddings":{"base_classes":["Embeddings"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate embeddings using Google Cloud Vertex AI models.","display_name":"Vertex AI Embeddings","documentation":"","edited":false,"field_order":["credentials","location","project","max_output_tokens","max_retries","model_name","n","request_parallelism","stop_sequences","streaming","temperature","top_k","top_p"],"frozen":false,"icon":"VertexAI","legacy":false,"metadata":{"code_hash":"3abd5c15264a","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"langchain_google_vertexai","version":"2.0.20"},{"name":"google","version":"0.8.5"}],"total_dependencies":3},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.vertexai.vertexai_embeddings.VertexAIEmbeddingsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Embeddings","group_outputs":false,"method":"build_embeddings","name":"embeddings","selected":"Embeddings","tool_mode":true,"types":["Embeddings"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import Embeddings\nfrom lfx.io import BoolInput, FileInput, FloatInput, IntInput, MessageTextInput, Output\n\n\nclass VertexAIEmbeddingsComponent(LCModelComponent):\n    display_name = \"Vertex AI Embeddings\"\n    description = \"Generate embeddings using Google Cloud Vertex AI models.\"\n    icon = \"VertexAI\"\n    name = \"VertexAIEmbeddings\"\n\n    inputs = [\n        FileInput(\n            name=\"credentials\",\n            display_name=\"Credentials\",\n            info=\"JSON credentials file. Leave empty to fallback to environment variables\",\n            value=\"\",\n            file_types=[\"json\"],\n            required=True,\n        ),\n        MessageTextInput(name=\"location\", display_name=\"Location\", value=\"us-central1\", advanced=True),\n        MessageTextInput(name=\"project\", display_name=\"Project\", info=\"The project ID.\", advanced=True),\n        IntInput(name=\"max_output_tokens\", display_name=\"Max Output Tokens\", advanced=True),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=1, advanced=True),\n        MessageTextInput(name=\"model_name\", display_name=\"Model Name\", value=\"textembedding-gecko\", required=True),\n        IntInput(name=\"n\", display_name=\"N\", value=1, advanced=True),\n        IntInput(name=\"request_parallelism\", value=5, display_name=\"Request Parallelism\", advanced=True),\n        MessageTextInput(name=\"stop_sequences\", display_name=\"Stop\", advanced=True, is_list=True),\n        BoolInput(name=\"streaming\", display_name=\"Streaming\", value=False, advanced=True),\n        FloatInput(name=\"temperature\", value=0.0, display_name=\"Temperature\"),\n        IntInput(name=\"top_k\", display_name=\"Top K\", advanced=True),\n        FloatInput(name=\"top_p\", display_name=\"Top P\", value=0.95, advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        try:\n            from langchain_google_vertexai import VertexAIEmbeddings\n        except ImportError as e:\n            msg = \"Please install the langchain-google-vertexai package to use the VertexAIEmbeddings component.\"\n            raise ImportError(msg) from e\n\n        from google.oauth2 import service_account\n\n        if self.credentials:\n            gcloud_credentials = service_account.Credentials.from_service_account_file(self.credentials)\n        else:\n            # will fallback to environment variable or inferred from gcloud CLI\n            gcloud_credentials = None\n        return VertexAIEmbeddings(\n            credentials=gcloud_credentials,\n            location=self.location,\n            max_output_tokens=self.max_output_tokens or None,\n            max_retries=self.max_retries,\n            model_name=self.model_name,\n            n=self.n,\n            project=self.project,\n            request_parallelism=self.request_parallelism,\n            stop=self.stop_sequences or None,\n            streaming=self.streaming,\n            temperature=self.temperature,\n            top_k=self.top_k or None,\n            top_p=self.top_p,\n        )\n"},"credentials":{"_input_type":"FileInput","advanced":false,"display_name":"Credentials","dynamic":false,"fileTypes":["json"],"file_path":"","info":"JSON credentials file. Leave empty to fallback to environment variables","list":false,"list_add_label":"Add More","name":"credentials","placeholder":"","required":true,"show":true,"temp_file":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"file","value":""},"location":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Location","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"location","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"us-central1"},"max_output_tokens":{"_input_type":"IntInput","advanced":true,"display_name":"Max Output Tokens","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"max_output_tokens","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"max_retries":{"_input_type":"IntInput","advanced":true,"display_name":"Max Retries","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"max_retries","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1},"model_name":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Model Name","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"model_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"textembedding-gecko"},"n":{"_input_type":"IntInput","advanced":true,"display_name":"N","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"n","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1},"project":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Project","dynamic":false,"info":"The project ID.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"project","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"request_parallelism":{"_input_type":"IntInput","advanced":true,"display_name":"Request Parallelism","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"request_parallelism","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5},"stop_sequences":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Stop","dynamic":false,"info":"","input_types":["Message"],"list":true,"list_add_label":"Add More","load_from_db":false,"name":"stop_sequences","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"streaming":{"_input_type":"BoolInput","advanced":true,"display_name":"Streaming","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"streaming","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"temperature":{"_input_type":"FloatInput","advanced":false,"display_name":"Temperature","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"temperature","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.0},"top_k":{"_input_type":"IntInput","advanced":true,"display_name":"Top K","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"top_k","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"top_p":{"_input_type":"FloatInput","advanced":true,"display_name":"Top P","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"top_p","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.95}},"tool_mode":false},"VertexAiModel":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generate text using Vertex AI LLMs.","display_name":"Vertex AI","documentation":"","edited":false,"field_order":["input_value","system_message","stream","credentials","model_name","project","location","max_output_tokens","max_retries","temperature","top_k","top_p","verbose"],"frozen":false,"icon":"VertexAI","legacy":false,"metadata":{"code_hash":"d9f75281d3fa","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"langchain_google_vertexai","version":"2.0.20"},{"name":"google","version":"0.8.5"}],"total_dependencies":3},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.vertexai.vertexai.ChatVertexAIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import cast\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import LanguageModel\nfrom lfx.inputs.inputs import MessageTextInput\nfrom lfx.io import BoolInput, FileInput, FloatInput, IntInput, StrInput\n\n\nclass ChatVertexAIComponent(LCModelComponent):\n    display_name = \"Vertex AI\"\n    description = \"Generate text using Vertex AI LLMs.\"\n    icon = \"VertexAI\"\n    name = \"VertexAiModel\"\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        FileInput(\n            name=\"credentials\",\n            display_name=\"Credentials\",\n            info=\"JSON credentials file. Leave empty to fallback to environment variables\",\n            file_types=[\"json\"],\n        ),\n        MessageTextInput(name=\"model_name\", display_name=\"Model Name\", value=\"gemini-1.5-pro\"),\n        StrInput(name=\"project\", display_name=\"Project\", info=\"The project ID.\", advanced=True),\n        StrInput(name=\"location\", display_name=\"Location\", value=\"us-central1\", advanced=True),\n        IntInput(name=\"max_output_tokens\", display_name=\"Max Output Tokens\", advanced=True),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=1, advanced=True),\n        FloatInput(name=\"temperature\", value=0.0, display_name=\"Temperature\"),\n        IntInput(name=\"top_k\", display_name=\"Top K\", advanced=True),\n        FloatInput(name=\"top_p\", display_name=\"Top P\", value=0.95, advanced=True),\n        BoolInput(name=\"verbose\", display_name=\"Verbose\", value=False, advanced=True),\n    ]\n\n    def build_model(self) -> LanguageModel:\n        try:\n            from langchain_google_vertexai import ChatVertexAI\n        except ImportError as e:\n            msg = \"Please install the langchain-google-vertexai package to use the VertexAIEmbeddings component.\"\n            raise ImportError(msg) from e\n        location = self.location or None\n        if self.credentials:\n            from google.cloud import aiplatform\n            from google.oauth2 import service_account\n\n            credentials = service_account.Credentials.from_service_account_file(self.credentials)\n            project = self.project or credentials.project_id\n            # ChatVertexAI sometimes skip manual credentials initialization\n            aiplatform.init(\n                project=project,\n                location=location,\n                credentials=credentials,\n            )\n        else:\n            project = self.project or None\n            credentials = None\n\n        return cast(\n            \"LanguageModel\",\n            ChatVertexAI(\n                credentials=credentials,\n                location=location,\n                project=project,\n                max_output_tokens=self.max_output_tokens or None,\n                max_retries=self.max_retries,\n                model_name=self.model_name,\n                temperature=self.temperature,\n                top_k=self.top_k or None,\n                top_p=self.top_p,\n                verbose=self.verbose,\n            ),\n        )\n"},"credentials":{"_input_type":"FileInput","advanced":false,"display_name":"Credentials","dynamic":false,"fileTypes":["json"],"file_path":"","info":"JSON credentials file. Leave empty to fallback to environment variables","list":false,"list_add_label":"Add More","name":"credentials","placeholder":"","required":false,"show":true,"temp_file":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"file","value":""},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"location":{"_input_type":"StrInput","advanced":true,"display_name":"Location","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"location","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"us-central1"},"max_output_tokens":{"_input_type":"IntInput","advanced":true,"display_name":"Max Output Tokens","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"max_output_tokens","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"max_retries":{"_input_type":"IntInput","advanced":true,"display_name":"Max Retries","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"max_retries","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1},"model_name":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Model Name","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"model_name","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"gemini-1.5-pro"},"project":{"_input_type":"StrInput","advanced":true,"display_name":"Project","dynamic":false,"info":"The project ID.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"project","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"FloatInput","advanced":false,"display_name":"Temperature","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"temperature","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.0},"top_k":{"_input_type":"IntInput","advanced":true,"display_name":"Top K","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"top_k","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"top_p":{"_input_type":"FloatInput","advanced":true,"display_name":"Top P","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"top_p","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"float","value":0.95},"verbose":{"_input_type":"BoolInput","advanced":true,"display_name":"Verbose","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"verbose","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false}}],["vlmrun",{"VLMRunTranscription":{"base_classes":["Data"],"beta":true,"conditional_paths":[],"custom_fields":{},"description":"Extract structured data from audio and video using [VLM Run AI](https://app.vlm.run)","display_name":"VLM Run Transcription","documentation":"https://docs.vlm.run","edited":false,"field_order":["api_key","media_type","media_files","media_url","timeout_seconds","domain"],"frozen":false,"icon":"VLMRun","legacy":false,"metadata":{"code_hash":"c91e2349a3df","dependencies":{"dependencies":[{"name":"langflow","version":null},{"name":"loguru","version":"0.7.3"},{"name":"vlmrun","version":"0.3.5"}],"total_dependencies":3},"module":"lfx.components.vlmrun.vlmrun_transcription.VLMRunTranscription"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Result","group_outputs":false,"method":"process_media","name":"result","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"VLM Run API Key","dynamic":false,"info":"Get your API key from https://app.vlm.run","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from pathlib import Path\nfrom urllib.parse import urlparse\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import (\n    DropdownInput,\n    FileInput,\n    IntInput,\n    MessageTextInput,\n    Output,\n    SecretStrInput,\n)\nfrom langflow.schema.data import Data\nfrom loguru import logger\n\n\nclass VLMRunTranscription(Component):\n    display_name = \"VLM Run Transcription\"\n    description = \"Extract structured data from audio and video using [VLM Run AI](https://app.vlm.run)\"\n    documentation = \"https://docs.vlm.run\"\n    icon = \"VLMRun\"\n    beta = True\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"VLM Run API Key\",\n            info=\"Get your API key from https://app.vlm.run\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"media_type\",\n            display_name=\"Media Type\",\n            options=[\"audio\", \"video\"],\n            value=\"audio\",\n            info=\"Select the type of media to process\",\n        ),\n        FileInput(\n            name=\"media_files\",\n            display_name=\"Media Files\",\n            file_types=[\n                \"mp3\",\n                \"wav\",\n                \"m4a\",\n                \"flac\",\n                \"ogg\",\n                \"opus\",\n                \"webm\",\n                \"aac\",\n                \"mp4\",\n                \"mov\",\n                \"avi\",\n                \"mkv\",\n                \"flv\",\n                \"wmv\",\n                \"m4v\",\n            ],\n            info=\"Upload one or more audio/video files\",\n            required=False,\n            is_list=True,\n        ),\n        MessageTextInput(\n            name=\"media_url\",\n            display_name=\"Media URL\",\n            info=\"URL to media file (alternative to file upload)\",\n            required=False,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"timeout_seconds\",\n            display_name=\"Timeout (seconds)\",\n            value=600,\n            info=\"Maximum time to wait for processing completion\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"domain\",\n            display_name=\"Processing Domain\",\n            options=[\"transcription\"],\n            value=\"transcription\",\n            info=\"Select the processing domain\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Result\",\n            name=\"result\",\n            method=\"process_media\",\n        ),\n    ]\n\n    def _check_inputs(self) -> str | None:\n        \"\"\"Validate that either media files or URL is provided.\"\"\"\n        if not self.media_files and not self.media_url:\n            return \"Either media files or media URL must be provided\"\n        return None\n\n    def _import_vlmrun(self):\n        \"\"\"Import and return VLMRun client class.\"\"\"\n        try:\n            from vlmrun.client import VLMRun\n        except ImportError as e:\n            error_msg = \"VLM Run SDK not installed. Run: pip install 'vlmrun[all]'\"\n            raise ImportError(error_msg) from e\n        else:\n            return VLMRun\n\n    def _generate_media_response(self, client, media_source):\n        \"\"\"Generate response for audio or video media.\"\"\"\n        domain_str = f\"{self.media_type}.{self.domain}\"\n\n        if self.media_type == \"audio\":\n            if isinstance(media_source, Path):\n                return client.audio.generate(file=media_source, domain=domain_str, batch=True)\n            return client.audio.generate(url=media_source, domain=domain_str, batch=True)\n        # video\n        if isinstance(media_source, Path):\n            return client.video.generate(file=media_source, domain=domain_str, batch=True)\n        return client.video.generate(url=media_source, domain=domain_str, batch=True)\n\n    def _wait_for_response(self, client, response):\n        \"\"\"Wait for batch processing to complete if needed.\"\"\"\n        if hasattr(response, \"id\"):\n            return client.predictions.wait(response.id, timeout=self.timeout_seconds)\n        return response\n\n    def _extract_transcription(self, segments: list) -> list[str]:\n        \"\"\"Extract transcription parts from segments.\"\"\"\n        transcription_parts = []\n        for segment in segments:\n            if self.media_type == \"audio\" and \"audio\" in segment:\n                transcription_parts.append(segment[\"audio\"].get(\"content\", \"\"))\n            elif self.media_type == \"video\" and \"video\" in segment:\n                transcription_parts.append(segment[\"video\"].get(\"content\", \"\"))\n                # Also include audio if available for video\n                if \"audio\" in segment:\n                    audio_content = segment[\"audio\"].get(\"content\", \"\")\n                    if audio_content and audio_content.strip():\n                        transcription_parts.append(f\"[Audio: {audio_content}]\")\n        return transcription_parts\n\n    def _create_result_dict(self, response, transcription_parts: list, source_name: str) -> dict:\n        \"\"\"Create a standardized result dictionary.\"\"\"\n        response_data = response.response if hasattr(response, \"response\") else {}\n        result = {\n            \"prediction_id\": response.id if hasattr(response, \"id\") else None,\n            \"transcription\": \" \".join(transcription_parts),\n            \"full_response\": response_data,\n            \"metadata\": {\n                \"media_type\": self.media_type,\n                \"duration\": response_data.get(\"metadata\", {}).get(\"duration\", 0),\n            },\n            \"usage\": response.usage if hasattr(response, \"usage\") else None,\n            \"status\": response.status if hasattr(response, \"status\") else \"completed\",\n        }\n\n        # Add source-specific field\n        parsed_url = urlparse(source_name)\n        if parsed_url.scheme in [\"http\", \"https\", \"s3\", \"gs\", \"ftp\", \"ftps\"]:\n            result[\"source\"] = source_name\n        else:\n            result[\"filename\"] = source_name\n\n        return result\n\n    def _process_single_media(self, client, media_source, source_name: str) -> dict:\n        \"\"\"Process a single media file or URL.\"\"\"\n        response = self._generate_media_response(client, media_source)\n        response = self._wait_for_response(client, response)\n        response_data = response.response if hasattr(response, \"response\") else {}\n        segments = response_data.get(\"segments\", [])\n        transcription_parts = self._extract_transcription(segments)\n        return self._create_result_dict(response, transcription_parts, source_name)\n\n    def process_media(self) -> Data:\n        \"\"\"Process audio or video file and extract structured data.\"\"\"\n        # Validate inputs\n        error_msg = self._check_inputs()\n        if error_msg:\n            self.status = error_msg\n            return Data(data={\"error\": error_msg})\n\n        try:\n            # Import and initialize client\n            vlmrun_class = self._import_vlmrun()\n            client = vlmrun_class(api_key=self.api_key)\n            all_results = []\n\n            # Handle multiple files\n            if self.media_files:\n                files_to_process = self.media_files if isinstance(self.media_files, list) else [self.media_files]\n                for idx, media_file in enumerate(files_to_process):\n                    self.status = f\"Processing file {idx + 1} of {len(files_to_process)}...\"\n                    result = self._process_single_media(client, Path(media_file), Path(media_file).name)\n                    all_results.append(result)\n\n            # Handle URL\n            elif self.media_url:\n                result = self._process_single_media(client, self.media_url, self.media_url)\n                all_results.append(result)\n\n            # Return clean, flexible output structure\n            output_data = {\n                \"results\": all_results,\n                \"total_files\": len(all_results),\n            }\n            self.status = f\"Successfully processed {len(all_results)} file(s)\"\n            return Data(data=output_data)\n\n        except ImportError as e:\n            self.status = str(e)\n            return Data(data={\"error\": str(e)})\n        except (ValueError, ConnectionError, TimeoutError) as e:\n            logger.opt(exception=True).debug(\"Error processing media with VLM Run\")\n            error_msg = f\"Processing failed: {e!s}\"\n            self.status = error_msg\n            return Data(data={\"error\": error_msg})\n        except (AttributeError, KeyError, OSError) as e:\n            logger.opt(exception=True).debug(\"Unexpected error processing media with VLM Run\")\n            error_msg = f\"Unexpected error: {e!s}\"\n            self.status = error_msg\n            return Data(data={\"error\": error_msg})\n"},"domain":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Processing Domain","dynamic":false,"external_options":{},"info":"Select the processing domain","name":"domain","options":["transcription"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"transcription"},"media_files":{"_input_type":"FileInput","advanced":false,"display_name":"Media Files","dynamic":false,"fileTypes":["mp3","wav","m4a","flac","ogg","opus","webm","aac","mp4","mov","avi","mkv","flv","wmv","m4v"],"file_path":"","info":"Upload one or more audio/video files","list":true,"list_add_label":"Add More","name":"media_files","placeholder":"","required":false,"show":true,"temp_file":false,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"file","value":""},"media_type":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Media Type","dynamic":false,"external_options":{},"info":"Select the type of media to process","name":"media_type","options":["audio","video"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"audio"},"media_url":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Media URL","dynamic":false,"info":"URL to media file (alternative to file upload)","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"media_url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"timeout_seconds":{"_input_type":"IntInput","advanced":true,"display_name":"Timeout (seconds)","dynamic":false,"info":"Maximum time to wait for processing completion","list":false,"list_add_label":"Add More","name":"timeout_seconds","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":600}},"tool_mode":false}}],["weaviate",{"Weaviate":{"base_classes":["Data","DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Weaviate Vector Store with search capabilities","display_name":"Weaviate","documentation":"","edited":false,"field_order":["url","api_key","index_name","text_key","ingest_data","search_query","should_cache_vector_store","embedding","number_of_results","search_by_text"],"frozen":false,"icon":"Weaviate","legacy":false,"metadata":{"code_hash":"ccc9f1e0149d","dependencies":{"dependencies":[{"name":"weaviate","version":"4.10.2"},{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.weaviate.weaviate.WeaviateVectorStoreComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_documents","name":"search_results","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"as_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"API Key","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import weaviate\nfrom langchain_community.vectorstores import Weaviate\n\nfrom lfx.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom lfx.helpers.data import docs_to_data\nfrom lfx.io import BoolInput, HandleInput, IntInput, SecretStrInput, StrInput\nfrom lfx.schema.data import Data\n\n\nclass WeaviateVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Weaviate\"\n    description = \"Weaviate Vector Store with search capabilities\"\n    name = \"Weaviate\"\n    icon = \"Weaviate\"\n\n    inputs = [\n        StrInput(name=\"url\", display_name=\"Weaviate URL\", value=\"http://localhost:8080\", required=True),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\", required=False),\n        StrInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            required=True,\n            info=\"Requires capitalized index name.\",\n        ),\n        StrInput(name=\"text_key\", display_name=\"Text Key\", value=\"text\", advanced=True),\n        *LCVectorStoreComponent.inputs,\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n        BoolInput(name=\"search_by_text\", display_name=\"Search By Text\", advanced=True),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> Weaviate:\n        if self.api_key:\n            auth_config = weaviate.AuthApiKey(api_key=self.api_key)\n            client = weaviate.Client(url=self.url, auth_client_secret=auth_config)\n        else:\n            client = weaviate.Client(url=self.url)\n\n        if self.index_name != self.index_name.capitalize():\n            msg = f\"Weaviate requires the index name to be capitalized. Use: {self.index_name.capitalize()}\"\n            raise ValueError(msg)\n\n        # Convert DataFrame to Data if needed using parent's method\n        self.ingest_data = self._prepare_ingest_data()\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents and self.embedding:\n            return Weaviate.from_documents(\n                client=client,\n                index_name=self.index_name,\n                documents=documents,\n                embedding=self.embedding,\n                by_text=self.search_by_text,\n            )\n\n        return Weaviate(\n            client=client,\n            index_name=self.index_name,\n            text_key=self.text_key,\n            embedding=self.embedding,\n            by_text=self.search_by_text,\n        )\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n"},"embedding":{"_input_type":"HandleInput","advanced":false,"display_name":"Embedding","dynamic":false,"info":"","input_types":["Embeddings"],"list":false,"list_add_label":"Add More","name":"embedding","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"index_name":{"_input_type":"StrInput","advanced":false,"display_name":"Index Name","dynamic":false,"info":"Requires capitalized index name.","list":false,"list_add_label":"Add More","load_from_db":false,"name":"index_name","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"ingest_data":{"_input_type":"HandleInput","advanced":false,"display_name":"Ingest Data","dynamic":false,"info":"","input_types":["Data","DataFrame"],"list":true,"list_add_label":"Add More","name":"ingest_data","placeholder":"","required":false,"show":true,"title_case":false,"trace_as_metadata":true,"type":"other","value":""},"number_of_results":{"_input_type":"IntInput","advanced":true,"display_name":"Number of Results","dynamic":false,"info":"Number of results to return.","list":false,"list_add_label":"Add More","name":"number_of_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"search_by_text":{"_input_type":"BoolInput","advanced":true,"display_name":"Search By Text","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"search_by_text","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"search_query":{"_input_type":"QueryInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"Enter a query to run a similarity search.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"search_query","placeholder":"Enter a query...","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"query","value":""},"should_cache_vector_store":{"_input_type":"BoolInput","advanced":true,"display_name":"Cache Vector Store","dynamic":false,"info":"If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.","list":false,"list_add_label":"Add More","name":"should_cache_vector_store","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"text_key":{"_input_type":"StrInput","advanced":true,"display_name":"Text Key","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"text_key","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"text"},"url":{"_input_type":"StrInput","advanced":false,"display_name":"Weaviate URL","dynamic":false,"info":"","list":false,"list_add_label":"Add More","load_from_db":false,"name":"url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"http://localhost:8080"}},"tool_mode":false}}],["wikipedia",{"WikidataComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Performs a search using the Wikidata API.","display_name":"Wikidata","documentation":"","edited":false,"field_order":["query"],"frozen":false,"icon":"Wikipedia","legacy":false,"metadata":{"code_hash":"59df9d399440","dependencies":{"dependencies":[{"name":"httpx","version":"0.28.1"},{"name":"langchain_core","version":"0.3.79"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.wikipedia.wikidata.WikidataComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"fetch_content_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import httpx\nfrom httpx import HTTPError\nfrom langchain_core.tools import ToolException\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import MultilineInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.template.field.base import Output\n\n\nclass WikidataComponent(Component):\n    display_name = \"Wikidata\"\n    description = \"Performs a search using the Wikidata API.\"\n    icon = \"Wikipedia\"\n\n    inputs = [\n        MultilineInput(\n            name=\"query\",\n            display_name=\"Query\",\n            info=\"The text query for similarity search on Wikidata.\",\n            required=True,\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"fetch_content_dataframe\"),\n    ]\n\n    def run_model(self) -> DataFrame:\n        return self.fetch_content_dataframe()\n\n    def fetch_content(self) -> list[Data]:\n        try:\n            # Define request parameters for Wikidata API\n            params = {\n                \"action\": \"wbsearchentities\",\n                \"format\": \"json\",\n                \"search\": self.query,\n                \"language\": \"en\",\n            }\n\n            # Send request to Wikidata API\n            wikidata_api_url = \"https://www.wikidata.org/w/api.php\"\n            response = httpx.get(wikidata_api_url, params=params)\n            response.raise_for_status()\n            response_json = response.json()\n\n            # Extract search results\n            results = response_json.get(\"search\", [])\n\n            if not results:\n                return [Data(data={\"error\": \"No search results found for the given query.\"})]\n\n            # Transform the API response into Data objects\n            data = [\n                Data(\n                    text=f\"{result['label']}: {result.get('description', '')}\",\n                    data={\n                        \"label\": result[\"label\"],\n                        \"id\": result.get(\"id\"),\n                        \"url\": result.get(\"url\"),\n                        \"description\": result.get(\"description\", \"\"),\n                        \"concepturi\": result.get(\"concepturi\"),\n                    },\n                )\n                for result in results\n            ]\n\n            self.status = data\n        except HTTPError as e:\n            error_message = f\"HTTP Error in Wikidata Search API: {e!s}\"\n            raise ToolException(error_message) from None\n        except KeyError as e:\n            error_message = f\"Data parsing error in Wikidata API response: {e!s}\"\n            raise ToolException(error_message) from None\n        except ValueError as e:\n            error_message = f\"Value error in Wikidata API: {e!s}\"\n            raise ToolException(error_message) from None\n        else:\n            return data\n\n    def fetch_content_dataframe(self) -> DataFrame:\n        data = self.fetch_content()\n        return DataFrame(data)\n"},"query":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Query","dynamic":false,"info":"The text query for similarity search on Wikidata.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"query","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"WikipediaComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Call Wikipedia API.","display_name":"Wikipedia","documentation":"","edited":false,"field_order":["input_value","lang","k","load_all_available_meta","doc_content_chars_max"],"frozen":false,"icon":"Wikipedia","legacy":false,"metadata":{"code_hash":"cc13e26c79c4","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.wikipedia.wikipedia.WikipediaComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"fetch_content_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_community.utilities.wikipedia import WikipediaAPIWrapper\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import BoolInput, IntInput, MessageTextInput, MultilineInput\nfrom lfx.io import Output\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\n\n\nclass WikipediaComponent(Component):\n    display_name = \"Wikipedia\"\n    description = \"Call Wikipedia API.\"\n    icon = \"Wikipedia\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            tool_mode=True,\n        ),\n        MessageTextInput(name=\"lang\", display_name=\"Language\", value=\"en\"),\n        IntInput(name=\"k\", display_name=\"Number of results\", value=4, required=True),\n        BoolInput(name=\"load_all_available_meta\", display_name=\"Load all available meta\", value=False, advanced=True),\n        IntInput(\n            name=\"doc_content_chars_max\", display_name=\"Document content characters max\", value=4000, advanced=True\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"fetch_content_dataframe\"),\n    ]\n\n    def run_model(self) -> DataFrame:\n        return self.fetch_content_dataframe()\n\n    def _build_wrapper(self) -> WikipediaAPIWrapper:\n        return WikipediaAPIWrapper(\n            top_k_results=self.k,\n            lang=self.lang,\n            load_all_available_meta=self.load_all_available_meta,\n            doc_content_chars_max=self.doc_content_chars_max,\n        )\n\n    def fetch_content(self) -> list[Data]:\n        wrapper = self._build_wrapper()\n        docs = wrapper.load(self.input_value)\n        data = [Data.from_document(doc) for doc in docs]\n        self.status = data\n        return data\n\n    def fetch_content_dataframe(self) -> DataFrame:\n        data = self.fetch_content()\n        return DataFrame(data)\n"},"doc_content_chars_max":{"_input_type":"IntInput","advanced":true,"display_name":"Document content characters max","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"doc_content_chars_max","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4000},"input_value":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"k":{"_input_type":"IntInput","advanced":false,"display_name":"Number of results","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"k","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":4},"lang":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Language","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"lang","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"en"},"load_all_available_meta":{"_input_type":"BoolInput","advanced":true,"display_name":"Load all available meta","dynamic":false,"info":"","list":false,"list_add_label":"Add More","name":"load_all_available_meta","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false}},"tool_mode":false}}],["wolframalpha",{"WolframAlphaAPI":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Enables queries to WolframAlpha for computational data, facts, and calculations across various topics, delivering structured responses.","display_name":"WolframAlpha API","documentation":"","edited":false,"field_order":["input_value","app_id"],"frozen":false,"icon":"WolframAlphaAPI","legacy":false,"metadata":{"code_hash":"86caf22224ad","dependencies":{"dependencies":[{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.wolframalpha.wolfram_alpha_api.WolframAlphaAPIComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"fetch_content_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","app_id":{"_input_type":"SecretStrInput","advanced":false,"display_name":"WolframAlpha App ID","dynamic":false,"info":"","input_types":[],"load_from_db":true,"name":"app_id","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from langchain_community.utilities.wolfram_alpha import WolframAlphaAPIWrapper\n\nfrom lfx.base.langchain_utilities.model import LCToolComponent\nfrom lfx.field_typing import Tool\nfrom lfx.inputs.inputs import MultilineInput, SecretStrInput\nfrom lfx.io import Output\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\n\n\nclass WolframAlphaAPIComponent(LCToolComponent):\n    display_name = \"WolframAlpha API\"\n    description = \"\"\"Enables queries to WolframAlpha for computational data, facts, and calculations across various \\\ntopics, delivering structured responses.\"\"\"\n    name = \"WolframAlphaAPI\"\n\n    outputs = [\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"fetch_content_dataframe\"),\n    ]\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\", display_name=\"Input Query\", info=\"Example query: 'What is the population of France?'\"\n        ),\n        SecretStrInput(name=\"app_id\", display_name=\"WolframAlpha App ID\", required=True),\n    ]\n\n    icon = \"WolframAlphaAPI\"\n\n    def run_model(self) -> DataFrame:\n        return self.fetch_content_dataframe()\n\n    def build_tool(self) -> Tool:\n        wrapper = self._build_wrapper()\n        return Tool(name=\"wolfram_alpha_api\", description=\"Answers mathematical questions.\", func=wrapper.run)\n\n    def _build_wrapper(self) -> WolframAlphaAPIWrapper:\n        return WolframAlphaAPIWrapper(wolfram_alpha_appid=self.app_id)\n\n    def fetch_content(self) -> list[Data]:\n        wrapper = self._build_wrapper()\n        result_str = wrapper.run(self.input_value)\n        data = [Data(text=result_str)]\n        self.status = data\n        return data\n\n    def fetch_content_dataframe(self) -> DataFrame:\n        \"\"\"Convert the WolframAlpha results to a DataFrame.\n\n        Returns:\n            DataFrame: A DataFrame containing the query results.\n        \"\"\"\n        data = self.fetch_content()\n        return DataFrame(data)\n"},"input_value":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Input Query","dynamic":false,"info":"Example query: 'What is the population of France?'","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["xai",{"xAIModel":{"base_classes":["LanguageModel","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Generates text using xAI models like Grok.","display_name":"xAI","documentation":"","edited":false,"field_order":["input_value","system_message","stream","max_tokens","model_kwargs","json_mode","model_name","base_url","api_key","temperature","seed"],"frozen":false,"icon":"xAI","legacy":false,"metadata":{"code_hash":"ef0eb1cfadeb","dependencies":{"dependencies":[{"name":"requests","version":"2.32.5"},{"name":"langchain_openai","version":"0.3.23"},{"name":"pydantic","version":"2.10.6"},{"name":"typing_extensions","version":"4.15.0"},{"name":"lfx","version":null},{"name":"openai","version":"1.82.1"}],"total_dependencies":6},"keywords":["model","llm","language model","large language model"],"module":"lfx.components.xai.xai.XAIModelComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Model Response","group_outputs":false,"method":"text_response","name":"text_output","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Language Model","group_outputs":false,"method":"build_model","name":"model_output","selected":"LanguageModel","tool_mode":true,"types":["LanguageModel"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"xAI API Key","dynamic":false,"info":"The xAI API Key to use for the model.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":"XAI_API_KEY"},"base_url":{"_input_type":"MessageTextInput","advanced":true,"display_name":"xAI API Base","dynamic":false,"info":"The base URL of the xAI API. Defaults to https://api.x.ai/v1","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"base_url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":"https://api.x.ai/v1"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import requests\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\nfrom typing_extensions import override\n\nfrom lfx.base.models.model import LCModelComponent\nfrom lfx.field_typing import LanguageModel\nfrom lfx.field_typing.range_spec import RangeSpec\nfrom lfx.inputs.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    IntInput,\n    MessageTextInput,\n    SecretStrInput,\n    SliderInput,\n)\n\nXAI_DEFAULT_MODELS = [\"grok-2-latest\"]\n\n\nclass XAIModelComponent(LCModelComponent):\n    display_name = \"xAI\"\n    description = \"Generates text using xAI models like Grok.\"\n    icon = \"xAI\"\n    name = \"xAIModel\"\n\n    inputs = [\n        *LCModelComponent.get_base_inputs(),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=XAI_DEFAULT_MODELS,\n            value=XAI_DEFAULT_MODELS[0],\n            refresh_button=True,\n            combobox=True,\n            info=\"The xAI model to use\",\n        ),\n        MessageTextInput(\n            name=\"base_url\",\n            display_name=\"xAI API Base\",\n            advanced=True,\n            info=\"The base URL of the xAI API. Defaults to https://api.x.ai/v1\",\n            value=\"https://api.x.ai/v1\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"xAI API Key\",\n            info=\"The xAI API Key to use for the model.\",\n            advanced=False,\n            value=\"XAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=2, step=0.01),\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def get_models(self) -> list[str]:\n        \"\"\"Fetch available models from xAI API.\"\"\"\n        if not self.api_key:\n            return XAI_DEFAULT_MODELS\n\n        base_url = self.base_url or \"https://api.x.ai/v1\"\n        url = f\"{base_url}/language-models\"\n        headers = {\"Authorization\": f\"Bearer {self.api_key}\", \"Accept\": \"application/json\"}\n\n        try:\n            response = requests.get(url, headers=headers, timeout=10)\n            response.raise_for_status()\n            data = response.json()\n\n            # Extract model IDs and any aliases\n            models = set()\n            for model in data.get(\"models\", []):\n                models.add(model[\"id\"])\n                models.update(model.get(\"aliases\", []))\n\n            return sorted(models) if models else XAI_DEFAULT_MODELS\n        except requests.RequestException as e:\n            self.status = f\"Error fetching models: {e}\"\n            return XAI_DEFAULT_MODELS\n\n    @override\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\n        \"\"\"Update build configuration with fresh model list when key fields change.\"\"\"\n        if field_name in {\"api_key\", \"base_url\", \"model_name\"}:\n            models = self.get_models()\n            build_config[\"model_name\"][\"options\"] = models\n        return build_config\n\n    def build_model(self) -> LanguageModel:\n        api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        base_url = self.base_url or \"https://api.x.ai/v1\"\n        json_mode = self.json_mode\n        seed = self.seed\n\n        api_key = SecretStr(api_key).get_secret_value() if api_key else None\n\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=base_url,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n\n        if json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an xAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n"},"input_value":{"_input_type":"MessageInput","advanced":false,"display_name":"Input","dynamic":false,"info":"","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"input_value","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"json_mode":{"_input_type":"BoolInput","advanced":true,"display_name":"JSON Mode","dynamic":false,"info":"If True, it will output JSON regardless of passing a schema.","list":false,"list_add_label":"Add More","name":"json_mode","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"max_tokens":{"_input_type":"IntInput","advanced":true,"display_name":"Max Tokens","dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","list":false,"list_add_label":"Add More","name":"max_tokens","placeholder":"","range_spec":{"max":128000.0,"min":0.0,"step":0.1,"step_type":"float"},"required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":""},"model_kwargs":{"_input_type":"DictInput","advanced":true,"display_name":"Model Kwargs","dynamic":false,"info":"Additional keyword arguments to pass to the model.","list":false,"list_add_label":"Add More","name":"model_kwargs","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"type":"dict","value":{}},"model_name":{"_input_type":"DropdownInput","advanced":false,"combobox":true,"dialog_inputs":{},"display_name":"Model Name","dynamic":false,"external_options":{},"info":"The xAI model to use","name":"model_name","options":["grok-2-latest"],"options_metadata":[],"placeholder":"","refresh_button":true,"required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"grok-2-latest"},"seed":{"_input_type":"IntInput","advanced":true,"display_name":"Seed","dynamic":false,"info":"The seed controls the reproducibility of the job.","list":false,"list_add_label":"Add More","name":"seed","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":1},"stream":{"_input_type":"BoolInput","advanced":true,"display_name":"Stream","dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","list":false,"list_add_label":"Add More","name":"stream","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"system_message":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"System Message","dynamic":false,"info":"System message to pass to the model.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"system_message","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"temperature":{"_input_type":"SliderInput","advanced":true,"display_name":"Temperature","dynamic":false,"info":"","max_label":"","max_label_icon":"","min_label":"","min_label_icon":"","name":"temperature","placeholder":"","range_spec":{"max":2.0,"min":0.0,"step":0.01,"step_type":"float"},"required":false,"show":true,"slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"title_case":false,"tool_mode":false,"type":"slider","value":0.1}},"tool_mode":false}}],["yahoosearch",{"YfinanceComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Uses [yfinance](https://pypi.org/project/yfinance/) (unofficial package) to access financial data and market information from Yahoo! Finance.","display_name":"Yahoo! Finance","documentation":"","edited":false,"field_order":["symbol","method","num_news"],"frozen":false,"icon":"trending-up","legacy":false,"metadata":{"code_hash":"d6bf628ab821","dependencies":{"dependencies":[{"name":"yfinance","version":"0.2.50"},{"name":"langchain_core","version":"0.3.79"},{"name":"pydantic","version":"2.10.6"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.yahoosearch.yahoo.YfinanceComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"DataFrame","group_outputs":false,"method":"fetch_content_dataframe","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import ast\nimport pprint\nfrom enum import Enum\n\nimport yfinance as yf\nfrom langchain_core.tools import ToolException\nfrom pydantic import BaseModel, Field\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import DropdownInput, IntInput, MessageTextInput\nfrom lfx.io import Output\nfrom lfx.log.logger import logger\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\n\n\nclass YahooFinanceMethod(Enum):\n    GET_INFO = \"get_info\"\n    GET_NEWS = \"get_news\"\n    GET_ACTIONS = \"get_actions\"\n    GET_ANALYSIS = \"get_analysis\"\n    GET_BALANCE_SHEET = \"get_balance_sheet\"\n    GET_CALENDAR = \"get_calendar\"\n    GET_CASHFLOW = \"get_cashflow\"\n    GET_INSTITUTIONAL_HOLDERS = \"get_institutional_holders\"\n    GET_RECOMMENDATIONS = \"get_recommendations\"\n    GET_SUSTAINABILITY = \"get_sustainability\"\n    GET_MAJOR_HOLDERS = \"get_major_holders\"\n    GET_MUTUALFUND_HOLDERS = \"get_mutualfund_holders\"\n    GET_INSIDER_PURCHASES = \"get_insider_purchases\"\n    GET_INSIDER_TRANSACTIONS = \"get_insider_transactions\"\n    GET_INSIDER_ROSTER_HOLDERS = \"get_insider_roster_holders\"\n    GET_DIVIDENDS = \"get_dividends\"\n    GET_CAPITAL_GAINS = \"get_capital_gains\"\n    GET_SPLITS = \"get_splits\"\n    GET_SHARES = \"get_shares\"\n    GET_FAST_INFO = \"get_fast_info\"\n    GET_SEC_FILINGS = \"get_sec_filings\"\n    GET_RECOMMENDATIONS_SUMMARY = \"get_recommendations_summary\"\n    GET_UPGRADES_DOWNGRADES = \"get_upgrades_downgrades\"\n    GET_EARNINGS = \"get_earnings\"\n    GET_INCOME_STMT = \"get_income_stmt\"\n\n\nclass YahooFinanceSchema(BaseModel):\n    symbol: str = Field(..., description=\"The stock symbol to retrieve data for.\")\n    method: YahooFinanceMethod = Field(YahooFinanceMethod.GET_INFO, description=\"The type of data to retrieve.\")\n    num_news: int | None = Field(5, description=\"The number of news articles to retrieve.\")\n\n\nclass YfinanceComponent(Component):\n    display_name = \"Yahoo! Finance\"\n    description = \"\"\"Uses [yfinance](https://pypi.org/project/yfinance/) (unofficial package) \\\nto access financial data and market information from Yahoo! Finance.\"\"\"\n    icon = \"trending-up\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"symbol\",\n            display_name=\"Stock Symbol\",\n            info=\"The stock symbol to retrieve data for (e.g., AAPL, GOOG).\",\n            tool_mode=True,\n        ),\n        DropdownInput(\n            name=\"method\",\n            display_name=\"Data Method\",\n            info=\"The type of data to retrieve.\",\n            options=list(YahooFinanceMethod),\n            value=\"get_news\",\n        ),\n        IntInput(\n            name=\"num_news\",\n            display_name=\"Number of News\",\n            info=\"The number of news articles to retrieve (only applicable for get_news).\",\n            value=5,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"fetch_content_dataframe\"),\n    ]\n\n    def run_model(self) -> DataFrame:\n        return self.fetch_content_dataframe()\n\n    def _fetch_yfinance_data(self, ticker: yf.Ticker, method: YahooFinanceMethod, num_news: int | None) -> str:\n        try:\n            if method == YahooFinanceMethod.GET_INFO:\n                result = ticker.info\n            elif method == YahooFinanceMethod.GET_NEWS:\n                result = ticker.news[:num_news]\n            else:\n                result = getattr(ticker, method.value)()\n            return pprint.pformat(result)\n        except Exception as e:\n            error_message = f\"Error retrieving data: {e}\"\n            logger.debug(error_message)\n            self.status = error_message\n            raise ToolException(error_message) from e\n\n    def fetch_content(self) -> list[Data]:\n        try:\n            return self._yahoo_finance_tool(\n                self.symbol,\n                YahooFinanceMethod(self.method),\n                self.num_news,\n            )\n        except ToolException:\n            raise\n        except Exception as e:\n            error_message = f\"Unexpected error: {e}\"\n            logger.debug(error_message)\n            self.status = error_message\n            raise ToolException(error_message) from e\n\n    def _yahoo_finance_tool(\n        self,\n        symbol: str,\n        method: YahooFinanceMethod,\n        num_news: int | None = 5,\n    ) -> list[Data]:\n        ticker = yf.Ticker(symbol)\n        result = self._fetch_yfinance_data(ticker, method, num_news)\n\n        if method == YahooFinanceMethod.GET_NEWS:\n            data_list = [\n                Data(text=f\"{article['title']}: {article['link']}\", data=article)\n                for article in ast.literal_eval(result)\n            ]\n        else:\n            data_list = [Data(text=result, data={\"result\": result})]\n\n        return data_list\n\n    def fetch_content_dataframe(self) -> DataFrame:\n        data = self.fetch_content()\n        return DataFrame(data)\n"},"method":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Data Method","dynamic":false,"external_options":{},"info":"The type of data to retrieve.","name":"method","options":["get_info","get_news","get_actions","get_analysis","get_balance_sheet","get_calendar","get_cashflow","get_institutional_holders","get_recommendations","get_sustainability","get_major_holders","get_mutualfund_holders","get_insider_purchases","get_insider_transactions","get_insider_roster_holders","get_dividends","get_capital_gains","get_splits","get_shares","get_fast_info","get_sec_filings","get_recommendations_summary","get_upgrades_downgrades","get_earnings","get_income_stmt"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"get_news"},"num_news":{"_input_type":"IntInput","advanced":false,"display_name":"Number of News","dynamic":false,"info":"The number of news articles to retrieve (only applicable for get_news).","list":false,"list_add_label":"Add More","name":"num_news","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":5},"symbol":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Stock Symbol","dynamic":false,"info":"The stock symbol to retrieve data for (e.g., AAPL, GOOG).","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"symbol","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["youtube",{"YouTubeChannelComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Retrieves detailed information and statistics about YouTube channels as a DataFrame.","display_name":"YouTube Channel","documentation":"","edited":false,"field_order":["channel_url","api_key","include_statistics","include_branding","include_playlists"],"frozen":false,"icon":"YouTube","legacy":false,"metadata":{"code_hash":"c889afb883fa","dependencies":{"dependencies":[{"name":"pandas","version":"2.2.3"},{"name":"googleapiclient","version":"2.154.0"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.youtube.channel.YouTubeChannelComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Channel Info","group_outputs":false,"method":"get_channel_info","name":"channel_df","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"YouTube API Key","dynamic":false,"info":"Your YouTube Data API key.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"channel_url":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Channel URL or ID","dynamic":false,"info":"The URL or ID of the YouTube channel.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"channel_url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from typing import Any\nfrom urllib.error import HTTPError\n\nimport pandas as pd\nfrom googleapiclient.discovery import build\nfrom googleapiclient.errors import HttpError\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import BoolInput, MessageTextInput, SecretStrInput\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.template.field.base import Output\n\n\nclass YouTubeChannelComponent(Component):\n    \"\"\"A component that retrieves detailed information about YouTube channels.\"\"\"\n\n    display_name: str = \"YouTube Channel\"\n    description: str = \"Retrieves detailed information and statistics about YouTube channels as a DataFrame.\"\n    icon: str = \"YouTube\"\n\n    # Constants\n    CHANNEL_ID_LENGTH = 24\n    QUOTA_EXCEEDED_STATUS = 403\n    NOT_FOUND_STATUS = 404\n    MAX_PLAYLIST_RESULTS = 10\n\n    inputs = [\n        MessageTextInput(\n            name=\"channel_url\",\n            display_name=\"Channel URL or ID\",\n            info=\"The URL or ID of the YouTube channel.\",\n            tool_mode=True,\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"YouTube API Key\",\n            info=\"Your YouTube Data API key.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"include_statistics\",\n            display_name=\"Include Statistics\",\n            value=True,\n            info=\"Include channel statistics (views, subscribers, videos).\",\n        ),\n        BoolInput(\n            name=\"include_branding\",\n            display_name=\"Include Branding\",\n            value=True,\n            info=\"Include channel branding settings (banner, thumbnails).\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_playlists\",\n            display_name=\"Include Playlists\",\n            value=False,\n            info=\"Include channel's public playlists.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"channel_df\", display_name=\"Channel Info\", method=\"get_channel_info\"),\n    ]\n\n    def _extract_channel_id(self, channel_url: str) -> str:\n        \"\"\"Extracts the channel ID from various YouTube channel URL formats.\"\"\"\n        import re\n\n        if channel_url.startswith(\"UC\") and len(channel_url) == self.CHANNEL_ID_LENGTH:\n            return channel_url\n\n        patterns = {\n            \"custom_url\": r\"youtube\\.com\\/c\\/([^\\/\\n?]+)\",\n            \"channel_id\": r\"youtube\\.com\\/channel\\/([^\\/\\n?]+)\",\n            \"user\": r\"youtube\\.com\\/user\\/([^\\/\\n?]+)\",\n            \"handle\": r\"youtube\\.com\\/@([^\\/\\n?]+)\",\n        }\n\n        for pattern_type, pattern in patterns.items():\n            match = re.search(pattern, channel_url)\n            if match:\n                if pattern_type == \"channel_id\":\n                    return match.group(1)\n                return self._get_channel_id_by_name(match.group(1), pattern_type)\n\n        return channel_url\n\n    def _get_channel_id_by_name(self, channel_name: str, identifier_type: str) -> str:\n        \"\"\"Gets the channel ID using the channel name or custom URL.\"\"\"\n        youtube = None\n        try:\n            youtube = build(\"youtube\", \"v3\", developerKey=self.api_key)\n\n            if identifier_type == \"handle\":\n                channel_name = channel_name.lstrip(\"@\")\n\n            request = youtube.search().list(part=\"id\", q=channel_name, type=\"channel\", maxResults=1)\n            response = request.execute()\n\n            if response[\"items\"]:\n                return response[\"items\"][0][\"id\"][\"channelId\"]\n\n            error_msg = f\"Could not find channel ID for: {channel_name}\"\n            raise ValueError(error_msg)\n\n        except (HttpError, HTTPError) as e:\n            error_msg = f\"YouTube API error while getting channel ID: {e!s}\"\n            raise RuntimeError(error_msg) from e\n        except Exception as e:\n            error_msg = f\"Unexpected error while getting channel ID: {e!s}\"\n            raise ValueError(error_msg) from e\n        finally:\n            if youtube:\n                youtube.close()\n\n    def _get_channel_playlists(self, youtube: Any, channel_id: str) -> list[dict[str, Any]]:\n        \"\"\"Gets the public playlists for a channel.\"\"\"\n        try:\n            playlists_request = youtube.playlists().list(\n                part=\"snippet,contentDetails\",\n                channelId=channel_id,\n                maxResults=self.MAX_PLAYLIST_RESULTS,\n            )\n            playlists_response = playlists_request.execute()\n            playlists = []\n\n            for item in playlists_response.get(\"items\", []):\n                playlist_data = {\n                    \"playlist_title\": item[\"snippet\"][\"title\"],\n                    \"playlist_description\": item[\"snippet\"][\"description\"],\n                    \"playlist_id\": item[\"id\"],\n                    \"playlist_video_count\": item[\"contentDetails\"][\"itemCount\"],\n                    \"playlist_published_at\": item[\"snippet\"][\"publishedAt\"],\n                    \"playlist_thumbnail_url\": item[\"snippet\"][\"thumbnails\"][\"default\"][\"url\"],\n                }\n                playlists.append(playlist_data)\n\n            return playlists\n        except (HttpError, HTTPError) as e:\n            return [{\"error\": str(e)}]\n        else:\n            return playlists\n\n    def get_channel_info(self) -> DataFrame:\n        \"\"\"Retrieves channel information and returns it as a DataFrame.\"\"\"\n        youtube = None\n        try:\n            # Get channel ID and initialize YouTube API client\n            channel_id = self._extract_channel_id(self.channel_url)\n            youtube = build(\"youtube\", \"v3\", developerKey=self.api_key)\n\n            # Prepare parts for the API request\n            parts = [\"snippet\", \"contentDetails\"]\n            if self.include_statistics:\n                parts.append(\"statistics\")\n            if self.include_branding:\n                parts.append(\"brandingSettings\")\n\n            # Get channel information\n            channel_response = youtube.channels().list(part=\",\".join(parts), id=channel_id).execute()\n\n            if not channel_response[\"items\"]:\n                return DataFrame(pd.DataFrame({\"error\": [\"Channel not found\"]}))\n\n            channel_info = channel_response[\"items\"][0]\n\n            # Build basic channel data\n            channel_data = {\n                \"title\": [channel_info[\"snippet\"][\"title\"]],\n                \"description\": [channel_info[\"snippet\"][\"description\"]],\n                \"custom_url\": [channel_info[\"snippet\"].get(\"customUrl\", \"\")],\n                \"published_at\": [channel_info[\"snippet\"][\"publishedAt\"]],\n                \"country\": [channel_info[\"snippet\"].get(\"country\", \"Not specified\")],\n                \"channel_id\": [channel_id],\n            }\n\n            # Add thumbnails\n            for size, thumb in channel_info[\"snippet\"][\"thumbnails\"].items():\n                channel_data[f\"thumbnail_{size}\"] = [thumb[\"url\"]]\n\n            # Add statistics if requested\n            if self.include_statistics:\n                stats = channel_info[\"statistics\"]\n                channel_data.update(\n                    {\n                        \"view_count\": [int(stats.get(\"viewCount\", 0))],\n                        \"subscriber_count\": [int(stats.get(\"subscriberCount\", 0))],\n                        \"hidden_subscriber_count\": [stats.get(\"hiddenSubscriberCount\", False)],\n                        \"video_count\": [int(stats.get(\"videoCount\", 0))],\n                    }\n                )\n\n            # Add branding if requested\n            if self.include_branding:\n                branding = channel_info.get(\"brandingSettings\", {})\n                channel_data.update(\n                    {\n                        \"brand_title\": [branding.get(\"channel\", {}).get(\"title\", \"\")],\n                        \"brand_description\": [branding.get(\"channel\", {}).get(\"description\", \"\")],\n                        \"brand_keywords\": [branding.get(\"channel\", {}).get(\"keywords\", \"\")],\n                        \"brand_banner_url\": [branding.get(\"image\", {}).get(\"bannerExternalUrl\", \"\")],\n                    }\n                )\n\n            # Create the initial DataFrame\n            channel_df = pd.DataFrame(channel_data)\n\n            # Add playlists if requested\n            if self.include_playlists:\n                playlists = self._get_channel_playlists(youtube, channel_id)\n                if playlists and \"error\" not in playlists[0]:\n                    # Create a DataFrame for playlists\n                    playlists_df = pd.DataFrame(playlists)\n                    # Join with main DataFrame\n                    channel_df = pd.concat([channel_df] * len(playlists_df), ignore_index=True)\n                    for column in playlists_df.columns:\n                        channel_df[column] = playlists_df[column].to_numpy()\n\n            return DataFrame(channel_df)\n\n        except (HttpError, HTTPError) as e:\n            return DataFrame(pd.DataFrame({\"error\": [str(e)]}))\n        finally:\n            if youtube:\n                youtube.close()\n"},"include_branding":{"_input_type":"BoolInput","advanced":true,"display_name":"Include Branding","dynamic":false,"info":"Include channel branding settings (banner, thumbnails).","list":false,"list_add_label":"Add More","name":"include_branding","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"include_playlists":{"_input_type":"BoolInput","advanced":true,"display_name":"Include Playlists","dynamic":false,"info":"Include channel's public playlists.","list":false,"list_add_label":"Add More","name":"include_playlists","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"include_statistics":{"_input_type":"BoolInput","advanced":false,"display_name":"Include Statistics","dynamic":false,"info":"Include channel statistics (views, subscribers, videos).","list":false,"list_add_label":"Add More","name":"include_statistics","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true}},"tool_mode":false},"YouTubeCommentsComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Retrieves and analyzes comments from YouTube videos.","display_name":"YouTube Comments","documentation":"","edited":false,"field_order":["video_url","api_key","max_results","sort_by","include_replies","include_metrics"],"frozen":false,"icon":"YouTube","legacy":false,"metadata":{"code_hash":"20398e0d18df","dependencies":{"dependencies":[{"name":"pandas","version":"2.2.3"},{"name":"googleapiclient","version":"2.154.0"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.youtube.comments.YouTubeCommentsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Comments","group_outputs":false,"method":"get_video_comments","name":"comments","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"YouTube API Key","dynamic":false,"info":"Your YouTube Data API key.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from contextlib import contextmanager\n\nimport pandas as pd\nfrom googleapiclient.discovery import build\nfrom googleapiclient.errors import HttpError\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import BoolInput, DropdownInput, IntInput, MessageTextInput, SecretStrInput\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.template.field.base import Output\n\n\nclass YouTubeCommentsComponent(Component):\n    \"\"\"A component that retrieves comments from YouTube videos.\"\"\"\n\n    display_name: str = \"YouTube Comments\"\n    description: str = \"Retrieves and analyzes comments from YouTube videos.\"\n    icon: str = \"YouTube\"\n\n    # Constants\n    COMMENTS_DISABLED_STATUS = 403\n    NOT_FOUND_STATUS = 404\n    API_MAX_RESULTS = 100\n\n    inputs = [\n        MessageTextInput(\n            name=\"video_url\",\n            display_name=\"Video URL\",\n            info=\"The URL of the YouTube video to get comments from.\",\n            tool_mode=True,\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"YouTube API Key\",\n            info=\"Your YouTube Data API key.\",\n            required=True,\n        ),\n        IntInput(\n            name=\"max_results\",\n            display_name=\"Max Results\",\n            value=20,\n            info=\"The maximum number of comments to return.\",\n        ),\n        DropdownInput(\n            name=\"sort_by\",\n            display_name=\"Sort By\",\n            options=[\"time\", \"relevance\"],\n            value=\"relevance\",\n            info=\"Sort comments by time or relevance.\",\n        ),\n        BoolInput(\n            name=\"include_replies\",\n            display_name=\"Include Replies\",\n            value=False,\n            info=\"Whether to include replies to comments.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_metrics\",\n            display_name=\"Include Metrics\",\n            value=True,\n            info=\"Include metrics like like count and reply count.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"comments\", display_name=\"Comments\", method=\"get_video_comments\"),\n    ]\n\n    def _extract_video_id(self, video_url: str) -> str:\n        \"\"\"Extracts the video ID from a YouTube URL.\"\"\"\n        import re\n\n        patterns = [\n            r\"(?:youtube\\.com\\/watch\\?v=|youtu.be\\/|youtube.com\\/embed\\/)([^&\\n?#]+)\",\n            r\"youtube.com\\/shorts\\/([^&\\n?#]+)\",\n        ]\n\n        for pattern in patterns:\n            match = re.search(pattern, video_url)\n            if match:\n                return match.group(1)\n\n        return video_url.strip()\n\n    def _process_reply(self, reply: dict, parent_id: str, *, include_metrics: bool = True) -> dict:\n        \"\"\"Process a single reply comment.\"\"\"\n        reply_snippet = reply[\"snippet\"]\n        reply_data = {\n            \"comment_id\": reply[\"id\"],\n            \"parent_comment_id\": parent_id,\n            \"author\": reply_snippet[\"authorDisplayName\"],\n            \"text\": reply_snippet[\"textDisplay\"],\n            \"published_at\": reply_snippet[\"publishedAt\"],\n            \"is_reply\": True,\n        }\n        if include_metrics:\n            reply_data[\"like_count\"] = reply_snippet[\"likeCount\"]\n            reply_data[\"reply_count\"] = 0  # Replies can't have replies\n\n        return reply_data\n\n    def _process_comment(\n        self, item: dict, *, include_metrics: bool = True, include_replies: bool = False\n    ) -> list[dict]:\n        \"\"\"Process a single comment thread.\"\"\"\n        comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n        comment_id = item[\"snippet\"][\"topLevelComment\"][\"id\"]\n\n        # Basic comment data\n        processed_comments = [\n            {\n                \"comment_id\": comment_id,\n                \"parent_comment_id\": \"\",  # Empty for top-level comments\n                \"author\": comment[\"authorDisplayName\"],\n                \"author_channel_url\": comment.get(\"authorChannelUrl\", \"\"),\n                \"text\": comment[\"textDisplay\"],\n                \"published_at\": comment[\"publishedAt\"],\n                \"updated_at\": comment[\"updatedAt\"],\n                \"is_reply\": False,\n            }\n        ]\n\n        # Add metrics if requested\n        if include_metrics:\n            processed_comments[0].update(\n                {\n                    \"like_count\": comment[\"likeCount\"],\n                    \"reply_count\": item[\"snippet\"][\"totalReplyCount\"],\n                }\n            )\n\n        # Add replies if requested\n        if include_replies and item[\"snippet\"][\"totalReplyCount\"] > 0 and \"replies\" in item:\n            for reply in item[\"replies\"][\"comments\"]:\n                reply_data = self._process_reply(reply, parent_id=comment_id, include_metrics=include_metrics)\n                processed_comments.append(reply_data)\n\n        return processed_comments\n\n    @contextmanager\n    def youtube_client(self):\n        \"\"\"Context manager for YouTube API client.\"\"\"\n        client = build(\"youtube\", \"v3\", developerKey=self.api_key)\n        try:\n            yield client\n        finally:\n            client.close()\n\n    def get_video_comments(self) -> DataFrame:\n        \"\"\"Retrieves comments from a YouTube video and returns as DataFrame.\"\"\"\n        try:\n            # Extract video ID from URL\n            video_id = self._extract_video_id(self.video_url)\n\n            # Use context manager for YouTube API client\n            with self.youtube_client() as youtube:\n                comments_data = []\n                results_count = 0\n                request = youtube.commentThreads().list(\n                    part=\"snippet,replies\",\n                    videoId=video_id,\n                    maxResults=min(self.API_MAX_RESULTS, self.max_results),\n                    order=self.sort_by,\n                    textFormat=\"plainText\",\n                )\n\n                while request and results_count < self.max_results:\n                    response = request.execute()\n\n                    for item in response.get(\"items\", []):\n                        if results_count >= self.max_results:\n                            break\n\n                        comments = self._process_comment(\n                            item, include_metrics=self.include_metrics, include_replies=self.include_replies\n                        )\n                        comments_data.extend(comments)\n                        results_count += 1\n\n                    # Get the next page if available and needed\n                    if \"nextPageToken\" in response and results_count < self.max_results:\n                        request = youtube.commentThreads().list(\n                            part=\"snippet,replies\",\n                            videoId=video_id,\n                            maxResults=min(self.API_MAX_RESULTS, self.max_results - results_count),\n                            order=self.sort_by,\n                            textFormat=\"plainText\",\n                            pageToken=response[\"nextPageToken\"],\n                        )\n                    else:\n                        request = None\n\n                # Convert to DataFrame\n                comments_df = pd.DataFrame(comments_data)\n\n                # Add video metadata\n                comments_df[\"video_id\"] = video_id\n                comments_df[\"video_url\"] = self.video_url\n\n                # Sort columns for better organization\n                column_order = [\n                    \"video_id\",\n                    \"video_url\",\n                    \"comment_id\",\n                    \"parent_comment_id\",\n                    \"is_reply\",\n                    \"author\",\n                    \"author_channel_url\",\n                    \"text\",\n                    \"published_at\",\n                    \"updated_at\",\n                ]\n\n                if self.include_metrics:\n                    column_order.extend([\"like_count\", \"reply_count\"])\n\n                comments_df = comments_df[column_order]\n\n                return DataFrame(comments_df)\n\n        except HttpError as e:\n            error_message = f\"YouTube API error: {e!s}\"\n            if e.resp.status == self.COMMENTS_DISABLED_STATUS:\n                error_message = \"Comments are disabled for this video or API quota exceeded.\"\n            elif e.resp.status == self.NOT_FOUND_STATUS:\n                error_message = \"Video not found.\"\n\n            return DataFrame(pd.DataFrame({\"error\": [error_message]}))\n"},"include_metrics":{"_input_type":"BoolInput","advanced":true,"display_name":"Include Metrics","dynamic":false,"info":"Include metrics like like count and reply count.","list":false,"list_add_label":"Add More","name":"include_metrics","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"include_replies":{"_input_type":"BoolInput","advanced":true,"display_name":"Include Replies","dynamic":false,"info":"Whether to include replies to comments.","list":false,"list_add_label":"Add More","name":"include_replies","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":false},"max_results":{"_input_type":"IntInput","advanced":false,"display_name":"Max Results","dynamic":false,"info":"The maximum number of comments to return.","list":false,"list_add_label":"Add More","name":"max_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":20},"sort_by":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Sort By","dynamic":false,"external_options":{},"info":"Sort comments by time or relevance.","name":"sort_by","options":["time","relevance"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"relevance"},"video_url":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Video URL","dynamic":false,"info":"The URL of the YouTube video to get comments from.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"video_url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"YouTubePlaylistComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Extracts all video URLs from a YouTube playlist.","display_name":"YouTube Playlist","documentation":"","edited":false,"field_order":["playlist_url"],"frozen":false,"icon":"YouTube","legacy":false,"metadata":{"code_hash":"2d6ac9665d53","dependencies":{"dependencies":[{"name":"pytube","version":"15.0.0"},{"name":"lfx","version":null}],"total_dependencies":2},"module":"lfx.components.youtube.playlist.YouTubePlaylistComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Video URLs","group_outputs":false,"method":"extract_video_urls","name":"video_urls","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from pytube import Playlist  # Ensure you have pytube installed\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import MessageTextInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.template.field.base import Output\n\n\nclass YouTubePlaylistComponent(Component):\n    display_name = \"YouTube Playlist\"\n    description = \"Extracts all video URLs from a YouTube playlist.\"\n    icon = \"YouTube\"  # Replace with a suitable icon\n\n    inputs = [\n        MessageTextInput(\n            name=\"playlist_url\",\n            display_name=\"Playlist URL\",\n            info=\"URL of the YouTube playlist.\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Video URLs\", name=\"video_urls\", method=\"extract_video_urls\"),\n    ]\n\n    def extract_video_urls(self) -> DataFrame:\n        playlist_url = self.playlist_url\n        playlist = Playlist(playlist_url)\n        video_urls = [video.watch_url for video in playlist.videos]\n\n        return DataFrame([Data(data={\"video_url\": url}) for url in video_urls])\n"},"playlist_url":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Playlist URL","dynamic":false,"info":"URL of the YouTube playlist.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"playlist_url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"YouTubeSearchComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Searches YouTube videos based on query.","display_name":"YouTube Search","documentation":"","edited":false,"field_order":["query","api_key","max_results","order","include_metadata"],"frozen":false,"icon":"YouTube","legacy":false,"metadata":{"code_hash":"1c4a94a094e2","dependencies":{"dependencies":[{"name":"pandas","version":"2.2.3"},{"name":"googleapiclient","version":"2.154.0"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.youtube.search.YouTubeSearchComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Search Results","group_outputs":false,"method":"search_videos","name":"results","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"YouTube API Key","dynamic":false,"info":"Your YouTube Data API key.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from contextlib import contextmanager\n\nimport pandas as pd\nfrom googleapiclient.discovery import build\nfrom googleapiclient.errors import HttpError\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import BoolInput, DropdownInput, IntInput, MessageTextInput, SecretStrInput\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.template.field.base import Output\n\n\nclass YouTubeSearchComponent(Component):\n    \"\"\"A component that searches YouTube videos.\"\"\"\n\n    display_name: str = \"YouTube Search\"\n    description: str = \"Searches YouTube videos based on query.\"\n    icon: str = \"YouTube\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"Search Query\",\n            info=\"The search query to look for on YouTube.\",\n            tool_mode=True,\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"YouTube API Key\",\n            info=\"Your YouTube Data API key.\",\n            required=True,\n        ),\n        IntInput(\n            name=\"max_results\",\n            display_name=\"Max Results\",\n            value=10,\n            info=\"The maximum number of results to return.\",\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Sort Order\",\n            options=[\"relevance\", \"date\", \"rating\", \"title\", \"viewCount\"],\n            value=\"relevance\",\n            info=\"Sort order for the search results.\",\n        ),\n        BoolInput(\n            name=\"include_metadata\",\n            display_name=\"Include Metadata\",\n            value=True,\n            info=\"Include video metadata like description and statistics.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"results\", display_name=\"Search Results\", method=\"search_videos\"),\n    ]\n\n    @contextmanager\n    def youtube_client(self):\n        \"\"\"Context manager for YouTube API client.\"\"\"\n        client = build(\"youtube\", \"v3\", developerKey=self.api_key)\n        try:\n            yield client\n        finally:\n            client.close()\n\n    def search_videos(self) -> DataFrame:\n        \"\"\"Searches YouTube videos and returns results as DataFrame.\"\"\"\n        try:\n            with self.youtube_client() as youtube:\n                search_response = (\n                    youtube.search()\n                    .list(\n                        q=self.query,\n                        part=\"id,snippet\",\n                        maxResults=self.max_results,\n                        order=self.order,\n                        type=\"video\",\n                    )\n                    .execute()\n                )\n\n                results = []\n                for search_result in search_response.get(\"items\", []):\n                    video_id = search_result[\"id\"][\"videoId\"]\n                    snippet = search_result[\"snippet\"]\n\n                    result = {\n                        \"video_id\": video_id,\n                        \"title\": snippet[\"title\"],\n                        \"description\": snippet[\"description\"],\n                        \"published_at\": snippet[\"publishedAt\"],\n                        \"channel_title\": snippet[\"channelTitle\"],\n                        \"thumbnail_url\": snippet[\"thumbnails\"][\"default\"][\"url\"],\n                    }\n\n                    if self.include_metadata:\n                        # Get video details for additional metadata\n                        video_response = youtube.videos().list(part=\"statistics,contentDetails\", id=video_id).execute()\n\n                        if video_response.get(\"items\"):\n                            video_details = video_response[\"items\"][0]\n                            result.update(\n                                {\n                                    \"view_count\": int(video_details[\"statistics\"][\"viewCount\"]),\n                                    \"like_count\": int(video_details[\"statistics\"].get(\"likeCount\", 0)),\n                                    \"comment_count\": int(video_details[\"statistics\"].get(\"commentCount\", 0)),\n                                    \"duration\": video_details[\"contentDetails\"][\"duration\"],\n                                }\n                            )\n\n                    results.append(result)\n\n                return DataFrame(pd.DataFrame(results))\n\n        except HttpError as e:\n            error_message = f\"YouTube API error: {e!s}\"\n            return DataFrame(pd.DataFrame({\"error\": [error_message]}))\n"},"include_metadata":{"_input_type":"BoolInput","advanced":true,"display_name":"Include Metadata","dynamic":false,"info":"Include video metadata like description and statistics.","list":false,"list_add_label":"Add More","name":"include_metadata","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"max_results":{"_input_type":"IntInput","advanced":false,"display_name":"Max Results","dynamic":false,"info":"The maximum number of results to return.","list":false,"list_add_label":"Add More","name":"max_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":10},"order":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Sort Order","dynamic":false,"external_options":{},"info":"Sort order for the search results.","name":"order","options":["relevance","date","rating","title","viewCount"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"relevance"},"query":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Search Query","dynamic":false,"info":"The search query to look for on YouTube.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"query","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"YouTubeTranscripts":{"base_classes":["Data","DataFrame","Message"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Extracts spoken content from YouTube videos with multiple output options.","display_name":"YouTube Transcripts","documentation":"","edited":false,"field_order":["url","chunk_size_seconds","translation"],"frozen":false,"icon":"YouTube","legacy":false,"metadata":{"code_hash":"c1771da1f21b","dependencies":{"dependencies":[{"name":"pandas","version":"2.2.3"},{"name":"youtube_transcript_api","version":"0.6.3"},{"name":"langchain_community","version":"0.3.21"},{"name":"lfx","version":null}],"total_dependencies":4},"module":"lfx.components.youtube.youtube_transcripts.YouTubeTranscriptsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Chunks","group_outputs":false,"method":"get_dataframe_output","name":"dataframe","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Transcript","group_outputs":false,"method":"get_message_output","name":"message","selected":"Message","tool_mode":true,"types":["Message"],"value":"__UNDEFINED__"},{"allows_loop":false,"cache":true,"display_name":"Transcript + Source","group_outputs":false,"method":"get_data_output","name":"data_output","selected":"Data","tool_mode":true,"types":["Data"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","chunk_size_seconds":{"_input_type":"IntInput","advanced":false,"display_name":"Chunk Size (seconds)","dynamic":false,"info":"The size of each transcript chunk in seconds.","list":false,"list_add_label":"Add More","name":"chunk_size_seconds","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":60},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"import pandas as pd\nimport youtube_transcript_api\nfrom langchain_community.document_loaders import YoutubeLoader\nfrom langchain_community.document_loaders.youtube import TranscriptFormat\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import DropdownInput, IntInput, MultilineInput\nfrom lfx.schema.data import Data\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.schema.message import Message\nfrom lfx.template.field.base import Output\n\n\nclass YouTubeTranscriptsComponent(Component):\n    \"\"\"A component that extracts spoken content from YouTube videos as transcripts.\"\"\"\n\n    display_name: str = \"YouTube Transcripts\"\n    description: str = \"Extracts spoken content from YouTube videos with multiple output options.\"\n    icon: str = \"YouTube\"\n    name = \"YouTubeTranscripts\"\n\n    inputs = [\n        MultilineInput(\n            name=\"url\",\n            display_name=\"Video URL\",\n            info=\"Enter the YouTube video URL to get transcripts from.\",\n            tool_mode=True,\n            required=True,\n        ),\n        IntInput(\n            name=\"chunk_size_seconds\",\n            display_name=\"Chunk Size (seconds)\",\n            value=60,\n            info=\"The size of each transcript chunk in seconds.\",\n        ),\n        DropdownInput(\n            name=\"translation\",\n            display_name=\"Translation Language\",\n            advanced=True,\n            options=[\"\", \"en\", \"es\", \"fr\", \"de\", \"it\", \"pt\", \"ru\", \"ja\", \"ko\", \"hi\", \"ar\", \"id\"],\n            info=\"Translate the transcripts to the specified language. Leave empty for no translation.\",\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"dataframe\", display_name=\"Chunks\", method=\"get_dataframe_output\"),\n        Output(name=\"message\", display_name=\"Transcript\", method=\"get_message_output\"),\n        Output(name=\"data_output\", display_name=\"Transcript + Source\", method=\"get_data_output\"),\n    ]\n\n    def _load_transcripts(self, *, as_chunks: bool = True):\n        \"\"\"Internal method to load transcripts from YouTube.\"\"\"\n        loader = YoutubeLoader.from_youtube_url(\n            self.url,\n            transcript_format=TranscriptFormat.CHUNKS if as_chunks else TranscriptFormat.TEXT,\n            chunk_size_seconds=self.chunk_size_seconds,\n            translation=self.translation or None,\n        )\n        return loader.load()\n\n    def get_dataframe_output(self) -> DataFrame:\n        \"\"\"Provides transcript output as a DataFrame with timestamp and text columns.\"\"\"\n        try:\n            transcripts = self._load_transcripts(as_chunks=True)\n\n            # Create DataFrame with timestamp and text columns\n            data = []\n            for doc in transcripts:\n                start_seconds = int(doc.metadata[\"start_seconds\"])\n                start_minutes = start_seconds // 60\n                start_seconds %= 60\n                timestamp = f\"{start_minutes:02d}:{start_seconds:02d}\"\n                data.append({\"timestamp\": timestamp, \"text\": doc.page_content})\n\n            return DataFrame(pd.DataFrame(data))\n\n        except (youtube_transcript_api.TranscriptsDisabled, youtube_transcript_api.NoTranscriptFound) as exc:\n            return DataFrame(pd.DataFrame({\"error\": [f\"Failed to get YouTube transcripts: {exc!s}\"]}))\n\n    def get_message_output(self) -> Message:\n        \"\"\"Provides transcript output as continuous text.\"\"\"\n        try:\n            transcripts = self._load_transcripts(as_chunks=False)\n            result = transcripts[0].page_content\n            return Message(text=result)\n\n        except (youtube_transcript_api.TranscriptsDisabled, youtube_transcript_api.NoTranscriptFound) as exc:\n            error_msg = f\"Failed to get YouTube transcripts: {exc!s}\"\n            return Message(text=error_msg)\n\n    def get_data_output(self) -> Data:\n        \"\"\"Creates a structured data object with transcript and metadata.\n\n        Returns a Data object containing transcript text, video URL, and any error\n        messages that occurred during processing. The object includes:\n        - 'transcript': continuous text from the entire video (concatenated if multiple parts)\n        - 'video_url': the input YouTube URL\n        - 'error': error message if an exception occurs\n        \"\"\"\n        default_data = {\"transcript\": \"\", \"video_url\": self.url, \"error\": None}\n\n        try:\n            transcripts = self._load_transcripts(as_chunks=False)\n            if not transcripts:\n                default_data[\"error\"] = \"No transcripts found.\"\n                return Data(data=default_data)\n\n            # Combine all transcript parts\n            full_transcript = \" \".join(doc.page_content for doc in transcripts)\n            return Data(data={\"transcript\": full_transcript, \"video_url\": self.url})\n\n        except (\n            youtube_transcript_api.TranscriptsDisabled,\n            youtube_transcript_api.NoTranscriptFound,\n            youtube_transcript_api.CouldNotRetrieveTranscript,\n        ) as exc:\n            default_data[\"error\"] = str(exc)\n            return Data(data=default_data)\n"},"translation":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"Translation Language","dynamic":false,"external_options":{},"info":"Translate the transcripts to the specified language. Leave empty for no translation.","name":"translation","options":["","en","es","fr","de","it","pt","ru","ja","ko","hi","ar","id"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":""},"url":{"_input_type":"MultilineInput","advanced":false,"copy_field":false,"display_name":"Video URL","dynamic":false,"info":"Enter the YouTube video URL to get transcripts from.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"multiline":true,"name":"url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false},"YouTubeTrendingComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Retrieves trending videos from YouTube with filtering options.","display_name":"YouTube Trending","documentation":"","edited":false,"field_order":["api_key","region","category","max_results","include_statistics","include_content_details","include_thumbnails"],"frozen":false,"icon":"YouTube","legacy":false,"metadata":{"code_hash":"1450a5529486","dependencies":{"dependencies":[{"name":"pandas","version":"2.2.3"},{"name":"googleapiclient","version":"2.154.0"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.youtube.trending.YouTubeTrendingComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Trending Videos","group_outputs":false,"method":"get_trending_videos","name":"trending_videos","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"YouTube API Key","dynamic":false,"info":"Your YouTube Data API key.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"category":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Category","dynamic":false,"external_options":{},"info":"The category of videos to retrieve.","name":"category","options":["All","Film & Animation","Autos & Vehicles","Music","Pets & Animals","Sports","Travel & Events","Gaming","People & Blogs","Comedy","Entertainment","News & Politics","Education","Science & Technology","Nonprofits & Activism"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"All"},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from contextlib import contextmanager\n\nimport pandas as pd\nfrom googleapiclient.discovery import build\nfrom googleapiclient.errors import HttpError\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import BoolInput, DropdownInput, IntInput, SecretStrInput\nfrom lfx.log.logger import logger\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.template.field.base import Output\n\nHTTP_FORBIDDEN = 403\nHTTP_NOT_FOUND = 404\nMAX_API_RESULTS = 50\n\n\nclass YouTubeTrendingComponent(Component):\n    \"\"\"A component that retrieves trending videos from YouTube.\"\"\"\n\n    display_name: str = \"YouTube Trending\"\n    description: str = \"Retrieves trending videos from YouTube with filtering options.\"\n    icon: str = \"YouTube\"\n\n    # Dictionary of country codes and names\n    COUNTRY_CODES = {\n        \"Global\": \"US\",  # Default to US for global\n        \"United States\": \"US\",\n        \"Brazil\": \"BR\",\n        \"United Kingdom\": \"GB\",\n        \"India\": \"IN\",\n        \"Japan\": \"JP\",\n        \"South Korea\": \"KR\",\n        \"Germany\": \"DE\",\n        \"France\": \"FR\",\n        \"Canada\": \"CA\",\n        \"Australia\": \"AU\",\n        \"Spain\": \"ES\",\n        \"Italy\": \"IT\",\n        \"Mexico\": \"MX\",\n        \"Russia\": \"RU\",\n        \"Netherlands\": \"NL\",\n        \"Poland\": \"PL\",\n        \"Argentina\": \"AR\",\n    }\n\n    # Dictionary of video categories\n    VIDEO_CATEGORIES = {\n        \"All\": \"0\",\n        \"Film & Animation\": \"1\",\n        \"Autos & Vehicles\": \"2\",\n        \"Music\": \"10\",\n        \"Pets & Animals\": \"15\",\n        \"Sports\": \"17\",\n        \"Travel & Events\": \"19\",\n        \"Gaming\": \"20\",\n        \"People & Blogs\": \"22\",\n        \"Comedy\": \"23\",\n        \"Entertainment\": \"24\",\n        \"News & Politics\": \"25\",\n        \"Education\": \"27\",\n        \"Science & Technology\": \"28\",\n        \"Nonprofits & Activism\": \"29\",\n    }\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"YouTube API Key\",\n            info=\"Your YouTube Data API key.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"region\",\n            display_name=\"Region\",\n            options=list(COUNTRY_CODES.keys()),\n            value=\"Global\",\n            info=\"The region to get trending videos from.\",\n        ),\n        DropdownInput(\n            name=\"category\",\n            display_name=\"Category\",\n            options=list(VIDEO_CATEGORIES.keys()),\n            value=\"All\",\n            info=\"The category of videos to retrieve.\",\n        ),\n        IntInput(\n            name=\"max_results\",\n            display_name=\"Max Results\",\n            value=10,\n            info=\"Maximum number of trending videos to return (1-50).\",\n        ),\n        BoolInput(\n            name=\"include_statistics\",\n            display_name=\"Include Statistics\",\n            value=True,\n            info=\"Include video statistics (views, likes, comments).\",\n        ),\n        BoolInput(\n            name=\"include_content_details\",\n            display_name=\"Include Content Details\",\n            value=True,\n            info=\"Include video duration and quality info.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_thumbnails\",\n            display_name=\"Include Thumbnails\",\n            value=True,\n            info=\"Include video thumbnail URLs.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"trending_videos\", display_name=\"Trending Videos\", method=\"get_trending_videos\"),\n    ]\n\n    max_results: int\n\n    def _format_duration(self, duration: str) -> str:\n        \"\"\"Formats ISO 8601 duration to readable format.\"\"\"\n        import re\n\n        # Remove 'PT' from the start of duration\n        duration = duration[2:]\n\n        hours = 0\n        minutes = 0\n        seconds = 0\n\n        # Extract hours, minutes and seconds\n        time_dict = {}\n        for time_unit in [\"H\", \"M\", \"S\"]:\n            match = re.search(r\"(\\d+)\" + time_unit, duration)\n            if match:\n                time_dict[time_unit] = int(match.group(1))\n\n        if \"H\" in time_dict:\n            hours = time_dict[\"H\"]\n        if \"M\" in time_dict:\n            minutes = time_dict[\"M\"]\n        if \"S\" in time_dict:\n            seconds = time_dict[\"S\"]\n\n        # Format the time string\n        if hours > 0:\n            return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n        return f\"{minutes:02d}:{seconds:02d}\"\n\n    @contextmanager\n    def youtube_client(self):\n        \"\"\"Context manager for YouTube API client.\"\"\"\n        client = build(\"youtube\", \"v3\", developerKey=self.api_key)\n        try:\n            yield client\n        finally:\n            client.close()\n\n    def get_trending_videos(self) -> DataFrame:\n        \"\"\"Retrieves trending videos from YouTube and returns as DataFrame.\"\"\"\n        try:\n            # Validate max_results\n            if not 1 <= self.max_results <= MAX_API_RESULTS:\n                self.max_results = min(max(1, self.max_results), MAX_API_RESULTS)\n\n            # Use context manager for YouTube API client\n            with self.youtube_client() as youtube:\n                # Get country code\n                region_code = self.COUNTRY_CODES[self.region]\n\n                # Prepare API request parts\n                parts = [\"snippet\"]\n                if self.include_statistics:\n                    parts.append(\"statistics\")\n                if self.include_content_details:\n                    parts.append(\"contentDetails\")\n\n                # Prepare API request parameters\n                request_params = {\n                    \"part\": \",\".join(parts),\n                    \"chart\": \"mostPopular\",\n                    \"regionCode\": region_code,\n                    \"maxResults\": self.max_results,\n                }\n\n                # Add category filter if not \"All\"\n                if self.category != \"All\":\n                    request_params[\"videoCategoryId\"] = self.VIDEO_CATEGORIES[self.category]\n\n                # Get trending videos\n                request = youtube.videos().list(**request_params)\n                response = request.execute()\n\n                videos_data = []\n                for item in response.get(\"items\", []):\n                    video_data = {\n                        \"video_id\": item[\"id\"],\n                        \"title\": item[\"snippet\"][\"title\"],\n                        \"description\": item[\"snippet\"][\"description\"],\n                        \"channel_id\": item[\"snippet\"][\"channelId\"],\n                        \"channel_title\": item[\"snippet\"][\"channelTitle\"],\n                        \"published_at\": item[\"snippet\"][\"publishedAt\"],\n                        \"url\": f\"https://www.youtube.com/watch?v={item['id']}\",\n                        \"region\": self.region,\n                        \"category\": self.category,\n                    }\n\n                    # Add thumbnails if requested\n                    if self.include_thumbnails:\n                        for size, thumb in item[\"snippet\"][\"thumbnails\"].items():\n                            video_data[f\"thumbnail_{size}_url\"] = thumb[\"url\"]\n                            video_data[f\"thumbnail_{size}_width\"] = thumb.get(\"width\", 0)\n                            video_data[f\"thumbnail_{size}_height\"] = thumb.get(\"height\", 0)\n\n                    # Add statistics if requested\n                    if self.include_statistics and \"statistics\" in item:\n                        video_data.update(\n                            {\n                                \"view_count\": int(item[\"statistics\"].get(\"viewCount\", 0)),\n                                \"like_count\": int(item[\"statistics\"].get(\"likeCount\", 0)),\n                                \"comment_count\": int(item[\"statistics\"].get(\"commentCount\", 0)),\n                            }\n                        )\n\n                    # Add content details if requested\n                    if self.include_content_details and \"contentDetails\" in item:\n                        content_details = item[\"contentDetails\"]\n                        video_data.update(\n                            {\n                                \"duration\": self._format_duration(content_details[\"duration\"]),\n                                \"definition\": content_details.get(\"definition\", \"hd\").upper(),\n                                \"has_captions\": content_details.get(\"caption\", \"false\") == \"true\",\n                                \"licensed_content\": content_details.get(\"licensedContent\", False),\n                                \"projection\": content_details.get(\"projection\", \"rectangular\"),\n                            }\n                        )\n\n                    videos_data.append(video_data)\n\n                # Convert to DataFrame\n                videos_df = pd.DataFrame(videos_data)\n\n                # Organize columns\n                column_order = [\n                    \"video_id\",\n                    \"title\",\n                    \"channel_id\",\n                    \"channel_title\",\n                    \"category\",\n                    \"region\",\n                    \"published_at\",\n                    \"url\",\n                    \"description\",\n                ]\n\n                if self.include_statistics:\n                    column_order.extend([\"view_count\", \"like_count\", \"comment_count\"])\n\n                if self.include_content_details:\n                    column_order.extend([\"duration\", \"definition\", \"has_captions\", \"licensed_content\", \"projection\"])\n\n                # Add thumbnail columns at the end if included\n                if self.include_thumbnails:\n                    thumbnail_cols = [col for col in videos_df.columns if col.startswith(\"thumbnail_\")]\n                    column_order.extend(sorted(thumbnail_cols))\n\n                # Reorder columns, including any that might not be in column_order\n                remaining_cols = [col for col in videos_df.columns if col not in column_order]\n                videos_df = videos_df[column_order + remaining_cols]\n\n                return DataFrame(videos_df)\n\n        except HttpError as e:\n            error_message = f\"YouTube API error: {e}\"\n            if e.resp.status == HTTP_FORBIDDEN:\n                error_message = \"API quota exceeded or access forbidden.\"\n            elif e.resp.status == HTTP_NOT_FOUND:\n                error_message = \"Resource not found.\"\n\n            return DataFrame(pd.DataFrame({\"error\": [error_message]}))\n\n        except Exception as e:  # noqa: BLE001\n            logger.exception(\"An unexpected error occurred:\")\n            return DataFrame(pd.DataFrame({\"error\": [str(e)]}))\n"},"include_content_details":{"_input_type":"BoolInput","advanced":true,"display_name":"Include Content Details","dynamic":false,"info":"Include video duration and quality info.","list":false,"list_add_label":"Add More","name":"include_content_details","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"include_statistics":{"_input_type":"BoolInput","advanced":false,"display_name":"Include Statistics","dynamic":false,"info":"Include video statistics (views, likes, comments).","list":false,"list_add_label":"Add More","name":"include_statistics","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"include_thumbnails":{"_input_type":"BoolInput","advanced":true,"display_name":"Include Thumbnails","dynamic":false,"info":"Include video thumbnail URLs.","list":false,"list_add_label":"Add More","name":"include_thumbnails","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"max_results":{"_input_type":"IntInput","advanced":false,"display_name":"Max Results","dynamic":false,"info":"Maximum number of trending videos to return (1-50).","list":false,"list_add_label":"Add More","name":"max_results","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"int","value":10},"region":{"_input_type":"DropdownInput","advanced":false,"combobox":false,"dialog_inputs":{},"display_name":"Region","dynamic":false,"external_options":{},"info":"The region to get trending videos from.","name":"region","options":["Global","United States","Brazil","United Kingdom","India","Japan","South Korea","Germany","France","Canada","Australia","Spain","Italy","Mexico","Russia","Netherlands","Poland","Argentina"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"Global"}},"tool_mode":false},"YouTubeVideoDetailsComponent":{"base_classes":["DataFrame"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Retrieves detailed information and statistics about YouTube videos.","display_name":"YouTube Video Details","documentation":"","edited":false,"field_order":["video_url","api_key","include_statistics","include_content_details","include_tags","include_thumbnails"],"frozen":false,"icon":"YouTube","legacy":false,"metadata":{"code_hash":"6c2be0d5450b","dependencies":{"dependencies":[{"name":"googleapiclient","version":"2.154.0"},{"name":"pandas","version":"2.2.3"},{"name":"lfx","version":null}],"total_dependencies":3},"module":"lfx.components.youtube.video_details.YouTubeVideoDetailsComponent"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Video Data","group_outputs":false,"method":"get_video_details","name":"video_data","selected":"DataFrame","tool_mode":true,"types":["DataFrame"],"value":"__UNDEFINED__"}],"pinned":false,"template":{"_type":"Component","api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"YouTube API Key","dynamic":false,"info":"Your YouTube Data API key.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":true,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from contextlib import contextmanager\n\nimport googleapiclient\nimport pandas as pd\nfrom googleapiclient.discovery import build\nfrom googleapiclient.errors import HttpError\n\nfrom lfx.custom.custom_component.component import Component\nfrom lfx.inputs.inputs import BoolInput, MessageTextInput, SecretStrInput\nfrom lfx.schema.dataframe import DataFrame\nfrom lfx.template.field.base import Output\n\n\nclass YouTubeVideoDetailsComponent(Component):\n    \"\"\"A component that retrieves detailed information about YouTube videos.\"\"\"\n\n    display_name: str = \"YouTube Video Details\"\n    description: str = \"Retrieves detailed information and statistics about YouTube videos.\"\n    icon: str = \"YouTube\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"video_url\",\n            display_name=\"Video URL\",\n            info=\"The URL of the YouTube video.\",\n            tool_mode=True,\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"YouTube API Key\",\n            info=\"Your YouTube Data API key.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"include_statistics\",\n            display_name=\"Include Statistics\",\n            value=True,\n            info=\"Include video statistics (views, likes, comments).\",\n        ),\n        BoolInput(\n            name=\"include_content_details\",\n            display_name=\"Include Content Details\",\n            value=True,\n            info=\"Include video duration, quality, and age restriction info.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_tags\",\n            display_name=\"Include Tags\",\n            value=True,\n            info=\"Include video tags and keywords.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_thumbnails\",\n            display_name=\"Include Thumbnails\",\n            value=True,\n            info=\"Include video thumbnail URLs in different resolutions.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"video_data\", display_name=\"Video Data\", method=\"get_video_details\"),\n    ]\n\n    API_FORBIDDEN = 403\n    VIDEO_NOT_FOUND = 404\n\n    @contextmanager\n    def youtube_client(self):\n        \"\"\"Context manager for YouTube API client.\"\"\"\n        client = build(\"youtube\", \"v3\", developerKey=self.api_key)\n        try:\n            yield client\n        finally:\n            client.close()\n\n    def _extract_video_id(self, video_url: str) -> str:\n        \"\"\"Extracts the video ID from a YouTube URL.\"\"\"\n        import re\n\n        patterns = [\n            r\"(?:youtube\\.com\\/watch\\?v=|youtu.be\\/|youtube.com\\/embed\\/)([^&\\n?#]+)\",\n            r\"youtube.com\\/shorts\\/([^&\\n?#]+)\",\n        ]\n\n        for pattern in patterns:\n            match = re.search(pattern, video_url)\n            if match:\n                return match.group(1)\n\n        return video_url.strip()\n\n    def _format_duration(self, duration: str) -> str:\n        \"\"\"Formats the ISO 8601 duration to a readable format.\"\"\"\n        import re\n\n        hours = 0\n        minutes = 0\n        seconds = 0\n\n        hours_match = re.search(r\"(\\d+)H\", duration)\n        minutes_match = re.search(r\"(\\d+)M\", duration)\n        seconds_match = re.search(r\"(\\d+)S\", duration)\n\n        if hours_match:\n            hours = int(hours_match.group(1))\n        if minutes_match:\n            minutes = int(minutes_match.group(1))\n        if seconds_match:\n            seconds = int(seconds_match.group(1))\n\n        if hours > 0:\n            return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n        return f\"{minutes:02d}:{seconds:02d}\"\n\n    def get_video_details(self) -> DataFrame:\n        \"\"\"Retrieves detailed information about a YouTube video and returns as DataFrame.\"\"\"\n        try:\n            with self.youtube_client() as youtube:\n                # Extract video ID\n                video_id = self._extract_video_id(self.video_url)\n\n                # Prepare parts for the API request\n                parts = [\"snippet\"]\n                if self.include_statistics:\n                    parts.append(\"statistics\")\n                if self.include_content_details:\n                    parts.append(\"contentDetails\")\n\n                # Get video information\n                video_response = youtube.videos().list(part=\",\".join(parts), id=video_id).execute()\n\n                if not video_response[\"items\"]:\n                    return DataFrame(pd.DataFrame({\"error\": [\"Video not found\"]}))\n\n                video_info = video_response[\"items\"][0]\n                snippet = video_info[\"snippet\"]\n\n                # Build video data dictionary\n                video_data = {\n                    \"video_id\": [video_id],\n                    \"url\": [f\"https://www.youtube.com/watch?v={video_id}\"],\n                    \"title\": [snippet[\"title\"]],\n                    \"description\": [snippet[\"description\"]],\n                    \"published_at\": [snippet[\"publishedAt\"]],\n                    \"channel_id\": [snippet[\"channelId\"]],\n                    \"channel_title\": [snippet[\"channelTitle\"]],\n                    \"category_id\": [snippet.get(\"categoryId\", \"Unknown\")],\n                    \"live_broadcast_content\": [snippet.get(\"liveBroadcastContent\", \"none\")],\n                }\n\n                # Add thumbnails if requested\n                if self.include_thumbnails:\n                    for size, thumb in snippet[\"thumbnails\"].items():\n                        video_data[f\"thumbnail_{size}_url\"] = [thumb[\"url\"]]\n                        video_data[f\"thumbnail_{size}_width\"] = [thumb.get(\"width\", 0)]\n                        video_data[f\"thumbnail_{size}_height\"] = [thumb.get(\"height\", 0)]\n\n                # Add tags if requested\n                if self.include_tags and \"tags\" in snippet:\n                    video_data[\"tags\"] = [\", \".join(snippet[\"tags\"])]\n                    video_data[\"tags_count\"] = [len(snippet[\"tags\"])]\n\n                # Add statistics if requested\n                if self.include_statistics and \"statistics\" in video_info:\n                    stats = video_info[\"statistics\"]\n                    video_data.update(\n                        {\n                            \"view_count\": [int(stats.get(\"viewCount\", 0))],\n                            \"like_count\": [int(stats.get(\"likeCount\", 0))],\n                            \"favorite_count\": [int(stats.get(\"favoriteCount\", 0))],\n                            \"comment_count\": [int(stats.get(\"commentCount\", 0))],\n                        }\n                    )\n\n                # Add content details if requested\n                if self.include_content_details and \"contentDetails\" in video_info:\n                    content_details = video_info[\"contentDetails\"]\n                    video_data.update(\n                        {\n                            \"duration\": [self._format_duration(content_details[\"duration\"])],\n                            \"dimension\": [content_details.get(\"dimension\", \"2d\")],\n                            \"definition\": [content_details.get(\"definition\", \"hd\").upper()],\n                            \"has_captions\": [content_details.get(\"caption\", \"false\") == \"true\"],\n                            \"licensed_content\": [content_details.get(\"licensedContent\", False)],\n                            \"projection\": [content_details.get(\"projection\", \"rectangular\")],\n                            \"has_custom_thumbnails\": [content_details.get(\"hasCustomThumbnail\", False)],\n                        }\n                    )\n\n                    # Add content rating if available\n                    if \"contentRating\" in content_details:\n                        rating_info = content_details[\"contentRating\"]\n                        video_data[\"content_rating\"] = [str(rating_info)]\n\n                # Create DataFrame with organized columns\n                video_df = pd.DataFrame(video_data)\n\n                # Organize columns in logical groups\n                basic_cols = [\n                    \"video_id\",\n                    \"title\",\n                    \"url\",\n                    \"channel_id\",\n                    \"channel_title\",\n                    \"published_at\",\n                    \"category_id\",\n                    \"live_broadcast_content\",\n                    \"description\",\n                ]\n\n                stat_cols = [\"view_count\", \"like_count\", \"favorite_count\", \"comment_count\"]\n\n                content_cols = [\n                    \"duration\",\n                    \"dimension\",\n                    \"definition\",\n                    \"has_captions\",\n                    \"licensed_content\",\n                    \"projection\",\n                    \"has_custom_thumbnails\",\n                    \"content_rating\",\n                ]\n\n                tag_cols = [\"tags\", \"tags_count\"]\n\n                thumb_cols = [col for col in video_df.columns if col.startswith(\"thumbnail_\")]\n\n                # Reorder columns based on what's included\n                ordered_cols = basic_cols.copy()\n\n                if self.include_statistics:\n                    ordered_cols.extend([col for col in stat_cols if col in video_df.columns])\n\n                if self.include_content_details:\n                    ordered_cols.extend([col for col in content_cols if col in video_df.columns])\n\n                if self.include_tags:\n                    ordered_cols.extend([col for col in tag_cols if col in video_df.columns])\n\n                if self.include_thumbnails:\n                    ordered_cols.extend(sorted(thumb_cols))\n\n                # Add any remaining columns\n                remaining_cols = [col for col in video_df.columns if col not in ordered_cols]\n                ordered_cols.extend(remaining_cols)\n\n                return DataFrame(video_df[ordered_cols])\n\n        except (HttpError, googleapiclient.errors.HttpError) as e:\n            error_message = f\"YouTube API error: {e!s}\"\n            if e.resp.status == self.API_FORBIDDEN:\n                error_message = \"API quota exceeded or access forbidden.\"\n            elif e.resp.status == self.VIDEO_NOT_FOUND:\n                error_message = \"Video not found.\"\n\n            return DataFrame(pd.DataFrame({\"error\": [error_message]}))\n\n        except KeyError as e:\n            return DataFrame(pd.DataFrame({\"error\": [str(e)]}))\n"},"include_content_details":{"_input_type":"BoolInput","advanced":true,"display_name":"Include Content Details","dynamic":false,"info":"Include video duration, quality, and age restriction info.","list":false,"list_add_label":"Add More","name":"include_content_details","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"include_statistics":{"_input_type":"BoolInput","advanced":false,"display_name":"Include Statistics","dynamic":false,"info":"Include video statistics (views, likes, comments).","list":false,"list_add_label":"Add More","name":"include_statistics","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"include_tags":{"_input_type":"BoolInput","advanced":true,"display_name":"Include Tags","dynamic":false,"info":"Include video tags and keywords.","list":false,"list_add_label":"Add More","name":"include_tags","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"include_thumbnails":{"_input_type":"BoolInput","advanced":true,"display_name":"Include Thumbnails","dynamic":false,"info":"Include video thumbnail URLs in different resolutions.","list":false,"list_add_label":"Add More","name":"include_thumbnails","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_metadata":true,"type":"bool","value":true},"video_url":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Video URL","dynamic":false,"info":"The URL of the YouTube video.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"video_url","placeholder":"","required":true,"show":true,"title_case":false,"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}],["zep",{"ZepChatMemory":{"base_classes":["Memory"],"beta":false,"conditional_paths":[],"custom_fields":{},"description":"Retrieves and store chat messages from Zep.","display_name":"Zep Chat Memory","documentation":"","edited":false,"field_order":["url","api_key","api_base_path","session_id"],"frozen":false,"icon":"ZepMemory","legacy":true,"metadata":{"code_hash":"ec825c33caf6","dependencies":{"dependencies":[{"name":"lfx","version":null},{"name":"zep_python","version":"2.0.2"}],"total_dependencies":2},"module":"lfx.components.zep.zep.ZepChatMemory"},"minimized":false,"output_types":[],"outputs":[{"allows_loop":false,"cache":true,"display_name":"Memory","group_outputs":false,"method":"build_message_history","name":"memory","selected":"Memory","tool_mode":true,"types":["Memory"],"value":"__UNDEFINED__"}],"pinned":false,"replacement":["helpers.Memory"],"template":{"_type":"Component","api_base_path":{"_input_type":"DropdownInput","advanced":true,"combobox":false,"dialog_inputs":{},"display_name":"API Base Path","dynamic":false,"external_options":{},"info":"","name":"api_base_path","options":["api/v1","api/v2"],"options_metadata":[],"placeholder":"","required":false,"show":true,"title_case":false,"toggle":false,"tool_mode":false,"trace_as_metadata":true,"type":"str","value":"api/v1"},"api_key":{"_input_type":"SecretStrInput","advanced":false,"display_name":"Zep API Key","dynamic":false,"info":"API Key for the Zep instance.","input_types":[],"load_from_db":true,"name":"api_key","password":true,"placeholder":"","required":false,"show":true,"title_case":false,"type":"str","value":""},"code":{"advanced":true,"dynamic":true,"fileTypes":[],"file_path":"","info":"","list":false,"load_from_db":false,"multiline":true,"name":"code","password":false,"placeholder":"","required":true,"show":true,"title_case":false,"type":"code","value":"from lfx.base.memory.model import LCChatMemoryComponent\nfrom lfx.field_typing.constants import Memory\nfrom lfx.inputs.inputs import DropdownInput, MessageTextInput, SecretStrInput\n\n\nclass ZepChatMemory(LCChatMemoryComponent):\n    display_name = \"Zep Chat Memory\"\n    description = \"Retrieves and store chat messages from Zep.\"\n    name = \"ZepChatMemory\"\n    icon = \"ZepMemory\"\n    legacy = True\n    replacement = [\"helpers.Memory\"]\n\n    inputs = [\n        MessageTextInput(name=\"url\", display_name=\"Zep URL\", info=\"URL of the Zep instance.\"),\n        SecretStrInput(name=\"api_key\", display_name=\"Zep API Key\", info=\"API Key for the Zep instance.\"),\n        DropdownInput(\n            name=\"api_base_path\",\n            display_name=\"API Base Path\",\n            options=[\"api/v1\", \"api/v2\"],\n            value=\"api/v1\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n    ]\n\n    def build_message_history(self) -> Memory:\n        try:\n            # Monkeypatch API_BASE_PATH to\n            # avoid 404\n            # This is a workaround for the local Zep instance\n            # cloud Zep works with v2\n            import zep_python.zep_client\n            from zep_python import ZepClient\n            from zep_python.langchain import ZepChatMessageHistory\n\n            zep_python.zep_client.API_BASE_PATH = self.api_base_path\n        except ImportError as e:\n            msg = \"Could not import zep-python package. Please install it with `pip install zep-python`.\"\n            raise ImportError(msg) from e\n\n        zep_client = ZepClient(api_url=self.url, api_key=self.api_key)\n        return ZepChatMessageHistory(session_id=self.session_id, zep_client=zep_client)\n"},"session_id":{"_input_type":"MessageTextInput","advanced":true,"display_name":"Session ID","dynamic":false,"info":"Session ID for the message.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"session_id","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""},"url":{"_input_type":"MessageTextInput","advanced":false,"display_name":"Zep URL","dynamic":false,"info":"URL of the Zep instance.","input_types":["Message"],"list":false,"list_add_label":"Add More","load_from_db":false,"name":"url","placeholder":"","required":false,"show":true,"title_case":false,"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"type":"str","value":""}},"tool_mode":false}}]],"metadata":{"num_components":358,"num_modules":92},"sha256":"51cad3d711f4a413dbc6a7758be752707d0813d44bbb0091d7a9459bbb83f787","version":"1.6.4"}